{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST](#3-patchtst)\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2157750\n",
      "\tspeed: 0.0573s/iter; left time: 1032.1750s\n",
      "\titers: 200, epoch: 1 | loss: 0.1963026\n",
      "\tspeed: 0.0345s/iter; left time: 618.3465s\n",
      "\titers: 300, epoch: 1 | loss: 0.1900428\n",
      "\tspeed: 0.0346s/iter; left time: 616.3469s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759242\n",
      "\tspeed: 0.0346s/iter; left time: 612.6584s\n",
      "\titers: 500, epoch: 1 | loss: 0.1711153\n",
      "\tspeed: 0.0346s/iter; left time: 609.0709s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630517\n",
      "\tspeed: 0.0346s/iter; left time: 605.7895s\n",
      "\titers: 700, epoch: 1 | loss: 0.1811213\n",
      "\tspeed: 0.0346s/iter; left time: 602.2036s\n",
      "\titers: 800, epoch: 1 | loss: 0.1556394\n",
      "\tspeed: 0.0346s/iter; left time: 598.6039s\n",
      "\titers: 900, epoch: 1 | loss: 0.1458707\n",
      "\tspeed: 0.0346s/iter; left time: 595.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.96s\n",
      "Steps: 906 | Train Loss: 0.1844934 Vali Loss: 0.1649067 Test Loss: 0.1739943\n",
      "Validation loss decreased (inf --> 0.164907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1358088\n",
      "\tspeed: 0.1027s/iter; left time: 1757.8565s\n",
      "\titers: 200, epoch: 2 | loss: 0.1412189\n",
      "\tspeed: 0.0345s/iter; left time: 586.6060s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239359\n",
      "\tspeed: 0.0345s/iter; left time: 582.8982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1101899\n",
      "\tspeed: 0.0345s/iter; left time: 579.3501s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120785\n",
      "\tspeed: 0.0344s/iter; left time: 575.1125s\n",
      "\titers: 600, epoch: 2 | loss: 0.1019989\n",
      "\tspeed: 0.0344s/iter; left time: 571.9308s\n",
      "\titers: 700, epoch: 2 | loss: 0.1072432\n",
      "\tspeed: 0.0339s/iter; left time: 559.6339s\n",
      "\titers: 800, epoch: 2 | loss: 0.1118224\n",
      "\tspeed: 0.0338s/iter; left time: 555.2880s\n",
      "\titers: 900, epoch: 2 | loss: 0.1012448\n",
      "\tspeed: 0.0338s/iter; left time: 551.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.1192783 Vali Loss: 0.1259812 Test Loss: 0.1363558\n",
      "Validation loss decreased (0.164907 --> 0.125981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092039\n",
      "\tspeed: 0.0994s/iter; left time: 1611.1556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914676\n",
      "\tspeed: 0.0344s/iter; left time: 554.0304s\n",
      "\titers: 300, epoch: 3 | loss: 0.0905245\n",
      "\tspeed: 0.0344s/iter; left time: 550.6343s\n",
      "\titers: 400, epoch: 3 | loss: 0.0860451\n",
      "\tspeed: 0.0344s/iter; left time: 547.1417s\n",
      "\titers: 500, epoch: 3 | loss: 0.0840570\n",
      "\tspeed: 0.0344s/iter; left time: 544.1619s\n",
      "\titers: 600, epoch: 3 | loss: 0.0864475\n",
      "\tspeed: 0.0345s/iter; left time: 541.2266s\n",
      "\titers: 700, epoch: 3 | loss: 0.0776535\n",
      "\tspeed: 0.0344s/iter; left time: 537.5386s\n",
      "\titers: 800, epoch: 3 | loss: 0.0880026\n",
      "\tspeed: 0.0339s/iter; left time: 525.2373s\n",
      "\titers: 900, epoch: 3 | loss: 0.0833839\n",
      "\tspeed: 0.0339s/iter; left time: 522.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.37s\n",
      "Steps: 906 | Train Loss: 0.0881952 Vali Loss: 0.1017724 Test Loss: 0.1044518\n",
      "Validation loss decreased (0.125981 --> 0.101772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744945\n",
      "\tspeed: 0.0997s/iter; left time: 1525.1724s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867104\n",
      "\tspeed: 0.0346s/iter; left time: 526.1904s\n",
      "\titers: 300, epoch: 4 | loss: 0.0777602\n",
      "\tspeed: 0.0346s/iter; left time: 522.0265s\n",
      "\titers: 400, epoch: 4 | loss: 0.0799538\n",
      "\tspeed: 0.0345s/iter; left time: 518.2007s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863173\n",
      "\tspeed: 0.0345s/iter; left time: 514.7978s\n",
      "\titers: 600, epoch: 4 | loss: 0.0789659\n",
      "\tspeed: 0.0345s/iter; left time: 510.7476s\n",
      "\titers: 700, epoch: 4 | loss: 0.0863506\n",
      "\tspeed: 0.0346s/iter; left time: 508.8477s\n",
      "\titers: 800, epoch: 4 | loss: 0.0809430\n",
      "\tspeed: 0.0346s/iter; left time: 504.7647s\n",
      "\titers: 900, epoch: 4 | loss: 0.0644707\n",
      "\tspeed: 0.0345s/iter; left time: 500.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0795589 Vali Loss: 0.0984519 Test Loss: 0.0999526\n",
      "Validation loss decreased (0.101772 --> 0.098452).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0721323\n",
      "\tspeed: 0.0989s/iter; left time: 1423.9969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783579\n",
      "\tspeed: 0.0345s/iter; left time: 493.9352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0719792\n",
      "\tspeed: 0.0346s/iter; left time: 490.6305s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887703\n",
      "\tspeed: 0.0346s/iter; left time: 487.6967s\n",
      "\titers: 500, epoch: 5 | loss: 0.0698399\n",
      "\tspeed: 0.0345s/iter; left time: 483.3961s\n",
      "\titers: 600, epoch: 5 | loss: 0.0868544\n",
      "\tspeed: 0.0346s/iter; left time: 480.1936s\n",
      "\titers: 700, epoch: 5 | loss: 0.0848192\n",
      "\tspeed: 0.0346s/iter; left time: 477.6474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0792127\n",
      "\tspeed: 0.0345s/iter; left time: 472.9793s\n",
      "\titers: 900, epoch: 5 | loss: 0.0864622\n",
      "\tspeed: 0.0345s/iter; left time: 469.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0759394 Vali Loss: 0.0958418 Test Loss: 0.1013505\n",
      "Validation loss decreased (0.098452 --> 0.095842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0766028\n",
      "\tspeed: 0.1005s/iter; left time: 1355.8127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0649590\n",
      "\tspeed: 0.0340s/iter; left time: 454.6845s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727186\n",
      "\tspeed: 0.0340s/iter; left time: 451.7025s\n",
      "\titers: 400, epoch: 6 | loss: 0.0766119\n",
      "\tspeed: 0.0340s/iter; left time: 448.5078s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743469\n",
      "\tspeed: 0.0339s/iter; left time: 444.3921s\n",
      "\titers: 600, epoch: 6 | loss: 0.0666672\n",
      "\tspeed: 0.0342s/iter; left time: 444.0445s\n",
      "\titers: 700, epoch: 6 | loss: 0.0702888\n",
      "\tspeed: 0.0346s/iter; left time: 445.4402s\n",
      "\titers: 800, epoch: 6 | loss: 0.0753023\n",
      "\tspeed: 0.0345s/iter; left time: 441.7408s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721991\n",
      "\tspeed: 0.0345s/iter; left time: 438.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 906 | Train Loss: 0.0725840 Vali Loss: 0.0960399 Test Loss: 0.1029606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0633076\n",
      "\tspeed: 0.0959s/iter; left time: 1207.1412s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646344\n",
      "\tspeed: 0.0341s/iter; left time: 425.4750s\n",
      "\titers: 300, epoch: 7 | loss: 0.0732895\n",
      "\tspeed: 0.0341s/iter; left time: 421.7839s\n",
      "\titers: 400, epoch: 7 | loss: 0.0704056\n",
      "\tspeed: 0.0341s/iter; left time: 418.9666s\n",
      "\titers: 500, epoch: 7 | loss: 0.0750957\n",
      "\tspeed: 0.0340s/iter; left time: 414.5119s\n",
      "\titers: 600, epoch: 7 | loss: 0.0560974\n",
      "\tspeed: 0.0340s/iter; left time: 411.1310s\n",
      "\titers: 700, epoch: 7 | loss: 0.0703704\n",
      "\tspeed: 0.0339s/iter; left time: 406.7731s\n",
      "\titers: 800, epoch: 7 | loss: 0.0585428\n",
      "\tspeed: 0.0340s/iter; left time: 404.0264s\n",
      "\titers: 900, epoch: 7 | loss: 0.0656901\n",
      "\tspeed: 0.0340s/iter; left time: 400.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0696662 Vali Loss: 0.0953170 Test Loss: 0.1043832\n",
      "Validation loss decreased (0.095842 --> 0.095317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597942\n",
      "\tspeed: 0.0999s/iter; left time: 1166.6990s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753576\n",
      "\tspeed: 0.0340s/iter; left time: 394.0254s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652202\n",
      "\tspeed: 0.0340s/iter; left time: 389.8927s\n",
      "\titers: 400, epoch: 8 | loss: 0.0703675\n",
      "\tspeed: 0.0340s/iter; left time: 386.8097s\n",
      "\titers: 500, epoch: 8 | loss: 0.0684308\n",
      "\tspeed: 0.0340s/iter; left time: 383.7727s\n",
      "\titers: 600, epoch: 8 | loss: 0.0796844\n",
      "\tspeed: 0.0340s/iter; left time: 379.9436s\n",
      "\titers: 700, epoch: 8 | loss: 0.0586823\n",
      "\tspeed: 0.0340s/iter; left time: 376.6601s\n",
      "\titers: 800, epoch: 8 | loss: 0.0628379\n",
      "\tspeed: 0.0340s/iter; left time: 373.1167s\n",
      "\titers: 900, epoch: 8 | loss: 0.0772258\n",
      "\tspeed: 0.0340s/iter; left time: 369.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0667833 Vali Loss: 0.0989558 Test Loss: 0.1058859\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731515\n",
      "\tspeed: 0.0953s/iter; left time: 1026.8488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666756\n",
      "\tspeed: 0.0339s/iter; left time: 362.1014s\n",
      "\titers: 300, epoch: 9 | loss: 0.0595185\n",
      "\tspeed: 0.0340s/iter; left time: 358.9964s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703624\n",
      "\tspeed: 0.0339s/iter; left time: 354.9658s\n",
      "\titers: 500, epoch: 9 | loss: 0.0656522\n",
      "\tspeed: 0.0339s/iter; left time: 351.8254s\n",
      "\titers: 600, epoch: 9 | loss: 0.0701082\n",
      "\tspeed: 0.0340s/iter; left time: 348.9358s\n",
      "\titers: 700, epoch: 9 | loss: 0.0658102\n",
      "\tspeed: 0.0340s/iter; left time: 345.7134s\n",
      "\titers: 800, epoch: 9 | loss: 0.0694849\n",
      "\tspeed: 0.0340s/iter; left time: 342.2395s\n",
      "\titers: 900, epoch: 9 | loss: 0.0585585\n",
      "\tspeed: 0.0340s/iter; left time: 338.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0644456 Vali Loss: 0.0969864 Test Loss: 0.1054834\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0660802\n",
      "\tspeed: 0.0965s/iter; left time: 952.2213s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685927\n",
      "\tspeed: 0.0346s/iter; left time: 337.5984s\n",
      "\titers: 300, epoch: 10 | loss: 0.0581311\n",
      "\tspeed: 0.0346s/iter; left time: 334.6282s\n",
      "\titers: 400, epoch: 10 | loss: 0.0709546\n",
      "\tspeed: 0.0346s/iter; left time: 330.5468s\n",
      "\titers: 500, epoch: 10 | loss: 0.0617054\n",
      "\tspeed: 0.0345s/iter; left time: 326.9514s\n",
      "\titers: 600, epoch: 10 | loss: 0.0566655\n",
      "\tspeed: 0.0344s/iter; left time: 322.5654s\n",
      "\titers: 700, epoch: 10 | loss: 0.0555644\n",
      "\tspeed: 0.0344s/iter; left time: 318.7316s\n",
      "\titers: 800, epoch: 10 | loss: 0.0605263\n",
      "\tspeed: 0.0342s/iter; left time: 313.3976s\n",
      "\titers: 900, epoch: 10 | loss: 0.0554270\n",
      "\tspeed: 0.0346s/iter; left time: 313.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.0618099 Vali Loss: 0.0958811 Test Loss: 0.1058694\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619151\n",
      "\tspeed: 0.0963s/iter; left time: 863.0085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597805\n",
      "\tspeed: 0.0344s/iter; left time: 304.8721s\n",
      "\titers: 300, epoch: 11 | loss: 0.0536805\n",
      "\tspeed: 0.0343s/iter; left time: 300.7942s\n",
      "\titers: 400, epoch: 11 | loss: 0.0513019\n",
      "\tspeed: 0.0342s/iter; left time: 296.3691s\n",
      "\titers: 500, epoch: 11 | loss: 0.0637296\n",
      "\tspeed: 0.0340s/iter; left time: 291.1695s\n",
      "\titers: 600, epoch: 11 | loss: 0.0655506\n",
      "\tspeed: 0.0345s/iter; left time: 291.5188s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623056\n",
      "\tspeed: 0.0346s/iter; left time: 289.1530s\n",
      "\titers: 800, epoch: 11 | loss: 0.0541347\n",
      "\tspeed: 0.0345s/iter; left time: 285.3061s\n",
      "\titers: 900, epoch: 11 | loss: 0.0503099\n",
      "\tspeed: 0.0346s/iter; left time: 282.1885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0593142 Vali Loss: 0.0960872 Test Loss: 0.1093873\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611448\n",
      "\tspeed: 0.0971s/iter; left time: 782.3115s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560043\n",
      "\tspeed: 0.0345s/iter; left time: 274.5392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0558763\n",
      "\tspeed: 0.0346s/iter; left time: 271.4691s\n",
      "\titers: 400, epoch: 12 | loss: 0.0633862\n",
      "\tspeed: 0.0345s/iter; left time: 267.7986s\n",
      "\titers: 500, epoch: 12 | loss: 0.0537031\n",
      "\tspeed: 0.0345s/iter; left time: 263.8130s\n",
      "\titers: 600, epoch: 12 | loss: 0.0556691\n",
      "\tspeed: 0.0345s/iter; left time: 260.6213s\n",
      "\titers: 700, epoch: 12 | loss: 0.0593802\n",
      "\tspeed: 0.0345s/iter; left time: 257.2170s\n",
      "\titers: 800, epoch: 12 | loss: 0.0507883\n",
      "\tspeed: 0.0341s/iter; left time: 251.0438s\n",
      "\titers: 900, epoch: 12 | loss: 0.0559344\n",
      "\tspeed: 0.0341s/iter; left time: 247.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.50s\n",
      "Steps: 906 | Train Loss: 0.0574293 Vali Loss: 0.0990894 Test Loss: 0.1103720\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025507517158985138, rmse:0.15971073508262634, mae:0.1042659804224968, rse:0.5640227794647217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2230141\n",
      "\tspeed: 0.0367s/iter; left time: 661.5227s\n",
      "\titers: 200, epoch: 1 | loss: 0.1912384\n",
      "\tspeed: 0.0340s/iter; left time: 608.9154s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890538\n",
      "\tspeed: 0.0340s/iter; left time: 606.1844s\n",
      "\titers: 400, epoch: 1 | loss: 0.1821308\n",
      "\tspeed: 0.0340s/iter; left time: 602.3591s\n",
      "\titers: 500, epoch: 1 | loss: 0.1777495\n",
      "\tspeed: 0.0340s/iter; left time: 598.7651s\n",
      "\titers: 600, epoch: 1 | loss: 0.1753001\n",
      "\tspeed: 0.0340s/iter; left time: 594.9457s\n",
      "\titers: 700, epoch: 1 | loss: 0.1703886\n",
      "\tspeed: 0.0339s/iter; left time: 591.3277s\n",
      "\titers: 800, epoch: 1 | loss: 0.1719142\n",
      "\tspeed: 0.0340s/iter; left time: 589.2019s\n",
      "\titers: 900, epoch: 1 | loss: 0.1525570\n",
      "\tspeed: 0.0343s/iter; left time: 590.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.1884397 Vali Loss: 0.1670010 Test Loss: 0.1773647\n",
      "Validation loss decreased (inf --> 0.167001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437568\n",
      "\tspeed: 0.0981s/iter; left time: 1678.7434s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364804\n",
      "\tspeed: 0.0340s/iter; left time: 578.6627s\n",
      "\titers: 300, epoch: 2 | loss: 0.1206845\n",
      "\tspeed: 0.0339s/iter; left time: 574.1556s\n",
      "\titers: 400, epoch: 2 | loss: 0.1204325\n",
      "\tspeed: 0.0339s/iter; left time: 570.6358s\n",
      "\titers: 500, epoch: 2 | loss: 0.1200934\n",
      "\tspeed: 0.0339s/iter; left time: 567.3894s\n",
      "\titers: 600, epoch: 2 | loss: 0.1026905\n",
      "\tspeed: 0.0340s/iter; left time: 565.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.1184056\n",
      "\tspeed: 0.0342s/iter; left time: 564.1581s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938529\n",
      "\tspeed: 0.0340s/iter; left time: 557.4805s\n",
      "\titers: 900, epoch: 2 | loss: 0.1178905\n",
      "\tspeed: 0.0340s/iter; left time: 554.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.1221062 Vali Loss: 0.1266311 Test Loss: 0.1376089\n",
      "Validation loss decreased (0.167001 --> 0.126631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071769\n",
      "\tspeed: 0.0964s/iter; left time: 1562.9527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011983\n",
      "\tspeed: 0.0340s/iter; left time: 547.1883s\n",
      "\titers: 300, epoch: 3 | loss: 0.0976297\n",
      "\tspeed: 0.0339s/iter; left time: 543.1893s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108132\n",
      "\tspeed: 0.0340s/iter; left time: 541.4452s\n",
      "\titers: 500, epoch: 3 | loss: 0.1018856\n",
      "\tspeed: 0.0340s/iter; left time: 537.0724s\n",
      "\titers: 600, epoch: 3 | loss: 0.0973330\n",
      "\tspeed: 0.0339s/iter; left time: 533.1113s\n",
      "\titers: 700, epoch: 3 | loss: 0.1023080\n",
      "\tspeed: 0.0340s/iter; left time: 530.2765s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062835\n",
      "\tspeed: 0.0340s/iter; left time: 527.0927s\n",
      "\titers: 900, epoch: 3 | loss: 0.1069887\n",
      "\tspeed: 0.0340s/iter; left time: 523.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.1036100 Vali Loss: 0.1243204 Test Loss: 0.1360400\n",
      "Validation loss decreased (0.126631 --> 0.124320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992623\n",
      "\tspeed: 0.0962s/iter; left time: 1472.6358s\n",
      "\titers: 200, epoch: 4 | loss: 0.1065900\n",
      "\tspeed: 0.0341s/iter; left time: 518.2205s\n",
      "\titers: 300, epoch: 4 | loss: 0.0931358\n",
      "\tspeed: 0.0339s/iter; left time: 512.1561s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058308\n",
      "\tspeed: 0.0339s/iter; left time: 509.0334s\n",
      "\titers: 500, epoch: 4 | loss: 0.0744899\n",
      "\tspeed: 0.0339s/iter; left time: 505.7343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0765016\n",
      "\tspeed: 0.0340s/iter; left time: 502.9699s\n",
      "\titers: 700, epoch: 4 | loss: 0.0799936\n",
      "\tspeed: 0.0340s/iter; left time: 500.2816s\n",
      "\titers: 800, epoch: 4 | loss: 0.0827769\n",
      "\tspeed: 0.0340s/iter; left time: 496.7079s\n",
      "\titers: 900, epoch: 4 | loss: 0.0796529\n",
      "\tspeed: 0.0340s/iter; left time: 493.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0907794 Vali Loss: 0.0990055 Test Loss: 0.1009647\n",
      "Validation loss decreased (0.124320 --> 0.099006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691942\n",
      "\tspeed: 0.0981s/iter; left time: 1411.9831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784808\n",
      "\tspeed: 0.0342s/iter; left time: 489.5829s\n",
      "\titers: 300, epoch: 5 | loss: 0.0777235\n",
      "\tspeed: 0.0340s/iter; left time: 482.8251s\n",
      "\titers: 400, epoch: 5 | loss: 0.0742996\n",
      "\tspeed: 0.0340s/iter; left time: 478.9214s\n",
      "\titers: 500, epoch: 5 | loss: 0.0769375\n",
      "\tspeed: 0.0340s/iter; left time: 476.0276s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693606\n",
      "\tspeed: 0.0340s/iter; left time: 472.2992s\n",
      "\titers: 700, epoch: 5 | loss: 0.0777253\n",
      "\tspeed: 0.0341s/iter; left time: 469.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0345s/iter; left time: 472.8234s\n",
      "\titers: 900, epoch: 5 | loss: 0.0693382\n",
      "\tspeed: 0.0345s/iter; left time: 469.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0772579 Vali Loss: 0.0970609 Test Loss: 0.1022710\n",
      "Validation loss decreased (0.099006 --> 0.097061).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816712\n",
      "\tspeed: 0.0976s/iter; left time: 1317.1927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686115\n",
      "\tspeed: 0.0340s/iter; left time: 455.8893s\n",
      "\titers: 300, epoch: 6 | loss: 0.0724844\n",
      "\tspeed: 0.0340s/iter; left time: 451.8054s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776625\n",
      "\tspeed: 0.0340s/iter; left time: 448.8444s\n",
      "\titers: 500, epoch: 6 | loss: 0.0742506\n",
      "\tspeed: 0.0340s/iter; left time: 445.3133s\n",
      "\titers: 600, epoch: 6 | loss: 0.0692068\n",
      "\tspeed: 0.0340s/iter; left time: 441.3233s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700073\n",
      "\tspeed: 0.0341s/iter; left time: 438.9639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0682788\n",
      "\tspeed: 0.0340s/iter; left time: 434.4684s\n",
      "\titers: 900, epoch: 6 | loss: 0.0709434\n",
      "\tspeed: 0.0340s/iter; left time: 431.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0735981 Vali Loss: 0.0985253 Test Loss: 0.1054766\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695847\n",
      "\tspeed: 0.0942s/iter; left time: 1185.8467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0663946\n",
      "\tspeed: 0.0347s/iter; left time: 432.8294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0748294\n",
      "\tspeed: 0.0347s/iter; left time: 429.4195s\n",
      "\titers: 400, epoch: 7 | loss: 0.0655389\n",
      "\tspeed: 0.0347s/iter; left time: 426.0399s\n",
      "\titers: 500, epoch: 7 | loss: 0.0710848\n",
      "\tspeed: 0.0347s/iter; left time: 422.4656s\n",
      "\titers: 600, epoch: 7 | loss: 0.0750432\n",
      "\tspeed: 0.0347s/iter; left time: 418.9342s\n",
      "\titers: 700, epoch: 7 | loss: 0.0589826\n",
      "\tspeed: 0.0347s/iter; left time: 415.5421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0753183\n",
      "\tspeed: 0.0345s/iter; left time: 410.4611s\n",
      "\titers: 900, epoch: 7 | loss: 0.0640458\n",
      "\tspeed: 0.0345s/iter; left time: 406.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0701836 Vali Loss: 0.0988405 Test Loss: 0.1049409\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640777\n",
      "\tspeed: 0.0967s/iter; left time: 1129.8765s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628060\n",
      "\tspeed: 0.0340s/iter; left time: 393.7841s\n",
      "\titers: 300, epoch: 8 | loss: 0.0658005\n",
      "\tspeed: 0.0340s/iter; left time: 390.8261s\n",
      "\titers: 400, epoch: 8 | loss: 0.0692687\n",
      "\tspeed: 0.0340s/iter; left time: 386.9866s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804830\n",
      "\tspeed: 0.0340s/iter; left time: 383.3645s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704948\n",
      "\tspeed: 0.0340s/iter; left time: 380.1543s\n",
      "\titers: 700, epoch: 8 | loss: 0.0721590\n",
      "\tspeed: 0.0340s/iter; left time: 376.3733s\n",
      "\titers: 800, epoch: 8 | loss: 0.0717574\n",
      "\tspeed: 0.0340s/iter; left time: 373.2058s\n",
      "\titers: 900, epoch: 8 | loss: 0.0600496\n",
      "\tspeed: 0.0340s/iter; left time: 369.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0675137 Vali Loss: 0.0970914 Test Loss: 0.1058643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0610077\n",
      "\tspeed: 0.0939s/iter; left time: 1012.0603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536139\n",
      "\tspeed: 0.0340s/iter; left time: 363.0301s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636304\n",
      "\tspeed: 0.0340s/iter; left time: 359.2915s\n",
      "\titers: 400, epoch: 9 | loss: 0.0654796\n",
      "\tspeed: 0.0339s/iter; left time: 355.4828s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599042\n",
      "\tspeed: 0.0340s/iter; left time: 352.4805s\n",
      "\titers: 600, epoch: 9 | loss: 0.0565385\n",
      "\tspeed: 0.0340s/iter; left time: 348.7747s\n",
      "\titers: 700, epoch: 9 | loss: 0.0668385\n",
      "\tspeed: 0.0340s/iter; left time: 345.7664s\n",
      "\titers: 800, epoch: 9 | loss: 0.0648912\n",
      "\tspeed: 0.0340s/iter; left time: 342.2205s\n",
      "\titers: 900, epoch: 9 | loss: 0.0582753\n",
      "\tspeed: 0.0340s/iter; left time: 339.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0648913 Vali Loss: 0.0960822 Test Loss: 0.1028538\n",
      "Validation loss decreased (0.097061 --> 0.096082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571060\n",
      "\tspeed: 0.0974s/iter; left time: 961.0195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593772\n",
      "\tspeed: 0.0340s/iter; left time: 332.1973s\n",
      "\titers: 300, epoch: 10 | loss: 0.0612443\n",
      "\tspeed: 0.0340s/iter; left time: 328.9119s\n",
      "\titers: 400, epoch: 10 | loss: 0.0655431\n",
      "\tspeed: 0.0340s/iter; left time: 325.6748s\n",
      "\titers: 500, epoch: 10 | loss: 0.0650016\n",
      "\tspeed: 0.0340s/iter; left time: 322.1937s\n",
      "\titers: 600, epoch: 10 | loss: 0.0638729\n",
      "\tspeed: 0.0341s/iter; left time: 319.2505s\n",
      "\titers: 700, epoch: 10 | loss: 0.0595213\n",
      "\tspeed: 0.0340s/iter; left time: 315.3304s\n",
      "\titers: 800, epoch: 10 | loss: 0.0569092\n",
      "\tspeed: 0.0340s/iter; left time: 311.9479s\n",
      "\titers: 900, epoch: 10 | loss: 0.0640525\n",
      "\tspeed: 0.0340s/iter; left time: 308.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0622086 Vali Loss: 0.0958591 Test Loss: 0.1072349\n",
      "Validation loss decreased (0.096082 --> 0.095859).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0614833\n",
      "\tspeed: 0.0974s/iter; left time: 872.4934s\n",
      "\titers: 200, epoch: 11 | loss: 0.0575255\n",
      "\tspeed: 0.0339s/iter; left time: 300.4564s\n",
      "\titers: 300, epoch: 11 | loss: 0.0580176\n",
      "\tspeed: 0.0339s/iter; left time: 297.3484s\n",
      "\titers: 400, epoch: 11 | loss: 0.0558818\n",
      "\tspeed: 0.0339s/iter; left time: 293.5805s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552967\n",
      "\tspeed: 0.0339s/iter; left time: 290.2811s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624112\n",
      "\tspeed: 0.0340s/iter; left time: 287.2546s\n",
      "\titers: 700, epoch: 11 | loss: 0.0603113\n",
      "\tspeed: 0.0339s/iter; left time: 283.7670s\n",
      "\titers: 800, epoch: 11 | loss: 0.0681967\n",
      "\tspeed: 0.0339s/iter; left time: 280.0891s\n",
      "\titers: 900, epoch: 11 | loss: 0.0524940\n",
      "\tspeed: 0.0339s/iter; left time: 276.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0599555 Vali Loss: 0.0940875 Test Loss: 0.1040663\n",
      "Validation loss decreased (0.095859 --> 0.094087).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0657773\n",
      "\tspeed: 0.0984s/iter; left time: 792.4305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594814\n",
      "\tspeed: 0.0340s/iter; left time: 270.1358s\n",
      "\titers: 300, epoch: 12 | loss: 0.0568700\n",
      "\tspeed: 0.0340s/iter; left time: 267.2081s\n",
      "\titers: 400, epoch: 12 | loss: 0.0558004\n",
      "\tspeed: 0.0341s/iter; left time: 264.1364s\n",
      "\titers: 500, epoch: 12 | loss: 0.0566751\n",
      "\tspeed: 0.0340s/iter; left time: 260.4906s\n",
      "\titers: 600, epoch: 12 | loss: 0.0581444\n",
      "\tspeed: 0.0340s/iter; left time: 257.1118s\n",
      "\titers: 700, epoch: 12 | loss: 0.0557531\n",
      "\tspeed: 0.0340s/iter; left time: 253.6974s\n",
      "\titers: 800, epoch: 12 | loss: 0.0620691\n",
      "\tspeed: 0.0340s/iter; left time: 250.2706s\n",
      "\titers: 900, epoch: 12 | loss: 0.0582283\n",
      "\tspeed: 0.0340s/iter; left time: 246.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0577892 Vali Loss: 0.0964437 Test Loss: 0.1105988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533582\n",
      "\tspeed: 0.0941s/iter; left time: 672.9972s\n",
      "\titers: 200, epoch: 13 | loss: 0.0481930\n",
      "\tspeed: 0.0347s/iter; left time: 244.4470s\n",
      "\titers: 300, epoch: 13 | loss: 0.0606546\n",
      "\tspeed: 0.0347s/iter; left time: 241.1487s\n",
      "\titers: 400, epoch: 13 | loss: 0.0518627\n",
      "\tspeed: 0.0347s/iter; left time: 237.4272s\n",
      "\titers: 500, epoch: 13 | loss: 0.0569521\n",
      "\tspeed: 0.0347s/iter; left time: 233.9909s\n",
      "\titers: 600, epoch: 13 | loss: 0.0532617\n",
      "\tspeed: 0.0347s/iter; left time: 230.4939s\n",
      "\titers: 700, epoch: 13 | loss: 0.0609730\n",
      "\tspeed: 0.0347s/iter; left time: 227.0485s\n",
      "\titers: 800, epoch: 13 | loss: 0.0557893\n",
      "\tspeed: 0.0347s/iter; left time: 223.6601s\n",
      "\titers: 900, epoch: 13 | loss: 0.0557036\n",
      "\tspeed: 0.0347s/iter; left time: 220.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.66s\n",
      "Steps: 906 | Train Loss: 0.0560332 Vali Loss: 0.0970379 Test Loss: 0.1079533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0597315\n",
      "\tspeed: 0.0939s/iter; left time: 586.2774s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535129\n",
      "\tspeed: 0.0345s/iter; left time: 212.0048s\n",
      "\titers: 300, epoch: 14 | loss: 0.0514123\n",
      "\tspeed: 0.0344s/iter; left time: 208.1608s\n",
      "\titers: 400, epoch: 14 | loss: 0.0533041\n",
      "\tspeed: 0.0339s/iter; left time: 201.7241s\n",
      "\titers: 500, epoch: 14 | loss: 0.0519378\n",
      "\tspeed: 0.0339s/iter; left time: 198.1319s\n",
      "\titers: 600, epoch: 14 | loss: 0.0486918\n",
      "\tspeed: 0.0339s/iter; left time: 194.8968s\n",
      "\titers: 700, epoch: 14 | loss: 0.0514592\n",
      "\tspeed: 0.0339s/iter; left time: 191.3317s\n",
      "\titers: 800, epoch: 14 | loss: 0.0511779\n",
      "\tspeed: 0.0340s/iter; left time: 188.2007s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592240\n",
      "\tspeed: 0.0340s/iter; left time: 184.8092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0542619 Vali Loss: 0.1007048 Test Loss: 0.1137719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533272\n",
      "\tspeed: 0.0937s/iter; left time: 500.2540s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540463\n",
      "\tspeed: 0.0340s/iter; left time: 178.0053s\n",
      "\titers: 300, epoch: 15 | loss: 0.0475888\n",
      "\tspeed: 0.0340s/iter; left time: 174.6277s\n",
      "\titers: 400, epoch: 15 | loss: 0.0573437\n",
      "\tspeed: 0.0340s/iter; left time: 171.1498s\n",
      "\titers: 500, epoch: 15 | loss: 0.0579779\n",
      "\tspeed: 0.0340s/iter; left time: 167.7634s\n",
      "\titers: 600, epoch: 15 | loss: 0.0538819\n",
      "\tspeed: 0.0340s/iter; left time: 164.3892s\n",
      "\titers: 700, epoch: 15 | loss: 0.0519059\n",
      "\tspeed: 0.0340s/iter; left time: 161.0040s\n",
      "\titers: 800, epoch: 15 | loss: 0.0557711\n",
      "\tspeed: 0.0341s/iter; left time: 157.8956s\n",
      "\titers: 900, epoch: 15 | loss: 0.0465270\n",
      "\tspeed: 0.0340s/iter; left time: 154.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0528399 Vali Loss: 0.0974168 Test Loss: 0.1095551\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476120\n",
      "\tspeed: 0.0947s/iter; left time: 419.5489s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560914\n",
      "\tspeed: 0.0340s/iter; left time: 147.1741s\n",
      "\titers: 300, epoch: 16 | loss: 0.0469050\n",
      "\tspeed: 0.0340s/iter; left time: 143.6711s\n",
      "\titers: 400, epoch: 16 | loss: 0.0462344\n",
      "\tspeed: 0.0340s/iter; left time: 140.2631s\n",
      "\titers: 500, epoch: 16 | loss: 0.0579376\n",
      "\tspeed: 0.0340s/iter; left time: 136.8792s\n",
      "\titers: 600, epoch: 16 | loss: 0.0472905\n",
      "\tspeed: 0.0340s/iter; left time: 133.6086s\n",
      "\titers: 700, epoch: 16 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 129.8898s\n",
      "\titers: 800, epoch: 16 | loss: 0.0483521\n",
      "\tspeed: 0.0340s/iter; left time: 126.7298s\n",
      "\titers: 900, epoch: 16 | loss: 0.0505118\n",
      "\tspeed: 0.0340s/iter; left time: 123.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0516243 Vali Loss: 0.0969801 Test Loss: 0.1082252\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027125487104058266, rmse:0.16469816863536835, mae:0.10410299152135849, rse:0.5816360116004944\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:33.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2236743\n",
      "\tspeed: 0.0659s/iter; left time: 1184.4053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113647\n",
      "\tspeed: 0.0418s/iter; left time: 747.1035s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026322\n",
      "\tspeed: 0.0415s/iter; left time: 737.3678s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935861\n",
      "\tspeed: 0.0415s/iter; left time: 733.9055s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860587\n",
      "\tspeed: 0.0420s/iter; left time: 738.5568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1778900\n",
      "\tspeed: 0.0416s/iter; left time: 727.0239s\n",
      "\titers: 700, epoch: 1 | loss: 0.1723806\n",
      "\tspeed: 0.0418s/iter; left time: 725.8630s\n",
      "\titers: 800, epoch: 1 | loss: 0.1740834\n",
      "\tspeed: 0.0421s/iter; left time: 727.4376s\n",
      "\titers: 900, epoch: 1 | loss: 0.1730634\n",
      "\tspeed: 0.0421s/iter; left time: 723.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 904 | Train Loss: 0.1950106 Vali Loss: 0.1828621 Test Loss: 0.2036057\n",
      "Validation loss decreased (inf --> 0.182862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645211\n",
      "\tspeed: 0.1168s/iter; left time: 1994.4889s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429543\n",
      "\tspeed: 0.0416s/iter; left time: 705.5633s\n",
      "\titers: 300, epoch: 2 | loss: 0.1374299\n",
      "\tspeed: 0.0416s/iter; left time: 701.5841s\n",
      "\titers: 400, epoch: 2 | loss: 0.1448636\n",
      "\tspeed: 0.0416s/iter; left time: 697.7827s\n",
      "\titers: 500, epoch: 2 | loss: 0.1413144\n",
      "\tspeed: 0.0416s/iter; left time: 693.9163s\n",
      "\titers: 600, epoch: 2 | loss: 0.1236145\n",
      "\tspeed: 0.0416s/iter; left time: 689.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.1246188\n",
      "\tspeed: 0.0416s/iter; left time: 685.3335s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242174\n",
      "\tspeed: 0.0416s/iter; left time: 681.5506s\n",
      "\titers: 900, epoch: 2 | loss: 0.1292692\n",
      "\tspeed: 0.0416s/iter; left time: 677.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1378524 Vali Loss: 0.1397373 Test Loss: 0.1576225\n",
      "Validation loss decreased (0.182862 --> 0.139737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1165264\n",
      "\tspeed: 0.1172s/iter; left time: 1894.8829s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007225\n",
      "\tspeed: 0.0417s/iter; left time: 670.0918s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167652\n",
      "\tspeed: 0.0416s/iter; left time: 665.2381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1072120\n",
      "\tspeed: 0.0416s/iter; left time: 659.8419s\n",
      "\titers: 500, epoch: 3 | loss: 0.1060360\n",
      "\tspeed: 0.0416s/iter; left time: 656.2613s\n",
      "\titers: 600, epoch: 3 | loss: 0.1059219\n",
      "\tspeed: 0.0416s/iter; left time: 651.9737s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176727\n",
      "\tspeed: 0.0416s/iter; left time: 647.9141s\n",
      "\titers: 800, epoch: 3 | loss: 0.0983266\n",
      "\tspeed: 0.0416s/iter; left time: 643.8895s\n",
      "\titers: 900, epoch: 3 | loss: 0.1117628\n",
      "\tspeed: 0.0417s/iter; left time: 640.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.1093381 Vali Loss: 0.1260393 Test Loss: 0.1418328\n",
      "Validation loss decreased (0.139737 --> 0.126039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144765\n",
      "\tspeed: 0.1182s/iter; left time: 1805.4575s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020382\n",
      "\tspeed: 0.0416s/iter; left time: 631.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.1153255\n",
      "\tspeed: 0.0416s/iter; left time: 627.1646s\n",
      "\titers: 400, epoch: 4 | loss: 0.1025088\n",
      "\tspeed: 0.0416s/iter; left time: 622.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.1027884\n",
      "\tspeed: 0.0416s/iter; left time: 618.4806s\n",
      "\titers: 600, epoch: 4 | loss: 0.1016667\n",
      "\tspeed: 0.0416s/iter; left time: 614.3470s\n",
      "\titers: 700, epoch: 4 | loss: 0.1033425\n",
      "\tspeed: 0.0416s/iter; left time: 610.2125s\n",
      "\titers: 800, epoch: 4 | loss: 0.0933737\n",
      "\tspeed: 0.0416s/iter; left time: 606.3138s\n",
      "\titers: 900, epoch: 4 | loss: 0.0934185\n",
      "\tspeed: 0.0416s/iter; left time: 601.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1001598 Vali Loss: 0.1275451 Test Loss: 0.1407701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895917\n",
      "\tspeed: 0.1148s/iter; left time: 1649.6186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927757\n",
      "\tspeed: 0.0416s/iter; left time: 593.4980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965540\n",
      "\tspeed: 0.0416s/iter; left time: 588.6807s\n",
      "\titers: 400, epoch: 5 | loss: 0.0999158\n",
      "\tspeed: 0.0416s/iter; left time: 585.5770s\n",
      "\titers: 500, epoch: 5 | loss: 0.0884686\n",
      "\tspeed: 0.0416s/iter; left time: 581.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.0966759\n",
      "\tspeed: 0.0417s/iter; left time: 578.2581s\n",
      "\titers: 700, epoch: 5 | loss: 0.0977219\n",
      "\tspeed: 0.0416s/iter; left time: 573.0901s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846407\n",
      "\tspeed: 0.0416s/iter; left time: 568.7870s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849928\n",
      "\tspeed: 0.0416s/iter; left time: 564.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 904 | Train Loss: 0.0935273 Vali Loss: 0.1276608 Test Loss: 0.1445250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835068\n",
      "\tspeed: 0.1146s/iter; left time: 1542.3072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837331\n",
      "\tspeed: 0.0416s/iter; left time: 555.9648s\n",
      "\titers: 300, epoch: 6 | loss: 0.0913434\n",
      "\tspeed: 0.0416s/iter; left time: 551.4175s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903796\n",
      "\tspeed: 0.0416s/iter; left time: 547.4075s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856775\n",
      "\tspeed: 0.0416s/iter; left time: 543.5327s\n",
      "\titers: 600, epoch: 6 | loss: 0.0846278\n",
      "\tspeed: 0.0416s/iter; left time: 539.4484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0778856\n",
      "\tspeed: 0.0416s/iter; left time: 535.0167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0858639\n",
      "\tspeed: 0.0416s/iter; left time: 530.9052s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903355\n",
      "\tspeed: 0.0416s/iter; left time: 527.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0873677 Vali Loss: 0.1281512 Test Loss: 0.1463322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829671\n",
      "\tspeed: 0.1144s/iter; left time: 1436.1222s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799333\n",
      "\tspeed: 0.0416s/iter; left time: 518.3830s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816214\n",
      "\tspeed: 0.0416s/iter; left time: 514.4665s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803851\n",
      "\tspeed: 0.0416s/iter; left time: 510.3534s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766140\n",
      "\tspeed: 0.0417s/iter; left time: 506.3998s\n",
      "\titers: 600, epoch: 7 | loss: 0.0814182\n",
      "\tspeed: 0.0416s/iter; left time: 502.0855s\n",
      "\titers: 700, epoch: 7 | loss: 0.0843650\n",
      "\tspeed: 0.0417s/iter; left time: 498.0307s\n",
      "\titers: 800, epoch: 7 | loss: 0.0786219\n",
      "\tspeed: 0.0416s/iter; left time: 493.6940s\n",
      "\titers: 900, epoch: 7 | loss: 0.0786166\n",
      "\tspeed: 0.0416s/iter; left time: 489.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0820126 Vali Loss: 0.1301628 Test Loss: 0.1494684\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744809\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1676s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740958\n",
      "\tspeed: 0.0416s/iter; left time: 480.6162s\n",
      "\titers: 300, epoch: 8 | loss: 0.0821366\n",
      "\tspeed: 0.0416s/iter; left time: 476.9035s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776912\n",
      "\tspeed: 0.0416s/iter; left time: 472.4502s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823452\n",
      "\tspeed: 0.0417s/iter; left time: 468.7491s\n",
      "\titers: 600, epoch: 8 | loss: 0.0832772\n",
      "\tspeed: 0.0416s/iter; left time: 464.2049s\n",
      "\titers: 700, epoch: 8 | loss: 0.0772706\n",
      "\tspeed: 0.0416s/iter; left time: 460.0779s\n",
      "\titers: 800, epoch: 8 | loss: 0.0733887\n",
      "\tspeed: 0.0416s/iter; left time: 455.9084s\n",
      "\titers: 900, epoch: 8 | loss: 0.0711432\n",
      "\tspeed: 0.0417s/iter; left time: 452.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0772220 Vali Loss: 0.1286450 Test Loss: 0.1474413\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111143946647644, rmse:0.20275956392288208, mae:0.14186589419841766, rse:0.7180125713348389\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2234415\n",
      "\tspeed: 0.0448s/iter; left time: 804.8949s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966856\n",
      "\tspeed: 0.0422s/iter; left time: 754.5125s\n",
      "\titers: 300, epoch: 1 | loss: 0.1985690\n",
      "\tspeed: 0.0422s/iter; left time: 750.9129s\n",
      "\titers: 400, epoch: 1 | loss: 0.1968302\n",
      "\tspeed: 0.0422s/iter; left time: 746.5394s\n",
      "\titers: 500, epoch: 1 | loss: 0.2051390\n",
      "\tspeed: 0.0422s/iter; left time: 742.6659s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833022\n",
      "\tspeed: 0.0422s/iter; left time: 737.9051s\n",
      "\titers: 700, epoch: 1 | loss: 0.1789588\n",
      "\tspeed: 0.0422s/iter; left time: 733.3599s\n",
      "\titers: 800, epoch: 1 | loss: 0.1781165\n",
      "\tspeed: 0.0422s/iter; left time: 730.0477s\n",
      "\titers: 900, epoch: 1 | loss: 0.1753210\n",
      "\tspeed: 0.0422s/iter; left time: 725.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 904 | Train Loss: 0.1983297 Vali Loss: 0.1792039 Test Loss: 0.1982639\n",
      "Validation loss decreased (inf --> 0.179204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652503\n",
      "\tspeed: 0.1185s/iter; left time: 2023.6443s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410911\n",
      "\tspeed: 0.0422s/iter; left time: 716.3351s\n",
      "\titers: 300, epoch: 2 | loss: 0.1531194\n",
      "\tspeed: 0.0422s/iter; left time: 712.5301s\n",
      "\titers: 400, epoch: 2 | loss: 0.1385903\n",
      "\tspeed: 0.0422s/iter; left time: 707.9972s\n",
      "\titers: 500, epoch: 2 | loss: 0.1392631\n",
      "\tspeed: 0.0422s/iter; left time: 703.6733s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265477\n",
      "\tspeed: 0.0419s/iter; left time: 694.9356s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320228\n",
      "\tspeed: 0.0417s/iter; left time: 686.5249s\n",
      "\titers: 800, epoch: 2 | loss: 0.1308168\n",
      "\tspeed: 0.0417s/iter; left time: 682.6446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1204412\n",
      "\tspeed: 0.0417s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 904 | Train Loss: 0.1407695 Vali Loss: 0.1408073 Test Loss: 0.1547505\n",
      "Validation loss decreased (0.179204 --> 0.140807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168671\n",
      "\tspeed: 0.1192s/iter; left time: 1927.4650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049146\n",
      "\tspeed: 0.0417s/iter; left time: 670.7429s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167228\n",
      "\tspeed: 0.0417s/iter; left time: 666.5092s\n",
      "\titers: 400, epoch: 3 | loss: 0.1142903\n",
      "\tspeed: 0.0417s/iter; left time: 662.3797s\n",
      "\titers: 500, epoch: 3 | loss: 0.1116785\n",
      "\tspeed: 0.0417s/iter; left time: 657.1454s\n",
      "\titers: 600, epoch: 3 | loss: 0.1235701\n",
      "\tspeed: 0.0417s/iter; left time: 653.4055s\n",
      "\titers: 700, epoch: 3 | loss: 0.1162522\n",
      "\tspeed: 0.0417s/iter; left time: 649.3268s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972967\n",
      "\tspeed: 0.0417s/iter; left time: 644.6283s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052426\n",
      "\tspeed: 0.0417s/iter; left time: 641.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.1110472 Vali Loss: 0.1264536 Test Loss: 0.1413004\n",
      "Validation loss decreased (0.140807 --> 0.126454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090948\n",
      "\tspeed: 0.1191s/iter; left time: 1818.1072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982538\n",
      "\tspeed: 0.0416s/iter; left time: 631.4894s\n",
      "\titers: 300, epoch: 4 | loss: 0.1019681\n",
      "\tspeed: 0.0416s/iter; left time: 627.4270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011304\n",
      "\tspeed: 0.0417s/iter; left time: 623.9304s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932572\n",
      "\tspeed: 0.0417s/iter; left time: 619.6904s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023407\n",
      "\tspeed: 0.0417s/iter; left time: 615.6053s\n",
      "\titers: 700, epoch: 4 | loss: 0.1069069\n",
      "\tspeed: 0.0417s/iter; left time: 611.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006559\n",
      "\tspeed: 0.0417s/iter; left time: 607.7450s\n",
      "\titers: 900, epoch: 4 | loss: 0.0924000\n",
      "\tspeed: 0.0417s/iter; left time: 603.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.1005647 Vali Loss: 0.1294573 Test Loss: 0.1431555\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859475\n",
      "\tspeed: 0.1151s/iter; left time: 1653.0452s\n",
      "\titers: 200, epoch: 5 | loss: 0.0939509\n",
      "\tspeed: 0.0417s/iter; left time: 594.5175s\n",
      "\titers: 300, epoch: 5 | loss: 0.1010361\n",
      "\tspeed: 0.0417s/iter; left time: 590.4591s\n",
      "\titers: 400, epoch: 5 | loss: 0.0910976\n",
      "\tspeed: 0.0417s/iter; left time: 586.6165s\n",
      "\titers: 500, epoch: 5 | loss: 0.0985042\n",
      "\tspeed: 0.0417s/iter; left time: 582.4643s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925515\n",
      "\tspeed: 0.0417s/iter; left time: 578.1049s\n",
      "\titers: 700, epoch: 5 | loss: 0.0912867\n",
      "\tspeed: 0.0417s/iter; left time: 574.5983s\n",
      "\titers: 800, epoch: 5 | loss: 0.0828394\n",
      "\tspeed: 0.0417s/iter; left time: 570.0924s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920023\n",
      "\tspeed: 0.0417s/iter; left time: 565.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.0930013 Vali Loss: 0.1250305 Test Loss: 0.1447869\n",
      "Validation loss decreased (0.126454 --> 0.125030).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0978971\n",
      "\tspeed: 0.1175s/iter; left time: 1581.6357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836452\n",
      "\tspeed: 0.0423s/iter; left time: 564.7488s\n",
      "\titers: 300, epoch: 6 | loss: 0.0813788\n",
      "\tspeed: 0.0423s/iter; left time: 560.4317s\n",
      "\titers: 400, epoch: 6 | loss: 0.0883501\n",
      "\tspeed: 0.0423s/iter; left time: 556.4378s\n",
      "\titers: 500, epoch: 6 | loss: 0.0908173\n",
      "\tspeed: 0.0419s/iter; left time: 547.4124s\n",
      "\titers: 600, epoch: 6 | loss: 0.0855428\n",
      "\tspeed: 0.0417s/iter; left time: 540.3965s\n",
      "\titers: 700, epoch: 6 | loss: 0.0813997\n",
      "\tspeed: 0.0418s/iter; left time: 538.0849s\n",
      "\titers: 800, epoch: 6 | loss: 0.0851901\n",
      "\tspeed: 0.0422s/iter; left time: 538.7857s\n",
      "\titers: 900, epoch: 6 | loss: 0.0928024\n",
      "\tspeed: 0.0422s/iter; left time: 534.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0864959 Vali Loss: 0.1274113 Test Loss: 0.1429392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860452\n",
      "\tspeed: 0.1152s/iter; left time: 1445.9693s\n",
      "\titers: 200, epoch: 7 | loss: 0.0802008\n",
      "\tspeed: 0.0417s/iter; left time: 520.0418s\n",
      "\titers: 300, epoch: 7 | loss: 0.0844645\n",
      "\tspeed: 0.0417s/iter; left time: 515.7681s\n",
      "\titers: 400, epoch: 7 | loss: 0.0800768\n",
      "\tspeed: 0.0417s/iter; left time: 511.2027s\n",
      "\titers: 500, epoch: 7 | loss: 0.0742883\n",
      "\tspeed: 0.0417s/iter; left time: 507.2303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0797856\n",
      "\tspeed: 0.0417s/iter; left time: 502.8343s\n",
      "\titers: 700, epoch: 7 | loss: 0.0820259\n",
      "\tspeed: 0.0417s/iter; left time: 498.4365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776940\n",
      "\tspeed: 0.0417s/iter; left time: 494.1525s\n",
      "\titers: 900, epoch: 7 | loss: 0.0846543\n",
      "\tspeed: 0.0417s/iter; left time: 490.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0810965 Vali Loss: 0.1287853 Test Loss: 0.1496999\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749170\n",
      "\tspeed: 0.1138s/iter; left time: 1326.4466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0768698\n",
      "\tspeed: 0.0416s/iter; left time: 481.0175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0775572\n",
      "\tspeed: 0.0416s/iter; left time: 476.9494s\n",
      "\titers: 400, epoch: 8 | loss: 0.0874197\n",
      "\tspeed: 0.0417s/iter; left time: 473.0103s\n",
      "\titers: 500, epoch: 8 | loss: 0.0777074\n",
      "\tspeed: 0.0417s/iter; left time: 468.9067s\n",
      "\titers: 600, epoch: 8 | loss: 0.0779779\n",
      "\tspeed: 0.0417s/iter; left time: 464.8537s\n",
      "\titers: 700, epoch: 8 | loss: 0.0688209\n",
      "\tspeed: 0.0416s/iter; left time: 460.1467s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773090\n",
      "\tspeed: 0.0416s/iter; left time: 455.8680s\n",
      "\titers: 900, epoch: 8 | loss: 0.0762522\n",
      "\tspeed: 0.0416s/iter; left time: 452.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0761603 Vali Loss: 0.1303706 Test Loss: 0.1481057\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745463\n",
      "\tspeed: 0.1140s/iter; left time: 1225.3924s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718982\n",
      "\tspeed: 0.0417s/iter; left time: 444.2716s\n",
      "\titers: 300, epoch: 9 | loss: 0.0661809\n",
      "\tspeed: 0.0417s/iter; left time: 439.7693s\n",
      "\titers: 400, epoch: 9 | loss: 0.0663692\n",
      "\tspeed: 0.0417s/iter; left time: 435.6156s\n",
      "\titers: 500, epoch: 9 | loss: 0.0759411\n",
      "\tspeed: 0.0417s/iter; left time: 431.6843s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733939\n",
      "\tspeed: 0.0417s/iter; left time: 427.4183s\n",
      "\titers: 700, epoch: 9 | loss: 0.0685498\n",
      "\tspeed: 0.0417s/iter; left time: 423.4725s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660150\n",
      "\tspeed: 0.0417s/iter; left time: 418.9598s\n",
      "\titers: 900, epoch: 9 | loss: 0.0665430\n",
      "\tspeed: 0.0417s/iter; left time: 414.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0720239 Vali Loss: 0.1313181 Test Loss: 0.1486595\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688543\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9525s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704562\n",
      "\tspeed: 0.0416s/iter; left time: 405.8092s\n",
      "\titers: 300, epoch: 10 | loss: 0.0691381\n",
      "\tspeed: 0.0416s/iter; left time: 401.6987s\n",
      "\titers: 400, epoch: 10 | loss: 0.0685972\n",
      "\tspeed: 0.0417s/iter; left time: 397.8337s\n",
      "\titers: 500, epoch: 10 | loss: 0.0678505\n",
      "\tspeed: 0.0417s/iter; left time: 393.6512s\n",
      "\titers: 600, epoch: 10 | loss: 0.0690019\n",
      "\tspeed: 0.0417s/iter; left time: 389.3610s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663853\n",
      "\tspeed: 0.0417s/iter; left time: 385.2586s\n",
      "\titers: 800, epoch: 10 | loss: 0.0663898\n",
      "\tspeed: 0.0417s/iter; left time: 381.0024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0707798\n",
      "\tspeed: 0.0417s/iter; left time: 376.8207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0684217 Vali Loss: 0.1309250 Test Loss: 0.1480408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04497264325618744, rmse:0.21206754446029663, mae:0.14488229155540466, rse:0.7509739995002747\n",
      "Intermediate time for DE and pred_len 96: 00h:13m:48.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2135790\n",
      "\tspeed: 0.0737s/iter; left time: 1322.8469s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131124\n",
      "\tspeed: 0.0512s/iter; left time: 912.6013s\n",
      "\titers: 300, epoch: 1 | loss: 0.1944744\n",
      "\tspeed: 0.0511s/iter; left time: 906.5395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934913\n",
      "\tspeed: 0.0511s/iter; left time: 901.8570s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860318\n",
      "\tspeed: 0.0512s/iter; left time: 898.2652s\n",
      "\titers: 600, epoch: 1 | loss: 0.1891531\n",
      "\tspeed: 0.0507s/iter; left time: 884.7699s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774250\n",
      "\tspeed: 0.0505s/iter; left time: 875.0270s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730052\n",
      "\tspeed: 0.0510s/iter; left time: 878.7949s\n",
      "\titers: 900, epoch: 1 | loss: 0.1795384\n",
      "\tspeed: 0.0510s/iter; left time: 874.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 902 | Train Loss: 0.1965859 Vali Loss: 0.1832028 Test Loss: 0.2074134\n",
      "Validation loss decreased (inf --> 0.183203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704737\n",
      "\tspeed: 0.1414s/iter; left time: 2408.5213s\n",
      "\titers: 200, epoch: 2 | loss: 0.1490840\n",
      "\tspeed: 0.0512s/iter; left time: 866.9052s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521463\n",
      "\tspeed: 0.0511s/iter; left time: 861.3000s\n",
      "\titers: 400, epoch: 2 | loss: 0.1506241\n",
      "\tspeed: 0.0512s/iter; left time: 856.7931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1406512\n",
      "\tspeed: 0.0512s/iter; left time: 851.7499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1345950\n",
      "\tspeed: 0.0512s/iter; left time: 846.4364s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337818\n",
      "\tspeed: 0.0512s/iter; left time: 841.2830s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407173\n",
      "\tspeed: 0.0512s/iter; left time: 835.9682s\n",
      "\titers: 900, epoch: 2 | loss: 0.1290744\n",
      "\tspeed: 0.0512s/iter; left time: 831.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1488273 Vali Loss: 0.1596573 Test Loss: 0.1774935\n",
      "Validation loss decreased (0.183203 --> 0.159657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323122\n",
      "\tspeed: 0.1454s/iter; left time: 2346.2832s\n",
      "\titers: 200, epoch: 3 | loss: 0.1293032\n",
      "\tspeed: 0.0512s/iter; left time: 820.8534s\n",
      "\titers: 300, epoch: 3 | loss: 0.1290850\n",
      "\tspeed: 0.0512s/iter; left time: 815.8447s\n",
      "\titers: 400, epoch: 3 | loss: 0.1349285\n",
      "\tspeed: 0.0512s/iter; left time: 811.2225s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263371\n",
      "\tspeed: 0.0511s/iter; left time: 803.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1262871\n",
      "\tspeed: 0.0510s/iter; left time: 797.6849s\n",
      "\titers: 700, epoch: 3 | loss: 0.1187956\n",
      "\tspeed: 0.0507s/iter; left time: 787.9002s\n",
      "\titers: 800, epoch: 3 | loss: 0.1199932\n",
      "\tspeed: 0.0508s/iter; left time: 784.8815s\n",
      "\titers: 900, epoch: 3 | loss: 0.1152969\n",
      "\tspeed: 0.0510s/iter; left time: 782.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 902 | Train Loss: 0.1267166 Vali Loss: 0.1417985 Test Loss: 0.1600939\n",
      "Validation loss decreased (0.159657 --> 0.141799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117888\n",
      "\tspeed: 0.1424s/iter; left time: 2169.7528s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026877\n",
      "\tspeed: 0.0505s/iter; left time: 763.6327s\n",
      "\titers: 300, epoch: 4 | loss: 0.1014980\n",
      "\tspeed: 0.0506s/iter; left time: 760.6549s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038646\n",
      "\tspeed: 0.0505s/iter; left time: 754.2511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0989735\n",
      "\tspeed: 0.0504s/iter; left time: 747.5785s\n",
      "\titers: 600, epoch: 4 | loss: 0.1064414\n",
      "\tspeed: 0.0504s/iter; left time: 742.2079s\n",
      "\titers: 700, epoch: 4 | loss: 0.0987112\n",
      "\tspeed: 0.0504s/iter; left time: 737.3631s\n",
      "\titers: 800, epoch: 4 | loss: 0.1000495\n",
      "\tspeed: 0.0504s/iter; left time: 732.4440s\n",
      "\titers: 900, epoch: 4 | loss: 0.0978920\n",
      "\tspeed: 0.0504s/iter; left time: 727.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1061221 Vali Loss: 0.1528979 Test Loss: 0.1627806\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918928\n",
      "\tspeed: 0.1384s/iter; left time: 1983.2864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0960290\n",
      "\tspeed: 0.0511s/iter; left time: 727.3949s\n",
      "\titers: 300, epoch: 5 | loss: 0.0931458\n",
      "\tspeed: 0.0512s/iter; left time: 724.2957s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993961\n",
      "\tspeed: 0.0511s/iter; left time: 716.4612s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912344\n",
      "\tspeed: 0.0506s/iter; left time: 704.4801s\n",
      "\titers: 600, epoch: 5 | loss: 0.0892607\n",
      "\tspeed: 0.0505s/iter; left time: 698.8492s\n",
      "\titers: 700, epoch: 5 | loss: 0.0910661\n",
      "\tspeed: 0.0504s/iter; left time: 692.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1011088\n",
      "\tspeed: 0.0505s/iter; left time: 688.4830s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920976\n",
      "\tspeed: 0.0504s/iter; left time: 682.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.0971309 Vali Loss: 0.1423063 Test Loss: 0.1565221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920235\n",
      "\tspeed: 0.1408s/iter; left time: 1890.4647s\n",
      "\titers: 200, epoch: 6 | loss: 0.0922436\n",
      "\tspeed: 0.0511s/iter; left time: 681.2781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902070\n",
      "\tspeed: 0.0511s/iter; left time: 676.7292s\n",
      "\titers: 400, epoch: 6 | loss: 0.0975088\n",
      "\tspeed: 0.0512s/iter; left time: 671.7489s\n",
      "\titers: 500, epoch: 6 | loss: 0.0972495\n",
      "\tspeed: 0.0511s/iter; left time: 666.4803s\n",
      "\titers: 600, epoch: 6 | loss: 0.0895226\n",
      "\tspeed: 0.0511s/iter; left time: 661.3073s\n",
      "\titers: 700, epoch: 6 | loss: 0.0809252\n",
      "\tspeed: 0.0511s/iter; left time: 655.7049s\n",
      "\titers: 800, epoch: 6 | loss: 0.0889638\n",
      "\tspeed: 0.0511s/iter; left time: 651.0962s\n",
      "\titers: 900, epoch: 6 | loss: 0.0874771\n",
      "\tspeed: 0.0511s/iter; left time: 645.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0901457 Vali Loss: 0.1472353 Test Loss: 0.1613897\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832280\n",
      "\tspeed: 0.1385s/iter; left time: 1735.5467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830341\n",
      "\tspeed: 0.0505s/iter; left time: 628.0122s\n",
      "\titers: 300, epoch: 7 | loss: 0.0871024\n",
      "\tspeed: 0.0505s/iter; left time: 622.9652s\n",
      "\titers: 400, epoch: 7 | loss: 0.0823863\n",
      "\tspeed: 0.0505s/iter; left time: 617.8123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869082\n",
      "\tspeed: 0.0506s/iter; left time: 613.9551s\n",
      "\titers: 600, epoch: 7 | loss: 0.0787628\n",
      "\tspeed: 0.0505s/iter; left time: 607.5038s\n",
      "\titers: 700, epoch: 7 | loss: 0.0807302\n",
      "\tspeed: 0.0504s/iter; left time: 601.6845s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859715\n",
      "\tspeed: 0.0505s/iter; left time: 596.9224s\n",
      "\titers: 900, epoch: 7 | loss: 0.0893550\n",
      "\tspeed: 0.0505s/iter; left time: 591.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0839997 Vali Loss: 0.1402461 Test Loss: 0.1580236\n",
      "Validation loss decreased (0.141799 --> 0.140246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807353\n",
      "\tspeed: 0.1480s/iter; left time: 1721.0885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845029\n",
      "\tspeed: 0.0505s/iter; left time: 582.2940s\n",
      "\titers: 300, epoch: 8 | loss: 0.0833175\n",
      "\tspeed: 0.0505s/iter; left time: 577.5719s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774543\n",
      "\tspeed: 0.0504s/iter; left time: 570.9776s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767989\n",
      "\tspeed: 0.0506s/iter; left time: 568.2994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0740711\n",
      "\tspeed: 0.0506s/iter; left time: 562.4822s\n",
      "\titers: 700, epoch: 8 | loss: 0.0755660\n",
      "\tspeed: 0.0506s/iter; left time: 557.9460s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745798\n",
      "\tspeed: 0.0506s/iter; left time: 553.4293s\n",
      "\titers: 900, epoch: 8 | loss: 0.0752394\n",
      "\tspeed: 0.0505s/iter; left time: 546.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.0790876 Vali Loss: 0.1432174 Test Loss: 0.1611511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703514\n",
      "\tspeed: 0.1390s/iter; left time: 1490.3299s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778098\n",
      "\tspeed: 0.0509s/iter; left time: 540.7775s\n",
      "\titers: 300, epoch: 9 | loss: 0.0785731\n",
      "\tspeed: 0.0505s/iter; left time: 531.7624s\n",
      "\titers: 400, epoch: 9 | loss: 0.0750980\n",
      "\tspeed: 0.0506s/iter; left time: 527.9468s\n",
      "\titers: 500, epoch: 9 | loss: 0.0785402\n",
      "\tspeed: 0.0512s/iter; left time: 528.2391s\n",
      "\titers: 600, epoch: 9 | loss: 0.0711287\n",
      "\tspeed: 0.0512s/iter; left time: 523.7596s\n",
      "\titers: 700, epoch: 9 | loss: 0.0769884\n",
      "\tspeed: 0.0513s/iter; left time: 518.9390s\n",
      "\titers: 800, epoch: 9 | loss: 0.0754216\n",
      "\tspeed: 0.0512s/iter; left time: 513.7073s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719022\n",
      "\tspeed: 0.0512s/iter; left time: 508.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.23s\n",
      "Steps: 902 | Train Loss: 0.0748285 Vali Loss: 0.1403084 Test Loss: 0.1591520\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676495\n",
      "\tspeed: 0.1400s/iter; left time: 1375.3179s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732440\n",
      "\tspeed: 0.0512s/iter; left time: 498.0206s\n",
      "\titers: 300, epoch: 10 | loss: 0.0741318\n",
      "\tspeed: 0.0512s/iter; left time: 492.5140s\n",
      "\titers: 400, epoch: 10 | loss: 0.0708465\n",
      "\tspeed: 0.0511s/iter; left time: 486.7042s\n",
      "\titers: 500, epoch: 10 | loss: 0.0714293\n",
      "\tspeed: 0.0512s/iter; left time: 482.4216s\n",
      "\titers: 600, epoch: 10 | loss: 0.0729542\n",
      "\tspeed: 0.0511s/iter; left time: 476.5732s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714578\n",
      "\tspeed: 0.0511s/iter; left time: 471.3907s\n",
      "\titers: 800, epoch: 10 | loss: 0.0682916\n",
      "\tspeed: 0.0511s/iter; left time: 466.2845s\n",
      "\titers: 900, epoch: 10 | loss: 0.0718856\n",
      "\tspeed: 0.0506s/iter; left time: 456.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.0712225 Vali Loss: 0.1423417 Test Loss: 0.1615068\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672577\n",
      "\tspeed: 0.1397s/iter; left time: 1246.3109s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695483\n",
      "\tspeed: 0.0512s/iter; left time: 451.4285s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647759\n",
      "\tspeed: 0.0510s/iter; left time: 445.1117s\n",
      "\titers: 400, epoch: 11 | loss: 0.0645632\n",
      "\tspeed: 0.0510s/iter; left time: 439.9699s\n",
      "\titers: 500, epoch: 11 | loss: 0.0772103\n",
      "\tspeed: 0.0510s/iter; left time: 434.5106s\n",
      "\titers: 600, epoch: 11 | loss: 0.0657790\n",
      "\tspeed: 0.0510s/iter; left time: 429.5179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0685922\n",
      "\tspeed: 0.0507s/iter; left time: 422.0749s\n",
      "\titers: 800, epoch: 11 | loss: 0.0658226\n",
      "\tspeed: 0.0510s/iter; left time: 419.3127s\n",
      "\titers: 900, epoch: 11 | loss: 0.0667105\n",
      "\tspeed: 0.0510s/iter; left time: 414.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.34s\n",
      "Steps: 902 | Train Loss: 0.0681893 Vali Loss: 0.1411986 Test Loss: 0.1595801\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650528\n",
      "\tspeed: 0.1383s/iter; left time: 1108.7168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708718\n",
      "\tspeed: 0.0511s/iter; left time: 404.2901s\n",
      "\titers: 300, epoch: 12 | loss: 0.0652237\n",
      "\tspeed: 0.0506s/iter; left time: 395.8605s\n",
      "\titers: 400, epoch: 12 | loss: 0.0649883\n",
      "\tspeed: 0.0507s/iter; left time: 391.5492s\n",
      "\titers: 500, epoch: 12 | loss: 0.0644263\n",
      "\tspeed: 0.0506s/iter; left time: 385.6037s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660991\n",
      "\tspeed: 0.0506s/iter; left time: 380.4517s\n",
      "\titers: 700, epoch: 12 | loss: 0.0694268\n",
      "\tspeed: 0.0506s/iter; left time: 375.5242s\n",
      "\titers: 800, epoch: 12 | loss: 0.0674071\n",
      "\tspeed: 0.0506s/iter; left time: 370.2007s\n",
      "\titers: 900, epoch: 12 | loss: 0.0676546\n",
      "\tspeed: 0.0506s/iter; left time: 365.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0656815 Vali Loss: 0.1400202 Test Loss: 0.1601845\n",
      "Validation loss decreased (0.140246 --> 0.140020).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625419\n",
      "\tspeed: 0.1435s/iter; left time: 1021.4043s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636671\n",
      "\tspeed: 0.0510s/iter; left time: 357.9900s\n",
      "\titers: 300, epoch: 13 | loss: 0.0667756\n",
      "\tspeed: 0.0510s/iter; left time: 353.0616s\n",
      "\titers: 400, epoch: 13 | loss: 0.0637611\n",
      "\tspeed: 0.0512s/iter; left time: 349.0311s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616729\n",
      "\tspeed: 0.0512s/iter; left time: 344.0386s\n",
      "\titers: 600, epoch: 13 | loss: 0.0642316\n",
      "\tspeed: 0.0509s/iter; left time: 336.7321s\n",
      "\titers: 700, epoch: 13 | loss: 0.0620666\n",
      "\tspeed: 0.0510s/iter; left time: 332.5125s\n",
      "\titers: 800, epoch: 13 | loss: 0.0658408\n",
      "\tspeed: 0.0513s/iter; left time: 328.8980s\n",
      "\titers: 900, epoch: 13 | loss: 0.0617386\n",
      "\tspeed: 0.0513s/iter; left time: 323.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 902 | Train Loss: 0.0634137 Vali Loss: 0.1419839 Test Loss: 0.1631894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0585671\n",
      "\tspeed: 0.1396s/iter; left time: 867.4336s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664492\n",
      "\tspeed: 0.0506s/iter; left time: 309.6088s\n",
      "\titers: 300, epoch: 14 | loss: 0.0629691\n",
      "\tspeed: 0.0507s/iter; left time: 304.6759s\n",
      "\titers: 400, epoch: 14 | loss: 0.0620267\n",
      "\tspeed: 0.0507s/iter; left time: 299.7290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0623624\n",
      "\tspeed: 0.0507s/iter; left time: 294.8488s\n",
      "\titers: 600, epoch: 14 | loss: 0.0619973\n",
      "\tspeed: 0.0506s/iter; left time: 289.3720s\n",
      "\titers: 700, epoch: 14 | loss: 0.0618283\n",
      "\tspeed: 0.0508s/iter; left time: 285.1200s\n",
      "\titers: 800, epoch: 14 | loss: 0.0577629\n",
      "\tspeed: 0.0511s/iter; left time: 281.8709s\n",
      "\titers: 900, epoch: 14 | loss: 0.0643250\n",
      "\tspeed: 0.0512s/iter; left time: 277.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.10s\n",
      "Steps: 902 | Train Loss: 0.0616388 Vali Loss: 0.1407283 Test Loss: 0.1611458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597400\n",
      "\tspeed: 0.1409s/iter; left time: 748.5759s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610378\n",
      "\tspeed: 0.0513s/iter; left time: 267.3372s\n",
      "\titers: 300, epoch: 15 | loss: 0.0592156\n",
      "\tspeed: 0.0513s/iter; left time: 262.3524s\n",
      "\titers: 400, epoch: 15 | loss: 0.0588845\n",
      "\tspeed: 0.0513s/iter; left time: 257.2757s\n",
      "\titers: 500, epoch: 15 | loss: 0.0618582\n",
      "\tspeed: 0.0513s/iter; left time: 251.8946s\n",
      "\titers: 600, epoch: 15 | loss: 0.0604138\n",
      "\tspeed: 0.0513s/iter; left time: 246.7312s\n",
      "\titers: 700, epoch: 15 | loss: 0.0605271\n",
      "\tspeed: 0.0513s/iter; left time: 241.7580s\n",
      "\titers: 800, epoch: 15 | loss: 0.0604768\n",
      "\tspeed: 0.0513s/iter; left time: 236.5873s\n",
      "\titers: 900, epoch: 15 | loss: 0.0590711\n",
      "\tspeed: 0.0513s/iter; left time: 231.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.0600248 Vali Loss: 0.1428889 Test Loss: 0.1618677\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0612130\n",
      "\tspeed: 0.1387s/iter; left time: 611.8801s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578973\n",
      "\tspeed: 0.0506s/iter; left time: 218.1125s\n",
      "\titers: 300, epoch: 16 | loss: 0.0590760\n",
      "\tspeed: 0.0507s/iter; left time: 213.3454s\n",
      "\titers: 400, epoch: 16 | loss: 0.0539181\n",
      "\tspeed: 0.0506s/iter; left time: 208.1322s\n",
      "\titers: 500, epoch: 16 | loss: 0.0605631\n",
      "\tspeed: 0.0507s/iter; left time: 203.3086s\n",
      "\titers: 600, epoch: 16 | loss: 0.0602342\n",
      "\tspeed: 0.0506s/iter; left time: 197.8721s\n",
      "\titers: 700, epoch: 16 | loss: 0.0567739\n",
      "\tspeed: 0.0506s/iter; left time: 192.9792s\n",
      "\titers: 800, epoch: 16 | loss: 0.0596344\n",
      "\tspeed: 0.0506s/iter; left time: 187.9486s\n",
      "\titers: 900, epoch: 16 | loss: 0.0615203\n",
      "\tspeed: 0.0506s/iter; left time: 182.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 902 | Train Loss: 0.0586482 Vali Loss: 0.1421482 Test Loss: 0.1612585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595209\n",
      "\tspeed: 0.1391s/iter; left time: 488.1010s\n",
      "\titers: 200, epoch: 17 | loss: 0.0596009\n",
      "\tspeed: 0.0504s/iter; left time: 171.6961s\n",
      "\titers: 300, epoch: 17 | loss: 0.0585621\n",
      "\tspeed: 0.0504s/iter; left time: 166.7300s\n",
      "\titers: 400, epoch: 17 | loss: 0.0652123\n",
      "\tspeed: 0.0504s/iter; left time: 161.8197s\n",
      "\titers: 500, epoch: 17 | loss: 0.0540461\n",
      "\tspeed: 0.0505s/iter; left time: 157.0520s\n",
      "\titers: 600, epoch: 17 | loss: 0.0559000\n",
      "\tspeed: 0.0506s/iter; left time: 152.3226s\n",
      "\titers: 700, epoch: 17 | loss: 0.0554206\n",
      "\tspeed: 0.0506s/iter; left time: 147.2073s\n",
      "\titers: 800, epoch: 17 | loss: 0.0559492\n",
      "\tspeed: 0.0506s/iter; left time: 142.2411s\n",
      "\titers: 900, epoch: 17 | loss: 0.0555495\n",
      "\tspeed: 0.0507s/iter; left time: 137.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 902 | Train Loss: 0.0575157 Vali Loss: 0.1406434 Test Loss: 0.1615269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05564524605870247, rmse:0.23589244484901428, mae:0.16008244454860687, rse:0.8356959223747253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2329182\n",
      "\tspeed: 0.0528s/iter; left time: 947.6494s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172202\n",
      "\tspeed: 0.0507s/iter; left time: 904.7054s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961658\n",
      "\tspeed: 0.0507s/iter; left time: 899.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1850062\n",
      "\tspeed: 0.0507s/iter; left time: 895.1299s\n",
      "\titers: 500, epoch: 1 | loss: 0.1870918\n",
      "\tspeed: 0.0508s/iter; left time: 890.3390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1944518\n",
      "\tspeed: 0.0506s/iter; left time: 882.1736s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783303\n",
      "\tspeed: 0.0506s/iter; left time: 876.9964s\n",
      "\titers: 800, epoch: 1 | loss: 0.1759333\n",
      "\tspeed: 0.0505s/iter; left time: 871.0565s\n",
      "\titers: 900, epoch: 1 | loss: 0.1763727\n",
      "\tspeed: 0.0506s/iter; left time: 867.0226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.1973616 Vali Loss: 0.1830743 Test Loss: 0.2059395\n",
      "Validation loss decreased (inf --> 0.183074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503127\n",
      "\tspeed: 0.1421s/iter; left time: 2420.4738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512766\n",
      "\tspeed: 0.0506s/iter; left time: 857.6590s\n",
      "\titers: 300, epoch: 2 | loss: 0.1382957\n",
      "\tspeed: 0.0506s/iter; left time: 852.5279s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341342\n",
      "\tspeed: 0.0506s/iter; left time: 847.7158s\n",
      "\titers: 500, epoch: 2 | loss: 0.1374097\n",
      "\tspeed: 0.0506s/iter; left time: 842.4117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1432593\n",
      "\tspeed: 0.0505s/iter; left time: 834.9621s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279730\n",
      "\tspeed: 0.0504s/iter; left time: 828.2137s\n",
      "\titers: 800, epoch: 2 | loss: 0.1409557\n",
      "\tspeed: 0.0504s/iter; left time: 823.0514s\n",
      "\titers: 900, epoch: 2 | loss: 0.1172102\n",
      "\tspeed: 0.0504s/iter; left time: 818.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 902 | Train Loss: 0.1439408 Vali Loss: 0.1546091 Test Loss: 0.1715550\n",
      "Validation loss decreased (0.183074 --> 0.154609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1301890\n",
      "\tspeed: 0.1410s/iter; left time: 2275.0167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247176\n",
      "\tspeed: 0.0505s/iter; left time: 809.6763s\n",
      "\titers: 300, epoch: 3 | loss: 0.1338786\n",
      "\tspeed: 0.0507s/iter; left time: 807.7225s\n",
      "\titers: 400, epoch: 3 | loss: 0.1215102\n",
      "\tspeed: 0.0507s/iter; left time: 802.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1196253\n",
      "\tspeed: 0.0507s/iter; left time: 797.5365s\n",
      "\titers: 600, epoch: 3 | loss: 0.1286701\n",
      "\tspeed: 0.0504s/iter; left time: 787.8341s\n",
      "\titers: 700, epoch: 3 | loss: 0.1157779\n",
      "\tspeed: 0.0504s/iter; left time: 782.7377s\n",
      "\titers: 800, epoch: 3 | loss: 0.1232034\n",
      "\tspeed: 0.0504s/iter; left time: 778.3771s\n",
      "\titers: 900, epoch: 3 | loss: 0.1138987\n",
      "\tspeed: 0.0504s/iter; left time: 773.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.1216343 Vali Loss: 0.1383445 Test Loss: 0.1558911\n",
      "Validation loss decreased (0.154609 --> 0.138345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097272\n",
      "\tspeed: 0.1400s/iter; left time: 2132.6516s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003548\n",
      "\tspeed: 0.0504s/iter; left time: 763.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034977\n",
      "\tspeed: 0.0504s/iter; left time: 757.4019s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083793\n",
      "\tspeed: 0.0504s/iter; left time: 752.3880s\n",
      "\titers: 500, epoch: 4 | loss: 0.1005158\n",
      "\tspeed: 0.0504s/iter; left time: 747.7124s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054492\n",
      "\tspeed: 0.0504s/iter; left time: 742.8598s\n",
      "\titers: 700, epoch: 4 | loss: 0.1030866\n",
      "\tspeed: 0.0504s/iter; left time: 737.7559s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006965\n",
      "\tspeed: 0.0504s/iter; left time: 732.9385s\n",
      "\titers: 900, epoch: 4 | loss: 0.1023383\n",
      "\tspeed: 0.0505s/iter; left time: 728.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.1054264 Vali Loss: 0.1426753 Test Loss: 0.1533596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043797\n",
      "\tspeed: 0.1380s/iter; left time: 1978.4526s\n",
      "\titers: 200, epoch: 5 | loss: 0.1015226\n",
      "\tspeed: 0.0506s/iter; left time: 719.8159s\n",
      "\titers: 300, epoch: 5 | loss: 0.1025427\n",
      "\tspeed: 0.0506s/iter; left time: 715.4537s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976157\n",
      "\tspeed: 0.0505s/iter; left time: 708.6062s\n",
      "\titers: 500, epoch: 5 | loss: 0.0992124\n",
      "\tspeed: 0.0506s/iter; left time: 704.4007s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925273\n",
      "\tspeed: 0.0505s/iter; left time: 698.1557s\n",
      "\titers: 700, epoch: 5 | loss: 0.0902019\n",
      "\tspeed: 0.0506s/iter; left time: 694.8242s\n",
      "\titers: 800, epoch: 5 | loss: 0.0899991\n",
      "\tspeed: 0.0505s/iter; left time: 688.3376s\n",
      "\titers: 900, epoch: 5 | loss: 0.0957246\n",
      "\tspeed: 0.0505s/iter; left time: 683.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0968106 Vali Loss: 0.1373353 Test Loss: 0.1569665\n",
      "Validation loss decreased (0.138345 --> 0.137335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0971396\n",
      "\tspeed: 0.1410s/iter; left time: 1893.4415s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877258\n",
      "\tspeed: 0.0505s/iter; left time: 673.6076s\n",
      "\titers: 300, epoch: 6 | loss: 0.0944563\n",
      "\tspeed: 0.0505s/iter; left time: 668.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0953016\n",
      "\tspeed: 0.0505s/iter; left time: 663.6332s\n",
      "\titers: 500, epoch: 6 | loss: 0.0904507\n",
      "\tspeed: 0.0506s/iter; left time: 658.7336s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920923\n",
      "\tspeed: 0.0507s/iter; left time: 655.0894s\n",
      "\titers: 700, epoch: 6 | loss: 0.0855336\n",
      "\tspeed: 0.0506s/iter; left time: 649.2819s\n",
      "\titers: 800, epoch: 6 | loss: 0.0849263\n",
      "\tspeed: 0.0507s/iter; left time: 645.0929s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849293\n",
      "\tspeed: 0.0505s/iter; left time: 638.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 902 | Train Loss: 0.0900812 Vali Loss: 0.1398693 Test Loss: 0.1587747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829473\n",
      "\tspeed: 0.1391s/iter; left time: 1742.6588s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794557\n",
      "\tspeed: 0.0507s/iter; left time: 630.6465s\n",
      "\titers: 300, epoch: 7 | loss: 0.0834720\n",
      "\tspeed: 0.0507s/iter; left time: 625.3873s\n",
      "\titers: 400, epoch: 7 | loss: 0.0812156\n",
      "\tspeed: 0.0507s/iter; left time: 620.2857s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828412\n",
      "\tspeed: 0.0507s/iter; left time: 614.8473s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856180\n",
      "\tspeed: 0.0506s/iter; left time: 609.1617s\n",
      "\titers: 700, epoch: 7 | loss: 0.0841857\n",
      "\tspeed: 0.0507s/iter; left time: 604.2357s\n",
      "\titers: 800, epoch: 7 | loss: 0.0855514\n",
      "\tspeed: 0.0506s/iter; left time: 598.9587s\n",
      "\titers: 900, epoch: 7 | loss: 0.0821454\n",
      "\tspeed: 0.0507s/iter; left time: 594.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0844364 Vali Loss: 0.1380800 Test Loss: 0.1562963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792243\n",
      "\tspeed: 0.1383s/iter; left time: 1607.5268s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758932\n",
      "\tspeed: 0.0506s/iter; left time: 583.1025s\n",
      "\titers: 300, epoch: 8 | loss: 0.0826427\n",
      "\tspeed: 0.0506s/iter; left time: 578.4702s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799903\n",
      "\tspeed: 0.0506s/iter; left time: 573.5689s\n",
      "\titers: 500, epoch: 8 | loss: 0.0791600\n",
      "\tspeed: 0.0504s/iter; left time: 565.6440s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825389\n",
      "\tspeed: 0.0505s/iter; left time: 562.1391s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792387\n",
      "\tspeed: 0.0506s/iter; left time: 557.6783s\n",
      "\titers: 800, epoch: 8 | loss: 0.0800074\n",
      "\tspeed: 0.0504s/iter; left time: 551.0006s\n",
      "\titers: 900, epoch: 8 | loss: 0.0764232\n",
      "\tspeed: 0.0504s/iter; left time: 545.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0794340 Vali Loss: 0.1406030 Test Loss: 0.1605993\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766746\n",
      "\tspeed: 0.1381s/iter; left time: 1481.6013s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807511\n",
      "\tspeed: 0.0505s/iter; left time: 536.5790s\n",
      "\titers: 300, epoch: 9 | loss: 0.0721841\n",
      "\tspeed: 0.0507s/iter; left time: 533.2897s\n",
      "\titers: 400, epoch: 9 | loss: 0.0782305\n",
      "\tspeed: 0.0507s/iter; left time: 528.4923s\n",
      "\titers: 500, epoch: 9 | loss: 0.0747176\n",
      "\tspeed: 0.0507s/iter; left time: 523.3335s\n",
      "\titers: 600, epoch: 9 | loss: 0.0727979\n",
      "\tspeed: 0.0507s/iter; left time: 518.3577s\n",
      "\titers: 700, epoch: 9 | loss: 0.0737757\n",
      "\tspeed: 0.0507s/iter; left time: 513.0490s\n",
      "\titers: 800, epoch: 9 | loss: 0.0740445\n",
      "\tspeed: 0.0506s/iter; left time: 506.9854s\n",
      "\titers: 900, epoch: 9 | loss: 0.0758738\n",
      "\tspeed: 0.0506s/iter; left time: 501.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 902 | Train Loss: 0.0753867 Vali Loss: 0.1409122 Test Loss: 0.1620111\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738081\n",
      "\tspeed: 0.1402s/iter; left time: 1377.4754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753992\n",
      "\tspeed: 0.0515s/iter; left time: 500.3210s\n",
      "\titers: 300, epoch: 10 | loss: 0.0722770\n",
      "\tspeed: 0.0515s/iter; left time: 495.7508s\n",
      "\titers: 400, epoch: 10 | loss: 0.0743530\n",
      "\tspeed: 0.0511s/iter; left time: 486.2793s\n",
      "\titers: 500, epoch: 10 | loss: 0.0718583\n",
      "\tspeed: 0.0510s/iter; left time: 481.0144s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755678\n",
      "\tspeed: 0.0511s/iter; left time: 476.3854s\n",
      "\titers: 700, epoch: 10 | loss: 0.0725444\n",
      "\tspeed: 0.0510s/iter; left time: 470.1557s\n",
      "\titers: 800, epoch: 10 | loss: 0.0725415\n",
      "\tspeed: 0.0507s/iter; left time: 462.4133s\n",
      "\titers: 900, epoch: 10 | loss: 0.0698420\n",
      "\tspeed: 0.0507s/iter; left time: 457.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0718391 Vali Loss: 0.1405233 Test Loss: 0.1635022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.051229722797870636, rmse:0.22633983194828033, mae:0.1569782793521881, rse:0.8018538951873779\n",
      "Intermediate time for DE and pred_len 168: 00h:24m:56.06s\n",
      "Intermediate time for DE: 00h:56m:17.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2065667\n",
      "\tspeed: 0.0585s/iter; left time: 1055.0276s\n",
      "\titers: 200, epoch: 1 | loss: 0.1898771\n",
      "\tspeed: 0.0340s/iter; left time: 608.9094s\n",
      "\titers: 300, epoch: 1 | loss: 0.1781441\n",
      "\tspeed: 0.0339s/iter; left time: 604.1571s\n",
      "\titers: 400, epoch: 1 | loss: 0.1769260\n",
      "\tspeed: 0.0339s/iter; left time: 601.0270s\n",
      "\titers: 500, epoch: 1 | loss: 0.1623933\n",
      "\tspeed: 0.0340s/iter; left time: 598.4446s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630156\n",
      "\tspeed: 0.0340s/iter; left time: 594.9816s\n",
      "\titers: 700, epoch: 1 | loss: 0.1549021\n",
      "\tspeed: 0.0339s/iter; left time: 591.3637s\n",
      "\titers: 800, epoch: 1 | loss: 0.1450832\n",
      "\tspeed: 0.0340s/iter; left time: 588.7659s\n",
      "\titers: 900, epoch: 1 | loss: 0.1431629\n",
      "\tspeed: 0.0340s/iter; left time: 585.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.1802093 Vali Loss: 0.1521474 Test Loss: 0.1806995\n",
      "Validation loss decreased (inf --> 0.152147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1379461\n",
      "\tspeed: 0.1024s/iter; left time: 1752.2041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1183134\n",
      "\tspeed: 0.0340s/iter; left time: 578.6834s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016329\n",
      "\tspeed: 0.0340s/iter; left time: 575.0825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1114180\n",
      "\tspeed: 0.0340s/iter; left time: 571.9411s\n",
      "\titers: 500, epoch: 2 | loss: 0.1128901\n",
      "\tspeed: 0.0340s/iter; left time: 568.0567s\n",
      "\titers: 600, epoch: 2 | loss: 0.0933868\n",
      "\tspeed: 0.0340s/iter; left time: 565.0899s\n",
      "\titers: 700, epoch: 2 | loss: 0.1148216\n",
      "\tspeed: 0.0340s/iter; left time: 562.1364s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128488\n",
      "\tspeed: 0.0340s/iter; left time: 558.8138s\n",
      "\titers: 900, epoch: 2 | loss: 0.0961874\n",
      "\tspeed: 0.0340s/iter; left time: 555.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.1125205 Vali Loss: 0.1164644 Test Loss: 0.1396194\n",
      "Validation loss decreased (0.152147 --> 0.116464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1032601\n",
      "\tspeed: 0.0965s/iter; left time: 1563.8764s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003233\n",
      "\tspeed: 0.0340s/iter; left time: 548.0625s\n",
      "\titers: 300, epoch: 3 | loss: 0.1062481\n",
      "\tspeed: 0.0340s/iter; left time: 544.6023s\n",
      "\titers: 400, epoch: 3 | loss: 0.0953404\n",
      "\tspeed: 0.0340s/iter; left time: 541.1076s\n",
      "\titers: 500, epoch: 3 | loss: 0.0999686\n",
      "\tspeed: 0.0340s/iter; left time: 538.0603s\n",
      "\titers: 600, epoch: 3 | loss: 0.0992506\n",
      "\tspeed: 0.0340s/iter; left time: 534.1618s\n",
      "\titers: 700, epoch: 3 | loss: 0.0999163\n",
      "\tspeed: 0.0340s/iter; left time: 531.0028s\n",
      "\titers: 800, epoch: 3 | loss: 0.0913728\n",
      "\tspeed: 0.0340s/iter; left time: 527.7707s\n",
      "\titers: 900, epoch: 3 | loss: 0.1034245\n",
      "\tspeed: 0.0340s/iter; left time: 524.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0998791 Vali Loss: 0.1129812 Test Loss: 0.1356770\n",
      "Validation loss decreased (0.116464 --> 0.112981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897522\n",
      "\tspeed: 0.0980s/iter; left time: 1499.8458s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064864\n",
      "\tspeed: 0.0346s/iter; left time: 526.4130s\n",
      "\titers: 300, epoch: 4 | loss: 0.0940685\n",
      "\tspeed: 0.0343s/iter; left time: 518.5255s\n",
      "\titers: 400, epoch: 4 | loss: 0.1048222\n",
      "\tspeed: 0.0341s/iter; left time: 511.0756s\n",
      "\titers: 500, epoch: 4 | loss: 0.1119908\n",
      "\tspeed: 0.0341s/iter; left time: 508.0281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1028988\n",
      "\tspeed: 0.0341s/iter; left time: 504.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.0919001\n",
      "\tspeed: 0.0341s/iter; left time: 501.7008s\n",
      "\titers: 800, epoch: 4 | loss: 0.0971707\n",
      "\tspeed: 0.0341s/iter; left time: 497.9438s\n",
      "\titers: 900, epoch: 4 | loss: 0.0936811\n",
      "\tspeed: 0.0341s/iter; left time: 494.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 906 | Train Loss: 0.0970638 Vali Loss: 0.1139413 Test Loss: 0.1345681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1065073\n",
      "\tspeed: 0.0945s/iter; left time: 1360.9809s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901787\n",
      "\tspeed: 0.0340s/iter; left time: 486.4075s\n",
      "\titers: 300, epoch: 5 | loss: 0.0899963\n",
      "\tspeed: 0.0340s/iter; left time: 483.3176s\n",
      "\titers: 400, epoch: 5 | loss: 0.1047166\n",
      "\tspeed: 0.0340s/iter; left time: 479.6122s\n",
      "\titers: 500, epoch: 5 | loss: 0.0848665\n",
      "\tspeed: 0.0340s/iter; left time: 476.0220s\n",
      "\titers: 600, epoch: 5 | loss: 0.0877800\n",
      "\tspeed: 0.0341s/iter; left time: 473.3804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0995184\n",
      "\tspeed: 0.0340s/iter; left time: 469.2897s\n",
      "\titers: 800, epoch: 5 | loss: 0.1012287\n",
      "\tspeed: 0.0340s/iter; left time: 466.3292s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855802\n",
      "\tspeed: 0.0341s/iter; left time: 463.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0934970 Vali Loss: 0.1173672 Test Loss: 0.1402675\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0928552\n",
      "\tspeed: 0.0936s/iter; left time: 1262.0840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0989584\n",
      "\tspeed: 0.0341s/iter; left time: 456.0414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907293\n",
      "\tspeed: 0.0341s/iter; left time: 453.4878s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939442\n",
      "\tspeed: 0.0341s/iter; left time: 449.2852s\n",
      "\titers: 500, epoch: 6 | loss: 0.0951724\n",
      "\tspeed: 0.0341s/iter; left time: 446.5104s\n",
      "\titers: 600, epoch: 6 | loss: 0.0863666\n",
      "\tspeed: 0.0341s/iter; left time: 442.9592s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910364\n",
      "\tspeed: 0.0341s/iter; left time: 439.9638s\n",
      "\titers: 800, epoch: 6 | loss: 0.0822814\n",
      "\tspeed: 0.0341s/iter; left time: 436.3053s\n",
      "\titers: 900, epoch: 6 | loss: 0.0938590\n",
      "\tspeed: 0.0341s/iter; left time: 433.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0908272 Vali Loss: 0.1192106 Test Loss: 0.1453762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746693\n",
      "\tspeed: 0.0942s/iter; left time: 1185.1489s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773950\n",
      "\tspeed: 0.0341s/iter; left time: 426.2154s\n",
      "\titers: 300, epoch: 7 | loss: 0.0814477\n",
      "\tspeed: 0.0341s/iter; left time: 421.8661s\n",
      "\titers: 400, epoch: 7 | loss: 0.0867475\n",
      "\tspeed: 0.0341s/iter; left time: 418.9123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766155\n",
      "\tspeed: 0.0341s/iter; left time: 415.1243s\n",
      "\titers: 600, epoch: 7 | loss: 0.0661413\n",
      "\tspeed: 0.0341s/iter; left time: 411.8718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0771113\n",
      "\tspeed: 0.0340s/iter; left time: 408.0494s\n",
      "\titers: 800, epoch: 7 | loss: 0.0708948\n",
      "\tspeed: 0.0341s/iter; left time: 404.7029s\n",
      "\titers: 900, epoch: 7 | loss: 0.0775627\n",
      "\tspeed: 0.0341s/iter; left time: 401.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0792233 Vali Loss: 0.1053339 Test Loss: 0.1323265\n",
      "Validation loss decreased (0.112981 --> 0.105334).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742684\n",
      "\tspeed: 0.0994s/iter; left time: 1160.8595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691775\n",
      "\tspeed: 0.0342s/iter; left time: 395.4680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0811470\n",
      "\tspeed: 0.0342s/iter; left time: 392.3738s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708296\n",
      "\tspeed: 0.0341s/iter; left time: 387.5259s\n",
      "\titers: 500, epoch: 8 | loss: 0.0749293\n",
      "\tspeed: 0.0341s/iter; left time: 384.5004s\n",
      "\titers: 600, epoch: 8 | loss: 0.0783654\n",
      "\tspeed: 0.0341s/iter; left time: 381.4007s\n",
      "\titers: 700, epoch: 8 | loss: 0.0806148\n",
      "\tspeed: 0.0341s/iter; left time: 378.3309s\n",
      "\titers: 800, epoch: 8 | loss: 0.0710718\n",
      "\tspeed: 0.0341s/iter; left time: 374.6150s\n",
      "\titers: 900, epoch: 8 | loss: 0.0672735\n",
      "\tspeed: 0.0341s/iter; left time: 371.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0752110 Vali Loss: 0.1059797 Test Loss: 0.1272185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0764559\n",
      "\tspeed: 0.0936s/iter; left time: 1008.6992s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805175\n",
      "\tspeed: 0.0341s/iter; left time: 364.3434s\n",
      "\titers: 300, epoch: 9 | loss: 0.0701884\n",
      "\tspeed: 0.0341s/iter; left time: 360.6060s\n",
      "\titers: 400, epoch: 9 | loss: 0.0753982\n",
      "\tspeed: 0.0341s/iter; left time: 357.3582s\n",
      "\titers: 500, epoch: 9 | loss: 0.0740065\n",
      "\tspeed: 0.0341s/iter; left time: 353.8814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0621589\n",
      "\tspeed: 0.0341s/iter; left time: 350.4821s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747598\n",
      "\tspeed: 0.0341s/iter; left time: 347.1544s\n",
      "\titers: 800, epoch: 9 | loss: 0.0816423\n",
      "\tspeed: 0.0342s/iter; left time: 344.0571s\n",
      "\titers: 900, epoch: 9 | loss: 0.0695066\n",
      "\tspeed: 0.0341s/iter; left time: 339.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0726019 Vali Loss: 0.1069399 Test Loss: 0.1331095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704984\n",
      "\tspeed: 0.0937s/iter; left time: 924.1009s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701090\n",
      "\tspeed: 0.0341s/iter; left time: 332.8216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0659057\n",
      "\tspeed: 0.0341s/iter; left time: 329.1772s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728105\n",
      "\tspeed: 0.0340s/iter; left time: 325.6335s\n",
      "\titers: 500, epoch: 10 | loss: 0.0748692\n",
      "\tspeed: 0.0341s/iter; left time: 322.9291s\n",
      "\titers: 600, epoch: 10 | loss: 0.0678749\n",
      "\tspeed: 0.0341s/iter; left time: 319.4862s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699628\n",
      "\tspeed: 0.0341s/iter; left time: 315.9728s\n",
      "\titers: 800, epoch: 10 | loss: 0.0634394\n",
      "\tspeed: 0.0341s/iter; left time: 312.2789s\n",
      "\titers: 900, epoch: 10 | loss: 0.0716516\n",
      "\tspeed: 0.0341s/iter; left time: 309.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0698472 Vali Loss: 0.0994613 Test Loss: 0.1233056\n",
      "Validation loss decreased (0.105334 --> 0.099461).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0626306\n",
      "\tspeed: 0.0962s/iter; left time: 861.7134s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640720\n",
      "\tspeed: 0.0340s/iter; left time: 301.5909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0588703\n",
      "\tspeed: 0.0341s/iter; left time: 298.7134s\n",
      "\titers: 400, epoch: 11 | loss: 0.0595044\n",
      "\tspeed: 0.0340s/iter; left time: 294.7817s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624516\n",
      "\tspeed: 0.0341s/iter; left time: 291.5805s\n",
      "\titers: 600, epoch: 11 | loss: 0.0580348\n",
      "\tspeed: 0.0340s/iter; left time: 287.6216s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642682\n",
      "\tspeed: 0.0341s/iter; left time: 285.1872s\n",
      "\titers: 800, epoch: 11 | loss: 0.0618705\n",
      "\tspeed: 0.0341s/iter; left time: 281.5465s\n",
      "\titers: 900, epoch: 11 | loss: 0.0543362\n",
      "\tspeed: 0.0340s/iter; left time: 277.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0620900 Vali Loss: 0.1001814 Test Loss: 0.1275305\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608115\n",
      "\tspeed: 0.0933s/iter; left time: 751.3224s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623593\n",
      "\tspeed: 0.0341s/iter; left time: 270.8942s\n",
      "\titers: 300, epoch: 12 | loss: 0.0562274\n",
      "\tspeed: 0.0341s/iter; left time: 268.0192s\n",
      "\titers: 400, epoch: 12 | loss: 0.0648748\n",
      "\tspeed: 0.0341s/iter; left time: 264.4116s\n",
      "\titers: 500, epoch: 12 | loss: 0.0535899\n",
      "\tspeed: 0.0341s/iter; left time: 260.6790s\n",
      "\titers: 600, epoch: 12 | loss: 0.0538404\n",
      "\tspeed: 0.0341s/iter; left time: 257.2894s\n",
      "\titers: 700, epoch: 12 | loss: 0.0548301\n",
      "\tspeed: 0.0341s/iter; left time: 254.1875s\n",
      "\titers: 800, epoch: 12 | loss: 0.0514138\n",
      "\tspeed: 0.0340s/iter; left time: 250.2762s\n",
      "\titers: 900, epoch: 12 | loss: 0.0655189\n",
      "\tspeed: 0.0341s/iter; left time: 247.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0597273 Vali Loss: 0.1036253 Test Loss: 0.1352557\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0566351\n",
      "\tspeed: 0.0941s/iter; left time: 673.0170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536230\n",
      "\tspeed: 0.0341s/iter; left time: 240.1297s\n",
      "\titers: 300, epoch: 13 | loss: 0.0634737\n",
      "\tspeed: 0.0341s/iter; left time: 237.0724s\n",
      "\titers: 400, epoch: 13 | loss: 0.0572632\n",
      "\tspeed: 0.0340s/iter; left time: 233.1244s\n",
      "\titers: 500, epoch: 13 | loss: 0.0540060\n",
      "\tspeed: 0.0341s/iter; left time: 229.8116s\n",
      "\titers: 600, epoch: 13 | loss: 0.0529787\n",
      "\tspeed: 0.0341s/iter; left time: 226.9394s\n",
      "\titers: 700, epoch: 13 | loss: 0.0610991\n",
      "\tspeed: 0.0341s/iter; left time: 223.1880s\n",
      "\titers: 800, epoch: 13 | loss: 0.0578308\n",
      "\tspeed: 0.0341s/iter; left time: 219.6118s\n",
      "\titers: 900, epoch: 13 | loss: 0.0553324\n",
      "\tspeed: 0.0341s/iter; left time: 216.2252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0578906 Vali Loss: 0.1017295 Test Loss: 0.1305108\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0616051\n",
      "\tspeed: 0.0943s/iter; left time: 588.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553820\n",
      "\tspeed: 0.0342s/iter; left time: 209.7892s\n",
      "\titers: 300, epoch: 14 | loss: 0.0544165\n",
      "\tspeed: 0.0342s/iter; left time: 206.4339s\n",
      "\titers: 400, epoch: 14 | loss: 0.0571011\n",
      "\tspeed: 0.0341s/iter; left time: 202.7012s\n",
      "\titers: 500, epoch: 14 | loss: 0.0607028\n",
      "\tspeed: 0.0341s/iter; left time: 199.2424s\n",
      "\titers: 600, epoch: 14 | loss: 0.0542016\n",
      "\tspeed: 0.0341s/iter; left time: 195.8150s\n",
      "\titers: 700, epoch: 14 | loss: 0.0561629\n",
      "\tspeed: 0.0342s/iter; left time: 192.8704s\n",
      "\titers: 800, epoch: 14 | loss: 0.0597202\n",
      "\tspeed: 0.0341s/iter; left time: 189.0456s\n",
      "\titers: 900, epoch: 14 | loss: 0.0638149\n",
      "\tspeed: 0.0342s/iter; left time: 186.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.25s\n",
      "Steps: 906 | Train Loss: 0.0560134 Vali Loss: 0.1008903 Test Loss: 0.1284106\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531591\n",
      "\tspeed: 0.0942s/iter; left time: 502.6085s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574485\n",
      "\tspeed: 0.0341s/iter; left time: 178.4678s\n",
      "\titers: 300, epoch: 15 | loss: 0.0499670\n",
      "\tspeed: 0.0341s/iter; left time: 175.3850s\n",
      "\titers: 400, epoch: 15 | loss: 0.0561084\n",
      "\tspeed: 0.0342s/iter; left time: 172.0325s\n",
      "\titers: 500, epoch: 15 | loss: 0.0534714\n",
      "\tspeed: 0.0342s/iter; left time: 168.7018s\n",
      "\titers: 600, epoch: 15 | loss: 0.0518036\n",
      "\tspeed: 0.0341s/iter; left time: 165.0023s\n",
      "\titers: 700, epoch: 15 | loss: 0.0593414\n",
      "\tspeed: 0.0341s/iter; left time: 161.5421s\n",
      "\titers: 800, epoch: 15 | loss: 0.0531404\n",
      "\tspeed: 0.0341s/iter; left time: 158.3529s\n",
      "\titers: 900, epoch: 15 | loss: 0.0592867\n",
      "\tspeed: 0.0341s/iter; left time: 154.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0546766 Vali Loss: 0.1010287 Test Loss: 0.1288189\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03368111699819565, rmse:0.18352416157722473, mae:0.12335905432701111, rse:0.6327870488166809\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2087424\n",
      "\tspeed: 0.0362s/iter; left time: 652.4385s\n",
      "\titers: 200, epoch: 1 | loss: 0.1828572\n",
      "\tspeed: 0.0342s/iter; left time: 612.3118s\n",
      "\titers: 300, epoch: 1 | loss: 0.1897422\n",
      "\tspeed: 0.0341s/iter; left time: 608.0596s\n",
      "\titers: 400, epoch: 1 | loss: 0.1720902\n",
      "\tspeed: 0.0342s/iter; left time: 605.3768s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669981\n",
      "\tspeed: 0.0341s/iter; left time: 600.9832s\n",
      "\titers: 600, epoch: 1 | loss: 0.1590210\n",
      "\tspeed: 0.0341s/iter; left time: 598.1668s\n",
      "\titers: 700, epoch: 1 | loss: 0.1618395\n",
      "\tspeed: 0.0341s/iter; left time: 594.8208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1537406\n",
      "\tspeed: 0.0342s/iter; left time: 591.7778s\n",
      "\titers: 900, epoch: 1 | loss: 0.1561620\n",
      "\tspeed: 0.0341s/iter; left time: 588.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1811837 Vali Loss: 0.1443907 Test Loss: 0.1706055\n",
      "Validation loss decreased (inf --> 0.144391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1264048\n",
      "\tspeed: 0.0961s/iter; left time: 1644.2747s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242911\n",
      "\tspeed: 0.0342s/iter; left time: 581.1043s\n",
      "\titers: 300, epoch: 2 | loss: 0.1100120\n",
      "\tspeed: 0.0342s/iter; left time: 577.6774s\n",
      "\titers: 400, epoch: 2 | loss: 0.0976940\n",
      "\tspeed: 0.0342s/iter; left time: 574.5811s\n",
      "\titers: 500, epoch: 2 | loss: 0.0993426\n",
      "\tspeed: 0.0341s/iter; left time: 570.3608s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993942\n",
      "\tspeed: 0.0342s/iter; left time: 567.6991s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957400\n",
      "\tspeed: 0.0342s/iter; left time: 564.1766s\n",
      "\titers: 800, epoch: 2 | loss: 0.0965493\n",
      "\tspeed: 0.0342s/iter; left time: 560.8260s\n",
      "\titers: 900, epoch: 2 | loss: 0.1025189\n",
      "\tspeed: 0.0341s/iter; left time: 556.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1120638 Vali Loss: 0.1135424 Test Loss: 0.1331562\n",
      "Validation loss decreased (0.144391 --> 0.113542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881129\n",
      "\tspeed: 0.0991s/iter; left time: 1606.9283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0977456\n",
      "\tspeed: 0.0347s/iter; left time: 559.4386s\n",
      "\titers: 300, epoch: 3 | loss: 0.1086163\n",
      "\tspeed: 0.0343s/iter; left time: 549.2724s\n",
      "\titers: 400, epoch: 3 | loss: 0.1002908\n",
      "\tspeed: 0.0341s/iter; left time: 542.8495s\n",
      "\titers: 500, epoch: 3 | loss: 0.0826901\n",
      "\tspeed: 0.0341s/iter; left time: 539.5337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893644\n",
      "\tspeed: 0.0342s/iter; left time: 536.9598s\n",
      "\titers: 700, epoch: 3 | loss: 0.0908650\n",
      "\tspeed: 0.0341s/iter; left time: 532.7367s\n",
      "\titers: 800, epoch: 3 | loss: 0.0975903\n",
      "\tspeed: 0.0346s/iter; left time: 536.0341s\n",
      "\titers: 900, epoch: 3 | loss: 0.0928147\n",
      "\tspeed: 0.0347s/iter; left time: 534.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.41s\n",
      "Steps: 906 | Train Loss: 0.0944582 Vali Loss: 0.1077265 Test Loss: 0.1298520\n",
      "Validation loss decreased (0.113542 --> 0.107726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863190\n",
      "\tspeed: 0.0970s/iter; left time: 1483.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907177\n",
      "\tspeed: 0.0341s/iter; left time: 518.1031s\n",
      "\titers: 300, epoch: 4 | loss: 0.0833950\n",
      "\tspeed: 0.0341s/iter; left time: 514.8418s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885096\n",
      "\tspeed: 0.0341s/iter; left time: 510.8771s\n",
      "\titers: 500, epoch: 4 | loss: 0.1024313\n",
      "\tspeed: 0.0341s/iter; left time: 508.6603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902057\n",
      "\tspeed: 0.0341s/iter; left time: 504.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877432\n",
      "\tspeed: 0.0341s/iter; left time: 501.8142s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994082\n",
      "\tspeed: 0.0342s/iter; left time: 499.0221s\n",
      "\titers: 900, epoch: 4 | loss: 0.0841573\n",
      "\tspeed: 0.0341s/iter; left time: 494.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0908629 Vali Loss: 0.1066669 Test Loss: 0.1268926\n",
      "Validation loss decreased (0.107726 --> 0.106667).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901364\n",
      "\tspeed: 0.0965s/iter; left time: 1388.7668s\n",
      "\titers: 200, epoch: 5 | loss: 0.0883172\n",
      "\tspeed: 0.0341s/iter; left time: 488.0627s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873815\n",
      "\tspeed: 0.0341s/iter; left time: 484.5753s\n",
      "\titers: 400, epoch: 5 | loss: 0.0802048\n",
      "\tspeed: 0.0342s/iter; left time: 481.8464s\n",
      "\titers: 500, epoch: 5 | loss: 0.0834858\n",
      "\tspeed: 0.0342s/iter; left time: 478.1296s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920321\n",
      "\tspeed: 0.0341s/iter; left time: 474.1742s\n",
      "\titers: 700, epoch: 5 | loss: 0.1012928\n",
      "\tspeed: 0.0341s/iter; left time: 470.7579s\n",
      "\titers: 800, epoch: 5 | loss: 0.0949160\n",
      "\tspeed: 0.0342s/iter; left time: 467.9884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0833733\n",
      "\tspeed: 0.0341s/iter; left time: 464.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0878463 Vali Loss: 0.1098253 Test Loss: 0.1307452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0875461\n",
      "\tspeed: 0.0945s/iter; left time: 1274.8394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793280\n",
      "\tspeed: 0.0347s/iter; left time: 464.6410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0823781\n",
      "\tspeed: 0.0347s/iter; left time: 461.2001s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781062\n",
      "\tspeed: 0.0347s/iter; left time: 458.1822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0726712\n",
      "\tspeed: 0.0347s/iter; left time: 453.9454s\n",
      "\titers: 600, epoch: 6 | loss: 0.0621493\n",
      "\tspeed: 0.0344s/iter; left time: 446.9567s\n",
      "\titers: 700, epoch: 6 | loss: 0.0807547\n",
      "\tspeed: 0.0341s/iter; left time: 439.7816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0704086\n",
      "\tspeed: 0.0341s/iter; left time: 436.5041s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726400\n",
      "\tspeed: 0.0341s/iter; left time: 432.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0782342 Vali Loss: 0.0994923 Test Loss: 0.1179419\n",
      "Validation loss decreased (0.106667 --> 0.099492).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712830\n",
      "\tspeed: 0.0978s/iter; left time: 1231.4343s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739732\n",
      "\tspeed: 0.0347s/iter; left time: 433.0052s\n",
      "\titers: 300, epoch: 7 | loss: 0.0753709\n",
      "\tspeed: 0.0347s/iter; left time: 429.3025s\n",
      "\titers: 400, epoch: 7 | loss: 0.0684797\n",
      "\tspeed: 0.0341s/iter; left time: 419.4674s\n",
      "\titers: 500, epoch: 7 | loss: 0.0776076\n",
      "\tspeed: 0.0342s/iter; left time: 416.5956s\n",
      "\titers: 600, epoch: 7 | loss: 0.0703165\n",
      "\tspeed: 0.0341s/iter; left time: 412.4213s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794782\n",
      "\tspeed: 0.0341s/iter; left time: 409.1995s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693715\n",
      "\tspeed: 0.0341s/iter; left time: 405.5195s\n",
      "\titers: 900, epoch: 7 | loss: 0.0780969\n",
      "\tspeed: 0.0342s/iter; left time: 402.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0721806 Vali Loss: 0.0970641 Test Loss: 0.1169970\n",
      "Validation loss decreased (0.099492 --> 0.097064).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0636127\n",
      "\tspeed: 0.0981s/iter; left time: 1145.4293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0630548\n",
      "\tspeed: 0.0342s/iter; left time: 395.8652s\n",
      "\titers: 300, epoch: 8 | loss: 0.0730316\n",
      "\tspeed: 0.0342s/iter; left time: 392.2474s\n",
      "\titers: 400, epoch: 8 | loss: 0.0669587\n",
      "\tspeed: 0.0341s/iter; left time: 388.5562s\n",
      "\titers: 500, epoch: 8 | loss: 0.0619939\n",
      "\tspeed: 0.0342s/iter; left time: 385.2777s\n",
      "\titers: 600, epoch: 8 | loss: 0.0640725\n",
      "\tspeed: 0.0342s/iter; left time: 382.2546s\n",
      "\titers: 700, epoch: 8 | loss: 0.0613099\n",
      "\tspeed: 0.0341s/iter; left time: 378.3109s\n",
      "\titers: 800, epoch: 8 | loss: 0.0650655\n",
      "\tspeed: 0.0342s/iter; left time: 375.4917s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699186\n",
      "\tspeed: 0.0342s/iter; left time: 371.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.21s\n",
      "Steps: 906 | Train Loss: 0.0689264 Vali Loss: 0.0993467 Test Loss: 0.1192917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681697\n",
      "\tspeed: 0.0938s/iter; left time: 1010.6405s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609449\n",
      "\tspeed: 0.0341s/iter; left time: 364.2415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0758209\n",
      "\tspeed: 0.0341s/iter; left time: 360.3506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0647182\n",
      "\tspeed: 0.0341s/iter; left time: 357.5211s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599880\n",
      "\tspeed: 0.0341s/iter; left time: 353.8521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696192\n",
      "\tspeed: 0.0342s/iter; left time: 351.0960s\n",
      "\titers: 700, epoch: 9 | loss: 0.0631149\n",
      "\tspeed: 0.0342s/iter; left time: 347.4902s\n",
      "\titers: 800, epoch: 9 | loss: 0.0657809\n",
      "\tspeed: 0.0342s/iter; left time: 344.1916s\n",
      "\titers: 900, epoch: 9 | loss: 0.0715103\n",
      "\tspeed: 0.0341s/iter; left time: 340.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.17s\n",
      "Steps: 906 | Train Loss: 0.0663550 Vali Loss: 0.0995142 Test Loss: 0.1232103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0680644\n",
      "\tspeed: 0.0938s/iter; left time: 925.4896s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559841\n",
      "\tspeed: 0.0342s/iter; left time: 333.7656s\n",
      "\titers: 300, epoch: 10 | loss: 0.0640021\n",
      "\tspeed: 0.0342s/iter; left time: 330.1482s\n",
      "\titers: 400, epoch: 10 | loss: 0.0558519\n",
      "\tspeed: 0.0342s/iter; left time: 327.0613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0592567\n",
      "\tspeed: 0.0341s/iter; left time: 323.1783s\n",
      "\titers: 600, epoch: 10 | loss: 0.0703132\n",
      "\tspeed: 0.0342s/iter; left time: 320.2512s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663644\n",
      "\tspeed: 0.0342s/iter; left time: 316.9101s\n",
      "\titers: 800, epoch: 10 | loss: 0.0713700\n",
      "\tspeed: 0.0342s/iter; left time: 313.5720s\n",
      "\titers: 900, epoch: 10 | loss: 0.0612881\n",
      "\tspeed: 0.0342s/iter; left time: 309.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0636049 Vali Loss: 0.1003592 Test Loss: 0.1226154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0635687\n",
      "\tspeed: 0.0959s/iter; left time: 858.9658s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579782\n",
      "\tspeed: 0.0341s/iter; left time: 302.2018s\n",
      "\titers: 300, epoch: 11 | loss: 0.0577329\n",
      "\tspeed: 0.0341s/iter; left time: 298.8250s\n",
      "\titers: 400, epoch: 11 | loss: 0.0584427\n",
      "\tspeed: 0.0341s/iter; left time: 295.6880s\n",
      "\titers: 500, epoch: 11 | loss: 0.0652117\n",
      "\tspeed: 0.0341s/iter; left time: 292.0533s\n",
      "\titers: 600, epoch: 11 | loss: 0.0556371\n",
      "\tspeed: 0.0341s/iter; left time: 288.8224s\n",
      "\titers: 700, epoch: 11 | loss: 0.0617914\n",
      "\tspeed: 0.0341s/iter; left time: 285.2151s\n",
      "\titers: 800, epoch: 11 | loss: 0.0650759\n",
      "\tspeed: 0.0341s/iter; left time: 281.8704s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628121\n",
      "\tspeed: 0.0341s/iter; left time: 278.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0608432 Vali Loss: 0.1019767 Test Loss: 0.1295339\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601404\n",
      "\tspeed: 0.0934s/iter; left time: 752.6225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608226\n",
      "\tspeed: 0.0342s/iter; left time: 271.9253s\n",
      "\titers: 300, epoch: 12 | loss: 0.0585720\n",
      "\tspeed: 0.0342s/iter; left time: 268.3737s\n",
      "\titers: 400, epoch: 12 | loss: 0.0671864\n",
      "\tspeed: 0.0342s/iter; left time: 264.9392s\n",
      "\titers: 500, epoch: 12 | loss: 0.0586702\n",
      "\tspeed: 0.0342s/iter; left time: 261.5608s\n",
      "\titers: 600, epoch: 12 | loss: 0.0578963\n",
      "\tspeed: 0.0342s/iter; left time: 258.2738s\n",
      "\titers: 700, epoch: 12 | loss: 0.0511237\n",
      "\tspeed: 0.0342s/iter; left time: 254.6666s\n",
      "\titers: 800, epoch: 12 | loss: 0.0598192\n",
      "\tspeed: 0.0342s/iter; left time: 251.4330s\n",
      "\titers: 900, epoch: 12 | loss: 0.0562920\n",
      "\tspeed: 0.0342s/iter; left time: 247.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0588874 Vali Loss: 0.1025693 Test Loss: 0.1268519\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03127928450703621, rmse:0.17685949802398682, mae:0.11696060001850128, rse:0.6098074316978455\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:51.71s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2268764\n",
      "\tspeed: 0.0655s/iter; left time: 1178.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.1978672\n",
      "\tspeed: 0.0413s/iter; left time: 739.0064s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943929\n",
      "\tspeed: 0.0420s/iter; left time: 747.6673s\n",
      "\titers: 400, epoch: 1 | loss: 0.1920299\n",
      "\tspeed: 0.0420s/iter; left time: 743.2215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1802773\n",
      "\tspeed: 0.0421s/iter; left time: 739.5867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717280\n",
      "\tspeed: 0.0421s/iter; left time: 735.5826s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656476\n",
      "\tspeed: 0.0420s/iter; left time: 730.7696s\n",
      "\titers: 800, epoch: 1 | loss: 0.1696963\n",
      "\tspeed: 0.0420s/iter; left time: 726.1528s\n",
      "\titers: 900, epoch: 1 | loss: 0.1643242\n",
      "\tspeed: 0.0421s/iter; left time: 723.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 904 | Train Loss: 0.1897053 Vali Loss: 0.1728368 Test Loss: 0.2124270\n",
      "Validation loss decreased (inf --> 0.172837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1457785\n",
      "\tspeed: 0.1164s/iter; left time: 1987.5548s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392656\n",
      "\tspeed: 0.0415s/iter; left time: 705.1681s\n",
      "\titers: 300, epoch: 2 | loss: 0.1343261\n",
      "\tspeed: 0.0415s/iter; left time: 699.7559s\n",
      "\titers: 400, epoch: 2 | loss: 0.1345560\n",
      "\tspeed: 0.0421s/iter; left time: 705.8104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1346623\n",
      "\tspeed: 0.0421s/iter; left time: 702.6320s\n",
      "\titers: 600, epoch: 2 | loss: 0.1332583\n",
      "\tspeed: 0.0419s/iter; left time: 694.3021s\n",
      "\titers: 700, epoch: 2 | loss: 0.1261364\n",
      "\tspeed: 0.0421s/iter; left time: 693.9271s\n",
      "\titers: 800, epoch: 2 | loss: 0.1254614\n",
      "\tspeed: 0.0421s/iter; left time: 689.2999s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305606\n",
      "\tspeed: 0.0421s/iter; left time: 684.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 904 | Train Loss: 0.1357239 Vali Loss: 0.1446885 Test Loss: 0.1781681\n",
      "Validation loss decreased (0.172837 --> 0.144689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1175372\n",
      "\tspeed: 0.1192s/iter; left time: 1927.9999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1188484\n",
      "\tspeed: 0.0421s/iter; left time: 676.6233s\n",
      "\titers: 300, epoch: 3 | loss: 0.1154065\n",
      "\tspeed: 0.0421s/iter; left time: 672.0777s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113715\n",
      "\tspeed: 0.0420s/iter; left time: 667.4296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1078852\n",
      "\tspeed: 0.0421s/iter; left time: 663.4356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1149738\n",
      "\tspeed: 0.0421s/iter; left time: 659.3680s\n",
      "\titers: 700, epoch: 3 | loss: 0.1066848\n",
      "\tspeed: 0.0421s/iter; left time: 655.3036s\n",
      "\titers: 800, epoch: 3 | loss: 0.1042039\n",
      "\tspeed: 0.0420s/iter; left time: 649.6626s\n",
      "\titers: 900, epoch: 3 | loss: 0.1103720\n",
      "\tspeed: 0.0420s/iter; left time: 645.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.1113842 Vali Loss: 0.1260925 Test Loss: 0.1568912\n",
      "Validation loss decreased (0.144689 --> 0.126093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1156684\n",
      "\tspeed: 0.1176s/iter; left time: 1795.7961s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072669\n",
      "\tspeed: 0.0415s/iter; left time: 629.9717s\n",
      "\titers: 300, epoch: 4 | loss: 0.1097675\n",
      "\tspeed: 0.0415s/iter; left time: 626.0487s\n",
      "\titers: 400, epoch: 4 | loss: 0.0987495\n",
      "\tspeed: 0.0416s/iter; left time: 622.0291s\n",
      "\titers: 500, epoch: 4 | loss: 0.0966180\n",
      "\tspeed: 0.0416s/iter; left time: 618.0380s\n",
      "\titers: 600, epoch: 4 | loss: 0.1013041\n",
      "\tspeed: 0.0416s/iter; left time: 613.6836s\n",
      "\titers: 700, epoch: 4 | loss: 0.0967172\n",
      "\tspeed: 0.0416s/iter; left time: 609.5065s\n",
      "\titers: 800, epoch: 4 | loss: 0.1014885\n",
      "\tspeed: 0.0415s/iter; left time: 605.2582s\n",
      "\titers: 900, epoch: 4 | loss: 0.1030009\n",
      "\tspeed: 0.0415s/iter; left time: 601.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1018708 Vali Loss: 0.1277115 Test Loss: 0.1587207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942518\n",
      "\tspeed: 0.1139s/iter; left time: 1636.5789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950471\n",
      "\tspeed: 0.0415s/iter; left time: 592.5768s\n",
      "\titers: 300, epoch: 5 | loss: 0.0928046\n",
      "\tspeed: 0.0415s/iter; left time: 588.2587s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033714\n",
      "\tspeed: 0.0415s/iter; left time: 583.5658s\n",
      "\titers: 500, epoch: 5 | loss: 0.0941585\n",
      "\tspeed: 0.0415s/iter; left time: 579.3170s\n",
      "\titers: 600, epoch: 5 | loss: 0.0995664\n",
      "\tspeed: 0.0415s/iter; left time: 575.1951s\n",
      "\titers: 700, epoch: 5 | loss: 0.1031185\n",
      "\tspeed: 0.0415s/iter; left time: 571.0616s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025636\n",
      "\tspeed: 0.0415s/iter; left time: 567.0282s\n",
      "\titers: 900, epoch: 5 | loss: 0.1002272\n",
      "\tspeed: 0.0415s/iter; left time: 562.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0953789 Vali Loss: 0.1268768 Test Loss: 0.1636338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910520\n",
      "\tspeed: 0.1140s/iter; left time: 1534.1408s\n",
      "\titers: 200, epoch: 6 | loss: 0.0860340\n",
      "\tspeed: 0.0415s/iter; left time: 554.6341s\n",
      "\titers: 300, epoch: 6 | loss: 0.0880820\n",
      "\tspeed: 0.0415s/iter; left time: 550.1306s\n",
      "\titers: 400, epoch: 6 | loss: 0.0941288\n",
      "\tspeed: 0.0415s/iter; left time: 546.4273s\n",
      "\titers: 500, epoch: 6 | loss: 0.0841647\n",
      "\tspeed: 0.0415s/iter; left time: 542.0510s\n",
      "\titers: 600, epoch: 6 | loss: 0.0876083\n",
      "\tspeed: 0.0415s/iter; left time: 537.7534s\n",
      "\titers: 700, epoch: 6 | loss: 0.0830211\n",
      "\tspeed: 0.0415s/iter; left time: 534.1377s\n",
      "\titers: 800, epoch: 6 | loss: 0.0914322\n",
      "\tspeed: 0.0415s/iter; left time: 529.4035s\n",
      "\titers: 900, epoch: 6 | loss: 0.0899133\n",
      "\tspeed: 0.0415s/iter; left time: 525.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0895236 Vali Loss: 0.1278808 Test Loss: 0.1652189\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0836434\n",
      "\tspeed: 0.1132s/iter; left time: 1421.1546s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844925\n",
      "\tspeed: 0.0415s/iter; left time: 517.5073s\n",
      "\titers: 300, epoch: 7 | loss: 0.0794558\n",
      "\tspeed: 0.0415s/iter; left time: 513.3383s\n",
      "\titers: 400, epoch: 7 | loss: 0.0855794\n",
      "\tspeed: 0.0415s/iter; left time: 508.9053s\n",
      "\titers: 500, epoch: 7 | loss: 0.0898345\n",
      "\tspeed: 0.0415s/iter; left time: 504.9240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0911049\n",
      "\tspeed: 0.0415s/iter; left time: 500.8588s\n",
      "\titers: 700, epoch: 7 | loss: 0.0897632\n",
      "\tspeed: 0.0415s/iter; left time: 496.6991s\n",
      "\titers: 800, epoch: 7 | loss: 0.0752865\n",
      "\tspeed: 0.0415s/iter; left time: 492.4032s\n",
      "\titers: 900, epoch: 7 | loss: 0.0809941\n",
      "\tspeed: 0.0415s/iter; left time: 488.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0841153 Vali Loss: 0.1298804 Test Loss: 0.1732888\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823286\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1804s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805886\n",
      "\tspeed: 0.0416s/iter; left time: 480.0498s\n",
      "\titers: 300, epoch: 8 | loss: 0.0787768\n",
      "\tspeed: 0.0415s/iter; left time: 475.3546s\n",
      "\titers: 400, epoch: 8 | loss: 0.0750168\n",
      "\tspeed: 0.0415s/iter; left time: 471.2326s\n",
      "\titers: 500, epoch: 8 | loss: 0.0819786\n",
      "\tspeed: 0.0415s/iter; left time: 466.9707s\n",
      "\titers: 600, epoch: 8 | loss: 0.0769879\n",
      "\tspeed: 0.0416s/iter; left time: 463.5953s\n",
      "\titers: 700, epoch: 8 | loss: 0.0801579\n",
      "\tspeed: 0.0415s/iter; left time: 458.9882s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806662\n",
      "\tspeed: 0.0415s/iter; left time: 454.6568s\n",
      "\titers: 900, epoch: 8 | loss: 0.0836962\n",
      "\tspeed: 0.0415s/iter; left time: 450.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0791007 Vali Loss: 0.1308822 Test Loss: 0.1750989\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049356184899806976, rmse:0.22216251492500305, mae:0.15691299736499786, rse:0.7682689428329468\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2278353\n",
      "\tspeed: 0.0436s/iter; left time: 783.7662s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020534\n",
      "\tspeed: 0.0415s/iter; left time: 742.9428s\n",
      "\titers: 300, epoch: 1 | loss: 0.1878239\n",
      "\tspeed: 0.0416s/iter; left time: 739.1002s\n",
      "\titers: 400, epoch: 1 | loss: 0.1944844\n",
      "\tspeed: 0.0416s/iter; left time: 734.9105s\n",
      "\titers: 500, epoch: 1 | loss: 0.1941353\n",
      "\tspeed: 0.0416s/iter; left time: 731.1568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1729999\n",
      "\tspeed: 0.0416s/iter; left time: 726.9874s\n",
      "\titers: 700, epoch: 1 | loss: 0.1679289\n",
      "\tspeed: 0.0416s/iter; left time: 722.5073s\n",
      "\titers: 800, epoch: 1 | loss: 0.1699705\n",
      "\tspeed: 0.0416s/iter; left time: 719.0877s\n",
      "\titers: 900, epoch: 1 | loss: 0.1647512\n",
      "\tspeed: 0.0416s/iter; left time: 715.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.1937501 Vali Loss: 0.1664132 Test Loss: 0.2047869\n",
      "Validation loss decreased (inf --> 0.166413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1548872\n",
      "\tspeed: 0.1165s/iter; left time: 1990.3129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364976\n",
      "\tspeed: 0.0416s/iter; left time: 706.8648s\n",
      "\titers: 300, epoch: 2 | loss: 0.1455883\n",
      "\tspeed: 0.0417s/iter; left time: 703.0128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1231301\n",
      "\tspeed: 0.0416s/iter; left time: 697.4636s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362744\n",
      "\tspeed: 0.0416s/iter; left time: 693.1189s\n",
      "\titers: 600, epoch: 2 | loss: 0.1244080\n",
      "\tspeed: 0.0416s/iter; left time: 689.3567s\n",
      "\titers: 700, epoch: 2 | loss: 0.1334690\n",
      "\tspeed: 0.0416s/iter; left time: 685.3067s\n",
      "\titers: 800, epoch: 2 | loss: 0.1270750\n",
      "\tspeed: 0.0416s/iter; left time: 680.8819s\n",
      "\titers: 900, epoch: 2 | loss: 0.1180649\n",
      "\tspeed: 0.0416s/iter; left time: 677.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1352863 Vali Loss: 0.1410898 Test Loss: 0.1708414\n",
      "Validation loss decreased (0.166413 --> 0.141090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147558\n",
      "\tspeed: 0.1170s/iter; left time: 1891.8432s\n",
      "\titers: 200, epoch: 3 | loss: 0.1144703\n",
      "\tspeed: 0.0417s/iter; left time: 669.6380s\n",
      "\titers: 300, epoch: 3 | loss: 0.1129461\n",
      "\tspeed: 0.0416s/iter; left time: 665.2663s\n",
      "\titers: 400, epoch: 3 | loss: 0.1159053\n",
      "\tspeed: 0.0417s/iter; left time: 661.1881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1037145\n",
      "\tspeed: 0.0416s/iter; left time: 656.4345s\n",
      "\titers: 600, epoch: 3 | loss: 0.1191663\n",
      "\tspeed: 0.0416s/iter; left time: 652.6964s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158241\n",
      "\tspeed: 0.0416s/iter; left time: 648.3619s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989802\n",
      "\tspeed: 0.0417s/iter; left time: 644.6881s\n",
      "\titers: 900, epoch: 3 | loss: 0.1078756\n",
      "\tspeed: 0.0416s/iter; left time: 639.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.1118837 Vali Loss: 0.1274420 Test Loss: 0.1581856\n",
      "Validation loss decreased (0.141090 --> 0.127442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1074443\n",
      "\tspeed: 0.1171s/iter; left time: 1788.3894s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052178\n",
      "\tspeed: 0.0416s/iter; left time: 630.7722s\n",
      "\titers: 300, epoch: 4 | loss: 0.1018802\n",
      "\tspeed: 0.0416s/iter; left time: 626.5580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1033611\n",
      "\tspeed: 0.0416s/iter; left time: 622.8882s\n",
      "\titers: 500, epoch: 4 | loss: 0.1052628\n",
      "\tspeed: 0.0416s/iter; left time: 618.2769s\n",
      "\titers: 600, epoch: 4 | loss: 0.1043086\n",
      "\tspeed: 0.0416s/iter; left time: 614.4294s\n",
      "\titers: 700, epoch: 4 | loss: 0.1040385\n",
      "\tspeed: 0.0416s/iter; left time: 610.2642s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061757\n",
      "\tspeed: 0.0416s/iter; left time: 606.3039s\n",
      "\titers: 900, epoch: 4 | loss: 0.1004524\n",
      "\tspeed: 0.0416s/iter; left time: 601.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.1023712 Vali Loss: 0.1312658 Test Loss: 0.1651838\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0989314\n",
      "\tspeed: 0.1142s/iter; left time: 1640.3943s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047119\n",
      "\tspeed: 0.0417s/iter; left time: 594.2167s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982214\n",
      "\tspeed: 0.0417s/iter; left time: 590.0576s\n",
      "\titers: 400, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0417s/iter; left time: 585.9079s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974938\n",
      "\tspeed: 0.0416s/iter; left time: 581.2475s\n",
      "\titers: 600, epoch: 5 | loss: 0.0970161\n",
      "\tspeed: 0.0416s/iter; left time: 576.9025s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918606\n",
      "\tspeed: 0.0416s/iter; left time: 572.8600s\n",
      "\titers: 800, epoch: 5 | loss: 0.0898132\n",
      "\tspeed: 0.0417s/iter; left time: 569.1998s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893147\n",
      "\tspeed: 0.0416s/iter; left time: 564.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0967186 Vali Loss: 0.1319823 Test Loss: 0.1671596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0955259\n",
      "\tspeed: 0.1140s/iter; left time: 1534.6863s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896132\n",
      "\tspeed: 0.0416s/iter; left time: 556.4829s\n",
      "\titers: 300, epoch: 6 | loss: 0.0947796\n",
      "\tspeed: 0.0417s/iter; left time: 552.5246s\n",
      "\titers: 400, epoch: 6 | loss: 0.0908911\n",
      "\tspeed: 0.0416s/iter; left time: 548.1117s\n",
      "\titers: 500, epoch: 6 | loss: 0.0873807\n",
      "\tspeed: 0.0417s/iter; left time: 544.2589s\n",
      "\titers: 600, epoch: 6 | loss: 0.0879827\n",
      "\tspeed: 0.0417s/iter; left time: 540.0754s\n",
      "\titers: 700, epoch: 6 | loss: 0.0896935\n",
      "\tspeed: 0.0417s/iter; left time: 536.0600s\n",
      "\titers: 800, epoch: 6 | loss: 0.0941269\n",
      "\tspeed: 0.0416s/iter; left time: 531.3673s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933578\n",
      "\tspeed: 0.0417s/iter; left time: 527.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0908674 Vali Loss: 0.1343007 Test Loss: 0.1725691\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869733\n",
      "\tspeed: 0.1148s/iter; left time: 1441.3462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865798\n",
      "\tspeed: 0.0417s/iter; left time: 519.1138s\n",
      "\titers: 300, epoch: 7 | loss: 0.0872979\n",
      "\tspeed: 0.0417s/iter; left time: 515.1221s\n",
      "\titers: 400, epoch: 7 | loss: 0.0808157\n",
      "\tspeed: 0.0417s/iter; left time: 510.9330s\n",
      "\titers: 500, epoch: 7 | loss: 0.0819069\n",
      "\tspeed: 0.0417s/iter; left time: 506.6866s\n",
      "\titers: 600, epoch: 7 | loss: 0.0884176\n",
      "\tspeed: 0.0417s/iter; left time: 502.3795s\n",
      "\titers: 700, epoch: 7 | loss: 0.0929823\n",
      "\tspeed: 0.0417s/iter; left time: 498.2833s\n",
      "\titers: 800, epoch: 7 | loss: 0.0822935\n",
      "\tspeed: 0.0417s/iter; left time: 494.2249s\n",
      "\titers: 900, epoch: 7 | loss: 0.0851985\n",
      "\tspeed: 0.0417s/iter; left time: 490.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0852665 Vali Loss: 0.1313283 Test Loss: 0.1676679\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839205\n",
      "\tspeed: 0.1140s/iter; left time: 1328.2757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803091\n",
      "\tspeed: 0.0416s/iter; left time: 481.1273s\n",
      "\titers: 300, epoch: 8 | loss: 0.0736933\n",
      "\tspeed: 0.0416s/iter; left time: 476.6921s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799875\n",
      "\tspeed: 0.0416s/iter; left time: 472.7424s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814201\n",
      "\tspeed: 0.0416s/iter; left time: 468.2029s\n",
      "\titers: 600, epoch: 8 | loss: 0.0776833\n",
      "\tspeed: 0.0416s/iter; left time: 464.3979s\n",
      "\titers: 700, epoch: 8 | loss: 0.0707026\n",
      "\tspeed: 0.0417s/iter; left time: 460.3869s\n",
      "\titers: 800, epoch: 8 | loss: 0.0765746\n",
      "\tspeed: 0.0417s/iter; left time: 456.2890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0856424\n",
      "\tspeed: 0.0416s/iter; left time: 451.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0801459 Vali Loss: 0.1328648 Test Loss: 0.1732243\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051835522055625916, rmse:0.22767415642738342, mae:0.158115953207016, rse:0.7873289585113525\n",
      "Intermediate time for GB and pred_len 96: 00h:12m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2144550\n",
      "\tspeed: 0.0736s/iter; left time: 1320.3347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2042320\n",
      "\tspeed: 0.0505s/iter; left time: 901.4268s\n",
      "\titers: 300, epoch: 1 | loss: 0.1855985\n",
      "\tspeed: 0.0507s/iter; left time: 899.5263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1828096\n",
      "\tspeed: 0.0508s/iter; left time: 896.1169s\n",
      "\titers: 500, epoch: 1 | loss: 0.1863522\n",
      "\tspeed: 0.0508s/iter; left time: 890.4390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1806218\n",
      "\tspeed: 0.0507s/iter; left time: 885.0513s\n",
      "\titers: 700, epoch: 1 | loss: 0.1707170\n",
      "\tspeed: 0.0508s/iter; left time: 880.8659s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668490\n",
      "\tspeed: 0.0507s/iter; left time: 874.7028s\n",
      "\titers: 900, epoch: 1 | loss: 0.1642738\n",
      "\tspeed: 0.0508s/iter; left time: 870.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 902 | Train Loss: 0.1902878 Vali Loss: 0.1756261 Test Loss: 0.2136206\n",
      "Validation loss decreased (inf --> 0.175626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546461\n",
      "\tspeed: 0.1416s/iter; left time: 2412.0118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1453713\n",
      "\tspeed: 0.0507s/iter; left time: 858.6454s\n",
      "\titers: 300, epoch: 2 | loss: 0.1408072\n",
      "\tspeed: 0.0507s/iter; left time: 853.8900s\n",
      "\titers: 400, epoch: 2 | loss: 0.1328956\n",
      "\tspeed: 0.0507s/iter; left time: 848.6835s\n",
      "\titers: 500, epoch: 2 | loss: 0.1344081\n",
      "\tspeed: 0.0507s/iter; left time: 844.3704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1351472\n",
      "\tspeed: 0.0507s/iter; left time: 838.7043s\n",
      "\titers: 700, epoch: 2 | loss: 0.1377063\n",
      "\tspeed: 0.0507s/iter; left time: 834.0462s\n",
      "\titers: 800, epoch: 2 | loss: 0.1352134\n",
      "\tspeed: 0.0508s/iter; left time: 829.4362s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376040\n",
      "\tspeed: 0.0507s/iter; left time: 823.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1412551 Vali Loss: 0.1557616 Test Loss: 0.1941232\n",
      "Validation loss decreased (0.175626 --> 0.155762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1322913\n",
      "\tspeed: 0.1434s/iter; left time: 2314.1137s\n",
      "\titers: 200, epoch: 3 | loss: 0.1251840\n",
      "\tspeed: 0.0507s/iter; left time: 812.6631s\n",
      "\titers: 300, epoch: 3 | loss: 0.1327689\n",
      "\tspeed: 0.0507s/iter; left time: 807.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.1270881\n",
      "\tspeed: 0.0507s/iter; left time: 802.8697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1229750\n",
      "\tspeed: 0.0506s/iter; left time: 797.0577s\n",
      "\titers: 600, epoch: 3 | loss: 0.1328987\n",
      "\tspeed: 0.0507s/iter; left time: 793.3704s\n",
      "\titers: 700, epoch: 3 | loss: 0.1204278\n",
      "\tspeed: 0.0506s/iter; left time: 785.9965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1188312\n",
      "\tspeed: 0.0508s/iter; left time: 784.4461s\n",
      "\titers: 900, epoch: 3 | loss: 0.1182145\n",
      "\tspeed: 0.0508s/iter; left time: 779.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.1258696 Vali Loss: 0.1498645 Test Loss: 0.1913567\n",
      "Validation loss decreased (0.155762 --> 0.149865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1236095\n",
      "\tspeed: 0.1429s/iter; left time: 2177.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127460\n",
      "\tspeed: 0.0517s/iter; left time: 783.0264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1189013\n",
      "\tspeed: 0.0511s/iter; left time: 768.8154s\n",
      "\titers: 400, epoch: 4 | loss: 0.1107328\n",
      "\tspeed: 0.0506s/iter; left time: 756.4537s\n",
      "\titers: 500, epoch: 4 | loss: 0.1057849\n",
      "\tspeed: 0.0507s/iter; left time: 751.7938s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077283\n",
      "\tspeed: 0.0506s/iter; left time: 745.7883s\n",
      "\titers: 700, epoch: 4 | loss: 0.1090573\n",
      "\tspeed: 0.0507s/iter; left time: 742.5099s\n",
      "\titers: 800, epoch: 4 | loss: 0.1042960\n",
      "\tspeed: 0.0508s/iter; left time: 737.7649s\n",
      "\titers: 900, epoch: 4 | loss: 0.0960267\n",
      "\tspeed: 0.0508s/iter; left time: 733.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1102404 Vali Loss: 0.1309775 Test Loss: 0.1653814\n",
      "Validation loss decreased (0.149865 --> 0.130978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0952837\n",
      "\tspeed: 0.1428s/iter; left time: 2046.0842s\n",
      "\titers: 200, epoch: 5 | loss: 0.1016937\n",
      "\tspeed: 0.0508s/iter; left time: 722.8595s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965871\n",
      "\tspeed: 0.0509s/iter; left time: 718.7543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0990509\n",
      "\tspeed: 0.0507s/iter; left time: 711.1350s\n",
      "\titers: 500, epoch: 5 | loss: 0.0965394\n",
      "\tspeed: 0.0507s/iter; left time: 706.1450s\n",
      "\titers: 600, epoch: 5 | loss: 0.0947464\n",
      "\tspeed: 0.0508s/iter; left time: 702.9266s\n",
      "\titers: 700, epoch: 5 | loss: 0.0906473\n",
      "\tspeed: 0.0507s/iter; left time: 696.2827s\n",
      "\titers: 800, epoch: 5 | loss: 0.1027681\n",
      "\tspeed: 0.0507s/iter; left time: 691.5529s\n",
      "\titers: 900, epoch: 5 | loss: 0.0998390\n",
      "\tspeed: 0.0507s/iter; left time: 686.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0975682 Vali Loss: 0.1345402 Test Loss: 0.1749502\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0953098\n",
      "\tspeed: 0.1394s/iter; left time: 1871.6152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0979535\n",
      "\tspeed: 0.0509s/iter; left time: 678.3546s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898484\n",
      "\tspeed: 0.0508s/iter; left time: 671.7667s\n",
      "\titers: 400, epoch: 6 | loss: 0.0891806\n",
      "\tspeed: 0.0508s/iter; left time: 666.6549s\n",
      "\titers: 500, epoch: 6 | loss: 0.1021477\n",
      "\tspeed: 0.0507s/iter; left time: 660.9795s\n",
      "\titers: 600, epoch: 6 | loss: 0.0873509\n",
      "\tspeed: 0.0507s/iter; left time: 656.0776s\n",
      "\titers: 700, epoch: 6 | loss: 0.0811544\n",
      "\tspeed: 0.0508s/iter; left time: 651.4109s\n",
      "\titers: 800, epoch: 6 | loss: 0.0884078\n",
      "\tspeed: 0.0510s/iter; left time: 649.1018s\n",
      "\titers: 900, epoch: 6 | loss: 0.0890452\n",
      "\tspeed: 0.0508s/iter; left time: 641.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0908929 Vali Loss: 0.1383472 Test Loss: 0.1792563\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0930536\n",
      "\tspeed: 0.1397s/iter; left time: 1750.8723s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848575\n",
      "\tspeed: 0.0508s/iter; left time: 630.9018s\n",
      "\titers: 300, epoch: 7 | loss: 0.0895651\n",
      "\tspeed: 0.0507s/iter; left time: 625.6852s\n",
      "\titers: 400, epoch: 7 | loss: 0.0846024\n",
      "\tspeed: 0.0508s/iter; left time: 620.9344s\n",
      "\titers: 500, epoch: 7 | loss: 0.0824052\n",
      "\tspeed: 0.0508s/iter; left time: 616.3262s\n",
      "\titers: 600, epoch: 7 | loss: 0.0801848\n",
      "\tspeed: 0.0507s/iter; left time: 610.1180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0878324\n",
      "\tspeed: 0.0507s/iter; left time: 605.1832s\n",
      "\titers: 800, epoch: 7 | loss: 0.0794692\n",
      "\tspeed: 0.0508s/iter; left time: 600.5393s\n",
      "\titers: 900, epoch: 7 | loss: 0.0923864\n",
      "\tspeed: 0.0508s/iter; left time: 595.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 902 | Train Loss: 0.0853172 Vali Loss: 0.1356244 Test Loss: 0.1794397\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0795482\n",
      "\tspeed: 0.1391s/iter; left time: 1616.8590s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793333\n",
      "\tspeed: 0.0509s/iter; left time: 586.2408s\n",
      "\titers: 300, epoch: 8 | loss: 0.0832426\n",
      "\tspeed: 0.0508s/iter; left time: 579.9564s\n",
      "\titers: 400, epoch: 8 | loss: 0.0788528\n",
      "\tspeed: 0.0507s/iter; left time: 574.7891s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814730\n",
      "\tspeed: 0.0508s/iter; left time: 569.9731s\n",
      "\titers: 600, epoch: 8 | loss: 0.0817954\n",
      "\tspeed: 0.0507s/iter; left time: 564.5199s\n",
      "\titers: 700, epoch: 8 | loss: 0.0758450\n",
      "\tspeed: 0.0507s/iter; left time: 559.4593s\n",
      "\titers: 800, epoch: 8 | loss: 0.0744339\n",
      "\tspeed: 0.0507s/iter; left time: 553.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0780436\n",
      "\tspeed: 0.0507s/iter; left time: 549.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0805622 Vali Loss: 0.1370406 Test Loss: 0.1795973\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742666\n",
      "\tspeed: 0.1390s/iter; left time: 1490.7365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785919\n",
      "\tspeed: 0.0507s/iter; left time: 539.1281s\n",
      "\titers: 300, epoch: 9 | loss: 0.0799072\n",
      "\tspeed: 0.0508s/iter; left time: 534.4281s\n",
      "\titers: 400, epoch: 9 | loss: 0.0714043\n",
      "\tspeed: 0.0508s/iter; left time: 529.4868s\n",
      "\titers: 500, epoch: 9 | loss: 0.0772576\n",
      "\tspeed: 0.0507s/iter; left time: 523.5973s\n",
      "\titers: 600, epoch: 9 | loss: 0.0725148\n",
      "\tspeed: 0.0507s/iter; left time: 518.2077s\n",
      "\titers: 700, epoch: 9 | loss: 0.0799865\n",
      "\tspeed: 0.0506s/iter; left time: 512.3497s\n",
      "\titers: 800, epoch: 9 | loss: 0.0802605\n",
      "\tspeed: 0.0507s/iter; left time: 508.6986s\n",
      "\titers: 900, epoch: 9 | loss: 0.0742895\n",
      "\tspeed: 0.0506s/iter; left time: 502.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.0766087 Vali Loss: 0.1366436 Test Loss: 0.1790668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05534675344824791, rmse:0.23525890707969666, mae:0.1653159260749817, rse:0.815612256526947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2155263\n",
      "\tspeed: 0.0535s/iter; left time: 959.0820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1987825\n",
      "\tspeed: 0.0508s/iter; left time: 906.4877s\n",
      "\titers: 300, epoch: 1 | loss: 0.1921764\n",
      "\tspeed: 0.0509s/iter; left time: 902.4375s\n",
      "\titers: 400, epoch: 1 | loss: 0.1906046\n",
      "\tspeed: 0.0508s/iter; left time: 895.3965s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840005\n",
      "\tspeed: 0.0507s/iter; left time: 888.9264s\n",
      "\titers: 600, epoch: 1 | loss: 0.1789132\n",
      "\tspeed: 0.0506s/iter; left time: 883.3171s\n",
      "\titers: 700, epoch: 1 | loss: 0.1818265\n",
      "\tspeed: 0.0507s/iter; left time: 878.3863s\n",
      "\titers: 800, epoch: 1 | loss: 0.1734744\n",
      "\tspeed: 0.0507s/iter; left time: 873.2800s\n",
      "\titers: 900, epoch: 1 | loss: 0.1659183\n",
      "\tspeed: 0.0507s/iter; left time: 868.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1887618 Vali Loss: 0.1742335 Test Loss: 0.2129559\n",
      "Validation loss decreased (inf --> 0.174234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1481940\n",
      "\tspeed: 0.1416s/iter; left time: 2412.2036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1454901\n",
      "\tspeed: 0.0507s/iter; left time: 859.2595s\n",
      "\titers: 300, epoch: 2 | loss: 0.1338724\n",
      "\tspeed: 0.0507s/iter; left time: 853.2802s\n",
      "\titers: 400, epoch: 2 | loss: 0.1323974\n",
      "\tspeed: 0.0507s/iter; left time: 849.0272s\n",
      "\titers: 500, epoch: 2 | loss: 0.1412918\n",
      "\tspeed: 0.0506s/iter; left time: 842.7404s\n",
      "\titers: 600, epoch: 2 | loss: 0.1327669\n",
      "\tspeed: 0.0507s/iter; left time: 837.7773s\n",
      "\titers: 700, epoch: 2 | loss: 0.1384447\n",
      "\tspeed: 0.0506s/iter; left time: 832.4445s\n",
      "\titers: 800, epoch: 2 | loss: 0.1426750\n",
      "\tspeed: 0.0507s/iter; left time: 828.2160s\n",
      "\titers: 900, epoch: 2 | loss: 0.1431397\n",
      "\tspeed: 0.0506s/iter; left time: 821.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1400927 Vali Loss: 0.1554372 Test Loss: 0.1979454\n",
      "Validation loss decreased (0.174234 --> 0.155437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1327099\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1331211\n",
      "\tspeed: 0.0508s/iter; left time: 814.9257s\n",
      "\titers: 300, epoch: 3 | loss: 0.1262807\n",
      "\tspeed: 0.0507s/iter; left time: 808.6486s\n",
      "\titers: 400, epoch: 3 | loss: 0.1330259\n",
      "\tspeed: 0.0507s/iter; left time: 803.5242s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233167\n",
      "\tspeed: 0.0508s/iter; left time: 798.7087s\n",
      "\titers: 600, epoch: 3 | loss: 0.1312564\n",
      "\tspeed: 0.0508s/iter; left time: 794.0562s\n",
      "\titers: 700, epoch: 3 | loss: 0.1340061\n",
      "\tspeed: 0.0508s/iter; left time: 788.8538s\n",
      "\titers: 800, epoch: 3 | loss: 0.1299911\n",
      "\tspeed: 0.0508s/iter; left time: 783.7229s\n",
      "\titers: 900, epoch: 3 | loss: 0.1227380\n",
      "\tspeed: 0.0508s/iter; left time: 778.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1299872 Vali Loss: 0.1563615 Test Loss: 0.1916026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1271074\n",
      "\tspeed: 0.1384s/iter; left time: 2107.9744s\n",
      "\titers: 200, epoch: 4 | loss: 0.1254569\n",
      "\tspeed: 0.0508s/iter; left time: 768.8118s\n",
      "\titers: 300, epoch: 4 | loss: 0.1280436\n",
      "\tspeed: 0.0508s/iter; left time: 763.2334s\n",
      "\titers: 400, epoch: 4 | loss: 0.1153991\n",
      "\tspeed: 0.0508s/iter; left time: 758.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.1159150\n",
      "\tspeed: 0.0508s/iter; left time: 753.6041s\n",
      "\titers: 600, epoch: 4 | loss: 0.1088557\n",
      "\tspeed: 0.0508s/iter; left time: 748.8954s\n",
      "\titers: 700, epoch: 4 | loss: 0.1164074\n",
      "\tspeed: 0.0508s/iter; left time: 743.0256s\n",
      "\titers: 800, epoch: 4 | loss: 0.1089536\n",
      "\tspeed: 0.0508s/iter; left time: 738.1433s\n",
      "\titers: 900, epoch: 4 | loss: 0.1018279\n",
      "\tspeed: 0.0508s/iter; left time: 733.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 902 | Train Loss: 0.1170789 Vali Loss: 0.1380812 Test Loss: 0.1758089\n",
      "Validation loss decreased (0.155437 --> 0.138081).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0984079\n",
      "\tspeed: 0.1416s/iter; left time: 2029.5328s\n",
      "\titers: 200, epoch: 5 | loss: 0.1044581\n",
      "\tspeed: 0.0508s/iter; left time: 722.8784s\n",
      "\titers: 300, epoch: 5 | loss: 0.1054922\n",
      "\tspeed: 0.0508s/iter; left time: 717.7790s\n",
      "\titers: 400, epoch: 5 | loss: 0.1023428\n",
      "\tspeed: 0.0507s/iter; left time: 711.4377s\n",
      "\titers: 500, epoch: 5 | loss: 0.0925209\n",
      "\tspeed: 0.0507s/iter; left time: 706.7249s\n",
      "\titers: 600, epoch: 5 | loss: 0.1032169\n",
      "\tspeed: 0.0506s/iter; left time: 700.3312s\n",
      "\titers: 700, epoch: 5 | loss: 0.0928220\n",
      "\tspeed: 0.0507s/iter; left time: 696.7048s\n",
      "\titers: 800, epoch: 5 | loss: 0.0937007\n",
      "\tspeed: 0.0507s/iter; left time: 691.8461s\n",
      "\titers: 900, epoch: 5 | loss: 0.0924801\n",
      "\tspeed: 0.0508s/iter; left time: 687.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0993847 Vali Loss: 0.1335634 Test Loss: 0.1753410\n",
      "Validation loss decreased (0.138081 --> 0.133563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0887428\n",
      "\tspeed: 0.1454s/iter; left time: 1952.7363s\n",
      "\titers: 200, epoch: 6 | loss: 0.0971114\n",
      "\tspeed: 0.0520s/iter; left time: 692.8835s\n",
      "\titers: 300, epoch: 6 | loss: 0.0936855\n",
      "\tspeed: 0.0519s/iter; left time: 687.2491s\n",
      "\titers: 400, epoch: 6 | loss: 0.0994137\n",
      "\tspeed: 0.0518s/iter; left time: 680.3947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0940784\n",
      "\tspeed: 0.0512s/iter; left time: 666.7375s\n",
      "\titers: 600, epoch: 6 | loss: 0.0946007\n",
      "\tspeed: 0.0512s/iter; left time: 662.5407s\n",
      "\titers: 700, epoch: 6 | loss: 0.0885791\n",
      "\tspeed: 0.0515s/iter; left time: 660.2895s\n",
      "\titers: 800, epoch: 6 | loss: 0.0929599\n",
      "\tspeed: 0.0519s/iter; left time: 661.1869s\n",
      "\titers: 900, epoch: 6 | loss: 0.0841106\n",
      "\tspeed: 0.0519s/iter; left time: 655.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 902 | Train Loss: 0.0917087 Vali Loss: 0.1354960 Test Loss: 0.1834424\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0964288\n",
      "\tspeed: 0.1416s/iter; left time: 1773.7211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0859183\n",
      "\tspeed: 0.0512s/iter; left time: 636.0309s\n",
      "\titers: 300, epoch: 7 | loss: 0.0867437\n",
      "\tspeed: 0.0512s/iter; left time: 630.7155s\n",
      "\titers: 400, epoch: 7 | loss: 0.0866471\n",
      "\tspeed: 0.0512s/iter; left time: 625.6057s\n",
      "\titers: 500, epoch: 7 | loss: 0.0843690\n",
      "\tspeed: 0.0512s/iter; left time: 621.0936s\n",
      "\titers: 600, epoch: 7 | loss: 0.0867086\n",
      "\tspeed: 0.0511s/iter; left time: 615.2524s\n",
      "\titers: 700, epoch: 7 | loss: 0.0789776\n",
      "\tspeed: 0.0512s/iter; left time: 610.4739s\n",
      "\titers: 800, epoch: 7 | loss: 0.0838990\n",
      "\tspeed: 0.0513s/iter; left time: 606.5523s\n",
      "\titers: 900, epoch: 7 | loss: 0.0761397\n",
      "\tspeed: 0.0512s/iter; left time: 600.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 902 | Train Loss: 0.0856256 Vali Loss: 0.1398314 Test Loss: 0.1858543\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0796307\n",
      "\tspeed: 0.1429s/iter; left time: 1661.3558s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775476\n",
      "\tspeed: 0.0512s/iter; left time: 589.7926s\n",
      "\titers: 300, epoch: 8 | loss: 0.0838974\n",
      "\tspeed: 0.0522s/iter; left time: 596.2414s\n",
      "\titers: 400, epoch: 8 | loss: 0.0857031\n",
      "\tspeed: 0.0522s/iter; left time: 590.7387s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767407\n",
      "\tspeed: 0.0521s/iter; left time: 585.4244s\n",
      "\titers: 600, epoch: 8 | loss: 0.0837792\n",
      "\tspeed: 0.0519s/iter; left time: 577.5250s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778488\n",
      "\tspeed: 0.0513s/iter; left time: 565.8063s\n",
      "\titers: 800, epoch: 8 | loss: 0.0795030\n",
      "\tspeed: 0.0516s/iter; left time: 563.3232s\n",
      "\titers: 900, epoch: 8 | loss: 0.0821027\n",
      "\tspeed: 0.0516s/iter; left time: 558.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 902 | Train Loss: 0.0805042 Vali Loss: 0.1397548 Test Loss: 0.1822339\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0796983\n",
      "\tspeed: 0.1412s/iter; left time: 1514.5020s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759311\n",
      "\tspeed: 0.0512s/iter; left time: 544.0384s\n",
      "\titers: 300, epoch: 9 | loss: 0.0725377\n",
      "\tspeed: 0.0512s/iter; left time: 538.8407s\n",
      "\titers: 400, epoch: 9 | loss: 0.0776962\n",
      "\tspeed: 0.0512s/iter; left time: 533.6721s\n",
      "\titers: 500, epoch: 9 | loss: 0.0771654\n",
      "\tspeed: 0.0512s/iter; left time: 528.1837s\n",
      "\titers: 600, epoch: 9 | loss: 0.0781724\n",
      "\tspeed: 0.0511s/iter; left time: 522.8375s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747964\n",
      "\tspeed: 0.0512s/iter; left time: 518.1575s\n",
      "\titers: 800, epoch: 9 | loss: 0.0739248\n",
      "\tspeed: 0.0517s/iter; left time: 517.8308s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719263\n",
      "\tspeed: 0.0518s/iter; left time: 514.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.59s\n",
      "Steps: 902 | Train Loss: 0.0762764 Vali Loss: 0.1386382 Test Loss: 0.1837785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0757313\n",
      "\tspeed: 0.1425s/iter; left time: 1399.7111s\n",
      "\titers: 200, epoch: 10 | loss: 0.0703537\n",
      "\tspeed: 0.0512s/iter; left time: 497.8154s\n",
      "\titers: 300, epoch: 10 | loss: 0.0718045\n",
      "\tspeed: 0.0513s/iter; left time: 493.2416s\n",
      "\titers: 400, epoch: 10 | loss: 0.0759848\n",
      "\tspeed: 0.0512s/iter; left time: 487.4466s\n",
      "\titers: 500, epoch: 10 | loss: 0.0713861\n",
      "\tspeed: 0.0512s/iter; left time: 482.5811s\n",
      "\titers: 600, epoch: 10 | loss: 0.0714854\n",
      "\tspeed: 0.0512s/iter; left time: 477.5115s\n",
      "\titers: 700, epoch: 10 | loss: 0.0705916\n",
      "\tspeed: 0.0512s/iter; left time: 472.0964s\n",
      "\titers: 800, epoch: 10 | loss: 0.0715127\n",
      "\tspeed: 0.0511s/iter; left time: 466.4510s\n",
      "\titers: 900, epoch: 10 | loss: 0.0668258\n",
      "\tspeed: 0.0511s/iter; left time: 461.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.54s\n",
      "Steps: 902 | Train Loss: 0.0727178 Vali Loss: 0.1394037 Test Loss: 0.1799662\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06533545255661011, rmse:0.2556079924106598, mae:0.17534701526165009, rse:0.8861599564552307\n",
      "Intermediate time for GB and pred_len 168: 00h:17m:42.97s\n",
      "Intermediate time for GB: 00h:46m:50.95s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2269582\n",
      "\tspeed: 0.0550s/iter; left time: 992.0042s\n",
      "\titers: 200, epoch: 1 | loss: 0.2340235\n",
      "\tspeed: 0.0340s/iter; left time: 609.4055s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960561\n",
      "\tspeed: 0.0340s/iter; left time: 605.0591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1941898\n",
      "\tspeed: 0.0340s/iter; left time: 602.1440s\n",
      "\titers: 500, epoch: 1 | loss: 0.1761629\n",
      "\tspeed: 0.0340s/iter; left time: 598.6742s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717397\n",
      "\tspeed: 0.0340s/iter; left time: 595.3969s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656946\n",
      "\tspeed: 0.0340s/iter; left time: 592.7206s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516853\n",
      "\tspeed: 0.0341s/iter; left time: 590.1445s\n",
      "\titers: 900, epoch: 1 | loss: 0.1433492\n",
      "\tspeed: 0.0340s/iter; left time: 585.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.53s\n",
      "Steps: 906 | Train Loss: 0.1867150 Vali Loss: 0.1149514 Test Loss: 0.1356010\n",
      "Validation loss decreased (inf --> 0.114951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169975\n",
      "\tspeed: 0.0965s/iter; left time: 1651.4534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949514\n",
      "\tspeed: 0.0340s/iter; left time: 578.8318s\n",
      "\titers: 300, epoch: 2 | loss: 0.0899529\n",
      "\tspeed: 0.0340s/iter; left time: 575.2054s\n",
      "\titers: 400, epoch: 2 | loss: 0.0936027\n",
      "\tspeed: 0.0340s/iter; left time: 571.3918s\n",
      "\titers: 500, epoch: 2 | loss: 0.0845074\n",
      "\tspeed: 0.0340s/iter; left time: 569.1422s\n",
      "\titers: 600, epoch: 2 | loss: 0.0868874\n",
      "\tspeed: 0.0340s/iter; left time: 564.8397s\n",
      "\titers: 700, epoch: 2 | loss: 0.0824947\n",
      "\tspeed: 0.0341s/iter; left time: 562.8252s\n",
      "\titers: 800, epoch: 2 | loss: 0.0807727\n",
      "\tspeed: 0.0341s/iter; left time: 559.1457s\n",
      "\titers: 900, epoch: 2 | loss: 0.0765388\n",
      "\tspeed: 0.0341s/iter; left time: 556.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0929535 Vali Loss: 0.0793667 Test Loss: 0.1067031\n",
      "Validation loss decreased (0.114951 --> 0.079367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0782373\n",
      "\tspeed: 0.0961s/iter; left time: 1557.6559s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824538\n",
      "\tspeed: 0.0341s/iter; left time: 548.9010s\n",
      "\titers: 300, epoch: 3 | loss: 0.0756728\n",
      "\tspeed: 0.0341s/iter; left time: 545.3158s\n",
      "\titers: 400, epoch: 3 | loss: 0.0700887\n",
      "\tspeed: 0.0341s/iter; left time: 542.1123s\n",
      "\titers: 500, epoch: 3 | loss: 0.0729940\n",
      "\tspeed: 0.0340s/iter; left time: 538.0838s\n",
      "\titers: 600, epoch: 3 | loss: 0.0716531\n",
      "\tspeed: 0.0340s/iter; left time: 534.1571s\n",
      "\titers: 700, epoch: 3 | loss: 0.0698253\n",
      "\tspeed: 0.0340s/iter; left time: 530.2364s\n",
      "\titers: 800, epoch: 3 | loss: 0.0800202\n",
      "\tspeed: 0.0340s/iter; left time: 527.0752s\n",
      "\titers: 900, epoch: 3 | loss: 0.0685005\n",
      "\tspeed: 0.0340s/iter; left time: 523.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0724489 Vali Loss: 0.0711922 Test Loss: 0.0986497\n",
      "Validation loss decreased (0.079367 --> 0.071192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0684435\n",
      "\tspeed: 0.0961s/iter; left time: 1470.2668s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712164\n",
      "\tspeed: 0.0340s/iter; left time: 516.3544s\n",
      "\titers: 300, epoch: 4 | loss: 0.0667114\n",
      "\tspeed: 0.0340s/iter; left time: 513.2033s\n",
      "\titers: 400, epoch: 4 | loss: 0.0691570\n",
      "\tspeed: 0.0340s/iter; left time: 509.5055s\n",
      "\titers: 500, epoch: 4 | loss: 0.0596550\n",
      "\tspeed: 0.0340s/iter; left time: 506.2716s\n",
      "\titers: 600, epoch: 4 | loss: 0.0636415\n",
      "\tspeed: 0.0340s/iter; left time: 503.0966s\n",
      "\titers: 700, epoch: 4 | loss: 0.0748894\n",
      "\tspeed: 0.0340s/iter; left time: 499.3996s\n",
      "\titers: 800, epoch: 4 | loss: 0.0641811\n",
      "\tspeed: 0.0340s/iter; left time: 496.2536s\n",
      "\titers: 900, epoch: 4 | loss: 0.0688866\n",
      "\tspeed: 0.0340s/iter; left time: 493.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0664552 Vali Loss: 0.0674176 Test Loss: 0.0996465\n",
      "Validation loss decreased (0.071192 --> 0.067418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659110\n",
      "\tspeed: 0.0963s/iter; left time: 1386.2203s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593955\n",
      "\tspeed: 0.0340s/iter; left time: 486.4223s\n",
      "\titers: 300, epoch: 5 | loss: 0.0572287\n",
      "\tspeed: 0.0341s/iter; left time: 483.8240s\n",
      "\titers: 400, epoch: 5 | loss: 0.0633422\n",
      "\tspeed: 0.0341s/iter; left time: 480.0095s\n",
      "\titers: 500, epoch: 5 | loss: 0.0599107\n",
      "\tspeed: 0.0340s/iter; left time: 476.1896s\n",
      "\titers: 600, epoch: 5 | loss: 0.0616285\n",
      "\tspeed: 0.0340s/iter; left time: 472.5554s\n",
      "\titers: 700, epoch: 5 | loss: 0.0670126\n",
      "\tspeed: 0.0341s/iter; left time: 469.9486s\n",
      "\titers: 800, epoch: 5 | loss: 0.0574715\n",
      "\tspeed: 0.0340s/iter; left time: 465.9960s\n",
      "\titers: 900, epoch: 5 | loss: 0.0618266\n",
      "\tspeed: 0.0341s/iter; left time: 463.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0625747 Vali Loss: 0.0616929 Test Loss: 0.0898060\n",
      "Validation loss decreased (0.067418 --> 0.061693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630031\n",
      "\tspeed: 0.0964s/iter; left time: 1300.5169s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529410\n",
      "\tspeed: 0.0341s/iter; left time: 456.7115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0593784\n",
      "\tspeed: 0.0341s/iter; left time: 452.8869s\n",
      "\titers: 400, epoch: 6 | loss: 0.0604928\n",
      "\tspeed: 0.0341s/iter; left time: 449.6964s\n",
      "\titers: 500, epoch: 6 | loss: 0.0600843\n",
      "\tspeed: 0.0341s/iter; left time: 445.9873s\n",
      "\titers: 600, epoch: 6 | loss: 0.0581049\n",
      "\tspeed: 0.0340s/iter; left time: 442.1294s\n",
      "\titers: 700, epoch: 6 | loss: 0.0540081\n",
      "\tspeed: 0.0340s/iter; left time: 438.9322s\n",
      "\titers: 800, epoch: 6 | loss: 0.0625412\n",
      "\tspeed: 0.0341s/iter; left time: 436.3913s\n",
      "\titers: 900, epoch: 6 | loss: 0.0629828\n",
      "\tspeed: 0.0340s/iter; left time: 432.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0593687 Vali Loss: 0.0626056 Test Loss: 0.0942342\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566213\n",
      "\tspeed: 0.0931s/iter; left time: 1171.3166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0615168\n",
      "\tspeed: 0.0341s/iter; left time: 425.2691s\n",
      "\titers: 300, epoch: 7 | loss: 0.0562484\n",
      "\tspeed: 0.0340s/iter; left time: 421.6475s\n",
      "\titers: 400, epoch: 7 | loss: 0.0569425\n",
      "\tspeed: 0.0340s/iter; left time: 417.6220s\n",
      "\titers: 500, epoch: 7 | loss: 0.0591812\n",
      "\tspeed: 0.0340s/iter; left time: 414.2646s\n",
      "\titers: 600, epoch: 7 | loss: 0.0496640\n",
      "\tspeed: 0.0340s/iter; left time: 410.5183s\n",
      "\titers: 700, epoch: 7 | loss: 0.0547029\n",
      "\tspeed: 0.0341s/iter; left time: 408.5837s\n",
      "\titers: 800, epoch: 7 | loss: 0.0546945\n",
      "\tspeed: 0.0341s/iter; left time: 404.6913s\n",
      "\titers: 900, epoch: 7 | loss: 0.0594512\n",
      "\tspeed: 0.0340s/iter; left time: 400.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0569890 Vali Loss: 0.0593294 Test Loss: 0.0925540\n",
      "Validation loss decreased (0.061693 --> 0.059329).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0525238\n",
      "\tspeed: 0.0961s/iter; left time: 1122.0307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0508008\n",
      "\tspeed: 0.0341s/iter; left time: 395.2702s\n",
      "\titers: 300, epoch: 8 | loss: 0.0481101\n",
      "\tspeed: 0.0341s/iter; left time: 391.3141s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521681\n",
      "\tspeed: 0.0340s/iter; left time: 387.3520s\n",
      "\titers: 500, epoch: 8 | loss: 0.0577647\n",
      "\tspeed: 0.0341s/iter; left time: 384.1358s\n",
      "\titers: 600, epoch: 8 | loss: 0.0543726\n",
      "\tspeed: 0.0341s/iter; left time: 380.7608s\n",
      "\titers: 700, epoch: 8 | loss: 0.0620679\n",
      "\tspeed: 0.0340s/iter; left time: 377.0847s\n",
      "\titers: 800, epoch: 8 | loss: 0.0583911\n",
      "\tspeed: 0.0341s/iter; left time: 374.1237s\n",
      "\titers: 900, epoch: 8 | loss: 0.0578499\n",
      "\tspeed: 0.0341s/iter; left time: 371.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0550839 Vali Loss: 0.0594405 Test Loss: 0.0994523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0505213\n",
      "\tspeed: 0.0943s/iter; left time: 1016.4260s\n",
      "\titers: 200, epoch: 9 | loss: 0.0526453\n",
      "\tspeed: 0.0341s/iter; left time: 363.7700s\n",
      "\titers: 300, epoch: 9 | loss: 0.0561748\n",
      "\tspeed: 0.0340s/iter; left time: 359.7932s\n",
      "\titers: 400, epoch: 9 | loss: 0.0582262\n",
      "\tspeed: 0.0340s/iter; left time: 356.2626s\n",
      "\titers: 500, epoch: 9 | loss: 0.0561789\n",
      "\tspeed: 0.0340s/iter; left time: 353.0543s\n",
      "\titers: 600, epoch: 9 | loss: 0.0563085\n",
      "\tspeed: 0.0340s/iter; left time: 349.3051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0522479\n",
      "\tspeed: 0.0340s/iter; left time: 345.8892s\n",
      "\titers: 800, epoch: 9 | loss: 0.0538578\n",
      "\tspeed: 0.0341s/iter; left time: 343.1276s\n",
      "\titers: 900, epoch: 9 | loss: 0.0456325\n",
      "\tspeed: 0.0341s/iter; left time: 339.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0536204 Vali Loss: 0.0587028 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.059329 --> 0.058703).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546516\n",
      "\tspeed: 0.0962s/iter; left time: 949.1378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576164\n",
      "\tspeed: 0.0341s/iter; left time: 332.6549s\n",
      "\titers: 300, epoch: 10 | loss: 0.0522396\n",
      "\tspeed: 0.0341s/iter; left time: 329.2737s\n",
      "\titers: 400, epoch: 10 | loss: 0.0645304\n",
      "\tspeed: 0.0341s/iter; left time: 326.1944s\n",
      "\titers: 500, epoch: 10 | loss: 0.0542212\n",
      "\tspeed: 0.0341s/iter; left time: 322.6437s\n",
      "\titers: 600, epoch: 10 | loss: 0.0521068\n",
      "\tspeed: 0.0341s/iter; left time: 319.2733s\n",
      "\titers: 700, epoch: 10 | loss: 0.0592318\n",
      "\tspeed: 0.0341s/iter; left time: 315.9926s\n",
      "\titers: 800, epoch: 10 | loss: 0.0469309\n",
      "\tspeed: 0.0341s/iter; left time: 312.1414s\n",
      "\titers: 900, epoch: 10 | loss: 0.0504858\n",
      "\tspeed: 0.0341s/iter; left time: 309.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0521291 Vali Loss: 0.0587004 Test Loss: 0.0948160\n",
      "Validation loss decreased (0.058703 --> 0.058700).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0521655\n",
      "\tspeed: 0.0968s/iter; left time: 867.6632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465787\n",
      "\tspeed: 0.0340s/iter; left time: 301.1818s\n",
      "\titers: 300, epoch: 11 | loss: 0.0509172\n",
      "\tspeed: 0.0340s/iter; left time: 297.5199s\n",
      "\titers: 400, epoch: 11 | loss: 0.0459693\n",
      "\tspeed: 0.0340s/iter; left time: 294.1597s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552192\n",
      "\tspeed: 0.0340s/iter; left time: 290.9819s\n",
      "\titers: 600, epoch: 11 | loss: 0.0559179\n",
      "\tspeed: 0.0340s/iter; left time: 287.9101s\n",
      "\titers: 700, epoch: 11 | loss: 0.0514091\n",
      "\tspeed: 0.0340s/iter; left time: 284.3034s\n",
      "\titers: 800, epoch: 11 | loss: 0.0528125\n",
      "\tspeed: 0.0340s/iter; left time: 281.0131s\n",
      "\titers: 900, epoch: 11 | loss: 0.0530001\n",
      "\tspeed: 0.0341s/iter; left time: 278.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0510566 Vali Loss: 0.0590035 Test Loss: 0.0986896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558984\n",
      "\tspeed: 0.0930s/iter; left time: 748.7564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513471\n",
      "\tspeed: 0.0340s/iter; left time: 270.8496s\n",
      "\titers: 300, epoch: 12 | loss: 0.0471879\n",
      "\tspeed: 0.0340s/iter; left time: 267.1381s\n",
      "\titers: 400, epoch: 12 | loss: 0.0593381\n",
      "\tspeed: 0.0341s/iter; left time: 264.3435s\n",
      "\titers: 500, epoch: 12 | loss: 0.0527025\n",
      "\tspeed: 0.0340s/iter; left time: 260.3050s\n",
      "\titers: 600, epoch: 12 | loss: 0.0466901\n",
      "\tspeed: 0.0340s/iter; left time: 257.1148s\n",
      "\titers: 700, epoch: 12 | loss: 0.0478527\n",
      "\tspeed: 0.0341s/iter; left time: 254.0793s\n",
      "\titers: 800, epoch: 12 | loss: 0.0519875\n",
      "\tspeed: 0.0340s/iter; left time: 250.2279s\n",
      "\titers: 900, epoch: 12 | loss: 0.0480679\n",
      "\tspeed: 0.0341s/iter; left time: 247.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0497550 Vali Loss: 0.0586147 Test Loss: 0.0984036\n",
      "Validation loss decreased (0.058700 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0475071\n",
      "\tspeed: 0.0975s/iter; left time: 697.0758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0483188\n",
      "\tspeed: 0.0340s/iter; left time: 239.9376s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545818\n",
      "\tspeed: 0.0340s/iter; left time: 236.5292s\n",
      "\titers: 400, epoch: 13 | loss: 0.0468574\n",
      "\tspeed: 0.0341s/iter; left time: 233.2553s\n",
      "\titers: 500, epoch: 13 | loss: 0.0488363\n",
      "\tspeed: 0.0341s/iter; left time: 230.0322s\n",
      "\titers: 600, epoch: 13 | loss: 0.0478834\n",
      "\tspeed: 0.0341s/iter; left time: 226.4960s\n",
      "\titers: 700, epoch: 13 | loss: 0.0478704\n",
      "\tspeed: 0.0341s/iter; left time: 223.1881s\n",
      "\titers: 800, epoch: 13 | loss: 0.0492090\n",
      "\tspeed: 0.0341s/iter; left time: 219.5957s\n",
      "\titers: 900, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.0341s/iter; left time: 216.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0488156 Vali Loss: 0.0577360 Test Loss: 0.0999878\n",
      "Validation loss decreased (0.058615 --> 0.057736).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0482094\n",
      "\tspeed: 0.0963s/iter; left time: 600.9922s\n",
      "\titers: 200, epoch: 14 | loss: 0.0487748\n",
      "\tspeed: 0.0340s/iter; left time: 209.1014s\n",
      "\titers: 300, epoch: 14 | loss: 0.0462699\n",
      "\tspeed: 0.0340s/iter; left time: 205.6403s\n",
      "\titers: 400, epoch: 14 | loss: 0.0482816\n",
      "\tspeed: 0.0340s/iter; left time: 202.0444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0434202\n",
      "\tspeed: 0.0340s/iter; left time: 198.6776s\n",
      "\titers: 600, epoch: 14 | loss: 0.0466136\n",
      "\tspeed: 0.0340s/iter; left time: 195.1986s\n",
      "\titers: 700, epoch: 14 | loss: 0.0498906\n",
      "\tspeed: 0.0340s/iter; left time: 191.8812s\n",
      "\titers: 800, epoch: 14 | loss: 0.0559277\n",
      "\tspeed: 0.0340s/iter; left time: 188.5343s\n",
      "\titers: 900, epoch: 14 | loss: 0.0500410\n",
      "\tspeed: 0.0340s/iter; left time: 185.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0481153 Vali Loss: 0.0569008 Test Loss: 0.0974887\n",
      "Validation loss decreased (0.057736 --> 0.056901).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0479455\n",
      "\tspeed: 0.0969s/iter; left time: 516.9925s\n",
      "\titers: 200, epoch: 15 | loss: 0.0423490\n",
      "\tspeed: 0.0340s/iter; left time: 178.2323s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470223\n",
      "\tspeed: 0.0340s/iter; left time: 174.7335s\n",
      "\titers: 400, epoch: 15 | loss: 0.0487020\n",
      "\tspeed: 0.0339s/iter; left time: 170.9948s\n",
      "\titers: 500, epoch: 15 | loss: 0.0482308\n",
      "\tspeed: 0.0341s/iter; left time: 168.3506s\n",
      "\titers: 600, epoch: 15 | loss: 0.0490022\n",
      "\tspeed: 0.0340s/iter; left time: 164.6517s\n",
      "\titers: 700, epoch: 15 | loss: 0.0457250\n",
      "\tspeed: 0.0341s/iter; left time: 161.4815s\n",
      "\titers: 800, epoch: 15 | loss: 0.0414258\n",
      "\tspeed: 0.0341s/iter; left time: 158.1757s\n",
      "\titers: 900, epoch: 15 | loss: 0.0480889\n",
      "\tspeed: 0.0341s/iter; left time: 154.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0471749 Vali Loss: 0.0581755 Test Loss: 0.1011218\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0504668\n",
      "\tspeed: 0.0941s/iter; left time: 417.0276s\n",
      "\titers: 200, epoch: 16 | loss: 0.0505805\n",
      "\tspeed: 0.0341s/iter; left time: 147.6880s\n",
      "\titers: 300, epoch: 16 | loss: 0.0436730\n",
      "\tspeed: 0.0341s/iter; left time: 144.1782s\n",
      "\titers: 400, epoch: 16 | loss: 0.0441560\n",
      "\tspeed: 0.0341s/iter; left time: 140.7082s\n",
      "\titers: 500, epoch: 16 | loss: 0.0476777\n",
      "\tspeed: 0.0340s/iter; left time: 137.1863s\n",
      "\titers: 600, epoch: 16 | loss: 0.0439132\n",
      "\tspeed: 0.0340s/iter; left time: 133.7169s\n",
      "\titers: 700, epoch: 16 | loss: 0.0488481\n",
      "\tspeed: 0.0341s/iter; left time: 130.6403s\n",
      "\titers: 800, epoch: 16 | loss: 0.0411422\n",
      "\tspeed: 0.0341s/iter; left time: 127.0459s\n",
      "\titers: 900, epoch: 16 | loss: 0.0461350\n",
      "\tspeed: 0.0341s/iter; left time: 123.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0463692 Vali Loss: 0.0586193 Test Loss: 0.1046662\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0439602\n",
      "\tspeed: 0.0929s/iter; left time: 327.3871s\n",
      "\titers: 200, epoch: 17 | loss: 0.0481706\n",
      "\tspeed: 0.0340s/iter; left time: 116.5163s\n",
      "\titers: 300, epoch: 17 | loss: 0.0420253\n",
      "\tspeed: 0.0340s/iter; left time: 112.9836s\n",
      "\titers: 400, epoch: 17 | loss: 0.0496195\n",
      "\tspeed: 0.0340s/iter; left time: 109.5946s\n",
      "\titers: 500, epoch: 17 | loss: 0.0452397\n",
      "\tspeed: 0.0340s/iter; left time: 106.2796s\n",
      "\titers: 600, epoch: 17 | loss: 0.0468022\n",
      "\tspeed: 0.0340s/iter; left time: 102.8425s\n",
      "\titers: 700, epoch: 17 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 99.4661s\n",
      "\titers: 800, epoch: 17 | loss: 0.0520706\n",
      "\tspeed: 0.0341s/iter; left time: 96.2139s\n",
      "\titers: 900, epoch: 17 | loss: 0.0444759\n",
      "\tspeed: 0.0340s/iter; left time: 92.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0455342 Vali Loss: 0.0581641 Test Loss: 0.1017385\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0446145\n",
      "\tspeed: 0.0929s/iter; left time: 243.4311s\n",
      "\titers: 200, epoch: 18 | loss: 0.0440156\n",
      "\tspeed: 0.0340s/iter; left time: 85.6971s\n",
      "\titers: 300, epoch: 18 | loss: 0.0425779\n",
      "\tspeed: 0.0340s/iter; left time: 82.2397s\n",
      "\titers: 400, epoch: 18 | loss: 0.0449517\n",
      "\tspeed: 0.0340s/iter; left time: 78.9489s\n",
      "\titers: 500, epoch: 18 | loss: 0.0484834\n",
      "\tspeed: 0.0340s/iter; left time: 75.5547s\n",
      "\titers: 600, epoch: 18 | loss: 0.0420635\n",
      "\tspeed: 0.0340s/iter; left time: 72.1029s\n",
      "\titers: 700, epoch: 18 | loss: 0.0470141\n",
      "\tspeed: 0.0340s/iter; left time: 68.6295s\n",
      "\titers: 800, epoch: 18 | loss: 0.0419604\n",
      "\tspeed: 0.0341s/iter; left time: 65.3850s\n",
      "\titers: 900, epoch: 18 | loss: 0.0463720\n",
      "\tspeed: 0.0340s/iter; left time: 61.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0450904 Vali Loss: 0.0583875 Test Loss: 0.1041857\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0424898\n",
      "\tspeed: 0.0931s/iter; left time: 159.4494s\n",
      "\titers: 200, epoch: 19 | loss: 0.0434248\n",
      "\tspeed: 0.0340s/iter; left time: 54.8737s\n",
      "\titers: 300, epoch: 19 | loss: 0.0410817\n",
      "\tspeed: 0.0340s/iter; left time: 51.4603s\n",
      "\titers: 400, epoch: 19 | loss: 0.0418899\n",
      "\tspeed: 0.0340s/iter; left time: 48.0451s\n",
      "\titers: 500, epoch: 19 | loss: 0.0446364\n",
      "\tspeed: 0.0341s/iter; left time: 44.7165s\n",
      "\titers: 600, epoch: 19 | loss: 0.0444938\n",
      "\tspeed: 0.0340s/iter; left time: 41.2340s\n",
      "\titers: 700, epoch: 19 | loss: 0.0418383\n",
      "\tspeed: 0.0341s/iter; left time: 37.9425s\n",
      "\titers: 800, epoch: 19 | loss: 0.0464259\n",
      "\tspeed: 0.0340s/iter; left time: 34.4403s\n",
      "\titers: 900, epoch: 19 | loss: 0.0461343\n",
      "\tspeed: 0.0340s/iter; left time: 31.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0444866 Vali Loss: 0.0587221 Test Loss: 0.1070130\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027461538091301918, rmse:0.16571523249149323, mae:0.09743039309978485, rse:0.4869214594364166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2149062\n",
      "\tspeed: 0.0359s/iter; left time: 647.8177s\n",
      "\titers: 200, epoch: 1 | loss: 0.2208412\n",
      "\tspeed: 0.0340s/iter; left time: 609.6411s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960506\n",
      "\tspeed: 0.0341s/iter; left time: 607.1201s\n",
      "\titers: 400, epoch: 1 | loss: 0.1785244\n",
      "\tspeed: 0.0341s/iter; left time: 604.3089s\n",
      "\titers: 500, epoch: 1 | loss: 0.1606690\n",
      "\tspeed: 0.0341s/iter; left time: 601.1981s\n",
      "\titers: 600, epoch: 1 | loss: 0.1587723\n",
      "\tspeed: 0.0341s/iter; left time: 597.8329s\n",
      "\titers: 700, epoch: 1 | loss: 0.1492396\n",
      "\tspeed: 0.0341s/iter; left time: 593.4278s\n",
      "\titers: 800, epoch: 1 | loss: 0.1445469\n",
      "\tspeed: 0.0341s/iter; left time: 590.6606s\n",
      "\titers: 900, epoch: 1 | loss: 0.1369113\n",
      "\tspeed: 0.0341s/iter; left time: 587.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.1828038 Vali Loss: 0.1089664 Test Loss: 0.1298395\n",
      "Validation loss decreased (inf --> 0.108966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1135225\n",
      "\tspeed: 0.0967s/iter; left time: 1655.7642s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148164\n",
      "\tspeed: 0.0341s/iter; left time: 579.4230s\n",
      "\titers: 300, epoch: 2 | loss: 0.0936463\n",
      "\tspeed: 0.0340s/iter; left time: 575.6874s\n",
      "\titers: 400, epoch: 2 | loss: 0.0820305\n",
      "\tspeed: 0.0340s/iter; left time: 571.7097s\n",
      "\titers: 500, epoch: 2 | loss: 0.0843619\n",
      "\tspeed: 0.0340s/iter; left time: 568.8378s\n",
      "\titers: 600, epoch: 2 | loss: 0.0846980\n",
      "\tspeed: 0.0341s/iter; left time: 565.9215s\n",
      "\titers: 700, epoch: 2 | loss: 0.0829176\n",
      "\tspeed: 0.0341s/iter; left time: 562.3783s\n",
      "\titers: 800, epoch: 2 | loss: 0.0821716\n",
      "\tspeed: 0.0341s/iter; left time: 559.9984s\n",
      "\titers: 900, epoch: 2 | loss: 0.0759475\n",
      "\tspeed: 0.0341s/iter; left time: 555.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0933928 Vali Loss: 0.0766692 Test Loss: 0.1036709\n",
      "Validation loss decreased (0.108966 --> 0.076669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689353\n",
      "\tspeed: 0.0964s/iter; left time: 1562.7546s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678947\n",
      "\tspeed: 0.0341s/iter; left time: 548.5724s\n",
      "\titers: 300, epoch: 3 | loss: 0.0727085\n",
      "\tspeed: 0.0340s/iter; left time: 544.8113s\n",
      "\titers: 400, epoch: 3 | loss: 0.0748758\n",
      "\tspeed: 0.0341s/iter; left time: 542.3137s\n",
      "\titers: 500, epoch: 3 | loss: 0.0773622\n",
      "\tspeed: 0.0341s/iter; left time: 538.4005s\n",
      "\titers: 600, epoch: 3 | loss: 0.0685271\n",
      "\tspeed: 0.0341s/iter; left time: 535.4238s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751804\n",
      "\tspeed: 0.0341s/iter; left time: 532.3713s\n",
      "\titers: 800, epoch: 3 | loss: 0.0565176\n",
      "\tspeed: 0.0341s/iter; left time: 528.6195s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646926\n",
      "\tspeed: 0.0341s/iter; left time: 524.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0711776 Vali Loss: 0.0796852 Test Loss: 0.1065500\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657408\n",
      "\tspeed: 0.0928s/iter; left time: 1419.9932s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647836\n",
      "\tspeed: 0.0341s/iter; left time: 518.5229s\n",
      "\titers: 300, epoch: 4 | loss: 0.0649817\n",
      "\tspeed: 0.0341s/iter; left time: 514.9193s\n",
      "\titers: 400, epoch: 4 | loss: 0.0786881\n",
      "\tspeed: 0.0341s/iter; left time: 512.0881s\n",
      "\titers: 500, epoch: 4 | loss: 0.0712274\n",
      "\tspeed: 0.0341s/iter; left time: 507.5204s\n",
      "\titers: 600, epoch: 4 | loss: 0.0682974\n",
      "\tspeed: 0.0342s/iter; left time: 505.6659s\n",
      "\titers: 700, epoch: 4 | loss: 0.0697354\n",
      "\tspeed: 0.0342s/iter; left time: 502.1557s\n",
      "\titers: 800, epoch: 4 | loss: 0.0585399\n",
      "\tspeed: 0.0341s/iter; left time: 498.6690s\n",
      "\titers: 900, epoch: 4 | loss: 0.0596235\n",
      "\tspeed: 0.0341s/iter; left time: 494.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0653138 Vali Loss: 0.0680534 Test Loss: 0.0976341\n",
      "Validation loss decreased (0.076669 --> 0.068053).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0725577\n",
      "\tspeed: 0.0963s/iter; left time: 1386.6411s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573841\n",
      "\tspeed: 0.0340s/iter; left time: 486.6671s\n",
      "\titers: 300, epoch: 5 | loss: 0.0539423\n",
      "\tspeed: 0.0341s/iter; left time: 483.5814s\n",
      "\titers: 400, epoch: 5 | loss: 0.0593723\n",
      "\tspeed: 0.0341s/iter; left time: 480.2758s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631876\n",
      "\tspeed: 0.0340s/iter; left time: 476.5368s\n",
      "\titers: 600, epoch: 5 | loss: 0.0533562\n",
      "\tspeed: 0.0341s/iter; left time: 473.4310s\n",
      "\titers: 700, epoch: 5 | loss: 0.0583013\n",
      "\tspeed: 0.0341s/iter; left time: 470.4378s\n",
      "\titers: 800, epoch: 5 | loss: 0.0527938\n",
      "\tspeed: 0.0340s/iter; left time: 466.2385s\n",
      "\titers: 900, epoch: 5 | loss: 0.0549873\n",
      "\tspeed: 0.0341s/iter; left time: 463.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0610250 Vali Loss: 0.0610558 Test Loss: 0.0921888\n",
      "Validation loss decreased (0.068053 --> 0.061056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0580953\n",
      "\tspeed: 0.0960s/iter; left time: 1295.5002s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602082\n",
      "\tspeed: 0.0340s/iter; left time: 455.9594s\n",
      "\titers: 300, epoch: 6 | loss: 0.0604460\n",
      "\tspeed: 0.0340s/iter; left time: 452.2778s\n",
      "\titers: 400, epoch: 6 | loss: 0.0563742\n",
      "\tspeed: 0.0341s/iter; left time: 449.4301s\n",
      "\titers: 500, epoch: 6 | loss: 0.0530320\n",
      "\tspeed: 0.0341s/iter; left time: 445.9065s\n",
      "\titers: 600, epoch: 6 | loss: 0.0533875\n",
      "\tspeed: 0.0340s/iter; left time: 441.9325s\n",
      "\titers: 700, epoch: 6 | loss: 0.0524571\n",
      "\tspeed: 0.0340s/iter; left time: 438.9373s\n",
      "\titers: 800, epoch: 6 | loss: 0.0500506\n",
      "\tspeed: 0.0340s/iter; left time: 435.2579s\n",
      "\titers: 900, epoch: 6 | loss: 0.0613379\n",
      "\tspeed: 0.0340s/iter; left time: 432.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0579149 Vali Loss: 0.0589280 Test Loss: 0.0870637\n",
      "Validation loss decreased (0.061056 --> 0.058928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542730\n",
      "\tspeed: 0.0957s/iter; left time: 1203.9772s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584979\n",
      "\tspeed: 0.0341s/iter; left time: 425.1150s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552041\n",
      "\tspeed: 0.0341s/iter; left time: 421.9635s\n",
      "\titers: 400, epoch: 7 | loss: 0.0513719\n",
      "\tspeed: 0.0340s/iter; left time: 418.0528s\n",
      "\titers: 500, epoch: 7 | loss: 0.0545608\n",
      "\tspeed: 0.0341s/iter; left time: 415.9115s\n",
      "\titers: 600, epoch: 7 | loss: 0.0571133\n",
      "\tspeed: 0.0341s/iter; left time: 411.7257s\n",
      "\titers: 700, epoch: 7 | loss: 0.0540548\n",
      "\tspeed: 0.0341s/iter; left time: 408.3959s\n",
      "\titers: 800, epoch: 7 | loss: 0.0513388\n",
      "\tspeed: 0.0341s/iter; left time: 405.2208s\n",
      "\titers: 900, epoch: 7 | loss: 0.0515127\n",
      "\tspeed: 0.0341s/iter; left time: 401.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0555515 Vali Loss: 0.0638483 Test Loss: 0.0944871\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0527631\n",
      "\tspeed: 0.0929s/iter; left time: 1085.3560s\n",
      "\titers: 200, epoch: 8 | loss: 0.0519219\n",
      "\tspeed: 0.0341s/iter; left time: 394.8668s\n",
      "\titers: 300, epoch: 8 | loss: 0.0529470\n",
      "\tspeed: 0.0341s/iter; left time: 391.2811s\n",
      "\titers: 400, epoch: 8 | loss: 0.0566683\n",
      "\tspeed: 0.0341s/iter; left time: 387.8255s\n",
      "\titers: 500, epoch: 8 | loss: 0.0511631\n",
      "\tspeed: 0.0341s/iter; left time: 384.8334s\n",
      "\titers: 600, epoch: 8 | loss: 0.0515833\n",
      "\tspeed: 0.0341s/iter; left time: 381.1682s\n",
      "\titers: 700, epoch: 8 | loss: 0.0480705\n",
      "\tspeed: 0.0341s/iter; left time: 377.5911s\n",
      "\titers: 800, epoch: 8 | loss: 0.0580791\n",
      "\tspeed: 0.0340s/iter; left time: 373.7311s\n",
      "\titers: 900, epoch: 8 | loss: 0.0615418\n",
      "\tspeed: 0.0341s/iter; left time: 370.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0541977 Vali Loss: 0.0600997 Test Loss: 0.0928956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0542574\n",
      "\tspeed: 0.0933s/iter; left time: 1004.7664s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516183\n",
      "\tspeed: 0.0340s/iter; left time: 363.3126s\n",
      "\titers: 300, epoch: 9 | loss: 0.0530071\n",
      "\tspeed: 0.0340s/iter; left time: 359.3725s\n",
      "\titers: 400, epoch: 9 | loss: 0.0483792\n",
      "\tspeed: 0.0340s/iter; left time: 356.3748s\n",
      "\titers: 500, epoch: 9 | loss: 0.0543778\n",
      "\tspeed: 0.0340s/iter; left time: 353.1151s\n",
      "\titers: 600, epoch: 9 | loss: 0.0531961\n",
      "\tspeed: 0.0340s/iter; left time: 349.6051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0557334\n",
      "\tspeed: 0.0340s/iter; left time: 346.2001s\n",
      "\titers: 800, epoch: 9 | loss: 0.0548735\n",
      "\tspeed: 0.0340s/iter; left time: 342.9241s\n",
      "\titers: 900, epoch: 9 | loss: 0.0554635\n",
      "\tspeed: 0.0340s/iter; left time: 339.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0527868 Vali Loss: 0.0606648 Test Loss: 0.0891905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564716\n",
      "\tspeed: 0.0931s/iter; left time: 918.4250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536913\n",
      "\tspeed: 0.0340s/iter; left time: 332.3861s\n",
      "\titers: 300, epoch: 10 | loss: 0.0534131\n",
      "\tspeed: 0.0341s/iter; left time: 329.2227s\n",
      "\titers: 400, epoch: 10 | loss: 0.0569648\n",
      "\tspeed: 0.0340s/iter; left time: 325.5396s\n",
      "\titers: 500, epoch: 10 | loss: 0.0553950\n",
      "\tspeed: 0.0340s/iter; left time: 322.3328s\n",
      "\titers: 600, epoch: 10 | loss: 0.0504877\n",
      "\tspeed: 0.0341s/iter; left time: 319.2523s\n",
      "\titers: 700, epoch: 10 | loss: 0.0442066\n",
      "\tspeed: 0.0341s/iter; left time: 315.9050s\n",
      "\titers: 800, epoch: 10 | loss: 0.0492407\n",
      "\tspeed: 0.0341s/iter; left time: 312.2782s\n",
      "\titers: 900, epoch: 10 | loss: 0.0494081\n",
      "\tspeed: 0.0341s/iter; left time: 308.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0516848 Vali Loss: 0.0591269 Test Loss: 0.0909714\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0543662\n",
      "\tspeed: 0.0930s/iter; left time: 833.5490s\n",
      "\titers: 200, epoch: 11 | loss: 0.0554431\n",
      "\tspeed: 0.0340s/iter; left time: 301.3541s\n",
      "\titers: 300, epoch: 11 | loss: 0.0557188\n",
      "\tspeed: 0.0341s/iter; left time: 298.3951s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493816\n",
      "\tspeed: 0.0340s/iter; left time: 294.7068s\n",
      "\titers: 500, epoch: 11 | loss: 0.0470877\n",
      "\tspeed: 0.0341s/iter; left time: 291.9255s\n",
      "\titers: 600, epoch: 11 | loss: 0.0478654\n",
      "\tspeed: 0.0341s/iter; left time: 288.4091s\n",
      "\titers: 700, epoch: 11 | loss: 0.0479112\n",
      "\tspeed: 0.0341s/iter; left time: 284.7780s\n",
      "\titers: 800, epoch: 11 | loss: 0.0557325\n",
      "\tspeed: 0.0341s/iter; left time: 281.5655s\n",
      "\titers: 900, epoch: 11 | loss: 0.0540772\n",
      "\tspeed: 0.0341s/iter; left time: 277.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0503803 Vali Loss: 0.0596729 Test Loss: 0.0918079\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019272608682513237, rmse:0.13882581889629364, mae:0.08702108263969421, rse:0.4079122245311737\n",
      "Intermediate time for ES and pred_len 24: 00h:18m:37.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2373950\n",
      "\tspeed: 0.0630s/iter; left time: 1132.0348s\n",
      "\titers: 200, epoch: 1 | loss: 0.2127535\n",
      "\tspeed: 0.0421s/iter; left time: 753.0910s\n",
      "\titers: 300, epoch: 1 | loss: 0.2200992\n",
      "\tspeed: 0.0421s/iter; left time: 748.5457s\n",
      "\titers: 400, epoch: 1 | loss: 0.2059206\n",
      "\tspeed: 0.0421s/iter; left time: 744.3850s\n",
      "\titers: 500, epoch: 1 | loss: 0.1971000\n",
      "\tspeed: 0.0421s/iter; left time: 740.1027s\n",
      "\titers: 600, epoch: 1 | loss: 0.1864508\n",
      "\tspeed: 0.0421s/iter; left time: 736.0255s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921179\n",
      "\tspeed: 0.0422s/iter; left time: 733.0808s\n",
      "\titers: 800, epoch: 1 | loss: 0.1733235\n",
      "\tspeed: 0.0421s/iter; left time: 727.6188s\n",
      "\titers: 900, epoch: 1 | loss: 0.1764061\n",
      "\tspeed: 0.0425s/iter; left time: 730.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 904 | Train Loss: 0.2055957 Vali Loss: 0.1704240 Test Loss: 0.2081109\n",
      "Validation loss decreased (inf --> 0.170424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474789\n",
      "\tspeed: 0.1169s/iter; left time: 1995.5735s\n",
      "\titers: 200, epoch: 2 | loss: 0.1373694\n",
      "\tspeed: 0.0420s/iter; left time: 713.7136s\n",
      "\titers: 300, epoch: 2 | loss: 0.1301654\n",
      "\tspeed: 0.0421s/iter; left time: 710.1622s\n",
      "\titers: 400, epoch: 2 | loss: 0.1124775\n",
      "\tspeed: 0.0421s/iter; left time: 706.2904s\n",
      "\titers: 500, epoch: 2 | loss: 0.1012060\n",
      "\tspeed: 0.0421s/iter; left time: 701.8246s\n",
      "\titers: 600, epoch: 2 | loss: 0.1080255\n",
      "\tspeed: 0.0421s/iter; left time: 698.2995s\n",
      "\titers: 700, epoch: 2 | loss: 0.0986939\n",
      "\tspeed: 0.0421s/iter; left time: 693.9462s\n",
      "\titers: 800, epoch: 2 | loss: 0.0948638\n",
      "\tspeed: 0.0421s/iter; left time: 689.3840s\n",
      "\titers: 900, epoch: 2 | loss: 0.0981427\n",
      "\tspeed: 0.0421s/iter; left time: 684.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 904 | Train Loss: 0.1190556 Vali Loss: 0.0968713 Test Loss: 0.1262738\n",
      "Validation loss decreased (0.170424 --> 0.096871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954394\n",
      "\tspeed: 0.1166s/iter; left time: 1886.4918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901963\n",
      "\tspeed: 0.0421s/iter; left time: 676.3143s\n",
      "\titers: 300, epoch: 3 | loss: 0.0962261\n",
      "\tspeed: 0.0421s/iter; left time: 672.3038s\n",
      "\titers: 400, epoch: 3 | loss: 0.0960315\n",
      "\tspeed: 0.0421s/iter; left time: 668.6412s\n",
      "\titers: 500, epoch: 3 | loss: 0.0871150\n",
      "\tspeed: 0.0420s/iter; left time: 663.1879s\n",
      "\titers: 600, epoch: 3 | loss: 0.0901583\n",
      "\tspeed: 0.0421s/iter; left time: 659.3545s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950876\n",
      "\tspeed: 0.0420s/iter; left time: 654.3531s\n",
      "\titers: 800, epoch: 3 | loss: 0.0905125\n",
      "\tspeed: 0.0420s/iter; left time: 650.5121s\n",
      "\titers: 900, epoch: 3 | loss: 0.0831911\n",
      "\tspeed: 0.0421s/iter; left time: 646.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0922454 Vali Loss: 0.0891734 Test Loss: 0.1277304\n",
      "Validation loss decreased (0.096871 --> 0.089173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0830763\n",
      "\tspeed: 0.1176s/iter; left time: 1796.2948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0852754\n",
      "\tspeed: 0.0421s/iter; left time: 638.2523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0858199\n",
      "\tspeed: 0.0421s/iter; left time: 634.1683s\n",
      "\titers: 400, epoch: 4 | loss: 0.0820458\n",
      "\tspeed: 0.0421s/iter; left time: 629.8990s\n",
      "\titers: 500, epoch: 4 | loss: 0.0901307\n",
      "\tspeed: 0.0420s/iter; left time: 625.0486s\n",
      "\titers: 600, epoch: 4 | loss: 0.0855317\n",
      "\tspeed: 0.0421s/iter; left time: 621.2486s\n",
      "\titers: 700, epoch: 4 | loss: 0.0796080\n",
      "\tspeed: 0.0421s/iter; left time: 617.0458s\n",
      "\titers: 800, epoch: 4 | loss: 0.0797859\n",
      "\tspeed: 0.0421s/iter; left time: 612.8719s\n",
      "\titers: 900, epoch: 4 | loss: 0.0875236\n",
      "\tspeed: 0.0421s/iter; left time: 608.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0864976 Vali Loss: 0.0881260 Test Loss: 0.1281893\n",
      "Validation loss decreased (0.089173 --> 0.088126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0831923\n",
      "\tspeed: 0.1170s/iter; left time: 1681.0620s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823494\n",
      "\tspeed: 0.0421s/iter; left time: 600.7790s\n",
      "\titers: 300, epoch: 5 | loss: 0.0849803\n",
      "\tspeed: 0.0421s/iter; left time: 596.2569s\n",
      "\titers: 400, epoch: 5 | loss: 0.0798522\n",
      "\tspeed: 0.0421s/iter; left time: 592.0255s\n",
      "\titers: 500, epoch: 5 | loss: 0.0811485\n",
      "\tspeed: 0.0421s/iter; left time: 588.2881s\n",
      "\titers: 600, epoch: 5 | loss: 0.0798577\n",
      "\tspeed: 0.0421s/iter; left time: 583.7078s\n",
      "\titers: 700, epoch: 5 | loss: 0.0791995\n",
      "\tspeed: 0.0421s/iter; left time: 579.9353s\n",
      "\titers: 800, epoch: 5 | loss: 0.0825909\n",
      "\tspeed: 0.0422s/iter; left time: 576.0551s\n",
      "\titers: 900, epoch: 5 | loss: 0.0805139\n",
      "\tspeed: 0.0421s/iter; left time: 570.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0819588 Vali Loss: 0.0869265 Test Loss: 0.1323719\n",
      "Validation loss decreased (0.088126 --> 0.086926).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814526\n",
      "\tspeed: 0.1178s/iter; left time: 1585.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821762\n",
      "\tspeed: 0.0421s/iter; left time: 562.3599s\n",
      "\titers: 300, epoch: 6 | loss: 0.0794167\n",
      "\tspeed: 0.0421s/iter; left time: 558.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0752672\n",
      "\tspeed: 0.0421s/iter; left time: 554.3897s\n",
      "\titers: 500, epoch: 6 | loss: 0.0766867\n",
      "\tspeed: 0.0420s/iter; left time: 549.1725s\n",
      "\titers: 600, epoch: 6 | loss: 0.0775365\n",
      "\tspeed: 0.0421s/iter; left time: 545.3077s\n",
      "\titers: 700, epoch: 6 | loss: 0.0771111\n",
      "\tspeed: 0.0421s/iter; left time: 541.3962s\n",
      "\titers: 800, epoch: 6 | loss: 0.0805728\n",
      "\tspeed: 0.0421s/iter; left time: 537.0451s\n",
      "\titers: 900, epoch: 6 | loss: 0.0751420\n",
      "\tspeed: 0.0421s/iter; left time: 533.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0784264 Vali Loss: 0.0879058 Test Loss: 0.1440845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763488\n",
      "\tspeed: 0.1153s/iter; left time: 1447.5681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769644\n",
      "\tspeed: 0.0420s/iter; left time: 523.5385s\n",
      "\titers: 300, epoch: 7 | loss: 0.0803116\n",
      "\tspeed: 0.0421s/iter; left time: 519.9943s\n",
      "\titers: 400, epoch: 7 | loss: 0.0778039\n",
      "\tspeed: 0.0421s/iter; left time: 515.5707s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726631\n",
      "\tspeed: 0.0421s/iter; left time: 511.8159s\n",
      "\titers: 600, epoch: 7 | loss: 0.0671688\n",
      "\tspeed: 0.0421s/iter; left time: 507.5547s\n",
      "\titers: 700, epoch: 7 | loss: 0.0728735\n",
      "\tspeed: 0.0418s/iter; left time: 499.7380s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 491.7005s\n",
      "\titers: 900, epoch: 7 | loss: 0.0791964\n",
      "\tspeed: 0.0415s/iter; left time: 487.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 904 | Train Loss: 0.0751993 Vali Loss: 0.0868586 Test Loss: 0.1397843\n",
      "Validation loss decreased (0.086926 --> 0.086859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776971\n",
      "\tspeed: 0.1174s/iter; left time: 1368.3659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721895\n",
      "\tspeed: 0.0416s/iter; left time: 480.0903s\n",
      "\titers: 300, epoch: 8 | loss: 0.0700485\n",
      "\tspeed: 0.0415s/iter; left time: 475.8155s\n",
      "\titers: 400, epoch: 8 | loss: 0.0711599\n",
      "\tspeed: 0.0416s/iter; left time: 471.8501s\n",
      "\titers: 500, epoch: 8 | loss: 0.0706868\n",
      "\tspeed: 0.0415s/iter; left time: 467.5249s\n",
      "\titers: 600, epoch: 8 | loss: 0.0683769\n",
      "\tspeed: 0.0416s/iter; left time: 463.6050s\n",
      "\titers: 700, epoch: 8 | loss: 0.0641797\n",
      "\tspeed: 0.0416s/iter; left time: 459.2867s\n",
      "\titers: 800, epoch: 8 | loss: 0.0709313\n",
      "\tspeed: 0.0416s/iter; left time: 455.4383s\n",
      "\titers: 900, epoch: 8 | loss: 0.0689372\n",
      "\tspeed: 0.0416s/iter; left time: 451.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0718957 Vali Loss: 0.0874921 Test Loss: 0.1515969\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0712285\n",
      "\tspeed: 0.1141s/iter; left time: 1225.9544s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697914\n",
      "\tspeed: 0.0415s/iter; left time: 441.5640s\n",
      "\titers: 300, epoch: 9 | loss: 0.0708499\n",
      "\tspeed: 0.0415s/iter; left time: 437.6952s\n",
      "\titers: 400, epoch: 9 | loss: 0.0671885\n",
      "\tspeed: 0.0415s/iter; left time: 433.7513s\n",
      "\titers: 500, epoch: 9 | loss: 0.0713352\n",
      "\tspeed: 0.0415s/iter; left time: 429.1352s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717964\n",
      "\tspeed: 0.0415s/iter; left time: 425.3757s\n",
      "\titers: 700, epoch: 9 | loss: 0.0682684\n",
      "\tspeed: 0.0415s/iter; left time: 421.1203s\n",
      "\titers: 800, epoch: 9 | loss: 0.0685369\n",
      "\tspeed: 0.0415s/iter; left time: 417.1008s\n",
      "\titers: 900, epoch: 9 | loss: 0.0697512\n",
      "\tspeed: 0.0415s/iter; left time: 412.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0691556 Vali Loss: 0.0882018 Test Loss: 0.1587183\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682209\n",
      "\tspeed: 0.1132s/iter; left time: 1114.3122s\n",
      "\titers: 200, epoch: 10 | loss: 0.0657655\n",
      "\tspeed: 0.0414s/iter; left time: 403.9179s\n",
      "\titers: 300, epoch: 10 | loss: 0.0661185\n",
      "\tspeed: 0.0415s/iter; left time: 400.0127s\n",
      "\titers: 400, epoch: 10 | loss: 0.0667656\n",
      "\tspeed: 0.0414s/iter; left time: 395.5766s\n",
      "\titers: 500, epoch: 10 | loss: 0.0639189\n",
      "\tspeed: 0.0415s/iter; left time: 391.6025s\n",
      "\titers: 600, epoch: 10 | loss: 0.0679160\n",
      "\tspeed: 0.0415s/iter; left time: 387.4287s\n",
      "\titers: 700, epoch: 10 | loss: 0.0706274\n",
      "\tspeed: 0.0414s/iter; left time: 383.2033s\n",
      "\titers: 800, epoch: 10 | loss: 0.0604116\n",
      "\tspeed: 0.0414s/iter; left time: 379.0521s\n",
      "\titers: 900, epoch: 10 | loss: 0.0648436\n",
      "\tspeed: 0.0414s/iter; left time: 374.8803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 904 | Train Loss: 0.0665796 Vali Loss: 0.0873402 Test Loss: 0.1584590\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0683132\n",
      "\tspeed: 0.1138s/iter; left time: 1017.2489s\n",
      "\titers: 200, epoch: 11 | loss: 0.0653537\n",
      "\tspeed: 0.0415s/iter; left time: 367.2876s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655010\n",
      "\tspeed: 0.0415s/iter; left time: 363.0876s\n",
      "\titers: 400, epoch: 11 | loss: 0.0705099\n",
      "\tspeed: 0.0415s/iter; left time: 358.8113s\n",
      "\titers: 500, epoch: 11 | loss: 0.0668215\n",
      "\tspeed: 0.0415s/iter; left time: 354.5913s\n",
      "\titers: 600, epoch: 11 | loss: 0.0674020\n",
      "\tspeed: 0.0415s/iter; left time: 350.3595s\n",
      "\titers: 700, epoch: 11 | loss: 0.0653524\n",
      "\tspeed: 0.0415s/iter; left time: 346.5444s\n",
      "\titers: 800, epoch: 11 | loss: 0.0633563\n",
      "\tspeed: 0.0415s/iter; left time: 342.0408s\n",
      "\titers: 900, epoch: 11 | loss: 0.0604338\n",
      "\tspeed: 0.0416s/iter; left time: 338.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0644156 Vali Loss: 0.0880552 Test Loss: 0.1590489\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583263\n",
      "\tspeed: 0.1149s/iter; left time: 923.2915s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638356\n",
      "\tspeed: 0.0415s/iter; left time: 329.0060s\n",
      "\titers: 300, epoch: 12 | loss: 0.0610895\n",
      "\tspeed: 0.0415s/iter; left time: 325.0781s\n",
      "\titers: 400, epoch: 12 | loss: 0.0576380\n",
      "\tspeed: 0.0415s/iter; left time: 321.0412s\n",
      "\titers: 500, epoch: 12 | loss: 0.0655818\n",
      "\tspeed: 0.0415s/iter; left time: 316.7267s\n",
      "\titers: 600, epoch: 12 | loss: 0.0575109\n",
      "\tspeed: 0.0418s/iter; left time: 314.9701s\n",
      "\titers: 700, epoch: 12 | loss: 0.0618829\n",
      "\tspeed: 0.0420s/iter; left time: 312.4757s\n",
      "\titers: 800, epoch: 12 | loss: 0.0603857\n",
      "\tspeed: 0.0420s/iter; left time: 308.1376s\n",
      "\titers: 900, epoch: 12 | loss: 0.0614875\n",
      "\tspeed: 0.0420s/iter; left time: 304.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 904 | Train Loss: 0.0624188 Vali Loss: 0.0871061 Test Loss: 0.1609867\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04883919283747673, rmse:0.2209959179162979, mae:0.1398049145936966, rse:0.6492194533348083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2255370\n",
      "\tspeed: 0.0439s/iter; left time: 789.5778s\n",
      "\titers: 200, epoch: 1 | loss: 0.2166498\n",
      "\tspeed: 0.0415s/iter; left time: 742.5966s\n",
      "\titers: 300, epoch: 1 | loss: 0.2044076\n",
      "\tspeed: 0.0415s/iter; left time: 738.6653s\n",
      "\titers: 400, epoch: 1 | loss: 0.2036429\n",
      "\tspeed: 0.0416s/iter; left time: 735.0498s\n",
      "\titers: 500, epoch: 1 | loss: 0.1952279\n",
      "\tspeed: 0.0416s/iter; left time: 730.7050s\n",
      "\titers: 600, epoch: 1 | loss: 0.1890704\n",
      "\tspeed: 0.0416s/iter; left time: 726.8284s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774556\n",
      "\tspeed: 0.0416s/iter; left time: 722.6038s\n",
      "\titers: 800, epoch: 1 | loss: 0.1774660\n",
      "\tspeed: 0.0416s/iter; left time: 718.2065s\n",
      "\titers: 900, epoch: 1 | loss: 0.1773101\n",
      "\tspeed: 0.0415s/iter; left time: 713.2413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.2017067 Vali Loss: 0.1653294 Test Loss: 0.2053860\n",
      "Validation loss decreased (inf --> 0.165329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482454\n",
      "\tspeed: 0.1171s/iter; left time: 2000.5558s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250862\n",
      "\tspeed: 0.0415s/iter; left time: 704.8476s\n",
      "\titers: 300, epoch: 2 | loss: 0.1308347\n",
      "\tspeed: 0.0415s/iter; left time: 700.7665s\n",
      "\titers: 400, epoch: 2 | loss: 0.1253198\n",
      "\tspeed: 0.0415s/iter; left time: 696.8225s\n",
      "\titers: 500, epoch: 2 | loss: 0.1118068\n",
      "\tspeed: 0.0415s/iter; left time: 692.3480s\n",
      "\titers: 600, epoch: 2 | loss: 0.1140664\n",
      "\tspeed: 0.0416s/iter; left time: 688.8759s\n",
      "\titers: 700, epoch: 2 | loss: 0.1062072\n",
      "\tspeed: 0.0416s/iter; left time: 684.9127s\n",
      "\titers: 800, epoch: 2 | loss: 0.1010479\n",
      "\tspeed: 0.0416s/iter; left time: 680.5475s\n",
      "\titers: 900, epoch: 2 | loss: 0.0990625\n",
      "\tspeed: 0.0416s/iter; left time: 676.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.1223058 Vali Loss: 0.0981640 Test Loss: 0.1313140\n",
      "Validation loss decreased (0.165329 --> 0.098164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0917345\n",
      "\tspeed: 0.1206s/iter; left time: 1950.2871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0968400\n",
      "\tspeed: 0.0415s/iter; left time: 667.5402s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922163\n",
      "\tspeed: 0.0415s/iter; left time: 663.6097s\n",
      "\titers: 400, epoch: 3 | loss: 0.0844943\n",
      "\tspeed: 0.0416s/iter; left time: 659.5445s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870728\n",
      "\tspeed: 0.0416s/iter; left time: 655.7148s\n",
      "\titers: 600, epoch: 3 | loss: 0.0913326\n",
      "\tspeed: 0.0416s/iter; left time: 651.5126s\n",
      "\titers: 700, epoch: 3 | loss: 0.0907997\n",
      "\tspeed: 0.0415s/iter; left time: 646.4715s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945480\n",
      "\tspeed: 0.0416s/iter; left time: 643.3192s\n",
      "\titers: 900, epoch: 3 | loss: 0.0911530\n",
      "\tspeed: 0.0416s/iter; left time: 639.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.0923384 Vali Loss: 0.0945549 Test Loss: 0.1335031\n",
      "Validation loss decreased (0.098164 --> 0.094555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901370\n",
      "\tspeed: 0.1166s/iter; left time: 1779.6277s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939121\n",
      "\tspeed: 0.0416s/iter; left time: 630.3666s\n",
      "\titers: 300, epoch: 4 | loss: 0.0888266\n",
      "\tspeed: 0.0416s/iter; left time: 626.5277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0939008\n",
      "\tspeed: 0.0416s/iter; left time: 622.4458s\n",
      "\titers: 500, epoch: 4 | loss: 0.0792086\n",
      "\tspeed: 0.0416s/iter; left time: 618.3303s\n",
      "\titers: 600, epoch: 4 | loss: 0.0830760\n",
      "\tspeed: 0.0416s/iter; left time: 613.8589s\n",
      "\titers: 700, epoch: 4 | loss: 0.0812820\n",
      "\tspeed: 0.0416s/iter; left time: 609.6404s\n",
      "\titers: 800, epoch: 4 | loss: 0.0889937\n",
      "\tspeed: 0.0416s/iter; left time: 605.5328s\n",
      "\titers: 900, epoch: 4 | loss: 0.0849229\n",
      "\tspeed: 0.0416s/iter; left time: 601.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0863824 Vali Loss: 0.0888520 Test Loss: 0.1328815\n",
      "Validation loss decreased (0.094555 --> 0.088852).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871914\n",
      "\tspeed: 0.1170s/iter; left time: 1680.2305s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801925\n",
      "\tspeed: 0.0416s/iter; left time: 592.9057s\n",
      "\titers: 300, epoch: 5 | loss: 0.0851149\n",
      "\tspeed: 0.0415s/iter; left time: 587.8497s\n",
      "\titers: 400, epoch: 5 | loss: 0.0847745\n",
      "\tspeed: 0.0415s/iter; left time: 583.5027s\n",
      "\titers: 500, epoch: 5 | loss: 0.0800787\n",
      "\tspeed: 0.0415s/iter; left time: 579.6990s\n",
      "\titers: 600, epoch: 5 | loss: 0.0951516\n",
      "\tspeed: 0.0415s/iter; left time: 575.3423s\n",
      "\titers: 700, epoch: 5 | loss: 0.0797609\n",
      "\tspeed: 0.0415s/iter; left time: 570.9798s\n",
      "\titers: 800, epoch: 5 | loss: 0.0892005\n",
      "\tspeed: 0.0415s/iter; left time: 567.0856s\n",
      "\titers: 900, epoch: 5 | loss: 0.0754987\n",
      "\tspeed: 0.0415s/iter; left time: 562.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0823251 Vali Loss: 0.0867483 Test Loss: 0.1332777\n",
      "Validation loss decreased (0.088852 --> 0.086748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733105\n",
      "\tspeed: 0.1167s/iter; left time: 1570.2430s\n",
      "\titers: 200, epoch: 6 | loss: 0.0700598\n",
      "\tspeed: 0.0415s/iter; left time: 554.4218s\n",
      "\titers: 300, epoch: 6 | loss: 0.0821968\n",
      "\tspeed: 0.0415s/iter; left time: 550.3302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788260\n",
      "\tspeed: 0.0415s/iter; left time: 546.0061s\n",
      "\titers: 500, epoch: 6 | loss: 0.0736750\n",
      "\tspeed: 0.0415s/iter; left time: 541.9977s\n",
      "\titers: 600, epoch: 6 | loss: 0.0731835\n",
      "\tspeed: 0.0416s/iter; left time: 538.6953s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804928\n",
      "\tspeed: 0.0416s/iter; left time: 534.4559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0761644\n",
      "\tspeed: 0.0415s/iter; left time: 529.8287s\n",
      "\titers: 900, epoch: 6 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 525.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0791167 Vali Loss: 0.0868076 Test Loss: 0.1432561\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792830\n",
      "\tspeed: 0.1135s/iter; left time: 1425.4236s\n",
      "\titers: 200, epoch: 7 | loss: 0.0736702\n",
      "\tspeed: 0.0416s/iter; left time: 518.0054s\n",
      "\titers: 300, epoch: 7 | loss: 0.0709306\n",
      "\tspeed: 0.0416s/iter; left time: 513.8523s\n",
      "\titers: 400, epoch: 7 | loss: 0.0709575\n",
      "\tspeed: 0.0416s/iter; left time: 509.4117s\n",
      "\titers: 500, epoch: 7 | loss: 0.0705057\n",
      "\tspeed: 0.0416s/iter; left time: 506.0713s\n",
      "\titers: 600, epoch: 7 | loss: 0.0775761\n",
      "\tspeed: 0.0416s/iter; left time: 501.3616s\n",
      "\titers: 700, epoch: 7 | loss: 0.0763834\n",
      "\tspeed: 0.0416s/iter; left time: 497.1976s\n",
      "\titers: 800, epoch: 7 | loss: 0.0740358\n",
      "\tspeed: 0.0416s/iter; left time: 492.9521s\n",
      "\titers: 900, epoch: 7 | loss: 0.0736507\n",
      "\tspeed: 0.0416s/iter; left time: 488.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0762565 Vali Loss: 0.0854730 Test Loss: 0.1467339\n",
      "Validation loss decreased (0.086748 --> 0.085473).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729528\n",
      "\tspeed: 0.1162s/iter; left time: 1353.5860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0769066\n",
      "\tspeed: 0.0415s/iter; left time: 479.8011s\n",
      "\titers: 300, epoch: 8 | loss: 0.0709053\n",
      "\tspeed: 0.0415s/iter; left time: 475.2179s\n",
      "\titers: 400, epoch: 8 | loss: 0.0712793\n",
      "\tspeed: 0.0415s/iter; left time: 471.3423s\n",
      "\titers: 500, epoch: 8 | loss: 0.0678615\n",
      "\tspeed: 0.0416s/iter; left time: 467.9069s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719967\n",
      "\tspeed: 0.0416s/iter; left time: 463.7415s\n",
      "\titers: 700, epoch: 8 | loss: 0.0767970\n",
      "\tspeed: 0.0416s/iter; left time: 459.7097s\n",
      "\titers: 800, epoch: 8 | loss: 0.0820074\n",
      "\tspeed: 0.0416s/iter; left time: 455.3627s\n",
      "\titers: 900, epoch: 8 | loss: 0.0792067\n",
      "\tspeed: 0.0416s/iter; left time: 451.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0729809 Vali Loss: 0.0853084 Test Loss: 0.1464679\n",
      "Validation loss decreased (0.085473 --> 0.085308).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0680521\n",
      "\tspeed: 0.1170s/iter; left time: 1257.4653s\n",
      "\titers: 200, epoch: 9 | loss: 0.0709191\n",
      "\tspeed: 0.0416s/iter; left time: 442.6350s\n",
      "\titers: 300, epoch: 9 | loss: 0.0691477\n",
      "\tspeed: 0.0416s/iter; left time: 438.5318s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703399\n",
      "\tspeed: 0.0416s/iter; left time: 434.4762s\n",
      "\titers: 500, epoch: 9 | loss: 0.0686584\n",
      "\tspeed: 0.0416s/iter; left time: 430.2977s\n",
      "\titers: 600, epoch: 9 | loss: 0.0730306\n",
      "\tspeed: 0.0416s/iter; left time: 426.3882s\n",
      "\titers: 700, epoch: 9 | loss: 0.0717609\n",
      "\tspeed: 0.0416s/iter; left time: 422.0754s\n",
      "\titers: 800, epoch: 9 | loss: 0.0705330\n",
      "\tspeed: 0.0416s/iter; left time: 417.9879s\n",
      "\titers: 900, epoch: 9 | loss: 0.0692707\n",
      "\tspeed: 0.0416s/iter; left time: 413.4969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0702632 Vali Loss: 0.0855913 Test Loss: 0.1535130\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698408\n",
      "\tspeed: 0.1140s/iter; left time: 1121.8448s\n",
      "\titers: 200, epoch: 10 | loss: 0.0679938\n",
      "\tspeed: 0.0415s/iter; left time: 404.7121s\n",
      "\titers: 300, epoch: 10 | loss: 0.0702723\n",
      "\tspeed: 0.0415s/iter; left time: 400.3426s\n",
      "\titers: 400, epoch: 10 | loss: 0.0665980\n",
      "\tspeed: 0.0415s/iter; left time: 396.1537s\n",
      "\titers: 500, epoch: 10 | loss: 0.0640535\n",
      "\tspeed: 0.0415s/iter; left time: 392.4156s\n",
      "\titers: 600, epoch: 10 | loss: 0.0687447\n",
      "\tspeed: 0.0416s/iter; left time: 388.9352s\n",
      "\titers: 700, epoch: 10 | loss: 0.0636232\n",
      "\tspeed: 0.0415s/iter; left time: 383.7071s\n",
      "\titers: 800, epoch: 10 | loss: 0.0637815\n",
      "\tspeed: 0.0415s/iter; left time: 379.4254s\n",
      "\titers: 900, epoch: 10 | loss: 0.0650070\n",
      "\tspeed: 0.0415s/iter; left time: 375.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0675522 Vali Loss: 0.0878237 Test Loss: 0.1574765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680077\n",
      "\tspeed: 0.1152s/iter; left time: 1029.7413s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625419\n",
      "\tspeed: 0.0416s/iter; left time: 367.5794s\n",
      "\titers: 300, epoch: 11 | loss: 0.0644673\n",
      "\tspeed: 0.0415s/iter; left time: 363.0404s\n",
      "\titers: 400, epoch: 11 | loss: 0.0685582\n",
      "\tspeed: 0.0415s/iter; left time: 358.5762s\n",
      "\titers: 500, epoch: 11 | loss: 0.0674249\n",
      "\tspeed: 0.0415s/iter; left time: 354.2847s\n",
      "\titers: 600, epoch: 11 | loss: 0.0653215\n",
      "\tspeed: 0.0415s/iter; left time: 350.3671s\n",
      "\titers: 700, epoch: 11 | loss: 0.0610816\n",
      "\tspeed: 0.0415s/iter; left time: 346.5466s\n",
      "\titers: 800, epoch: 11 | loss: 0.0660871\n",
      "\tspeed: 0.0415s/iter; left time: 342.1604s\n",
      "\titers: 900, epoch: 11 | loss: 0.0601333\n",
      "\tspeed: 0.0415s/iter; left time: 337.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0652383 Vali Loss: 0.0865308 Test Loss: 0.1594289\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594552\n",
      "\tspeed: 0.1140s/iter; left time: 916.4326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654352\n",
      "\tspeed: 0.0415s/iter; left time: 329.3632s\n",
      "\titers: 300, epoch: 12 | loss: 0.0618489\n",
      "\tspeed: 0.0415s/iter; left time: 325.2592s\n",
      "\titers: 400, epoch: 12 | loss: 0.0673705\n",
      "\tspeed: 0.0415s/iter; left time: 321.0622s\n",
      "\titers: 500, epoch: 12 | loss: 0.0666839\n",
      "\tspeed: 0.0415s/iter; left time: 316.9643s\n",
      "\titers: 600, epoch: 12 | loss: 0.0667761\n",
      "\tspeed: 0.0415s/iter; left time: 312.8686s\n",
      "\titers: 700, epoch: 12 | loss: 0.0607388\n",
      "\tspeed: 0.0415s/iter; left time: 308.6200s\n",
      "\titers: 800, epoch: 12 | loss: 0.0608705\n",
      "\tspeed: 0.0415s/iter; left time: 304.4714s\n",
      "\titers: 900, epoch: 12 | loss: 0.0617118\n",
      "\tspeed: 0.0415s/iter; left time: 300.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0632101 Vali Loss: 0.0859873 Test Loss: 0.1564025\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0644529\n",
      "\tspeed: 0.1137s/iter; left time: 811.0558s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554359\n",
      "\tspeed: 0.0416s/iter; left time: 292.4215s\n",
      "\titers: 300, epoch: 13 | loss: 0.0615502\n",
      "\tspeed: 0.0416s/iter; left time: 288.4158s\n",
      "\titers: 400, epoch: 13 | loss: 0.0606781\n",
      "\tspeed: 0.0416s/iter; left time: 284.2330s\n",
      "\titers: 500, epoch: 13 | loss: 0.0597327\n",
      "\tspeed: 0.0416s/iter; left time: 280.1644s\n",
      "\titers: 600, epoch: 13 | loss: 0.0621458\n",
      "\tspeed: 0.0416s/iter; left time: 275.8850s\n",
      "\titers: 700, epoch: 13 | loss: 0.0588029\n",
      "\tspeed: 0.0416s/iter; left time: 271.6671s\n",
      "\titers: 800, epoch: 13 | loss: 0.0633195\n",
      "\tspeed: 0.0416s/iter; left time: 267.5730s\n",
      "\titers: 900, epoch: 13 | loss: 0.0699742\n",
      "\tspeed: 0.0416s/iter; left time: 263.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0609191 Vali Loss: 0.0863986 Test Loss: 0.1637643\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05644026771187782, rmse:0.2375716120004654, mae:0.14639423787593842, rse:0.6979138851165771\n",
      "Intermediate time for ES and pred_len 96: 00h:19m:00.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2492964\n",
      "\tspeed: 0.0712s/iter; left time: 1277.1901s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172240\n",
      "\tspeed: 0.0504s/iter; left time: 899.7993s\n",
      "\titers: 300, epoch: 1 | loss: 0.2131199\n",
      "\tspeed: 0.0505s/iter; left time: 896.4523s\n",
      "\titers: 400, epoch: 1 | loss: 0.2037690\n",
      "\tspeed: 0.0505s/iter; left time: 891.4202s\n",
      "\titers: 500, epoch: 1 | loss: 0.1987259\n",
      "\tspeed: 0.0505s/iter; left time: 885.4587s\n",
      "\titers: 600, epoch: 1 | loss: 0.1937901\n",
      "\tspeed: 0.0505s/iter; left time: 880.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921680\n",
      "\tspeed: 0.0506s/iter; left time: 876.8671s\n",
      "\titers: 800, epoch: 1 | loss: 0.1843900\n",
      "\tspeed: 0.0506s/iter; left time: 871.9005s\n",
      "\titers: 900, epoch: 1 | loss: 0.1844022\n",
      "\tspeed: 0.0505s/iter; left time: 865.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 902 | Train Loss: 0.2083722 Vali Loss: 0.1819980 Test Loss: 0.2220403\n",
      "Validation loss decreased (inf --> 0.181998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1653086\n",
      "\tspeed: 0.1417s/iter; left time: 2413.8571s\n",
      "\titers: 200, epoch: 2 | loss: 0.1531178\n",
      "\tspeed: 0.0504s/iter; left time: 853.2940s\n",
      "\titers: 300, epoch: 2 | loss: 0.1426768\n",
      "\tspeed: 0.0504s/iter; left time: 849.1057s\n",
      "\titers: 400, epoch: 2 | loss: 0.1295031\n",
      "\tspeed: 0.0504s/iter; left time: 844.0830s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160058\n",
      "\tspeed: 0.0504s/iter; left time: 838.5864s\n",
      "\titers: 600, epoch: 2 | loss: 0.1129280\n",
      "\tspeed: 0.0504s/iter; left time: 834.3003s\n",
      "\titers: 700, epoch: 2 | loss: 0.1077385\n",
      "\tspeed: 0.0504s/iter; left time: 827.7760s\n",
      "\titers: 800, epoch: 2 | loss: 0.1035756\n",
      "\tspeed: 0.0504s/iter; left time: 824.1451s\n",
      "\titers: 900, epoch: 2 | loss: 0.0996339\n",
      "\tspeed: 0.0504s/iter; left time: 818.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1298264 Vali Loss: 0.1035160 Test Loss: 0.1475300\n",
      "Validation loss decreased (0.181998 --> 0.103516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033866\n",
      "\tspeed: 0.1412s/iter; left time: 2278.6888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975054\n",
      "\tspeed: 0.0505s/iter; left time: 809.1720s\n",
      "\titers: 300, epoch: 3 | loss: 0.0915680\n",
      "\tspeed: 0.0504s/iter; left time: 803.1125s\n",
      "\titers: 400, epoch: 3 | loss: 0.0927011\n",
      "\tspeed: 0.0504s/iter; left time: 798.1891s\n",
      "\titers: 500, epoch: 3 | loss: 0.0954466\n",
      "\tspeed: 0.0504s/iter; left time: 793.2339s\n",
      "\titers: 600, epoch: 3 | loss: 0.1021520\n",
      "\tspeed: 0.0504s/iter; left time: 788.3923s\n",
      "\titers: 700, epoch: 3 | loss: 0.0969066\n",
      "\tspeed: 0.0504s/iter; left time: 783.1803s\n",
      "\titers: 800, epoch: 3 | loss: 0.0930721\n",
      "\tspeed: 0.0504s/iter; left time: 778.3916s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931172\n",
      "\tspeed: 0.0504s/iter; left time: 773.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0972800 Vali Loss: 0.0986148 Test Loss: 0.1403995\n",
      "Validation loss decreased (0.103516 --> 0.098615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0925042\n",
      "\tspeed: 0.1410s/iter; left time: 2147.4261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977211\n",
      "\tspeed: 0.0504s/iter; left time: 763.3308s\n",
      "\titers: 300, epoch: 4 | loss: 0.0909184\n",
      "\tspeed: 0.0504s/iter; left time: 758.0967s\n",
      "\titers: 400, epoch: 4 | loss: 0.0948582\n",
      "\tspeed: 0.0505s/iter; left time: 753.4728s\n",
      "\titers: 500, epoch: 4 | loss: 0.0912337\n",
      "\tspeed: 0.0504s/iter; left time: 748.1623s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878440\n",
      "\tspeed: 0.0504s/iter; left time: 743.1452s\n",
      "\titers: 700, epoch: 4 | loss: 0.0873194\n",
      "\tspeed: 0.0504s/iter; left time: 737.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.0957726\n",
      "\tspeed: 0.0504s/iter; left time: 733.0270s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906419\n",
      "\tspeed: 0.0504s/iter; left time: 727.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0912431 Vali Loss: 0.0933874 Test Loss: 0.1351360\n",
      "Validation loss decreased (0.098615 --> 0.093387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860944\n",
      "\tspeed: 0.1425s/iter; left time: 2042.0201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0850665\n",
      "\tspeed: 0.0504s/iter; left time: 717.2623s\n",
      "\titers: 300, epoch: 5 | loss: 0.0901280\n",
      "\tspeed: 0.0504s/iter; left time: 712.9415s\n",
      "\titers: 400, epoch: 5 | loss: 0.0854654\n",
      "\tspeed: 0.0506s/iter; left time: 709.8097s\n",
      "\titers: 500, epoch: 5 | loss: 0.0851015\n",
      "\tspeed: 0.0506s/iter; left time: 705.2464s\n",
      "\titers: 600, epoch: 5 | loss: 0.0846908\n",
      "\tspeed: 0.0506s/iter; left time: 699.8147s\n",
      "\titers: 700, epoch: 5 | loss: 0.0850851\n",
      "\tspeed: 0.0506s/iter; left time: 694.3147s\n",
      "\titers: 800, epoch: 5 | loss: 0.0879443\n",
      "\tspeed: 0.0504s/iter; left time: 687.0974s\n",
      "\titers: 900, epoch: 5 | loss: 0.0815824\n",
      "\tspeed: 0.0504s/iter; left time: 682.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0865540 Vali Loss: 0.0953768 Test Loss: 0.1449964\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0880546\n",
      "\tspeed: 0.1384s/iter; left time: 1858.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0880220\n",
      "\tspeed: 0.0504s/iter; left time: 672.1573s\n",
      "\titers: 300, epoch: 6 | loss: 0.0851828\n",
      "\tspeed: 0.0504s/iter; left time: 667.0128s\n",
      "\titers: 400, epoch: 6 | loss: 0.0814955\n",
      "\tspeed: 0.0504s/iter; left time: 662.3892s\n",
      "\titers: 500, epoch: 6 | loss: 0.0808422\n",
      "\tspeed: 0.0504s/iter; left time: 656.7175s\n",
      "\titers: 600, epoch: 6 | loss: 0.0843075\n",
      "\tspeed: 0.0504s/iter; left time: 652.3007s\n",
      "\titers: 700, epoch: 6 | loss: 0.0827094\n",
      "\tspeed: 0.0505s/iter; left time: 648.1374s\n",
      "\titers: 800, epoch: 6 | loss: 0.0847130\n",
      "\tspeed: 0.0504s/iter; left time: 641.5816s\n",
      "\titers: 900, epoch: 6 | loss: 0.0832033\n",
      "\tspeed: 0.0504s/iter; left time: 636.7428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0824581 Vali Loss: 0.0938004 Test Loss: 0.1515495\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0807643\n",
      "\tspeed: 0.1365s/iter; left time: 1709.5910s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733612\n",
      "\tspeed: 0.0504s/iter; left time: 626.5840s\n",
      "\titers: 300, epoch: 7 | loss: 0.0787084\n",
      "\tspeed: 0.0504s/iter; left time: 621.0739s\n",
      "\titers: 400, epoch: 7 | loss: 0.0756619\n",
      "\tspeed: 0.0504s/iter; left time: 616.5083s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772191\n",
      "\tspeed: 0.0504s/iter; left time: 611.6287s\n",
      "\titers: 600, epoch: 7 | loss: 0.0766708\n",
      "\tspeed: 0.0505s/iter; left time: 606.9050s\n",
      "\titers: 700, epoch: 7 | loss: 0.0778410\n",
      "\tspeed: 0.0504s/iter; left time: 601.0559s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783041\n",
      "\tspeed: 0.0504s/iter; left time: 596.3140s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758551\n",
      "\tspeed: 0.0505s/iter; left time: 592.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0786968 Vali Loss: 0.0945030 Test Loss: 0.1575315\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0765909\n",
      "\tspeed: 0.1369s/iter; left time: 1591.5120s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756120\n",
      "\tspeed: 0.0504s/iter; left time: 580.6304s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762664\n",
      "\tspeed: 0.0504s/iter; left time: 575.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0798623\n",
      "\tspeed: 0.0504s/iter; left time: 570.8086s\n",
      "\titers: 500, epoch: 8 | loss: 0.0781074\n",
      "\tspeed: 0.0505s/iter; left time: 566.7603s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719266\n",
      "\tspeed: 0.0504s/iter; left time: 561.2141s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752170\n",
      "\tspeed: 0.0504s/iter; left time: 555.5328s\n",
      "\titers: 800, epoch: 8 | loss: 0.0754173\n",
      "\tspeed: 0.0505s/iter; left time: 552.1497s\n",
      "\titers: 900, epoch: 8 | loss: 0.0684457\n",
      "\tspeed: 0.0505s/iter; left time: 546.4118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0753874 Vali Loss: 0.0934107 Test Loss: 0.1613924\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704094\n",
      "\tspeed: 0.1380s/iter; left time: 1480.5162s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717454\n",
      "\tspeed: 0.0504s/iter; left time: 535.8080s\n",
      "\titers: 300, epoch: 9 | loss: 0.0741613\n",
      "\tspeed: 0.0504s/iter; left time: 530.6156s\n",
      "\titers: 400, epoch: 9 | loss: 0.0742769\n",
      "\tspeed: 0.0504s/iter; left time: 525.9377s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733934\n",
      "\tspeed: 0.0504s/iter; left time: 520.7536s\n",
      "\titers: 600, epoch: 9 | loss: 0.0716762\n",
      "\tspeed: 0.0505s/iter; left time: 515.9702s\n",
      "\titers: 700, epoch: 9 | loss: 0.0709206\n",
      "\tspeed: 0.0504s/iter; left time: 510.4875s\n",
      "\titers: 800, epoch: 9 | loss: 0.0728439\n",
      "\tspeed: 0.0504s/iter; left time: 505.7294s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723040\n",
      "\tspeed: 0.0504s/iter; left time: 500.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0723324 Vali Loss: 0.0969553 Test Loss: 0.1759281\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04438893124461174, rmse:0.2106868028640747, mae:0.13518424332141876, rse:0.6188546419143677\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2389837\n",
      "\tspeed: 0.0525s/iter; left time: 941.8531s\n",
      "\titers: 200, epoch: 1 | loss: 0.2256297\n",
      "\tspeed: 0.0505s/iter; left time: 901.0100s\n",
      "\titers: 300, epoch: 1 | loss: 0.2167884\n",
      "\tspeed: 0.0504s/iter; left time: 893.7508s\n",
      "\titers: 400, epoch: 1 | loss: 0.2074835\n",
      "\tspeed: 0.0505s/iter; left time: 891.2074s\n",
      "\titers: 500, epoch: 1 | loss: 0.2109853\n",
      "\tspeed: 0.0505s/iter; left time: 885.3476s\n",
      "\titers: 600, epoch: 1 | loss: 0.2032430\n",
      "\tspeed: 0.0504s/iter; left time: 879.2211s\n",
      "\titers: 700, epoch: 1 | loss: 0.1951404\n",
      "\tspeed: 0.0505s/iter; left time: 875.8518s\n",
      "\titers: 800, epoch: 1 | loss: 0.1859338\n",
      "\tspeed: 0.0504s/iter; left time: 868.6547s\n",
      "\titers: 900, epoch: 1 | loss: 0.1889469\n",
      "\tspeed: 0.0504s/iter; left time: 864.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.2128992 Vali Loss: 0.1829299 Test Loss: 0.2247479\n",
      "Validation loss decreased (inf --> 0.182930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1616415\n",
      "\tspeed: 0.1418s/iter; left time: 2415.6081s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435303\n",
      "\tspeed: 0.0504s/iter; left time: 854.1932s\n",
      "\titers: 300, epoch: 2 | loss: 0.1445888\n",
      "\tspeed: 0.0504s/iter; left time: 849.3128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1351373\n",
      "\tspeed: 0.0504s/iter; left time: 843.8295s\n",
      "\titers: 500, epoch: 2 | loss: 0.1191210\n",
      "\tspeed: 0.0504s/iter; left time: 839.0269s\n",
      "\titers: 600, epoch: 2 | loss: 0.1166453\n",
      "\tspeed: 0.0505s/iter; left time: 834.4495s\n",
      "\titers: 700, epoch: 2 | loss: 0.1043696\n",
      "\tspeed: 0.0505s/iter; left time: 829.7016s\n",
      "\titers: 800, epoch: 2 | loss: 0.0989133\n",
      "\tspeed: 0.0505s/iter; left time: 824.4989s\n",
      "\titers: 900, epoch: 2 | loss: 0.1004393\n",
      "\tspeed: 0.0504s/iter; left time: 819.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.80s\n",
      "Steps: 902 | Train Loss: 0.1309356 Vali Loss: 0.1029980 Test Loss: 0.1407493\n",
      "Validation loss decreased (0.182930 --> 0.102998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012470\n",
      "\tspeed: 0.1409s/iter; left time: 2274.3233s\n",
      "\titers: 200, epoch: 3 | loss: 0.0983157\n",
      "\tspeed: 0.0505s/iter; left time: 809.2159s\n",
      "\titers: 300, epoch: 3 | loss: 0.0947418\n",
      "\tspeed: 0.0504s/iter; left time: 802.6096s\n",
      "\titers: 400, epoch: 3 | loss: 0.0990990\n",
      "\tspeed: 0.0504s/iter; left time: 798.1440s\n",
      "\titers: 500, epoch: 3 | loss: 0.0928705\n",
      "\tspeed: 0.0505s/iter; left time: 795.0857s\n",
      "\titers: 600, epoch: 3 | loss: 0.0926267\n",
      "\tspeed: 0.0505s/iter; left time: 788.9751s\n",
      "\titers: 700, epoch: 3 | loss: 0.0929120\n",
      "\tspeed: 0.0505s/iter; left time: 784.3314s\n",
      "\titers: 800, epoch: 3 | loss: 0.0964417\n",
      "\tspeed: 0.0505s/iter; left time: 778.9006s\n",
      "\titers: 900, epoch: 3 | loss: 0.0912257\n",
      "\tspeed: 0.0505s/iter; left time: 773.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0973411 Vali Loss: 0.0984464 Test Loss: 0.1338115\n",
      "Validation loss decreased (0.102998 --> 0.098446).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919027\n",
      "\tspeed: 0.1410s/iter; left time: 2148.1578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967809\n",
      "\tspeed: 0.0504s/iter; left time: 762.2060s\n",
      "\titers: 300, epoch: 4 | loss: 0.0983866\n",
      "\tspeed: 0.0504s/iter; left time: 758.0238s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937310\n",
      "\tspeed: 0.0504s/iter; left time: 752.4804s\n",
      "\titers: 500, epoch: 4 | loss: 0.0924264\n",
      "\tspeed: 0.0504s/iter; left time: 747.6431s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878538\n",
      "\tspeed: 0.0504s/iter; left time: 742.4975s\n",
      "\titers: 700, epoch: 4 | loss: 0.0897520\n",
      "\tspeed: 0.0504s/iter; left time: 737.5460s\n",
      "\titers: 800, epoch: 4 | loss: 0.0854635\n",
      "\tspeed: 0.0505s/iter; left time: 734.1163s\n",
      "\titers: 900, epoch: 4 | loss: 0.0885362\n",
      "\tspeed: 0.0504s/iter; left time: 728.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0909175 Vali Loss: 0.0953376 Test Loss: 0.1429246\n",
      "Validation loss decreased (0.098446 --> 0.095338).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0883355\n",
      "\tspeed: 0.1403s/iter; left time: 2010.8001s\n",
      "\titers: 200, epoch: 5 | loss: 0.0869098\n",
      "\tspeed: 0.0504s/iter; left time: 717.2617s\n",
      "\titers: 300, epoch: 5 | loss: 0.0865536\n",
      "\tspeed: 0.0504s/iter; left time: 712.0929s\n",
      "\titers: 400, epoch: 5 | loss: 0.0860558\n",
      "\tspeed: 0.0504s/iter; left time: 707.2679s\n",
      "\titers: 500, epoch: 5 | loss: 0.0856702\n",
      "\tspeed: 0.0504s/iter; left time: 702.2311s\n",
      "\titers: 600, epoch: 5 | loss: 0.0879596\n",
      "\tspeed: 0.0504s/iter; left time: 697.0911s\n",
      "\titers: 700, epoch: 5 | loss: 0.0895608\n",
      "\tspeed: 0.0504s/iter; left time: 691.9814s\n",
      "\titers: 800, epoch: 5 | loss: 0.0870850\n",
      "\tspeed: 0.0504s/iter; left time: 687.2620s\n",
      "\titers: 900, epoch: 5 | loss: 0.0834234\n",
      "\tspeed: 0.0504s/iter; left time: 682.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0860294 Vali Loss: 0.0938435 Test Loss: 0.1573096\n",
      "Validation loss decreased (0.095338 --> 0.093843).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0819926\n",
      "\tspeed: 0.1410s/iter; left time: 1893.2018s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884785\n",
      "\tspeed: 0.0505s/iter; left time: 673.4415s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834609\n",
      "\tspeed: 0.0505s/iter; left time: 667.7094s\n",
      "\titers: 400, epoch: 6 | loss: 0.0848006\n",
      "\tspeed: 0.0504s/iter; left time: 662.3203s\n",
      "\titers: 500, epoch: 6 | loss: 0.0842216\n",
      "\tspeed: 0.0504s/iter; left time: 656.7688s\n",
      "\titers: 600, epoch: 6 | loss: 0.0790967\n",
      "\tspeed: 0.0505s/iter; left time: 653.3962s\n",
      "\titers: 700, epoch: 6 | loss: 0.0801027\n",
      "\tspeed: 0.0505s/iter; left time: 648.2780s\n",
      "\titers: 800, epoch: 6 | loss: 0.0799710\n",
      "\tspeed: 0.0504s/iter; left time: 642.1083s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813835\n",
      "\tspeed: 0.0506s/iter; left time: 638.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0821843 Vali Loss: 0.0972141 Test Loss: 0.1531661\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797309\n",
      "\tspeed: 0.1377s/iter; left time: 1725.4798s\n",
      "\titers: 200, epoch: 7 | loss: 0.0862694\n",
      "\tspeed: 0.0511s/iter; left time: 635.3108s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818903\n",
      "\tspeed: 0.0511s/iter; left time: 629.6545s\n",
      "\titers: 400, epoch: 7 | loss: 0.0793917\n",
      "\tspeed: 0.0511s/iter; left time: 624.5239s\n",
      "\titers: 500, epoch: 7 | loss: 0.0825225\n",
      "\tspeed: 0.0511s/iter; left time: 619.4273s\n",
      "\titers: 600, epoch: 7 | loss: 0.0773069\n",
      "\tspeed: 0.0511s/iter; left time: 614.2800s\n",
      "\titers: 700, epoch: 7 | loss: 0.0710885\n",
      "\tspeed: 0.0506s/iter; left time: 603.8980s\n",
      "\titers: 800, epoch: 7 | loss: 0.0778921\n",
      "\tspeed: 0.0504s/iter; left time: 596.4990s\n",
      "\titers: 900, epoch: 7 | loss: 0.0772341\n",
      "\tspeed: 0.0504s/iter; left time: 590.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.15s\n",
      "Steps: 902 | Train Loss: 0.0783491 Vali Loss: 0.0925858 Test Loss: 0.1583009\n",
      "Validation loss decreased (0.093843 --> 0.092586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754644\n",
      "\tspeed: 0.1407s/iter; left time: 1635.5573s\n",
      "\titers: 200, epoch: 8 | loss: 0.0817999\n",
      "\tspeed: 0.0511s/iter; left time: 589.0371s\n",
      "\titers: 300, epoch: 8 | loss: 0.0772513\n",
      "\tspeed: 0.0511s/iter; left time: 583.9912s\n",
      "\titers: 400, epoch: 8 | loss: 0.0731126\n",
      "\tspeed: 0.0506s/iter; left time: 573.3439s\n",
      "\titers: 500, epoch: 8 | loss: 0.0765568\n",
      "\tspeed: 0.0506s/iter; left time: 567.7213s\n",
      "\titers: 600, epoch: 8 | loss: 0.0775171\n",
      "\tspeed: 0.0505s/iter; left time: 562.0332s\n",
      "\titers: 700, epoch: 8 | loss: 0.0783013\n",
      "\tspeed: 0.0505s/iter; left time: 556.3621s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769860\n",
      "\tspeed: 0.0504s/iter; left time: 550.9337s\n",
      "\titers: 900, epoch: 8 | loss: 0.0720528\n",
      "\tspeed: 0.0504s/iter; left time: 546.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0750094 Vali Loss: 0.0931359 Test Loss: 0.1548578\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725504\n",
      "\tspeed: 0.1379s/iter; left time: 1478.9149s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699559\n",
      "\tspeed: 0.0504s/iter; left time: 535.1801s\n",
      "\titers: 300, epoch: 9 | loss: 0.0776160\n",
      "\tspeed: 0.0504s/iter; left time: 530.1342s\n",
      "\titers: 400, epoch: 9 | loss: 0.0731432\n",
      "\tspeed: 0.0504s/iter; left time: 525.0941s\n",
      "\titers: 500, epoch: 9 | loss: 0.0761598\n",
      "\tspeed: 0.0504s/iter; left time: 520.3729s\n",
      "\titers: 600, epoch: 9 | loss: 0.0740233\n",
      "\tspeed: 0.0504s/iter; left time: 515.5336s\n",
      "\titers: 700, epoch: 9 | loss: 0.0749604\n",
      "\tspeed: 0.0504s/iter; left time: 510.5437s\n",
      "\titers: 800, epoch: 9 | loss: 0.0692300\n",
      "\tspeed: 0.0504s/iter; left time: 505.5818s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723800\n",
      "\tspeed: 0.0505s/iter; left time: 500.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0717975 Vali Loss: 0.0956336 Test Loss: 0.1646968\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0664784\n",
      "\tspeed: 0.1388s/iter; left time: 1363.0090s\n",
      "\titers: 200, epoch: 10 | loss: 0.0747654\n",
      "\tspeed: 0.0504s/iter; left time: 489.7599s\n",
      "\titers: 300, epoch: 10 | loss: 0.0689450\n",
      "\tspeed: 0.0504s/iter; left time: 485.1702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0679197\n",
      "\tspeed: 0.0504s/iter; left time: 480.0177s\n",
      "\titers: 500, epoch: 10 | loss: 0.0737662\n",
      "\tspeed: 0.0505s/iter; left time: 475.8619s\n",
      "\titers: 600, epoch: 10 | loss: 0.0641387\n",
      "\tspeed: 0.0504s/iter; left time: 470.0892s\n",
      "\titers: 700, epoch: 10 | loss: 0.0697696\n",
      "\tspeed: 0.0504s/iter; left time: 464.7363s\n",
      "\titers: 800, epoch: 10 | loss: 0.0677867\n",
      "\tspeed: 0.0504s/iter; left time: 459.8094s\n",
      "\titers: 900, epoch: 10 | loss: 0.0695094\n",
      "\tspeed: 0.0504s/iter; left time: 454.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 902 | Train Loss: 0.0689554 Vali Loss: 0.0961502 Test Loss: 0.1730712\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672925\n",
      "\tspeed: 0.1373s/iter; left time: 1224.9632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0610949\n",
      "\tspeed: 0.0505s/iter; left time: 445.6581s\n",
      "\titers: 300, epoch: 11 | loss: 0.0667393\n",
      "\tspeed: 0.0505s/iter; left time: 440.8279s\n",
      "\titers: 400, epoch: 11 | loss: 0.0678346\n",
      "\tspeed: 0.0505s/iter; left time: 435.7379s\n",
      "\titers: 500, epoch: 11 | loss: 0.0672898\n",
      "\tspeed: 0.0505s/iter; left time: 429.9508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0637237\n",
      "\tspeed: 0.0504s/iter; left time: 424.2824s\n",
      "\titers: 700, epoch: 11 | loss: 0.0640562\n",
      "\tspeed: 0.0504s/iter; left time: 419.1978s\n",
      "\titers: 800, epoch: 11 | loss: 0.0617589\n",
      "\tspeed: 0.0504s/iter; left time: 414.6768s\n",
      "\titers: 900, epoch: 11 | loss: 0.0612631\n",
      "\tspeed: 0.0504s/iter; left time: 409.3253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0663154 Vali Loss: 0.0945666 Test Loss: 0.1649144\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646060\n",
      "\tspeed: 0.1378s/iter; left time: 1104.9374s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642981\n",
      "\tspeed: 0.0504s/iter; left time: 399.1010s\n",
      "\titers: 300, epoch: 12 | loss: 0.0621096\n",
      "\tspeed: 0.0504s/iter; left time: 394.0479s\n",
      "\titers: 400, epoch: 12 | loss: 0.0637253\n",
      "\tspeed: 0.0504s/iter; left time: 388.9243s\n",
      "\titers: 500, epoch: 12 | loss: 0.0630992\n",
      "\tspeed: 0.0504s/iter; left time: 383.9630s\n",
      "\titers: 600, epoch: 12 | loss: 0.0635810\n",
      "\tspeed: 0.0504s/iter; left time: 378.8416s\n",
      "\titers: 700, epoch: 12 | loss: 0.0700417\n",
      "\tspeed: 0.0504s/iter; left time: 373.9896s\n",
      "\titers: 800, epoch: 12 | loss: 0.0633632\n",
      "\tspeed: 0.0504s/iter; left time: 368.9444s\n",
      "\titers: 900, epoch: 12 | loss: 0.0606417\n",
      "\tspeed: 0.0504s/iter; left time: 363.8252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 902 | Train Loss: 0.0640580 Vali Loss: 0.0962546 Test Loss: 0.1658105\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.060231514275074005, rmse:0.24542109668254852, mae:0.15826410055160522, rse:0.7208803296089172\n",
      "Intermediate time for ES and pred_len 168: 00h:19m:19.39s\n",
      "Intermediate time for ES: 00h:56m:56.97s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1754016\n",
      "\tspeed: 0.0559s/iter; left time: 1007.9014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1718795\n",
      "\tspeed: 0.0346s/iter; left time: 619.4958s\n",
      "\titers: 300, epoch: 1 | loss: 0.1623744\n",
      "\tspeed: 0.0345s/iter; left time: 615.5059s\n",
      "\titers: 400, epoch: 1 | loss: 0.1527693\n",
      "\tspeed: 0.0345s/iter; left time: 612.0520s\n",
      "\titers: 500, epoch: 1 | loss: 0.1545722\n",
      "\tspeed: 0.0345s/iter; left time: 608.5005s\n",
      "\titers: 600, epoch: 1 | loss: 0.1503175\n",
      "\tspeed: 0.0345s/iter; left time: 605.0299s\n",
      "\titers: 700, epoch: 1 | loss: 0.1476793\n",
      "\tspeed: 0.0345s/iter; left time: 601.1617s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516313\n",
      "\tspeed: 0.0345s/iter; left time: 597.7319s\n",
      "\titers: 900, epoch: 1 | loss: 0.1358661\n",
      "\tspeed: 0.0345s/iter; left time: 593.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.99s\n",
      "Steps: 906 | Train Loss: 0.1572264 Vali Loss: 0.1465191 Test Loss: 0.1681759\n",
      "Validation loss decreased (inf --> 0.146519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1367733\n",
      "\tspeed: 0.0988s/iter; left time: 1691.4399s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841815\n",
      "\tspeed: 0.0345s/iter; left time: 586.9984s\n",
      "\titers: 300, epoch: 2 | loss: 0.0651053\n",
      "\tspeed: 0.0345s/iter; left time: 583.7436s\n",
      "\titers: 400, epoch: 2 | loss: 0.0618266\n",
      "\tspeed: 0.0345s/iter; left time: 579.9539s\n",
      "\titers: 500, epoch: 2 | loss: 0.0634880\n",
      "\tspeed: 0.0342s/iter; left time: 571.3485s\n",
      "\titers: 600, epoch: 2 | loss: 0.0748803\n",
      "\tspeed: 0.0339s/iter; left time: 563.6168s\n",
      "\titers: 700, epoch: 2 | loss: 0.0605217\n",
      "\tspeed: 0.0339s/iter; left time: 559.9852s\n",
      "\titers: 800, epoch: 2 | loss: 0.0677919\n",
      "\tspeed: 0.0339s/iter; left time: 557.1336s\n",
      "\titers: 900, epoch: 2 | loss: 0.0628310\n",
      "\tspeed: 0.0339s/iter; left time: 553.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0795633 Vali Loss: 0.0664881 Test Loss: 0.0766027\n",
      "Validation loss decreased (0.146519 --> 0.066488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0596052\n",
      "\tspeed: 0.0963s/iter; left time: 1561.5185s\n",
      "\titers: 200, epoch: 3 | loss: 0.0513732\n",
      "\tspeed: 0.0339s/iter; left time: 546.1884s\n",
      "\titers: 300, epoch: 3 | loss: 0.0622984\n",
      "\tspeed: 0.0339s/iter; left time: 542.8349s\n",
      "\titers: 400, epoch: 3 | loss: 0.0550099\n",
      "\tspeed: 0.0339s/iter; left time: 539.8263s\n",
      "\titers: 500, epoch: 3 | loss: 0.0614815\n",
      "\tspeed: 0.0339s/iter; left time: 536.5546s\n",
      "\titers: 600, epoch: 3 | loss: 0.0572914\n",
      "\tspeed: 0.0340s/iter; left time: 533.4422s\n",
      "\titers: 700, epoch: 3 | loss: 0.0545936\n",
      "\tspeed: 0.0339s/iter; left time: 529.3358s\n",
      "\titers: 800, epoch: 3 | loss: 0.0497180\n",
      "\tspeed: 0.0340s/iter; left time: 527.2602s\n",
      "\titers: 900, epoch: 3 | loss: 0.0469406\n",
      "\tspeed: 0.0340s/iter; left time: 523.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0554530 Vali Loss: 0.0634343 Test Loss: 0.0724585\n",
      "Validation loss decreased (0.066488 --> 0.063434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495711\n",
      "\tspeed: 0.0963s/iter; left time: 1474.0030s\n",
      "\titers: 200, epoch: 4 | loss: 0.0469635\n",
      "\tspeed: 0.0340s/iter; left time: 516.6050s\n",
      "\titers: 300, epoch: 4 | loss: 0.0530830\n",
      "\tspeed: 0.0340s/iter; left time: 513.3490s\n",
      "\titers: 400, epoch: 4 | loss: 0.0561377\n",
      "\tspeed: 0.0340s/iter; left time: 509.8152s\n",
      "\titers: 500, epoch: 4 | loss: 0.0476814\n",
      "\tspeed: 0.0340s/iter; left time: 507.0071s\n",
      "\titers: 600, epoch: 4 | loss: 0.0456952\n",
      "\tspeed: 0.0340s/iter; left time: 503.4136s\n",
      "\titers: 700, epoch: 4 | loss: 0.0571596\n",
      "\tspeed: 0.0341s/iter; left time: 500.8640s\n",
      "\titers: 800, epoch: 4 | loss: 0.0540078\n",
      "\tspeed: 0.0340s/iter; left time: 496.0978s\n",
      "\titers: 900, epoch: 4 | loss: 0.0462834\n",
      "\tspeed: 0.0340s/iter; left time: 492.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0518115 Vali Loss: 0.0635223 Test Loss: 0.0695745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0488895\n",
      "\tspeed: 0.0948s/iter; left time: 1364.1187s\n",
      "\titers: 200, epoch: 5 | loss: 0.0499913\n",
      "\tspeed: 0.0339s/iter; left time: 485.1753s\n",
      "\titers: 300, epoch: 5 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 481.4244s\n",
      "\titers: 400, epoch: 5 | loss: 0.0502475\n",
      "\tspeed: 0.0339s/iter; left time: 478.0747s\n",
      "\titers: 500, epoch: 5 | loss: 0.0491475\n",
      "\tspeed: 0.0339s/iter; left time: 474.6270s\n",
      "\titers: 600, epoch: 5 | loss: 0.0568916\n",
      "\tspeed: 0.0339s/iter; left time: 471.4574s\n",
      "\titers: 700, epoch: 5 | loss: 0.0549902\n",
      "\tspeed: 0.0339s/iter; left time: 468.3713s\n",
      "\titers: 800, epoch: 5 | loss: 0.0451431\n",
      "\tspeed: 0.0340s/iter; left time: 465.8810s\n",
      "\titers: 900, epoch: 5 | loss: 0.0446936\n",
      "\tspeed: 0.0340s/iter; left time: 462.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.01s\n",
      "Steps: 906 | Train Loss: 0.0493321 Vali Loss: 0.0611000 Test Loss: 0.0659227\n",
      "Validation loss decreased (0.063434 --> 0.061100).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0444498\n",
      "\tspeed: 0.0979s/iter; left time: 1320.1492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0404346\n",
      "\tspeed: 0.0340s/iter; left time: 455.4152s\n",
      "\titers: 300, epoch: 6 | loss: 0.0465716\n",
      "\tspeed: 0.0341s/iter; left time: 452.5626s\n",
      "\titers: 400, epoch: 6 | loss: 0.0545136\n",
      "\tspeed: 0.0340s/iter; left time: 448.8263s\n",
      "\titers: 500, epoch: 6 | loss: 0.0427680\n",
      "\tspeed: 0.0340s/iter; left time: 445.3560s\n",
      "\titers: 600, epoch: 6 | loss: 0.0515021\n",
      "\tspeed: 0.0340s/iter; left time: 442.2144s\n",
      "\titers: 700, epoch: 6 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 438.8689s\n",
      "\titers: 800, epoch: 6 | loss: 0.0440863\n",
      "\tspeed: 0.0340s/iter; left time: 435.0576s\n",
      "\titers: 900, epoch: 6 | loss: 0.0484343\n",
      "\tspeed: 0.0340s/iter; left time: 431.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0473150 Vali Loss: 0.0597577 Test Loss: 0.0665739\n",
      "Validation loss decreased (0.061100 --> 0.059758).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0403488\n",
      "\tspeed: 0.0966s/iter; left time: 1215.3639s\n",
      "\titers: 200, epoch: 7 | loss: 0.0512392\n",
      "\tspeed: 0.0341s/iter; left time: 425.2229s\n",
      "\titers: 300, epoch: 7 | loss: 0.0439793\n",
      "\tspeed: 0.0340s/iter; left time: 421.6574s\n",
      "\titers: 400, epoch: 7 | loss: 0.0472125\n",
      "\tspeed: 0.0341s/iter; left time: 419.0718s\n",
      "\titers: 500, epoch: 7 | loss: 0.0420035\n",
      "\tspeed: 0.0341s/iter; left time: 415.1392s\n",
      "\titers: 600, epoch: 7 | loss: 0.0384621\n",
      "\tspeed: 0.0340s/iter; left time: 411.1737s\n",
      "\titers: 700, epoch: 7 | loss: 0.0459063\n",
      "\tspeed: 0.0340s/iter; left time: 407.8058s\n",
      "\titers: 800, epoch: 7 | loss: 0.0440278\n",
      "\tspeed: 0.0340s/iter; left time: 404.4169s\n",
      "\titers: 900, epoch: 7 | loss: 0.0393112\n",
      "\tspeed: 0.0341s/iter; left time: 401.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0454778 Vali Loss: 0.0590582 Test Loss: 0.0647275\n",
      "Validation loss decreased (0.059758 --> 0.059058).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406533\n",
      "\tspeed: 0.0963s/iter; left time: 1124.3786s\n",
      "\titers: 200, epoch: 8 | loss: 0.0469764\n",
      "\tspeed: 0.0340s/iter; left time: 393.9680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0392994\n",
      "\tspeed: 0.0341s/iter; left time: 390.9760s\n",
      "\titers: 400, epoch: 8 | loss: 0.0500969\n",
      "\tspeed: 0.0340s/iter; left time: 386.7208s\n",
      "\titers: 500, epoch: 8 | loss: 0.0434114\n",
      "\tspeed: 0.0341s/iter; left time: 384.0735s\n",
      "\titers: 600, epoch: 8 | loss: 0.0427843\n",
      "\tspeed: 0.0340s/iter; left time: 380.4872s\n",
      "\titers: 700, epoch: 8 | loss: 0.0442753\n",
      "\tspeed: 0.0340s/iter; left time: 377.0512s\n",
      "\titers: 800, epoch: 8 | loss: 0.0417612\n",
      "\tspeed: 0.0341s/iter; left time: 373.8817s\n",
      "\titers: 900, epoch: 8 | loss: 0.0468672\n",
      "\tspeed: 0.0340s/iter; left time: 370.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0443256 Vali Loss: 0.0590278 Test Loss: 0.0666126\n",
      "Validation loss decreased (0.059058 --> 0.059028).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409645\n",
      "\tspeed: 0.0981s/iter; left time: 1056.9135s\n",
      "\titers: 200, epoch: 9 | loss: 0.0432575\n",
      "\tspeed: 0.0340s/iter; left time: 363.3648s\n",
      "\titers: 300, epoch: 9 | loss: 0.0464971\n",
      "\tspeed: 0.0340s/iter; left time: 359.6136s\n",
      "\titers: 400, epoch: 9 | loss: 0.0420422\n",
      "\tspeed: 0.0340s/iter; left time: 356.5808s\n",
      "\titers: 500, epoch: 9 | loss: 0.0445137\n",
      "\tspeed: 0.0340s/iter; left time: 352.9895s\n",
      "\titers: 600, epoch: 9 | loss: 0.0377047\n",
      "\tspeed: 0.0340s/iter; left time: 349.1521s\n",
      "\titers: 700, epoch: 9 | loss: 0.0373535\n",
      "\tspeed: 0.0340s/iter; left time: 345.8586s\n",
      "\titers: 800, epoch: 9 | loss: 0.0378851\n",
      "\tspeed: 0.0341s/iter; left time: 343.0847s\n",
      "\titers: 900, epoch: 9 | loss: 0.0343114\n",
      "\tspeed: 0.0340s/iter; left time: 339.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0427961 Vali Loss: 0.0573571 Test Loss: 0.0648689\n",
      "Validation loss decreased (0.059028 --> 0.057357).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0417384\n",
      "\tspeed: 0.0961s/iter; left time: 948.5302s\n",
      "\titers: 200, epoch: 10 | loss: 0.0398730\n",
      "\tspeed: 0.0341s/iter; left time: 332.5684s\n",
      "\titers: 300, epoch: 10 | loss: 0.0431907\n",
      "\tspeed: 0.0341s/iter; left time: 329.3007s\n",
      "\titers: 400, epoch: 10 | loss: 0.0450556\n",
      "\tspeed: 0.0340s/iter; left time: 325.5051s\n",
      "\titers: 500, epoch: 10 | loss: 0.0350549\n",
      "\tspeed: 0.0340s/iter; left time: 321.8316s\n",
      "\titers: 600, epoch: 10 | loss: 0.0404603\n",
      "\tspeed: 0.0340s/iter; left time: 318.3607s\n",
      "\titers: 700, epoch: 10 | loss: 0.0432734\n",
      "\tspeed: 0.0340s/iter; left time: 315.3881s\n",
      "\titers: 800, epoch: 10 | loss: 0.0391883\n",
      "\tspeed: 0.0340s/iter; left time: 311.7923s\n",
      "\titers: 900, epoch: 10 | loss: 0.0427314\n",
      "\tspeed: 0.0340s/iter; left time: 308.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0417776 Vali Loss: 0.0574123 Test Loss: 0.0637241\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417736\n",
      "\tspeed: 0.0940s/iter; left time: 842.1604s\n",
      "\titers: 200, epoch: 11 | loss: 0.0475188\n",
      "\tspeed: 0.0346s/iter; left time: 306.1956s\n",
      "\titers: 300, epoch: 11 | loss: 0.0371066\n",
      "\tspeed: 0.0345s/iter; left time: 302.6752s\n",
      "\titers: 400, epoch: 11 | loss: 0.0418829\n",
      "\tspeed: 0.0346s/iter; left time: 299.4190s\n",
      "\titers: 500, epoch: 11 | loss: 0.0450594\n",
      "\tspeed: 0.0345s/iter; left time: 295.7692s\n",
      "\titers: 600, epoch: 11 | loss: 0.0439484\n",
      "\tspeed: 0.0346s/iter; left time: 292.4431s\n",
      "\titers: 700, epoch: 11 | loss: 0.0418536\n",
      "\tspeed: 0.0347s/iter; left time: 290.4458s\n",
      "\titers: 800, epoch: 11 | loss: 0.0409613\n",
      "\tspeed: 0.0346s/iter; left time: 285.9516s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418191\n",
      "\tspeed: 0.0346s/iter; left time: 282.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0406990 Vali Loss: 0.0576143 Test Loss: 0.0632747\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0370599\n",
      "\tspeed: 0.0946s/iter; left time: 761.8586s\n",
      "\titers: 200, epoch: 12 | loss: 0.0422251\n",
      "\tspeed: 0.0341s/iter; left time: 270.9392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0389508\n",
      "\tspeed: 0.0340s/iter; left time: 267.0887s\n",
      "\titers: 400, epoch: 12 | loss: 0.0401749\n",
      "\tspeed: 0.0340s/iter; left time: 263.7060s\n",
      "\titers: 500, epoch: 12 | loss: 0.0385777\n",
      "\tspeed: 0.0340s/iter; left time: 260.1403s\n",
      "\titers: 600, epoch: 12 | loss: 0.0389454\n",
      "\tspeed: 0.0339s/iter; left time: 256.3173s\n",
      "\titers: 700, epoch: 12 | loss: 0.0357124\n",
      "\tspeed: 0.0340s/iter; left time: 253.4781s\n",
      "\titers: 800, epoch: 12 | loss: 0.0377932\n",
      "\tspeed: 0.0340s/iter; left time: 250.0363s\n",
      "\titers: 900, epoch: 12 | loss: 0.0412504\n",
      "\tspeed: 0.0340s/iter; left time: 246.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0396205 Vali Loss: 0.0564137 Test Loss: 0.0632015\n",
      "Validation loss decreased (0.057357 --> 0.056414).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0420268\n",
      "\tspeed: 0.0988s/iter; left time: 706.5339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0387494\n",
      "\tspeed: 0.0340s/iter; left time: 239.5933s\n",
      "\titers: 300, epoch: 13 | loss: 0.0355878\n",
      "\tspeed: 0.0340s/iter; left time: 236.3251s\n",
      "\titers: 400, epoch: 13 | loss: 0.0343830\n",
      "\tspeed: 0.0339s/iter; left time: 232.1565s\n",
      "\titers: 500, epoch: 13 | loss: 0.0421653\n",
      "\tspeed: 0.0340s/iter; left time: 229.2012s\n",
      "\titers: 600, epoch: 13 | loss: 0.0360691\n",
      "\tspeed: 0.0339s/iter; left time: 225.5456s\n",
      "\titers: 700, epoch: 13 | loss: 0.0363027\n",
      "\tspeed: 0.0340s/iter; left time: 222.5785s\n",
      "\titers: 800, epoch: 13 | loss: 0.0376486\n",
      "\tspeed: 0.0339s/iter; left time: 218.7247s\n",
      "\titers: 900, epoch: 13 | loss: 0.0431237\n",
      "\tspeed: 0.0340s/iter; left time: 215.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0385994 Vali Loss: 0.0564743 Test Loss: 0.0633992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0412338\n",
      "\tspeed: 0.0937s/iter; left time: 584.9274s\n",
      "\titers: 200, epoch: 14 | loss: 0.0365248\n",
      "\tspeed: 0.0339s/iter; left time: 208.4826s\n",
      "\titers: 300, epoch: 14 | loss: 0.0365122\n",
      "\tspeed: 0.0340s/iter; left time: 205.2606s\n",
      "\titers: 400, epoch: 14 | loss: 0.0376992\n",
      "\tspeed: 0.0340s/iter; left time: 202.1956s\n",
      "\titers: 500, epoch: 14 | loss: 0.0416844\n",
      "\tspeed: 0.0340s/iter; left time: 198.5506s\n",
      "\titers: 600, epoch: 14 | loss: 0.0383253\n",
      "\tspeed: 0.0339s/iter; left time: 194.8081s\n",
      "\titers: 700, epoch: 14 | loss: 0.0366903\n",
      "\tspeed: 0.0341s/iter; left time: 192.1697s\n",
      "\titers: 800, epoch: 14 | loss: 0.0462296\n",
      "\tspeed: 0.0340s/iter; left time: 188.3393s\n",
      "\titers: 900, epoch: 14 | loss: 0.0353763\n",
      "\tspeed: 0.0340s/iter; left time: 185.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0376544 Vali Loss: 0.0559921 Test Loss: 0.0616274\n",
      "Validation loss decreased (0.056414 --> 0.055992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0385241\n",
      "\tspeed: 0.0967s/iter; left time: 516.1917s\n",
      "\titers: 200, epoch: 15 | loss: 0.0367979\n",
      "\tspeed: 0.0339s/iter; left time: 177.7850s\n",
      "\titers: 300, epoch: 15 | loss: 0.0331814\n",
      "\tspeed: 0.0340s/iter; left time: 174.4053s\n",
      "\titers: 400, epoch: 15 | loss: 0.0364987\n",
      "\tspeed: 0.0340s/iter; left time: 171.0100s\n",
      "\titers: 500, epoch: 15 | loss: 0.0332029\n",
      "\tspeed: 0.0340s/iter; left time: 168.0468s\n",
      "\titers: 600, epoch: 15 | loss: 0.0384601\n",
      "\tspeed: 0.0339s/iter; left time: 163.9847s\n",
      "\titers: 700, epoch: 15 | loss: 0.0368570\n",
      "\tspeed: 0.0339s/iter; left time: 160.6274s\n",
      "\titers: 800, epoch: 15 | loss: 0.0354397\n",
      "\tspeed: 0.0339s/iter; left time: 157.0704s\n",
      "\titers: 900, epoch: 15 | loss: 0.0366562\n",
      "\tspeed: 0.0339s/iter; left time: 153.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0369873 Vali Loss: 0.0558398 Test Loss: 0.0628962\n",
      "Validation loss decreased (0.055992 --> 0.055840).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0392919\n",
      "\tspeed: 0.0961s/iter; left time: 426.0157s\n",
      "\titers: 200, epoch: 16 | loss: 0.0445064\n",
      "\tspeed: 0.0339s/iter; left time: 146.8060s\n",
      "\titers: 300, epoch: 16 | loss: 0.0404944\n",
      "\tspeed: 0.0339s/iter; left time: 143.4647s\n",
      "\titers: 400, epoch: 16 | loss: 0.0348784\n",
      "\tspeed: 0.0339s/iter; left time: 140.0167s\n",
      "\titers: 500, epoch: 16 | loss: 0.0308083\n",
      "\tspeed: 0.0340s/iter; left time: 136.9805s\n",
      "\titers: 600, epoch: 16 | loss: 0.0367714\n",
      "\tspeed: 0.0339s/iter; left time: 133.3032s\n",
      "\titers: 700, epoch: 16 | loss: 0.0356430\n",
      "\tspeed: 0.0339s/iter; left time: 129.9085s\n",
      "\titers: 800, epoch: 16 | loss: 0.0364897\n",
      "\tspeed: 0.0340s/iter; left time: 126.9509s\n",
      "\titers: 900, epoch: 16 | loss: 0.0351077\n",
      "\tspeed: 0.0340s/iter; left time: 123.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0361995 Vali Loss: 0.0570393 Test Loss: 0.0630939\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0382720\n",
      "\tspeed: 0.0941s/iter; left time: 331.8666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0357151\n",
      "\tspeed: 0.0340s/iter; left time: 116.4433s\n",
      "\titers: 300, epoch: 17 | loss: 0.0355730\n",
      "\tspeed: 0.0340s/iter; left time: 113.2038s\n",
      "\titers: 400, epoch: 17 | loss: 0.0348953\n",
      "\tspeed: 0.0345s/iter; left time: 111.3173s\n",
      "\titers: 500, epoch: 17 | loss: 0.0320778\n",
      "\tspeed: 0.0345s/iter; left time: 107.8330s\n",
      "\titers: 600, epoch: 17 | loss: 0.0328302\n",
      "\tspeed: 0.0345s/iter; left time: 104.5112s\n",
      "\titers: 700, epoch: 17 | loss: 0.0377763\n",
      "\tspeed: 0.0345s/iter; left time: 100.9964s\n",
      "\titers: 800, epoch: 17 | loss: 0.0368321\n",
      "\tspeed: 0.0346s/iter; left time: 97.6821s\n",
      "\titers: 900, epoch: 17 | loss: 0.0395076\n",
      "\tspeed: 0.0345s/iter; left time: 93.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0355288 Vali Loss: 0.0563765 Test Loss: 0.0635618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0334214\n",
      "\tspeed: 0.0942s/iter; left time: 246.8353s\n",
      "\titers: 200, epoch: 18 | loss: 0.0349425\n",
      "\tspeed: 0.0341s/iter; left time: 85.7858s\n",
      "\titers: 300, epoch: 18 | loss: 0.0340762\n",
      "\tspeed: 0.0341s/iter; left time: 82.3672s\n",
      "\titers: 400, epoch: 18 | loss: 0.0363117\n",
      "\tspeed: 0.0341s/iter; left time: 78.9903s\n",
      "\titers: 500, epoch: 18 | loss: 0.0395520\n",
      "\tspeed: 0.0340s/iter; left time: 75.5496s\n",
      "\titers: 600, epoch: 18 | loss: 0.0366950\n",
      "\tspeed: 0.0341s/iter; left time: 72.1646s\n",
      "\titers: 700, epoch: 18 | loss: 0.0427621\n",
      "\tspeed: 0.0340s/iter; left time: 68.7282s\n",
      "\titers: 800, epoch: 18 | loss: 0.0320136\n",
      "\tspeed: 0.0340s/iter; left time: 65.3171s\n",
      "\titers: 900, epoch: 18 | loss: 0.0407823\n",
      "\tspeed: 0.0341s/iter; left time: 61.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0349199 Vali Loss: 0.0566797 Test Loss: 0.0626437\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0350009\n",
      "\tspeed: 0.0930s/iter; left time: 159.3698s\n",
      "\titers: 200, epoch: 19 | loss: 0.0359370\n",
      "\tspeed: 0.0340s/iter; left time: 54.8002s\n",
      "\titers: 300, epoch: 19 | loss: 0.0364045\n",
      "\tspeed: 0.0340s/iter; left time: 51.4413s\n",
      "\titers: 400, epoch: 19 | loss: 0.0337826\n",
      "\tspeed: 0.0340s/iter; left time: 47.9738s\n",
      "\titers: 500, epoch: 19 | loss: 0.0354946\n",
      "\tspeed: 0.0340s/iter; left time: 44.6339s\n",
      "\titers: 600, epoch: 19 | loss: 0.0339434\n",
      "\tspeed: 0.0340s/iter; left time: 41.2057s\n",
      "\titers: 700, epoch: 19 | loss: 0.0348568\n",
      "\tspeed: 0.0340s/iter; left time: 37.8161s\n",
      "\titers: 800, epoch: 19 | loss: 0.0328255\n",
      "\tspeed: 0.0340s/iter; left time: 34.4323s\n",
      "\titers: 900, epoch: 19 | loss: 0.0363572\n",
      "\tspeed: 0.0340s/iter; left time: 31.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0345114 Vali Loss: 0.0565572 Test Loss: 0.0630916\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0393753\n",
      "\tspeed: 0.0944s/iter; left time: 76.2104s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383313\n",
      "\tspeed: 0.0339s/iter; left time: 23.9371s\n",
      "\titers: 300, epoch: 20 | loss: 0.0362157\n",
      "\tspeed: 0.0339s/iter; left time: 20.5805s\n",
      "\titers: 400, epoch: 20 | loss: 0.0314259\n",
      "\tspeed: 0.0340s/iter; left time: 17.2133s\n",
      "\titers: 500, epoch: 20 | loss: 0.0358881\n",
      "\tspeed: 0.0340s/iter; left time: 13.8198s\n",
      "\titers: 600, epoch: 20 | loss: 0.0343928\n",
      "\tspeed: 0.0340s/iter; left time: 10.4321s\n",
      "\titers: 700, epoch: 20 | loss: 0.0340157\n",
      "\tspeed: 0.0339s/iter; left time: 7.0263s\n",
      "\titers: 800, epoch: 20 | loss: 0.0352002\n",
      "\tspeed: 0.0339s/iter; left time: 3.6284s\n",
      "\titers: 900, epoch: 20 | loss: 0.0332215\n",
      "\tspeed: 0.0340s/iter; left time: 0.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0340116 Vali Loss: 0.0563868 Test Loss: 0.0630755\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012454495765268803, rmse:0.11159971356391907, mae:0.06283904612064362, rse:0.4306430518627167\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1799639\n",
      "\tspeed: 0.0362s/iter; left time: 652.4446s\n",
      "\titers: 200, epoch: 1 | loss: 0.1643134\n",
      "\tspeed: 0.0340s/iter; left time: 610.0871s\n",
      "\titers: 300, epoch: 1 | loss: 0.1678073\n",
      "\tspeed: 0.0340s/iter; left time: 606.4789s\n",
      "\titers: 400, epoch: 1 | loss: 0.1560568\n",
      "\tspeed: 0.0340s/iter; left time: 603.2615s\n",
      "\titers: 500, epoch: 1 | loss: 0.1497856\n",
      "\tspeed: 0.0340s/iter; left time: 599.3590s\n",
      "\titers: 600, epoch: 1 | loss: 0.1513730\n",
      "\tspeed: 0.0340s/iter; left time: 596.2770s\n",
      "\titers: 700, epoch: 1 | loss: 0.1495658\n",
      "\tspeed: 0.0341s/iter; left time: 593.4248s\n",
      "\titers: 800, epoch: 1 | loss: 0.1475314\n",
      "\tspeed: 0.0340s/iter; left time: 589.2816s\n",
      "\titers: 900, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0340s/iter; left time: 586.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.1621176 Vali Loss: 0.1434601 Test Loss: 0.1637105\n",
      "Validation loss decreased (inf --> 0.143460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1280499\n",
      "\tspeed: 0.0969s/iter; left time: 1658.2526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0996244\n",
      "\tspeed: 0.0341s/iter; left time: 580.6063s\n",
      "\titers: 300, epoch: 2 | loss: 0.1066693\n",
      "\tspeed: 0.0341s/iter; left time: 576.4870s\n",
      "\titers: 400, epoch: 2 | loss: 0.0870007\n",
      "\tspeed: 0.0341s/iter; left time: 573.9577s\n",
      "\titers: 500, epoch: 2 | loss: 0.0831003\n",
      "\tspeed: 0.0341s/iter; left time: 570.0731s\n",
      "\titers: 600, epoch: 2 | loss: 0.0833607\n",
      "\tspeed: 0.0341s/iter; left time: 566.2976s\n",
      "\titers: 700, epoch: 2 | loss: 0.0783962\n",
      "\tspeed: 0.0340s/iter; left time: 561.6904s\n",
      "\titers: 800, epoch: 2 | loss: 0.0747123\n",
      "\tspeed: 0.0340s/iter; left time: 558.8937s\n",
      "\titers: 900, epoch: 2 | loss: 0.0690103\n",
      "\tspeed: 0.0341s/iter; left time: 555.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0950980 Vali Loss: 0.0901362 Test Loss: 0.1025138\n",
      "Validation loss decreased (0.143460 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686186\n",
      "\tspeed: 0.0970s/iter; left time: 1573.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774667\n",
      "\tspeed: 0.0340s/iter; left time: 547.6336s\n",
      "\titers: 300, epoch: 3 | loss: 0.0744100\n",
      "\tspeed: 0.0341s/iter; left time: 545.1095s\n",
      "\titers: 400, epoch: 3 | loss: 0.0659564\n",
      "\tspeed: 0.0340s/iter; left time: 540.8907s\n",
      "\titers: 500, epoch: 3 | loss: 0.0685518\n",
      "\tspeed: 0.0340s/iter; left time: 538.1349s\n",
      "\titers: 600, epoch: 3 | loss: 0.0650003\n",
      "\tspeed: 0.0340s/iter; left time: 534.8691s\n",
      "\titers: 700, epoch: 3 | loss: 0.0603844\n",
      "\tspeed: 0.0340s/iter; left time: 531.0855s\n",
      "\titers: 800, epoch: 3 | loss: 0.0562463\n",
      "\tspeed: 0.0340s/iter; left time: 527.6460s\n",
      "\titers: 900, epoch: 3 | loss: 0.0498774\n",
      "\tspeed: 0.0341s/iter; left time: 524.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0693412 Vali Loss: 0.0679662 Test Loss: 0.0759230\n",
      "Validation loss decreased (0.090136 --> 0.067966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609032\n",
      "\tspeed: 0.1011s/iter; left time: 1547.7745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538243\n",
      "\tspeed: 0.0341s/iter; left time: 517.9878s\n",
      "\titers: 300, epoch: 4 | loss: 0.0516822\n",
      "\tspeed: 0.0341s/iter; left time: 514.3943s\n",
      "\titers: 400, epoch: 4 | loss: 0.0576723\n",
      "\tspeed: 0.0340s/iter; left time: 510.6228s\n",
      "\titers: 500, epoch: 4 | loss: 0.0511567\n",
      "\tspeed: 0.0340s/iter; left time: 506.6648s\n",
      "\titers: 600, epoch: 4 | loss: 0.0473879\n",
      "\tspeed: 0.0340s/iter; left time: 503.3008s\n",
      "\titers: 700, epoch: 4 | loss: 0.0561181\n",
      "\tspeed: 0.0341s/iter; left time: 500.8967s\n",
      "\titers: 800, epoch: 4 | loss: 0.0411501\n",
      "\tspeed: 0.0340s/iter; left time: 496.7483s\n",
      "\titers: 900, epoch: 4 | loss: 0.0510259\n",
      "\tspeed: 0.0341s/iter; left time: 493.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0531958 Vali Loss: 0.0632272 Test Loss: 0.0694707\n",
      "Validation loss decreased (0.067966 --> 0.063227).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619297\n",
      "\tspeed: 0.0968s/iter; left time: 1393.6483s\n",
      "\titers: 200, epoch: 5 | loss: 0.0546464\n",
      "\tspeed: 0.0340s/iter; left time: 486.8072s\n",
      "\titers: 300, epoch: 5 | loss: 0.0613711\n",
      "\tspeed: 0.0341s/iter; left time: 483.9119s\n",
      "\titers: 400, epoch: 5 | loss: 0.0470468\n",
      "\tspeed: 0.0341s/iter; left time: 480.5576s\n",
      "\titers: 500, epoch: 5 | loss: 0.0465499\n",
      "\tspeed: 0.0341s/iter; left time: 477.5381s\n",
      "\titers: 600, epoch: 5 | loss: 0.0433100\n",
      "\tspeed: 0.0341s/iter; left time: 474.1792s\n",
      "\titers: 700, epoch: 5 | loss: 0.0539502\n",
      "\tspeed: 0.0341s/iter; left time: 470.8634s\n",
      "\titers: 800, epoch: 5 | loss: 0.0489548\n",
      "\tspeed: 0.0341s/iter; left time: 467.0049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0480206\n",
      "\tspeed: 0.0340s/iter; left time: 462.8215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0503956 Vali Loss: 0.0638788 Test Loss: 0.0694296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0558476\n",
      "\tspeed: 0.0931s/iter; left time: 1255.5520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0517960\n",
      "\tspeed: 0.0341s/iter; left time: 456.0462s\n",
      "\titers: 300, epoch: 6 | loss: 0.0477182\n",
      "\tspeed: 0.0340s/iter; left time: 451.8443s\n",
      "\titers: 400, epoch: 6 | loss: 0.0510341\n",
      "\tspeed: 0.0340s/iter; left time: 449.0183s\n",
      "\titers: 500, epoch: 6 | loss: 0.0578296\n",
      "\tspeed: 0.0341s/iter; left time: 446.2099s\n",
      "\titers: 600, epoch: 6 | loss: 0.0474456\n",
      "\tspeed: 0.0340s/iter; left time: 442.1500s\n",
      "\titers: 700, epoch: 6 | loss: 0.0449998\n",
      "\tspeed: 0.0340s/iter; left time: 438.3822s\n",
      "\titers: 800, epoch: 6 | loss: 0.0488756\n",
      "\tspeed: 0.0341s/iter; left time: 435.7082s\n",
      "\titers: 900, epoch: 6 | loss: 0.0458535\n",
      "\tspeed: 0.0341s/iter; left time: 432.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0484827 Vali Loss: 0.0618802 Test Loss: 0.0675384\n",
      "Validation loss decreased (0.063227 --> 0.061880).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504562\n",
      "\tspeed: 0.0961s/iter; left time: 1209.5752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0376698\n",
      "\tspeed: 0.0340s/iter; left time: 424.8540s\n",
      "\titers: 300, epoch: 7 | loss: 0.0475422\n",
      "\tspeed: 0.0340s/iter; left time: 421.4028s\n",
      "\titers: 400, epoch: 7 | loss: 0.0474081\n",
      "\tspeed: 0.0340s/iter; left time: 417.7398s\n",
      "\titers: 500, epoch: 7 | loss: 0.0480068\n",
      "\tspeed: 0.0341s/iter; left time: 415.1552s\n",
      "\titers: 600, epoch: 7 | loss: 0.0499294\n",
      "\tspeed: 0.0340s/iter; left time: 411.3285s\n",
      "\titers: 700, epoch: 7 | loss: 0.0466667\n",
      "\tspeed: 0.0341s/iter; left time: 409.0004s\n",
      "\titers: 800, epoch: 7 | loss: 0.0481679\n",
      "\tspeed: 0.0347s/iter; left time: 412.2438s\n",
      "\titers: 900, epoch: 7 | loss: 0.0472499\n",
      "\tspeed: 0.0346s/iter; left time: 408.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 906 | Train Loss: 0.0468621 Vali Loss: 0.0617771 Test Loss: 0.0675191\n",
      "Validation loss decreased (0.061880 --> 0.061777).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513489\n",
      "\tspeed: 0.0969s/iter; left time: 1132.0153s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440349\n",
      "\tspeed: 0.0341s/iter; left time: 394.6745s\n",
      "\titers: 300, epoch: 8 | loss: 0.0446530\n",
      "\tspeed: 0.0340s/iter; left time: 390.7435s\n",
      "\titers: 400, epoch: 8 | loss: 0.0405290\n",
      "\tspeed: 0.0340s/iter; left time: 387.3347s\n",
      "\titers: 500, epoch: 8 | loss: 0.0435242\n",
      "\tspeed: 0.0341s/iter; left time: 384.3399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0423415\n",
      "\tspeed: 0.0340s/iter; left time: 380.4947s\n",
      "\titers: 700, epoch: 8 | loss: 0.0417117\n",
      "\tspeed: 0.0341s/iter; left time: 377.3020s\n",
      "\titers: 800, epoch: 8 | loss: 0.0462200\n",
      "\tspeed: 0.0341s/iter; left time: 374.0436s\n",
      "\titers: 900, epoch: 8 | loss: 0.0429036\n",
      "\tspeed: 0.0340s/iter; left time: 370.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0452779 Vali Loss: 0.0590413 Test Loss: 0.0656133\n",
      "Validation loss decreased (0.061777 --> 0.059041).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0433994\n",
      "\tspeed: 0.0971s/iter; left time: 1045.5309s\n",
      "\titers: 200, epoch: 9 | loss: 0.0410988\n",
      "\tspeed: 0.0340s/iter; left time: 363.1287s\n",
      "\titers: 300, epoch: 9 | loss: 0.0437933\n",
      "\tspeed: 0.0340s/iter; left time: 359.9408s\n",
      "\titers: 400, epoch: 9 | loss: 0.0443417\n",
      "\tspeed: 0.0340s/iter; left time: 356.3902s\n",
      "\titers: 500, epoch: 9 | loss: 0.0440277\n",
      "\tspeed: 0.0340s/iter; left time: 353.1507s\n",
      "\titers: 600, epoch: 9 | loss: 0.0452474\n",
      "\tspeed: 0.0340s/iter; left time: 349.6943s\n",
      "\titers: 700, epoch: 9 | loss: 0.0401173\n",
      "\tspeed: 0.0341s/iter; left time: 346.4884s\n",
      "\titers: 800, epoch: 9 | loss: 0.0455280\n",
      "\tspeed: 0.0340s/iter; left time: 342.8749s\n",
      "\titers: 900, epoch: 9 | loss: 0.0525242\n",
      "\tspeed: 0.0340s/iter; left time: 339.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0436650 Vali Loss: 0.0592790 Test Loss: 0.0648833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0408640\n",
      "\tspeed: 0.0932s/iter; left time: 919.7983s\n",
      "\titers: 200, epoch: 10 | loss: 0.0427431\n",
      "\tspeed: 0.0341s/iter; left time: 332.7807s\n",
      "\titers: 300, epoch: 10 | loss: 0.0461511\n",
      "\tspeed: 0.0340s/iter; left time: 328.8849s\n",
      "\titers: 400, epoch: 10 | loss: 0.0389742\n",
      "\tspeed: 0.0340s/iter; left time: 325.4653s\n",
      "\titers: 500, epoch: 10 | loss: 0.0366748\n",
      "\tspeed: 0.0340s/iter; left time: 322.2732s\n",
      "\titers: 600, epoch: 10 | loss: 0.0407804\n",
      "\tspeed: 0.0340s/iter; left time: 318.5451s\n",
      "\titers: 700, epoch: 10 | loss: 0.0439256\n",
      "\tspeed: 0.0341s/iter; left time: 315.6877s\n",
      "\titers: 800, epoch: 10 | loss: 0.0396320\n",
      "\tspeed: 0.0340s/iter; left time: 311.9610s\n",
      "\titers: 900, epoch: 10 | loss: 0.0464057\n",
      "\tspeed: 0.0341s/iter; left time: 308.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0421371 Vali Loss: 0.0582751 Test Loss: 0.0668456\n",
      "Validation loss decreased (0.059041 --> 0.058275).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0364203\n",
      "\tspeed: 0.0983s/iter; left time: 881.0335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0393139\n",
      "\tspeed: 0.0346s/iter; left time: 306.7814s\n",
      "\titers: 300, epoch: 11 | loss: 0.0412469\n",
      "\tspeed: 0.0347s/iter; left time: 303.6201s\n",
      "\titers: 400, epoch: 11 | loss: 0.0424502\n",
      "\tspeed: 0.0344s/iter; left time: 298.1432s\n",
      "\titers: 500, epoch: 11 | loss: 0.0420882\n",
      "\tspeed: 0.0341s/iter; left time: 291.6435s\n",
      "\titers: 600, epoch: 11 | loss: 0.0404220\n",
      "\tspeed: 0.0340s/iter; left time: 287.9176s\n",
      "\titers: 700, epoch: 11 | loss: 0.0364543\n",
      "\tspeed: 0.0340s/iter; left time: 284.3522s\n",
      "\titers: 800, epoch: 11 | loss: 0.0391739\n",
      "\tspeed: 0.0341s/iter; left time: 281.5530s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418266\n",
      "\tspeed: 0.0341s/iter; left time: 277.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.33s\n",
      "Steps: 906 | Train Loss: 0.0407368 Vali Loss: 0.0578185 Test Loss: 0.0662903\n",
      "Validation loss decreased (0.058275 --> 0.057818).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0390506\n",
      "\tspeed: 0.0988s/iter; left time: 795.8017s\n",
      "\titers: 200, epoch: 12 | loss: 0.0443430\n",
      "\tspeed: 0.0341s/iter; left time: 271.1316s\n",
      "\titers: 300, epoch: 12 | loss: 0.0402047\n",
      "\tspeed: 0.0341s/iter; left time: 267.5208s\n",
      "\titers: 400, epoch: 12 | loss: 0.0388500\n",
      "\tspeed: 0.0341s/iter; left time: 264.2932s\n",
      "\titers: 500, epoch: 12 | loss: 0.0390783\n",
      "\tspeed: 0.0341s/iter; left time: 260.9770s\n",
      "\titers: 600, epoch: 12 | loss: 0.0352140\n",
      "\tspeed: 0.0341s/iter; left time: 257.9070s\n",
      "\titers: 700, epoch: 12 | loss: 0.0395783\n",
      "\tspeed: 0.0341s/iter; left time: 254.4347s\n",
      "\titers: 800, epoch: 12 | loss: 0.0411608\n",
      "\tspeed: 0.0341s/iter; left time: 250.6289s\n",
      "\titers: 900, epoch: 12 | loss: 0.0375333\n",
      "\tspeed: 0.0341s/iter; left time: 247.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0397211 Vali Loss: 0.0578994 Test Loss: 0.0657681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463221\n",
      "\tspeed: 0.0943s/iter; left time: 674.1530s\n",
      "\titers: 200, epoch: 13 | loss: 0.0320999\n",
      "\tspeed: 0.0341s/iter; left time: 240.3496s\n",
      "\titers: 300, epoch: 13 | loss: 0.0338570\n",
      "\tspeed: 0.0340s/iter; left time: 236.4549s\n",
      "\titers: 400, epoch: 13 | loss: 0.0367805\n",
      "\tspeed: 0.0340s/iter; left time: 232.9457s\n",
      "\titers: 500, epoch: 13 | loss: 0.0399524\n",
      "\tspeed: 0.0340s/iter; left time: 229.3342s\n",
      "\titers: 600, epoch: 13 | loss: 0.0407709\n",
      "\tspeed: 0.0340s/iter; left time: 226.0676s\n",
      "\titers: 700, epoch: 13 | loss: 0.0385915\n",
      "\tspeed: 0.0340s/iter; left time: 222.9273s\n",
      "\titers: 800, epoch: 13 | loss: 0.0377566\n",
      "\tspeed: 0.0341s/iter; left time: 219.7198s\n",
      "\titers: 900, epoch: 13 | loss: 0.0359108\n",
      "\tspeed: 0.0341s/iter; left time: 216.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0386944 Vali Loss: 0.0576511 Test Loss: 0.0644637\n",
      "Validation loss decreased (0.057818 --> 0.057651).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0370453\n",
      "\tspeed: 0.0966s/iter; left time: 603.2771s\n",
      "\titers: 200, epoch: 14 | loss: 0.0355818\n",
      "\tspeed: 0.0341s/iter; left time: 209.5007s\n",
      "\titers: 300, epoch: 14 | loss: 0.0373862\n",
      "\tspeed: 0.0341s/iter; left time: 206.0621s\n",
      "\titers: 400, epoch: 14 | loss: 0.0363934\n",
      "\tspeed: 0.0341s/iter; left time: 202.8280s\n",
      "\titers: 500, epoch: 14 | loss: 0.0408763\n",
      "\tspeed: 0.0341s/iter; left time: 199.0434s\n",
      "\titers: 600, epoch: 14 | loss: 0.0316915\n",
      "\tspeed: 0.0341s/iter; left time: 195.7352s\n",
      "\titers: 700, epoch: 14 | loss: 0.0352258\n",
      "\tspeed: 0.0340s/iter; left time: 191.6210s\n",
      "\titers: 800, epoch: 14 | loss: 0.0406870\n",
      "\tspeed: 0.0340s/iter; left time: 188.4585s\n",
      "\titers: 900, epoch: 14 | loss: 0.0330149\n",
      "\tspeed: 0.0341s/iter; left time: 185.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0376825 Vali Loss: 0.0588694 Test Loss: 0.0671663\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0404172\n",
      "\tspeed: 0.0934s/iter; left time: 498.3921s\n",
      "\titers: 200, epoch: 15 | loss: 0.0358362\n",
      "\tspeed: 0.0339s/iter; left time: 177.7817s\n",
      "\titers: 300, epoch: 15 | loss: 0.0366841\n",
      "\tspeed: 0.0340s/iter; left time: 174.6389s\n",
      "\titers: 400, epoch: 15 | loss: 0.0430892\n",
      "\tspeed: 0.0340s/iter; left time: 171.3631s\n",
      "\titers: 500, epoch: 15 | loss: 0.0377812\n",
      "\tspeed: 0.0339s/iter; left time: 167.5859s\n",
      "\titers: 600, epoch: 15 | loss: 0.0361609\n",
      "\tspeed: 0.0340s/iter; left time: 164.3873s\n",
      "\titers: 700, epoch: 15 | loss: 0.0323415\n",
      "\tspeed: 0.0340s/iter; left time: 160.8702s\n",
      "\titers: 800, epoch: 15 | loss: 0.0385448\n",
      "\tspeed: 0.0340s/iter; left time: 157.5110s\n",
      "\titers: 900, epoch: 15 | loss: 0.0349694\n",
      "\tspeed: 0.0340s/iter; left time: 154.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.02s\n",
      "Steps: 906 | Train Loss: 0.0371047 Vali Loss: 0.0579351 Test Loss: 0.0650045\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0371176\n",
      "\tspeed: 0.0933s/iter; left time: 413.5632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0388558\n",
      "\tspeed: 0.0340s/iter; left time: 147.1480s\n",
      "\titers: 300, epoch: 16 | loss: 0.0379867\n",
      "\tspeed: 0.0340s/iter; left time: 143.8585s\n",
      "\titers: 400, epoch: 16 | loss: 0.0419456\n",
      "\tspeed: 0.0340s/iter; left time: 140.3840s\n",
      "\titers: 500, epoch: 16 | loss: 0.0323641\n",
      "\tspeed: 0.0340s/iter; left time: 137.0274s\n",
      "\titers: 600, epoch: 16 | loss: 0.0388941\n",
      "\tspeed: 0.0340s/iter; left time: 133.6431s\n",
      "\titers: 700, epoch: 16 | loss: 0.0388042\n",
      "\tspeed: 0.0340s/iter; left time: 130.1446s\n",
      "\titers: 800, epoch: 16 | loss: 0.0336426\n",
      "\tspeed: 0.0340s/iter; left time: 126.8455s\n",
      "\titers: 900, epoch: 16 | loss: 0.0334118\n",
      "\tspeed: 0.0340s/iter; left time: 123.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0364606 Vali Loss: 0.0591877 Test Loss: 0.0641280\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0336711\n",
      "\tspeed: 0.0932s/iter; left time: 328.4885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0368703\n",
      "\tspeed: 0.0340s/iter; left time: 116.6046s\n",
      "\titers: 300, epoch: 17 | loss: 0.0379302\n",
      "\tspeed: 0.0341s/iter; left time: 113.4628s\n",
      "\titers: 400, epoch: 17 | loss: 0.0395388\n",
      "\tspeed: 0.0340s/iter; left time: 109.7315s\n",
      "\titers: 500, epoch: 17 | loss: 0.0376200\n",
      "\tspeed: 0.0340s/iter; left time: 106.2791s\n",
      "\titers: 600, epoch: 17 | loss: 0.0365006\n",
      "\tspeed: 0.0341s/iter; left time: 103.0427s\n",
      "\titers: 700, epoch: 17 | loss: 0.0371170\n",
      "\tspeed: 0.0341s/iter; left time: 99.6480s\n",
      "\titers: 800, epoch: 17 | loss: 0.0356720\n",
      "\tspeed: 0.0340s/iter; left time: 96.0678s\n",
      "\titers: 900, epoch: 17 | loss: 0.0351860\n",
      "\tspeed: 0.0341s/iter; left time: 92.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0358196 Vali Loss: 0.0584597 Test Loss: 0.0634428\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0369047\n",
      "\tspeed: 0.0937s/iter; left time: 245.2724s\n",
      "\titers: 200, epoch: 18 | loss: 0.0333894\n",
      "\tspeed: 0.0341s/iter; left time: 85.8503s\n",
      "\titers: 300, epoch: 18 | loss: 0.0319502\n",
      "\tspeed: 0.0341s/iter; left time: 82.3783s\n",
      "\titers: 400, epoch: 18 | loss: 0.0355705\n",
      "\tspeed: 0.0341s/iter; left time: 79.0800s\n",
      "\titers: 500, epoch: 18 | loss: 0.0322271\n",
      "\tspeed: 0.0340s/iter; left time: 75.5469s\n",
      "\titers: 600, epoch: 18 | loss: 0.0342900\n",
      "\tspeed: 0.0341s/iter; left time: 72.2025s\n",
      "\titers: 700, epoch: 18 | loss: 0.0366018\n",
      "\tspeed: 0.0341s/iter; left time: 68.7861s\n",
      "\titers: 800, epoch: 18 | loss: 0.0388807\n",
      "\tspeed: 0.0340s/iter; left time: 65.3016s\n",
      "\titers: 900, epoch: 18 | loss: 0.0359373\n",
      "\tspeed: 0.0341s/iter; left time: 62.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0352443 Vali Loss: 0.0587067 Test Loss: 0.0646590\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01250072754919529, rmse:0.11180665343999863, mae:0.06438585370779037, rse:0.4314415752887726\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:35.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1902333\n",
      "\tspeed: 0.0636s/iter; left time: 1142.9379s\n",
      "\titers: 200, epoch: 1 | loss: 0.1634794\n",
      "\tspeed: 0.0419s/iter; left time: 749.2805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1666822\n",
      "\tspeed: 0.0420s/iter; left time: 746.1554s\n",
      "\titers: 400, epoch: 1 | loss: 0.1558330\n",
      "\tspeed: 0.0419s/iter; left time: 741.1753s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509849\n",
      "\tspeed: 0.0420s/iter; left time: 738.1542s\n",
      "\titers: 600, epoch: 1 | loss: 0.1476412\n",
      "\tspeed: 0.0420s/iter; left time: 734.5278s\n",
      "\titers: 700, epoch: 1 | loss: 0.1512190\n",
      "\tspeed: 0.0420s/iter; left time: 730.4839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1417792\n",
      "\tspeed: 0.0420s/iter; left time: 726.5070s\n",
      "\titers: 900, epoch: 1 | loss: 0.1403145\n",
      "\tspeed: 0.0424s/iter; left time: 729.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 904 | Train Loss: 0.1621709 Vali Loss: 0.1583142 Test Loss: 0.1844553\n",
      "Validation loss decreased (inf --> 0.158314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330157\n",
      "\tspeed: 0.1175s/iter; left time: 2006.5724s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246072\n",
      "\tspeed: 0.0420s/iter; left time: 713.5594s\n",
      "\titers: 300, epoch: 2 | loss: 0.1126059\n",
      "\tspeed: 0.0421s/iter; left time: 710.1757s\n",
      "\titers: 400, epoch: 2 | loss: 0.1093363\n",
      "\tspeed: 0.0421s/iter; left time: 705.6017s\n",
      "\titers: 500, epoch: 2 | loss: 0.1034709\n",
      "\tspeed: 0.0421s/iter; left time: 701.4904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1020617\n",
      "\tspeed: 0.0420s/iter; left time: 696.0989s\n",
      "\titers: 700, epoch: 2 | loss: 0.0958327\n",
      "\tspeed: 0.0420s/iter; left time: 692.4386s\n",
      "\titers: 800, epoch: 2 | loss: 0.0837372\n",
      "\tspeed: 0.0418s/iter; left time: 684.7476s\n",
      "\titers: 900, epoch: 2 | loss: 0.0910152\n",
      "\tspeed: 0.0415s/iter; left time: 675.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.1095183 Vali Loss: 0.1063607 Test Loss: 0.1212249\n",
      "Validation loss decreased (0.158314 --> 0.106361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888553\n",
      "\tspeed: 0.1167s/iter; left time: 1886.6447s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888103\n",
      "\tspeed: 0.0421s/iter; left time: 676.2275s\n",
      "\titers: 300, epoch: 3 | loss: 0.0863014\n",
      "\tspeed: 0.0421s/iter; left time: 671.7998s\n",
      "\titers: 400, epoch: 3 | loss: 0.0804213\n",
      "\tspeed: 0.0421s/iter; left time: 667.5718s\n",
      "\titers: 500, epoch: 3 | loss: 0.0833842\n",
      "\tspeed: 0.0421s/iter; left time: 663.2878s\n",
      "\titers: 600, epoch: 3 | loss: 0.0776550\n",
      "\tspeed: 0.0421s/iter; left time: 659.6652s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751079\n",
      "\tspeed: 0.0420s/iter; left time: 654.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0775777\n",
      "\tspeed: 0.0415s/iter; left time: 641.7995s\n",
      "\titers: 900, epoch: 3 | loss: 0.0718875\n",
      "\tspeed: 0.0415s/iter; left time: 637.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 904 | Train Loss: 0.0825873 Vali Loss: 0.0874852 Test Loss: 0.1007140\n",
      "Validation loss decreased (0.106361 --> 0.087485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0644550\n",
      "\tspeed: 0.1176s/iter; left time: 1794.9362s\n",
      "\titers: 200, epoch: 4 | loss: 0.0673058\n",
      "\tspeed: 0.0414s/iter; left time: 628.7548s\n",
      "\titers: 300, epoch: 4 | loss: 0.0663593\n",
      "\tspeed: 0.0414s/iter; left time: 624.2688s\n",
      "\titers: 400, epoch: 4 | loss: 0.0698647\n",
      "\tspeed: 0.0415s/iter; left time: 620.4678s\n",
      "\titers: 500, epoch: 4 | loss: 0.0648271\n",
      "\tspeed: 0.0415s/iter; left time: 616.3495s\n",
      "\titers: 600, epoch: 4 | loss: 0.0635923\n",
      "\tspeed: 0.0414s/iter; left time: 612.1505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0624922\n",
      "\tspeed: 0.0415s/iter; left time: 608.3211s\n",
      "\titers: 800, epoch: 4 | loss: 0.0619351\n",
      "\tspeed: 0.0414s/iter; left time: 603.8803s\n",
      "\titers: 900, epoch: 4 | loss: 0.0630612\n",
      "\tspeed: 0.0415s/iter; left time: 600.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.74s\n",
      "Steps: 904 | Train Loss: 0.0674741 Vali Loss: 0.0844296 Test Loss: 0.0921732\n",
      "Validation loss decreased (0.087485 --> 0.084430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639159\n",
      "\tspeed: 0.1174s/iter; left time: 1686.5920s\n",
      "\titers: 200, epoch: 5 | loss: 0.0614217\n",
      "\tspeed: 0.0416s/iter; left time: 592.8504s\n",
      "\titers: 300, epoch: 5 | loss: 0.0670402\n",
      "\tspeed: 0.0415s/iter; left time: 588.2780s\n",
      "\titers: 400, epoch: 5 | loss: 0.0595234\n",
      "\tspeed: 0.0415s/iter; left time: 583.8364s\n",
      "\titers: 500, epoch: 5 | loss: 0.0611329\n",
      "\tspeed: 0.0415s/iter; left time: 579.7432s\n",
      "\titers: 600, epoch: 5 | loss: 0.0632634\n",
      "\tspeed: 0.0415s/iter; left time: 575.5308s\n",
      "\titers: 700, epoch: 5 | loss: 0.0614533\n",
      "\tspeed: 0.0415s/iter; left time: 571.4856s\n",
      "\titers: 800, epoch: 5 | loss: 0.0643962\n",
      "\tspeed: 0.0415s/iter; left time: 567.3923s\n",
      "\titers: 900, epoch: 5 | loss: 0.0656714\n",
      "\tspeed: 0.0415s/iter; left time: 563.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0626034 Vali Loss: 0.0815981 Test Loss: 0.0909119\n",
      "Validation loss decreased (0.084430 --> 0.081598).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579641\n",
      "\tspeed: 0.1187s/iter; left time: 1598.3911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0595998\n",
      "\tspeed: 0.0415s/iter; left time: 554.7178s\n",
      "\titers: 300, epoch: 6 | loss: 0.0583193\n",
      "\tspeed: 0.0415s/iter; left time: 550.5876s\n",
      "\titers: 400, epoch: 6 | loss: 0.0573336\n",
      "\tspeed: 0.0415s/iter; left time: 546.7790s\n",
      "\titers: 500, epoch: 6 | loss: 0.0537359\n",
      "\tspeed: 0.0416s/iter; left time: 542.7198s\n",
      "\titers: 600, epoch: 6 | loss: 0.0568817\n",
      "\tspeed: 0.0415s/iter; left time: 537.9688s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555145\n",
      "\tspeed: 0.0415s/iter; left time: 533.7798s\n",
      "\titers: 800, epoch: 6 | loss: 0.0552718\n",
      "\tspeed: 0.0415s/iter; left time: 530.2181s\n",
      "\titers: 900, epoch: 6 | loss: 0.0597004\n",
      "\tspeed: 0.0416s/iter; left time: 526.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0590999 Vali Loss: 0.0809355 Test Loss: 0.0917555\n",
      "Validation loss decreased (0.081598 --> 0.080936).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0539223\n",
      "\tspeed: 0.1172s/iter; left time: 1472.2428s\n",
      "\titers: 200, epoch: 7 | loss: 0.0613421\n",
      "\tspeed: 0.0415s/iter; left time: 516.5350s\n",
      "\titers: 300, epoch: 7 | loss: 0.0540870\n",
      "\tspeed: 0.0415s/iter; left time: 512.4116s\n",
      "\titers: 400, epoch: 7 | loss: 0.0517807\n",
      "\tspeed: 0.0415s/iter; left time: 508.2118s\n",
      "\titers: 500, epoch: 7 | loss: 0.0519386\n",
      "\tspeed: 0.0415s/iter; left time: 504.1703s\n",
      "\titers: 600, epoch: 7 | loss: 0.0478697\n",
      "\tspeed: 0.0415s/iter; left time: 500.2220s\n",
      "\titers: 700, epoch: 7 | loss: 0.0569892\n",
      "\tspeed: 0.0415s/iter; left time: 495.9877s\n",
      "\titers: 800, epoch: 7 | loss: 0.0547691\n",
      "\tspeed: 0.0415s/iter; left time: 491.9064s\n",
      "\titers: 900, epoch: 7 | loss: 0.0566718\n",
      "\tspeed: 0.0415s/iter; left time: 487.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0561235 Vali Loss: 0.0818110 Test Loss: 0.0925347\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0545926\n",
      "\tspeed: 0.1134s/iter; left time: 1320.9235s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537039\n",
      "\tspeed: 0.0415s/iter; left time: 479.6749s\n",
      "\titers: 300, epoch: 8 | loss: 0.0538438\n",
      "\tspeed: 0.0420s/iter; left time: 481.5297s\n",
      "\titers: 400, epoch: 8 | loss: 0.0485980\n",
      "\tspeed: 0.0421s/iter; left time: 477.8452s\n",
      "\titers: 500, epoch: 8 | loss: 0.0490118\n",
      "\tspeed: 0.0421s/iter; left time: 473.5320s\n",
      "\titers: 600, epoch: 8 | loss: 0.0507474\n",
      "\tspeed: 0.0421s/iter; left time: 469.4826s\n",
      "\titers: 700, epoch: 8 | loss: 0.0488948\n",
      "\tspeed: 0.0421s/iter; left time: 465.4635s\n",
      "\titers: 800, epoch: 8 | loss: 0.0515667\n",
      "\tspeed: 0.0421s/iter; left time: 461.2118s\n",
      "\titers: 900, epoch: 8 | loss: 0.0471621\n",
      "\tspeed: 0.0421s/iter; left time: 456.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 904 | Train Loss: 0.0534966 Vali Loss: 0.0834365 Test Loss: 0.0937311\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0504029\n",
      "\tspeed: 0.1146s/iter; left time: 1232.1206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0501226\n",
      "\tspeed: 0.0421s/iter; left time: 447.8415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0521222\n",
      "\tspeed: 0.0421s/iter; left time: 443.8949s\n",
      "\titers: 400, epoch: 9 | loss: 0.0458085\n",
      "\tspeed: 0.0421s/iter; left time: 439.7019s\n",
      "\titers: 500, epoch: 9 | loss: 0.0503745\n",
      "\tspeed: 0.0421s/iter; left time: 435.3861s\n",
      "\titers: 600, epoch: 9 | loss: 0.0523974\n",
      "\tspeed: 0.0421s/iter; left time: 431.0932s\n",
      "\titers: 700, epoch: 9 | loss: 0.0510676\n",
      "\tspeed: 0.0421s/iter; left time: 426.9360s\n",
      "\titers: 800, epoch: 9 | loss: 0.0508459\n",
      "\tspeed: 0.0421s/iter; left time: 422.6381s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501447\n",
      "\tspeed: 0.0421s/iter; left time: 418.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0511315 Vali Loss: 0.0806643 Test Loss: 0.0902437\n",
      "Validation loss decreased (0.080936 --> 0.080664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0479229\n",
      "\tspeed: 0.1181s/iter; left time: 1162.5802s\n",
      "\titers: 200, epoch: 10 | loss: 0.0458388\n",
      "\tspeed: 0.0421s/iter; left time: 410.0027s\n",
      "\titers: 300, epoch: 10 | loss: 0.0468625\n",
      "\tspeed: 0.0422s/iter; left time: 406.5477s\n",
      "\titers: 400, epoch: 10 | loss: 0.0468525\n",
      "\tspeed: 0.0421s/iter; left time: 402.3018s\n",
      "\titers: 500, epoch: 10 | loss: 0.0479589\n",
      "\tspeed: 0.0421s/iter; left time: 397.7641s\n",
      "\titers: 600, epoch: 10 | loss: 0.0515600\n",
      "\tspeed: 0.0421s/iter; left time: 393.0768s\n",
      "\titers: 700, epoch: 10 | loss: 0.0529387\n",
      "\tspeed: 0.0421s/iter; left time: 388.9255s\n",
      "\titers: 800, epoch: 10 | loss: 0.0519285\n",
      "\tspeed: 0.0421s/iter; left time: 385.1772s\n",
      "\titers: 900, epoch: 10 | loss: 0.0498877\n",
      "\tspeed: 0.0421s/iter; left time: 380.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0491287 Vali Loss: 0.0825551 Test Loss: 0.0938539\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0456407\n",
      "\tspeed: 0.1147s/iter; left time: 1025.6345s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484030\n",
      "\tspeed: 0.0415s/iter; left time: 367.2298s\n",
      "\titers: 300, epoch: 11 | loss: 0.0500798\n",
      "\tspeed: 0.0415s/iter; left time: 363.0895s\n",
      "\titers: 400, epoch: 11 | loss: 0.0489990\n",
      "\tspeed: 0.0415s/iter; left time: 358.7714s\n",
      "\titers: 500, epoch: 11 | loss: 0.0480193\n",
      "\tspeed: 0.0415s/iter; left time: 354.8332s\n",
      "\titers: 600, epoch: 11 | loss: 0.0455437\n",
      "\tspeed: 0.0415s/iter; left time: 350.5578s\n",
      "\titers: 700, epoch: 11 | loss: 0.0465373\n",
      "\tspeed: 0.0415s/iter; left time: 346.4876s\n",
      "\titers: 800, epoch: 11 | loss: 0.0471579\n",
      "\tspeed: 0.0415s/iter; left time: 342.2289s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470960\n",
      "\tspeed: 0.0415s/iter; left time: 338.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.0474263 Vali Loss: 0.0815087 Test Loss: 0.0885854\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0434840\n",
      "\tspeed: 0.1146s/iter; left time: 920.6887s\n",
      "\titers: 200, epoch: 12 | loss: 0.0445123\n",
      "\tspeed: 0.0420s/iter; left time: 333.5449s\n",
      "\titers: 300, epoch: 12 | loss: 0.0451364\n",
      "\tspeed: 0.0420s/iter; left time: 329.3751s\n",
      "\titers: 400, epoch: 12 | loss: 0.0416487\n",
      "\tspeed: 0.0420s/iter; left time: 325.0469s\n",
      "\titers: 500, epoch: 12 | loss: 0.0491649\n",
      "\tspeed: 0.0420s/iter; left time: 320.6819s\n",
      "\titers: 600, epoch: 12 | loss: 0.0467862\n",
      "\tspeed: 0.0420s/iter; left time: 316.8661s\n",
      "\titers: 700, epoch: 12 | loss: 0.0475624\n",
      "\tspeed: 0.0420s/iter; left time: 312.2396s\n",
      "\titers: 800, epoch: 12 | loss: 0.0455075\n",
      "\tspeed: 0.0420s/iter; left time: 308.3541s\n",
      "\titers: 900, epoch: 12 | loss: 0.0451173\n",
      "\tspeed: 0.0420s/iter; left time: 304.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 904 | Train Loss: 0.0458701 Vali Loss: 0.0813544 Test Loss: 0.0891244\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434529\n",
      "\tspeed: 0.1139s/iter; left time: 812.5212s\n",
      "\titers: 200, epoch: 13 | loss: 0.0425601\n",
      "\tspeed: 0.0414s/iter; left time: 291.4937s\n",
      "\titers: 300, epoch: 13 | loss: 0.0390885\n",
      "\tspeed: 0.0415s/iter; left time: 287.4257s\n",
      "\titers: 400, epoch: 13 | loss: 0.0431902\n",
      "\tspeed: 0.0415s/iter; left time: 283.3661s\n",
      "\titers: 500, epoch: 13 | loss: 0.0442528\n",
      "\tspeed: 0.0415s/iter; left time: 279.1462s\n",
      "\titers: 600, epoch: 13 | loss: 0.0448327\n",
      "\tspeed: 0.0414s/iter; left time: 274.9087s\n",
      "\titers: 700, epoch: 13 | loss: 0.0427357\n",
      "\tspeed: 0.0415s/iter; left time: 270.9401s\n",
      "\titers: 800, epoch: 13 | loss: 0.0454790\n",
      "\tspeed: 0.0415s/iter; left time: 266.7131s\n",
      "\titers: 900, epoch: 13 | loss: 0.0471705\n",
      "\tspeed: 0.0415s/iter; left time: 262.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 904 | Train Loss: 0.0444942 Vali Loss: 0.0826097 Test Loss: 0.0910248\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0420628\n",
      "\tspeed: 0.1133s/iter; left time: 705.8496s\n",
      "\titers: 200, epoch: 14 | loss: 0.0434183\n",
      "\tspeed: 0.0415s/iter; left time: 254.3482s\n",
      "\titers: 300, epoch: 14 | loss: 0.0415930\n",
      "\tspeed: 0.0415s/iter; left time: 250.2050s\n",
      "\titers: 400, epoch: 14 | loss: 0.0413548\n",
      "\tspeed: 0.0415s/iter; left time: 245.9290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0413789\n",
      "\tspeed: 0.0415s/iter; left time: 241.9992s\n",
      "\titers: 600, epoch: 14 | loss: 0.0463429\n",
      "\tspeed: 0.0415s/iter; left time: 237.8058s\n",
      "\titers: 700, epoch: 14 | loss: 0.0457477\n",
      "\tspeed: 0.0415s/iter; left time: 233.6698s\n",
      "\titers: 800, epoch: 14 | loss: 0.0433612\n",
      "\tspeed: 0.0415s/iter; left time: 229.5864s\n",
      "\titers: 900, epoch: 14 | loss: 0.0437617\n",
      "\tspeed: 0.0416s/iter; left time: 225.8041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0433176 Vali Loss: 0.0822506 Test Loss: 0.0912996\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022864822298288345, rmse:0.1512111872434616, mae:0.09028714150190353, rse:0.5849250555038452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1801853\n",
      "\tspeed: 0.0440s/iter; left time: 791.3338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1757706\n",
      "\tspeed: 0.0415s/iter; left time: 742.3598s\n",
      "\titers: 300, epoch: 1 | loss: 0.1683250\n",
      "\tspeed: 0.0416s/iter; left time: 738.8906s\n",
      "\titers: 400, epoch: 1 | loss: 0.1585326\n",
      "\tspeed: 0.0416s/iter; left time: 734.6853s\n",
      "\titers: 500, epoch: 1 | loss: 0.1467624\n",
      "\tspeed: 0.0415s/iter; left time: 730.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1519888\n",
      "\tspeed: 0.0415s/iter; left time: 726.2310s\n",
      "\titers: 700, epoch: 1 | loss: 0.1499733\n",
      "\tspeed: 0.0415s/iter; left time: 722.0790s\n",
      "\titers: 800, epoch: 1 | loss: 0.1427606\n",
      "\tspeed: 0.0416s/iter; left time: 718.2521s\n",
      "\titers: 900, epoch: 1 | loss: 0.1468351\n",
      "\tspeed: 0.0416s/iter; left time: 713.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1637526 Vali Loss: 0.1575865 Test Loss: 0.1835811\n",
      "Validation loss decreased (inf --> 0.157586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303630\n",
      "\tspeed: 0.1164s/iter; left time: 1988.3099s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302949\n",
      "\tspeed: 0.0415s/iter; left time: 705.1301s\n",
      "\titers: 300, epoch: 2 | loss: 0.1157242\n",
      "\tspeed: 0.0415s/iter; left time: 700.7159s\n",
      "\titers: 400, epoch: 2 | loss: 0.1105489\n",
      "\tspeed: 0.0415s/iter; left time: 696.8772s\n",
      "\titers: 500, epoch: 2 | loss: 0.1054600\n",
      "\tspeed: 0.0415s/iter; left time: 692.2461s\n",
      "\titers: 600, epoch: 2 | loss: 0.1001050\n",
      "\tspeed: 0.0415s/iter; left time: 688.4405s\n",
      "\titers: 700, epoch: 2 | loss: 0.1084336\n",
      "\tspeed: 0.0416s/iter; left time: 684.7686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0790982\n",
      "\tspeed: 0.0415s/iter; left time: 680.0364s\n",
      "\titers: 900, epoch: 2 | loss: 0.0886261\n",
      "\tspeed: 0.0415s/iter; left time: 676.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1079180 Vali Loss: 0.1051555 Test Loss: 0.1193966\n",
      "Validation loss decreased (0.157586 --> 0.105156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0876562\n",
      "\tspeed: 0.1174s/iter; left time: 1899.3789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0827423\n",
      "\tspeed: 0.0416s/iter; left time: 668.4151s\n",
      "\titers: 300, epoch: 3 | loss: 0.0847814\n",
      "\tspeed: 0.0420s/iter; left time: 671.6212s\n",
      "\titers: 400, epoch: 3 | loss: 0.0777887\n",
      "\tspeed: 0.0422s/iter; left time: 669.6548s\n",
      "\titers: 500, epoch: 3 | loss: 0.0885318\n",
      "\tspeed: 0.0422s/iter; left time: 665.4361s\n",
      "\titers: 600, epoch: 3 | loss: 0.0824113\n",
      "\tspeed: 0.0422s/iter; left time: 660.7655s\n",
      "\titers: 700, epoch: 3 | loss: 0.0705649\n",
      "\tspeed: 0.0421s/iter; left time: 656.3357s\n",
      "\titers: 800, epoch: 3 | loss: 0.0739427\n",
      "\tspeed: 0.0422s/iter; left time: 652.2881s\n",
      "\titers: 900, epoch: 3 | loss: 0.0669540\n",
      "\tspeed: 0.0422s/iter; left time: 648.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.0807194 Vali Loss: 0.0859751 Test Loss: 0.0970179\n",
      "Validation loss decreased (0.105156 --> 0.085975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0694406\n",
      "\tspeed: 0.1169s/iter; left time: 1785.3883s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649310\n",
      "\tspeed: 0.0421s/iter; left time: 639.1821s\n",
      "\titers: 300, epoch: 4 | loss: 0.0693028\n",
      "\tspeed: 0.0421s/iter; left time: 634.7391s\n",
      "\titers: 400, epoch: 4 | loss: 0.0685778\n",
      "\tspeed: 0.0421s/iter; left time: 630.5093s\n",
      "\titers: 500, epoch: 4 | loss: 0.0600520\n",
      "\tspeed: 0.0421s/iter; left time: 626.5364s\n",
      "\titers: 600, epoch: 4 | loss: 0.0625884\n",
      "\tspeed: 0.0421s/iter; left time: 622.2753s\n",
      "\titers: 700, epoch: 4 | loss: 0.0620745\n",
      "\tspeed: 0.0422s/iter; left time: 618.5591s\n",
      "\titers: 800, epoch: 4 | loss: 0.0639772\n",
      "\tspeed: 0.0421s/iter; left time: 613.7473s\n",
      "\titers: 900, epoch: 4 | loss: 0.0614068\n",
      "\tspeed: 0.0422s/iter; left time: 609.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0670069 Vali Loss: 0.0825358 Test Loss: 0.0950642\n",
      "Validation loss decreased (0.085975 --> 0.082536).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0631184\n",
      "\tspeed: 0.1167s/iter; left time: 1676.0975s\n",
      "\titers: 200, epoch: 5 | loss: 0.0672402\n",
      "\tspeed: 0.0422s/iter; left time: 601.3006s\n",
      "\titers: 300, epoch: 5 | loss: 0.0590044\n",
      "\tspeed: 0.0421s/iter; left time: 596.7791s\n",
      "\titers: 400, epoch: 5 | loss: 0.0598044\n",
      "\tspeed: 0.0421s/iter; left time: 592.5886s\n",
      "\titers: 500, epoch: 5 | loss: 0.0639175\n",
      "\tspeed: 0.0422s/iter; left time: 588.8828s\n",
      "\titers: 600, epoch: 5 | loss: 0.0653268\n",
      "\tspeed: 0.0422s/iter; left time: 584.6260s\n",
      "\titers: 700, epoch: 5 | loss: 0.0598224\n",
      "\tspeed: 0.0422s/iter; left time: 580.9071s\n",
      "\titers: 800, epoch: 5 | loss: 0.0627552\n",
      "\tspeed: 0.0422s/iter; left time: 576.0732s\n",
      "\titers: 900, epoch: 5 | loss: 0.0581154\n",
      "\tspeed: 0.0422s/iter; left time: 572.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 904 | Train Loss: 0.0621152 Vali Loss: 0.0814626 Test Loss: 0.0897293\n",
      "Validation loss decreased (0.082536 --> 0.081463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614372\n",
      "\tspeed: 0.1186s/iter; left time: 1596.5839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612931\n",
      "\tspeed: 0.0422s/iter; left time: 563.4863s\n",
      "\titers: 300, epoch: 6 | loss: 0.0573931\n",
      "\tspeed: 0.0422s/iter; left time: 559.7017s\n",
      "\titers: 400, epoch: 6 | loss: 0.0569089\n",
      "\tspeed: 0.0422s/iter; left time: 555.2582s\n",
      "\titers: 500, epoch: 6 | loss: 0.0555158\n",
      "\tspeed: 0.0422s/iter; left time: 551.2511s\n",
      "\titers: 600, epoch: 6 | loss: 0.0548578\n",
      "\tspeed: 0.0422s/iter; left time: 546.4935s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584947\n",
      "\tspeed: 0.0422s/iter; left time: 542.6575s\n",
      "\titers: 800, epoch: 6 | loss: 0.0564002\n",
      "\tspeed: 0.0422s/iter; left time: 538.6592s\n",
      "\titers: 900, epoch: 6 | loss: 0.0607242\n",
      "\tspeed: 0.0422s/iter; left time: 534.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.0587400 Vali Loss: 0.0810837 Test Loss: 0.0917180\n",
      "Validation loss decreased (0.081463 --> 0.081084).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583565\n",
      "\tspeed: 0.1175s/iter; left time: 1475.7372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0520255\n",
      "\tspeed: 0.0421s/iter; left time: 524.7099s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552256\n",
      "\tspeed: 0.0422s/iter; left time: 521.0978s\n",
      "\titers: 400, epoch: 7 | loss: 0.0547102\n",
      "\tspeed: 0.0422s/iter; left time: 516.6803s\n",
      "\titers: 500, epoch: 7 | loss: 0.0543888\n",
      "\tspeed: 0.0422s/iter; left time: 512.5356s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582229\n",
      "\tspeed: 0.0421s/iter; left time: 507.9209s\n",
      "\titers: 700, epoch: 7 | loss: 0.0542132\n",
      "\tspeed: 0.0421s/iter; left time: 503.5968s\n",
      "\titers: 800, epoch: 7 | loss: 0.0564435\n",
      "\tspeed: 0.0421s/iter; left time: 499.4522s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559337\n",
      "\tspeed: 0.0422s/iter; left time: 495.7002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.0559357 Vali Loss: 0.0815365 Test Loss: 0.0903651\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0521917\n",
      "\tspeed: 0.1150s/iter; left time: 1340.4555s\n",
      "\titers: 200, epoch: 8 | loss: 0.0473949\n",
      "\tspeed: 0.0418s/iter; left time: 483.2140s\n",
      "\titers: 300, epoch: 8 | loss: 0.0566309\n",
      "\tspeed: 0.0415s/iter; left time: 475.8055s\n",
      "\titers: 400, epoch: 8 | loss: 0.0504954\n",
      "\tspeed: 0.0415s/iter; left time: 471.6473s\n",
      "\titers: 500, epoch: 8 | loss: 0.0503554\n",
      "\tspeed: 0.0416s/iter; left time: 467.7012s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523519\n",
      "\tspeed: 0.0417s/iter; left time: 465.5451s\n",
      "\titers: 700, epoch: 8 | loss: 0.0601990\n",
      "\tspeed: 0.0422s/iter; left time: 466.3816s\n",
      "\titers: 800, epoch: 8 | loss: 0.0574024\n",
      "\tspeed: 0.0422s/iter; left time: 462.0786s\n",
      "\titers: 900, epoch: 8 | loss: 0.0504944\n",
      "\tspeed: 0.0422s/iter; left time: 458.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 904 | Train Loss: 0.0534219 Vali Loss: 0.0815038 Test Loss: 0.0924361\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0555919\n",
      "\tspeed: 0.1144s/iter; left time: 1229.5071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0495185\n",
      "\tspeed: 0.0422s/iter; left time: 449.3055s\n",
      "\titers: 300, epoch: 9 | loss: 0.0503814\n",
      "\tspeed: 0.0422s/iter; left time: 444.9955s\n",
      "\titers: 400, epoch: 9 | loss: 0.0510218\n",
      "\tspeed: 0.0422s/iter; left time: 440.9606s\n",
      "\titers: 500, epoch: 9 | loss: 0.0455104\n",
      "\tspeed: 0.0422s/iter; left time: 436.7347s\n",
      "\titers: 600, epoch: 9 | loss: 0.0525810\n",
      "\tspeed: 0.0422s/iter; left time: 432.1226s\n",
      "\titers: 700, epoch: 9 | loss: 0.0497616\n",
      "\tspeed: 0.0422s/iter; left time: 428.2829s\n",
      "\titers: 800, epoch: 9 | loss: 0.0543077\n",
      "\tspeed: 0.0422s/iter; left time: 424.1257s\n",
      "\titers: 900, epoch: 9 | loss: 0.0499346\n",
      "\tspeed: 0.0422s/iter; left time: 419.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 904 | Train Loss: 0.0513986 Vali Loss: 0.0811884 Test Loss: 0.0904090\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0520169\n",
      "\tspeed: 0.1141s/iter; left time: 1123.7260s\n",
      "\titers: 200, epoch: 10 | loss: 0.0472272\n",
      "\tspeed: 0.0421s/iter; left time: 410.3697s\n",
      "\titers: 300, epoch: 10 | loss: 0.0494040\n",
      "\tspeed: 0.0421s/iter; left time: 406.2686s\n",
      "\titers: 400, epoch: 10 | loss: 0.0476900\n",
      "\tspeed: 0.0422s/iter; left time: 402.5648s\n",
      "\titers: 500, epoch: 10 | loss: 0.0437683\n",
      "\tspeed: 0.0422s/iter; left time: 398.5206s\n",
      "\titers: 600, epoch: 10 | loss: 0.0510910\n",
      "\tspeed: 0.0422s/iter; left time: 394.2528s\n",
      "\titers: 700, epoch: 10 | loss: 0.0468750\n",
      "\tspeed: 0.0422s/iter; left time: 389.9539s\n",
      "\titers: 800, epoch: 10 | loss: 0.0480250\n",
      "\tspeed: 0.0421s/iter; left time: 385.1841s\n",
      "\titers: 900, epoch: 10 | loss: 0.0472614\n",
      "\tspeed: 0.0421s/iter; left time: 381.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0495849 Vali Loss: 0.0814730 Test Loss: 0.0901214\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0507243\n",
      "\tspeed: 0.1141s/iter; left time: 1020.6024s\n",
      "\titers: 200, epoch: 11 | loss: 0.0478392\n",
      "\tspeed: 0.0422s/iter; left time: 372.7031s\n",
      "\titers: 300, epoch: 11 | loss: 0.0494696\n",
      "\tspeed: 0.0421s/iter; left time: 367.6222s\n",
      "\titers: 400, epoch: 11 | loss: 0.0495104\n",
      "\tspeed: 0.0416s/iter; left time: 359.1142s\n",
      "\titers: 500, epoch: 11 | loss: 0.0487904\n",
      "\tspeed: 0.0416s/iter; left time: 355.1483s\n",
      "\titers: 600, epoch: 11 | loss: 0.0512776\n",
      "\tspeed: 0.0415s/iter; left time: 350.6539s\n",
      "\titers: 700, epoch: 11 | loss: 0.0480168\n",
      "\tspeed: 0.0416s/iter; left time: 346.8143s\n",
      "\titers: 800, epoch: 11 | loss: 0.0467180\n",
      "\tspeed: 0.0416s/iter; left time: 342.6088s\n",
      "\titers: 900, epoch: 11 | loss: 0.0499095\n",
      "\tspeed: 0.0416s/iter; left time: 338.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.0479882 Vali Loss: 0.0793715 Test Loss: 0.0891887\n",
      "Validation loss decreased (0.081084 --> 0.079371).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468300\n",
      "\tspeed: 0.1166s/iter; left time: 937.1695s\n",
      "\titers: 200, epoch: 12 | loss: 0.0471748\n",
      "\tspeed: 0.0415s/iter; left time: 329.6437s\n",
      "\titers: 300, epoch: 12 | loss: 0.0472506\n",
      "\tspeed: 0.0415s/iter; left time: 325.5373s\n",
      "\titers: 400, epoch: 12 | loss: 0.0449921\n",
      "\tspeed: 0.0415s/iter; left time: 321.2439s\n",
      "\titers: 500, epoch: 12 | loss: 0.0452186\n",
      "\tspeed: 0.0416s/iter; left time: 317.3878s\n",
      "\titers: 600, epoch: 12 | loss: 0.0509672\n",
      "\tspeed: 0.0415s/iter; left time: 313.1249s\n",
      "\titers: 700, epoch: 12 | loss: 0.0462397\n",
      "\tspeed: 0.0416s/iter; left time: 309.5066s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501083\n",
      "\tspeed: 0.0415s/iter; left time: 304.8201s\n",
      "\titers: 900, epoch: 12 | loss: 0.0409865\n",
      "\tspeed: 0.0415s/iter; left time: 300.6787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0465710 Vali Loss: 0.0800179 Test Loss: 0.0904158\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0508476\n",
      "\tspeed: 0.1133s/iter; left time: 808.3958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0427458\n",
      "\tspeed: 0.0415s/iter; left time: 292.0275s\n",
      "\titers: 300, epoch: 13 | loss: 0.0444610\n",
      "\tspeed: 0.0415s/iter; left time: 287.6441s\n",
      "\titers: 400, epoch: 13 | loss: 0.0467233\n",
      "\tspeed: 0.0415s/iter; left time: 283.5360s\n",
      "\titers: 500, epoch: 13 | loss: 0.0473262\n",
      "\tspeed: 0.0415s/iter; left time: 279.3990s\n",
      "\titers: 600, epoch: 13 | loss: 0.0471629\n",
      "\tspeed: 0.0415s/iter; left time: 275.2035s\n",
      "\titers: 700, epoch: 13 | loss: 0.0465323\n",
      "\tspeed: 0.0415s/iter; left time: 271.1061s\n",
      "\titers: 800, epoch: 13 | loss: 0.0462343\n",
      "\tspeed: 0.0415s/iter; left time: 267.0899s\n",
      "\titers: 900, epoch: 13 | loss: 0.0459190\n",
      "\tspeed: 0.0415s/iter; left time: 262.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0452570 Vali Loss: 0.0803579 Test Loss: 0.0906105\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0445291\n",
      "\tspeed: 0.1147s/iter; left time: 714.6974s\n",
      "\titers: 200, epoch: 14 | loss: 0.0431228\n",
      "\tspeed: 0.0416s/iter; left time: 254.9392s\n",
      "\titers: 300, epoch: 14 | loss: 0.0411837\n",
      "\tspeed: 0.0416s/iter; left time: 250.7114s\n",
      "\titers: 400, epoch: 14 | loss: 0.0460565\n",
      "\tspeed: 0.0416s/iter; left time: 246.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0461464\n",
      "\tspeed: 0.0416s/iter; left time: 242.3795s\n",
      "\titers: 600, epoch: 14 | loss: 0.0450274\n",
      "\tspeed: 0.0416s/iter; left time: 238.2954s\n",
      "\titers: 700, epoch: 14 | loss: 0.0455625\n",
      "\tspeed: 0.0416s/iter; left time: 234.2062s\n",
      "\titers: 800, epoch: 14 | loss: 0.0467562\n",
      "\tspeed: 0.0416s/iter; left time: 230.0066s\n",
      "\titers: 900, epoch: 14 | loss: 0.0428233\n",
      "\tspeed: 0.0416s/iter; left time: 225.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0440268 Vali Loss: 0.0806199 Test Loss: 0.0894073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441201\n",
      "\tspeed: 0.1141s/iter; left time: 607.4821s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444535\n",
      "\tspeed: 0.0416s/iter; left time: 217.3685s\n",
      "\titers: 300, epoch: 15 | loss: 0.0421129\n",
      "\tspeed: 0.0416s/iter; left time: 213.2131s\n",
      "\titers: 400, epoch: 15 | loss: 0.0428866\n",
      "\tspeed: 0.0416s/iter; left time: 208.9029s\n",
      "\titers: 500, epoch: 15 | loss: 0.0471378\n",
      "\tspeed: 0.0416s/iter; left time: 204.8338s\n",
      "\titers: 600, epoch: 15 | loss: 0.0420919\n",
      "\tspeed: 0.0415s/iter; left time: 200.3340s\n",
      "\titers: 700, epoch: 15 | loss: 0.0439522\n",
      "\tspeed: 0.0415s/iter; left time: 196.2551s\n",
      "\titers: 800, epoch: 15 | loss: 0.0430104\n",
      "\tspeed: 0.0415s/iter; left time: 192.0512s\n",
      "\titers: 900, epoch: 15 | loss: 0.0440404\n",
      "\tspeed: 0.0415s/iter; left time: 188.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.0429491 Vali Loss: 0.0811198 Test Loss: 0.0907875\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0435821\n",
      "\tspeed: 0.1137s/iter; left time: 502.4845s\n",
      "\titers: 200, epoch: 16 | loss: 0.0400924\n",
      "\tspeed: 0.0415s/iter; left time: 179.4197s\n",
      "\titers: 300, epoch: 16 | loss: 0.0406727\n",
      "\tspeed: 0.0415s/iter; left time: 175.2932s\n",
      "\titers: 400, epoch: 16 | loss: 0.0391660\n",
      "\tspeed: 0.0415s/iter; left time: 171.1423s\n",
      "\titers: 500, epoch: 16 | loss: 0.0432506\n",
      "\tspeed: 0.0415s/iter; left time: 167.0319s\n",
      "\titers: 600, epoch: 16 | loss: 0.0443221\n",
      "\tspeed: 0.0415s/iter; left time: 162.8413s\n",
      "\titers: 700, epoch: 16 | loss: 0.0404722\n",
      "\tspeed: 0.0416s/iter; left time: 158.7643s\n",
      "\titers: 800, epoch: 16 | loss: 0.0418555\n",
      "\tspeed: 0.0415s/iter; left time: 154.5318s\n",
      "\titers: 900, epoch: 16 | loss: 0.0435021\n",
      "\tspeed: 0.0415s/iter; left time: 150.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0420716 Vali Loss: 0.0813945 Test Loss: 0.0900143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022085649892687798, rmse:0.14861240983009338, mae:0.08917967230081558, rse:0.5748723149299622\n",
      "Intermediate time for FR and pred_len 96: 00h:22m:47.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1909381\n",
      "\tspeed: 0.0731s/iter; left time: 1312.3339s\n",
      "\titers: 200, epoch: 1 | loss: 0.1680391\n",
      "\tspeed: 0.0507s/iter; left time: 904.6320s\n",
      "\titers: 300, epoch: 1 | loss: 0.1600669\n",
      "\tspeed: 0.0508s/iter; left time: 900.5058s\n",
      "\titers: 400, epoch: 1 | loss: 0.1592189\n",
      "\tspeed: 0.0508s/iter; left time: 896.9464s\n",
      "\titers: 500, epoch: 1 | loss: 0.1627102\n",
      "\tspeed: 0.0507s/iter; left time: 889.1758s\n",
      "\titers: 600, epoch: 1 | loss: 0.1537818\n",
      "\tspeed: 0.0509s/iter; left time: 887.1121s\n",
      "\titers: 700, epoch: 1 | loss: 0.1487422\n",
      "\tspeed: 0.0509s/iter; left time: 882.5645s\n",
      "\titers: 800, epoch: 1 | loss: 0.1472233\n",
      "\tspeed: 0.0508s/iter; left time: 876.6289s\n",
      "\titers: 900, epoch: 1 | loss: 0.1481563\n",
      "\tspeed: 0.0508s/iter; left time: 871.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1627582 Vali Loss: 0.1600794 Test Loss: 0.1866036\n",
      "Validation loss decreased (inf --> 0.160079).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1354579\n",
      "\tspeed: 0.1418s/iter; left time: 2415.9916s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132466\n",
      "\tspeed: 0.0504s/iter; left time: 852.9638s\n",
      "\titers: 300, epoch: 2 | loss: 0.1104991\n",
      "\tspeed: 0.0503s/iter; left time: 847.4892s\n",
      "\titers: 400, epoch: 2 | loss: 0.1086443\n",
      "\tspeed: 0.0503s/iter; left time: 841.3644s\n",
      "\titers: 500, epoch: 2 | loss: 0.1163496\n",
      "\tspeed: 0.0503s/iter; left time: 837.1216s\n",
      "\titers: 600, epoch: 2 | loss: 0.1089604\n",
      "\tspeed: 0.0504s/iter; left time: 834.3447s\n",
      "\titers: 700, epoch: 2 | loss: 0.1045236\n",
      "\tspeed: 0.0504s/iter; left time: 828.4931s\n",
      "\titers: 800, epoch: 2 | loss: 0.0951248\n",
      "\tspeed: 0.0503s/iter; left time: 821.6065s\n",
      "\titers: 900, epoch: 2 | loss: 0.0957951\n",
      "\tspeed: 0.0503s/iter; left time: 817.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.1135591 Vali Loss: 0.1164185 Test Loss: 0.1333146\n",
      "Validation loss decreased (0.160079 --> 0.116418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982654\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013190\n",
      "\tspeed: 0.0505s/iter; left time: 809.4094s\n",
      "\titers: 300, epoch: 3 | loss: 0.0925633\n",
      "\tspeed: 0.0504s/iter; left time: 803.6832s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857650\n",
      "\tspeed: 0.0504s/iter; left time: 798.1677s\n",
      "\titers: 500, epoch: 3 | loss: 0.0912207\n",
      "\tspeed: 0.0504s/iter; left time: 792.8329s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933190\n",
      "\tspeed: 0.0504s/iter; left time: 787.6501s\n",
      "\titers: 700, epoch: 3 | loss: 0.0857234\n",
      "\tspeed: 0.0504s/iter; left time: 783.2593s\n",
      "\titers: 800, epoch: 3 | loss: 0.0845863\n",
      "\tspeed: 0.0504s/iter; left time: 777.4839s\n",
      "\titers: 900, epoch: 3 | loss: 0.0849761\n",
      "\tspeed: 0.0504s/iter; left time: 772.3460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0924629 Vali Loss: 0.1071270 Test Loss: 0.1229606\n",
      "Validation loss decreased (0.116418 --> 0.107127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786718\n",
      "\tspeed: 0.1427s/iter; left time: 2173.8139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772330\n",
      "\tspeed: 0.0508s/iter; left time: 769.2309s\n",
      "\titers: 300, epoch: 4 | loss: 0.0676827\n",
      "\tspeed: 0.0508s/iter; left time: 764.0135s\n",
      "\titers: 400, epoch: 4 | loss: 0.0790973\n",
      "\tspeed: 0.0508s/iter; left time: 758.7215s\n",
      "\titers: 500, epoch: 4 | loss: 0.0708028\n",
      "\tspeed: 0.0508s/iter; left time: 753.5663s\n",
      "\titers: 600, epoch: 4 | loss: 0.0716025\n",
      "\tspeed: 0.0508s/iter; left time: 748.6905s\n",
      "\titers: 700, epoch: 4 | loss: 0.0682254\n",
      "\tspeed: 0.0509s/iter; left time: 744.3430s\n",
      "\titers: 800, epoch: 4 | loss: 0.0689737\n",
      "\tspeed: 0.0509s/iter; left time: 740.2185s\n",
      "\titers: 900, epoch: 4 | loss: 0.0658434\n",
      "\tspeed: 0.0509s/iter; left time: 735.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 902 | Train Loss: 0.0725442 Vali Loss: 0.0860735 Test Loss: 0.0965769\n",
      "Validation loss decreased (0.107127 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0697073\n",
      "\tspeed: 0.1409s/iter; left time: 2019.6899s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624888\n",
      "\tspeed: 0.0504s/iter; left time: 716.8856s\n",
      "\titers: 300, epoch: 5 | loss: 0.0617630\n",
      "\tspeed: 0.0504s/iter; left time: 711.9624s\n",
      "\titers: 400, epoch: 5 | loss: 0.0649016\n",
      "\tspeed: 0.0504s/iter; left time: 707.4037s\n",
      "\titers: 500, epoch: 5 | loss: 0.0683278\n",
      "\tspeed: 0.0503s/iter; left time: 701.4687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693546\n",
      "\tspeed: 0.0504s/iter; left time: 696.8262s\n",
      "\titers: 700, epoch: 5 | loss: 0.0664765\n",
      "\tspeed: 0.0504s/iter; left time: 691.6092s\n",
      "\titers: 800, epoch: 5 | loss: 0.0678215\n",
      "\tspeed: 0.0504s/iter; left time: 687.0570s\n",
      "\titers: 900, epoch: 5 | loss: 0.0628805\n",
      "\tspeed: 0.0504s/iter; left time: 681.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0666008 Vali Loss: 0.0907133 Test Loss: 0.1022113\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630694\n",
      "\tspeed: 0.1370s/iter; left time: 1839.6319s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735694\n",
      "\tspeed: 0.0509s/iter; left time: 678.4986s\n",
      "\titers: 300, epoch: 6 | loss: 0.0657603\n",
      "\tspeed: 0.0504s/iter; left time: 667.1797s\n",
      "\titers: 400, epoch: 6 | loss: 0.0630703\n",
      "\tspeed: 0.0504s/iter; left time: 662.3338s\n",
      "\titers: 500, epoch: 6 | loss: 0.0608161\n",
      "\tspeed: 0.0505s/iter; left time: 657.7881s\n",
      "\titers: 600, epoch: 6 | loss: 0.0605147\n",
      "\tspeed: 0.0504s/iter; left time: 652.2240s\n",
      "\titers: 700, epoch: 6 | loss: 0.0623604\n",
      "\tspeed: 0.0505s/iter; left time: 647.8566s\n",
      "\titers: 800, epoch: 6 | loss: 0.0683586\n",
      "\tspeed: 0.0504s/iter; left time: 641.5434s\n",
      "\titers: 900, epoch: 6 | loss: 0.0637278\n",
      "\tspeed: 0.0504s/iter; left time: 636.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0630607 Vali Loss: 0.0877217 Test Loss: 0.1008626\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606438\n",
      "\tspeed: 0.1377s/iter; left time: 1725.1466s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599479\n",
      "\tspeed: 0.0508s/iter; left time: 631.3995s\n",
      "\titers: 300, epoch: 7 | loss: 0.0584510\n",
      "\tspeed: 0.0508s/iter; left time: 626.5690s\n",
      "\titers: 400, epoch: 7 | loss: 0.0613597\n",
      "\tspeed: 0.0508s/iter; left time: 621.3450s\n",
      "\titers: 500, epoch: 7 | loss: 0.0601924\n",
      "\tspeed: 0.0508s/iter; left time: 615.9718s\n",
      "\titers: 600, epoch: 7 | loss: 0.0676273\n",
      "\tspeed: 0.0508s/iter; left time: 611.1803s\n",
      "\titers: 700, epoch: 7 | loss: 0.0549083\n",
      "\tspeed: 0.0508s/iter; left time: 606.1187s\n",
      "\titers: 800, epoch: 7 | loss: 0.0545960\n",
      "\tspeed: 0.0508s/iter; left time: 600.9414s\n",
      "\titers: 900, epoch: 7 | loss: 0.0554606\n",
      "\tspeed: 0.0504s/iter; left time: 591.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0600904 Vali Loss: 0.0871552 Test Loss: 0.0970986\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0598685\n",
      "\tspeed: 0.1370s/iter; left time: 1592.5344s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554238\n",
      "\tspeed: 0.0505s/iter; left time: 582.0014s\n",
      "\titers: 300, epoch: 8 | loss: 0.0563658\n",
      "\tspeed: 0.0505s/iter; left time: 576.7205s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521641\n",
      "\tspeed: 0.0504s/iter; left time: 570.6692s\n",
      "\titers: 500, epoch: 8 | loss: 0.0586885\n",
      "\tspeed: 0.0504s/iter; left time: 566.0399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0537777\n",
      "\tspeed: 0.0504s/iter; left time: 560.2831s\n",
      "\titers: 700, epoch: 8 | loss: 0.0583096\n",
      "\tspeed: 0.0505s/iter; left time: 556.6289s\n",
      "\titers: 800, epoch: 8 | loss: 0.0598436\n",
      "\tspeed: 0.0505s/iter; left time: 551.8235s\n",
      "\titers: 900, epoch: 8 | loss: 0.0546309\n",
      "\tspeed: 0.0504s/iter; left time: 546.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0570632 Vali Loss: 0.0868398 Test Loss: 0.0970632\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570800\n",
      "\tspeed: 0.1395s/iter; left time: 1495.6201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0570607\n",
      "\tspeed: 0.0510s/iter; left time: 541.7118s\n",
      "\titers: 300, epoch: 9 | loss: 0.0564059\n",
      "\tspeed: 0.0508s/iter; left time: 534.7881s\n",
      "\titers: 400, epoch: 9 | loss: 0.0511184\n",
      "\tspeed: 0.0508s/iter; left time: 529.3799s\n",
      "\titers: 500, epoch: 9 | loss: 0.0548899\n",
      "\tspeed: 0.0509s/iter; left time: 525.9523s\n",
      "\titers: 600, epoch: 9 | loss: 0.0602870\n",
      "\tspeed: 0.0506s/iter; left time: 517.3814s\n",
      "\titers: 700, epoch: 9 | loss: 0.0530320\n",
      "\tspeed: 0.0504s/iter; left time: 510.6846s\n",
      "\titers: 800, epoch: 9 | loss: 0.0585114\n",
      "\tspeed: 0.0504s/iter; left time: 505.1865s\n",
      "\titers: 900, epoch: 9 | loss: 0.0489683\n",
      "\tspeed: 0.0504s/iter; left time: 499.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0545657 Vali Loss: 0.0866638 Test Loss: 0.0968798\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024343758821487427, rmse:0.15602487325668335, mae:0.09656928479671478, rse:0.6042738556861877\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1787698\n",
      "\tspeed: 0.0528s/iter; left time: 947.9105s\n",
      "\titers: 200, epoch: 1 | loss: 0.1756977\n",
      "\tspeed: 0.0507s/iter; left time: 904.1720s\n",
      "\titers: 300, epoch: 1 | loss: 0.1726988\n",
      "\tspeed: 0.0503s/iter; left time: 892.9432s\n",
      "\titers: 400, epoch: 1 | loss: 0.1645466\n",
      "\tspeed: 0.0504s/iter; left time: 888.6241s\n",
      "\titers: 500, epoch: 1 | loss: 0.1546046\n",
      "\tspeed: 0.0504s/iter; left time: 883.5847s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575418\n",
      "\tspeed: 0.0504s/iter; left time: 878.7539s\n",
      "\titers: 700, epoch: 1 | loss: 0.1498622\n",
      "\tspeed: 0.0503s/iter; left time: 873.0147s\n",
      "\titers: 800, epoch: 1 | loss: 0.1442681\n",
      "\tspeed: 0.0504s/iter; left time: 869.3829s\n",
      "\titers: 900, epoch: 1 | loss: 0.1440777\n",
      "\tspeed: 0.0504s/iter; left time: 863.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.1643646 Vali Loss: 0.1578211 Test Loss: 0.1845102\n",
      "Validation loss decreased (inf --> 0.157821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1305881\n",
      "\tspeed: 0.1433s/iter; left time: 2441.5336s\n",
      "\titers: 200, epoch: 2 | loss: 0.1231588\n",
      "\tspeed: 0.0508s/iter; left time: 860.5270s\n",
      "\titers: 300, epoch: 2 | loss: 0.1234287\n",
      "\tspeed: 0.0509s/iter; left time: 856.2911s\n",
      "\titers: 400, epoch: 2 | loss: 0.1189174\n",
      "\tspeed: 0.0506s/iter; left time: 846.5236s\n",
      "\titers: 500, epoch: 2 | loss: 0.1040148\n",
      "\tspeed: 0.0504s/iter; left time: 838.9250s\n",
      "\titers: 600, epoch: 2 | loss: 0.1109011\n",
      "\tspeed: 0.0505s/iter; left time: 835.5339s\n",
      "\titers: 700, epoch: 2 | loss: 0.0989013\n",
      "\tspeed: 0.0510s/iter; left time: 838.0980s\n",
      "\titers: 800, epoch: 2 | loss: 0.1028772\n",
      "\tspeed: 0.0510s/iter; left time: 832.7449s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027167\n",
      "\tspeed: 0.0509s/iter; left time: 826.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 902 | Train Loss: 0.1155884 Vali Loss: 0.1181208 Test Loss: 0.1364703\n",
      "Validation loss decreased (0.157821 --> 0.118121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007679\n",
      "\tspeed: 0.1420s/iter; left time: 2291.0337s\n",
      "\titers: 200, epoch: 3 | loss: 0.0926124\n",
      "\tspeed: 0.0504s/iter; left time: 808.8751s\n",
      "\titers: 300, epoch: 3 | loss: 0.0921094\n",
      "\tspeed: 0.0504s/iter; left time: 802.8691s\n",
      "\titers: 400, epoch: 3 | loss: 0.0896702\n",
      "\tspeed: 0.0505s/iter; left time: 799.8326s\n",
      "\titers: 500, epoch: 3 | loss: 0.0918375\n",
      "\tspeed: 0.0505s/iter; left time: 794.0894s\n",
      "\titers: 600, epoch: 3 | loss: 0.0904693\n",
      "\tspeed: 0.0505s/iter; left time: 789.4782s\n",
      "\titers: 700, epoch: 3 | loss: 0.0870313\n",
      "\tspeed: 0.0505s/iter; left time: 785.1167s\n",
      "\titers: 800, epoch: 3 | loss: 0.0861187\n",
      "\tspeed: 0.0504s/iter; left time: 778.1310s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808909\n",
      "\tspeed: 0.0504s/iter; left time: 773.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0923859 Vali Loss: 0.0995988 Test Loss: 0.1143600\n",
      "Validation loss decreased (0.118121 --> 0.099599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0715621\n",
      "\tspeed: 0.1421s/iter; left time: 2165.4658s\n",
      "\titers: 200, epoch: 4 | loss: 0.0746090\n",
      "\tspeed: 0.0504s/iter; left time: 763.2307s\n",
      "\titers: 300, epoch: 4 | loss: 0.0718534\n",
      "\tspeed: 0.0505s/iter; left time: 759.2869s\n",
      "\titers: 400, epoch: 4 | loss: 0.0711537\n",
      "\tspeed: 0.0505s/iter; left time: 754.1019s\n",
      "\titers: 500, epoch: 4 | loss: 0.0706193\n",
      "\tspeed: 0.0505s/iter; left time: 749.3533s\n",
      "\titers: 600, epoch: 4 | loss: 0.0673912\n",
      "\tspeed: 0.0509s/iter; left time: 749.8819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0730096\n",
      "\tspeed: 0.0509s/iter; left time: 745.2173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0678658\n",
      "\tspeed: 0.0509s/iter; left time: 739.5509s\n",
      "\titers: 900, epoch: 4 | loss: 0.0666774\n",
      "\tspeed: 0.0504s/iter; left time: 728.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 902 | Train Loss: 0.0718374 Vali Loss: 0.0865255 Test Loss: 0.0977247\n",
      "Validation loss decreased (0.099599 --> 0.086525).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0699938\n",
      "\tspeed: 0.1422s/iter; left time: 2037.8694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737990\n",
      "\tspeed: 0.0509s/iter; left time: 724.3411s\n",
      "\titers: 300, epoch: 5 | loss: 0.0675461\n",
      "\tspeed: 0.0508s/iter; left time: 718.6058s\n",
      "\titers: 400, epoch: 5 | loss: 0.0678671\n",
      "\tspeed: 0.0505s/iter; left time: 709.2199s\n",
      "\titers: 500, epoch: 5 | loss: 0.0709195\n",
      "\tspeed: 0.0504s/iter; left time: 702.5562s\n",
      "\titers: 600, epoch: 5 | loss: 0.0634956\n",
      "\tspeed: 0.0504s/iter; left time: 697.4582s\n",
      "\titers: 700, epoch: 5 | loss: 0.0716952\n",
      "\tspeed: 0.0504s/iter; left time: 692.1110s\n",
      "\titers: 800, epoch: 5 | loss: 0.0626705\n",
      "\tspeed: 0.0504s/iter; left time: 686.9049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0658662\n",
      "\tspeed: 0.0506s/iter; left time: 684.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.0667991 Vali Loss: 0.0870556 Test Loss: 0.0983676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631729\n",
      "\tspeed: 0.1376s/iter; left time: 1847.8868s\n",
      "\titers: 200, epoch: 6 | loss: 0.0667560\n",
      "\tspeed: 0.0504s/iter; left time: 672.2412s\n",
      "\titers: 300, epoch: 6 | loss: 0.0655189\n",
      "\tspeed: 0.0505s/iter; left time: 667.6030s\n",
      "\titers: 400, epoch: 6 | loss: 0.0713132\n",
      "\tspeed: 0.0505s/iter; left time: 663.0947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0651720\n",
      "\tspeed: 0.0505s/iter; left time: 658.5894s\n",
      "\titers: 600, epoch: 6 | loss: 0.0628549\n",
      "\tspeed: 0.0504s/iter; left time: 651.5607s\n",
      "\titers: 700, epoch: 6 | loss: 0.0626928\n",
      "\tspeed: 0.0505s/iter; left time: 647.3282s\n",
      "\titers: 800, epoch: 6 | loss: 0.0640463\n",
      "\tspeed: 0.0504s/iter; left time: 641.8127s\n",
      "\titers: 900, epoch: 6 | loss: 0.0650508\n",
      "\tspeed: 0.0504s/iter; left time: 636.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0635975 Vali Loss: 0.0885732 Test Loss: 0.0982766\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599360\n",
      "\tspeed: 0.1378s/iter; left time: 1725.9544s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667914\n",
      "\tspeed: 0.0504s/iter; left time: 626.5123s\n",
      "\titers: 300, epoch: 7 | loss: 0.0598708\n",
      "\tspeed: 0.0505s/iter; left time: 622.5029s\n",
      "\titers: 400, epoch: 7 | loss: 0.0618586\n",
      "\tspeed: 0.0504s/iter; left time: 616.3025s\n",
      "\titers: 500, epoch: 7 | loss: 0.0605755\n",
      "\tspeed: 0.0505s/iter; left time: 612.4694s\n",
      "\titers: 600, epoch: 7 | loss: 0.0601703\n",
      "\tspeed: 0.0505s/iter; left time: 607.2587s\n",
      "\titers: 700, epoch: 7 | loss: 0.0572209\n",
      "\tspeed: 0.0505s/iter; left time: 602.3009s\n",
      "\titers: 800, epoch: 7 | loss: 0.0604722\n",
      "\tspeed: 0.0505s/iter; left time: 597.2390s\n",
      "\titers: 900, epoch: 7 | loss: 0.0577094\n",
      "\tspeed: 0.0504s/iter; left time: 591.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0607851 Vali Loss: 0.0876664 Test Loss: 0.0979006\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569773\n",
      "\tspeed: 0.1371s/iter; left time: 1593.5984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633521\n",
      "\tspeed: 0.0504s/iter; left time: 580.9436s\n",
      "\titers: 300, epoch: 8 | loss: 0.0593943\n",
      "\tspeed: 0.0504s/iter; left time: 576.3091s\n",
      "\titers: 400, epoch: 8 | loss: 0.0533727\n",
      "\tspeed: 0.0504s/iter; left time: 571.3853s\n",
      "\titers: 500, epoch: 8 | loss: 0.0565611\n",
      "\tspeed: 0.0504s/iter; left time: 566.2452s\n",
      "\titers: 600, epoch: 8 | loss: 0.0577994\n",
      "\tspeed: 0.0504s/iter; left time: 561.2605s\n",
      "\titers: 700, epoch: 8 | loss: 0.0628309\n",
      "\tspeed: 0.0504s/iter; left time: 556.1685s\n",
      "\titers: 800, epoch: 8 | loss: 0.0571598\n",
      "\tspeed: 0.0505s/iter; left time: 551.2688s\n",
      "\titers: 900, epoch: 8 | loss: 0.0570874\n",
      "\tspeed: 0.0504s/iter; left time: 546.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0579347 Vali Loss: 0.0868271 Test Loss: 0.0977674\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0567947\n",
      "\tspeed: 0.1387s/iter; left time: 1487.3222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0572171\n",
      "\tspeed: 0.0505s/iter; left time: 536.7575s\n",
      "\titers: 300, epoch: 9 | loss: 0.0628344\n",
      "\tspeed: 0.0508s/iter; left time: 534.4601s\n",
      "\titers: 400, epoch: 9 | loss: 0.0569898\n",
      "\tspeed: 0.0505s/iter; left time: 526.7027s\n",
      "\titers: 500, epoch: 9 | loss: 0.0498729\n",
      "\tspeed: 0.0504s/iter; left time: 520.5277s\n",
      "\titers: 600, epoch: 9 | loss: 0.0571429\n",
      "\tspeed: 0.0509s/iter; left time: 520.5847s\n",
      "\titers: 700, epoch: 9 | loss: 0.0585564\n",
      "\tspeed: 0.0509s/iter; left time: 515.6574s\n",
      "\titers: 800, epoch: 9 | loss: 0.0577915\n",
      "\tspeed: 0.0504s/iter; left time: 505.6153s\n",
      "\titers: 900, epoch: 9 | loss: 0.0516842\n",
      "\tspeed: 0.0507s/iter; left time: 503.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0556215 Vali Loss: 0.0889604 Test Loss: 0.0997862\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024290841072797775, rmse:0.155855193734169, mae:0.09771759808063507, rse:0.6036167144775391\n",
      "Intermediate time for FR and pred_len 168: 00h:16m:38.56s\n",
      "Intermediate time for FR: 01h:03m:01.02s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2289756\n",
      "\tspeed: 0.0571s/iter; left time: 1028.6264s\n",
      "\titers: 200, epoch: 1 | loss: 0.2147405\n",
      "\tspeed: 0.0344s/iter; left time: 616.8185s\n",
      "\titers: 300, epoch: 1 | loss: 0.2024794\n",
      "\tspeed: 0.0344s/iter; left time: 612.3553s\n",
      "\titers: 400, epoch: 1 | loss: 0.1978398\n",
      "\tspeed: 0.0344s/iter; left time: 608.9401s\n",
      "\titers: 500, epoch: 1 | loss: 0.1838570\n",
      "\tspeed: 0.0344s/iter; left time: 605.7099s\n",
      "\titers: 600, epoch: 1 | loss: 0.1871906\n",
      "\tspeed: 0.0342s/iter; left time: 599.0307s\n",
      "\titers: 700, epoch: 1 | loss: 0.1718587\n",
      "\tspeed: 0.0338s/iter; left time: 589.5431s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741228\n",
      "\tspeed: 0.0338s/iter; left time: 585.1718s\n",
      "\titers: 900, epoch: 1 | loss: 0.1741925\n",
      "\tspeed: 0.0339s/iter; left time: 583.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.1946895 Vali Loss: 0.1531637 Test Loss: 0.1688930\n",
      "Validation loss decreased (inf --> 0.153164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200996\n",
      "\tspeed: 0.0980s/iter; left time: 1676.6751s\n",
      "\titers: 200, epoch: 2 | loss: 0.0943886\n",
      "\tspeed: 0.0344s/iter; left time: 585.0408s\n",
      "\titers: 300, epoch: 2 | loss: 0.0873010\n",
      "\tspeed: 0.0344s/iter; left time: 581.0857s\n",
      "\titers: 400, epoch: 2 | loss: 0.0911078\n",
      "\tspeed: 0.0344s/iter; left time: 577.9463s\n",
      "\titers: 500, epoch: 2 | loss: 0.0900601\n",
      "\tspeed: 0.0344s/iter; left time: 574.3511s\n",
      "\titers: 600, epoch: 2 | loss: 0.0939043\n",
      "\tspeed: 0.0343s/iter; left time: 570.6688s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763428\n",
      "\tspeed: 0.0343s/iter; left time: 566.8765s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738119\n",
      "\tspeed: 0.0343s/iter; left time: 563.4438s\n",
      "\titers: 900, epoch: 2 | loss: 0.0727385\n",
      "\tspeed: 0.0343s/iter; left time: 560.2103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0941843 Vali Loss: 0.0731850 Test Loss: 0.0763463\n",
      "Validation loss decreased (0.153164 --> 0.073185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689264\n",
      "\tspeed: 0.0987s/iter; left time: 1600.0744s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680265\n",
      "\tspeed: 0.0338s/iter; left time: 544.5820s\n",
      "\titers: 300, epoch: 3 | loss: 0.0720875\n",
      "\tspeed: 0.0338s/iter; left time: 541.3244s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637039\n",
      "\tspeed: 0.0338s/iter; left time: 538.2675s\n",
      "\titers: 500, epoch: 3 | loss: 0.0603021\n",
      "\tspeed: 0.0338s/iter; left time: 534.1296s\n",
      "\titers: 600, epoch: 3 | loss: 0.0701781\n",
      "\tspeed: 0.0338s/iter; left time: 531.0419s\n",
      "\titers: 700, epoch: 3 | loss: 0.0690891\n",
      "\tspeed: 0.0338s/iter; left time: 527.4586s\n",
      "\titers: 800, epoch: 3 | loss: 0.0771389\n",
      "\tspeed: 0.0338s/iter; left time: 524.0841s\n",
      "\titers: 900, epoch: 3 | loss: 0.0653842\n",
      "\tspeed: 0.0338s/iter; left time: 520.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.91s\n",
      "Steps: 906 | Train Loss: 0.0697471 Vali Loss: 0.0669245 Test Loss: 0.0713615\n",
      "Validation loss decreased (0.073185 --> 0.066924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727013\n",
      "\tspeed: 0.0986s/iter; left time: 1508.1638s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631000\n",
      "\tspeed: 0.0344s/iter; left time: 522.7673s\n",
      "\titers: 300, epoch: 4 | loss: 0.0641052\n",
      "\tspeed: 0.0344s/iter; left time: 519.2833s\n",
      "\titers: 400, epoch: 4 | loss: 0.0677283\n",
      "\tspeed: 0.0344s/iter; left time: 515.5153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0661093\n",
      "\tspeed: 0.0344s/iter; left time: 512.0733s\n",
      "\titers: 600, epoch: 4 | loss: 0.0596208\n",
      "\tspeed: 0.0344s/iter; left time: 509.0584s\n",
      "\titers: 700, epoch: 4 | loss: 0.0618208\n",
      "\tspeed: 0.0344s/iter; left time: 505.2721s\n",
      "\titers: 800, epoch: 4 | loss: 0.0644566\n",
      "\tspeed: 0.0344s/iter; left time: 501.6529s\n",
      "\titers: 900, epoch: 4 | loss: 0.0667040\n",
      "\tspeed: 0.0344s/iter; left time: 498.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.44s\n",
      "Steps: 906 | Train Loss: 0.0649319 Vali Loss: 0.0651137 Test Loss: 0.0699982\n",
      "Validation loss decreased (0.066924 --> 0.065114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597008\n",
      "\tspeed: 0.1023s/iter; left time: 1472.9348s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717447\n",
      "\tspeed: 0.0344s/iter; left time: 491.7666s\n",
      "\titers: 300, epoch: 5 | loss: 0.0594414\n",
      "\tspeed: 0.0344s/iter; left time: 487.9869s\n",
      "\titers: 400, epoch: 5 | loss: 0.0574381\n",
      "\tspeed: 0.0344s/iter; left time: 484.3206s\n",
      "\titers: 500, epoch: 5 | loss: 0.0629130\n",
      "\tspeed: 0.0344s/iter; left time: 481.3928s\n",
      "\titers: 600, epoch: 5 | loss: 0.0602561\n",
      "\tspeed: 0.0341s/iter; left time: 473.7533s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723139\n",
      "\tspeed: 0.0338s/iter; left time: 466.4928s\n",
      "\titers: 800, epoch: 5 | loss: 0.0493080\n",
      "\tspeed: 0.0339s/iter; left time: 463.7789s\n",
      "\titers: 900, epoch: 5 | loss: 0.0612842\n",
      "\tspeed: 0.0338s/iter; left time: 459.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.0610163 Vali Loss: 0.0614561 Test Loss: 0.0658055\n",
      "Validation loss decreased (0.065114 --> 0.061456).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591033\n",
      "\tspeed: 0.0984s/iter; left time: 1327.4845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583568\n",
      "\tspeed: 0.0345s/iter; left time: 461.3400s\n",
      "\titers: 300, epoch: 6 | loss: 0.0663953\n",
      "\tspeed: 0.0344s/iter; left time: 457.4677s\n",
      "\titers: 400, epoch: 6 | loss: 0.0580835\n",
      "\tspeed: 0.0344s/iter; left time: 454.0186s\n",
      "\titers: 500, epoch: 6 | loss: 0.0495465\n",
      "\tspeed: 0.0344s/iter; left time: 450.4742s\n",
      "\titers: 600, epoch: 6 | loss: 0.0566977\n",
      "\tspeed: 0.0344s/iter; left time: 447.1341s\n",
      "\titers: 700, epoch: 6 | loss: 0.0582300\n",
      "\tspeed: 0.0344s/iter; left time: 443.7517s\n",
      "\titers: 800, epoch: 6 | loss: 0.0565420\n",
      "\tspeed: 0.0344s/iter; left time: 439.5191s\n",
      "\titers: 900, epoch: 6 | loss: 0.0544238\n",
      "\tspeed: 0.0344s/iter; left time: 436.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0582357 Vali Loss: 0.0605395 Test Loss: 0.0657733\n",
      "Validation loss decreased (0.061456 --> 0.060540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0518394\n",
      "\tspeed: 0.0998s/iter; left time: 1255.3815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625482\n",
      "\tspeed: 0.0339s/iter; left time: 423.0757s\n",
      "\titers: 300, epoch: 7 | loss: 0.0538388\n",
      "\tspeed: 0.0339s/iter; left time: 419.8996s\n",
      "\titers: 400, epoch: 7 | loss: 0.0608252\n",
      "\tspeed: 0.0339s/iter; left time: 416.6479s\n",
      "\titers: 500, epoch: 7 | loss: 0.0573636\n",
      "\tspeed: 0.0339s/iter; left time: 412.7597s\n",
      "\titers: 600, epoch: 7 | loss: 0.0511362\n",
      "\tspeed: 0.0339s/iter; left time: 409.0841s\n",
      "\titers: 700, epoch: 7 | loss: 0.0534262\n",
      "\tspeed: 0.0339s/iter; left time: 405.9108s\n",
      "\titers: 800, epoch: 7 | loss: 0.0597523\n",
      "\tspeed: 0.0339s/iter; left time: 402.6076s\n",
      "\titers: 900, epoch: 7 | loss: 0.0498654\n",
      "\tspeed: 0.0339s/iter; left time: 399.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.99s\n",
      "Steps: 906 | Train Loss: 0.0561592 Vali Loss: 0.0586244 Test Loss: 0.0642837\n",
      "Validation loss decreased (0.060540 --> 0.058624).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0509520\n",
      "\tspeed: 0.0982s/iter; left time: 1147.2853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0509359\n",
      "\tspeed: 0.0344s/iter; left time: 398.2165s\n",
      "\titers: 300, epoch: 8 | loss: 0.0527956\n",
      "\tspeed: 0.0344s/iter; left time: 394.5786s\n",
      "\titers: 400, epoch: 8 | loss: 0.0565501\n",
      "\tspeed: 0.0344s/iter; left time: 391.4198s\n",
      "\titers: 500, epoch: 8 | loss: 0.0532382\n",
      "\tspeed: 0.0344s/iter; left time: 387.9617s\n",
      "\titers: 600, epoch: 8 | loss: 0.0565472\n",
      "\tspeed: 0.0344s/iter; left time: 384.0717s\n",
      "\titers: 700, epoch: 8 | loss: 0.0503138\n",
      "\tspeed: 0.0344s/iter; left time: 380.9368s\n",
      "\titers: 800, epoch: 8 | loss: 0.0552599\n",
      "\tspeed: 0.0344s/iter; left time: 377.7964s\n",
      "\titers: 900, epoch: 8 | loss: 0.0519355\n",
      "\tspeed: 0.0344s/iter; left time: 374.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0541787 Vali Loss: 0.0579991 Test Loss: 0.0646259\n",
      "Validation loss decreased (0.058624 --> 0.057999).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463596\n",
      "\tspeed: 0.0994s/iter; left time: 1071.2717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533909\n",
      "\tspeed: 0.0339s/iter; left time: 362.2133s\n",
      "\titers: 300, epoch: 9 | loss: 0.0609420\n",
      "\tspeed: 0.0339s/iter; left time: 357.8963s\n",
      "\titers: 400, epoch: 9 | loss: 0.0476018\n",
      "\tspeed: 0.0338s/iter; left time: 354.5008s\n",
      "\titers: 500, epoch: 9 | loss: 0.0494947\n",
      "\tspeed: 0.0344s/iter; left time: 356.5728s\n",
      "\titers: 600, epoch: 9 | loss: 0.0558363\n",
      "\tspeed: 0.0344s/iter; left time: 353.4206s\n",
      "\titers: 700, epoch: 9 | loss: 0.0526480\n",
      "\tspeed: 0.0344s/iter; left time: 349.5025s\n",
      "\titers: 800, epoch: 9 | loss: 0.0504616\n",
      "\tspeed: 0.0344s/iter; left time: 346.5170s\n",
      "\titers: 900, epoch: 9 | loss: 0.0483640\n",
      "\tspeed: 0.0344s/iter; left time: 342.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 906 | Train Loss: 0.0524793 Vali Loss: 0.0583450 Test Loss: 0.0629489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541091\n",
      "\tspeed: 0.0952s/iter; left time: 939.3233s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536419\n",
      "\tspeed: 0.0344s/iter; left time: 336.0498s\n",
      "\titers: 300, epoch: 10 | loss: 0.0514194\n",
      "\tspeed: 0.0344s/iter; left time: 332.4185s\n",
      "\titers: 400, epoch: 10 | loss: 0.0504203\n",
      "\tspeed: 0.0344s/iter; left time: 328.9377s\n",
      "\titers: 500, epoch: 10 | loss: 0.0432660\n",
      "\tspeed: 0.0344s/iter; left time: 326.0878s\n",
      "\titers: 600, epoch: 10 | loss: 0.0556666\n",
      "\tspeed: 0.0344s/iter; left time: 322.5387s\n",
      "\titers: 700, epoch: 10 | loss: 0.0505122\n",
      "\tspeed: 0.0344s/iter; left time: 318.9934s\n",
      "\titers: 800, epoch: 10 | loss: 0.0518186\n",
      "\tspeed: 0.0344s/iter; left time: 315.5373s\n",
      "\titers: 900, epoch: 10 | loss: 0.0462847\n",
      "\tspeed: 0.0344s/iter; left time: 312.0584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0511121 Vali Loss: 0.0566754 Test Loss: 0.0640028\n",
      "Validation loss decreased (0.057999 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0522779\n",
      "\tspeed: 0.0990s/iter; left time: 886.7043s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463553\n",
      "\tspeed: 0.0339s/iter; left time: 300.1341s\n",
      "\titers: 300, epoch: 11 | loss: 0.0524409\n",
      "\tspeed: 0.0339s/iter; left time: 296.7200s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493511\n",
      "\tspeed: 0.0339s/iter; left time: 293.1921s\n",
      "\titers: 500, epoch: 11 | loss: 0.0535235\n",
      "\tspeed: 0.0339s/iter; left time: 289.8067s\n",
      "\titers: 600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.0339s/iter; left time: 286.5283s\n",
      "\titers: 700, epoch: 11 | loss: 0.0487254\n",
      "\tspeed: 0.0339s/iter; left time: 283.1318s\n",
      "\titers: 800, epoch: 11 | loss: 0.0524150\n",
      "\tspeed: 0.0340s/iter; left time: 280.5251s\n",
      "\titers: 900, epoch: 11 | loss: 0.0441130\n",
      "\tspeed: 0.0344s/iter; left time: 280.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0498137 Vali Loss: 0.0567335 Test Loss: 0.0640843\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454959\n",
      "\tspeed: 0.0955s/iter; left time: 769.3419s\n",
      "\titers: 200, epoch: 12 | loss: 0.0510769\n",
      "\tspeed: 0.0344s/iter; left time: 273.4583s\n",
      "\titers: 300, epoch: 12 | loss: 0.0456563\n",
      "\tspeed: 0.0344s/iter; left time: 270.4168s\n",
      "\titers: 400, epoch: 12 | loss: 0.0503837\n",
      "\tspeed: 0.0344s/iter; left time: 266.6420s\n",
      "\titers: 500, epoch: 12 | loss: 0.0526142\n",
      "\tspeed: 0.0344s/iter; left time: 263.1913s\n",
      "\titers: 600, epoch: 12 | loss: 0.0477144\n",
      "\tspeed: 0.0344s/iter; left time: 259.7137s\n",
      "\titers: 700, epoch: 12 | loss: 0.0439736\n",
      "\tspeed: 0.0344s/iter; left time: 256.6034s\n",
      "\titers: 800, epoch: 12 | loss: 0.0518971\n",
      "\tspeed: 0.0344s/iter; left time: 253.0095s\n",
      "\titers: 900, epoch: 12 | loss: 0.0473772\n",
      "\tspeed: 0.0339s/iter; left time: 246.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0486576 Vali Loss: 0.0559295 Test Loss: 0.0642169\n",
      "Validation loss decreased (0.056675 --> 0.055930).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0414750\n",
      "\tspeed: 0.0990s/iter; left time: 707.4082s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494478\n",
      "\tspeed: 0.0344s/iter; left time: 242.4017s\n",
      "\titers: 300, epoch: 13 | loss: 0.0469200\n",
      "\tspeed: 0.0344s/iter; left time: 239.2543s\n",
      "\titers: 400, epoch: 13 | loss: 0.0549754\n",
      "\tspeed: 0.0344s/iter; left time: 235.6954s\n",
      "\titers: 500, epoch: 13 | loss: 0.0429797\n",
      "\tspeed: 0.0344s/iter; left time: 232.2055s\n",
      "\titers: 600, epoch: 13 | loss: 0.0493610\n",
      "\tspeed: 0.0344s/iter; left time: 228.8044s\n",
      "\titers: 700, epoch: 13 | loss: 0.0470018\n",
      "\tspeed: 0.0344s/iter; left time: 225.2410s\n",
      "\titers: 800, epoch: 13 | loss: 0.0505446\n",
      "\tspeed: 0.0344s/iter; left time: 222.0993s\n",
      "\titers: 900, epoch: 13 | loss: 0.0527018\n",
      "\tspeed: 0.0344s/iter; left time: 218.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.48s\n",
      "Steps: 906 | Train Loss: 0.0474767 Vali Loss: 0.0565293 Test Loss: 0.0645984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0478024\n",
      "\tspeed: 0.0952s/iter; left time: 594.1187s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465574\n",
      "\tspeed: 0.0345s/iter; left time: 211.7217s\n",
      "\titers: 300, epoch: 14 | loss: 0.0409424\n",
      "\tspeed: 0.0344s/iter; left time: 208.0992s\n",
      "\titers: 400, epoch: 14 | loss: 0.0393596\n",
      "\tspeed: 0.0344s/iter; left time: 204.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0479720\n",
      "\tspeed: 0.0344s/iter; left time: 200.9919s\n",
      "\titers: 600, epoch: 14 | loss: 0.0455824\n",
      "\tspeed: 0.0344s/iter; left time: 197.4515s\n",
      "\titers: 700, epoch: 14 | loss: 0.0412655\n",
      "\tspeed: 0.0340s/iter; left time: 191.9091s\n",
      "\titers: 800, epoch: 14 | loss: 0.0518019\n",
      "\tspeed: 0.0339s/iter; left time: 187.7954s\n",
      "\titers: 900, epoch: 14 | loss: 0.0401611\n",
      "\tspeed: 0.0342s/iter; left time: 186.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.0464986 Vali Loss: 0.0564530 Test Loss: 0.0648331\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453141\n",
      "\tspeed: 0.0946s/iter; left time: 504.9078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0427157\n",
      "\tspeed: 0.0339s/iter; left time: 177.6196s\n",
      "\titers: 300, epoch: 15 | loss: 0.0424050\n",
      "\tspeed: 0.0339s/iter; left time: 174.0996s\n",
      "\titers: 400, epoch: 15 | loss: 0.0450250\n",
      "\tspeed: 0.0340s/iter; left time: 171.1165s\n",
      "\titers: 500, epoch: 15 | loss: 0.0498884\n",
      "\tspeed: 0.0339s/iter; left time: 167.4988s\n",
      "\titers: 600, epoch: 15 | loss: 0.0426898\n",
      "\tspeed: 0.0339s/iter; left time: 163.9400s\n",
      "\titers: 700, epoch: 15 | loss: 0.0478519\n",
      "\tspeed: 0.0339s/iter; left time: 160.6394s\n",
      "\titers: 800, epoch: 15 | loss: 0.0399454\n",
      "\tspeed: 0.0339s/iter; left time: 157.2868s\n",
      "\titers: 900, epoch: 15 | loss: 0.0482494\n",
      "\tspeed: 0.0339s/iter; left time: 153.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0455909 Vali Loss: 0.0574777 Test Loss: 0.0649152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0477243\n",
      "\tspeed: 0.0966s/iter; left time: 428.0084s\n",
      "\titers: 200, epoch: 16 | loss: 0.0499466\n",
      "\tspeed: 0.0344s/iter; left time: 149.0762s\n",
      "\titers: 300, epoch: 16 | loss: 0.0453695\n",
      "\tspeed: 0.0344s/iter; left time: 145.5417s\n",
      "\titers: 400, epoch: 16 | loss: 0.0438813\n",
      "\tspeed: 0.0344s/iter; left time: 142.2158s\n",
      "\titers: 500, epoch: 16 | loss: 0.0471978\n",
      "\tspeed: 0.0344s/iter; left time: 138.8512s\n",
      "\titers: 600, epoch: 16 | loss: 0.0432691\n",
      "\tspeed: 0.0344s/iter; left time: 135.0316s\n",
      "\titers: 700, epoch: 16 | loss: 0.0403846\n",
      "\tspeed: 0.0344s/iter; left time: 131.8651s\n",
      "\titers: 800, epoch: 16 | loss: 0.0475129\n",
      "\tspeed: 0.0344s/iter; left time: 128.3959s\n",
      "\titers: 900, epoch: 16 | loss: 0.0473321\n",
      "\tspeed: 0.0344s/iter; left time: 125.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0446047 Vali Loss: 0.0561414 Test Loss: 0.0642355\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387600\n",
      "\tspeed: 0.0965s/iter; left time: 340.1043s\n",
      "\titers: 200, epoch: 17 | loss: 0.0365247\n",
      "\tspeed: 0.0344s/iter; left time: 117.9369s\n",
      "\titers: 300, epoch: 17 | loss: 0.0416560\n",
      "\tspeed: 0.0344s/iter; left time: 114.4035s\n",
      "\titers: 400, epoch: 17 | loss: 0.0426961\n",
      "\tspeed: 0.0344s/iter; left time: 110.9422s\n",
      "\titers: 500, epoch: 17 | loss: 0.0431453\n",
      "\tspeed: 0.0344s/iter; left time: 107.5261s\n",
      "\titers: 600, epoch: 17 | loss: 0.0430919\n",
      "\tspeed: 0.0344s/iter; left time: 104.1321s\n",
      "\titers: 700, epoch: 17 | loss: 0.0497445\n",
      "\tspeed: 0.0344s/iter; left time: 100.7481s\n",
      "\titers: 800, epoch: 17 | loss: 0.0412744\n",
      "\tspeed: 0.0344s/iter; left time: 97.1845s\n",
      "\titers: 900, epoch: 17 | loss: 0.0451680\n",
      "\tspeed: 0.0344s/iter; left time: 93.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0439459 Vali Loss: 0.0560204 Test Loss: 0.0647921\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01203176286071539, rmse:0.1096893921494484, mae:0.06421584635972977, rse:0.4145238697528839\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2498116\n",
      "\tspeed: 0.0370s/iter; left time: 666.5389s\n",
      "\titers: 200, epoch: 1 | loss: 0.2011735\n",
      "\tspeed: 0.0340s/iter; left time: 608.7283s\n",
      "\titers: 300, epoch: 1 | loss: 0.2150934\n",
      "\tspeed: 0.0338s/iter; left time: 602.7235s\n",
      "\titers: 400, epoch: 1 | loss: 0.1960537\n",
      "\tspeed: 0.0339s/iter; left time: 600.7765s\n",
      "\titers: 500, epoch: 1 | loss: 0.1826794\n",
      "\tspeed: 0.0342s/iter; left time: 603.0035s\n",
      "\titers: 600, epoch: 1 | loss: 0.1927706\n",
      "\tspeed: 0.0340s/iter; left time: 595.9660s\n",
      "\titers: 700, epoch: 1 | loss: 0.1779167\n",
      "\tspeed: 0.0344s/iter; left time: 599.7866s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746279\n",
      "\tspeed: 0.0344s/iter; left time: 595.2989s\n",
      "\titers: 900, epoch: 1 | loss: 0.1654574\n",
      "\tspeed: 0.0341s/iter; left time: 587.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.1992125 Vali Loss: 0.1432941 Test Loss: 0.1544233\n",
      "Validation loss decreased (inf --> 0.143294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1207117\n",
      "\tspeed: 0.0978s/iter; left time: 1673.5689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950160\n",
      "\tspeed: 0.0344s/iter; left time: 585.2503s\n",
      "\titers: 300, epoch: 2 | loss: 0.1002817\n",
      "\tspeed: 0.0344s/iter; left time: 581.7880s\n",
      "\titers: 400, epoch: 2 | loss: 0.0960616\n",
      "\tspeed: 0.0344s/iter; left time: 578.6741s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890009\n",
      "\tspeed: 0.0344s/iter; left time: 575.1517s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752527\n",
      "\tspeed: 0.0344s/iter; left time: 571.0349s\n",
      "\titers: 700, epoch: 2 | loss: 0.0765394\n",
      "\tspeed: 0.0344s/iter; left time: 567.7912s\n",
      "\titers: 800, epoch: 2 | loss: 0.0737386\n",
      "\tspeed: 0.0345s/iter; left time: 565.7726s\n",
      "\titers: 900, epoch: 2 | loss: 0.0719303\n",
      "\tspeed: 0.0344s/iter; left time: 561.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0930362 Vali Loss: 0.0793414 Test Loss: 0.0821712\n",
      "Validation loss decreased (0.143294 --> 0.079341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749184\n",
      "\tspeed: 0.0985s/iter; left time: 1596.5709s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750817\n",
      "\tspeed: 0.0354s/iter; left time: 570.6225s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689839\n",
      "\tspeed: 0.0354s/iter; left time: 567.1619s\n",
      "\titers: 400, epoch: 3 | loss: 0.0704358\n",
      "\tspeed: 0.0353s/iter; left time: 562.2200s\n",
      "\titers: 500, epoch: 3 | loss: 0.0624443\n",
      "\tspeed: 0.0347s/iter; left time: 548.4937s\n",
      "\titers: 600, epoch: 3 | loss: 0.0694029\n",
      "\tspeed: 0.0347s/iter; left time: 544.7530s\n",
      "\titers: 700, epoch: 3 | loss: 0.0815309\n",
      "\tspeed: 0.0347s/iter; left time: 541.4119s\n",
      "\titers: 800, epoch: 3 | loss: 0.0664670\n",
      "\tspeed: 0.0347s/iter; left time: 537.6137s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646821\n",
      "\tspeed: 0.0347s/iter; left time: 534.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.02s\n",
      "Steps: 906 | Train Loss: 0.0724885 Vali Loss: 0.0685023 Test Loss: 0.0725131\n",
      "Validation loss decreased (0.079341 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744193\n",
      "\tspeed: 0.0981s/iter; left time: 1501.0904s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712759\n",
      "\tspeed: 0.0347s/iter; left time: 527.5156s\n",
      "\titers: 300, epoch: 4 | loss: 0.0668154\n",
      "\tspeed: 0.0346s/iter; left time: 523.0114s\n",
      "\titers: 400, epoch: 4 | loss: 0.0690735\n",
      "\tspeed: 0.0347s/iter; left time: 520.1602s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684960\n",
      "\tspeed: 0.0347s/iter; left time: 517.1179s\n",
      "\titers: 600, epoch: 4 | loss: 0.0681758\n",
      "\tspeed: 0.0347s/iter; left time: 513.0677s\n",
      "\titers: 700, epoch: 4 | loss: 0.0672854\n",
      "\tspeed: 0.0347s/iter; left time: 509.7975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0688433\n",
      "\tspeed: 0.0347s/iter; left time: 506.9368s\n",
      "\titers: 900, epoch: 4 | loss: 0.0717380\n",
      "\tspeed: 0.0347s/iter; left time: 503.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.71s\n",
      "Steps: 906 | Train Loss: 0.0678150 Vali Loss: 0.0665552 Test Loss: 0.0727431\n",
      "Validation loss decreased (0.068502 --> 0.066555).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659932\n",
      "\tspeed: 0.0981s/iter; left time: 1412.5186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691543\n",
      "\tspeed: 0.0349s/iter; left time: 498.3155s\n",
      "\titers: 300, epoch: 5 | loss: 0.0622396\n",
      "\tspeed: 0.0347s/iter; left time: 492.6222s\n",
      "\titers: 400, epoch: 5 | loss: 0.0609198\n",
      "\tspeed: 0.0347s/iter; left time: 488.8965s\n",
      "\titers: 500, epoch: 5 | loss: 0.0666150\n",
      "\tspeed: 0.0347s/iter; left time: 485.7598s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587350\n",
      "\tspeed: 0.0347s/iter; left time: 482.1804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0578601\n",
      "\tspeed: 0.0348s/iter; left time: 480.5091s\n",
      "\titers: 800, epoch: 5 | loss: 0.0598911\n",
      "\tspeed: 0.0347s/iter; left time: 475.9499s\n",
      "\titers: 900, epoch: 5 | loss: 0.0647039\n",
      "\tspeed: 0.0350s/iter; left time: 476.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0635315 Vali Loss: 0.0618177 Test Loss: 0.0684821\n",
      "Validation loss decreased (0.066555 --> 0.061818).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551207\n",
      "\tspeed: 0.0990s/iter; left time: 1335.9846s\n",
      "\titers: 200, epoch: 6 | loss: 0.0664826\n",
      "\tspeed: 0.0354s/iter; left time: 473.8274s\n",
      "\titers: 300, epoch: 6 | loss: 0.0643861\n",
      "\tspeed: 0.0349s/iter; left time: 464.2556s\n",
      "\titers: 400, epoch: 6 | loss: 0.0645496\n",
      "\tspeed: 0.0348s/iter; left time: 459.4172s\n",
      "\titers: 500, epoch: 6 | loss: 0.0522045\n",
      "\tspeed: 0.0348s/iter; left time: 456.0432s\n",
      "\titers: 600, epoch: 6 | loss: 0.0588533\n",
      "\tspeed: 0.0348s/iter; left time: 452.3222s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584210\n",
      "\tspeed: 0.0349s/iter; left time: 449.8974s\n",
      "\titers: 800, epoch: 6 | loss: 0.0518436\n",
      "\tspeed: 0.0348s/iter; left time: 445.5703s\n",
      "\titers: 900, epoch: 6 | loss: 0.0592274\n",
      "\tspeed: 0.0348s/iter; left time: 441.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.00s\n",
      "Steps: 906 | Train Loss: 0.0598389 Vali Loss: 0.0608522 Test Loss: 0.0686492\n",
      "Validation loss decreased (0.061818 --> 0.060852).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570249\n",
      "\tspeed: 0.1002s/iter; left time: 1261.3629s\n",
      "\titers: 200, epoch: 7 | loss: 0.0546420\n",
      "\tspeed: 0.0348s/iter; left time: 434.3797s\n",
      "\titers: 300, epoch: 7 | loss: 0.0586133\n",
      "\tspeed: 0.0348s/iter; left time: 431.3394s\n",
      "\titers: 400, epoch: 7 | loss: 0.0534843\n",
      "\tspeed: 0.0347s/iter; left time: 426.7654s\n",
      "\titers: 500, epoch: 7 | loss: 0.0500044\n",
      "\tspeed: 0.0347s/iter; left time: 422.9477s\n",
      "\titers: 600, epoch: 7 | loss: 0.0479839\n",
      "\tspeed: 0.0348s/iter; left time: 420.8973s\n",
      "\titers: 700, epoch: 7 | loss: 0.0544220\n",
      "\tspeed: 0.0348s/iter; left time: 417.2883s\n",
      "\titers: 800, epoch: 7 | loss: 0.0504415\n",
      "\tspeed: 0.0348s/iter; left time: 413.2339s\n",
      "\titers: 900, epoch: 7 | loss: 0.0664917\n",
      "\tspeed: 0.0347s/iter; left time: 409.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.82s\n",
      "Steps: 906 | Train Loss: 0.0572039 Vali Loss: 0.0600482 Test Loss: 0.0666491\n",
      "Validation loss decreased (0.060852 --> 0.060048).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569239\n",
      "\tspeed: 0.0975s/iter; left time: 1139.1124s\n",
      "\titers: 200, epoch: 8 | loss: 0.0524420\n",
      "\tspeed: 0.0347s/iter; left time: 402.1669s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549767\n",
      "\tspeed: 0.0347s/iter; left time: 398.7406s\n",
      "\titers: 400, epoch: 8 | loss: 0.0569074\n",
      "\tspeed: 0.0347s/iter; left time: 394.5755s\n",
      "\titers: 500, epoch: 8 | loss: 0.0560224\n",
      "\tspeed: 0.0347s/iter; left time: 391.2381s\n",
      "\titers: 600, epoch: 8 | loss: 0.0586272\n",
      "\tspeed: 0.0347s/iter; left time: 387.4443s\n",
      "\titers: 700, epoch: 8 | loss: 0.0534134\n",
      "\tspeed: 0.0347s/iter; left time: 384.2815s\n",
      "\titers: 800, epoch: 8 | loss: 0.0507184\n",
      "\tspeed: 0.0347s/iter; left time: 381.3517s\n",
      "\titers: 900, epoch: 8 | loss: 0.0588685\n",
      "\tspeed: 0.0347s/iter; left time: 377.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0554143 Vali Loss: 0.0588686 Test Loss: 0.0643074\n",
      "Validation loss decreased (0.060048 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554289\n",
      "\tspeed: 0.0976s/iter; left time: 1051.5838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0491354\n",
      "\tspeed: 0.0348s/iter; left time: 371.0447s\n",
      "\titers: 300, epoch: 9 | loss: 0.0533709\n",
      "\tspeed: 0.0346s/iter; left time: 366.2234s\n",
      "\titers: 400, epoch: 9 | loss: 0.0478047\n",
      "\tspeed: 0.0346s/iter; left time: 362.6454s\n",
      "\titers: 500, epoch: 9 | loss: 0.0562404\n",
      "\tspeed: 0.0347s/iter; left time: 359.5503s\n",
      "\titers: 600, epoch: 9 | loss: 0.0546994\n",
      "\tspeed: 0.0347s/iter; left time: 356.9094s\n",
      "\titers: 700, epoch: 9 | loss: 0.0573833\n",
      "\tspeed: 0.0347s/iter; left time: 352.8255s\n",
      "\titers: 800, epoch: 9 | loss: 0.0525519\n",
      "\tspeed: 0.0347s/iter; left time: 349.5498s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501279\n",
      "\tspeed: 0.0347s/iter; left time: 346.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.75s\n",
      "Steps: 906 | Train Loss: 0.0537802 Vali Loss: 0.0572465 Test Loss: 0.0636292\n",
      "Validation loss decreased (0.058869 --> 0.057246).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570313\n",
      "\tspeed: 0.0972s/iter; left time: 959.5169s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489191\n",
      "\tspeed: 0.0346s/iter; left time: 337.5840s\n",
      "\titers: 300, epoch: 10 | loss: 0.0466328\n",
      "\tspeed: 0.0347s/iter; left time: 335.0048s\n",
      "\titers: 400, epoch: 10 | loss: 0.0506991\n",
      "\tspeed: 0.0345s/iter; left time: 330.5165s\n",
      "\titers: 500, epoch: 10 | loss: 0.0551326\n",
      "\tspeed: 0.0346s/iter; left time: 327.4180s\n",
      "\titers: 600, epoch: 10 | loss: 0.0489854\n",
      "\tspeed: 0.0347s/iter; left time: 324.7745s\n",
      "\titers: 700, epoch: 10 | loss: 0.0582220\n",
      "\tspeed: 0.0346s/iter; left time: 320.6847s\n",
      "\titers: 800, epoch: 10 | loss: 0.0630818\n",
      "\tspeed: 0.0346s/iter; left time: 317.2015s\n",
      "\titers: 900, epoch: 10 | loss: 0.0590224\n",
      "\tspeed: 0.0347s/iter; left time: 314.2078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.64s\n",
      "Steps: 906 | Train Loss: 0.0524546 Vali Loss: 0.0584495 Test Loss: 0.0668093\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541355\n",
      "\tspeed: 0.0950s/iter; left time: 850.9173s\n",
      "\titers: 200, epoch: 11 | loss: 0.0514751\n",
      "\tspeed: 0.0347s/iter; left time: 307.1480s\n",
      "\titers: 300, epoch: 11 | loss: 0.0508684\n",
      "\tspeed: 0.0347s/iter; left time: 304.1859s\n",
      "\titers: 400, epoch: 11 | loss: 0.0488365\n",
      "\tspeed: 0.0347s/iter; left time: 300.4539s\n",
      "\titers: 500, epoch: 11 | loss: 0.0411242\n",
      "\tspeed: 0.0347s/iter; left time: 297.1902s\n",
      "\titers: 600, epoch: 11 | loss: 0.0533406\n",
      "\tspeed: 0.0347s/iter; left time: 293.6787s\n",
      "\titers: 700, epoch: 11 | loss: 0.0518379\n",
      "\tspeed: 0.0346s/iter; left time: 288.9753s\n",
      "\titers: 800, epoch: 11 | loss: 0.0526628\n",
      "\tspeed: 0.0346s/iter; left time: 285.9920s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498659\n",
      "\tspeed: 0.0346s/iter; left time: 282.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0511982 Vali Loss: 0.0571466 Test Loss: 0.0659549\n",
      "Validation loss decreased (0.057246 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0479833\n",
      "\tspeed: 0.0978s/iter; left time: 787.9345s\n",
      "\titers: 200, epoch: 12 | loss: 0.0515542\n",
      "\tspeed: 0.0347s/iter; left time: 276.0988s\n",
      "\titers: 300, epoch: 12 | loss: 0.0507848\n",
      "\tspeed: 0.0347s/iter; left time: 272.2591s\n",
      "\titers: 400, epoch: 12 | loss: 0.0510435\n",
      "\tspeed: 0.0347s/iter; left time: 268.7503s\n",
      "\titers: 500, epoch: 12 | loss: 0.0462130\n",
      "\tspeed: 0.0347s/iter; left time: 265.9512s\n",
      "\titers: 600, epoch: 12 | loss: 0.0533448\n",
      "\tspeed: 0.0347s/iter; left time: 262.1570s\n",
      "\titers: 700, epoch: 12 | loss: 0.0432821\n",
      "\tspeed: 0.0346s/iter; left time: 258.2145s\n",
      "\titers: 800, epoch: 12 | loss: 0.0530810\n",
      "\tspeed: 0.0347s/iter; left time: 255.3143s\n",
      "\titers: 900, epoch: 12 | loss: 0.0456739\n",
      "\tspeed: 0.0347s/iter; left time: 251.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.72s\n",
      "Steps: 906 | Train Loss: 0.0497971 Vali Loss: 0.0571572 Test Loss: 0.0657481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0520588\n",
      "\tspeed: 0.0957s/iter; left time: 683.8958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0471978\n",
      "\tspeed: 0.0353s/iter; left time: 248.8270s\n",
      "\titers: 300, epoch: 13 | loss: 0.0492734\n",
      "\tspeed: 0.0347s/iter; left time: 240.9171s\n",
      "\titers: 400, epoch: 13 | loss: 0.0487693\n",
      "\tspeed: 0.0347s/iter; left time: 237.8179s\n",
      "\titers: 500, epoch: 13 | loss: 0.0490274\n",
      "\tspeed: 0.0350s/iter; left time: 235.9805s\n",
      "\titers: 600, epoch: 13 | loss: 0.0444182\n",
      "\tspeed: 0.0345s/iter; left time: 229.6636s\n",
      "\titers: 700, epoch: 13 | loss: 0.0454526\n",
      "\tspeed: 0.0347s/iter; left time: 227.3076s\n",
      "\titers: 800, epoch: 13 | loss: 0.0502009\n",
      "\tspeed: 0.0347s/iter; left time: 224.0524s\n",
      "\titers: 900, epoch: 13 | loss: 0.0519659\n",
      "\tspeed: 0.0347s/iter; left time: 220.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0487688 Vali Loss: 0.0568870 Test Loss: 0.0654286\n",
      "Validation loss decreased (0.057147 --> 0.056887).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0472592\n",
      "\tspeed: 0.0989s/iter; left time: 617.6909s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461481\n",
      "\tspeed: 0.0346s/iter; left time: 212.8299s\n",
      "\titers: 300, epoch: 14 | loss: 0.0439564\n",
      "\tspeed: 0.0347s/iter; left time: 209.6598s\n",
      "\titers: 400, epoch: 14 | loss: 0.0481552\n",
      "\tspeed: 0.0346s/iter; left time: 205.6444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0552839\n",
      "\tspeed: 0.0346s/iter; left time: 202.3369s\n",
      "\titers: 600, epoch: 14 | loss: 0.0544599\n",
      "\tspeed: 0.0346s/iter; left time: 198.9589s\n",
      "\titers: 700, epoch: 14 | loss: 0.0492873\n",
      "\tspeed: 0.0346s/iter; left time: 195.4065s\n",
      "\titers: 800, epoch: 14 | loss: 0.0519501\n",
      "\tspeed: 0.0347s/iter; left time: 192.1339s\n",
      "\titers: 900, epoch: 14 | loss: 0.0444011\n",
      "\tspeed: 0.0347s/iter; left time: 188.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.0478288 Vali Loss: 0.0574118 Test Loss: 0.0649276\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518620\n",
      "\tspeed: 0.0950s/iter; left time: 506.9968s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447321\n",
      "\tspeed: 0.0346s/iter; left time: 181.3134s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470643\n",
      "\tspeed: 0.0346s/iter; left time: 177.8876s\n",
      "\titers: 400, epoch: 15 | loss: 0.0505560\n",
      "\tspeed: 0.0348s/iter; left time: 175.1414s\n",
      "\titers: 500, epoch: 15 | loss: 0.0455437\n",
      "\tspeed: 0.0347s/iter; left time: 171.4088s\n",
      "\titers: 600, epoch: 15 | loss: 0.0463022\n",
      "\tspeed: 0.0346s/iter; left time: 167.5804s\n",
      "\titers: 700, epoch: 15 | loss: 0.0565158\n",
      "\tspeed: 0.0347s/iter; left time: 164.3168s\n",
      "\titers: 800, epoch: 15 | loss: 0.0485040\n",
      "\tspeed: 0.0346s/iter; left time: 160.5875s\n",
      "\titers: 900, epoch: 15 | loss: 0.0463231\n",
      "\tspeed: 0.0346s/iter; left time: 157.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0470613 Vali Loss: 0.0568892 Test Loss: 0.0665978\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476478\n",
      "\tspeed: 0.0958s/iter; left time: 424.5514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0442408\n",
      "\tspeed: 0.0347s/iter; left time: 150.2413s\n",
      "\titers: 300, epoch: 16 | loss: 0.0460189\n",
      "\tspeed: 0.0347s/iter; left time: 146.8148s\n",
      "\titers: 400, epoch: 16 | loss: 0.0477852\n",
      "\tspeed: 0.0347s/iter; left time: 143.2491s\n",
      "\titers: 500, epoch: 16 | loss: 0.0508246\n",
      "\tspeed: 0.0347s/iter; left time: 139.7995s\n",
      "\titers: 600, epoch: 16 | loss: 0.0476234\n",
      "\tspeed: 0.0347s/iter; left time: 136.2444s\n",
      "\titers: 700, epoch: 16 | loss: 0.0496349\n",
      "\tspeed: 0.0347s/iter; left time: 132.8671s\n",
      "\titers: 800, epoch: 16 | loss: 0.0451010\n",
      "\tspeed: 0.0347s/iter; left time: 129.3319s\n",
      "\titers: 900, epoch: 16 | loss: 0.0472244\n",
      "\tspeed: 0.0347s/iter; left time: 125.8357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.73s\n",
      "Steps: 906 | Train Loss: 0.0462200 Vali Loss: 0.0565890 Test Loss: 0.0651991\n",
      "Validation loss decreased (0.056887 --> 0.056589).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0511533\n",
      "\tspeed: 0.0990s/iter; left time: 348.8845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410157\n",
      "\tspeed: 0.0347s/iter; left time: 118.8367s\n",
      "\titers: 300, epoch: 17 | loss: 0.0532006\n",
      "\tspeed: 0.0346s/iter; left time: 115.1362s\n",
      "\titers: 400, epoch: 17 | loss: 0.0506476\n",
      "\tspeed: 0.0347s/iter; left time: 111.8803s\n",
      "\titers: 500, epoch: 17 | loss: 0.0444746\n",
      "\tspeed: 0.0347s/iter; left time: 108.5460s\n",
      "\titers: 600, epoch: 17 | loss: 0.0454823\n",
      "\tspeed: 0.0347s/iter; left time: 104.8775s\n",
      "\titers: 700, epoch: 17 | loss: 0.0417460\n",
      "\tspeed: 0.0348s/iter; left time: 101.7171s\n",
      "\titers: 800, epoch: 17 | loss: 0.0485935\n",
      "\tspeed: 0.0347s/iter; left time: 98.1239s\n",
      "\titers: 900, epoch: 17 | loss: 0.0427209\n",
      "\tspeed: 0.0347s/iter; left time: 94.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.77s\n",
      "Steps: 906 | Train Loss: 0.0454245 Vali Loss: 0.0563723 Test Loss: 0.0671997\n",
      "Validation loss decreased (0.056589 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0397315\n",
      "\tspeed: 0.0992s/iter; left time: 259.7061s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411270\n",
      "\tspeed: 0.0354s/iter; left time: 89.2592s\n",
      "\titers: 300, epoch: 18 | loss: 0.0484297\n",
      "\tspeed: 0.0353s/iter; left time: 85.4810s\n",
      "\titers: 400, epoch: 18 | loss: 0.0467603\n",
      "\tspeed: 0.0347s/iter; left time: 80.3745s\n",
      "\titers: 500, epoch: 18 | loss: 0.0422288\n",
      "\tspeed: 0.0347s/iter; left time: 77.1078s\n",
      "\titers: 600, epoch: 18 | loss: 0.0504954\n",
      "\tspeed: 0.0347s/iter; left time: 73.4995s\n",
      "\titers: 700, epoch: 18 | loss: 0.0396327\n",
      "\tspeed: 0.0347s/iter; left time: 70.1133s\n",
      "\titers: 800, epoch: 18 | loss: 0.0461913\n",
      "\tspeed: 0.0348s/iter; left time: 66.7656s\n",
      "\titers: 900, epoch: 18 | loss: 0.0522097\n",
      "\tspeed: 0.0353s/iter; left time: 64.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.05s\n",
      "Steps: 906 | Train Loss: 0.0448353 Vali Loss: 0.0574077 Test Loss: 0.0666983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0404343\n",
      "\tspeed: 0.0962s/iter; left time: 164.8634s\n",
      "\titers: 200, epoch: 19 | loss: 0.0435289\n",
      "\tspeed: 0.0354s/iter; left time: 57.0615s\n",
      "\titers: 300, epoch: 19 | loss: 0.0437113\n",
      "\tspeed: 0.0354s/iter; left time: 53.5034s\n",
      "\titers: 400, epoch: 19 | loss: 0.0464690\n",
      "\tspeed: 0.0347s/iter; left time: 49.0817s\n",
      "\titers: 500, epoch: 19 | loss: 0.0434488\n",
      "\tspeed: 0.0345s/iter; left time: 45.3597s\n",
      "\titers: 600, epoch: 19 | loss: 0.0420474\n",
      "\tspeed: 0.0346s/iter; left time: 41.9174s\n",
      "\titers: 700, epoch: 19 | loss: 0.0488688\n",
      "\tspeed: 0.0346s/iter; left time: 38.4872s\n",
      "\titers: 800, epoch: 19 | loss: 0.0425040\n",
      "\tspeed: 0.0347s/iter; left time: 35.1069s\n",
      "\titers: 900, epoch: 19 | loss: 0.0387297\n",
      "\tspeed: 0.0346s/iter; left time: 31.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.91s\n",
      "Steps: 906 | Train Loss: 0.0441012 Vali Loss: 0.0579686 Test Loss: 0.0662565\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443658\n",
      "\tspeed: 0.0947s/iter; left time: 76.3905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0434084\n",
      "\tspeed: 0.0346s/iter; left time: 24.4717s\n",
      "\titers: 300, epoch: 20 | loss: 0.0444593\n",
      "\tspeed: 0.0347s/iter; left time: 21.0411s\n",
      "\titers: 400, epoch: 20 | loss: 0.0421418\n",
      "\tspeed: 0.0346s/iter; left time: 17.5626s\n",
      "\titers: 500, epoch: 20 | loss: 0.0421504\n",
      "\tspeed: 0.0346s/iter; left time: 14.0774s\n",
      "\titers: 600, epoch: 20 | loss: 0.0476669\n",
      "\tspeed: 0.0347s/iter; left time: 10.6547s\n",
      "\titers: 700, epoch: 20 | loss: 0.0507700\n",
      "\tspeed: 0.0346s/iter; left time: 7.1550s\n",
      "\titers: 800, epoch: 20 | loss: 0.0446998\n",
      "\tspeed: 0.0346s/iter; left time: 3.7025s\n",
      "\titers: 900, epoch: 20 | loss: 0.0413743\n",
      "\tspeed: 0.0346s/iter; left time: 0.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.65s\n",
      "Steps: 906 | Train Loss: 0.0435656 Vali Loss: 0.0569343 Test Loss: 0.0663891\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013082382269203663, rmse:0.11437824368476868, mae:0.06724400073289871, rse:0.43224334716796875\n",
      "Intermediate time for IT and pred_len 24: 00h:23m:18.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2329149\n",
      "\tspeed: 0.0654s/iter; left time: 1176.2400s\n",
      "\titers: 200, epoch: 1 | loss: 0.2132984\n",
      "\tspeed: 0.0419s/iter; left time: 749.7176s\n",
      "\titers: 300, epoch: 1 | loss: 0.2021164\n",
      "\tspeed: 0.0419s/iter; left time: 745.8109s\n",
      "\titers: 400, epoch: 1 | loss: 0.1994694\n",
      "\tspeed: 0.0419s/iter; left time: 741.5871s\n",
      "\titers: 500, epoch: 1 | loss: 0.1993076\n",
      "\tspeed: 0.0419s/iter; left time: 737.5135s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911502\n",
      "\tspeed: 0.0420s/iter; left time: 733.4970s\n",
      "\titers: 700, epoch: 1 | loss: 0.1889577\n",
      "\tspeed: 0.0419s/iter; left time: 728.8116s\n",
      "\titers: 800, epoch: 1 | loss: 0.1783947\n",
      "\tspeed: 0.0415s/iter; left time: 717.1408s\n",
      "\titers: 900, epoch: 1 | loss: 0.1868250\n",
      "\tspeed: 0.0420s/iter; left time: 720.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 904 | Train Loss: 0.2045878 Vali Loss: 0.1702724 Test Loss: 0.1878111\n",
      "Validation loss decreased (inf --> 0.170272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1723534\n",
      "\tspeed: 0.1170s/iter; left time: 1998.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.1603348\n",
      "\tspeed: 0.0415s/iter; left time: 704.5081s\n",
      "\titers: 300, epoch: 2 | loss: 0.1485798\n",
      "\tspeed: 0.0415s/iter; left time: 700.8199s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373307\n",
      "\tspeed: 0.0415s/iter; left time: 696.6399s\n",
      "\titers: 500, epoch: 2 | loss: 0.1285997\n",
      "\tspeed: 0.0415s/iter; left time: 692.2526s\n",
      "\titers: 600, epoch: 2 | loss: 0.1198477\n",
      "\tspeed: 0.0415s/iter; left time: 688.1834s\n",
      "\titers: 700, epoch: 2 | loss: 0.1147303\n",
      "\tspeed: 0.0415s/iter; left time: 683.9993s\n",
      "\titers: 800, epoch: 2 | loss: 0.1007503\n",
      "\tspeed: 0.0415s/iter; left time: 679.8908s\n",
      "\titers: 900, epoch: 2 | loss: 0.0971180\n",
      "\tspeed: 0.0415s/iter; left time: 676.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1339202 Vali Loss: 0.0941798 Test Loss: 0.1007875\n",
      "Validation loss decreased (0.170272 --> 0.094180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933497\n",
      "\tspeed: 0.1176s/iter; left time: 1901.4621s\n",
      "\titers: 200, epoch: 3 | loss: 0.0936517\n",
      "\tspeed: 0.0420s/iter; left time: 675.2535s\n",
      "\titers: 300, epoch: 3 | loss: 0.0927260\n",
      "\tspeed: 0.0420s/iter; left time: 670.9438s\n",
      "\titers: 400, epoch: 3 | loss: 0.0904723\n",
      "\tspeed: 0.0420s/iter; left time: 666.9150s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878174\n",
      "\tspeed: 0.0419s/iter; left time: 661.3822s\n",
      "\titers: 600, epoch: 3 | loss: 0.0923175\n",
      "\tspeed: 0.0415s/iter; left time: 650.1710s\n",
      "\titers: 700, epoch: 3 | loss: 0.0842094\n",
      "\tspeed: 0.0415s/iter; left time: 645.7592s\n",
      "\titers: 800, epoch: 3 | loss: 0.0947829\n",
      "\tspeed: 0.0416s/iter; left time: 643.4295s\n",
      "\titers: 900, epoch: 3 | loss: 0.0795053\n",
      "\tspeed: 0.0420s/iter; left time: 645.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 904 | Train Loss: 0.0910683 Vali Loss: 0.0842124 Test Loss: 0.0916354\n",
      "Validation loss decreased (0.094180 --> 0.084212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810681\n",
      "\tspeed: 0.1176s/iter; left time: 1795.0221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898334\n",
      "\tspeed: 0.0415s/iter; left time: 629.5262s\n",
      "\titers: 300, epoch: 4 | loss: 0.0877813\n",
      "\tspeed: 0.0415s/iter; left time: 625.5383s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827008\n",
      "\tspeed: 0.0415s/iter; left time: 620.9080s\n",
      "\titers: 500, epoch: 4 | loss: 0.0800275\n",
      "\tspeed: 0.0415s/iter; left time: 617.5306s\n",
      "\titers: 600, epoch: 4 | loss: 0.0795660\n",
      "\tspeed: 0.0415s/iter; left time: 613.3683s\n",
      "\titers: 700, epoch: 4 | loss: 0.0887710\n",
      "\tspeed: 0.0415s/iter; left time: 609.4629s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751216\n",
      "\tspeed: 0.0415s/iter; left time: 605.2594s\n",
      "\titers: 900, epoch: 4 | loss: 0.0814652\n",
      "\tspeed: 0.0415s/iter; left time: 600.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0842684 Vali Loss: 0.0824417 Test Loss: 0.0909199\n",
      "Validation loss decreased (0.084212 --> 0.082442).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819404\n",
      "\tspeed: 0.1164s/iter; left time: 1672.1114s\n",
      "\titers: 200, epoch: 5 | loss: 0.0734804\n",
      "\tspeed: 0.0415s/iter; left time: 591.8577s\n",
      "\titers: 300, epoch: 5 | loss: 0.0850687\n",
      "\tspeed: 0.0415s/iter; left time: 587.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.0805629\n",
      "\tspeed: 0.0415s/iter; left time: 583.3193s\n",
      "\titers: 500, epoch: 5 | loss: 0.0772669\n",
      "\tspeed: 0.0415s/iter; left time: 579.6728s\n",
      "\titers: 600, epoch: 5 | loss: 0.0835028\n",
      "\tspeed: 0.0415s/iter; left time: 575.0510s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755597\n",
      "\tspeed: 0.0415s/iter; left time: 571.0340s\n",
      "\titers: 800, epoch: 5 | loss: 0.0821126\n",
      "\tspeed: 0.0415s/iter; left time: 566.8882s\n",
      "\titers: 900, epoch: 5 | loss: 0.0793681\n",
      "\tspeed: 0.0415s/iter; left time: 563.0824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0794752 Vali Loss: 0.0815711 Test Loss: 0.0942506\n",
      "Validation loss decreased (0.082442 --> 0.081571).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839607\n",
      "\tspeed: 0.1197s/iter; left time: 1610.7661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795517\n",
      "\tspeed: 0.0415s/iter; left time: 555.1379s\n",
      "\titers: 300, epoch: 6 | loss: 0.0796291\n",
      "\tspeed: 0.0415s/iter; left time: 550.8724s\n",
      "\titers: 400, epoch: 6 | loss: 0.0740407\n",
      "\tspeed: 0.0415s/iter; left time: 546.6841s\n",
      "\titers: 500, epoch: 6 | loss: 0.0732674\n",
      "\tspeed: 0.0415s/iter; left time: 542.1567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0717258\n",
      "\tspeed: 0.0415s/iter; left time: 538.1807s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781353\n",
      "\tspeed: 0.0415s/iter; left time: 533.8559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0775410\n",
      "\tspeed: 0.0415s/iter; left time: 529.6971s\n",
      "\titers: 900, epoch: 6 | loss: 0.0719830\n",
      "\tspeed: 0.0415s/iter; left time: 526.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0759981 Vali Loss: 0.0810199 Test Loss: 0.0920831\n",
      "Validation loss decreased (0.081571 --> 0.081020).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723580\n",
      "\tspeed: 0.1173s/iter; left time: 1472.4495s\n",
      "\titers: 200, epoch: 7 | loss: 0.0775005\n",
      "\tspeed: 0.0415s/iter; left time: 516.4661s\n",
      "\titers: 300, epoch: 7 | loss: 0.0755266\n",
      "\tspeed: 0.0415s/iter; left time: 512.4093s\n",
      "\titers: 400, epoch: 7 | loss: 0.0716491\n",
      "\tspeed: 0.0415s/iter; left time: 508.4572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726988\n",
      "\tspeed: 0.0415s/iter; left time: 504.2027s\n",
      "\titers: 600, epoch: 7 | loss: 0.0645041\n",
      "\tspeed: 0.0415s/iter; left time: 500.0718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0743607\n",
      "\tspeed: 0.0415s/iter; left time: 496.0049s\n",
      "\titers: 800, epoch: 7 | loss: 0.0622560\n",
      "\tspeed: 0.0415s/iter; left time: 491.8869s\n",
      "\titers: 900, epoch: 7 | loss: 0.0748020\n",
      "\tspeed: 0.0415s/iter; left time: 487.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0728088 Vali Loss: 0.0797380 Test Loss: 0.0911746\n",
      "Validation loss decreased (0.081020 --> 0.079738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803198\n",
      "\tspeed: 0.1181s/iter; left time: 1376.5631s\n",
      "\titers: 200, epoch: 8 | loss: 0.0780065\n",
      "\tspeed: 0.0415s/iter; left time: 479.7795s\n",
      "\titers: 300, epoch: 8 | loss: 0.0705057\n",
      "\tspeed: 0.0415s/iter; left time: 475.6276s\n",
      "\titers: 400, epoch: 8 | loss: 0.0695511\n",
      "\tspeed: 0.0416s/iter; left time: 471.7291s\n",
      "\titers: 500, epoch: 8 | loss: 0.0667554\n",
      "\tspeed: 0.0415s/iter; left time: 467.1372s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727597\n",
      "\tspeed: 0.0415s/iter; left time: 463.1018s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681027\n",
      "\tspeed: 0.0415s/iter; left time: 459.0644s\n",
      "\titers: 800, epoch: 8 | loss: 0.0727258\n",
      "\tspeed: 0.0415s/iter; left time: 454.9328s\n",
      "\titers: 900, epoch: 8 | loss: 0.0665395\n",
      "\tspeed: 0.0415s/iter; left time: 450.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0701697 Vali Loss: 0.0797013 Test Loss: 0.0913741\n",
      "Validation loss decreased (0.079738 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698563\n",
      "\tspeed: 0.1180s/iter; left time: 1268.2817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0712313\n",
      "\tspeed: 0.0415s/iter; left time: 441.8347s\n",
      "\titers: 300, epoch: 9 | loss: 0.0642897\n",
      "\tspeed: 0.0415s/iter; left time: 437.9253s\n",
      "\titers: 400, epoch: 9 | loss: 0.0650743\n",
      "\tspeed: 0.0415s/iter; left time: 433.4531s\n",
      "\titers: 500, epoch: 9 | loss: 0.0677874\n",
      "\tspeed: 0.0416s/iter; left time: 430.0321s\n",
      "\titers: 600, epoch: 9 | loss: 0.0642288\n",
      "\tspeed: 0.0416s/iter; left time: 426.0446s\n",
      "\titers: 700, epoch: 9 | loss: 0.0613472\n",
      "\tspeed: 0.0415s/iter; left time: 421.6572s\n",
      "\titers: 800, epoch: 9 | loss: 0.0655759\n",
      "\tspeed: 0.0416s/iter; left time: 417.8767s\n",
      "\titers: 900, epoch: 9 | loss: 0.0630118\n",
      "\tspeed: 0.0415s/iter; left time: 413.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0675159 Vali Loss: 0.0817569 Test Loss: 0.0939381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0707889\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9164s\n",
      "\titers: 200, epoch: 10 | loss: 0.0646257\n",
      "\tspeed: 0.0415s/iter; left time: 404.3090s\n",
      "\titers: 300, epoch: 10 | loss: 0.0597870\n",
      "\tspeed: 0.0415s/iter; left time: 400.0274s\n",
      "\titers: 400, epoch: 10 | loss: 0.0606851\n",
      "\tspeed: 0.0415s/iter; left time: 396.0367s\n",
      "\titers: 500, epoch: 10 | loss: 0.0722949\n",
      "\tspeed: 0.0415s/iter; left time: 391.8655s\n",
      "\titers: 600, epoch: 10 | loss: 0.0613441\n",
      "\tspeed: 0.0415s/iter; left time: 387.7212s\n",
      "\titers: 700, epoch: 10 | loss: 0.0637856\n",
      "\tspeed: 0.0415s/iter; left time: 383.5531s\n",
      "\titers: 800, epoch: 10 | loss: 0.0674466\n",
      "\tspeed: 0.0415s/iter; left time: 379.4913s\n",
      "\titers: 900, epoch: 10 | loss: 0.0660359\n",
      "\tspeed: 0.0415s/iter; left time: 375.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0650114 Vali Loss: 0.0814649 Test Loss: 0.0932802\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628955\n",
      "\tspeed: 0.1142s/iter; left time: 1021.1997s\n",
      "\titers: 200, epoch: 11 | loss: 0.0667712\n",
      "\tspeed: 0.0415s/iter; left time: 367.1091s\n",
      "\titers: 300, epoch: 11 | loss: 0.0622564\n",
      "\tspeed: 0.0415s/iter; left time: 362.8662s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667247\n",
      "\tspeed: 0.0415s/iter; left time: 358.5564s\n",
      "\titers: 500, epoch: 11 | loss: 0.0588989\n",
      "\tspeed: 0.0415s/iter; left time: 354.8069s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601503\n",
      "\tspeed: 0.0415s/iter; left time: 350.5460s\n",
      "\titers: 700, epoch: 11 | loss: 0.0651884\n",
      "\tspeed: 0.0415s/iter; left time: 346.4933s\n",
      "\titers: 800, epoch: 11 | loss: 0.0648965\n",
      "\tspeed: 0.0415s/iter; left time: 342.2225s\n",
      "\titers: 900, epoch: 11 | loss: 0.0662556\n",
      "\tspeed: 0.0415s/iter; left time: 338.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.76s\n",
      "Steps: 904 | Train Loss: 0.0628507 Vali Loss: 0.0824759 Test Loss: 0.0953183\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586193\n",
      "\tspeed: 0.1132s/iter; left time: 910.0730s\n",
      "\titers: 200, epoch: 12 | loss: 0.0632593\n",
      "\tspeed: 0.0414s/iter; left time: 328.9784s\n",
      "\titers: 300, epoch: 12 | loss: 0.0581805\n",
      "\tspeed: 0.0414s/iter; left time: 324.8005s\n",
      "\titers: 400, epoch: 12 | loss: 0.0527286\n",
      "\tspeed: 0.0415s/iter; left time: 320.8751s\n",
      "\titers: 500, epoch: 12 | loss: 0.0617137\n",
      "\tspeed: 0.0415s/iter; left time: 316.7904s\n",
      "\titers: 600, epoch: 12 | loss: 0.0588900\n",
      "\tspeed: 0.0414s/iter; left time: 312.4074s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644570\n",
      "\tspeed: 0.0415s/iter; left time: 308.3568s\n",
      "\titers: 800, epoch: 12 | loss: 0.0602104\n",
      "\tspeed: 0.0415s/iter; left time: 304.2294s\n",
      "\titers: 900, epoch: 12 | loss: 0.0594495\n",
      "\tspeed: 0.0415s/iter; left time: 300.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 904 | Train Loss: 0.0606359 Vali Loss: 0.0830488 Test Loss: 0.0953343\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596162\n",
      "\tspeed: 0.1131s/iter; left time: 807.0245s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571232\n",
      "\tspeed: 0.0415s/iter; left time: 291.9264s\n",
      "\titers: 300, epoch: 13 | loss: 0.0555218\n",
      "\tspeed: 0.0415s/iter; left time: 287.6298s\n",
      "\titers: 400, epoch: 13 | loss: 0.0576127\n",
      "\tspeed: 0.0415s/iter; left time: 283.7168s\n",
      "\titers: 500, epoch: 13 | loss: 0.0613527\n",
      "\tspeed: 0.0415s/iter; left time: 279.3836s\n",
      "\titers: 600, epoch: 13 | loss: 0.0561092\n",
      "\tspeed: 0.0415s/iter; left time: 275.2104s\n",
      "\titers: 700, epoch: 13 | loss: 0.0549113\n",
      "\tspeed: 0.0415s/iter; left time: 271.0120s\n",
      "\titers: 800, epoch: 13 | loss: 0.0601151\n",
      "\tspeed: 0.0415s/iter; left time: 266.8849s\n",
      "\titers: 900, epoch: 13 | loss: 0.0564174\n",
      "\tspeed: 0.0415s/iter; left time: 262.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0588037 Vali Loss: 0.0848033 Test Loss: 0.0960292\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022316191345453262, rmse:0.14938604831695557, mae:0.09133996814489365, rse:0.5648447275161743\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2292959\n",
      "\tspeed: 0.0439s/iter; left time: 790.0637s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081810\n",
      "\tspeed: 0.0416s/iter; left time: 743.1444s\n",
      "\titers: 300, epoch: 1 | loss: 0.2096158\n",
      "\tspeed: 0.0416s/iter; left time: 738.9012s\n",
      "\titers: 400, epoch: 1 | loss: 0.2077726\n",
      "\tspeed: 0.0416s/iter; left time: 734.8712s\n",
      "\titers: 500, epoch: 1 | loss: 0.1998558\n",
      "\tspeed: 0.0416s/iter; left time: 730.8517s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957197\n",
      "\tspeed: 0.0416s/iter; left time: 726.7343s\n",
      "\titers: 700, epoch: 1 | loss: 0.1891191\n",
      "\tspeed: 0.0416s/iter; left time: 722.6622s\n",
      "\titers: 800, epoch: 1 | loss: 0.1786730\n",
      "\tspeed: 0.0416s/iter; left time: 718.8404s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799013\n",
      "\tspeed: 0.0416s/iter; left time: 714.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.2049319 Vali Loss: 0.1680077 Test Loss: 0.1860517\n",
      "Validation loss decreased (inf --> 0.168008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652640\n",
      "\tspeed: 0.1168s/iter; left time: 1995.2893s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542776\n",
      "\tspeed: 0.0416s/iter; left time: 705.8684s\n",
      "\titers: 300, epoch: 2 | loss: 0.1318608\n",
      "\tspeed: 0.0416s/iter; left time: 701.9676s\n",
      "\titers: 400, epoch: 2 | loss: 0.1279899\n",
      "\tspeed: 0.0416s/iter; left time: 697.8615s\n",
      "\titers: 500, epoch: 2 | loss: 0.1211760\n",
      "\tspeed: 0.0416s/iter; left time: 693.6336s\n",
      "\titers: 600, epoch: 2 | loss: 0.1045376\n",
      "\tspeed: 0.0416s/iter; left time: 689.3137s\n",
      "\titers: 700, epoch: 2 | loss: 0.1058448\n",
      "\tspeed: 0.0416s/iter; left time: 685.0528s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937553\n",
      "\tspeed: 0.0416s/iter; left time: 681.1193s\n",
      "\titers: 900, epoch: 2 | loss: 0.0992664\n",
      "\tspeed: 0.0416s/iter; left time: 676.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1267896 Vali Loss: 0.0913177 Test Loss: 0.0968462\n",
      "Validation loss decreased (0.168008 --> 0.091318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0841759\n",
      "\tspeed: 0.1182s/iter; left time: 1911.4221s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893953\n",
      "\tspeed: 0.0422s/iter; left time: 678.8770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0954204\n",
      "\tspeed: 0.0421s/iter; left time: 673.1054s\n",
      "\titers: 400, epoch: 3 | loss: 0.1050853\n",
      "\tspeed: 0.0421s/iter; left time: 668.4050s\n",
      "\titers: 500, epoch: 3 | loss: 0.0887890\n",
      "\tspeed: 0.0421s/iter; left time: 664.0398s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911384\n",
      "\tspeed: 0.0421s/iter; left time: 660.1369s\n",
      "\titers: 700, epoch: 3 | loss: 0.0956997\n",
      "\tspeed: 0.0421s/iter; left time: 655.4478s\n",
      "\titers: 800, epoch: 3 | loss: 0.0855911\n",
      "\tspeed: 0.0421s/iter; left time: 651.3994s\n",
      "\titers: 900, epoch: 3 | loss: 0.0926109\n",
      "\tspeed: 0.0421s/iter; left time: 647.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 904 | Train Loss: 0.0894015 Vali Loss: 0.0832333 Test Loss: 0.0903517\n",
      "Validation loss decreased (0.091318 --> 0.083233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.1173s/iter; left time: 1791.4033s\n",
      "\titers: 200, epoch: 4 | loss: 0.0908587\n",
      "\tspeed: 0.0416s/iter; left time: 630.3665s\n",
      "\titers: 300, epoch: 4 | loss: 0.0815956\n",
      "\tspeed: 0.0416s/iter; left time: 626.1857s\n",
      "\titers: 400, epoch: 4 | loss: 0.0794364\n",
      "\tspeed: 0.0415s/iter; left time: 621.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.0824227\n",
      "\tspeed: 0.0416s/iter; left time: 618.1104s\n",
      "\titers: 600, epoch: 4 | loss: 0.0863480\n",
      "\tspeed: 0.0416s/iter; left time: 613.9127s\n",
      "\titers: 700, epoch: 4 | loss: 0.0751134\n",
      "\tspeed: 0.0416s/iter; left time: 609.5003s\n",
      "\titers: 800, epoch: 4 | loss: 0.0925940\n",
      "\tspeed: 0.0416s/iter; left time: 605.9970s\n",
      "\titers: 900, epoch: 4 | loss: 0.0779531\n",
      "\tspeed: 0.0416s/iter; left time: 601.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0827076 Vali Loss: 0.0849494 Test Loss: 0.0960318\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767040\n",
      "\tspeed: 0.1147s/iter; left time: 1646.9957s\n",
      "\titers: 200, epoch: 5 | loss: 0.0699800\n",
      "\tspeed: 0.0416s/iter; left time: 593.1308s\n",
      "\titers: 300, epoch: 5 | loss: 0.0853455\n",
      "\tspeed: 0.0416s/iter; left time: 588.8973s\n",
      "\titers: 400, epoch: 5 | loss: 0.0704516\n",
      "\tspeed: 0.0416s/iter; left time: 585.1993s\n",
      "\titers: 500, epoch: 5 | loss: 0.0756307\n",
      "\tspeed: 0.0416s/iter; left time: 580.8204s\n",
      "\titers: 600, epoch: 5 | loss: 0.0742427\n",
      "\tspeed: 0.0416s/iter; left time: 576.6748s\n",
      "\titers: 700, epoch: 5 | loss: 0.0752169\n",
      "\tspeed: 0.0416s/iter; left time: 572.6171s\n",
      "\titers: 800, epoch: 5 | loss: 0.0806310\n",
      "\tspeed: 0.0416s/iter; left time: 568.3955s\n",
      "\titers: 900, epoch: 5 | loss: 0.0723156\n",
      "\tspeed: 0.0416s/iter; left time: 564.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0782667 Vali Loss: 0.0774129 Test Loss: 0.0860390\n",
      "Validation loss decreased (0.083233 --> 0.077413).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741043\n",
      "\tspeed: 0.1177s/iter; left time: 1584.3770s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707103\n",
      "\tspeed: 0.0419s/iter; left time: 559.2264s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718977\n",
      "\tspeed: 0.0416s/iter; left time: 551.5400s\n",
      "\titers: 400, epoch: 6 | loss: 0.0712616\n",
      "\tspeed: 0.0416s/iter; left time: 547.3957s\n",
      "\titers: 500, epoch: 6 | loss: 0.0730634\n",
      "\tspeed: 0.0416s/iter; left time: 543.2703s\n",
      "\titers: 600, epoch: 6 | loss: 0.0824830\n",
      "\tspeed: 0.0416s/iter; left time: 539.1506s\n",
      "\titers: 700, epoch: 6 | loss: 0.0697925\n",
      "\tspeed: 0.0416s/iter; left time: 535.2309s\n",
      "\titers: 800, epoch: 6 | loss: 0.0703837\n",
      "\tspeed: 0.0416s/iter; left time: 530.9931s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704858\n",
      "\tspeed: 0.0416s/iter; left time: 526.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 904 | Train Loss: 0.0749824 Vali Loss: 0.0792238 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748432\n",
      "\tspeed: 0.1146s/iter; left time: 1439.4933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809488\n",
      "\tspeed: 0.0421s/iter; left time: 524.7787s\n",
      "\titers: 300, epoch: 7 | loss: 0.0747016\n",
      "\tspeed: 0.0421s/iter; left time: 520.0955s\n",
      "\titers: 400, epoch: 7 | loss: 0.0723035\n",
      "\tspeed: 0.0420s/iter; left time: 515.3437s\n",
      "\titers: 500, epoch: 7 | loss: 0.0700389\n",
      "\tspeed: 0.0418s/iter; left time: 508.5885s\n",
      "\titers: 600, epoch: 7 | loss: 0.0682066\n",
      "\tspeed: 0.0420s/iter; left time: 506.9452s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772949\n",
      "\tspeed: 0.0421s/iter; left time: 503.4054s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649828\n",
      "\tspeed: 0.0421s/iter; left time: 499.1290s\n",
      "\titers: 900, epoch: 7 | loss: 0.0713191\n",
      "\tspeed: 0.0420s/iter; left time: 494.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 904 | Train Loss: 0.0719335 Vali Loss: 0.0794691 Test Loss: 0.0918467\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724586\n",
      "\tspeed: 0.1142s/iter; left time: 1330.5487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0715756\n",
      "\tspeed: 0.0415s/iter; left time: 479.8969s\n",
      "\titers: 300, epoch: 8 | loss: 0.0657794\n",
      "\tspeed: 0.0415s/iter; left time: 475.6346s\n",
      "\titers: 400, epoch: 8 | loss: 0.0654476\n",
      "\tspeed: 0.0415s/iter; left time: 471.6994s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704021\n",
      "\tspeed: 0.0415s/iter; left time: 467.4944s\n",
      "\titers: 600, epoch: 8 | loss: 0.0675833\n",
      "\tspeed: 0.0416s/iter; left time: 463.5340s\n",
      "\titers: 700, epoch: 8 | loss: 0.0698371\n",
      "\tspeed: 0.0416s/iter; left time: 459.3636s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766558\n",
      "\tspeed: 0.0415s/iter; left time: 455.0782s\n",
      "\titers: 900, epoch: 8 | loss: 0.0691651\n",
      "\tspeed: 0.0416s/iter; left time: 451.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0692788 Vali Loss: 0.0809576 Test Loss: 0.0899754\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0643936\n",
      "\tspeed: 0.1136s/iter; left time: 1221.2237s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613265\n",
      "\tspeed: 0.0415s/iter; left time: 441.8698s\n",
      "\titers: 300, epoch: 9 | loss: 0.0656117\n",
      "\tspeed: 0.0415s/iter; left time: 437.8691s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665474\n",
      "\tspeed: 0.0415s/iter; left time: 433.7844s\n",
      "\titers: 500, epoch: 9 | loss: 0.0646721\n",
      "\tspeed: 0.0415s/iter; left time: 429.7658s\n",
      "\titers: 600, epoch: 9 | loss: 0.0673045\n",
      "\tspeed: 0.0415s/iter; left time: 425.3731s\n",
      "\titers: 700, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0415s/iter; left time: 421.4103s\n",
      "\titers: 800, epoch: 9 | loss: 0.0713633\n",
      "\tspeed: 0.0415s/iter; left time: 417.2159s\n",
      "\titers: 900, epoch: 9 | loss: 0.0673369\n",
      "\tspeed: 0.0415s/iter; left time: 413.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0662697 Vali Loss: 0.0811222 Test Loss: 0.0916531\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0716086\n",
      "\tspeed: 0.1136s/iter; left time: 1118.5103s\n",
      "\titers: 200, epoch: 10 | loss: 0.0616231\n",
      "\tspeed: 0.0416s/iter; left time: 405.1216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0624919\n",
      "\tspeed: 0.0416s/iter; left time: 400.7687s\n",
      "\titers: 400, epoch: 10 | loss: 0.0612750\n",
      "\tspeed: 0.0416s/iter; left time: 396.6213s\n",
      "\titers: 500, epoch: 10 | loss: 0.0687094\n",
      "\tspeed: 0.0416s/iter; left time: 392.6357s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689967\n",
      "\tspeed: 0.0416s/iter; left time: 388.3021s\n",
      "\titers: 700, epoch: 10 | loss: 0.0666971\n",
      "\tspeed: 0.0416s/iter; left time: 384.3920s\n",
      "\titers: 800, epoch: 10 | loss: 0.0618813\n",
      "\tspeed: 0.0416s/iter; left time: 380.2382s\n",
      "\titers: 900, epoch: 10 | loss: 0.0615688\n",
      "\tspeed: 0.0416s/iter; left time: 375.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0640776 Vali Loss: 0.0819628 Test Loss: 0.0911019\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019260551780462265, rmse:0.13878239691257477, mae:0.08605317771434784, rse:0.5247511863708496\n",
      "Intermediate time for IT and pred_len 96: 00h:17m:29.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2417706\n",
      "\tspeed: 0.0736s/iter; left time: 1320.0040s\n",
      "\titers: 200, epoch: 1 | loss: 0.2105667\n",
      "\tspeed: 0.0507s/iter; left time: 905.0718s\n",
      "\titers: 300, epoch: 1 | loss: 0.2133086\n",
      "\tspeed: 0.0508s/iter; left time: 900.7788s\n",
      "\titers: 400, epoch: 1 | loss: 0.2001980\n",
      "\tspeed: 0.0508s/iter; left time: 896.6578s\n",
      "\titers: 500, epoch: 1 | loss: 0.1996722\n",
      "\tspeed: 0.0509s/iter; left time: 892.1233s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957152\n",
      "\tspeed: 0.0508s/iter; left time: 886.5263s\n",
      "\titers: 700, epoch: 1 | loss: 0.1911985\n",
      "\tspeed: 0.0508s/iter; left time: 881.4821s\n",
      "\titers: 800, epoch: 1 | loss: 0.1923567\n",
      "\tspeed: 0.0504s/iter; left time: 869.0295s\n",
      "\titers: 900, epoch: 1 | loss: 0.1911421\n",
      "\tspeed: 0.0507s/iter; left time: 869.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.2067105 Vali Loss: 0.1742837 Test Loss: 0.1910858\n",
      "Validation loss decreased (inf --> 0.174284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1741898\n",
      "\tspeed: 0.1420s/iter; left time: 2419.5547s\n",
      "\titers: 200, epoch: 2 | loss: 0.1590756\n",
      "\tspeed: 0.0504s/iter; left time: 853.3194s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492482\n",
      "\tspeed: 0.0504s/iter; left time: 848.3516s\n",
      "\titers: 400, epoch: 2 | loss: 0.1439626\n",
      "\tspeed: 0.0504s/iter; left time: 843.9217s\n",
      "\titers: 500, epoch: 2 | loss: 0.1376841\n",
      "\tspeed: 0.0504s/iter; left time: 837.8947s\n",
      "\titers: 600, epoch: 2 | loss: 0.1318157\n",
      "\tspeed: 0.0504s/iter; left time: 834.1674s\n",
      "\titers: 700, epoch: 2 | loss: 0.1226903\n",
      "\tspeed: 0.0505s/iter; left time: 829.4095s\n",
      "\titers: 800, epoch: 2 | loss: 0.1155013\n",
      "\tspeed: 0.0504s/iter; left time: 823.6467s\n",
      "\titers: 900, epoch: 2 | loss: 0.1036045\n",
      "\tspeed: 0.0503s/iter; left time: 817.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1425180 Vali Loss: 0.0997220 Test Loss: 0.1080564\n",
      "Validation loss decreased (0.174284 --> 0.099722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1070874\n",
      "\tspeed: 0.1400s/iter; left time: 2259.1733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982135\n",
      "\tspeed: 0.0504s/iter; left time: 808.0465s\n",
      "\titers: 300, epoch: 3 | loss: 0.0975068\n",
      "\tspeed: 0.0504s/iter; left time: 803.1246s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913634\n",
      "\tspeed: 0.0505s/iter; left time: 799.1843s\n",
      "\titers: 500, epoch: 3 | loss: 0.0938966\n",
      "\tspeed: 0.0504s/iter; left time: 792.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963875\n",
      "\tspeed: 0.0504s/iter; left time: 787.6281s\n",
      "\titers: 700, epoch: 3 | loss: 0.0930466\n",
      "\tspeed: 0.0504s/iter; left time: 782.8578s\n",
      "\titers: 800, epoch: 3 | loss: 0.0894339\n",
      "\tspeed: 0.0504s/iter; left time: 777.7969s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931466\n",
      "\tspeed: 0.0503s/iter; left time: 771.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0965498 Vali Loss: 0.0912357 Test Loss: 0.1002337\n",
      "Validation loss decreased (0.099722 --> 0.091236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912320\n",
      "\tspeed: 0.1400s/iter; left time: 2132.5732s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867965\n",
      "\tspeed: 0.0507s/iter; left time: 766.7007s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868980\n",
      "\tspeed: 0.0504s/iter; left time: 757.3387s\n",
      "\titers: 400, epoch: 4 | loss: 0.0909916\n",
      "\tspeed: 0.0505s/iter; left time: 754.3584s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869087\n",
      "\tspeed: 0.0504s/iter; left time: 747.6462s\n",
      "\titers: 600, epoch: 4 | loss: 0.0885214\n",
      "\tspeed: 0.0505s/iter; left time: 743.8012s\n",
      "\titers: 700, epoch: 4 | loss: 0.0855719\n",
      "\tspeed: 0.0504s/iter; left time: 736.8779s\n",
      "\titers: 800, epoch: 4 | loss: 0.0911454\n",
      "\tspeed: 0.0505s/iter; left time: 733.7025s\n",
      "\titers: 900, epoch: 4 | loss: 0.0852361\n",
      "\tspeed: 0.0505s/iter; left time: 729.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 902 | Train Loss: 0.0885773 Vali Loss: 0.0855312 Test Loss: 0.0943597\n",
      "Validation loss decreased (0.091236 --> 0.085531).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867432\n",
      "\tspeed: 0.1406s/iter; left time: 2015.7843s\n",
      "\titers: 200, epoch: 5 | loss: 0.0810685\n",
      "\tspeed: 0.0508s/iter; left time: 723.4109s\n",
      "\titers: 300, epoch: 5 | loss: 0.0855442\n",
      "\tspeed: 0.0509s/iter; left time: 718.7145s\n",
      "\titers: 400, epoch: 5 | loss: 0.0874002\n",
      "\tspeed: 0.0508s/iter; left time: 713.4811s\n",
      "\titers: 500, epoch: 5 | loss: 0.0819072\n",
      "\tspeed: 0.0508s/iter; left time: 708.2703s\n",
      "\titers: 600, epoch: 5 | loss: 0.0860219\n",
      "\tspeed: 0.0505s/iter; left time: 698.6841s\n",
      "\titers: 700, epoch: 5 | loss: 0.0811444\n",
      "\tspeed: 0.0504s/iter; left time: 692.2963s\n",
      "\titers: 800, epoch: 5 | loss: 0.0809208\n",
      "\tspeed: 0.0504s/iter; left time: 687.4578s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855082\n",
      "\tspeed: 0.0504s/iter; left time: 682.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0836334 Vali Loss: 0.0855765 Test Loss: 0.0958990\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0837307\n",
      "\tspeed: 0.1369s/iter; left time: 1838.9239s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879220\n",
      "\tspeed: 0.0504s/iter; left time: 671.5331s\n",
      "\titers: 300, epoch: 6 | loss: 0.0843503\n",
      "\tspeed: 0.0504s/iter; left time: 667.0104s\n",
      "\titers: 400, epoch: 6 | loss: 0.0791846\n",
      "\tspeed: 0.0505s/iter; left time: 662.9974s\n",
      "\titers: 500, epoch: 6 | loss: 0.0788330\n",
      "\tspeed: 0.0504s/iter; left time: 656.3321s\n",
      "\titers: 600, epoch: 6 | loss: 0.0786551\n",
      "\tspeed: 0.0504s/iter; left time: 651.4243s\n",
      "\titers: 700, epoch: 6 | loss: 0.0774791\n",
      "\tspeed: 0.0503s/iter; left time: 645.9442s\n",
      "\titers: 800, epoch: 6 | loss: 0.0832842\n",
      "\tspeed: 0.0504s/iter; left time: 641.4467s\n",
      "\titers: 900, epoch: 6 | loss: 0.0777149\n",
      "\tspeed: 0.0504s/iter; left time: 636.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0799680 Vali Loss: 0.0855314 Test Loss: 0.0941967\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832227\n",
      "\tspeed: 0.1374s/iter; left time: 1721.4858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769130\n",
      "\tspeed: 0.0504s/iter; left time: 626.6860s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797686\n",
      "\tspeed: 0.0504s/iter; left time: 621.5318s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803033\n",
      "\tspeed: 0.0504s/iter; left time: 616.8940s\n",
      "\titers: 500, epoch: 7 | loss: 0.0713358\n",
      "\tspeed: 0.0504s/iter; left time: 611.6196s\n",
      "\titers: 600, epoch: 7 | loss: 0.0767121\n",
      "\tspeed: 0.0504s/iter; left time: 606.4779s\n",
      "\titers: 700, epoch: 7 | loss: 0.0724495\n",
      "\tspeed: 0.0504s/iter; left time: 601.4541s\n",
      "\titers: 800, epoch: 7 | loss: 0.0772860\n",
      "\tspeed: 0.0504s/iter; left time: 596.5747s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758775\n",
      "\tspeed: 0.0504s/iter; left time: 591.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0763688 Vali Loss: 0.0862588 Test Loss: 0.0960034\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746740\n",
      "\tspeed: 0.1380s/iter; left time: 1604.7483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710704\n",
      "\tspeed: 0.0504s/iter; left time: 581.3052s\n",
      "\titers: 300, epoch: 8 | loss: 0.0767001\n",
      "\tspeed: 0.0504s/iter; left time: 576.2394s\n",
      "\titers: 400, epoch: 8 | loss: 0.0722365\n",
      "\tspeed: 0.0505s/iter; left time: 571.5276s\n",
      "\titers: 500, epoch: 8 | loss: 0.0735169\n",
      "\tspeed: 0.0504s/iter; left time: 566.0925s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702938\n",
      "\tspeed: 0.0504s/iter; left time: 561.0255s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752317\n",
      "\tspeed: 0.0504s/iter; left time: 556.1749s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745411\n",
      "\tspeed: 0.0504s/iter; left time: 551.2586s\n",
      "\titers: 900, epoch: 8 | loss: 0.0704616\n",
      "\tspeed: 0.0505s/iter; left time: 546.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0728395 Vali Loss: 0.0874766 Test Loss: 0.0982277\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0669056\n",
      "\tspeed: 0.1385s/iter; left time: 1485.4205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704915\n",
      "\tspeed: 0.0505s/iter; left time: 536.4953s\n",
      "\titers: 300, epoch: 9 | loss: 0.0730468\n",
      "\tspeed: 0.0505s/iter; left time: 531.1503s\n",
      "\titers: 400, epoch: 9 | loss: 0.0681769\n",
      "\tspeed: 0.0504s/iter; left time: 525.8961s\n",
      "\titers: 500, epoch: 9 | loss: 0.0706938\n",
      "\tspeed: 0.0504s/iter; left time: 520.7010s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717596\n",
      "\tspeed: 0.0504s/iter; left time: 515.5981s\n",
      "\titers: 700, epoch: 9 | loss: 0.0657810\n",
      "\tspeed: 0.0504s/iter; left time: 510.4238s\n",
      "\titers: 800, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0504s/iter; left time: 505.3338s\n",
      "\titers: 900, epoch: 9 | loss: 0.0668692\n",
      "\tspeed: 0.0504s/iter; left time: 500.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0693792 Vali Loss: 0.0873247 Test Loss: 0.0969773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020803824067115784, rmse:0.14423531293869019, mae:0.09436223655939102, rse:0.5457460880279541\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2284859\n",
      "\tspeed: 0.0530s/iter; left time: 950.1871s\n",
      "\titers: 200, epoch: 1 | loss: 0.2267227\n",
      "\tspeed: 0.0508s/iter; left time: 906.6906s\n",
      "\titers: 300, epoch: 1 | loss: 0.2108397\n",
      "\tspeed: 0.0504s/iter; left time: 893.5250s\n",
      "\titers: 400, epoch: 1 | loss: 0.2069933\n",
      "\tspeed: 0.0504s/iter; left time: 889.6918s\n",
      "\titers: 500, epoch: 1 | loss: 0.2013356\n",
      "\tspeed: 0.0504s/iter; left time: 884.5309s\n",
      "\titers: 600, epoch: 1 | loss: 0.1998173\n",
      "\tspeed: 0.0504s/iter; left time: 879.8400s\n",
      "\titers: 700, epoch: 1 | loss: 0.1979535\n",
      "\tspeed: 0.0507s/iter; left time: 879.3869s\n",
      "\titers: 800, epoch: 1 | loss: 0.1894962\n",
      "\tspeed: 0.0504s/iter; left time: 869.3943s\n",
      "\titers: 900, epoch: 1 | loss: 0.1864503\n",
      "\tspeed: 0.0504s/iter; left time: 864.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.2082656 Vali Loss: 0.1732536 Test Loss: 0.1907203\n",
      "Validation loss decreased (inf --> 0.173254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1713080\n",
      "\tspeed: 0.1403s/iter; left time: 2391.2121s\n",
      "\titers: 200, epoch: 2 | loss: 0.1709103\n",
      "\tspeed: 0.0504s/iter; left time: 853.8744s\n",
      "\titers: 300, epoch: 2 | loss: 0.1648743\n",
      "\tspeed: 0.0504s/iter; left time: 849.1595s\n",
      "\titers: 400, epoch: 2 | loss: 0.1496821\n",
      "\tspeed: 0.0506s/iter; left time: 846.7754s\n",
      "\titers: 500, epoch: 2 | loss: 0.1361954\n",
      "\tspeed: 0.0506s/iter; left time: 841.4153s\n",
      "\titers: 600, epoch: 2 | loss: 0.1361084\n",
      "\tspeed: 0.0505s/iter; left time: 835.2886s\n",
      "\titers: 700, epoch: 2 | loss: 0.1295184\n",
      "\tspeed: 0.0504s/iter; left time: 829.2730s\n",
      "\titers: 800, epoch: 2 | loss: 0.1168782\n",
      "\tspeed: 0.0504s/iter; left time: 824.1832s\n",
      "\titers: 900, epoch: 2 | loss: 0.1084049\n",
      "\tspeed: 0.0504s/iter; left time: 819.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1460171 Vali Loss: 0.0987828 Test Loss: 0.1063009\n",
      "Validation loss decreased (0.173254 --> 0.098783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1028040\n",
      "\tspeed: 0.1409s/iter; left time: 2274.2749s\n",
      "\titers: 200, epoch: 3 | loss: 0.1012544\n",
      "\tspeed: 0.0504s/iter; left time: 808.7178s\n",
      "\titers: 300, epoch: 3 | loss: 0.0942322\n",
      "\tspeed: 0.0505s/iter; left time: 804.2001s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913546\n",
      "\tspeed: 0.0505s/iter; left time: 799.2814s\n",
      "\titers: 500, epoch: 3 | loss: 0.0966000\n",
      "\tspeed: 0.0506s/iter; left time: 796.0874s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914325\n",
      "\tspeed: 0.0505s/iter; left time: 789.9978s\n",
      "\titers: 700, epoch: 3 | loss: 0.0900648\n",
      "\tspeed: 0.0504s/iter; left time: 783.6762s\n",
      "\titers: 800, epoch: 3 | loss: 0.0941671\n",
      "\tspeed: 0.0504s/iter; left time: 778.7342s\n",
      "\titers: 900, epoch: 3 | loss: 0.0972075\n",
      "\tspeed: 0.0504s/iter; left time: 773.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0964605 Vali Loss: 0.0890032 Test Loss: 0.0937895\n",
      "Validation loss decreased (0.098783 --> 0.089003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857249\n",
      "\tspeed: 0.1414s/iter; left time: 2154.7841s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923728\n",
      "\tspeed: 0.0510s/iter; left time: 772.5200s\n",
      "\titers: 300, epoch: 4 | loss: 0.0903793\n",
      "\tspeed: 0.0511s/iter; left time: 768.5896s\n",
      "\titers: 400, epoch: 4 | loss: 0.0886440\n",
      "\tspeed: 0.0510s/iter; left time: 761.8474s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932834\n",
      "\tspeed: 0.0510s/iter; left time: 757.3216s\n",
      "\titers: 600, epoch: 4 | loss: 0.0853107\n",
      "\tspeed: 0.0510s/iter; left time: 751.9702s\n",
      "\titers: 700, epoch: 4 | loss: 0.0900107\n",
      "\tspeed: 0.0510s/iter; left time: 746.5617s\n",
      "\titers: 800, epoch: 4 | loss: 0.0842938\n",
      "\tspeed: 0.0512s/iter; left time: 743.4796s\n",
      "\titers: 900, epoch: 4 | loss: 0.0850098\n",
      "\tspeed: 0.0510s/iter; left time: 736.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.39s\n",
      "Steps: 902 | Train Loss: 0.0881512 Vali Loss: 0.0848641 Test Loss: 0.0966458\n",
      "Validation loss decreased (0.089003 --> 0.084864).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882770\n",
      "\tspeed: 0.1422s/iter; left time: 2038.8512s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824666\n",
      "\tspeed: 0.0504s/iter; left time: 717.6569s\n",
      "\titers: 300, epoch: 5 | loss: 0.0812579\n",
      "\tspeed: 0.0504s/iter; left time: 712.7247s\n",
      "\titers: 400, epoch: 5 | loss: 0.0867619\n",
      "\tspeed: 0.0504s/iter; left time: 707.9227s\n",
      "\titers: 500, epoch: 5 | loss: 0.0906413\n",
      "\tspeed: 0.0504s/iter; left time: 702.4616s\n",
      "\titers: 600, epoch: 5 | loss: 0.0816955\n",
      "\tspeed: 0.0504s/iter; left time: 697.5462s\n",
      "\titers: 700, epoch: 5 | loss: 0.0825760\n",
      "\tspeed: 0.0504s/iter; left time: 692.3392s\n",
      "\titers: 800, epoch: 5 | loss: 0.0871430\n",
      "\tspeed: 0.0505s/iter; left time: 688.0002s\n",
      "\titers: 900, epoch: 5 | loss: 0.0818188\n",
      "\tspeed: 0.0505s/iter; left time: 682.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0832878 Vali Loss: 0.0822736 Test Loss: 0.0991102\n",
      "Validation loss decreased (0.084864 --> 0.082274).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807753\n",
      "\tspeed: 0.1417s/iter; left time: 1903.7318s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926194\n",
      "\tspeed: 0.0504s/iter; left time: 672.3669s\n",
      "\titers: 300, epoch: 6 | loss: 0.0734528\n",
      "\tspeed: 0.0504s/iter; left time: 667.3297s\n",
      "\titers: 400, epoch: 6 | loss: 0.0836199\n",
      "\tspeed: 0.0504s/iter; left time: 662.0244s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807985\n",
      "\tspeed: 0.0504s/iter; left time: 657.1533s\n",
      "\titers: 600, epoch: 6 | loss: 0.0781274\n",
      "\tspeed: 0.0504s/iter; left time: 651.9781s\n",
      "\titers: 700, epoch: 6 | loss: 0.0795121\n",
      "\tspeed: 0.0504s/iter; left time: 647.0378s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790593\n",
      "\tspeed: 0.0505s/iter; left time: 642.5466s\n",
      "\titers: 900, epoch: 6 | loss: 0.0770177\n",
      "\tspeed: 0.0504s/iter; left time: 637.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0793978 Vali Loss: 0.0833777 Test Loss: 0.0989826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754626\n",
      "\tspeed: 0.1373s/iter; left time: 1720.0845s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837843\n",
      "\tspeed: 0.0504s/iter; left time: 626.6227s\n",
      "\titers: 300, epoch: 7 | loss: 0.0735349\n",
      "\tspeed: 0.0505s/iter; left time: 622.1110s\n",
      "\titers: 400, epoch: 7 | loss: 0.0791819\n",
      "\tspeed: 0.0505s/iter; left time: 617.3518s\n",
      "\titers: 500, epoch: 7 | loss: 0.0693690\n",
      "\tspeed: 0.0504s/iter; left time: 611.2815s\n",
      "\titers: 600, epoch: 7 | loss: 0.0743524\n",
      "\tspeed: 0.0504s/iter; left time: 606.8297s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732933\n",
      "\tspeed: 0.0505s/iter; left time: 602.0026s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761782\n",
      "\tspeed: 0.0504s/iter; left time: 596.3598s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737806\n",
      "\tspeed: 0.0505s/iter; left time: 591.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0760379 Vali Loss: 0.0858319 Test Loss: 0.0968157\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726987\n",
      "\tspeed: 0.1384s/iter; left time: 1609.0217s\n",
      "\titers: 200, epoch: 8 | loss: 0.0783981\n",
      "\tspeed: 0.0504s/iter; left time: 581.5175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806944\n",
      "\tspeed: 0.0505s/iter; left time: 576.9424s\n",
      "\titers: 400, epoch: 8 | loss: 0.0715075\n",
      "\tspeed: 0.0505s/iter; left time: 572.5696s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0504s/iter; left time: 566.3231s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702019\n",
      "\tspeed: 0.0505s/iter; left time: 561.4528s\n",
      "\titers: 700, epoch: 8 | loss: 0.0728789\n",
      "\tspeed: 0.0504s/iter; left time: 556.0862s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746686\n",
      "\tspeed: 0.0504s/iter; left time: 551.0988s\n",
      "\titers: 900, epoch: 8 | loss: 0.0702752\n",
      "\tspeed: 0.0504s/iter; left time: 545.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0726852 Vali Loss: 0.0867959 Test Loss: 0.0998598\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0709978\n",
      "\tspeed: 0.1381s/iter; left time: 1481.3268s\n",
      "\titers: 200, epoch: 9 | loss: 0.0679601\n",
      "\tspeed: 0.0510s/iter; left time: 541.8042s\n",
      "\titers: 300, epoch: 9 | loss: 0.0751877\n",
      "\tspeed: 0.0511s/iter; left time: 537.3441s\n",
      "\titers: 400, epoch: 9 | loss: 0.0699946\n",
      "\tspeed: 0.0510s/iter; left time: 531.8428s\n",
      "\titers: 500, epoch: 9 | loss: 0.0732694\n",
      "\tspeed: 0.0511s/iter; left time: 527.1437s\n",
      "\titers: 600, epoch: 9 | loss: 0.0649203\n",
      "\tspeed: 0.0510s/iter; left time: 521.5651s\n",
      "\titers: 700, epoch: 9 | loss: 0.0642313\n",
      "\tspeed: 0.0510s/iter; left time: 516.1117s\n",
      "\titers: 800, epoch: 9 | loss: 0.0708400\n",
      "\tspeed: 0.0510s/iter; left time: 511.2901s\n",
      "\titers: 900, epoch: 9 | loss: 0.0663069\n",
      "\tspeed: 0.0506s/iter; left time: 501.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 902 | Train Loss: 0.0691620 Vali Loss: 0.0897910 Test Loss: 0.1007773\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0708059\n",
      "\tspeed: 0.1368s/iter; left time: 1344.0071s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699524\n",
      "\tspeed: 0.0504s/iter; left time: 490.3308s\n",
      "\titers: 300, epoch: 10 | loss: 0.0707789\n",
      "\tspeed: 0.0504s/iter; left time: 485.3786s\n",
      "\titers: 400, epoch: 10 | loss: 0.0686859\n",
      "\tspeed: 0.0504s/iter; left time: 480.1413s\n",
      "\titers: 500, epoch: 10 | loss: 0.0652517\n",
      "\tspeed: 0.0504s/iter; left time: 474.8593s\n",
      "\titers: 600, epoch: 10 | loss: 0.0646466\n",
      "\tspeed: 0.0504s/iter; left time: 470.0499s\n",
      "\titers: 700, epoch: 10 | loss: 0.0682247\n",
      "\tspeed: 0.0504s/iter; left time: 465.0166s\n",
      "\titers: 800, epoch: 10 | loss: 0.0651449\n",
      "\tspeed: 0.0506s/iter; left time: 461.9457s\n",
      "\titers: 900, epoch: 10 | loss: 0.0604966\n",
      "\tspeed: 0.0505s/iter; left time: 455.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0659150 Vali Loss: 0.0909240 Test Loss: 0.1030022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023398978635668755, rmse:0.15296724438667297, mae:0.09908542037010193, rse:0.578785240650177\n",
      "Intermediate time for IT and pred_len 168: 00h:17m:32.00s\n",
      "Intermediate time for IT: 00h:58m:20.06s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[26], line 98\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m hours, mins, secs \u001b[38;5;241m=\u001b[39m running_time(start, end)\n",
      "\u001b[1;32m     97\u001b[0m statement_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time: \u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mm:\u001b[39m\u001b[38;5;132;01m{:05.2f}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hours, mins, secs)\n",
      "\u001b[0;32m---> 98\u001b[0m \u001b[43mlog_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement_5\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(statement_5)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0263  0.1622  0.1042\n",
       "        96         0.0430  0.2074  0.1434\n",
       "        168        0.0534  0.2311  0.1585\n",
       "ES      24         0.0234  0.1523  0.0922\n",
       "        96         0.0526  0.2293  0.1431\n",
       "        168        0.0523  0.2281  0.1467\n",
       "FR      24         0.0125  0.1117  0.0636\n",
       "        96         0.0225  0.1499  0.0897\n",
       "        168        0.0243  0.1559  0.0971\n",
       "GB      24         0.0325  0.1802  0.1202\n",
       "        96         0.0506  0.2249  0.1575\n",
       "        168        0.0603  0.2454  0.1703\n",
       "IT      24         0.0126  0.1120  0.0657\n",
       "        96         0.0208  0.1441  0.0887\n",
       "        168        0.0221  0.1486  0.0967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1552846\n",
      "\tspeed: 0.0386s/iter; left time: 169.1497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349387\n",
      "\tspeed: 0.0171s/iter; left time: 73.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1540624 Vali Loss: 0.1402043 Test Loss: 0.1497415\n",
      "Validation loss decreased (inf --> 0.140204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870196\n",
      "\tspeed: 0.0377s/iter; left time: 156.6963s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852675\n",
      "\tspeed: 0.0172s/iter; left time: 69.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0921912 Vali Loss: 0.0948991 Test Loss: 0.0956263\n",
      "Validation loss decreased (0.140204 --> 0.094899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0780745\n",
      "\tspeed: 0.0375s/iter; left time: 147.3494s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829521\n",
      "\tspeed: 0.0172s/iter; left time: 65.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0813875 Vali Loss: 0.0914835 Test Loss: 0.0926128\n",
      "Validation loss decreased (0.094899 --> 0.091483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0763411\n",
      "\tspeed: 0.0370s/iter; left time: 137.0593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788606\n",
      "\tspeed: 0.0172s/iter; left time: 61.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0785792 Vali Loss: 0.0897479 Test Loss: 0.0915311\n",
      "Validation loss decreased (0.091483 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786201\n",
      "\tspeed: 0.0372s/iter; left time: 129.8125s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775603\n",
      "\tspeed: 0.0171s/iter; left time: 58.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0770201 Vali Loss: 0.0888097 Test Loss: 0.0907630\n",
      "Validation loss decreased (0.089748 --> 0.088810).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797430\n",
      "\tspeed: 0.0367s/iter; left time: 119.8188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739905\n",
      "\tspeed: 0.0171s/iter; left time: 54.0657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0759351 Vali Loss: 0.0882563 Test Loss: 0.0899552\n",
      "Validation loss decreased (0.088810 --> 0.088256).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744912\n",
      "\tspeed: 0.0361s/iter; left time: 109.4976s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771100\n",
      "\tspeed: 0.0171s/iter; left time: 50.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0752218 Vali Loss: 0.0878177 Test Loss: 0.0892529\n",
      "Validation loss decreased (0.088256 --> 0.087818).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781358\n",
      "\tspeed: 0.0364s/iter; left time: 102.5174s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730628\n",
      "\tspeed: 0.0171s/iter; left time: 46.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0746178 Vali Loss: 0.0877714 Test Loss: 0.0892701\n",
      "Validation loss decreased (0.087818 --> 0.087771).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749489\n",
      "\tspeed: 0.0378s/iter; left time: 97.9551s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725721\n",
      "\tspeed: 0.0171s/iter; left time: 42.5431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0740126 Vali Loss: 0.0871786 Test Loss: 0.0891943\n",
      "Validation loss decreased (0.087771 --> 0.087179).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726015\n",
      "\tspeed: 0.0367s/iter; left time: 86.8023s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741761\n",
      "\tspeed: 0.0171s/iter; left time: 38.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0736832 Vali Loss: 0.0868305 Test Loss: 0.0889153\n",
      "Validation loss decreased (0.087179 --> 0.086830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685348\n",
      "\tspeed: 0.0372s/iter; left time: 79.6720s\n",
      "\titers: 200, epoch: 11 | loss: 0.0705283\n",
      "\tspeed: 0.0172s/iter; left time: 35.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0734142 Vali Loss: 0.0868541 Test Loss: 0.0888376\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0706811\n",
      "\tspeed: 0.0366s/iter; left time: 70.2452s\n",
      "\titers: 200, epoch: 12 | loss: 0.0724820\n",
      "\tspeed: 0.0171s/iter; left time: 31.0776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0730704 Vali Loss: 0.0866896 Test Loss: 0.0885880\n",
      "Validation loss decreased (0.086830 --> 0.086690).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729633\n",
      "\tspeed: 0.0369s/iter; left time: 62.4995s\n",
      "\titers: 200, epoch: 13 | loss: 0.0778621\n",
      "\tspeed: 0.0171s/iter; left time: 27.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0727560 Vali Loss: 0.0865001 Test Loss: 0.0886636\n",
      "Validation loss decreased (0.086690 --> 0.086500).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709714\n",
      "\tspeed: 0.0387s/iter; left time: 56.8315s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751399\n",
      "\tspeed: 0.0176s/iter; left time: 24.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0725595 Vali Loss: 0.0860851 Test Loss: 0.0884585\n",
      "Validation loss decreased (0.086500 --> 0.086085).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0737076\n",
      "\tspeed: 0.0386s/iter; left time: 48.0530s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740580\n",
      "\tspeed: 0.0176s/iter; left time: 20.1028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0723475 Vali Loss: 0.0862519 Test Loss: 0.0885224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741089\n",
      "\tspeed: 0.0376s/iter; left time: 38.4246s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679487\n",
      "\tspeed: 0.0176s/iter; left time: 16.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0722050 Vali Loss: 0.0863559 Test Loss: 0.0885100\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0714612\n",
      "\tspeed: 0.0381s/iter; left time: 30.3517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703044\n",
      "\tspeed: 0.0178s/iter; left time: 12.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0720605 Vali Loss: 0.0860859 Test Loss: 0.0882050\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692411\n",
      "\tspeed: 0.0377s/iter; left time: 21.6031s\n",
      "\titers: 200, epoch: 18 | loss: 0.0696555\n",
      "\tspeed: 0.0175s/iter; left time: 8.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0719251 Vali Loss: 0.0860834 Test Loss: 0.0883264\n",
      "Validation loss decreased (0.086085 --> 0.086083).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0666350\n",
      "\tspeed: 0.0387s/iter; left time: 13.4968s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690289\n",
      "\tspeed: 0.0176s/iter; left time: 4.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0718146 Vali Loss: 0.0862328 Test Loss: 0.0883009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727314\n",
      "\tspeed: 0.0387s/iter; left time: 4.8361s\n",
      "\titers: 200, epoch: 20 | loss: 0.0679560\n",
      "\tspeed: 0.0176s/iter; left time: 0.4397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0717518 Vali Loss: 0.0859731 Test Loss: 0.0882746\n",
      "Validation loss decreased (0.086083 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0210769884288311, rmse:0.1451791524887085, mae:0.08827455341815948, rse:0.5123573541641235\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1570233\n",
      "\tspeed: 0.0199s/iter; left time: 86.9701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1280985\n",
      "\tspeed: 0.0176s/iter; left time: 75.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1548676 Vali Loss: 0.1411604 Test Loss: 0.1500474\n",
      "Validation loss decreased (inf --> 0.141160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0882181\n",
      "\tspeed: 0.0378s/iter; left time: 157.1319s\n",
      "\titers: 200, epoch: 2 | loss: 0.0908060\n",
      "\tspeed: 0.0177s/iter; left time: 71.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0924610 Vali Loss: 0.0944853 Test Loss: 0.0955149\n",
      "Validation loss decreased (0.141160 --> 0.094485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820593\n",
      "\tspeed: 0.0370s/iter; left time: 145.3278s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806413\n",
      "\tspeed: 0.0175s/iter; left time: 67.2454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0812146 Vali Loss: 0.0912485 Test Loss: 0.0926978\n",
      "Validation loss decreased (0.094485 --> 0.091248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721176\n",
      "\tspeed: 0.0372s/iter; left time: 138.0003s\n",
      "\titers: 200, epoch: 4 | loss: 0.0759243\n",
      "\tspeed: 0.0176s/iter; left time: 63.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0786283 Vali Loss: 0.0901646 Test Loss: 0.0913521\n",
      "Validation loss decreased (0.091248 --> 0.090165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0774314\n",
      "\tspeed: 0.0371s/iter; left time: 129.3976s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733740\n",
      "\tspeed: 0.0176s/iter; left time: 59.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0771180 Vali Loss: 0.0891310 Test Loss: 0.0905645\n",
      "Validation loss decreased (0.090165 --> 0.089131).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777217\n",
      "\tspeed: 0.0381s/iter; left time: 124.1840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0788934\n",
      "\tspeed: 0.0174s/iter; left time: 55.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0760264 Vali Loss: 0.0887408 Test Loss: 0.0903082\n",
      "Validation loss decreased (0.089131 --> 0.088741).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783334\n",
      "\tspeed: 0.0375s/iter; left time: 113.9005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0725325\n",
      "\tspeed: 0.0176s/iter; left time: 51.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0752755 Vali Loss: 0.0877701 Test Loss: 0.0896570\n",
      "Validation loss decreased (0.088741 --> 0.087770).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0791230\n",
      "\tspeed: 0.0374s/iter; left time: 105.2542s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748657\n",
      "\tspeed: 0.0176s/iter; left time: 47.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0746919 Vali Loss: 0.0874901 Test Loss: 0.0895536\n",
      "Validation loss decreased (0.087770 --> 0.087490).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736110\n",
      "\tspeed: 0.0377s/iter; left time: 97.5055s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704603\n",
      "\tspeed: 0.0176s/iter; left time: 43.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0741805 Vali Loss: 0.0873955 Test Loss: 0.0892691\n",
      "Validation loss decreased (0.087490 --> 0.087395).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0782311\n",
      "\tspeed: 0.0382s/iter; left time: 90.4315s\n",
      "\titers: 200, epoch: 10 | loss: 0.0763321\n",
      "\tspeed: 0.0177s/iter; left time: 40.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0737265 Vali Loss: 0.0872063 Test Loss: 0.0889933\n",
      "Validation loss decreased (0.087395 --> 0.087206).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0760693\n",
      "\tspeed: 0.0371s/iter; left time: 79.4071s\n",
      "\titers: 200, epoch: 11 | loss: 0.0712096\n",
      "\tspeed: 0.0177s/iter; left time: 36.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0734939 Vali Loss: 0.0869958 Test Loss: 0.0890277\n",
      "Validation loss decreased (0.087206 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767276\n",
      "\tspeed: 0.0374s/iter; left time: 71.7213s\n",
      "\titers: 200, epoch: 12 | loss: 0.0735241\n",
      "\tspeed: 0.0173s/iter; left time: 31.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0731428 Vali Loss: 0.0867699 Test Loss: 0.0890896\n",
      "Validation loss decreased (0.086996 --> 0.086770).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764216\n",
      "\tspeed: 0.0366s/iter; left time: 61.9050s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709676\n",
      "\tspeed: 0.0172s/iter; left time: 27.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0728482 Vali Loss: 0.0863059 Test Loss: 0.0886948\n",
      "Validation loss decreased (0.086770 --> 0.086306).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0664139\n",
      "\tspeed: 0.0371s/iter; left time: 54.4901s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747447\n",
      "\tspeed: 0.0176s/iter; left time: 24.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0727029 Vali Loss: 0.0865522 Test Loss: 0.0888920\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720799\n",
      "\tspeed: 0.0370s/iter; left time: 46.0796s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687887\n",
      "\tspeed: 0.0176s/iter; left time: 20.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0724657 Vali Loss: 0.0861464 Test Loss: 0.0884602\n",
      "Validation loss decreased (0.086306 --> 0.086146).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0697779\n",
      "\tspeed: 0.0374s/iter; left time: 38.1614s\n",
      "\titers: 200, epoch: 16 | loss: 0.0776083\n",
      "\tspeed: 0.0176s/iter; left time: 16.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0722829 Vali Loss: 0.0861370 Test Loss: 0.0884659\n",
      "Validation loss decreased (0.086146 --> 0.086137).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0755604\n",
      "\tspeed: 0.0385s/iter; left time: 30.6520s\n",
      "\titers: 200, epoch: 17 | loss: 0.0652553\n",
      "\tspeed: 0.0176s/iter; left time: 12.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0720857 Vali Loss: 0.0861050 Test Loss: 0.0884551\n",
      "Validation loss decreased (0.086137 --> 0.086105).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0759788\n",
      "\tspeed: 0.0374s/iter; left time: 21.4187s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702495\n",
      "\tspeed: 0.0173s/iter; left time: 8.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0719627 Vali Loss: 0.0861501 Test Loss: 0.0885607\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0757058\n",
      "\tspeed: 0.0367s/iter; left time: 12.8078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721789\n",
      "\tspeed: 0.0175s/iter; left time: 4.3465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0718498 Vali Loss: 0.0861521 Test Loss: 0.0884756\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717254\n",
      "\tspeed: 0.0365s/iter; left time: 4.5626s\n",
      "\titers: 200, epoch: 20 | loss: 0.0702315\n",
      "\tspeed: 0.0178s/iter; left time: 0.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0717969 Vali Loss: 0.0858329 Test Loss: 0.0882293\n",
      "Validation loss decreased (0.086105 --> 0.085833).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02107721008360386, rmse:0.14517992734909058, mae:0.08822928369045258, rse:0.5123600363731384\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:49.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1619344\n",
      "\tspeed: 0.0377s/iter; left time: 164.9479s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504099\n",
      "\tspeed: 0.0174s/iter; left time: 74.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1589250 Vali Loss: 0.1489491 Test Loss: 0.1608326\n",
      "Validation loss decreased (inf --> 0.148949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089703\n",
      "\tspeed: 0.0377s/iter; left time: 156.8415s\n",
      "\titers: 200, epoch: 2 | loss: 0.1149744\n",
      "\tspeed: 0.0174s/iter; left time: 70.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1169351 Vali Loss: 0.1223615 Test Loss: 0.1302950\n",
      "Validation loss decreased (0.148949 --> 0.122361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056557\n",
      "\tspeed: 0.0387s/iter; left time: 152.0560s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986517\n",
      "\tspeed: 0.0174s/iter; left time: 66.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1074685 Vali Loss: 0.1198070 Test Loss: 0.1282619\n",
      "Validation loss decreased (0.122361 --> 0.119807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025510\n",
      "\tspeed: 0.0376s/iter; left time: 139.5475s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046377\n",
      "\tspeed: 0.0174s/iter; left time: 62.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1054033 Vali Loss: 0.1191063 Test Loss: 0.1278673\n",
      "Validation loss decreased (0.119807 --> 0.119106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1038417\n",
      "\tspeed: 0.0376s/iter; left time: 131.0251s\n",
      "\titers: 200, epoch: 5 | loss: 0.1063736\n",
      "\tspeed: 0.0174s/iter; left time: 59.0648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1040633 Vali Loss: 0.1187290 Test Loss: 0.1275928\n",
      "Validation loss decreased (0.119106 --> 0.118729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1033758\n",
      "\tspeed: 0.0385s/iter; left time: 125.6103s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998508\n",
      "\tspeed: 0.0175s/iter; left time: 55.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1030631 Vali Loss: 0.1175519 Test Loss: 0.1267884\n",
      "Validation loss decreased (0.118729 --> 0.117552).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0990547\n",
      "\tspeed: 0.0379s/iter; left time: 115.2469s\n",
      "\titers: 200, epoch: 7 | loss: 0.1022646\n",
      "\tspeed: 0.0175s/iter; left time: 51.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1023639 Vali Loss: 0.1179993 Test Loss: 0.1276480\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988650\n",
      "\tspeed: 0.0375s/iter; left time: 105.5605s\n",
      "\titers: 200, epoch: 8 | loss: 0.1039498\n",
      "\tspeed: 0.0174s/iter; left time: 47.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1016782 Vali Loss: 0.1179397 Test Loss: 0.1280137\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008036\n",
      "\tspeed: 0.0376s/iter; left time: 97.4247s\n",
      "\titers: 200, epoch: 9 | loss: 0.1005208\n",
      "\tspeed: 0.0174s/iter; left time: 43.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1010756 Vali Loss: 0.1179529 Test Loss: 0.1277854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0970302\n",
      "\tspeed: 0.0376s/iter; left time: 88.9268s\n",
      "\titers: 200, epoch: 10 | loss: 0.0986957\n",
      "\tspeed: 0.0174s/iter; left time: 39.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1004807 Vali Loss: 0.1180902 Test Loss: 0.1278614\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994967\n",
      "\tspeed: 0.0380s/iter; left time: 81.2950s\n",
      "\titers: 200, epoch: 11 | loss: 0.1038442\n",
      "\tspeed: 0.0174s/iter; left time: 35.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1000124 Vali Loss: 0.1173964 Test Loss: 0.1274240\n",
      "Validation loss decreased (0.117552 --> 0.117396).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996821\n",
      "\tspeed: 0.0376s/iter; left time: 72.1304s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990979\n",
      "\tspeed: 0.0174s/iter; left time: 31.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0994957 Vali Loss: 0.1176490 Test Loss: 0.1276904\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1023465\n",
      "\tspeed: 0.0376s/iter; left time: 63.5964s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957390\n",
      "\tspeed: 0.0175s/iter; left time: 27.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0990532 Vali Loss: 0.1175529 Test Loss: 0.1279353\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013488\n",
      "\tspeed: 0.0372s/iter; left time: 54.6649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959193\n",
      "\tspeed: 0.0175s/iter; left time: 23.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0987154 Vali Loss: 0.1176766 Test Loss: 0.1277661\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0998006\n",
      "\tspeed: 0.0372s/iter; left time: 46.2830s\n",
      "\titers: 200, epoch: 15 | loss: 0.1027932\n",
      "\tspeed: 0.0176s/iter; left time: 20.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0982760 Vali Loss: 0.1177681 Test Loss: 0.1287941\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000815\n",
      "\tspeed: 0.0381s/iter; left time: 38.8788s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991594\n",
      "\tspeed: 0.0174s/iter; left time: 15.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0979667 Vali Loss: 0.1176327 Test Loss: 0.1287536\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03713487833738327, rmse:0.19270412623882294, mae:0.12742400169372559, rse:0.6824042201042175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1629421\n",
      "\tspeed: 0.0194s/iter; left time: 85.0090s\n",
      "\titers: 200, epoch: 1 | loss: 0.1449223\n",
      "\tspeed: 0.0174s/iter; left time: 74.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1604962 Vali Loss: 0.1499582 Test Loss: 0.1620217\n",
      "Validation loss decreased (inf --> 0.149958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091688\n",
      "\tspeed: 0.0389s/iter; left time: 161.5524s\n",
      "\titers: 200, epoch: 2 | loss: 0.1061413\n",
      "\tspeed: 0.0174s/iter; left time: 70.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1169925 Vali Loss: 0.1220629 Test Loss: 0.1303540\n",
      "Validation loss decreased (0.149958 --> 0.122063).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1125579\n",
      "\tspeed: 0.0388s/iter; left time: 152.6543s\n",
      "\titers: 200, epoch: 3 | loss: 0.1056803\n",
      "\tspeed: 0.0174s/iter; left time: 66.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1075579 Vali Loss: 0.1201527 Test Loss: 0.1298505\n",
      "Validation loss decreased (0.122063 --> 0.120153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016130\n",
      "\tspeed: 0.0382s/iter; left time: 141.8455s\n",
      "\titers: 200, epoch: 4 | loss: 0.1063603\n",
      "\tspeed: 0.0174s/iter; left time: 62.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1053327 Vali Loss: 0.1193292 Test Loss: 0.1300284\n",
      "Validation loss decreased (0.120153 --> 0.119329).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1039883\n",
      "\tspeed: 0.0384s/iter; left time: 133.8520s\n",
      "\titers: 200, epoch: 5 | loss: 0.1141819\n",
      "\tspeed: 0.0174s/iter; left time: 59.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1039553 Vali Loss: 0.1187222 Test Loss: 0.1288536\n",
      "Validation loss decreased (0.119329 --> 0.118722).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036907\n",
      "\tspeed: 0.0381s/iter; left time: 124.2237s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987412\n",
      "\tspeed: 0.0174s/iter; left time: 55.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1029148 Vali Loss: 0.1181296 Test Loss: 0.1285886\n",
      "Validation loss decreased (0.118722 --> 0.118130).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0984505\n",
      "\tspeed: 0.0382s/iter; left time: 115.9160s\n",
      "\titers: 200, epoch: 7 | loss: 0.1076829\n",
      "\tspeed: 0.0175s/iter; left time: 51.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1020770 Vali Loss: 0.1182825 Test Loss: 0.1284680\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1005999\n",
      "\tspeed: 0.0377s/iter; left time: 105.9937s\n",
      "\titers: 200, epoch: 8 | loss: 0.1040235\n",
      "\tspeed: 0.0174s/iter; left time: 47.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1012994 Vali Loss: 0.1186805 Test Loss: 0.1291316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027327\n",
      "\tspeed: 0.0383s/iter; left time: 99.1656s\n",
      "\titers: 200, epoch: 9 | loss: 0.1049346\n",
      "\tspeed: 0.0174s/iter; left time: 43.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1006749 Vali Loss: 0.1181007 Test Loss: 0.1283150\n",
      "Validation loss decreased (0.118130 --> 0.118101).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0991371\n",
      "\tspeed: 0.0401s/iter; left time: 94.9165s\n",
      "\titers: 200, epoch: 10 | loss: 0.0956333\n",
      "\tspeed: 0.0174s/iter; left time: 39.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0999219 Vali Loss: 0.1180787 Test Loss: 0.1285358\n",
      "Validation loss decreased (0.118101 --> 0.118079).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0958790\n",
      "\tspeed: 0.0379s/iter; left time: 81.1053s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004438\n",
      "\tspeed: 0.0176s/iter; left time: 35.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0994439 Vali Loss: 0.1180479 Test Loss: 0.1286640\n",
      "Validation loss decreased (0.118079 --> 0.118048).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1038648\n",
      "\tspeed: 0.0378s/iter; left time: 72.3786s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940785\n",
      "\tspeed: 0.0174s/iter; left time: 31.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0988478 Vali Loss: 0.1186219 Test Loss: 0.1295672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0929158\n",
      "\tspeed: 0.0373s/iter; left time: 63.1928s\n",
      "\titers: 200, epoch: 13 | loss: 0.1013541\n",
      "\tspeed: 0.0174s/iter; left time: 27.7130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0983381 Vali Loss: 0.1181220 Test Loss: 0.1292001\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0962316\n",
      "\tspeed: 0.0384s/iter; left time: 56.4344s\n",
      "\titers: 200, epoch: 14 | loss: 0.0996268\n",
      "\tspeed: 0.0176s/iter; left time: 24.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0979179 Vali Loss: 0.1186127 Test Loss: 0.1297009\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0958015\n",
      "\tspeed: 0.0395s/iter; left time: 49.1659s\n",
      "\titers: 200, epoch: 15 | loss: 0.0987199\n",
      "\tspeed: 0.0175s/iter; left time: 20.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0975216 Vali Loss: 0.1186228 Test Loss: 0.1295691\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0936652\n",
      "\tspeed: 0.0388s/iter; left time: 39.6273s\n",
      "\titers: 200, epoch: 16 | loss: 0.0967917\n",
      "\tspeed: 0.0176s/iter; left time: 16.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0971746 Vali Loss: 0.1185344 Test Loss: 0.1296407\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03818440064787865, rmse:0.19540829956531525, mae:0.1286640465259552, rse:0.6919803023338318\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:08.50s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1628355\n",
      "\tspeed: 0.0386s/iter; left time: 168.5114s\n",
      "\titers: 200, epoch: 1 | loss: 0.1461226\n",
      "\tspeed: 0.0176s/iter; left time: 75.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1605776 Vali Loss: 0.1508951 Test Loss: 0.1630175\n",
      "Validation loss decreased (inf --> 0.150895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295495\n",
      "\tspeed: 0.0384s/iter; left time: 158.9452s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168577\n",
      "\tspeed: 0.0176s/iter; left time: 71.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1227509 Vali Loss: 0.1269903 Test Loss: 0.1363985\n",
      "Validation loss decreased (0.150895 --> 0.126990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139878\n",
      "\tspeed: 0.0411s/iter; left time: 160.8091s\n",
      "\titers: 200, epoch: 3 | loss: 0.1160950\n",
      "\tspeed: 0.0177s/iter; left time: 67.4128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1136342 Vali Loss: 0.1248411 Test Loss: 0.1347367\n",
      "Validation loss decreased (0.126990 --> 0.124841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1093246\n",
      "\tspeed: 0.0387s/iter; left time: 142.7660s\n",
      "\titers: 200, epoch: 4 | loss: 0.1123354\n",
      "\tspeed: 0.0176s/iter; left time: 63.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1113418 Vali Loss: 0.1242843 Test Loss: 0.1348724\n",
      "Validation loss decreased (0.124841 --> 0.124284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121740\n",
      "\tspeed: 0.0382s/iter; left time: 132.6832s\n",
      "\titers: 200, epoch: 5 | loss: 0.1110278\n",
      "\tspeed: 0.0176s/iter; left time: 59.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1099283 Vali Loss: 0.1237305 Test Loss: 0.1349811\n",
      "Validation loss decreased (0.124284 --> 0.123731).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062920\n",
      "\tspeed: 0.0392s/iter; left time: 127.2175s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049748\n",
      "\tspeed: 0.0177s/iter; left time: 55.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1088134 Vali Loss: 0.1234774 Test Loss: 0.1352224\n",
      "Validation loss decreased (0.123731 --> 0.123477).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020317\n",
      "\tspeed: 0.0391s/iter; left time: 118.2618s\n",
      "\titers: 200, epoch: 7 | loss: 0.1096161\n",
      "\tspeed: 0.0176s/iter; left time: 51.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1079568 Vali Loss: 0.1236840 Test Loss: 0.1353464\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1095021\n",
      "\tspeed: 0.0380s/iter; left time: 106.4613s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080197\n",
      "\tspeed: 0.0177s/iter; left time: 47.7045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1071359 Vali Loss: 0.1236301 Test Loss: 0.1354977\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036291\n",
      "\tspeed: 0.0381s/iter; left time: 98.2305s\n",
      "\titers: 200, epoch: 9 | loss: 0.1095203\n",
      "\tspeed: 0.0176s/iter; left time: 43.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1063827 Vali Loss: 0.1240077 Test Loss: 0.1362663\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034006\n",
      "\tspeed: 0.0383s/iter; left time: 90.2585s\n",
      "\titers: 200, epoch: 10 | loss: 0.1180468\n",
      "\tspeed: 0.0176s/iter; left time: 39.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1057231 Vali Loss: 0.1239120 Test Loss: 0.1363678\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1066202\n",
      "\tspeed: 0.0376s/iter; left time: 80.0861s\n",
      "\titers: 200, epoch: 11 | loss: 0.1106018\n",
      "\tspeed: 0.0177s/iter; left time: 35.9707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1050407 Vali Loss: 0.1239418 Test Loss: 0.1362969\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039771974086761475, rmse:0.19942912459373474, mae:0.13522249460220337, rse:0.7063939571380615\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1551516\n",
      "\tspeed: 0.0200s/iter; left time: 87.1928s\n",
      "\titers: 200, epoch: 1 | loss: 0.1452319\n",
      "\tspeed: 0.0176s/iter; left time: 74.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1597897 Vali Loss: 0.1508700 Test Loss: 0.1624745\n",
      "Validation loss decreased (inf --> 0.150870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205210\n",
      "\tspeed: 0.0424s/iter; left time: 175.3020s\n",
      "\titers: 200, epoch: 2 | loss: 0.1155377\n",
      "\tspeed: 0.0176s/iter; left time: 71.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1224981 Vali Loss: 0.1261784 Test Loss: 0.1358866\n",
      "Validation loss decreased (0.150870 --> 0.126178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1154976\n",
      "\tspeed: 0.0392s/iter; left time: 153.5256s\n",
      "\titers: 200, epoch: 3 | loss: 0.1205826\n",
      "\tspeed: 0.0176s/iter; left time: 67.0342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1134431 Vali Loss: 0.1243780 Test Loss: 0.1350724\n",
      "Validation loss decreased (0.126178 --> 0.124378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1084444\n",
      "\tspeed: 0.0389s/iter; left time: 143.5099s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114469\n",
      "\tspeed: 0.0175s/iter; left time: 62.9946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1111445 Vali Loss: 0.1237809 Test Loss: 0.1348892\n",
      "Validation loss decreased (0.124378 --> 0.123781).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1089066\n",
      "\tspeed: 0.0398s/iter; left time: 138.0498s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137042\n",
      "\tspeed: 0.0176s/iter; left time: 59.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1096994 Vali Loss: 0.1238349 Test Loss: 0.1351202\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1059890\n",
      "\tspeed: 0.0380s/iter; left time: 123.4960s\n",
      "\titers: 200, epoch: 6 | loss: 0.1077313\n",
      "\tspeed: 0.0176s/iter; left time: 55.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1085598 Vali Loss: 0.1238074 Test Loss: 0.1351869\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061355\n",
      "\tspeed: 0.0381s/iter; left time: 115.0556s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075903\n",
      "\tspeed: 0.0176s/iter; left time: 51.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1075068 Vali Loss: 0.1243649 Test Loss: 0.1356606\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1056887\n",
      "\tspeed: 0.0385s/iter; left time: 107.8338s\n",
      "\titers: 200, epoch: 8 | loss: 0.1032582\n",
      "\tspeed: 0.0176s/iter; left time: 47.5355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1067399 Vali Loss: 0.1240940 Test Loss: 0.1352382\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1021452\n",
      "\tspeed: 0.0384s/iter; left time: 98.8739s\n",
      "\titers: 200, epoch: 9 | loss: 0.1055389\n",
      "\tspeed: 0.0176s/iter; left time: 43.5374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1058441 Vali Loss: 0.1242146 Test Loss: 0.1354213\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03952934965491295, rmse:0.19881989061832428, mae:0.13488918542861938, rse:0.7042360901832581\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:05.79s\n",
      "Intermediate time for DE: 00h:09m:03.76s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1414340\n",
      "\tspeed: 0.0376s/iter; left time: 164.6216s\n",
      "\titers: 200, epoch: 1 | loss: 0.1221013\n",
      "\tspeed: 0.0173s/iter; left time: 73.8638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1394487 Vali Loss: 0.1303349 Test Loss: 0.1521696\n",
      "Validation loss decreased (inf --> 0.130335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0840514\n",
      "\tspeed: 0.0370s/iter; left time: 153.7809s\n",
      "\titers: 200, epoch: 2 | loss: 0.0808714\n",
      "\tspeed: 0.0172s/iter; left time: 69.5860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0883156 Vali Loss: 0.0921759 Test Loss: 0.1036873\n",
      "Validation loss decreased (0.130335 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803500\n",
      "\tspeed: 0.0367s/iter; left time: 144.4488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805062\n",
      "\tspeed: 0.0171s/iter; left time: 65.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0800184 Vali Loss: 0.0905325 Test Loss: 0.1025728\n",
      "Validation loss decreased (0.092176 --> 0.090532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798231\n",
      "\tspeed: 0.0370s/iter; left time: 137.3117s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777466\n",
      "\tspeed: 0.0172s/iter; left time: 61.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0784797 Vali Loss: 0.0899157 Test Loss: 0.1023136\n",
      "Validation loss decreased (0.090532 --> 0.089916).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795304\n",
      "\tspeed: 0.0367s/iter; left time: 127.8021s\n",
      "\titers: 200, epoch: 5 | loss: 0.0756811\n",
      "\tspeed: 0.0172s/iter; left time: 58.2482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0774861 Vali Loss: 0.0895856 Test Loss: 0.1022673\n",
      "Validation loss decreased (0.089916 --> 0.089586).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0745707\n",
      "\tspeed: 0.0361s/iter; left time: 117.8830s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718807\n",
      "\tspeed: 0.0172s/iter; left time: 54.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0767927 Vali Loss: 0.0892474 Test Loss: 0.1016225\n",
      "Validation loss decreased (0.089586 --> 0.089247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763125\n",
      "\tspeed: 0.0362s/iter; left time: 109.9274s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761305\n",
      "\tspeed: 0.0171s/iter; left time: 50.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0762174 Vali Loss: 0.0889595 Test Loss: 0.1021078\n",
      "Validation loss decreased (0.089247 --> 0.088960).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740032\n",
      "\tspeed: 0.0380s/iter; left time: 106.7556s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748307\n",
      "\tspeed: 0.0172s/iter; left time: 46.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0758005 Vali Loss: 0.0888929 Test Loss: 0.1011652\n",
      "Validation loss decreased (0.088960 --> 0.088893).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0772215\n",
      "\tspeed: 0.0359s/iter; left time: 93.0665s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779016\n",
      "\tspeed: 0.0172s/iter; left time: 42.6890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0754587 Vali Loss: 0.0887787 Test Loss: 0.1017626\n",
      "Validation loss decreased (0.088893 --> 0.088779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781136\n",
      "\tspeed: 0.0369s/iter; left time: 87.1581s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792562\n",
      "\tspeed: 0.0172s/iter; left time: 38.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0750786 Vali Loss: 0.0883456 Test Loss: 0.1013593\n",
      "Validation loss decreased (0.088779 --> 0.088346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0763240\n",
      "\tspeed: 0.0362s/iter; left time: 77.4065s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766105\n",
      "\tspeed: 0.0172s/iter; left time: 35.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0748253 Vali Loss: 0.0884376 Test Loss: 0.1009040\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720343\n",
      "\tspeed: 0.0368s/iter; left time: 70.5606s\n",
      "\titers: 200, epoch: 12 | loss: 0.0749820\n",
      "\tspeed: 0.0171s/iter; left time: 31.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0745866 Vali Loss: 0.0884318 Test Loss: 0.1014207\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764522\n",
      "\tspeed: 0.0362s/iter; left time: 61.2742s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720733\n",
      "\tspeed: 0.0171s/iter; left time: 27.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0743763 Vali Loss: 0.0881860 Test Loss: 0.1007518\n",
      "Validation loss decreased (0.088346 --> 0.088186).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0781043\n",
      "\tspeed: 0.0375s/iter; left time: 55.1082s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749587\n",
      "\tspeed: 0.0172s/iter; left time: 23.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0742807 Vali Loss: 0.0881734 Test Loss: 0.1011914\n",
      "Validation loss decreased (0.088186 --> 0.088173).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0691805\n",
      "\tspeed: 0.0368s/iter; left time: 45.8291s\n",
      "\titers: 200, epoch: 15 | loss: 0.0790325\n",
      "\tspeed: 0.0172s/iter; left time: 19.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0741194 Vali Loss: 0.0882669 Test Loss: 0.1008864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723666\n",
      "\tspeed: 0.0362s/iter; left time: 36.9924s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744868\n",
      "\tspeed: 0.0172s/iter; left time: 15.8018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0739220 Vali Loss: 0.0880005 Test Loss: 0.1011248\n",
      "Validation loss decreased (0.088173 --> 0.088000).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0806842\n",
      "\tspeed: 0.0366s/iter; left time: 29.1805s\n",
      "\titers: 200, epoch: 17 | loss: 0.0699300\n",
      "\tspeed: 0.0172s/iter; left time: 11.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0737822 Vali Loss: 0.0880966 Test Loss: 0.1010500\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789800\n",
      "\tspeed: 0.0358s/iter; left time: 20.5026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703603\n",
      "\tspeed: 0.0171s/iter; left time: 8.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0736363 Vali Loss: 0.0880285 Test Loss: 0.1005919\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718165\n",
      "\tspeed: 0.0362s/iter; left time: 12.6340s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751730\n",
      "\tspeed: 0.0172s/iter; left time: 4.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0735602 Vali Loss: 0.0878067 Test Loss: 0.1006212\n",
      "Validation loss decreased (0.088000 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748918\n",
      "\tspeed: 0.0368s/iter; left time: 4.6028s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692953\n",
      "\tspeed: 0.0171s/iter; left time: 0.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734651 Vali Loss: 0.0879854 Test Loss: 0.1006300\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025700200349092484, rmse:0.16031281650066376, mae:0.10062122344970703, rse:0.5530337691307068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1422009\n",
      "\tspeed: 0.0191s/iter; left time: 83.5473s\n",
      "\titers: 200, epoch: 1 | loss: 0.1200285\n",
      "\tspeed: 0.0171s/iter; left time: 73.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.1414123 Vali Loss: 0.1313294 Test Loss: 0.1529285\n",
      "Validation loss decreased (inf --> 0.131329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922377\n",
      "\tspeed: 0.0372s/iter; left time: 154.4811s\n",
      "\titers: 200, epoch: 2 | loss: 0.0919798\n",
      "\tspeed: 0.0173s/iter; left time: 70.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0886869 Vali Loss: 0.0919450 Test Loss: 0.1033028\n",
      "Validation loss decreased (0.131329 --> 0.091945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0748871\n",
      "\tspeed: 0.0362s/iter; left time: 142.5595s\n",
      "\titers: 200, epoch: 3 | loss: 0.0777108\n",
      "\tspeed: 0.0171s/iter; left time: 65.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0799962 Vali Loss: 0.0908523 Test Loss: 0.1022962\n",
      "Validation loss decreased (0.091945 --> 0.090852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786184\n",
      "\tspeed: 0.0363s/iter; left time: 134.6324s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803857\n",
      "\tspeed: 0.0172s/iter; left time: 61.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0784213 Vali Loss: 0.0900642 Test Loss: 0.1022148\n",
      "Validation loss decreased (0.090852 --> 0.090064).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0738037\n",
      "\tspeed: 0.0362s/iter; left time: 126.0584s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784855\n",
      "\tspeed: 0.0171s/iter; left time: 58.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0774722 Vali Loss: 0.0897736 Test Loss: 0.1024334\n",
      "Validation loss decreased (0.090064 --> 0.089774).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0762075\n",
      "\tspeed: 0.0361s/iter; left time: 117.7522s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760078\n",
      "\tspeed: 0.0172s/iter; left time: 54.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0767708 Vali Loss: 0.0894914 Test Loss: 0.1016460\n",
      "Validation loss decreased (0.089774 --> 0.089491).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769813\n",
      "\tspeed: 0.0367s/iter; left time: 111.4068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0738989\n",
      "\tspeed: 0.0172s/iter; left time: 50.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0761804 Vali Loss: 0.0888315 Test Loss: 0.1016231\n",
      "Validation loss decreased (0.089491 --> 0.088831).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770518\n",
      "\tspeed: 0.0362s/iter; left time: 101.9397s\n",
      "\titers: 200, epoch: 8 | loss: 0.0699307\n",
      "\tspeed: 0.0172s/iter; left time: 46.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0757875 Vali Loss: 0.0889037 Test Loss: 0.1016399\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742829\n",
      "\tspeed: 0.0357s/iter; left time: 92.4262s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798777\n",
      "\tspeed: 0.0171s/iter; left time: 42.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0754156 Vali Loss: 0.0887733 Test Loss: 0.1010946\n",
      "Validation loss decreased (0.088831 --> 0.088773).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0693498\n",
      "\tspeed: 0.0359s/iter; left time: 84.9851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0747973\n",
      "\tspeed: 0.0172s/iter; left time: 38.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0751455 Vali Loss: 0.0890305 Test Loss: 0.1011741\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0776062\n",
      "\tspeed: 0.0356s/iter; left time: 76.2751s\n",
      "\titers: 200, epoch: 11 | loss: 0.0710389\n",
      "\tspeed: 0.0172s/iter; left time: 35.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0748430 Vali Loss: 0.0885079 Test Loss: 0.1005311\n",
      "Validation loss decreased (0.088773 --> 0.088508).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774497\n",
      "\tspeed: 0.0362s/iter; left time: 69.4721s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763883\n",
      "\tspeed: 0.0172s/iter; left time: 31.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0746614 Vali Loss: 0.0886720 Test Loss: 0.1007122\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738585\n",
      "\tspeed: 0.0357s/iter; left time: 60.4062s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666320\n",
      "\tspeed: 0.0172s/iter; left time: 27.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0743507 Vali Loss: 0.0881569 Test Loss: 0.1011065\n",
      "Validation loss decreased (0.088508 --> 0.088157).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715535\n",
      "\tspeed: 0.0370s/iter; left time: 54.4190s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718102\n",
      "\tspeed: 0.0171s/iter; left time: 23.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0742120 Vali Loss: 0.0883131 Test Loss: 0.1009890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0764904\n",
      "\tspeed: 0.0359s/iter; left time: 44.6822s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760919\n",
      "\tspeed: 0.0171s/iter; left time: 19.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0740144 Vali Loss: 0.0880940 Test Loss: 0.1007358\n",
      "Validation loss decreased (0.088157 --> 0.088094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715841\n",
      "\tspeed: 0.0363s/iter; left time: 37.0853s\n",
      "\titers: 200, epoch: 16 | loss: 0.0754959\n",
      "\tspeed: 0.0171s/iter; left time: 15.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0738687 Vali Loss: 0.0881185 Test Loss: 0.1006489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0757043\n",
      "\tspeed: 0.0360s/iter; left time: 28.6693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0710046\n",
      "\tspeed: 0.0172s/iter; left time: 11.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0737722 Vali Loss: 0.0879211 Test Loss: 0.1009671\n",
      "Validation loss decreased (0.088094 --> 0.087921).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0715606\n",
      "\tspeed: 0.0361s/iter; left time: 20.6916s\n",
      "\titers: 200, epoch: 18 | loss: 0.0714183\n",
      "\tspeed: 0.0171s/iter; left time: 8.1036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0736600 Vali Loss: 0.0879440 Test Loss: 0.1007076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0691574\n",
      "\tspeed: 0.0358s/iter; left time: 12.4911s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773228\n",
      "\tspeed: 0.0172s/iter; left time: 4.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0735008 Vali Loss: 0.0879841 Test Loss: 0.1003970\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747810\n",
      "\tspeed: 0.0360s/iter; left time: 4.5033s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733762\n",
      "\tspeed: 0.0172s/iter; left time: 0.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734122 Vali Loss: 0.0880092 Test Loss: 0.1003906\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02568984590470791, rmse:0.1602805256843567, mae:0.10096710920333862, rse:0.5529223680496216\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:44.17s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1466275\n",
      "\tspeed: 0.0390s/iter; left time: 170.6765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1337850\n",
      "\tspeed: 0.0177s/iter; left time: 75.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1435828 Vali Loss: 0.1385492 Test Loss: 0.1633576\n",
      "Validation loss decreased (inf --> 0.138549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1104258\n",
      "\tspeed: 0.0380s/iter; left time: 157.9074s\n",
      "\titers: 200, epoch: 2 | loss: 0.1112381\n",
      "\tspeed: 0.0175s/iter; left time: 71.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1108078 Vali Loss: 0.1185432 Test Loss: 0.1400204\n",
      "Validation loss decreased (0.138549 --> 0.118543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055267\n",
      "\tspeed: 0.0388s/iter; left time: 152.7872s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024510\n",
      "\tspeed: 0.0175s/iter; left time: 67.1051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1047173 Vali Loss: 0.1173792 Test Loss: 0.1411833\n",
      "Validation loss decreased (0.118543 --> 0.117379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1010584\n",
      "\tspeed: 0.0386s/iter; left time: 143.2510s\n",
      "\titers: 200, epoch: 4 | loss: 0.1023916\n",
      "\tspeed: 0.0176s/iter; left time: 63.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1031035 Vali Loss: 0.1173137 Test Loss: 0.1412240\n",
      "Validation loss decreased (0.117379 --> 0.117314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018159\n",
      "\tspeed: 0.0397s/iter; left time: 138.2124s\n",
      "\titers: 200, epoch: 5 | loss: 0.1006902\n",
      "\tspeed: 0.0175s/iter; left time: 59.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1020479 Vali Loss: 0.1172939 Test Loss: 0.1422832\n",
      "Validation loss decreased (0.117314 --> 0.117294).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1007758\n",
      "\tspeed: 0.0389s/iter; left time: 126.8225s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994306\n",
      "\tspeed: 0.0174s/iter; left time: 55.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1009951 Vali Loss: 0.1164035 Test Loss: 0.1401911\n",
      "Validation loss decreased (0.117294 --> 0.116403).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036470\n",
      "\tspeed: 0.0379s/iter; left time: 115.1075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978406\n",
      "\tspeed: 0.0176s/iter; left time: 51.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1001050 Vali Loss: 0.1163152 Test Loss: 0.1423407\n",
      "Validation loss decreased (0.116403 --> 0.116315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0974191\n",
      "\tspeed: 0.0380s/iter; left time: 106.9084s\n",
      "\titers: 200, epoch: 8 | loss: 0.1014476\n",
      "\tspeed: 0.0175s/iter; left time: 47.5436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0992137 Vali Loss: 0.1164122 Test Loss: 0.1430775\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0985387\n",
      "\tspeed: 0.0375s/iter; left time: 97.0764s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965922\n",
      "\tspeed: 0.0172s/iter; left time: 42.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0984681 Vali Loss: 0.1171481 Test Loss: 0.1426953\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0963279\n",
      "\tspeed: 0.0383s/iter; left time: 90.5825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998888\n",
      "\tspeed: 0.0175s/iter; left time: 39.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0978281 Vali Loss: 0.1175429 Test Loss: 0.1437618\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0968340\n",
      "\tspeed: 0.0386s/iter; left time: 82.7142s\n",
      "\titers: 200, epoch: 11 | loss: 0.1017763\n",
      "\tspeed: 0.0176s/iter; left time: 36.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0972433 Vali Loss: 0.1171132 Test Loss: 0.1428917\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0951716\n",
      "\tspeed: 0.0381s/iter; left time: 73.0416s\n",
      "\titers: 200, epoch: 12 | loss: 0.0948278\n",
      "\tspeed: 0.0177s/iter; left time: 32.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0967977 Vali Loss: 0.1174284 Test Loss: 0.1440489\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043783560395240784, rmse:0.2092452198266983, mae:0.14234068989753723, rse:0.7235991358757019\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1440759\n",
      "\tspeed: 0.0204s/iter; left time: 89.3097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1328751\n",
      "\tspeed: 0.0175s/iter; left time: 75.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1449540 Vali Loss: 0.1393136 Test Loss: 0.1642298\n",
      "Validation loss decreased (inf --> 0.139314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1102223\n",
      "\tspeed: 0.0397s/iter; left time: 165.1439s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079791\n",
      "\tspeed: 0.0176s/iter; left time: 71.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1110439 Vali Loss: 0.1183170 Test Loss: 0.1403053\n",
      "Validation loss decreased (0.139314 --> 0.118317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1059737\n",
      "\tspeed: 0.0393s/iter; left time: 154.4078s\n",
      "\titers: 200, epoch: 3 | loss: 0.1034809\n",
      "\tspeed: 0.0176s/iter; left time: 67.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.1046243 Vali Loss: 0.1172979 Test Loss: 0.1405665\n",
      "Validation loss decreased (0.118317 --> 0.117298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1017363\n",
      "\tspeed: 0.0398s/iter; left time: 147.7825s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028161\n",
      "\tspeed: 0.0176s/iter; left time: 63.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1028885 Vali Loss: 0.1164917 Test Loss: 0.1403750\n",
      "Validation loss decreased (0.117298 --> 0.116492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0997417\n",
      "\tspeed: 0.0474s/iter; left time: 165.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999667\n",
      "\tspeed: 0.0175s/iter; left time: 59.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.1016265 Vali Loss: 0.1166197 Test Loss: 0.1419718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1000853\n",
      "\tspeed: 0.0401s/iter; left time: 130.7600s\n",
      "\titers: 200, epoch: 6 | loss: 0.1028287\n",
      "\tspeed: 0.0175s/iter; left time: 55.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1004530 Vali Loss: 0.1165940 Test Loss: 0.1414203\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026894\n",
      "\tspeed: 0.0394s/iter; left time: 119.5488s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959040\n",
      "\tspeed: 0.0176s/iter; left time: 51.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0994967 Vali Loss: 0.1165230 Test Loss: 0.1413475\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995387\n",
      "\tspeed: 0.0387s/iter; left time: 108.9935s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041096\n",
      "\tspeed: 0.0176s/iter; left time: 47.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0985223 Vali Loss: 0.1168115 Test Loss: 0.1421495\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1005742\n",
      "\tspeed: 0.0387s/iter; left time: 100.1714s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009817\n",
      "\tspeed: 0.0176s/iter; left time: 43.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0977647 Vali Loss: 0.1178261 Test Loss: 0.1428408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04229957237839699, rmse:0.2056685984134674, mae:0.14037492871284485, rse:0.7112306952476501\n",
      "Intermediate time for GB and pred_len 96: 00h:02m:09.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1476450\n",
      "\tspeed: 0.0394s/iter; left time: 172.0233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1322379\n",
      "\tspeed: 0.0176s/iter; left time: 74.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1446634 Vali Loss: 0.1403988 Test Loss: 0.1657538\n",
      "Validation loss decreased (inf --> 0.140399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1181542\n",
      "\tspeed: 0.0387s/iter; left time: 160.1993s\n",
      "\titers: 200, epoch: 2 | loss: 0.1103590\n",
      "\tspeed: 0.0176s/iter; left time: 70.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1153974 Vali Loss: 0.1230213 Test Loss: 0.1469014\n",
      "Validation loss decreased (0.140399 --> 0.123021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1078933\n",
      "\tspeed: 0.0390s/iter; left time: 152.8634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1094684\n",
      "\tspeed: 0.0173s/iter; left time: 66.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1095194 Vali Loss: 0.1215952 Test Loss: 0.1471972\n",
      "Validation loss decreased (0.123021 --> 0.121595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068714\n",
      "\tspeed: 0.0400s/iter; left time: 147.6835s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091786\n",
      "\tspeed: 0.0175s/iter; left time: 62.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1077170 Vali Loss: 0.1219872 Test Loss: 0.1488043\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074749\n",
      "\tspeed: 0.0391s/iter; left time: 135.4877s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072562\n",
      "\tspeed: 0.0175s/iter; left time: 58.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1063439 Vali Loss: 0.1214106 Test Loss: 0.1474847\n",
      "Validation loss decreased (0.121595 --> 0.121411).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1031363\n",
      "\tspeed: 0.0404s/iter; left time: 131.2125s\n",
      "\titers: 200, epoch: 6 | loss: 0.1033070\n",
      "\tspeed: 0.0175s/iter; left time: 55.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1048237 Vali Loss: 0.1214159 Test Loss: 0.1477327\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015336\n",
      "\tspeed: 0.0395s/iter; left time: 119.3526s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040114\n",
      "\tspeed: 0.0180s/iter; left time: 52.5328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1036718 Vali Loss: 0.1211991 Test Loss: 0.1474411\n",
      "Validation loss decreased (0.121411 --> 0.121199).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045649\n",
      "\tspeed: 0.0402s/iter; left time: 112.6007s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997393\n",
      "\tspeed: 0.0180s/iter; left time: 48.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1027916 Vali Loss: 0.1215216 Test Loss: 0.1471704\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1015813\n",
      "\tspeed: 0.0397s/iter; left time: 102.4155s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016080\n",
      "\tspeed: 0.0176s/iter; left time: 43.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1020035 Vali Loss: 0.1216637 Test Loss: 0.1498252\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1022068\n",
      "\tspeed: 0.0382s/iter; left time: 90.0211s\n",
      "\titers: 200, epoch: 10 | loss: 0.1057559\n",
      "\tspeed: 0.0175s/iter; left time: 39.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1014043 Vali Loss: 0.1225466 Test Loss: 0.1508662\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1012574\n",
      "\tspeed: 0.0382s/iter; left time: 81.3747s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064127\n",
      "\tspeed: 0.0174s/iter; left time: 35.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1008412 Vali Loss: 0.1222213 Test Loss: 0.1478938\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0995592\n",
      "\tspeed: 0.0382s/iter; left time: 72.9362s\n",
      "\titers: 200, epoch: 12 | loss: 0.1017008\n",
      "\tspeed: 0.0177s/iter; left time: 31.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1004033 Vali Loss: 0.1223581 Test Loss: 0.1499430\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04548247531056404, rmse:0.21326620876789093, mae:0.14744102954864502, rse:0.7394245862960815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1443954\n",
      "\tspeed: 0.0199s/iter; left time: 86.6705s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329396\n",
      "\tspeed: 0.0174s/iter; left time: 74.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1444746 Vali Loss: 0.1397851 Test Loss: 0.1651123\n",
      "Validation loss decreased (inf --> 0.139785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1152997\n",
      "\tspeed: 0.0404s/iter; left time: 167.3385s\n",
      "\titers: 200, epoch: 2 | loss: 0.1154610\n",
      "\tspeed: 0.0180s/iter; left time: 72.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1152647 Vali Loss: 0.1229733 Test Loss: 0.1469299\n",
      "Validation loss decreased (0.139785 --> 0.122973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091522\n",
      "\tspeed: 0.0411s/iter; left time: 160.9824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1074008\n",
      "\tspeed: 0.0180s/iter; left time: 68.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.1093979 Vali Loss: 0.1222026 Test Loss: 0.1474644\n",
      "Validation loss decreased (0.122973 --> 0.122203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1105969\n",
      "\tspeed: 0.0395s/iter; left time: 145.6556s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092896\n",
      "\tspeed: 0.0174s/iter; left time: 62.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1075571 Vali Loss: 0.1213144 Test Loss: 0.1466673\n",
      "Validation loss decreased (0.122203 --> 0.121314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026646\n",
      "\tspeed: 0.0415s/iter; left time: 144.0521s\n",
      "\titers: 200, epoch: 5 | loss: 0.1054192\n",
      "\tspeed: 0.0174s/iter; left time: 58.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1060407 Vali Loss: 0.1211272 Test Loss: 0.1483335\n",
      "Validation loss decreased (0.121314 --> 0.121127).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1051621\n",
      "\tspeed: 0.0392s/iter; left time: 127.3985s\n",
      "\titers: 200, epoch: 6 | loss: 0.1033786\n",
      "\tspeed: 0.0177s/iter; left time: 55.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1045825 Vali Loss: 0.1220101 Test Loss: 0.1496769\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1046920\n",
      "\tspeed: 0.0399s/iter; left time: 120.5473s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026492\n",
      "\tspeed: 0.0179s/iter; left time: 52.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1035206 Vali Loss: 0.1215435 Test Loss: 0.1485344\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016812\n",
      "\tspeed: 0.0404s/iter; left time: 113.1318s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051641\n",
      "\tspeed: 0.0180s/iter; left time: 48.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.1025836 Vali Loss: 0.1214356 Test Loss: 0.1485675\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1025469\n",
      "\tspeed: 0.0402s/iter; left time: 103.7101s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990375\n",
      "\tspeed: 0.0179s/iter; left time: 44.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1018556 Vali Loss: 0.1213479 Test Loss: 0.1500267\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0973733\n",
      "\tspeed: 0.0400s/iter; left time: 94.2096s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971824\n",
      "\tspeed: 0.0176s/iter; left time: 39.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1011464 Vali Loss: 0.1214701 Test Loss: 0.1500645\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0455465130507946, rmse:0.21341629326343536, mae:0.14833343029022217, rse:0.7399449348449707\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:19.33s\n",
      "Intermediate time for GB: 00h:08m:13.48s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1494770\n",
      "\tspeed: 0.0317s/iter; left time: 139.0300s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274537\n",
      "\tspeed: 0.0114s/iter; left time: 48.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.1528605 Vali Loss: 0.1144877 Test Loss: 0.1285769\n",
      "Validation loss decreased (inf --> 0.114488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765437\n",
      "\tspeed: 0.0273s/iter; left time: 113.4174s\n",
      "\titers: 200, epoch: 2 | loss: 0.0665579\n",
      "\tspeed: 0.0114s/iter; left time: 46.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0811992 Vali Loss: 0.0652718 Test Loss: 0.0723863\n",
      "Validation loss decreased (0.114488 --> 0.065272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697450\n",
      "\tspeed: 0.0267s/iter; left time: 104.9098s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660162\n",
      "\tspeed: 0.0113s/iter; left time: 43.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0678131 Vali Loss: 0.0617073 Test Loss: 0.0685091\n",
      "Validation loss decreased (0.065272 --> 0.061707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611825\n",
      "\tspeed: 0.0267s/iter; left time: 99.2155s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663184\n",
      "\tspeed: 0.0113s/iter; left time: 40.8007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0643569 Vali Loss: 0.0592894 Test Loss: 0.0658884\n",
      "Validation loss decreased (0.061707 --> 0.059289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620450\n",
      "\tspeed: 0.0275s/iter; left time: 95.6716s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624085\n",
      "\tspeed: 0.0113s/iter; left time: 38.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0622190 Vali Loss: 0.0580893 Test Loss: 0.0645561\n",
      "Validation loss decreased (0.059289 --> 0.058089).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605343\n",
      "\tspeed: 0.0262s/iter; left time: 85.4232s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587551\n",
      "\tspeed: 0.0113s/iter; left time: 35.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0572285 Test Loss: 0.0637012\n",
      "Validation loss decreased (0.058089 --> 0.057228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607917\n",
      "\tspeed: 0.0276s/iter; left time: 83.8662s\n",
      "\titers: 200, epoch: 7 | loss: 0.0628559\n",
      "\tspeed: 0.0114s/iter; left time: 33.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0597911 Vali Loss: 0.0568611 Test Loss: 0.0632574\n",
      "Validation loss decreased (0.057228 --> 0.056861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585717\n",
      "\tspeed: 0.0273s/iter; left time: 76.7984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590016\n",
      "\tspeed: 0.0113s/iter; left time: 30.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0589440 Vali Loss: 0.0562228 Test Loss: 0.0624446\n",
      "Validation loss decreased (0.056861 --> 0.056223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570429\n",
      "\tspeed: 0.0273s/iter; left time: 70.6142s\n",
      "\titers: 200, epoch: 9 | loss: 0.0550695\n",
      "\tspeed: 0.0113s/iter; left time: 28.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0582554 Vali Loss: 0.0558884 Test Loss: 0.0622871\n",
      "Validation loss decreased (0.056223 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585720\n",
      "\tspeed: 0.0269s/iter; left time: 63.6232s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569206\n",
      "\tspeed: 0.0113s/iter; left time: 25.5959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0577634 Vali Loss: 0.0553971 Test Loss: 0.0617752\n",
      "Validation loss decreased (0.055888 --> 0.055397).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0591369\n",
      "\tspeed: 0.0270s/iter; left time: 57.7607s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592699\n",
      "\tspeed: 0.0112s/iter; left time: 22.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0572746 Vali Loss: 0.0550906 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.055397 --> 0.055091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0612531\n",
      "\tspeed: 0.0269s/iter; left time: 51.4909s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553235\n",
      "\tspeed: 0.0113s/iter; left time: 20.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0567800 Vali Loss: 0.0550882 Test Loss: 0.0614859\n",
      "Validation loss decreased (0.055091 --> 0.055088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0574471\n",
      "\tspeed: 0.0269s/iter; left time: 45.5146s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576361\n",
      "\tspeed: 0.0113s/iter; left time: 18.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0565321 Vali Loss: 0.0548449 Test Loss: 0.0614008\n",
      "Validation loss decreased (0.055088 --> 0.054845).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0557640\n",
      "\tspeed: 0.0269s/iter; left time: 39.4663s\n",
      "\titers: 200, epoch: 14 | loss: 0.0564044\n",
      "\tspeed: 0.0114s/iter; left time: 15.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0562479 Vali Loss: 0.0548242 Test Loss: 0.0611537\n",
      "Validation loss decreased (0.054845 --> 0.054824).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533020\n",
      "\tspeed: 0.0279s/iter; left time: 34.6767s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543857\n",
      "\tspeed: 0.0113s/iter; left time: 12.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0559401 Vali Loss: 0.0545402 Test Loss: 0.0610489\n",
      "Validation loss decreased (0.054824 --> 0.054540).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609088\n",
      "\tspeed: 0.0265s/iter; left time: 27.0094s\n",
      "\titers: 200, epoch: 16 | loss: 0.0545612\n",
      "\tspeed: 0.0113s/iter; left time: 10.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0558091 Vali Loss: 0.0543885 Test Loss: 0.0608586\n",
      "Validation loss decreased (0.054540 --> 0.054389).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537297\n",
      "\tspeed: 0.0274s/iter; left time: 21.8437s\n",
      "\titers: 200, epoch: 17 | loss: 0.0562503\n",
      "\tspeed: 0.0113s/iter; left time: 7.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0556262 Vali Loss: 0.0542731 Test Loss: 0.0607741\n",
      "Validation loss decreased (0.054389 --> 0.054273).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572393\n",
      "\tspeed: 0.0264s/iter; left time: 15.0990s\n",
      "\titers: 200, epoch: 18 | loss: 0.0538083\n",
      "\tspeed: 0.0113s/iter; left time: 5.3247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0553770 Vali Loss: 0.0542938 Test Loss: 0.0607562\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543686\n",
      "\tspeed: 0.0273s/iter; left time: 9.5140s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553563\n",
      "\tspeed: 0.0113s/iter; left time: 2.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0552918 Vali Loss: 0.0541263 Test Loss: 0.0606835\n",
      "Validation loss decreased (0.054273 --> 0.054126).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0580385\n",
      "\tspeed: 0.0267s/iter; left time: 3.3388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0506126\n",
      "\tspeed: 0.0113s/iter; left time: 0.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0551724 Vali Loss: 0.0539999 Test Loss: 0.0603945\n",
      "Validation loss decreased (0.054126 --> 0.054000).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009931187145411968, rmse:0.09965534508228302, mae:0.06039450317621231, rse:0.2932736277580261\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1556551\n",
      "\tspeed: 0.0137s/iter; left time: 60.0390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238871\n",
      "\tspeed: 0.0117s/iter; left time: 49.8921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.1551209 Vali Loss: 0.1149658 Test Loss: 0.1298747\n",
      "Validation loss decreased (inf --> 0.114966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784185\n",
      "\tspeed: 0.0280s/iter; left time: 116.3490s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682577\n",
      "\tspeed: 0.0113s/iter; left time: 45.9172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0810422 Vali Loss: 0.0650935 Test Loss: 0.0717688\n",
      "Validation loss decreased (0.114966 --> 0.065094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0690213\n",
      "\tspeed: 0.0269s/iter; left time: 105.8000s\n",
      "\titers: 200, epoch: 3 | loss: 0.0668357\n",
      "\tspeed: 0.0113s/iter; left time: 43.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0675884 Vali Loss: 0.0610957 Test Loss: 0.0677405\n",
      "Validation loss decreased (0.065094 --> 0.061096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637767\n",
      "\tspeed: 0.0262s/iter; left time: 97.1458s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622976\n",
      "\tspeed: 0.0113s/iter; left time: 40.8076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0641213 Vali Loss: 0.0590871 Test Loss: 0.0657832\n",
      "Validation loss decreased (0.061096 --> 0.059087).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0605592\n",
      "\tspeed: 0.0276s/iter; left time: 96.0129s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578117\n",
      "\tspeed: 0.0113s/iter; left time: 38.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0620087 Vali Loss: 0.0577362 Test Loss: 0.0641884\n",
      "Validation loss decreased (0.059087 --> 0.057736).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597171\n",
      "\tspeed: 0.0275s/iter; left time: 89.6045s\n",
      "\titers: 200, epoch: 6 | loss: 0.0631097\n",
      "\tspeed: 0.0114s/iter; left time: 35.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0605131 Vali Loss: 0.0567674 Test Loss: 0.0632716\n",
      "Validation loss decreased (0.057736 --> 0.056767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0600709\n",
      "\tspeed: 0.0267s/iter; left time: 80.9579s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558400\n",
      "\tspeed: 0.0113s/iter; left time: 33.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0593662 Vali Loss: 0.0560938 Test Loss: 0.0625260\n",
      "Validation loss decreased (0.056767 --> 0.056094).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591932\n",
      "\tspeed: 0.0267s/iter; left time: 75.0977s\n",
      "\titers: 200, epoch: 8 | loss: 0.0566134\n",
      "\tspeed: 0.0113s/iter; left time: 30.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0586497 Vali Loss: 0.0559053 Test Loss: 0.0623956\n",
      "Validation loss decreased (0.056094 --> 0.055905).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578017\n",
      "\tspeed: 0.0268s/iter; left time: 69.2913s\n",
      "\titers: 200, epoch: 9 | loss: 0.0608524\n",
      "\tspeed: 0.0113s/iter; left time: 28.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0579206 Vali Loss: 0.0554532 Test Loss: 0.0619622\n",
      "Validation loss decreased (0.055905 --> 0.055453).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0557183\n",
      "\tspeed: 0.0262s/iter; left time: 61.9002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0574988\n",
      "\tspeed: 0.0113s/iter; left time: 25.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0574463 Vali Loss: 0.0551643 Test Loss: 0.0615977\n",
      "Validation loss decreased (0.055453 --> 0.055164).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0562042\n",
      "\tspeed: 0.0261s/iter; left time: 55.8944s\n",
      "\titers: 200, epoch: 11 | loss: 0.0547854\n",
      "\tspeed: 0.0113s/iter; left time: 23.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0570041 Vali Loss: 0.0548636 Test Loss: 0.0612392\n",
      "Validation loss decreased (0.055164 --> 0.054864).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0536011\n",
      "\tspeed: 0.0262s/iter; left time: 50.2201s\n",
      "\titers: 200, epoch: 12 | loss: 0.0547583\n",
      "\tspeed: 0.0113s/iter; left time: 20.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0565564 Vali Loss: 0.0548057 Test Loss: 0.0613708\n",
      "Validation loss decreased (0.054864 --> 0.054806).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0538747\n",
      "\tspeed: 0.0261s/iter; left time: 44.2553s\n",
      "\titers: 200, epoch: 13 | loss: 0.0558614\n",
      "\tspeed: 0.0113s/iter; left time: 17.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0563296 Vali Loss: 0.0545942 Test Loss: 0.0609953\n",
      "Validation loss decreased (0.054806 --> 0.054594).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0570528\n",
      "\tspeed: 0.0271s/iter; left time: 39.8674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0539998\n",
      "\tspeed: 0.0113s/iter; left time: 15.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0560721 Vali Loss: 0.0545014 Test Loss: 0.0608965\n",
      "Validation loss decreased (0.054594 --> 0.054501).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0558659\n",
      "\tspeed: 0.0264s/iter; left time: 32.8463s\n",
      "\titers: 200, epoch: 15 | loss: 0.0555724\n",
      "\tspeed: 0.0113s/iter; left time: 12.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0558337 Vali Loss: 0.0543190 Test Loss: 0.0608781\n",
      "Validation loss decreased (0.054501 --> 0.054319).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0502567\n",
      "\tspeed: 0.0260s/iter; left time: 26.5949s\n",
      "\titers: 200, epoch: 16 | loss: 0.0585473\n",
      "\tspeed: 0.0113s/iter; left time: 10.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0555682 Vali Loss: 0.0541908 Test Loss: 0.0607273\n",
      "Validation loss decreased (0.054319 --> 0.054191).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571907\n",
      "\tspeed: 0.0260s/iter; left time: 20.7251s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549186\n",
      "\tspeed: 0.0113s/iter; left time: 7.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0554409 Vali Loss: 0.0539711 Test Loss: 0.0604676\n",
      "Validation loss decreased (0.054191 --> 0.053971).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570545\n",
      "\tspeed: 0.0277s/iter; left time: 15.8615s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563004\n",
      "\tspeed: 0.0113s/iter; left time: 5.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0552863 Vali Loss: 0.0539168 Test Loss: 0.0604286\n",
      "Validation loss decreased (0.053971 --> 0.053917).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0544547\n",
      "\tspeed: 0.0262s/iter; left time: 9.1362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538205\n",
      "\tspeed: 0.0113s/iter; left time: 2.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0550870 Vali Loss: 0.0540152 Test Loss: 0.0605182\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0500700\n",
      "\tspeed: 0.0262s/iter; left time: 3.2755s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550875\n",
      "\tspeed: 0.0113s/iter; left time: 0.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0549684 Vali Loss: 0.0539093 Test Loss: 0.0603909\n",
      "Validation loss decreased (0.053917 --> 0.053909).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009954366832971573, rmse:0.09977157413959503, mae:0.060390934348106384, rse:0.2936156690120697\n",
      "Intermediate time for ES and pred_len 24: 00h:02m:42.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600715\n",
      "\tspeed: 0.0319s/iter; left time: 139.9661s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329738\n",
      "\tspeed: 0.0115s/iter; left time: 49.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.1563259 Vali Loss: 0.1220047 Test Loss: 0.1377991\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986281\n",
      "\tspeed: 0.0278s/iter; left time: 115.5698s\n",
      "\titers: 200, epoch: 2 | loss: 0.0916502\n",
      "\tspeed: 0.0114s/iter; left time: 46.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0987325 Vali Loss: 0.0868770 Test Loss: 0.0978651\n",
      "Validation loss decreased (0.122005 --> 0.086877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870886\n",
      "\tspeed: 0.0284s/iter; left time: 111.5707s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855636\n",
      "\tspeed: 0.0115s/iter; left time: 43.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0874873 Vali Loss: 0.0815230 Test Loss: 0.0928167\n",
      "Validation loss decreased (0.086877 --> 0.081523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859502\n",
      "\tspeed: 0.0285s/iter; left time: 105.7301s\n",
      "\titers: 200, epoch: 4 | loss: 0.0796197\n",
      "\tspeed: 0.0115s/iter; left time: 41.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0837237 Vali Loss: 0.0794888 Test Loss: 0.0907266\n",
      "Validation loss decreased (0.081523 --> 0.079489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817280\n",
      "\tspeed: 0.0282s/iter; left time: 98.1448s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827391\n",
      "\tspeed: 0.0114s/iter; left time: 38.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0817404 Vali Loss: 0.0787186 Test Loss: 0.0896066\n",
      "Validation loss decreased (0.079489 --> 0.078719).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0804231\n",
      "\tspeed: 0.0281s/iter; left time: 91.4792s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756826\n",
      "\tspeed: 0.0115s/iter; left time: 36.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0802827 Vali Loss: 0.0777990 Test Loss: 0.0888387\n",
      "Validation loss decreased (0.078719 --> 0.077799).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785264\n",
      "\tspeed: 0.0282s/iter; left time: 85.7239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755876\n",
      "\tspeed: 0.0115s/iter; left time: 33.8616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0792729 Vali Loss: 0.0773480 Test Loss: 0.0884110\n",
      "Validation loss decreased (0.077799 --> 0.077348).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815148\n",
      "\tspeed: 0.0280s/iter; left time: 78.6349s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805861\n",
      "\tspeed: 0.0115s/iter; left time: 31.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0784637 Vali Loss: 0.0769119 Test Loss: 0.0878655\n",
      "Validation loss decreased (0.077348 --> 0.076912).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779870\n",
      "\tspeed: 0.0291s/iter; left time: 75.2372s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807751\n",
      "\tspeed: 0.0115s/iter; left time: 28.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0777863 Vali Loss: 0.0771217 Test Loss: 0.0875601\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772136\n",
      "\tspeed: 0.0279s/iter; left time: 65.9296s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758945\n",
      "\tspeed: 0.0115s/iter; left time: 26.0033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0772079 Vali Loss: 0.0772257 Test Loss: 0.0879205\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747496\n",
      "\tspeed: 0.0280s/iter; left time: 59.9301s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791871\n",
      "\tspeed: 0.0116s/iter; left time: 23.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0767879 Vali Loss: 0.0771484 Test Loss: 0.0879905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0762381\n",
      "\tspeed: 0.0280s/iter; left time: 53.7355s\n",
      "\titers: 200, epoch: 12 | loss: 0.0765716\n",
      "\tspeed: 0.0116s/iter; left time: 21.0194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0764095 Vali Loss: 0.0771252 Test Loss: 0.0876286\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0747886\n",
      "\tspeed: 0.0276s/iter; left time: 46.6801s\n",
      "\titers: 200, epoch: 13 | loss: 0.0747912\n",
      "\tspeed: 0.0116s/iter; left time: 18.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0760711 Vali Loss: 0.0773463 Test Loss: 0.0876072\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018780911341309547, rmse:0.13704346120357513, mae:0.08786552399396896, rse:0.4025924503803253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1609155\n",
      "\tspeed: 0.0136s/iter; left time: 59.3758s\n",
      "\titers: 200, epoch: 1 | loss: 0.1392553\n",
      "\tspeed: 0.0115s/iter; left time: 49.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.1606353 Vali Loss: 0.1255435 Test Loss: 0.1420600\n",
      "Validation loss decreased (inf --> 0.125544).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989368\n",
      "\tspeed: 0.0272s/iter; left time: 113.0269s\n",
      "\titers: 200, epoch: 2 | loss: 0.0917517\n",
      "\tspeed: 0.0115s/iter; left time: 46.5570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0989939 Vali Loss: 0.0866069 Test Loss: 0.0975074\n",
      "Validation loss decreased (0.125544 --> 0.086607).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881878\n",
      "\tspeed: 0.0280s/iter; left time: 110.2228s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868338\n",
      "\tspeed: 0.0115s/iter; left time: 44.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0873806 Vali Loss: 0.0815672 Test Loss: 0.0929901\n",
      "Validation loss decreased (0.086607 --> 0.081567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868333\n",
      "\tspeed: 0.0283s/iter; left time: 104.9011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0832773\n",
      "\tspeed: 0.0115s/iter; left time: 41.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0838568 Vali Loss: 0.0793864 Test Loss: 0.0907652\n",
      "Validation loss decreased (0.081567 --> 0.079386).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838556\n",
      "\tspeed: 0.0323s/iter; left time: 112.6370s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836494\n",
      "\tspeed: 0.0115s/iter; left time: 38.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0818360 Vali Loss: 0.0784956 Test Loss: 0.0893709\n",
      "Validation loss decreased (0.079386 --> 0.078496).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0806378\n",
      "\tspeed: 0.0286s/iter; left time: 93.1447s\n",
      "\titers: 200, epoch: 6 | loss: 0.0794055\n",
      "\tspeed: 0.0115s/iter; left time: 36.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0803881 Vali Loss: 0.0777162 Test Loss: 0.0886234\n",
      "Validation loss decreased (0.078496 --> 0.077716).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788840\n",
      "\tspeed: 0.0279s/iter; left time: 84.8396s\n",
      "\titers: 200, epoch: 7 | loss: 0.0766921\n",
      "\tspeed: 0.0114s/iter; left time: 33.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0793882 Vali Loss: 0.0770763 Test Loss: 0.0880639\n",
      "Validation loss decreased (0.077716 --> 0.077076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0799958\n",
      "\tspeed: 0.0273s/iter; left time: 76.8830s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752629\n",
      "\tspeed: 0.0114s/iter; left time: 31.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0785344 Vali Loss: 0.0771097 Test Loss: 0.0877821\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0798732\n",
      "\tspeed: 0.0273s/iter; left time: 70.6047s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763348\n",
      "\tspeed: 0.0115s/iter; left time: 28.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0778461 Vali Loss: 0.0769220 Test Loss: 0.0876128\n",
      "Validation loss decreased (0.077076 --> 0.076922).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743215\n",
      "\tspeed: 0.0274s/iter; left time: 64.7420s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804870\n",
      "\tspeed: 0.0114s/iter; left time: 25.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0772132 Vali Loss: 0.0769246 Test Loss: 0.0874467\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0826044\n",
      "\tspeed: 0.0272s/iter; left time: 58.2747s\n",
      "\titers: 200, epoch: 11 | loss: 0.0788673\n",
      "\tspeed: 0.0115s/iter; left time: 23.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0766971 Vali Loss: 0.0773208 Test Loss: 0.0875554\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752086\n",
      "\tspeed: 0.0269s/iter; left time: 51.6387s\n",
      "\titers: 200, epoch: 12 | loss: 0.0771490\n",
      "\tspeed: 0.0115s/iter; left time: 20.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0763049 Vali Loss: 0.0769417 Test Loss: 0.0873715\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728450\n",
      "\tspeed: 0.0272s/iter; left time: 46.0181s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766766\n",
      "\tspeed: 0.0115s/iter; left time: 18.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0759119 Vali Loss: 0.0769993 Test Loss: 0.0874939\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771995\n",
      "\tspeed: 0.0274s/iter; left time: 40.2334s\n",
      "\titers: 200, epoch: 14 | loss: 0.0776248\n",
      "\tspeed: 0.0115s/iter; left time: 15.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0755728 Vali Loss: 0.0772427 Test Loss: 0.0875207\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018756497651338577, rmse:0.13695436716079712, mae:0.0876128226518631, rse:0.4023307263851166\n",
      "Intermediate time for ES and pred_len 96: 00h:01m:55.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1587022\n",
      "\tspeed: 0.0277s/iter; left time: 120.7666s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341747\n",
      "\tspeed: 0.0118s/iter; left time: 50.2674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 223 | Train Loss: 0.1577783 Vali Loss: 0.1251705 Test Loss: 0.1401281\n",
      "Validation loss decreased (inf --> 0.125171).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031412\n",
      "\tspeed: 0.0284s/iter; left time: 117.4405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0959672\n",
      "\tspeed: 0.0117s/iter; left time: 47.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.1027157 Vali Loss: 0.0919966 Test Loss: 0.1034162\n",
      "Validation loss decreased (0.125171 --> 0.091997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0920534\n",
      "\tspeed: 0.0294s/iter; left time: 115.1407s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888611\n",
      "\tspeed: 0.0117s/iter; left time: 44.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0920359 Vali Loss: 0.0870327 Test Loss: 0.0976905\n",
      "Validation loss decreased (0.091997 --> 0.087033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0895105\n",
      "\tspeed: 0.0294s/iter; left time: 108.4737s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878107\n",
      "\tspeed: 0.0120s/iter; left time: 43.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0884706 Vali Loss: 0.0853649 Test Loss: 0.0954801\n",
      "Validation loss decreased (0.087033 --> 0.085365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862070\n",
      "\tspeed: 0.0295s/iter; left time: 102.3714s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893748\n",
      "\tspeed: 0.0118s/iter; left time: 39.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0865734 Vali Loss: 0.0847053 Test Loss: 0.0949914\n",
      "Validation loss decreased (0.085365 --> 0.084705).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864203\n",
      "\tspeed: 0.0300s/iter; left time: 97.5177s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820089\n",
      "\tspeed: 0.0119s/iter; left time: 37.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0852276 Vali Loss: 0.0837621 Test Loss: 0.0942142\n",
      "Validation loss decreased (0.084705 --> 0.083762).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0851779\n",
      "\tspeed: 0.0297s/iter; left time: 89.8212s\n",
      "\titers: 200, epoch: 7 | loss: 0.0864495\n",
      "\tspeed: 0.0119s/iter; left time: 34.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 223 | Train Loss: 0.0841670 Vali Loss: 0.0831766 Test Loss: 0.0941424\n",
      "Validation loss decreased (0.083762 --> 0.083177).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873072\n",
      "\tspeed: 0.0299s/iter; left time: 83.6507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819371\n",
      "\tspeed: 0.0116s/iter; left time: 31.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0833336 Vali Loss: 0.0830012 Test Loss: 0.0937584\n",
      "Validation loss decreased (0.083177 --> 0.083001).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824002\n",
      "\tspeed: 0.0290s/iter; left time: 74.6439s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809036\n",
      "\tspeed: 0.0118s/iter; left time: 29.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0827256 Vali Loss: 0.0830959 Test Loss: 0.0934695\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832733\n",
      "\tspeed: 0.0290s/iter; left time: 68.3761s\n",
      "\titers: 200, epoch: 10 | loss: 0.0845594\n",
      "\tspeed: 0.0120s/iter; left time: 27.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0820771 Vali Loss: 0.0831661 Test Loss: 0.0935841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0840108\n",
      "\tspeed: 0.0294s/iter; left time: 62.6391s\n",
      "\titers: 200, epoch: 11 | loss: 0.0846826\n",
      "\tspeed: 0.0119s/iter; left time: 24.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0816523 Vali Loss: 0.0829173 Test Loss: 0.0937325\n",
      "Validation loss decreased (0.083001 --> 0.082917).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819534\n",
      "\tspeed: 0.0294s/iter; left time: 56.0105s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778076\n",
      "\tspeed: 0.0114s/iter; left time: 20.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0812295 Vali Loss: 0.0828364 Test Loss: 0.0937928\n",
      "Validation loss decreased (0.082917 --> 0.082836).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0812906\n",
      "\tspeed: 0.0291s/iter; left time: 49.0698s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818937\n",
      "\tspeed: 0.0116s/iter; left time: 18.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0807780 Vali Loss: 0.0831400 Test Loss: 0.0939310\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822786\n",
      "\tspeed: 0.0284s/iter; left time: 41.4949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779815\n",
      "\tspeed: 0.0115s/iter; left time: 15.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0805288 Vali Loss: 0.0833648 Test Loss: 0.0938287\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780915\n",
      "\tspeed: 0.0283s/iter; left time: 35.0180s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791826\n",
      "\tspeed: 0.0115s/iter; left time: 13.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0801763 Vali Loss: 0.0833790 Test Loss: 0.0936142\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0781371\n",
      "\tspeed: 0.0291s/iter; left time: 29.5890s\n",
      "\titers: 200, epoch: 16 | loss: 0.0776101\n",
      "\tspeed: 0.0121s/iter; left time: 11.0529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 223 | Train Loss: 0.0799538 Vali Loss: 0.0833786 Test Loss: 0.0939362\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800811\n",
      "\tspeed: 0.0281s/iter; left time: 22.3130s\n",
      "\titers: 200, epoch: 17 | loss: 0.0839744\n",
      "\tspeed: 0.0118s/iter; left time: 8.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0796631 Vali Loss: 0.0837506 Test Loss: 0.0939819\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021249037235975266, rmse:0.14577049016952515, mae:0.09379277378320694, rse:0.42826059460639954\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1613253\n",
      "\tspeed: 0.0143s/iter; left time: 62.1798s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379661\n",
      "\tspeed: 0.0116s/iter; left time: 49.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.1605699 Vali Loss: 0.1269564 Test Loss: 0.1422651\n",
      "Validation loss decreased (inf --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1011166\n",
      "\tspeed: 0.0288s/iter; left time: 119.3730s\n",
      "\titers: 200, epoch: 2 | loss: 0.0964100\n",
      "\tspeed: 0.0117s/iter; left time: 47.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.1028684 Vali Loss: 0.0919216 Test Loss: 0.1033256\n",
      "Validation loss decreased (0.126956 --> 0.091922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0919904\n",
      "\tspeed: 0.0289s/iter; left time: 113.3043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932997\n",
      "\tspeed: 0.0117s/iter; left time: 44.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0919826 Vali Loss: 0.0869391 Test Loss: 0.0977627\n",
      "Validation loss decreased (0.091922 --> 0.086939).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853900\n",
      "\tspeed: 0.0317s/iter; left time: 117.1775s\n",
      "\titers: 200, epoch: 4 | loss: 0.0877520\n",
      "\tspeed: 0.0121s/iter; left time: 43.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 223 | Train Loss: 0.0882947 Vali Loss: 0.0853301 Test Loss: 0.0954336\n",
      "Validation loss decreased (0.086939 --> 0.085330).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0842153\n",
      "\tspeed: 0.0301s/iter; left time: 104.2579s\n",
      "\titers: 200, epoch: 5 | loss: 0.0884012\n",
      "\tspeed: 0.0119s/iter; left time: 40.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0863264 Vali Loss: 0.0842051 Test Loss: 0.0947297\n",
      "Validation loss decreased (0.085330 --> 0.084205).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863844\n",
      "\tspeed: 0.0291s/iter; left time: 94.3492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844114\n",
      "\tspeed: 0.0117s/iter; left time: 36.7241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0849223 Vali Loss: 0.0838633 Test Loss: 0.0939944\n",
      "Validation loss decreased (0.084205 --> 0.083863).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0817755\n",
      "\tspeed: 0.0285s/iter; left time: 86.1333s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835092\n",
      "\tspeed: 0.0117s/iter; left time: 34.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0839199 Vali Loss: 0.0835818 Test Loss: 0.0939294\n",
      "Validation loss decreased (0.083863 --> 0.083582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832944\n",
      "\tspeed: 0.0286s/iter; left time: 80.0193s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838037\n",
      "\tspeed: 0.0116s/iter; left time: 31.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0830767 Vali Loss: 0.0830342 Test Loss: 0.0935405\n",
      "Validation loss decreased (0.083582 --> 0.083034).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0783223\n",
      "\tspeed: 0.0287s/iter; left time: 74.0256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815742\n",
      "\tspeed: 0.0117s/iter; left time: 29.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0824175 Vali Loss: 0.0832622 Test Loss: 0.0935256\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825320\n",
      "\tspeed: 0.0290s/iter; left time: 68.2133s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812171\n",
      "\tspeed: 0.0119s/iter; left time: 26.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0818186 Vali Loss: 0.0831434 Test Loss: 0.0934408\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0828382\n",
      "\tspeed: 0.0299s/iter; left time: 63.6815s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794838\n",
      "\tspeed: 0.0116s/iter; left time: 23.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0813276 Vali Loss: 0.0833540 Test Loss: 0.0934451\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0841984\n",
      "\tspeed: 0.0292s/iter; left time: 55.6406s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807900\n",
      "\tspeed: 0.0116s/iter; left time: 21.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0808180 Vali Loss: 0.0831364 Test Loss: 0.0931335\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0804507\n",
      "\tspeed: 0.0288s/iter; left time: 48.4642s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830584\n",
      "\tspeed: 0.0119s/iter; left time: 18.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0804731 Vali Loss: 0.0834696 Test Loss: 0.0930707\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02081207185983658, rmse:0.14426389336585999, mae:0.09354054182767868, rse:0.42383435368537903\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:12.80s\n",
      "Intermediate time for ES: 00h:06m:51.29s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1109400\n",
      "\tspeed: 0.0328s/iter; left time: 143.8481s\n",
      "\titers: 200, epoch: 1 | loss: 0.0880111\n",
      "\tspeed: 0.0117s/iter; left time: 50.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.1121065 Vali Loss: 0.0946012 Test Loss: 0.1039492\n",
      "Validation loss decreased (inf --> 0.094601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0538929\n",
      "\tspeed: 0.0273s/iter; left time: 113.5271s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533425\n",
      "\tspeed: 0.0116s/iter; left time: 46.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0594639 Vali Loss: 0.0593115 Test Loss: 0.0626804\n",
      "Validation loss decreased (0.094601 --> 0.059311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0489332\n",
      "\tspeed: 0.0274s/iter; left time: 107.7529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0485343\n",
      "\tspeed: 0.0113s/iter; left time: 43.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0507693 Vali Loss: 0.0568483 Test Loss: 0.0600760\n",
      "Validation loss decreased (0.059311 --> 0.056848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0487404\n",
      "\tspeed: 0.0285s/iter; left time: 105.8727s\n",
      "\titers: 200, epoch: 4 | loss: 0.0477995\n",
      "\tspeed: 0.0116s/iter; left time: 41.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0485856 Vali Loss: 0.0556100 Test Loss: 0.0589949\n",
      "Validation loss decreased (0.056848 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0472121\n",
      "\tspeed: 0.0273s/iter; left time: 94.9841s\n",
      "\titers: 200, epoch: 5 | loss: 0.0472476\n",
      "\tspeed: 0.0113s/iter; left time: 38.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0472403 Vali Loss: 0.0546619 Test Loss: 0.0584079\n",
      "Validation loss decreased (0.055610 --> 0.054662).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473987\n",
      "\tspeed: 0.0275s/iter; left time: 89.5337s\n",
      "\titers: 200, epoch: 6 | loss: 0.0465832\n",
      "\tspeed: 0.0113s/iter; left time: 35.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0462808 Vali Loss: 0.0536563 Test Loss: 0.0576321\n",
      "Validation loss decreased (0.054662 --> 0.053656).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0467726\n",
      "\tspeed: 0.0271s/iter; left time: 82.1835s\n",
      "\titers: 200, epoch: 7 | loss: 0.0450430\n",
      "\tspeed: 0.0113s/iter; left time: 33.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0456065 Vali Loss: 0.0533683 Test Loss: 0.0574062\n",
      "Validation loss decreased (0.053656 --> 0.053368).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0468291\n",
      "\tspeed: 0.0276s/iter; left time: 77.6114s\n",
      "\titers: 200, epoch: 8 | loss: 0.0441214\n",
      "\tspeed: 0.0116s/iter; left time: 31.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0450418 Vali Loss: 0.0531526 Test Loss: 0.0570093\n",
      "Validation loss decreased (0.053368 --> 0.053153).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0461029\n",
      "\tspeed: 0.0272s/iter; left time: 70.4458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0408064\n",
      "\tspeed: 0.0114s/iter; left time: 28.4553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0445590 Vali Loss: 0.0528589 Test Loss: 0.0570480\n",
      "Validation loss decreased (0.053153 --> 0.052859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465658\n",
      "\tspeed: 0.0278s/iter; left time: 65.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442628\n",
      "\tspeed: 0.0113s/iter; left time: 25.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0441614 Vali Loss: 0.0525321 Test Loss: 0.0567075\n",
      "Validation loss decreased (0.052859 --> 0.052532).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0423924\n",
      "\tspeed: 0.0273s/iter; left time: 58.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0421286\n",
      "\tspeed: 0.0115s/iter; left time: 23.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0438235 Vali Loss: 0.0523531 Test Loss: 0.0565543\n",
      "Validation loss decreased (0.052532 --> 0.052353).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0432395\n",
      "\tspeed: 0.0270s/iter; left time: 51.8299s\n",
      "\titers: 200, epoch: 12 | loss: 0.0427727\n",
      "\tspeed: 0.0114s/iter; left time: 20.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0435605 Vali Loss: 0.0522622 Test Loss: 0.0562977\n",
      "Validation loss decreased (0.052353 --> 0.052262).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0425658\n",
      "\tspeed: 0.0272s/iter; left time: 46.0590s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426574\n",
      "\tspeed: 0.0114s/iter; left time: 18.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0433638 Vali Loss: 0.0520600 Test Loss: 0.0562625\n",
      "Validation loss decreased (0.052262 --> 0.052060).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0430053\n",
      "\tspeed: 0.0283s/iter; left time: 41.6454s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461629\n",
      "\tspeed: 0.0117s/iter; left time: 16.0345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0431846 Vali Loss: 0.0523483 Test Loss: 0.0562605\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0421305\n",
      "\tspeed: 0.0297s/iter; left time: 36.9925s\n",
      "\titers: 200, epoch: 15 | loss: 0.0412395\n",
      "\tspeed: 0.0116s/iter; left time: 13.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0429814 Vali Loss: 0.0519295 Test Loss: 0.0562118\n",
      "Validation loss decreased (0.052060 --> 0.051930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0420358\n",
      "\tspeed: 0.0293s/iter; left time: 29.9298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441732\n",
      "\tspeed: 0.0117s/iter; left time: 10.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0428641 Vali Loss: 0.0518976 Test Loss: 0.0560167\n",
      "Validation loss decreased (0.051930 --> 0.051898).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0419349\n",
      "\tspeed: 0.0288s/iter; left time: 22.9721s\n",
      "\titers: 200, epoch: 17 | loss: 0.0407056\n",
      "\tspeed: 0.0117s/iter; left time: 8.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0426269 Vali Loss: 0.0517025 Test Loss: 0.0560059\n",
      "Validation loss decreased (0.051898 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0445126\n",
      "\tspeed: 0.0304s/iter; left time: 17.4073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0424769\n",
      "\tspeed: 0.0118s/iter; left time: 5.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0425544 Vali Loss: 0.0517746 Test Loss: 0.0559971\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0395071\n",
      "\tspeed: 0.0287s/iter; left time: 10.0244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0431924\n",
      "\tspeed: 0.0117s/iter; left time: 2.9122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0424392 Vali Loss: 0.0516417 Test Loss: 0.0558206\n",
      "Validation loss decreased (0.051702 --> 0.051642).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0415440\n",
      "\tspeed: 0.0288s/iter; left time: 3.6025s\n",
      "\titers: 200, epoch: 20 | loss: 0.0394489\n",
      "\tspeed: 0.0116s/iter; left time: 0.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0423368 Vali Loss: 0.0516620 Test Loss: 0.0558139\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010159791447222233, rmse:0.10079579055309296, mae:0.05582056939601898, rse:0.3888673782348633\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1158036\n",
      "\tspeed: 0.0143s/iter; left time: 62.6084s\n",
      "\titers: 200, epoch: 1 | loss: 0.0897452\n",
      "\tspeed: 0.0116s/iter; left time: 49.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.1133295 Vali Loss: 0.0949919 Test Loss: 0.1035445\n",
      "Validation loss decreased (inf --> 0.094992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0569122\n",
      "\tspeed: 0.0280s/iter; left time: 116.2907s\n",
      "\titers: 200, epoch: 2 | loss: 0.0541146\n",
      "\tspeed: 0.0116s/iter; left time: 47.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0595537 Vali Loss: 0.0592307 Test Loss: 0.0624938\n",
      "Validation loss decreased (0.094992 --> 0.059231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0535804\n",
      "\tspeed: 0.0283s/iter; left time: 111.4540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0482767\n",
      "\tspeed: 0.0116s/iter; left time: 44.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0507777 Vali Loss: 0.0568637 Test Loss: 0.0602203\n",
      "Validation loss decreased (0.059231 --> 0.056864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0489563\n",
      "\tspeed: 0.0281s/iter; left time: 104.1438s\n",
      "\titers: 200, epoch: 4 | loss: 0.0472311\n",
      "\tspeed: 0.0116s/iter; left time: 41.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0485894 Vali Loss: 0.0553823 Test Loss: 0.0590451\n",
      "Validation loss decreased (0.056864 --> 0.055382).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476006\n",
      "\tspeed: 0.0290s/iter; left time: 101.1218s\n",
      "\titers: 200, epoch: 5 | loss: 0.0451604\n",
      "\tspeed: 0.0116s/iter; left time: 39.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0472259 Vali Loss: 0.0547291 Test Loss: 0.0585976\n",
      "Validation loss decreased (0.055382 --> 0.054729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460030\n",
      "\tspeed: 0.0285s/iter; left time: 93.0952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0442784\n",
      "\tspeed: 0.0116s/iter; left time: 36.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0462648 Vali Loss: 0.0540650 Test Loss: 0.0579539\n",
      "Validation loss decreased (0.054729 --> 0.054065).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0454986\n",
      "\tspeed: 0.0280s/iter; left time: 85.1777s\n",
      "\titers: 200, epoch: 7 | loss: 0.0469666\n",
      "\tspeed: 0.0116s/iter; left time: 34.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0455293 Vali Loss: 0.0532679 Test Loss: 0.0573423\n",
      "Validation loss decreased (0.054065 --> 0.053268).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447970\n",
      "\tspeed: 0.0277s/iter; left time: 78.0220s\n",
      "\titers: 200, epoch: 8 | loss: 0.0483812\n",
      "\tspeed: 0.0116s/iter; left time: 31.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0449567 Vali Loss: 0.0530940 Test Loss: 0.0571498\n",
      "Validation loss decreased (0.053268 --> 0.053094).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444100\n",
      "\tspeed: 0.0279s/iter; left time: 72.2106s\n",
      "\titers: 200, epoch: 9 | loss: 0.0438467\n",
      "\tspeed: 0.0115s/iter; left time: 28.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0444837 Vali Loss: 0.0528195 Test Loss: 0.0569643\n",
      "Validation loss decreased (0.053094 --> 0.052819).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0440547\n",
      "\tspeed: 0.0278s/iter; left time: 65.8084s\n",
      "\titers: 200, epoch: 10 | loss: 0.0428151\n",
      "\tspeed: 0.0116s/iter; left time: 26.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0440762 Vali Loss: 0.0526214 Test Loss: 0.0568737\n",
      "Validation loss decreased (0.052819 --> 0.052621).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0445571\n",
      "\tspeed: 0.0283s/iter; left time: 60.5750s\n",
      "\titers: 200, epoch: 11 | loss: 0.0471088\n",
      "\tspeed: 0.0117s/iter; left time: 23.8888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0437659 Vali Loss: 0.0523438 Test Loss: 0.0564469\n",
      "Validation loss decreased (0.052621 --> 0.052344).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0434962\n",
      "\tspeed: 0.0280s/iter; left time: 53.6655s\n",
      "\titers: 200, epoch: 12 | loss: 0.0420639\n",
      "\tspeed: 0.0117s/iter; left time: 21.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0435228 Vali Loss: 0.0522977 Test Loss: 0.0564896\n",
      "Validation loss decreased (0.052344 --> 0.052298).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465735\n",
      "\tspeed: 0.0276s/iter; left time: 46.7459s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405169\n",
      "\tspeed: 0.0117s/iter; left time: 18.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0432881 Vali Loss: 0.0522314 Test Loss: 0.0563967\n",
      "Validation loss decreased (0.052298 --> 0.052231).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0418454\n",
      "\tspeed: 0.0280s/iter; left time: 41.1613s\n",
      "\titers: 200, epoch: 14 | loss: 0.0447588\n",
      "\tspeed: 0.0116s/iter; left time: 15.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0430877 Vali Loss: 0.0519799 Test Loss: 0.0562589\n",
      "Validation loss decreased (0.052231 --> 0.051980).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0423968\n",
      "\tspeed: 0.0275s/iter; left time: 34.2506s\n",
      "\titers: 200, epoch: 15 | loss: 0.0383774\n",
      "\tspeed: 0.0112s/iter; left time: 12.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0428894 Vali Loss: 0.0519243 Test Loss: 0.0561372\n",
      "Validation loss decreased (0.051980 --> 0.051924).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407413\n",
      "\tspeed: 0.0278s/iter; left time: 28.3533s\n",
      "\titers: 200, epoch: 16 | loss: 0.0405852\n",
      "\tspeed: 0.0122s/iter; left time: 11.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0427432 Vali Loss: 0.0518589 Test Loss: 0.0561070\n",
      "Validation loss decreased (0.051924 --> 0.051859).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0430592\n",
      "\tspeed: 0.0283s/iter; left time: 22.5159s\n",
      "\titers: 200, epoch: 17 | loss: 0.0412801\n",
      "\tspeed: 0.0123s/iter; left time: 8.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 224 | Train Loss: 0.0426225 Vali Loss: 0.0518812 Test Loss: 0.0561238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0411777\n",
      "\tspeed: 0.0276s/iter; left time: 15.8272s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410426\n",
      "\tspeed: 0.0122s/iter; left time: 5.7567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0425417 Vali Loss: 0.0517370 Test Loss: 0.0560527\n",
      "Validation loss decreased (0.051859 --> 0.051737).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0427175\n",
      "\tspeed: 0.0282s/iter; left time: 9.8363s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448190\n",
      "\tspeed: 0.0123s/iter; left time: 3.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 224 | Train Loss: 0.0423826 Vali Loss: 0.0516347 Test Loss: 0.0559927\n",
      "Validation loss decreased (0.051737 --> 0.051635).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0438801\n",
      "\tspeed: 0.0287s/iter; left time: 3.5837s\n",
      "\titers: 200, epoch: 20 | loss: 0.0390797\n",
      "\tspeed: 0.0124s/iter; left time: 0.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0423430 Vali Loss: 0.0516649 Test Loss: 0.0558768\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010225766338407993, rmse:0.10112252831459045, mae:0.055992696434259415, rse:0.39012792706489563\n",
      "Intermediate time for FR and pred_len 24: 00h:02m:48.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1147146\n",
      "\tspeed: 0.0335s/iter; left time: 146.7454s\n",
      "\titers: 200, epoch: 1 | loss: 0.1000472\n",
      "\tspeed: 0.0117s/iter; left time: 50.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.1151350 Vali Loss: 0.1004755 Test Loss: 0.1112628\n",
      "Validation loss decreased (inf --> 0.100475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692950\n",
      "\tspeed: 0.0286s/iter; left time: 118.8001s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726237\n",
      "\tspeed: 0.0116s/iter; left time: 46.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0735507 Vali Loss: 0.0766084 Test Loss: 0.0845824\n",
      "Validation loss decreased (0.100475 --> 0.076608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0612146\n",
      "\tspeed: 0.0291s/iter; left time: 114.5152s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639182\n",
      "\tspeed: 0.0115s/iter; left time: 44.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0659023 Vali Loss: 0.0733167 Test Loss: 0.0827081\n",
      "Validation loss decreased (0.076608 --> 0.073317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0624377\n",
      "\tspeed: 0.0291s/iter; left time: 107.9314s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632359\n",
      "\tspeed: 0.0118s/iter; left time: 42.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 224 | Train Loss: 0.0634114 Vali Loss: 0.0719024 Test Loss: 0.0820890\n",
      "Validation loss decreased (0.073317 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0613682\n",
      "\tspeed: 0.0287s/iter; left time: 100.1649s\n",
      "\titers: 200, epoch: 5 | loss: 0.0603765\n",
      "\tspeed: 0.0115s/iter; left time: 39.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0622096 Vali Loss: 0.0716747 Test Loss: 0.0817658\n",
      "Validation loss decreased (0.071902 --> 0.071675).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0613188\n",
      "\tspeed: 0.0289s/iter; left time: 94.2221s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585596\n",
      "\tspeed: 0.0116s/iter; left time: 36.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0613992 Vali Loss: 0.0709265 Test Loss: 0.0814199\n",
      "Validation loss decreased (0.071675 --> 0.070926).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581186\n",
      "\tspeed: 0.0294s/iter; left time: 89.3218s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601980\n",
      "\tspeed: 0.0118s/iter; left time: 34.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0607734 Vali Loss: 0.0705771 Test Loss: 0.0811658\n",
      "Validation loss decreased (0.070926 --> 0.070577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599504\n",
      "\tspeed: 0.0289s/iter; left time: 81.1635s\n",
      "\titers: 200, epoch: 8 | loss: 0.0627330\n",
      "\tspeed: 0.0117s/iter; left time: 31.6516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0602172 Vali Loss: 0.0707170 Test Loss: 0.0811702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0582917\n",
      "\tspeed: 0.0291s/iter; left time: 75.2427s\n",
      "\titers: 200, epoch: 9 | loss: 0.0607997\n",
      "\tspeed: 0.0117s/iter; left time: 29.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0597521 Vali Loss: 0.0708032 Test Loss: 0.0809484\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596805\n",
      "\tspeed: 0.0281s/iter; left time: 66.3860s\n",
      "\titers: 200, epoch: 10 | loss: 0.0599481\n",
      "\tspeed: 0.0117s/iter; left time: 26.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0594114 Vali Loss: 0.0709393 Test Loss: 0.0808087\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559060\n",
      "\tspeed: 0.0284s/iter; left time: 60.8353s\n",
      "\titers: 200, epoch: 11 | loss: 0.0589835\n",
      "\tspeed: 0.0117s/iter; left time: 23.8450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0590685 Vali Loss: 0.0707514 Test Loss: 0.0809203\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0602128\n",
      "\tspeed: 0.0290s/iter; left time: 55.6871s\n",
      "\titers: 200, epoch: 12 | loss: 0.0592024\n",
      "\tspeed: 0.0117s/iter; left time: 21.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0587862 Vali Loss: 0.0708335 Test Loss: 0.0807095\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019104918465018272, rmse:0.13822054862976074, mae:0.08116577565670013, rse:0.534673810005188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1143000\n",
      "\tspeed: 0.0145s/iter; left time: 63.5347s\n",
      "\titers: 200, epoch: 1 | loss: 0.0998920\n",
      "\tspeed: 0.0118s/iter; left time: 50.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.1165416 Vali Loss: 0.1021830 Test Loss: 0.1129842\n",
      "Validation loss decreased (inf --> 0.102183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0689287\n",
      "\tspeed: 0.0291s/iter; left time: 120.9753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0708336\n",
      "\tspeed: 0.0117s/iter; left time: 47.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0736541 Vali Loss: 0.0765947 Test Loss: 0.0845144\n",
      "Validation loss decreased (0.102183 --> 0.076595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0688908\n",
      "\tspeed: 0.0293s/iter; left time: 115.3649s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633019\n",
      "\tspeed: 0.0118s/iter; left time: 45.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0657550 Vali Loss: 0.0734985 Test Loss: 0.0830433\n",
      "Validation loss decreased (0.076595 --> 0.073499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691519\n",
      "\tspeed: 0.0300s/iter; left time: 111.1389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618158\n",
      "\tspeed: 0.0118s/iter; left time: 42.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0632717 Vali Loss: 0.0722616 Test Loss: 0.0826190\n",
      "Validation loss decreased (0.073499 --> 0.072262).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622582\n",
      "\tspeed: 0.0353s/iter; left time: 123.0562s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615297\n",
      "\tspeed: 0.0133s/iter; left time: 45.1396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0619997 Vali Loss: 0.0715764 Test Loss: 0.0818878\n",
      "Validation loss decreased (0.072262 --> 0.071576).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590784\n",
      "\tspeed: 0.0289s/iter; left time: 94.3597s\n",
      "\titers: 200, epoch: 6 | loss: 0.0622722\n",
      "\tspeed: 0.0117s/iter; left time: 37.1052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0611935 Vali Loss: 0.0714514 Test Loss: 0.0817338\n",
      "Validation loss decreased (0.071576 --> 0.071451).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0604725\n",
      "\tspeed: 0.0294s/iter; left time: 89.2865s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604548\n",
      "\tspeed: 0.0118s/iter; left time: 34.5435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0605358 Vali Loss: 0.0712921 Test Loss: 0.0815184\n",
      "Validation loss decreased (0.071451 --> 0.071292).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0592130\n",
      "\tspeed: 0.0291s/iter; left time: 81.7847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590778\n",
      "\tspeed: 0.0116s/iter; left time: 31.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0599328 Vali Loss: 0.0709609 Test Loss: 0.0816006\n",
      "Validation loss decreased (0.071292 --> 0.070961).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0577401\n",
      "\tspeed: 0.0278s/iter; left time: 71.8713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0619090\n",
      "\tspeed: 0.0114s/iter; left time: 28.4931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0595059 Vali Loss: 0.0710032 Test Loss: 0.0812286\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633323\n",
      "\tspeed: 0.0285s/iter; left time: 67.3003s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548593\n",
      "\tspeed: 0.0118s/iter; left time: 26.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0591519 Vali Loss: 0.0709546 Test Loss: 0.0809395\n",
      "Validation loss decreased (0.070961 --> 0.070955).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0578921\n",
      "\tspeed: 0.0302s/iter; left time: 64.7035s\n",
      "\titers: 200, epoch: 11 | loss: 0.0616430\n",
      "\tspeed: 0.0117s/iter; left time: 23.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0587993 Vali Loss: 0.0710152 Test Loss: 0.0811566\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0562681\n",
      "\tspeed: 0.0287s/iter; left time: 54.9371s\n",
      "\titers: 200, epoch: 12 | loss: 0.0630862\n",
      "\tspeed: 0.0114s/iter; left time: 20.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0585476 Vali Loss: 0.0710435 Test Loss: 0.0810608\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0615604\n",
      "\tspeed: 0.0283s/iter; left time: 47.9113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0607418\n",
      "\tspeed: 0.0115s/iter; left time: 18.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0582608 Vali Loss: 0.0711067 Test Loss: 0.0807557\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0583864\n",
      "\tspeed: 0.0282s/iter; left time: 41.4720s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560069\n",
      "\tspeed: 0.0117s/iter; left time: 16.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0579940 Vali Loss: 0.0712457 Test Loss: 0.0812506\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537845\n",
      "\tspeed: 0.0285s/iter; left time: 35.4472s\n",
      "\titers: 200, epoch: 15 | loss: 0.0620155\n",
      "\tspeed: 0.0118s/iter; left time: 13.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0578380 Vali Loss: 0.0711892 Test Loss: 0.0811719\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019235698506236076, rmse:0.13869282603263855, mae:0.08093950152397156, rse:0.5365006923675537\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:00.24s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1183062\n",
      "\tspeed: 0.0328s/iter; left time: 142.9406s\n",
      "\titers: 200, epoch: 1 | loss: 0.0972488\n",
      "\tspeed: 0.0118s/iter; left time: 50.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 223 | Train Loss: 0.1167069 Vali Loss: 0.1032240 Test Loss: 0.1129787\n",
      "Validation loss decreased (inf --> 0.103224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0826022\n",
      "\tspeed: 0.0281s/iter; left time: 116.1534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746639\n",
      "\tspeed: 0.0116s/iter; left time: 46.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0773228 Vali Loss: 0.0803081 Test Loss: 0.0886298\n",
      "Validation loss decreased (0.103224 --> 0.080308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714847\n",
      "\tspeed: 0.0288s/iter; left time: 112.7304s\n",
      "\titers: 200, epoch: 3 | loss: 0.0688747\n",
      "\tspeed: 0.0116s/iter; left time: 44.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0697671 Vali Loss: 0.0767658 Test Loss: 0.0878571\n",
      "Validation loss decreased (0.080308 --> 0.076766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0678537\n",
      "\tspeed: 0.0317s/iter; left time: 116.8599s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696913\n",
      "\tspeed: 0.0116s/iter; left time: 41.8282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0672740 Vali Loss: 0.0758421 Test Loss: 0.0871055\n",
      "Validation loss decreased (0.076766 --> 0.075842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679309\n",
      "\tspeed: 0.0289s/iter; left time: 100.1727s\n",
      "\titers: 200, epoch: 5 | loss: 0.0694386\n",
      "\tspeed: 0.0116s/iter; left time: 39.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0661240 Vali Loss: 0.0754434 Test Loss: 0.0868867\n",
      "Validation loss decreased (0.075842 --> 0.075443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640229\n",
      "\tspeed: 0.0287s/iter; left time: 93.2148s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638434\n",
      "\tspeed: 0.0116s/iter; left time: 36.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0653081 Vali Loss: 0.0750301 Test Loss: 0.0866583\n",
      "Validation loss decreased (0.075443 --> 0.075030).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656921\n",
      "\tspeed: 0.0290s/iter; left time: 87.6558s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664725\n",
      "\tspeed: 0.0116s/iter; left time: 34.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0647015 Vali Loss: 0.0748772 Test Loss: 0.0860748\n",
      "Validation loss decreased (0.075030 --> 0.074877).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0677239\n",
      "\tspeed: 0.0293s/iter; left time: 82.1328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618351\n",
      "\tspeed: 0.0117s/iter; left time: 31.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0641984 Vali Loss: 0.0750208 Test Loss: 0.0871818\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654734\n",
      "\tspeed: 0.0285s/iter; left time: 73.3489s\n",
      "\titers: 200, epoch: 9 | loss: 0.0638321\n",
      "\tspeed: 0.0117s/iter; left time: 28.8734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0637861 Vali Loss: 0.0750694 Test Loss: 0.0867115\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0613091\n",
      "\tspeed: 0.0279s/iter; left time: 65.7059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665837\n",
      "\tspeed: 0.0116s/iter; left time: 26.1477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0634266 Vali Loss: 0.0752134 Test Loss: 0.0868901\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667932\n",
      "\tspeed: 0.0286s/iter; left time: 60.9111s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656480\n",
      "\tspeed: 0.0119s/iter; left time: 24.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0631315 Vali Loss: 0.0750217 Test Loss: 0.0868845\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0645292\n",
      "\tspeed: 0.0282s/iter; left time: 53.8033s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635025\n",
      "\tspeed: 0.0116s/iter; left time: 20.9435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0628285 Vali Loss: 0.0754389 Test Loss: 0.0868052\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02051929198205471, rmse:0.14324556291103363, mae:0.08607485145330429, rse:0.5548036694526672\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163215\n",
      "\tspeed: 0.0138s/iter; left time: 59.9905s\n",
      "\titers: 200, epoch: 1 | loss: 0.1008288\n",
      "\tspeed: 0.0118s/iter; left time: 50.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.1164158 Vali Loss: 0.1032304 Test Loss: 0.1131373\n",
      "Validation loss decreased (inf --> 0.103230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0742068\n",
      "\tspeed: 0.0287s/iter; left time: 118.6475s\n",
      "\titers: 200, epoch: 2 | loss: 0.0729584\n",
      "\tspeed: 0.0116s/iter; left time: 46.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0772881 Vali Loss: 0.0804655 Test Loss: 0.0887936\n",
      "Validation loss decreased (0.103230 --> 0.080465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693759\n",
      "\tspeed: 0.0283s/iter; left time: 110.7495s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663430\n",
      "\tspeed: 0.0116s/iter; left time: 44.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0697295 Vali Loss: 0.0766993 Test Loss: 0.0879378\n",
      "Validation loss decreased (0.080465 --> 0.076699).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0690095\n",
      "\tspeed: 0.0287s/iter; left time: 105.9435s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655570\n",
      "\tspeed: 0.0117s/iter; left time: 41.8768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0672098 Vali Loss: 0.0757153 Test Loss: 0.0876326\n",
      "Validation loss decreased (0.076699 --> 0.075715).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0648292\n",
      "\tspeed: 0.0365s/iter; left time: 126.7079s\n",
      "\titers: 200, epoch: 5 | loss: 0.0636270\n",
      "\tspeed: 0.0118s/iter; left time: 39.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.0660205 Vali Loss: 0.0755744 Test Loss: 0.0876081\n",
      "Validation loss decreased (0.075715 --> 0.075574).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0668137\n",
      "\tspeed: 0.0298s/iter; left time: 96.6959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653384\n",
      "\tspeed: 0.0119s/iter; left time: 37.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0652508 Vali Loss: 0.0750264 Test Loss: 0.0864856\n",
      "Validation loss decreased (0.075574 --> 0.075026).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0650892\n",
      "\tspeed: 0.0288s/iter; left time: 87.1309s\n",
      "\titers: 200, epoch: 7 | loss: 0.0644793\n",
      "\tspeed: 0.0117s/iter; left time: 34.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0645868 Vali Loss: 0.0750114 Test Loss: 0.0868331\n",
      "Validation loss decreased (0.075026 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0653592\n",
      "\tspeed: 0.0298s/iter; left time: 83.3679s\n",
      "\titers: 200, epoch: 8 | loss: 0.0653282\n",
      "\tspeed: 0.0118s/iter; left time: 31.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0641446 Vali Loss: 0.0748277 Test Loss: 0.0862671\n",
      "Validation loss decreased (0.075011 --> 0.074828).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0644312\n",
      "\tspeed: 0.0289s/iter; left time: 74.4920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615943\n",
      "\tspeed: 0.0116s/iter; left time: 28.7163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0637232 Vali Loss: 0.0751069 Test Loss: 0.0860124\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0620447\n",
      "\tspeed: 0.0285s/iter; left time: 66.9874s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633003\n",
      "\tspeed: 0.0117s/iter; left time: 26.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0633491 Vali Loss: 0.0752738 Test Loss: 0.0857870\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0609704\n",
      "\tspeed: 0.0286s/iter; left time: 60.8659s\n",
      "\titers: 200, epoch: 11 | loss: 0.0661358\n",
      "\tspeed: 0.0117s/iter; left time: 23.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0630023 Vali Loss: 0.0749894 Test Loss: 0.0863085\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0640791\n",
      "\tspeed: 0.0289s/iter; left time: 55.0650s\n",
      "\titers: 200, epoch: 12 | loss: 0.0625561\n",
      "\tspeed: 0.0117s/iter; left time: 21.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0627204 Vali Loss: 0.0749291 Test Loss: 0.0859225\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646269\n",
      "\tspeed: 0.0284s/iter; left time: 47.8859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0641280\n",
      "\tspeed: 0.0117s/iter; left time: 18.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0624306 Vali Loss: 0.0750348 Test Loss: 0.0861682\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020482137799263, rmse:0.1431158185005188, mae:0.08626711368560791, rse:0.5543011426925659\n",
      "Intermediate time for FR and pred_len 168: 00h:01m:52.57s\n",
      "Intermediate time for FR: 00h:06m:41.56s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1628962\n",
      "\tspeed: 0.0321s/iter; left time: 140.8314s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291237\n",
      "\tspeed: 0.0115s/iter; left time: 49.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.1621927 Vali Loss: 0.1139153 Test Loss: 0.1173210\n",
      "Validation loss decreased (inf --> 0.113915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784920\n",
      "\tspeed: 0.0274s/iter; left time: 113.9878s\n",
      "\titers: 200, epoch: 2 | loss: 0.0711628\n",
      "\tspeed: 0.0114s/iter; left time: 46.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0831000 Vali Loss: 0.0642116 Test Loss: 0.0672076\n",
      "Validation loss decreased (0.113915 --> 0.064212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0703022\n",
      "\tspeed: 0.0270s/iter; left time: 106.1965s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671893\n",
      "\tspeed: 0.0113s/iter; left time: 43.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0678163 Vali Loss: 0.0607519 Test Loss: 0.0635062\n",
      "Validation loss decreased (0.064212 --> 0.060752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609002\n",
      "\tspeed: 0.0281s/iter; left time: 104.3447s\n",
      "\titers: 200, epoch: 4 | loss: 0.0623605\n",
      "\tspeed: 0.0114s/iter; left time: 41.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0644234 Vali Loss: 0.0591367 Test Loss: 0.0617633\n",
      "Validation loss decreased (0.060752 --> 0.059137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633016\n",
      "\tspeed: 0.0279s/iter; left time: 97.3548s\n",
      "\titers: 200, epoch: 5 | loss: 0.0651986\n",
      "\tspeed: 0.0113s/iter; left time: 38.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0625412 Vali Loss: 0.0581853 Test Loss: 0.0606249\n",
      "Validation loss decreased (0.059137 --> 0.058185).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0649286\n",
      "\tspeed: 0.0270s/iter; left time: 88.0467s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616859\n",
      "\tspeed: 0.0115s/iter; left time: 36.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0611915 Vali Loss: 0.0574970 Test Loss: 0.0600334\n",
      "Validation loss decreased (0.058185 --> 0.057497).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590814\n",
      "\tspeed: 0.0272s/iter; left time: 82.7353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585640\n",
      "\tspeed: 0.0113s/iter; left time: 33.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0602745 Vali Loss: 0.0569347 Test Loss: 0.0594827\n",
      "Validation loss decreased (0.057497 --> 0.056935).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0607947\n",
      "\tspeed: 0.0274s/iter; left time: 77.0214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0553050\n",
      "\tspeed: 0.0113s/iter; left time: 30.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0595292 Vali Loss: 0.0563626 Test Loss: 0.0592692\n",
      "Validation loss decreased (0.056935 --> 0.056363).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550640\n",
      "\tspeed: 0.0270s/iter; left time: 69.8897s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581901\n",
      "\tspeed: 0.0113s/iter; left time: 28.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0589363 Vali Loss: 0.0561472 Test Loss: 0.0590204\n",
      "Validation loss decreased (0.056363 --> 0.056147).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586622\n",
      "\tspeed: 0.0264s/iter; left time: 62.4701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589459\n",
      "\tspeed: 0.0114s/iter; left time: 25.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0584518 Vali Loss: 0.0559549 Test Loss: 0.0588039\n",
      "Validation loss decreased (0.056147 --> 0.055955).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0604423\n",
      "\tspeed: 0.0271s/iter; left time: 58.0682s\n",
      "\titers: 200, epoch: 11 | loss: 0.0600132\n",
      "\tspeed: 0.0113s/iter; left time: 23.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0579917 Vali Loss: 0.0557425 Test Loss: 0.0584588\n",
      "Validation loss decreased (0.055955 --> 0.055742).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0585862\n",
      "\tspeed: 0.0272s/iter; left time: 52.2296s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565248\n",
      "\tspeed: 0.0113s/iter; left time: 20.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0575839 Vali Loss: 0.0553778 Test Loss: 0.0581512\n",
      "Validation loss decreased (0.055742 --> 0.055378).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0592767\n",
      "\tspeed: 0.0276s/iter; left time: 46.6804s\n",
      "\titers: 200, epoch: 13 | loss: 0.0601190\n",
      "\tspeed: 0.0113s/iter; left time: 18.0660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0572631 Vali Loss: 0.0554036 Test Loss: 0.0582940\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0584438\n",
      "\tspeed: 0.0269s/iter; left time: 39.5251s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597098\n",
      "\tspeed: 0.0114s/iter; left time: 15.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0570509 Vali Loss: 0.0552208 Test Loss: 0.0581448\n",
      "Validation loss decreased (0.055378 --> 0.055221).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0570238\n",
      "\tspeed: 0.0279s/iter; left time: 34.7792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0546779\n",
      "\tspeed: 0.0113s/iter; left time: 12.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0568364 Vali Loss: 0.0549905 Test Loss: 0.0578448\n",
      "Validation loss decreased (0.055221 --> 0.054990).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0585651\n",
      "\tspeed: 0.0272s/iter; left time: 27.7257s\n",
      "\titers: 200, epoch: 16 | loss: 0.0602605\n",
      "\tspeed: 0.0113s/iter; left time: 10.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0566376 Vali Loss: 0.0548767 Test Loss: 0.0577145\n",
      "Validation loss decreased (0.054990 --> 0.054877).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632500\n",
      "\tspeed: 0.0267s/iter; left time: 21.2693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582883\n",
      "\tspeed: 0.0114s/iter; left time: 7.9652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0564069 Vali Loss: 0.0548520 Test Loss: 0.0575403\n",
      "Validation loss decreased (0.054877 --> 0.054852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549437\n",
      "\tspeed: 0.0271s/iter; left time: 15.5545s\n",
      "\titers: 200, epoch: 18 | loss: 0.0606063\n",
      "\tspeed: 0.0113s/iter; left time: 5.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0563488 Vali Loss: 0.0549136 Test Loss: 0.0575645\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0539349\n",
      "\tspeed: 0.0264s/iter; left time: 9.2265s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541664\n",
      "\tspeed: 0.0113s/iter; left time: 2.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0561536 Vali Loss: 0.0546398 Test Loss: 0.0574950\n",
      "Validation loss decreased (0.054852 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0571351\n",
      "\tspeed: 0.0274s/iter; left time: 3.4275s\n",
      "\titers: 200, epoch: 20 | loss: 0.0553324\n",
      "\tspeed: 0.0114s/iter; left time: 0.2846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0560287 Vali Loss: 0.0546072 Test Loss: 0.0573911\n",
      "Validation loss decreased (0.054640 --> 0.054607).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010179038159549236, rmse:0.10089121758937836, mae:0.05739111453294754, rse:0.3812182545661926\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1643064\n",
      "\tspeed: 0.0135s/iter; left time: 59.0639s\n",
      "\titers: 200, epoch: 1 | loss: 0.1332380\n",
      "\tspeed: 0.0113s/iter; left time: 48.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.1647739 Vali Loss: 0.1140934 Test Loss: 0.1179993\n",
      "Validation loss decreased (inf --> 0.114093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0783891\n",
      "\tspeed: 0.0273s/iter; left time: 113.2803s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731892\n",
      "\tspeed: 0.0113s/iter; left time: 45.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0831498 Vali Loss: 0.0640458 Test Loss: 0.0669815\n",
      "Validation loss decreased (0.114093 --> 0.064046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0668713\n",
      "\tspeed: 0.0262s/iter; left time: 103.0121s\n",
      "\titers: 200, epoch: 3 | loss: 0.0657760\n",
      "\tspeed: 0.0113s/iter; left time: 43.2574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0676153 Vali Loss: 0.0606492 Test Loss: 0.0632237\n",
      "Validation loss decreased (0.064046 --> 0.060649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620542\n",
      "\tspeed: 0.0265s/iter; left time: 98.4674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0630409\n",
      "\tspeed: 0.0113s/iter; left time: 40.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0642292 Vali Loss: 0.0588349 Test Loss: 0.0615947\n",
      "Validation loss decreased (0.060649 --> 0.058835).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629932\n",
      "\tspeed: 0.0265s/iter; left time: 92.2697s\n",
      "\titers: 200, epoch: 5 | loss: 0.0583962\n",
      "\tspeed: 0.0113s/iter; left time: 38.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0622446 Vali Loss: 0.0577234 Test Loss: 0.0604983\n",
      "Validation loss decreased (0.058835 --> 0.057723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631058\n",
      "\tspeed: 0.0268s/iter; left time: 87.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0636711\n",
      "\tspeed: 0.0115s/iter; left time: 36.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0609994 Vali Loss: 0.0572215 Test Loss: 0.0600380\n",
      "Validation loss decreased (0.057723 --> 0.057222).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0620245\n",
      "\tspeed: 0.0272s/iter; left time: 82.5019s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590188\n",
      "\tspeed: 0.0114s/iter; left time: 33.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0601276 Vali Loss: 0.0566568 Test Loss: 0.0594509\n",
      "Validation loss decreased (0.057222 --> 0.056657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0584333\n",
      "\tspeed: 0.0263s/iter; left time: 74.0808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558407\n",
      "\tspeed: 0.0113s/iter; left time: 30.5627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0593526 Vali Loss: 0.0562219 Test Loss: 0.0585741\n",
      "Validation loss decreased (0.056657 --> 0.056222).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546636\n",
      "\tspeed: 0.0271s/iter; left time: 70.2266s\n",
      "\titers: 200, epoch: 9 | loss: 0.0594059\n",
      "\tspeed: 0.0113s/iter; left time: 28.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0587434 Vali Loss: 0.0561855 Test Loss: 0.0587512\n",
      "Validation loss decreased (0.056222 --> 0.056185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0599125\n",
      "\tspeed: 0.0264s/iter; left time: 62.5541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551820\n",
      "\tspeed: 0.0113s/iter; left time: 25.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0582120 Vali Loss: 0.0557990 Test Loss: 0.0583509\n",
      "Validation loss decreased (0.056185 --> 0.055799).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0542246\n",
      "\tspeed: 0.0275s/iter; left time: 58.8962s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568748\n",
      "\tspeed: 0.0117s/iter; left time: 23.9817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0578913 Vali Loss: 0.0554993 Test Loss: 0.0581651\n",
      "Validation loss decreased (0.055799 --> 0.055499).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0534663\n",
      "\tspeed: 0.0282s/iter; left time: 54.1318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535820\n",
      "\tspeed: 0.0115s/iter; left time: 20.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0575138 Vali Loss: 0.0551920 Test Loss: 0.0578730\n",
      "Validation loss decreased (0.055499 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0578202\n",
      "\tspeed: 0.0268s/iter; left time: 45.3700s\n",
      "\titers: 200, epoch: 13 | loss: 0.0523866\n",
      "\tspeed: 0.0113s/iter; left time: 18.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0571534 Vali Loss: 0.0551626 Test Loss: 0.0578474\n",
      "Validation loss decreased (0.055192 --> 0.055163).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552824\n",
      "\tspeed: 0.0259s/iter; left time: 38.0826s\n",
      "\titers: 200, epoch: 14 | loss: 0.0516682\n",
      "\tspeed: 0.0113s/iter; left time: 15.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0569531 Vali Loss: 0.0551356 Test Loss: 0.0576503\n",
      "Validation loss decreased (0.055163 --> 0.055136).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0594676\n",
      "\tspeed: 0.0261s/iter; left time: 32.4792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0545479\n",
      "\tspeed: 0.0113s/iter; left time: 12.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0566778 Vali Loss: 0.0548414 Test Loss: 0.0575935\n",
      "Validation loss decreased (0.055136 --> 0.054841).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0543843\n",
      "\tspeed: 0.0263s/iter; left time: 26.8968s\n",
      "\titers: 200, epoch: 16 | loss: 0.0565425\n",
      "\tspeed: 0.0113s/iter; left time: 10.4313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0565070 Vali Loss: 0.0548034 Test Loss: 0.0574594\n",
      "Validation loss decreased (0.054841 --> 0.054803).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0619975\n",
      "\tspeed: 0.0268s/iter; left time: 21.3236s\n",
      "\titers: 200, epoch: 17 | loss: 0.0535555\n",
      "\tspeed: 0.0113s/iter; left time: 7.8661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0563112 Vali Loss: 0.0548327 Test Loss: 0.0573983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0553390\n",
      "\tspeed: 0.0261s/iter; left time: 14.9370s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519897\n",
      "\tspeed: 0.0113s/iter; left time: 5.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0561897 Vali Loss: 0.0547850 Test Loss: 0.0573173\n",
      "Validation loss decreased (0.054803 --> 0.054785).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0521124\n",
      "\tspeed: 0.0263s/iter; left time: 9.1845s\n",
      "\titers: 200, epoch: 19 | loss: 0.0521864\n",
      "\tspeed: 0.0113s/iter; left time: 2.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0559832 Vali Loss: 0.0548023 Test Loss: 0.0572995\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0512948\n",
      "\tspeed: 0.0260s/iter; left time: 3.2522s\n",
      "\titers: 200, epoch: 20 | loss: 0.0542285\n",
      "\tspeed: 0.0114s/iter; left time: 0.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0559045 Vali Loss: 0.0546398 Test Loss: 0.0573421\n",
      "Validation loss decreased (0.054785 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010212065652012825, rmse:0.10105476528406143, mae:0.057342130690813065, rse:0.3818362355232239\n",
      "Intermediate time for IT and pred_len 24: 00h:02m:42.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1694137\n",
      "\tspeed: 0.0322s/iter; left time: 140.9059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1422566\n",
      "\tspeed: 0.0115s/iter; left time: 49.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.1661313 Vali Loss: 0.1205659 Test Loss: 0.1253998\n",
      "Validation loss decreased (inf --> 0.120566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982611\n",
      "\tspeed: 0.0290s/iter; left time: 120.7142s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932958\n",
      "\tspeed: 0.0115s/iter; left time: 46.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.1010618 Vali Loss: 0.0828836 Test Loss: 0.0877833\n",
      "Validation loss decreased (0.120566 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0864613\n",
      "\tspeed: 0.0281s/iter; left time: 110.5085s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823260\n",
      "\tspeed: 0.0115s/iter; left time: 44.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0868094 Vali Loss: 0.0794397 Test Loss: 0.0843617\n",
      "Validation loss decreased (0.082884 --> 0.079440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839486\n",
      "\tspeed: 0.0287s/iter; left time: 106.3726s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801206\n",
      "\tspeed: 0.0115s/iter; left time: 41.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0835503 Vali Loss: 0.0782552 Test Loss: 0.0835699\n",
      "Validation loss decreased (0.079440 --> 0.078255).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815459\n",
      "\tspeed: 0.0302s/iter; left time: 105.3279s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828756\n",
      "\tspeed: 0.0116s/iter; left time: 39.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0818222 Vali Loss: 0.0776317 Test Loss: 0.0827362\n",
      "Validation loss decreased (0.078255 --> 0.077632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834187\n",
      "\tspeed: 0.0317s/iter; left time: 103.4027s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795873\n",
      "\tspeed: 0.0115s/iter; left time: 36.3559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0805658 Vali Loss: 0.0772948 Test Loss: 0.0826314\n",
      "Validation loss decreased (0.077632 --> 0.077295).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0768925\n",
      "\tspeed: 0.0284s/iter; left time: 86.2397s\n",
      "\titers: 200, epoch: 7 | loss: 0.0789800\n",
      "\tspeed: 0.0116s/iter; left time: 33.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0796422 Vali Loss: 0.0770975 Test Loss: 0.0823685\n",
      "Validation loss decreased (0.077295 --> 0.077098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801099\n",
      "\tspeed: 0.0291s/iter; left time: 81.9227s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806852\n",
      "\tspeed: 0.0115s/iter; left time: 31.3275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0789244 Vali Loss: 0.0767069 Test Loss: 0.0817630\n",
      "Validation loss decreased (0.077098 --> 0.076707).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0756710\n",
      "\tspeed: 0.0288s/iter; left time: 74.6022s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760978\n",
      "\tspeed: 0.0115s/iter; left time: 28.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0782492 Vali Loss: 0.0765156 Test Loss: 0.0816814\n",
      "Validation loss decreased (0.076707 --> 0.076516).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783817\n",
      "\tspeed: 0.0280s/iter; left time: 66.1651s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794710\n",
      "\tspeed: 0.0115s/iter; left time: 26.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0776505 Vali Loss: 0.0763667 Test Loss: 0.0815143\n",
      "Validation loss decreased (0.076516 --> 0.076367).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764569\n",
      "\tspeed: 0.0292s/iter; left time: 62.4961s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764720\n",
      "\tspeed: 0.0115s/iter; left time: 23.5634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0772299 Vali Loss: 0.0762668 Test Loss: 0.0814972\n",
      "Validation loss decreased (0.076367 --> 0.076267).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0755686\n",
      "\tspeed: 0.0285s/iter; left time: 54.5823s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748391\n",
      "\tspeed: 0.0116s/iter; left time: 21.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0767714 Vali Loss: 0.0761280 Test Loss: 0.0812074\n",
      "Validation loss decreased (0.076267 --> 0.076128).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782008\n",
      "\tspeed: 0.0295s/iter; left time: 49.9895s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751148\n",
      "\tspeed: 0.0115s/iter; left time: 18.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0763727 Vali Loss: 0.0763362 Test Loss: 0.0812979\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707611\n",
      "\tspeed: 0.0284s/iter; left time: 41.7819s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763229\n",
      "\tspeed: 0.0115s/iter; left time: 15.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0760496 Vali Loss: 0.0761597 Test Loss: 0.0812481\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798078\n",
      "\tspeed: 0.0284s/iter; left time: 35.3032s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711448\n",
      "\tspeed: 0.0115s/iter; left time: 13.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0757627 Vali Loss: 0.0761455 Test Loss: 0.0810610\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709446\n",
      "\tspeed: 0.0284s/iter; left time: 29.0244s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774027\n",
      "\tspeed: 0.0115s/iter; left time: 10.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0754142 Vali Loss: 0.0760802 Test Loss: 0.0811172\n",
      "Validation loss decreased (0.076128 --> 0.076080).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734147\n",
      "\tspeed: 0.0290s/iter; left time: 23.0817s\n",
      "\titers: 200, epoch: 17 | loss: 0.0760152\n",
      "\tspeed: 0.0115s/iter; left time: 8.0491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0751861 Vali Loss: 0.0760274 Test Loss: 0.0810721\n",
      "Validation loss decreased (0.076080 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773675\n",
      "\tspeed: 0.0284s/iter; left time: 16.2618s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752099\n",
      "\tspeed: 0.0116s/iter; left time: 5.4758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0749369 Vali Loss: 0.0759469 Test Loss: 0.0809807\n",
      "Validation loss decreased (0.076027 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726778\n",
      "\tspeed: 0.0287s/iter; left time: 10.0274s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723060\n",
      "\tspeed: 0.0115s/iter; left time: 2.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0747569 Vali Loss: 0.0760007 Test Loss: 0.0810970\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0714997\n",
      "\tspeed: 0.0285s/iter; left time: 3.5624s\n",
      "\titers: 200, epoch: 20 | loss: 0.0753793\n",
      "\tspeed: 0.0115s/iter; left time: 0.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0746135 Vali Loss: 0.0759967 Test Loss: 0.0809578\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018395546823740005, rmse:0.13563019037246704, mae:0.08098065108060837, rse:0.5128323435783386\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1659828\n",
      "\tspeed: 0.0185s/iter; left time: 80.9585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1377545\n",
      "\tspeed: 0.0115s/iter; left time: 49.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.1651078 Vali Loss: 0.1197496 Test Loss: 0.1245617\n",
      "Validation loss decreased (inf --> 0.119750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1041728\n",
      "\tspeed: 0.0281s/iter; left time: 116.7155s\n",
      "\titers: 200, epoch: 2 | loss: 0.0899635\n",
      "\tspeed: 0.0115s/iter; left time: 46.8451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.1007306 Vali Loss: 0.0832745 Test Loss: 0.0876749\n",
      "Validation loss decreased (0.119750 --> 0.083274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899828\n",
      "\tspeed: 0.0281s/iter; left time: 110.6926s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884937\n",
      "\tspeed: 0.0115s/iter; left time: 44.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0869526 Vali Loss: 0.0797011 Test Loss: 0.0844012\n",
      "Validation loss decreased (0.083274 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0844673\n",
      "\tspeed: 0.0284s/iter; left time: 105.4245s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826469\n",
      "\tspeed: 0.0115s/iter; left time: 41.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0837113 Vali Loss: 0.0787353 Test Loss: 0.0831461\n",
      "Validation loss decreased (0.079701 --> 0.078735).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856277\n",
      "\tspeed: 0.0282s/iter; left time: 98.2904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0847376\n",
      "\tspeed: 0.0116s/iter; left time: 39.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0817940 Vali Loss: 0.0780197 Test Loss: 0.0824059\n",
      "Validation loss decreased (0.078735 --> 0.078020).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0799199\n",
      "\tspeed: 0.0281s/iter; left time: 91.4724s\n",
      "\titers: 200, epoch: 6 | loss: 0.0797415\n",
      "\tspeed: 0.0116s/iter; left time: 36.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0804718 Vali Loss: 0.0775971 Test Loss: 0.0818354\n",
      "Validation loss decreased (0.078020 --> 0.077597).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792248\n",
      "\tspeed: 0.0280s/iter; left time: 84.9436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814994\n",
      "\tspeed: 0.0115s/iter; left time: 33.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0795296 Vali Loss: 0.0773038 Test Loss: 0.0817166\n",
      "Validation loss decreased (0.077597 --> 0.077304).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807771\n",
      "\tspeed: 0.0280s/iter; left time: 78.7140s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778802\n",
      "\tspeed: 0.0116s/iter; left time: 31.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0788082 Vali Loss: 0.0770593 Test Loss: 0.0815343\n",
      "Validation loss decreased (0.077304 --> 0.077059).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779113\n",
      "\tspeed: 0.0276s/iter; left time: 71.5707s\n",
      "\titers: 200, epoch: 9 | loss: 0.0765582\n",
      "\tspeed: 0.0115s/iter; left time: 28.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0782034 Vali Loss: 0.0769300 Test Loss: 0.0815683\n",
      "Validation loss decreased (0.077059 --> 0.076930).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0745629\n",
      "\tspeed: 0.0278s/iter; left time: 65.7567s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756760\n",
      "\tspeed: 0.0115s/iter; left time: 26.1083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0776538 Vali Loss: 0.0768092 Test Loss: 0.0813674\n",
      "Validation loss decreased (0.076930 --> 0.076809).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764665\n",
      "\tspeed: 0.0278s/iter; left time: 59.5152s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809056\n",
      "\tspeed: 0.0116s/iter; left time: 23.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0772223 Vali Loss: 0.0768539 Test Loss: 0.0814002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0786310\n",
      "\tspeed: 0.0274s/iter; left time: 52.4824s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731935\n",
      "\tspeed: 0.0116s/iter; left time: 21.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0768144 Vali Loss: 0.0769477 Test Loss: 0.0813958\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0762809\n",
      "\tspeed: 0.0272s/iter; left time: 45.9776s\n",
      "\titers: 200, epoch: 13 | loss: 0.0762783\n",
      "\tspeed: 0.0116s/iter; left time: 18.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0764390 Vali Loss: 0.0768751 Test Loss: 0.0811918\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0726768\n",
      "\tspeed: 0.0274s/iter; left time: 40.2532s\n",
      "\titers: 200, epoch: 14 | loss: 0.0798649\n",
      "\tspeed: 0.0115s/iter; left time: 15.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0761796 Vali Loss: 0.0765816 Test Loss: 0.0812422\n",
      "Validation loss decreased (0.076809 --> 0.076582).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803482\n",
      "\tspeed: 0.0278s/iter; left time: 34.5811s\n",
      "\titers: 200, epoch: 15 | loss: 0.0738454\n",
      "\tspeed: 0.0116s/iter; left time: 13.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0758314 Vali Loss: 0.0767500 Test Loss: 0.0811962\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800447\n",
      "\tspeed: 0.0276s/iter; left time: 28.1365s\n",
      "\titers: 200, epoch: 16 | loss: 0.0752598\n",
      "\tspeed: 0.0115s/iter; left time: 10.5840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0756317 Vali Loss: 0.0765777 Test Loss: 0.0811239\n",
      "Validation loss decreased (0.076582 --> 0.076578).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782356\n",
      "\tspeed: 0.0276s/iter; left time: 21.9743s\n",
      "\titers: 200, epoch: 17 | loss: 0.0716928\n",
      "\tspeed: 0.0115s/iter; left time: 8.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0753781 Vali Loss: 0.0766676 Test Loss: 0.0810611\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713939\n",
      "\tspeed: 0.0273s/iter; left time: 15.6425s\n",
      "\titers: 200, epoch: 18 | loss: 0.0712077\n",
      "\tspeed: 0.0115s/iter; left time: 5.4360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0751830 Vali Loss: 0.0766489 Test Loss: 0.0810038\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0750694\n",
      "\tspeed: 0.0273s/iter; left time: 9.5345s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721135\n",
      "\tspeed: 0.0116s/iter; left time: 2.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0750273 Vali Loss: 0.0766039 Test Loss: 0.0810596\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0684590\n",
      "\tspeed: 0.0278s/iter; left time: 3.4764s\n",
      "\titers: 200, epoch: 20 | loss: 0.0789137\n",
      "\tspeed: 0.0117s/iter; left time: 0.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0748275 Vali Loss: 0.0766555 Test Loss: 0.0809131\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018500106409192085, rmse:0.13601510226726532, mae:0.08112388104200363, rse:0.5142877101898193\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:49.36s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1690010\n",
      "\tspeed: 0.0333s/iter; left time: 145.3071s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379525\n",
      "\tspeed: 0.0118s/iter; left time: 50.1914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 223 | Train Loss: 0.1674818 Vali Loss: 0.1228408 Test Loss: 0.1272520\n",
      "Validation loss decreased (inf --> 0.122841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1055019\n",
      "\tspeed: 0.0284s/iter; left time: 117.4111s\n",
      "\titers: 200, epoch: 2 | loss: 0.0947789\n",
      "\tspeed: 0.0116s/iter; left time: 46.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.1046888 Vali Loss: 0.0870983 Test Loss: 0.0914740\n",
      "Validation loss decreased (0.122841 --> 0.087098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945887\n",
      "\tspeed: 0.0290s/iter; left time: 113.5805s\n",
      "\titers: 200, epoch: 3 | loss: 0.0912248\n",
      "\tspeed: 0.0116s/iter; left time: 44.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0910463 Vali Loss: 0.0845167 Test Loss: 0.0886465\n",
      "Validation loss decreased (0.087098 --> 0.084517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0890638\n",
      "\tspeed: 0.0283s/iter; left time: 104.3749s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876659\n",
      "\tspeed: 0.0116s/iter; left time: 41.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0876957 Vali Loss: 0.0838203 Test Loss: 0.0880159\n",
      "Validation loss decreased (0.084517 --> 0.083820).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888273\n",
      "\tspeed: 0.0292s/iter; left time: 101.4495s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901279\n",
      "\tspeed: 0.0118s/iter; left time: 39.9192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0858796 Vali Loss: 0.0827751 Test Loss: 0.0877248\n",
      "Validation loss decreased (0.083820 --> 0.082775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843554\n",
      "\tspeed: 0.0294s/iter; left time: 95.4344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846031\n",
      "\tspeed: 0.0117s/iter; left time: 36.6958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0846602 Vali Loss: 0.0825831 Test Loss: 0.0875698\n",
      "Validation loss decreased (0.082775 --> 0.082583).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839404\n",
      "\tspeed: 0.0290s/iter; left time: 87.5380s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820961\n",
      "\tspeed: 0.0116s/iter; left time: 33.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0836598 Vali Loss: 0.0826961 Test Loss: 0.0873808\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0833263\n",
      "\tspeed: 0.0287s/iter; left time: 80.2427s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827962\n",
      "\tspeed: 0.0117s/iter; left time: 31.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0828944 Vali Loss: 0.0821371 Test Loss: 0.0873078\n",
      "Validation loss decreased (0.082583 --> 0.082137).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822694\n",
      "\tspeed: 0.0287s/iter; left time: 74.0251s\n",
      "\titers: 200, epoch: 9 | loss: 0.0826395\n",
      "\tspeed: 0.0119s/iter; left time: 29.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0822426 Vali Loss: 0.0819558 Test Loss: 0.0873221\n",
      "Validation loss decreased (0.082137 --> 0.081956).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777007\n",
      "\tspeed: 0.0292s/iter; left time: 68.7713s\n",
      "\titers: 200, epoch: 10 | loss: 0.0856002\n",
      "\tspeed: 0.0117s/iter; left time: 26.2940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0817157 Vali Loss: 0.0821818 Test Loss: 0.0874224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795958\n",
      "\tspeed: 0.0279s/iter; left time: 59.4082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828160\n",
      "\tspeed: 0.0116s/iter; left time: 23.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0812583 Vali Loss: 0.0822034 Test Loss: 0.0871338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838655\n",
      "\tspeed: 0.0291s/iter; left time: 55.4707s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794579\n",
      "\tspeed: 0.0118s/iter; left time: 21.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0807852 Vali Loss: 0.0821391 Test Loss: 0.0870446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816532\n",
      "\tspeed: 0.0277s/iter; left time: 46.7095s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783536\n",
      "\tspeed: 0.0116s/iter; left time: 18.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0804130 Vali Loss: 0.0822525 Test Loss: 0.0869995\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825000\n",
      "\tspeed: 0.0288s/iter; left time: 42.0523s\n",
      "\titers: 200, epoch: 14 | loss: 0.0804190\n",
      "\tspeed: 0.0119s/iter; left time: 16.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0800701 Vali Loss: 0.0822010 Test Loss: 0.0872152\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020744217559695244, rmse:0.14402852952480316, mae:0.08732207864522934, rse:0.5450934767723083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1728229\n",
      "\tspeed: 0.0146s/iter; left time: 63.7496s\n",
      "\titers: 200, epoch: 1 | loss: 0.1374964\n",
      "\tspeed: 0.0119s/iter; left time: 50.6436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 223 | Train Loss: 0.1687018 Vali Loss: 0.1234342 Test Loss: 0.1279982\n",
      "Validation loss decreased (inf --> 0.123434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038418\n",
      "\tspeed: 0.0292s/iter; left time: 120.7189s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941175\n",
      "\tspeed: 0.0117s/iter; left time: 47.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.1045210 Vali Loss: 0.0871740 Test Loss: 0.0917077\n",
      "Validation loss decreased (0.123434 --> 0.087174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930343\n",
      "\tspeed: 0.0318s/iter; left time: 124.3571s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850276\n",
      "\tspeed: 0.0116s/iter; left time: 44.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0911007 Vali Loss: 0.0846023 Test Loss: 0.0887443\n",
      "Validation loss decreased (0.087174 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857418\n",
      "\tspeed: 0.0292s/iter; left time: 107.7636s\n",
      "\titers: 200, epoch: 4 | loss: 0.0871077\n",
      "\tspeed: 0.0116s/iter; left time: 41.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0878101 Vali Loss: 0.0834646 Test Loss: 0.0878316\n",
      "Validation loss decreased (0.084602 --> 0.083465).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859645\n",
      "\tspeed: 0.0285s/iter; left time: 98.7949s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848323\n",
      "\tspeed: 0.0116s/iter; left time: 38.9909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0858897 Vali Loss: 0.0828111 Test Loss: 0.0874313\n",
      "Validation loss decreased (0.083465 --> 0.082811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838870\n",
      "\tspeed: 0.0296s/iter; left time: 96.1081s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844055\n",
      "\tspeed: 0.0116s/iter; left time: 36.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0845650 Vali Loss: 0.0827209 Test Loss: 0.0872308\n",
      "Validation loss decreased (0.082811 --> 0.082721).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821112\n",
      "\tspeed: 0.0284s/iter; left time: 85.8596s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814037\n",
      "\tspeed: 0.0117s/iter; left time: 34.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0835194 Vali Loss: 0.0824771 Test Loss: 0.0871494\n",
      "Validation loss decreased (0.082721 --> 0.082477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815682\n",
      "\tspeed: 0.0284s/iter; left time: 79.4926s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851163\n",
      "\tspeed: 0.0116s/iter; left time: 31.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0827619 Vali Loss: 0.0826948 Test Loss: 0.0870347\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843730\n",
      "\tspeed: 0.0274s/iter; left time: 70.6490s\n",
      "\titers: 200, epoch: 9 | loss: 0.0853319\n",
      "\tspeed: 0.0116s/iter; left time: 28.8162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0821315 Vali Loss: 0.0826753 Test Loss: 0.0870150\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0810438\n",
      "\tspeed: 0.0278s/iter; left time: 65.4689s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787690\n",
      "\tspeed: 0.0116s/iter; left time: 26.2422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0815343 Vali Loss: 0.0824560 Test Loss: 0.0871205\n",
      "Validation loss decreased (0.082477 --> 0.082456).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0786969\n",
      "\tspeed: 0.0285s/iter; left time: 60.6654s\n",
      "\titers: 200, epoch: 11 | loss: 0.0804603\n",
      "\tspeed: 0.0119s/iter; left time: 24.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0810415 Vali Loss: 0.0826562 Test Loss: 0.0870654\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778386\n",
      "\tspeed: 0.0277s/iter; left time: 52.7735s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787151\n",
      "\tspeed: 0.0117s/iter; left time: 21.0780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0806434 Vali Loss: 0.0829397 Test Loss: 0.0868908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0840895\n",
      "\tspeed: 0.0284s/iter; left time: 47.8581s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783719\n",
      "\tspeed: 0.0119s/iter; left time: 18.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0802445 Vali Loss: 0.0827911 Test Loss: 0.0864662\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0831609\n",
      "\tspeed: 0.0281s/iter; left time: 41.0208s\n",
      "\titers: 200, epoch: 14 | loss: 0.0801993\n",
      "\tspeed: 0.0119s/iter; left time: 16.2479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0799630 Vali Loss: 0.0827387 Test Loss: 0.0868728\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797336\n",
      "\tspeed: 0.0281s/iter; left time: 34.8661s\n",
      "\titers: 200, epoch: 15 | loss: 0.0788411\n",
      "\tspeed: 0.0118s/iter; left time: 13.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0796749 Vali Loss: 0.0828900 Test Loss: 0.0868879\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02060188353061676, rmse:0.14353355765342712, mae:0.08712054044008255, rse:0.5432202219963074\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:07.05s\n",
      "Intermediate time for IT: 00h:07m:39.07s\n",
      "Total time: 00h:38m:29.16s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0211  0.1452  0.0882\n",
       "        96         0.0377  0.1940  0.1280\n",
       "        168        0.0397  0.1991  0.1350\n",
       "ES      24         0.0100  0.0998  0.0604\n",
       "        96         0.0188  0.1370  0.0878\n",
       "        168        0.0210  0.1451  0.0936\n",
       "FR      24         0.0102  0.1010  0.0559\n",
       "        96         0.0192  0.1384  0.0810\n",
       "        168        0.0205  0.1432  0.0862\n",
       "GB      24         0.0257  0.1603  0.1008\n",
       "        96         0.0430  0.2074  0.1414\n",
       "        168        0.0455  0.2134  0.1478\n",
       "IT      24         0.0102  0.1010  0.0574\n",
       "        96         0.0184  0.1358  0.0811\n",
       "        168        0.0207  0.1438  0.0872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1373355\n",
      "\tspeed: 0.0457s/iter; left time: 199.3868s\n",
      "\titers: 200, epoch: 1 | loss: 0.1334118\n",
      "\tspeed: 0.0249s/iter; left time: 106.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.1453993 Vali Loss: 0.1329783 Test Loss: 0.1404441\n",
      "Validation loss decreased (inf --> 0.132978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888796\n",
      "\tspeed: 0.0490s/iter; left time: 202.8774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0831336\n",
      "\tspeed: 0.0249s/iter; left time: 100.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0907415 Vali Loss: 0.0933192 Test Loss: 0.0952993\n",
      "Validation loss decreased (0.132978 --> 0.093319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792083\n",
      "\tspeed: 0.0500s/iter; left time: 195.7325s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782485\n",
      "\tspeed: 0.0250s/iter; left time: 95.4262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0800919 Vali Loss: 0.0906347 Test Loss: 0.0927831\n",
      "Validation loss decreased (0.093319 --> 0.090635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760983\n",
      "\tspeed: 0.0495s/iter; left time: 182.8128s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804803\n",
      "\tspeed: 0.0250s/iter; left time: 89.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0776514 Vali Loss: 0.0891426 Test Loss: 0.0911534\n",
      "Validation loss decreased (0.090635 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0731426\n",
      "\tspeed: 0.0497s/iter; left time: 172.4770s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730842\n",
      "\tspeed: 0.0250s/iter; left time: 84.1632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0762323 Vali Loss: 0.0887006 Test Loss: 0.0911575\n",
      "Validation loss decreased (0.089143 --> 0.088701).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770437\n",
      "\tspeed: 0.0499s/iter; left time: 161.9939s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688699\n",
      "\tspeed: 0.0250s/iter; left time: 78.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0752050 Vali Loss: 0.0875822 Test Loss: 0.0899144\n",
      "Validation loss decreased (0.088701 --> 0.087582).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776841\n",
      "\tspeed: 0.0497s/iter; left time: 150.2287s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760563\n",
      "\tspeed: 0.0250s/iter; left time: 73.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0744924 Vali Loss: 0.0878255 Test Loss: 0.0900309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724099\n",
      "\tspeed: 0.0491s/iter; left time: 137.3829s\n",
      "\titers: 200, epoch: 8 | loss: 0.0770502\n",
      "\tspeed: 0.0251s/iter; left time: 67.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0739047 Vali Loss: 0.0875601 Test Loss: 0.0895829\n",
      "Validation loss decreased (0.087582 --> 0.087560).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0735691\n",
      "\tspeed: 0.0490s/iter; left time: 126.1622s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746017\n",
      "\tspeed: 0.0250s/iter; left time: 61.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0733632 Vali Loss: 0.0873396 Test Loss: 0.0894276\n",
      "Validation loss decreased (0.087560 --> 0.087340).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712517\n",
      "\tspeed: 0.0490s/iter; left time: 115.4570s\n",
      "\titers: 200, epoch: 10 | loss: 0.0719973\n",
      "\tspeed: 0.0250s/iter; left time: 56.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0730056 Vali Loss: 0.0871200 Test Loss: 0.0890380\n",
      "Validation loss decreased (0.087340 --> 0.087120).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736760\n",
      "\tspeed: 0.0492s/iter; left time: 104.7781s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749013\n",
      "\tspeed: 0.0250s/iter; left time: 50.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0726510 Vali Loss: 0.0867601 Test Loss: 0.0890658\n",
      "Validation loss decreased (0.087120 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733816\n",
      "\tspeed: 0.0490s/iter; left time: 93.5557s\n",
      "\titers: 200, epoch: 12 | loss: 0.0710724\n",
      "\tspeed: 0.0250s/iter; left time: 45.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0723448 Vali Loss: 0.0869641 Test Loss: 0.0890288\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775656\n",
      "\tspeed: 0.0488s/iter; left time: 82.2093s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687345\n",
      "\tspeed: 0.0251s/iter; left time: 39.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0720741 Vali Loss: 0.0867219 Test Loss: 0.0888413\n",
      "Validation loss decreased (0.086760 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752403\n",
      "\tspeed: 0.0490s/iter; left time: 71.6950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746249\n",
      "\tspeed: 0.0250s/iter; left time: 34.0516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0718593 Vali Loss: 0.0864101 Test Loss: 0.0884662\n",
      "Validation loss decreased (0.086722 --> 0.086410).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0715580\n",
      "\tspeed: 0.0493s/iter; left time: 61.0501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659076\n",
      "\tspeed: 0.0250s/iter; left time: 28.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0717240 Vali Loss: 0.0864764 Test Loss: 0.0888205\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0784111\n",
      "\tspeed: 0.0491s/iter; left time: 49.9073s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652250\n",
      "\tspeed: 0.0250s/iter; left time: 22.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0714541 Vali Loss: 0.0865088 Test Loss: 0.0888026\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695369\n",
      "\tspeed: 0.0496s/iter; left time: 39.3088s\n",
      "\titers: 200, epoch: 17 | loss: 0.0679761\n",
      "\tspeed: 0.0250s/iter; left time: 17.3283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0713016 Vali Loss: 0.0866600 Test Loss: 0.0888405\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0707704\n",
      "\tspeed: 0.0490s/iter; left time: 27.9288s\n",
      "\titers: 200, epoch: 18 | loss: 0.0674867\n",
      "\tspeed: 0.0250s/iter; left time: 11.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0711602 Vali Loss: 0.0860936 Test Loss: 0.0882517\n",
      "Validation loss decreased (0.086410 --> 0.086094).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734340\n",
      "\tspeed: 0.0497s/iter; left time: 17.2329s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713441\n",
      "\tspeed: 0.0249s/iter; left time: 6.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0710292 Vali Loss: 0.0862774 Test Loss: 0.0884907\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0644633\n",
      "\tspeed: 0.0489s/iter; left time: 6.0581s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701132\n",
      "\tspeed: 0.0250s/iter; left time: 0.5993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0709714 Vali Loss: 0.0861165 Test Loss: 0.0884363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02113972045481205, rmse:0.14539505541324615, mae:0.08825169503688812, rse:0.5131192803382874\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1387260\n",
      "\tspeed: 0.0268s/iter; left time: 116.8880s\n",
      "\titers: 200, epoch: 1 | loss: 0.1324830\n",
      "\tspeed: 0.0249s/iter; left time: 106.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.1422265 Vali Loss: 0.1323882 Test Loss: 0.1402231\n",
      "Validation loss decreased (inf --> 0.132388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0881633\n",
      "\tspeed: 0.0490s/iter; left time: 202.8462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0869370\n",
      "\tspeed: 0.0251s/iter; left time: 101.2003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0903240 Vali Loss: 0.0937527 Test Loss: 0.0951589\n",
      "Validation loss decreased (0.132388 --> 0.093753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821824\n",
      "\tspeed: 0.0491s/iter; left time: 192.3118s\n",
      "\titers: 200, epoch: 3 | loss: 0.0797993\n",
      "\tspeed: 0.0251s/iter; left time: 95.6078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0801487 Vali Loss: 0.0902874 Test Loss: 0.0924725\n",
      "Validation loss decreased (0.093753 --> 0.090287).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0778300\n",
      "\tspeed: 0.0487s/iter; left time: 179.8589s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749223\n",
      "\tspeed: 0.0249s/iter; left time: 89.5862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0775661 Vali Loss: 0.0892974 Test Loss: 0.0914376\n",
      "Validation loss decreased (0.090287 --> 0.089297).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769507\n",
      "\tspeed: 0.0489s/iter; left time: 169.6334s\n",
      "\titers: 200, epoch: 5 | loss: 0.0768380\n",
      "\tspeed: 0.0249s/iter; left time: 84.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0760782 Vali Loss: 0.0889501 Test Loss: 0.0910797\n",
      "Validation loss decreased (0.089297 --> 0.088950).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768618\n",
      "\tspeed: 0.0494s/iter; left time: 160.4455s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756993\n",
      "\tspeed: 0.0250s/iter; left time: 78.6890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0750654 Vali Loss: 0.0880747 Test Loss: 0.0902579\n",
      "Validation loss decreased (0.088950 --> 0.088075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731461\n",
      "\tspeed: 0.0501s/iter; left time: 151.4604s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774921\n",
      "\tspeed: 0.0250s/iter; left time: 73.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0742952 Vali Loss: 0.0876327 Test Loss: 0.0900111\n",
      "Validation loss decreased (0.088075 --> 0.087633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776454\n",
      "\tspeed: 0.0518s/iter; left time: 144.9353s\n",
      "\titers: 200, epoch: 8 | loss: 0.0741013\n",
      "\tspeed: 0.0250s/iter; left time: 67.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0737748 Vali Loss: 0.0873966 Test Loss: 0.0896094\n",
      "Validation loss decreased (0.087633 --> 0.087397).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758426\n",
      "\tspeed: 0.0503s/iter; left time: 129.5705s\n",
      "\titers: 200, epoch: 9 | loss: 0.0721907\n",
      "\tspeed: 0.0252s/iter; left time: 62.3020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0733159 Vali Loss: 0.0870264 Test Loss: 0.0894529\n",
      "Validation loss decreased (0.087397 --> 0.087026).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0737975\n",
      "\tspeed: 0.0514s/iter; left time: 120.9728s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756847\n",
      "\tspeed: 0.0250s/iter; left time: 56.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0729094 Vali Loss: 0.0873865 Test Loss: 0.0895283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0738934\n",
      "\tspeed: 0.0485s/iter; left time: 103.3111s\n",
      "\titers: 200, epoch: 11 | loss: 0.0704107\n",
      "\tspeed: 0.0250s/iter; left time: 50.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0726011 Vali Loss: 0.0867967 Test Loss: 0.0889862\n",
      "Validation loss decreased (0.087026 --> 0.086797).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0739036\n",
      "\tspeed: 0.0503s/iter; left time: 96.0113s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699825\n",
      "\tspeed: 0.0253s/iter; left time: 45.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0722698 Vali Loss: 0.0866896 Test Loss: 0.0890082\n",
      "Validation loss decreased (0.086797 --> 0.086690).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0681471\n",
      "\tspeed: 0.0503s/iter; left time: 84.6751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0717300\n",
      "\tspeed: 0.0250s/iter; left time: 39.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0720004 Vali Loss: 0.0864829 Test Loss: 0.0886948\n",
      "Validation loss decreased (0.086690 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715130\n",
      "\tspeed: 0.0492s/iter; left time: 71.8976s\n",
      "\titers: 200, epoch: 14 | loss: 0.0686836\n",
      "\tspeed: 0.0251s/iter; left time: 34.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0717527 Vali Loss: 0.0866668 Test Loss: 0.0888871\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0708634\n",
      "\tspeed: 0.0487s/iter; left time: 60.2789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0683472\n",
      "\tspeed: 0.0250s/iter; left time: 28.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0716079 Vali Loss: 0.0864506 Test Loss: 0.0887673\n",
      "Validation loss decreased (0.086483 --> 0.086451).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0710361\n",
      "\tspeed: 0.0494s/iter; left time: 50.2099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0785230\n",
      "\tspeed: 0.0249s/iter; left time: 22.8512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0714277 Vali Loss: 0.0864223 Test Loss: 0.0885017\n",
      "Validation loss decreased (0.086451 --> 0.086422).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653563\n",
      "\tspeed: 0.0491s/iter; left time: 38.9623s\n",
      "\titers: 200, epoch: 17 | loss: 0.0704447\n",
      "\tspeed: 0.0250s/iter; left time: 17.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0712278 Vali Loss: 0.0865197 Test Loss: 0.0885296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662463\n",
      "\tspeed: 0.0486s/iter; left time: 27.7158s\n",
      "\titers: 200, epoch: 18 | loss: 0.0720317\n",
      "\tspeed: 0.0249s/iter; left time: 11.7161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0711606 Vali Loss: 0.0865448 Test Loss: 0.0887078\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693354\n",
      "\tspeed: 0.0493s/iter; left time: 17.0970s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727959\n",
      "\tspeed: 0.0250s/iter; left time: 6.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0710075 Vali Loss: 0.0861939 Test Loss: 0.0884476\n",
      "Validation loss decreased (0.086422 --> 0.086194).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0703969\n",
      "\tspeed: 0.0490s/iter; left time: 6.0740s\n",
      "\titers: 200, epoch: 20 | loss: 0.0697241\n",
      "\tspeed: 0.0250s/iter; left time: 0.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0709244 Vali Loss: 0.0862467 Test Loss: 0.0884698\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021096836775541306, rmse:0.14524750411510468, mae:0.08844760060310364, rse:0.5125985145568848\n",
      "Intermediate time for DE and pred_len 24: 00h:05m:07.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1524197\n",
      "\tspeed: 0.0463s/iter; left time: 200.8558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375952\n",
      "\tspeed: 0.0253s/iter; left time: 107.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.1509252 Vali Loss: 0.1419280 Test Loss: 0.1509789\n",
      "Validation loss decreased (inf --> 0.141928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138061\n",
      "\tspeed: 0.0503s/iter; left time: 207.1054s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108992\n",
      "\tspeed: 0.0252s/iter; left time: 101.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1142543 Vali Loss: 0.1206686 Test Loss: 0.1282206\n",
      "Validation loss decreased (0.141928 --> 0.120669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041095\n",
      "\tspeed: 0.0496s/iter; left time: 193.4045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048442\n",
      "\tspeed: 0.0251s/iter; left time: 95.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1059201 Vali Loss: 0.1185557 Test Loss: 0.1270821\n",
      "Validation loss decreased (0.120669 --> 0.118556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1051723\n",
      "\tspeed: 0.0495s/iter; left time: 181.8689s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051609\n",
      "\tspeed: 0.0252s/iter; left time: 89.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1039714 Vali Loss: 0.1180957 Test Loss: 0.1273423\n",
      "Validation loss decreased (0.118556 --> 0.118096).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1021679\n",
      "\tspeed: 0.0497s/iter; left time: 171.6917s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999732\n",
      "\tspeed: 0.0252s/iter; left time: 84.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1025546 Vali Loss: 0.1181811 Test Loss: 0.1268808\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1011426\n",
      "\tspeed: 0.0488s/iter; left time: 157.7509s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999946\n",
      "\tspeed: 0.0252s/iter; left time: 78.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.1014402 Vali Loss: 0.1177357 Test Loss: 0.1269181\n",
      "Validation loss decreased (0.118096 --> 0.117736).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005419\n",
      "\tspeed: 0.0500s/iter; left time: 150.3295s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978059\n",
      "\tspeed: 0.0253s/iter; left time: 73.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1004559 Vali Loss: 0.1176819 Test Loss: 0.1281645\n",
      "Validation loss decreased (0.117736 --> 0.117682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985050\n",
      "\tspeed: 0.0494s/iter; left time: 137.7020s\n",
      "\titers: 200, epoch: 8 | loss: 0.1038893\n",
      "\tspeed: 0.0251s/iter; left time: 67.4332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.0995783 Vali Loss: 0.1171959 Test Loss: 0.1264225\n",
      "Validation loss decreased (0.117682 --> 0.117196).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951688\n",
      "\tspeed: 0.0518s/iter; left time: 132.9921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956111\n",
      "\tspeed: 0.0251s/iter; left time: 61.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0988268 Vali Loss: 0.1174052 Test Loss: 0.1277224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954819\n",
      "\tspeed: 0.0488s/iter; left time: 114.3995s\n",
      "\titers: 200, epoch: 10 | loss: 0.1034079\n",
      "\tspeed: 0.0251s/iter; left time: 56.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.0981092 Vali Loss: 0.1172850 Test Loss: 0.1271868\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022108\n",
      "\tspeed: 0.0490s/iter; left time: 103.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883767\n",
      "\tspeed: 0.0251s/iter; left time: 50.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 222 | Train Loss: 0.0974056 Vali Loss: 0.1178961 Test Loss: 0.1278977\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1006592\n",
      "\tspeed: 0.0498s/iter; left time: 94.6347s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967516\n",
      "\tspeed: 0.0251s/iter; left time: 45.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0967342 Vali Loss: 0.1180168 Test Loss: 0.1285491\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893896\n",
      "\tspeed: 0.0501s/iter; left time: 83.9550s\n",
      "\titers: 200, epoch: 13 | loss: 0.1023085\n",
      "\tspeed: 0.0253s/iter; left time: 39.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.0962980 Vali Loss: 0.1178484 Test Loss: 0.1280199\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03628804534673691, rmse:0.19049420952796936, mae:0.12642250955104828, rse:0.6745785474777222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1509143\n",
      "\tspeed: 0.0274s/iter; left time: 118.8341s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396052\n",
      "\tspeed: 0.0254s/iter; left time: 107.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1545742 Vali Loss: 0.1438320 Test Loss: 0.1527672\n",
      "Validation loss decreased (inf --> 0.143832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1096659\n",
      "\tspeed: 0.0518s/iter; left time: 213.1952s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083580\n",
      "\tspeed: 0.0252s/iter; left time: 101.4405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1146843 Vali Loss: 0.1206286 Test Loss: 0.1288152\n",
      "Validation loss decreased (0.143832 --> 0.120629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055950\n",
      "\tspeed: 0.0504s/iter; left time: 196.4441s\n",
      "\titers: 200, epoch: 3 | loss: 0.1063335\n",
      "\tspeed: 0.0252s/iter; left time: 95.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.1061741 Vali Loss: 0.1190469 Test Loss: 0.1273288\n",
      "Validation loss decreased (0.120629 --> 0.119047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1054941\n",
      "\tspeed: 0.0561s/iter; left time: 206.0017s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054156\n",
      "\tspeed: 0.0254s/iter; left time: 90.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1037878 Vali Loss: 0.1172908 Test Loss: 0.1273427\n",
      "Validation loss decreased (0.119047 --> 0.117291).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1014776\n",
      "\tspeed: 0.0519s/iter; left time: 179.1725s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076194\n",
      "\tspeed: 0.0252s/iter; left time: 84.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1022845 Vali Loss: 0.1175373 Test Loss: 0.1275375\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0997480\n",
      "\tspeed: 0.0503s/iter; left time: 162.4067s\n",
      "\titers: 200, epoch: 6 | loss: 0.1095149\n",
      "\tspeed: 0.0252s/iter; left time: 79.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 222 | Train Loss: 0.1011955 Vali Loss: 0.1171618 Test Loss: 0.1267175\n",
      "Validation loss decreased (0.117291 --> 0.117162).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0976854\n",
      "\tspeed: 0.0517s/iter; left time: 155.5617s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983340\n",
      "\tspeed: 0.0253s/iter; left time: 73.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1003771 Vali Loss: 0.1167987 Test Loss: 0.1267028\n",
      "Validation loss decreased (0.117162 --> 0.116799).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997622\n",
      "\tspeed: 0.0506s/iter; left time: 141.0098s\n",
      "\titers: 200, epoch: 8 | loss: 0.0992231\n",
      "\tspeed: 0.0253s/iter; left time: 68.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 222 | Train Loss: 0.0996266 Vali Loss: 0.1171689 Test Loss: 0.1272052\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1002065\n",
      "\tspeed: 0.0502s/iter; left time: 128.6977s\n",
      "\titers: 200, epoch: 9 | loss: 0.0960183\n",
      "\tspeed: 0.0253s/iter; left time: 62.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.0989336 Vali Loss: 0.1171821 Test Loss: 0.1277008\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0958978\n",
      "\tspeed: 0.0498s/iter; left time: 116.7292s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998627\n",
      "\tspeed: 0.0253s/iter; left time: 56.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0983088 Vali Loss: 0.1171546 Test Loss: 0.1274462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0966632\n",
      "\tspeed: 0.0504s/iter; left time: 106.9843s\n",
      "\titers: 200, epoch: 11 | loss: 0.0963016\n",
      "\tspeed: 0.0253s/iter; left time: 51.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0978272 Vali Loss: 0.1172742 Test Loss: 0.1275713\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0967989\n",
      "\tspeed: 0.0511s/iter; left time: 97.0387s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002217\n",
      "\tspeed: 0.0253s/iter; left time: 45.4362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0971994 Vali Loss: 0.1176822 Test Loss: 0.1279267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03638647496700287, rmse:0.19075238704681396, mae:0.12670288980007172, rse:0.6754928231239319\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:20.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1490380\n",
      "\tspeed: 0.0470s/iter; left time: 203.9462s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348439\n",
      "\tspeed: 0.0256s/iter; left time: 108.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 222 | Train Loss: 0.1536819 Vali Loss: 0.1435488 Test Loss: 0.1536387\n",
      "Validation loss decreased (inf --> 0.143549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156273\n",
      "\tspeed: 0.0513s/iter; left time: 211.1736s\n",
      "\titers: 200, epoch: 2 | loss: 0.1153742\n",
      "\tspeed: 0.0255s/iter; left time: 102.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1194604 Vali Loss: 0.1243052 Test Loss: 0.1335621\n",
      "Validation loss decreased (0.143549 --> 0.124305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091914\n",
      "\tspeed: 0.0512s/iter; left time: 199.5210s\n",
      "\titers: 200, epoch: 3 | loss: 0.1107274\n",
      "\tspeed: 0.0254s/iter; left time: 96.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1114915 Vali Loss: 0.1228457 Test Loss: 0.1317932\n",
      "Validation loss decreased (0.124305 --> 0.122846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125002\n",
      "\tspeed: 0.0513s/iter; left time: 188.5952s\n",
      "\titers: 200, epoch: 4 | loss: 0.1050300\n",
      "\tspeed: 0.0255s/iter; left time: 90.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1093076 Vali Loss: 0.1216234 Test Loss: 0.1328400\n",
      "Validation loss decreased (0.122846 --> 0.121623).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088410\n",
      "\tspeed: 0.0512s/iter; left time: 176.8172s\n",
      "\titers: 200, epoch: 5 | loss: 0.1082159\n",
      "\tspeed: 0.0254s/iter; left time: 85.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1076152 Vali Loss: 0.1219271 Test Loss: 0.1323917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080438\n",
      "\tspeed: 0.0508s/iter; left time: 164.0521s\n",
      "\titers: 200, epoch: 6 | loss: 0.1060845\n",
      "\tspeed: 0.0255s/iter; left time: 79.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1063124 Vali Loss: 0.1223658 Test Loss: 0.1331617\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041891\n",
      "\tspeed: 0.0511s/iter; left time: 153.7708s\n",
      "\titers: 200, epoch: 7 | loss: 0.1084695\n",
      "\tspeed: 0.0256s/iter; left time: 74.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1050821 Vali Loss: 0.1230205 Test Loss: 0.1332460\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057436\n",
      "\tspeed: 0.0510s/iter; left time: 142.0456s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041152\n",
      "\tspeed: 0.0255s/iter; left time: 68.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.1038863 Vali Loss: 0.1226599 Test Loss: 0.1340252\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044045\n",
      "\tspeed: 0.0508s/iter; left time: 130.3976s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016497\n",
      "\tspeed: 0.0255s/iter; left time: 62.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1028623 Vali Loss: 0.1233028 Test Loss: 0.1341052\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03833557665348053, rmse:0.1957947313785553, mae:0.13283993303775787, rse:0.6935206651687622\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1512634\n",
      "\tspeed: 0.0277s/iter; left time: 120.3187s\n",
      "\titers: 200, epoch: 1 | loss: 0.1386232\n",
      "\tspeed: 0.0256s/iter; left time: 108.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1542056 Vali Loss: 0.1439728 Test Loss: 0.1536107\n",
      "Validation loss decreased (inf --> 0.143973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1199878\n",
      "\tspeed: 0.0519s/iter; left time: 213.8710s\n",
      "\titers: 200, epoch: 2 | loss: 0.1082336\n",
      "\tspeed: 0.0255s/iter; left time: 102.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1194501 Vali Loss: 0.1245349 Test Loss: 0.1338168\n",
      "Validation loss decreased (0.143973 --> 0.124535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146913\n",
      "\tspeed: 0.0517s/iter; left time: 201.5605s\n",
      "\titers: 200, epoch: 3 | loss: 0.1125843\n",
      "\tspeed: 0.0254s/iter; left time: 96.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1114812 Vali Loss: 0.1228653 Test Loss: 0.1336787\n",
      "Validation loss decreased (0.124535 --> 0.122865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086331\n",
      "\tspeed: 0.0554s/iter; left time: 203.6868s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056447\n",
      "\tspeed: 0.0256s/iter; left time: 91.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1090843 Vali Loss: 0.1226171 Test Loss: 0.1336725\n",
      "Validation loss decreased (0.122865 --> 0.122617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1079249\n",
      "\tspeed: 0.0526s/iter; left time: 181.7254s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057752\n",
      "\tspeed: 0.0255s/iter; left time: 85.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1075889 Vali Loss: 0.1217376 Test Loss: 0.1339359\n",
      "Validation loss decreased (0.122617 --> 0.121738).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1065142\n",
      "\tspeed: 0.0538s/iter; left time: 173.7805s\n",
      "\titers: 200, epoch: 6 | loss: 0.1090356\n",
      "\tspeed: 0.0256s/iter; left time: 80.2195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1062648 Vali Loss: 0.1221878 Test Loss: 0.1343143\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1081868\n",
      "\tspeed: 0.0520s/iter; left time: 156.4754s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031092\n",
      "\tspeed: 0.0257s/iter; left time: 74.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1050724 Vali Loss: 0.1228293 Test Loss: 0.1336516\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039568\n",
      "\tspeed: 0.0517s/iter; left time: 144.1828s\n",
      "\titers: 200, epoch: 8 | loss: 0.1012034\n",
      "\tspeed: 0.0256s/iter; left time: 68.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1039466 Vali Loss: 0.1221145 Test Loss: 0.1339977\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027512\n",
      "\tspeed: 0.0520s/iter; left time: 133.3644s\n",
      "\titers: 200, epoch: 9 | loss: 0.1043352\n",
      "\tspeed: 0.0256s/iter; left time: 63.2072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.1029358 Vali Loss: 0.1227088 Test Loss: 0.1333162\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035414\n",
      "\tspeed: 0.0516s/iter; left time: 120.9529s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019643\n",
      "\tspeed: 0.0255s/iter; left time: 57.1356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1019297 Vali Loss: 0.1230178 Test Loss: 0.1333210\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03888119384646416, rmse:0.19718314707279205, mae:0.13393597304821014, rse:0.6984385848045349\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:39.41s\n",
      "Intermediate time for DE: 00h:11m:06.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248104\n",
      "\tspeed: 0.0477s/iter; left time: 207.8651s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189683\n",
      "\tspeed: 0.0249s/iter; left time: 106.1931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.1320080 Vali Loss: 0.1245858 Test Loss: 0.1461386\n",
      "Validation loss decreased (inf --> 0.124586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871835\n",
      "\tspeed: 0.0502s/iter; left time: 207.8396s\n",
      "\titers: 200, epoch: 2 | loss: 0.0825444\n",
      "\tspeed: 0.0249s/iter; left time: 100.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0873957 Vali Loss: 0.0911867 Test Loss: 0.1036528\n",
      "Validation loss decreased (0.124586 --> 0.091187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829440\n",
      "\tspeed: 0.0492s/iter; left time: 192.6282s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811696\n",
      "\tspeed: 0.0249s/iter; left time: 94.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0794493 Vali Loss: 0.0906464 Test Loss: 0.1034824\n",
      "Validation loss decreased (0.091187 --> 0.090646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736907\n",
      "\tspeed: 0.0496s/iter; left time: 183.1612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760392\n",
      "\tspeed: 0.0249s/iter; left time: 89.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0779166 Vali Loss: 0.0895404 Test Loss: 0.1021740\n",
      "Validation loss decreased (0.090646 --> 0.089540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748423\n",
      "\tspeed: 0.0495s/iter; left time: 171.6201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785504\n",
      "\tspeed: 0.0249s/iter; left time: 83.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0768613 Vali Loss: 0.0893269 Test Loss: 0.1015313\n",
      "Validation loss decreased (0.089540 --> 0.089327).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773457\n",
      "\tspeed: 0.0493s/iter; left time: 159.9414s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689240\n",
      "\tspeed: 0.0249s/iter; left time: 78.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0760901 Vali Loss: 0.0886091 Test Loss: 0.1013818\n",
      "Validation loss decreased (0.089327 --> 0.088609).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797589\n",
      "\tspeed: 0.0497s/iter; left time: 150.3662s\n",
      "\titers: 200, epoch: 7 | loss: 0.0784155\n",
      "\tspeed: 0.0250s/iter; left time: 73.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0755444 Vali Loss: 0.0884675 Test Loss: 0.1010676\n",
      "Validation loss decreased (0.088609 --> 0.088467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801681\n",
      "\tspeed: 0.0492s/iter; left time: 137.7477s\n",
      "\titers: 200, epoch: 8 | loss: 0.0736745\n",
      "\tspeed: 0.0250s/iter; left time: 67.3720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0749900 Vali Loss: 0.0884748 Test Loss: 0.1007913\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.0493s/iter; left time: 127.0295s\n",
      "\titers: 200, epoch: 9 | loss: 0.0762836\n",
      "\tspeed: 0.0251s/iter; left time: 62.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0746327 Vali Loss: 0.0882159 Test Loss: 0.1009664\n",
      "Validation loss decreased (0.088467 --> 0.088216).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769711\n",
      "\tspeed: 0.0504s/iter; left time: 118.5537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704211\n",
      "\tspeed: 0.0252s/iter; left time: 56.7280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0743007 Vali Loss: 0.0878040 Test Loss: 0.1006743\n",
      "Validation loss decreased (0.088216 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712703\n",
      "\tspeed: 0.0499s/iter; left time: 106.3984s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745102\n",
      "\tspeed: 0.0250s/iter; left time: 50.8021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0739317 Vali Loss: 0.0876703 Test Loss: 0.1006999\n",
      "Validation loss decreased (0.087804 --> 0.087670).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710412\n",
      "\tspeed: 0.0497s/iter; left time: 94.7622s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782618\n",
      "\tspeed: 0.0250s/iter; left time: 45.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0736354 Vali Loss: 0.0876544 Test Loss: 0.1004437\n",
      "Validation loss decreased (0.087670 --> 0.087654).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783196\n",
      "\tspeed: 0.0497s/iter; left time: 83.7753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716469\n",
      "\tspeed: 0.0252s/iter; left time: 39.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0734116 Vali Loss: 0.0879656 Test Loss: 0.1002505\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0729655\n",
      "\tspeed: 0.0486s/iter; left time: 71.0545s\n",
      "\titers: 200, epoch: 14 | loss: 0.0741272\n",
      "\tspeed: 0.0250s/iter; left time: 34.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0731876 Vali Loss: 0.0877671 Test Loss: 0.1007679\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0784120\n",
      "\tspeed: 0.0492s/iter; left time: 60.9394s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713894\n",
      "\tspeed: 0.0250s/iter; left time: 28.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0730301 Vali Loss: 0.0874009 Test Loss: 0.1004193\n",
      "Validation loss decreased (0.087654 --> 0.087401).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0752648\n",
      "\tspeed: 0.0504s/iter; left time: 51.2257s\n",
      "\titers: 200, epoch: 16 | loss: 0.0692569\n",
      "\tspeed: 0.0251s/iter; left time: 22.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0728606 Vali Loss: 0.0875206 Test Loss: 0.0998576\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0696480\n",
      "\tspeed: 0.0496s/iter; left time: 39.3573s\n",
      "\titers: 200, epoch: 17 | loss: 0.0696990\n",
      "\tspeed: 0.0251s/iter; left time: 17.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0727070 Vali Loss: 0.0874191 Test Loss: 0.1002236\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680822\n",
      "\tspeed: 0.0489s/iter; left time: 27.8962s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788060\n",
      "\tspeed: 0.0250s/iter; left time: 11.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0725290 Vali Loss: 0.0875011 Test Loss: 0.1004622\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758588\n",
      "\tspeed: 0.0493s/iter; left time: 17.1204s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707837\n",
      "\tspeed: 0.0250s/iter; left time: 6.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0724507 Vali Loss: 0.0874077 Test Loss: 0.1003668\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709867\n",
      "\tspeed: 0.0490s/iter; left time: 6.0732s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729043\n",
      "\tspeed: 0.0251s/iter; left time: 0.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0723412 Vali Loss: 0.0872065 Test Loss: 0.0999682\n",
      "Validation loss decreased (0.087401 --> 0.087207).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02504582144320011, rmse:0.15825872123241425, mae:0.09996816515922546, rse:0.5459477305412292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1294611\n",
      "\tspeed: 0.0271s/iter; left time: 118.1447s\n",
      "\titers: 200, epoch: 1 | loss: 0.1205135\n",
      "\tspeed: 0.0250s/iter; left time: 106.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.1303674 Vali Loss: 0.1248064 Test Loss: 0.1454734\n",
      "Validation loss decreased (inf --> 0.124806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0866117\n",
      "\tspeed: 0.0500s/iter; left time: 207.1024s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824038\n",
      "\tspeed: 0.0252s/iter; left time: 101.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0872526 Vali Loss: 0.0912432 Test Loss: 0.1033538\n",
      "Validation loss decreased (0.124806 --> 0.091243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0770556\n",
      "\tspeed: 0.0501s/iter; left time: 196.0652s\n",
      "\titers: 200, epoch: 3 | loss: 0.0759367\n",
      "\tspeed: 0.0251s/iter; left time: 95.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0795269 Vali Loss: 0.0903121 Test Loss: 0.1026443\n",
      "Validation loss decreased (0.091243 --> 0.090312).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0794817\n",
      "\tspeed: 0.0503s/iter; left time: 185.8143s\n",
      "\titers: 200, epoch: 4 | loss: 0.0725037\n",
      "\tspeed: 0.0250s/iter; left time: 89.7171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0779244 Vali Loss: 0.0894066 Test Loss: 0.1028099\n",
      "Validation loss decreased (0.090312 --> 0.089407).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0751133\n",
      "\tspeed: 0.0501s/iter; left time: 173.9664s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759372\n",
      "\tspeed: 0.0252s/iter; left time: 84.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0767845 Vali Loss: 0.0892266 Test Loss: 0.1017113\n",
      "Validation loss decreased (0.089407 --> 0.089227).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793913\n",
      "\tspeed: 0.0499s/iter; left time: 161.8157s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791184\n",
      "\tspeed: 0.0250s/iter; left time: 78.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0760865 Vali Loss: 0.0890232 Test Loss: 0.1013097\n",
      "Validation loss decreased (0.089227 --> 0.089023).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772553\n",
      "\tspeed: 0.0491s/iter; left time: 148.4508s\n",
      "\titers: 200, epoch: 7 | loss: 0.0757662\n",
      "\tspeed: 0.0249s/iter; left time: 72.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0754369 Vali Loss: 0.0883436 Test Loss: 0.1013570\n",
      "Validation loss decreased (0.089023 --> 0.088344).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0808531\n",
      "\tspeed: 0.0492s/iter; left time: 137.6462s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733330\n",
      "\tspeed: 0.0251s/iter; left time: 67.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0749820 Vali Loss: 0.0884141 Test Loss: 0.1013714\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805251\n",
      "\tspeed: 0.0490s/iter; left time: 126.3493s\n",
      "\titers: 200, epoch: 9 | loss: 0.0774776\n",
      "\tspeed: 0.0250s/iter; left time: 61.8244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0745466 Vali Loss: 0.0880825 Test Loss: 0.1015604\n",
      "Validation loss decreased (0.088344 --> 0.088082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799305\n",
      "\tspeed: 0.0504s/iter; left time: 118.6181s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753193\n",
      "\tspeed: 0.0252s/iter; left time: 56.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0742156 Vali Loss: 0.0882399 Test Loss: 0.1005099\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0748022\n",
      "\tspeed: 0.0501s/iter; left time: 106.7275s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708263\n",
      "\tspeed: 0.0250s/iter; left time: 50.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0738708 Vali Loss: 0.0879598 Test Loss: 0.1008806\n",
      "Validation loss decreased (0.088082 --> 0.087960).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710602\n",
      "\tspeed: 0.0488s/iter; left time: 93.0726s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746384\n",
      "\tspeed: 0.0249s/iter; left time: 45.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0736211 Vali Loss: 0.0879124 Test Loss: 0.1001388\n",
      "Validation loss decreased (0.087960 --> 0.087912).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0735792\n",
      "\tspeed: 0.0508s/iter; left time: 85.6758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0734467\n",
      "\tspeed: 0.0249s/iter; left time: 39.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0733581 Vali Loss: 0.0879119 Test Loss: 0.1007672\n",
      "Validation loss decreased (0.087912 --> 0.087912).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709326\n",
      "\tspeed: 0.0494s/iter; left time: 72.2768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794831\n",
      "\tspeed: 0.0250s/iter; left time: 34.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0731631 Vali Loss: 0.0879339 Test Loss: 0.1001540\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0708378\n",
      "\tspeed: 0.0497s/iter; left time: 61.5561s\n",
      "\titers: 200, epoch: 15 | loss: 0.0727752\n",
      "\tspeed: 0.0249s/iter; left time: 28.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0729571 Vali Loss: 0.0874541 Test Loss: 0.1003712\n",
      "Validation loss decreased (0.087912 --> 0.087454).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0687091\n",
      "\tspeed: 0.0491s/iter; left time: 49.9321s\n",
      "\titers: 200, epoch: 16 | loss: 0.0780086\n",
      "\tspeed: 0.0249s/iter; left time: 22.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0727654 Vali Loss: 0.0874904 Test Loss: 0.1000285\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0719278\n",
      "\tspeed: 0.0487s/iter; left time: 38.6552s\n",
      "\titers: 200, epoch: 17 | loss: 0.0681665\n",
      "\tspeed: 0.0249s/iter; left time: 17.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0726065 Vali Loss: 0.0876727 Test Loss: 0.1004601\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0678561\n",
      "\tspeed: 0.0491s/iter; left time: 27.9724s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691214\n",
      "\tspeed: 0.0250s/iter; left time: 11.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0724923 Vali Loss: 0.0875289 Test Loss: 0.0999042\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711187\n",
      "\tspeed: 0.0496s/iter; left time: 17.2100s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721421\n",
      "\tspeed: 0.0249s/iter; left time: 6.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0723260 Vali Loss: 0.0874994 Test Loss: 0.1004439\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0697939\n",
      "\tspeed: 0.0496s/iter; left time: 6.1453s\n",
      "\titers: 200, epoch: 20 | loss: 0.0699597\n",
      "\tspeed: 0.0249s/iter; left time: 0.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0722401 Vali Loss: 0.0876277 Test Loss: 0.1000945\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025304274633526802, rmse:0.15907317399978638, mae:0.10037115961313248, rse:0.5487573742866516\n",
      "Intermediate time for GB and pred_len 24: 00h:05m:08.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1394340\n",
      "\tspeed: 0.0473s/iter; left time: 205.3154s\n",
      "\titers: 200, epoch: 1 | loss: 0.1290265\n",
      "\tspeed: 0.0251s/iter; left time: 106.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.1366888 Vali Loss: 0.1331916 Test Loss: 0.1571194\n",
      "Validation loss decreased (inf --> 0.133192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1068254\n",
      "\tspeed: 0.0511s/iter; left time: 210.3761s\n",
      "\titers: 200, epoch: 2 | loss: 0.1038789\n",
      "\tspeed: 0.0250s/iter; left time: 100.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.1089743 Vali Loss: 0.1170851 Test Loss: 0.1377481\n",
      "Validation loss decreased (0.133192 --> 0.117085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039727\n",
      "\tspeed: 0.0498s/iter; left time: 193.8929s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007207\n",
      "\tspeed: 0.0250s/iter; left time: 94.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1035166 Vali Loss: 0.1159595 Test Loss: 0.1386739\n",
      "Validation loss decreased (0.117085 --> 0.115960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032024\n",
      "\tspeed: 0.0502s/iter; left time: 184.3200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009170\n",
      "\tspeed: 0.0250s/iter; left time: 89.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 222 | Train Loss: 0.1019685 Vali Loss: 0.1150414 Test Loss: 0.1387783\n",
      "Validation loss decreased (0.115960 --> 0.115041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023183\n",
      "\tspeed: 0.0491s/iter; left time: 169.4553s\n",
      "\titers: 200, epoch: 5 | loss: 0.0971835\n",
      "\tspeed: 0.0251s/iter; left time: 84.0776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1006222 Vali Loss: 0.1144552 Test Loss: 0.1380308\n",
      "Validation loss decreased (0.115041 --> 0.114455).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0979462\n",
      "\tspeed: 0.0506s/iter; left time: 163.4448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0962899\n",
      "\tspeed: 0.0250s/iter; left time: 78.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.0993785 Vali Loss: 0.1143939 Test Loss: 0.1384692\n",
      "Validation loss decreased (0.114455 --> 0.114394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0957437\n",
      "\tspeed: 0.0511s/iter; left time: 153.9008s\n",
      "\titers: 200, epoch: 7 | loss: 0.0956334\n",
      "\tspeed: 0.0250s/iter; left time: 72.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0984068 Vali Loss: 0.1152558 Test Loss: 0.1409329\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985388\n",
      "\tspeed: 0.0491s/iter; left time: 136.7956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979370\n",
      "\tspeed: 0.0250s/iter; left time: 67.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 222 | Train Loss: 0.0974339 Vali Loss: 0.1146337 Test Loss: 0.1407919\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0960061\n",
      "\tspeed: 0.0505s/iter; left time: 129.6123s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977183\n",
      "\tspeed: 0.0254s/iter; left time: 62.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0965533 Vali Loss: 0.1147367 Test Loss: 0.1410791\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983268\n",
      "\tspeed: 0.0517s/iter; left time: 121.0222s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971290\n",
      "\tspeed: 0.0254s/iter; left time: 57.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0957947 Vali Loss: 0.1152980 Test Loss: 0.1419808\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0965237\n",
      "\tspeed: 0.0513s/iter; left time: 108.7725s\n",
      "\titers: 200, epoch: 11 | loss: 0.0888941\n",
      "\tspeed: 0.0255s/iter; left time: 51.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0951090 Vali Loss: 0.1158843 Test Loss: 0.1428171\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04119270667433739, rmse:0.20295986533164978, mae:0.13846930861473083, rse:0.7018635272979736\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1365912\n",
      "\tspeed: 0.0279s/iter; left time: 121.2763s\n",
      "\titers: 200, epoch: 1 | loss: 0.1290740\n",
      "\tspeed: 0.0254s/iter; left time: 107.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1389132 Vali Loss: 0.1345307 Test Loss: 0.1591601\n",
      "Validation loss decreased (inf --> 0.134531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1076054\n",
      "\tspeed: 0.0587s/iter; left time: 241.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1062119\n",
      "\tspeed: 0.0253s/iter; left time: 101.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1092445 Vali Loss: 0.1172763 Test Loss: 0.1378209\n",
      "Validation loss decreased (0.134531 --> 0.117276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020365\n",
      "\tspeed: 0.0521s/iter; left time: 203.0195s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043519\n",
      "\tspeed: 0.0254s/iter; left time: 96.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1036230 Vali Loss: 0.1157246 Test Loss: 0.1374671\n",
      "Validation loss decreased (0.117276 --> 0.115725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982133\n",
      "\tspeed: 0.0523s/iter; left time: 192.0524s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026201\n",
      "\tspeed: 0.0255s/iter; left time: 91.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1017590 Vali Loss: 0.1151671 Test Loss: 0.1382986\n",
      "Validation loss decreased (0.115725 --> 0.115167).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018179\n",
      "\tspeed: 0.0522s/iter; left time: 180.2671s\n",
      "\titers: 200, epoch: 5 | loss: 0.1009365\n",
      "\tspeed: 0.0255s/iter; left time: 85.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1003516 Vali Loss: 0.1149728 Test Loss: 0.1380189\n",
      "Validation loss decreased (0.115167 --> 0.114973).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041179\n",
      "\tspeed: 0.0520s/iter; left time: 168.1364s\n",
      "\titers: 200, epoch: 6 | loss: 0.1016819\n",
      "\tspeed: 0.0254s/iter; left time: 79.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0991088 Vali Loss: 0.1147444 Test Loss: 0.1384884\n",
      "Validation loss decreased (0.114973 --> 0.114744).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1039703\n",
      "\tspeed: 0.0527s/iter; left time: 158.4277s\n",
      "\titers: 200, epoch: 7 | loss: 0.1030468\n",
      "\tspeed: 0.0255s/iter; left time: 74.3117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0980691 Vali Loss: 0.1146851 Test Loss: 0.1393597\n",
      "Validation loss decreased (0.114744 --> 0.114685).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0925659\n",
      "\tspeed: 0.0517s/iter; left time: 144.1034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1030127\n",
      "\tspeed: 0.0255s/iter; left time: 68.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0971579 Vali Loss: 0.1146965 Test Loss: 0.1400719\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991212\n",
      "\tspeed: 0.0508s/iter; left time: 130.1917s\n",
      "\titers: 200, epoch: 9 | loss: 0.0950394\n",
      "\tspeed: 0.0256s/iter; left time: 63.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0964368 Vali Loss: 0.1152398 Test Loss: 0.1415877\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0937270\n",
      "\tspeed: 0.0513s/iter; left time: 120.2759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928974\n",
      "\tspeed: 0.0255s/iter; left time: 57.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0956364 Vali Loss: 0.1152773 Test Loss: 0.1406660\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969222\n",
      "\tspeed: 0.0518s/iter; left time: 109.8593s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946718\n",
      "\tspeed: 0.0255s/iter; left time: 51.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0949587 Vali Loss: 0.1158046 Test Loss: 0.1421930\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0901898\n",
      "\tspeed: 0.0512s/iter; left time: 97.2574s\n",
      "\titers: 200, epoch: 12 | loss: 0.0933780\n",
      "\tspeed: 0.0255s/iter; left time: 45.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0943317 Vali Loss: 0.1156237 Test Loss: 0.1397123\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041973523795604706, rmse:0.2048744112253189, mae:0.13935968279838562, rse:0.7084842920303345\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:07.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1374336\n",
      "\tspeed: 0.0462s/iter; left time: 200.3797s\n",
      "\titers: 200, epoch: 1 | loss: 0.1251440\n",
      "\tspeed: 0.0253s/iter; left time: 107.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 222 | Train Loss: 0.1389109 Vali Loss: 0.1349851 Test Loss: 0.1598008\n",
      "Validation loss decreased (inf --> 0.134985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122300\n",
      "\tspeed: 0.0498s/iter; left time: 205.2928s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079164\n",
      "\tspeed: 0.0253s/iter; left time: 101.5836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.1132026 Vali Loss: 0.1214197 Test Loss: 0.1451650\n",
      "Validation loss decreased (0.134985 --> 0.121420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036352\n",
      "\tspeed: 0.0500s/iter; left time: 194.7553s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043559\n",
      "\tspeed: 0.0254s/iter; left time: 96.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1080314 Vali Loss: 0.1201407 Test Loss: 0.1442623\n",
      "Validation loss decreased (0.121420 --> 0.120141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083568\n",
      "\tspeed: 0.0508s/iter; left time: 186.6568s\n",
      "\titers: 200, epoch: 4 | loss: 0.1068884\n",
      "\tspeed: 0.0254s/iter; left time: 90.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1063734 Vali Loss: 0.1194321 Test Loss: 0.1463639\n",
      "Validation loss decreased (0.120141 --> 0.119432).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059435\n",
      "\tspeed: 0.0512s/iter; left time: 176.9128s\n",
      "\titers: 200, epoch: 5 | loss: 0.1046826\n",
      "\tspeed: 0.0254s/iter; left time: 85.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1048385 Vali Loss: 0.1198237 Test Loss: 0.1464768\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1037265\n",
      "\tspeed: 0.0500s/iter; left time: 161.5218s\n",
      "\titers: 200, epoch: 6 | loss: 0.1038950\n",
      "\tspeed: 0.0254s/iter; left time: 79.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1033754 Vali Loss: 0.1201003 Test Loss: 0.1470414\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1040469\n",
      "\tspeed: 0.0497s/iter; left time: 149.4529s\n",
      "\titers: 200, epoch: 7 | loss: 0.1053304\n",
      "\tspeed: 0.0255s/iter; left time: 74.1017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 222 | Train Loss: 0.1021183 Vali Loss: 0.1202404 Test Loss: 0.1469195\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039958\n",
      "\tspeed: 0.0508s/iter; left time: 141.6486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013930\n",
      "\tspeed: 0.0254s/iter; left time: 68.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.1009759 Vali Loss: 0.1207501 Test Loss: 0.1468556\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0994803\n",
      "\tspeed: 0.0501s/iter; left time: 128.5502s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979783\n",
      "\tspeed: 0.0253s/iter; left time: 62.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0998242 Vali Loss: 0.1210882 Test Loss: 0.1469089\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04480735957622528, rmse:0.21167749166488647, mae:0.14636394381523132, rse:0.7339162826538086\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1355522\n",
      "\tspeed: 0.0273s/iter; left time: 118.4042s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274015\n",
      "\tspeed: 0.0254s/iter; left time: 107.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1394984 Vali Loss: 0.1352586 Test Loss: 0.1598129\n",
      "Validation loss decreased (inf --> 0.135259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091381\n",
      "\tspeed: 0.0512s/iter; left time: 210.9057s\n",
      "\titers: 200, epoch: 2 | loss: 0.1071792\n",
      "\tspeed: 0.0255s/iter; left time: 102.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1131621 Vali Loss: 0.1214741 Test Loss: 0.1446611\n",
      "Validation loss decreased (0.135259 --> 0.121474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1094883\n",
      "\tspeed: 0.0506s/iter; left time: 197.1634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1045896\n",
      "\tspeed: 0.0254s/iter; left time: 96.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1081718 Vali Loss: 0.1202765 Test Loss: 0.1443724\n",
      "Validation loss decreased (0.121474 --> 0.120276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1076571\n",
      "\tspeed: 0.0562s/iter; left time: 206.6492s\n",
      "\titers: 200, epoch: 4 | loss: 0.1014475\n",
      "\tspeed: 0.0255s/iter; left time: 91.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1063156 Vali Loss: 0.1197968 Test Loss: 0.1463517\n",
      "Validation loss decreased (0.120276 --> 0.119797).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1025544\n",
      "\tspeed: 0.0516s/iter; left time: 178.3187s\n",
      "\titers: 200, epoch: 5 | loss: 0.1026519\n",
      "\tspeed: 0.0255s/iter; left time: 85.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1047799 Vali Loss: 0.1200861 Test Loss: 0.1472630\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1064387\n",
      "\tspeed: 0.0515s/iter; left time: 166.4209s\n",
      "\titers: 200, epoch: 6 | loss: 0.1037773\n",
      "\tspeed: 0.0256s/iter; left time: 80.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1034544 Vali Loss: 0.1205088 Test Loss: 0.1483668\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036646\n",
      "\tspeed: 0.0507s/iter; left time: 152.6592s\n",
      "\titers: 200, epoch: 7 | loss: 0.0979128\n",
      "\tspeed: 0.0255s/iter; left time: 74.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1022100 Vali Loss: 0.1204105 Test Loss: 0.1481286\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995876\n",
      "\tspeed: 0.0513s/iter; left time: 143.1053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977129\n",
      "\tspeed: 0.0254s/iter; left time: 68.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1009682 Vali Loss: 0.1205941 Test Loss: 0.1476202\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0968032\n",
      "\tspeed: 0.0516s/iter; left time: 132.2275s\n",
      "\titers: 200, epoch: 9 | loss: 0.0991139\n",
      "\tspeed: 0.0255s/iter; left time: 62.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0997093 Vali Loss: 0.1207828 Test Loss: 0.1471774\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04440097510814667, rmse:0.2107153832912445, mae:0.14635175466537476, rse:0.7305805087089539\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:29.28s\n",
      "Intermediate time for GB: 00h:10m:46.06s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1329129\n",
      "\tspeed: 0.0379s/iter; left time: 165.4441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1140730\n",
      "\tspeed: 0.0158s/iter; left time: 67.2718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1388291 Vali Loss: 0.1031739 Test Loss: 0.1167768\n",
      "Validation loss decreased (inf --> 0.103174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0760406\n",
      "\tspeed: 0.0345s/iter; left time: 142.7941s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709279\n",
      "\tspeed: 0.0157s/iter; left time: 63.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0782182 Vali Loss: 0.0637507 Test Loss: 0.0713524\n",
      "Validation loss decreased (0.103174 --> 0.063751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656441\n",
      "\tspeed: 0.0345s/iter; left time: 135.1514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637093\n",
      "\tspeed: 0.0159s/iter; left time: 60.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0659534 Vali Loss: 0.0600094 Test Loss: 0.0667960\n",
      "Validation loss decreased (0.063751 --> 0.060009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627606\n",
      "\tspeed: 0.0345s/iter; left time: 127.2860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0611268\n",
      "\tspeed: 0.0159s/iter; left time: 57.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0627434 Vali Loss: 0.0586569 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.060009 --> 0.058657).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597999\n",
      "\tspeed: 0.0361s/iter; left time: 125.3710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628164\n",
      "\tspeed: 0.0162s/iter; left time: 54.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0608250 Vali Loss: 0.0571451 Test Loss: 0.0638910\n",
      "Validation loss decreased (0.058657 --> 0.057145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588184\n",
      "\tspeed: 0.0361s/iter; left time: 117.3406s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603673\n",
      "\tspeed: 0.0162s/iter; left time: 50.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0595142 Vali Loss: 0.0563593 Test Loss: 0.0631915\n",
      "Validation loss decreased (0.057145 --> 0.056359).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571423\n",
      "\tspeed: 0.0366s/iter; left time: 110.5641s\n",
      "\titers: 200, epoch: 7 | loss: 0.0634167\n",
      "\tspeed: 0.0162s/iter; left time: 47.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0586404 Vali Loss: 0.0558892 Test Loss: 0.0628020\n",
      "Validation loss decreased (0.056359 --> 0.055889).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0587911\n",
      "\tspeed: 0.0360s/iter; left time: 100.9207s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589734\n",
      "\tspeed: 0.0162s/iter; left time: 43.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0579511 Vali Loss: 0.0554596 Test Loss: 0.0625661\n",
      "Validation loss decreased (0.055889 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562014\n",
      "\tspeed: 0.0361s/iter; left time: 92.9534s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573063\n",
      "\tspeed: 0.0162s/iter; left time: 40.2268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0573422 Vali Loss: 0.0551464 Test Loss: 0.0621672\n",
      "Validation loss decreased (0.055460 --> 0.055146).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563526\n",
      "\tspeed: 0.0360s/iter; left time: 84.6992s\n",
      "\titers: 200, epoch: 10 | loss: 0.0558840\n",
      "\tspeed: 0.0163s/iter; left time: 36.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0568031 Vali Loss: 0.0549321 Test Loss: 0.0619139\n",
      "Validation loss decreased (0.055146 --> 0.054932).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561171\n",
      "\tspeed: 0.0359s/iter; left time: 76.4112s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546085\n",
      "\tspeed: 0.0163s/iter; left time: 33.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0563940 Vali Loss: 0.0546079 Test Loss: 0.0616910\n",
      "Validation loss decreased (0.054932 --> 0.054608).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553174\n",
      "\tspeed: 0.0374s/iter; left time: 71.2823s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555087\n",
      "\tspeed: 0.0162s/iter; left time: 29.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0560539 Vali Loss: 0.0541861 Test Loss: 0.0612447\n",
      "Validation loss decreased (0.054608 --> 0.054186).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536061\n",
      "\tspeed: 0.0362s/iter; left time: 60.9948s\n",
      "\titers: 200, epoch: 13 | loss: 0.0512201\n",
      "\tspeed: 0.0162s/iter; left time: 25.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0556423 Vali Loss: 0.0539564 Test Loss: 0.0611355\n",
      "Validation loss decreased (0.054186 --> 0.053956).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0582338\n",
      "\tspeed: 0.0362s/iter; left time: 52.9429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572633\n",
      "\tspeed: 0.0162s/iter; left time: 22.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0554266 Vali Loss: 0.0539151 Test Loss: 0.0609410\n",
      "Validation loss decreased (0.053956 --> 0.053915).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0551506\n",
      "\tspeed: 0.0357s/iter; left time: 44.2579s\n",
      "\titers: 200, epoch: 15 | loss: 0.0490729\n",
      "\tspeed: 0.0161s/iter; left time: 18.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0551881 Vali Loss: 0.0538702 Test Loss: 0.0607723\n",
      "Validation loss decreased (0.053915 --> 0.053870).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550896\n",
      "\tspeed: 0.0360s/iter; left time: 36.5572s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553330\n",
      "\tspeed: 0.0157s/iter; left time: 14.3835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0549647 Vali Loss: 0.0537893 Test Loss: 0.0606530\n",
      "Validation loss decreased (0.053870 --> 0.053789).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518273\n",
      "\tspeed: 0.0362s/iter; left time: 28.7407s\n",
      "\titers: 200, epoch: 17 | loss: 0.0541851\n",
      "\tspeed: 0.0157s/iter; left time: 10.8802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0548265 Vali Loss: 0.0535404 Test Loss: 0.0606558\n",
      "Validation loss decreased (0.053789 --> 0.053540).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0561151\n",
      "\tspeed: 0.0350s/iter; left time: 19.9765s\n",
      "\titers: 200, epoch: 18 | loss: 0.0536424\n",
      "\tspeed: 0.0158s/iter; left time: 7.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0545902 Vali Loss: 0.0535757 Test Loss: 0.0607545\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0576345\n",
      "\tspeed: 0.0363s/iter; left time: 12.5915s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547254\n",
      "\tspeed: 0.0163s/iter; left time: 4.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0545236 Vali Loss: 0.0534763 Test Loss: 0.0604636\n",
      "Validation loss decreased (0.053540 --> 0.053476).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522795\n",
      "\tspeed: 0.0360s/iter; left time: 4.4700s\n",
      "\titers: 200, epoch: 20 | loss: 0.0537029\n",
      "\tspeed: 0.0163s/iter; left time: 0.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0544254 Vali Loss: 0.0533704 Test Loss: 0.0604521\n",
      "Validation loss decreased (0.053476 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009890918619930744, rmse:0.09945309907197952, mae:0.06045207753777504, rse:0.29267844557762146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1279595\n",
      "\tspeed: 0.0230s/iter; left time: 100.1254s\n",
      "\titers: 200, epoch: 1 | loss: 0.1086019\n",
      "\tspeed: 0.0161s/iter; left time: 68.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.1344859 Vali Loss: 0.1017183 Test Loss: 0.1152673\n",
      "Validation loss decreased (inf --> 0.101718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0735457\n",
      "\tspeed: 0.0357s/iter; left time: 147.7778s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693448\n",
      "\tspeed: 0.0162s/iter; left time: 65.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0775861 Vali Loss: 0.0633993 Test Loss: 0.0710598\n",
      "Validation loss decreased (0.101718 --> 0.063399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0666565\n",
      "\tspeed: 0.0359s/iter; left time: 140.6370s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644751\n",
      "\tspeed: 0.0162s/iter; left time: 61.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0657430 Vali Loss: 0.0598359 Test Loss: 0.0666923\n",
      "Validation loss decreased (0.063399 --> 0.059836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0654695\n",
      "\tspeed: 0.0347s/iter; left time: 128.2464s\n",
      "\titers: 200, epoch: 4 | loss: 0.0609133\n",
      "\tspeed: 0.0156s/iter; left time: 56.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0624257 Vali Loss: 0.0581786 Test Loss: 0.0650473\n",
      "Validation loss decreased (0.059836 --> 0.058179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629714\n",
      "\tspeed: 0.0358s/iter; left time: 124.3160s\n",
      "\titers: 200, epoch: 5 | loss: 0.0566989\n",
      "\tspeed: 0.0160s/iter; left time: 53.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0605862 Vali Loss: 0.0572167 Test Loss: 0.0640629\n",
      "Validation loss decreased (0.058179 --> 0.057217).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0580013\n",
      "\tspeed: 0.0360s/iter; left time: 116.7343s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592974\n",
      "\tspeed: 0.0164s/iter; left time: 51.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0592775 Vali Loss: 0.0563820 Test Loss: 0.0630901\n",
      "Validation loss decreased (0.057217 --> 0.056382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606943\n",
      "\tspeed: 0.0359s/iter; left time: 108.6003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0561517\n",
      "\tspeed: 0.0161s/iter; left time: 47.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0583424 Vali Loss: 0.0557012 Test Loss: 0.0625994\n",
      "Validation loss decreased (0.056382 --> 0.055701).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603218\n",
      "\tspeed: 0.0350s/iter; left time: 98.0653s\n",
      "\titers: 200, epoch: 8 | loss: 0.0588647\n",
      "\tspeed: 0.0163s/iter; left time: 43.8880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0576146 Vali Loss: 0.0552016 Test Loss: 0.0622390\n",
      "Validation loss decreased (0.055701 --> 0.055202).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0566144\n",
      "\tspeed: 0.0354s/iter; left time: 91.2476s\n",
      "\titers: 200, epoch: 9 | loss: 0.0567635\n",
      "\tspeed: 0.0162s/iter; left time: 40.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0570295 Vali Loss: 0.0550724 Test Loss: 0.0619212\n",
      "Validation loss decreased (0.055202 --> 0.055072).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563664\n",
      "\tspeed: 0.0358s/iter; left time: 84.3294s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591527\n",
      "\tspeed: 0.0162s/iter; left time: 36.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0565442 Vali Loss: 0.0546937 Test Loss: 0.0616718\n",
      "Validation loss decreased (0.055072 --> 0.054694).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0577397\n",
      "\tspeed: 0.0355s/iter; left time: 75.6932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553575\n",
      "\tspeed: 0.0162s/iter; left time: 32.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0561088 Vali Loss: 0.0544968 Test Loss: 0.0613600\n",
      "Validation loss decreased (0.054694 --> 0.054497).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0573475\n",
      "\tspeed: 0.0359s/iter; left time: 68.5430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0556808\n",
      "\tspeed: 0.0162s/iter; left time: 29.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0557425 Vali Loss: 0.0542554 Test Loss: 0.0610903\n",
      "Validation loss decreased (0.054497 --> 0.054255).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580835\n",
      "\tspeed: 0.0353s/iter; left time: 59.4894s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562407\n",
      "\tspeed: 0.0161s/iter; left time: 25.5769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0554549 Vali Loss: 0.0541976 Test Loss: 0.0609923\n",
      "Validation loss decreased (0.054255 --> 0.054198).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577417\n",
      "\tspeed: 0.0350s/iter; left time: 51.2410s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546249\n",
      "\tspeed: 0.0162s/iter; left time: 22.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0551867 Vali Loss: 0.0538669 Test Loss: 0.0609006\n",
      "Validation loss decreased (0.054198 --> 0.053867).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580590\n",
      "\tspeed: 0.0357s/iter; left time: 44.2141s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533785\n",
      "\tspeed: 0.0160s/iter; left time: 18.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0549592 Vali Loss: 0.0537050 Test Loss: 0.0606348\n",
      "Validation loss decreased (0.053867 --> 0.053705).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584997\n",
      "\tspeed: 0.0361s/iter; left time: 36.7068s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622431\n",
      "\tspeed: 0.0158s/iter; left time: 14.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0547352 Vali Loss: 0.0537173 Test Loss: 0.0607005\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567969\n",
      "\tspeed: 0.0352s/iter; left time: 27.9276s\n",
      "\titers: 200, epoch: 17 | loss: 0.0530954\n",
      "\tspeed: 0.0159s/iter; left time: 10.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0546198 Vali Loss: 0.0534973 Test Loss: 0.0604868\n",
      "Validation loss decreased (0.053705 --> 0.053497).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0558345\n",
      "\tspeed: 0.0356s/iter; left time: 20.3038s\n",
      "\titers: 200, epoch: 18 | loss: 0.0515417\n",
      "\tspeed: 0.0158s/iter; left time: 7.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0543856 Vali Loss: 0.0535284 Test Loss: 0.0605108\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0532008\n",
      "\tspeed: 0.0357s/iter; left time: 12.3987s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540956\n",
      "\tspeed: 0.0161s/iter; left time: 3.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0542990 Vali Loss: 0.0535540 Test Loss: 0.0603973\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522034\n",
      "\tspeed: 0.0347s/iter; left time: 4.3084s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543188\n",
      "\tspeed: 0.0156s/iter; left time: 0.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0542121 Vali Loss: 0.0533839 Test Loss: 0.0602595\n",
      "Validation loss decreased (0.053497 --> 0.053384).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009858346544206142, rmse:0.09928920865058899, mae:0.06025950610637665, rse:0.292196124792099\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:37.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1382145\n",
      "\tspeed: 0.0379s/iter; left time: 164.7397s\n",
      "\titers: 200, epoch: 1 | loss: 0.1181780\n",
      "\tspeed: 0.0160s/iter; left time: 67.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.1422870 Vali Loss: 0.1110726 Test Loss: 0.1262145\n",
      "Validation loss decreased (inf --> 0.111073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934740\n",
      "\tspeed: 0.0365s/iter; left time: 150.3850s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868728\n",
      "\tspeed: 0.0161s/iter; left time: 64.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0946656 Vali Loss: 0.0840059 Test Loss: 0.0971048\n",
      "Validation loss decreased (0.111073 --> 0.084006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818275\n",
      "\tspeed: 0.0364s/iter; left time: 141.9095s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815208\n",
      "\tspeed: 0.0158s/iter; left time: 60.1087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0849752 Vali Loss: 0.0803390 Test Loss: 0.0920883\n",
      "Validation loss decreased (0.084006 --> 0.080339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0843434\n",
      "\tspeed: 0.0367s/iter; left time: 135.0444s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803908\n",
      "\tspeed: 0.0164s/iter; left time: 58.7824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0819896 Vali Loss: 0.0789692 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.080339 --> 0.078969).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0778120\n",
      "\tspeed: 0.0369s/iter; left time: 127.4601s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792906\n",
      "\tspeed: 0.0162s/iter; left time: 54.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0802503 Vali Loss: 0.0777747 Test Loss: 0.0894107\n",
      "Validation loss decreased (0.078969 --> 0.077775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807522\n",
      "\tspeed: 0.0380s/iter; left time: 122.8049s\n",
      "\titers: 200, epoch: 6 | loss: 0.0769921\n",
      "\tspeed: 0.0161s/iter; left time: 50.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0790549 Vali Loss: 0.0774048 Test Loss: 0.0887209\n",
      "Validation loss decreased (0.077775 --> 0.077405).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823921\n",
      "\tspeed: 0.0368s/iter; left time: 110.7950s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769773\n",
      "\tspeed: 0.0165s/iter; left time: 48.1353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0780271 Vali Loss: 0.0765681 Test Loss: 0.0888416\n",
      "Validation loss decreased (0.077405 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805103\n",
      "\tspeed: 0.0372s/iter; left time: 103.5773s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825891\n",
      "\tspeed: 0.0166s/iter; left time: 44.6667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0772853 Vali Loss: 0.0766558 Test Loss: 0.0883564\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758953\n",
      "\tspeed: 0.0376s/iter; left time: 96.3159s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758411\n",
      "\tspeed: 0.0165s/iter; left time: 40.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0766971 Vali Loss: 0.0760411 Test Loss: 0.0879879\n",
      "Validation loss decreased (0.076568 --> 0.076041).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772159\n",
      "\tspeed: 0.0370s/iter; left time: 86.5931s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762513\n",
      "\tspeed: 0.0166s/iter; left time: 37.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0761602 Vali Loss: 0.0759706 Test Loss: 0.0880720\n",
      "Validation loss decreased (0.076041 --> 0.075971).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0755076\n",
      "\tspeed: 0.0362s/iter; left time: 76.8158s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763734\n",
      "\tspeed: 0.0165s/iter; left time: 33.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0756422 Vali Loss: 0.0762044 Test Loss: 0.0878475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0748532\n",
      "\tspeed: 0.0359s/iter; left time: 68.0922s\n",
      "\titers: 200, epoch: 12 | loss: 0.0741075\n",
      "\tspeed: 0.0165s/iter; left time: 29.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0751778 Vali Loss: 0.0761833 Test Loss: 0.0877756\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0756494\n",
      "\tspeed: 0.0362s/iter; left time: 60.7856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696331\n",
      "\tspeed: 0.0165s/iter; left time: 26.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0747903 Vali Loss: 0.0759777 Test Loss: 0.0875898\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709691\n",
      "\tspeed: 0.0360s/iter; left time: 52.4383s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781972\n",
      "\tspeed: 0.0165s/iter; left time: 22.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0744701 Vali Loss: 0.0760754 Test Loss: 0.0878949\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766354\n",
      "\tspeed: 0.0373s/iter; left time: 45.9441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760197\n",
      "\tspeed: 0.0165s/iter; left time: 18.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0741755 Vali Loss: 0.0762521 Test Loss: 0.0875846\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01861393451690674, rmse:0.13643290102481842, mae:0.08807197213172913, rse:0.4007987976074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1401673\n",
      "\tspeed: 0.0193s/iter; left time: 83.7271s\n",
      "\titers: 200, epoch: 1 | loss: 0.1195182\n",
      "\tspeed: 0.0165s/iter; left time: 70.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.1430732 Vali Loss: 0.1126027 Test Loss: 0.1276715\n",
      "Validation loss decreased (inf --> 0.112603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918490\n",
      "\tspeed: 0.0411s/iter; left time: 169.2667s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912421\n",
      "\tspeed: 0.0166s/iter; left time: 66.8071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0946936 Vali Loss: 0.0846617 Test Loss: 0.0975314\n",
      "Validation loss decreased (0.112603 --> 0.084662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851025\n",
      "\tspeed: 0.0366s/iter; left time: 142.7199s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807028\n",
      "\tspeed: 0.0166s/iter; left time: 62.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0852020 Vali Loss: 0.0806539 Test Loss: 0.0927236\n",
      "Validation loss decreased (0.084662 --> 0.080654).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0821001\n",
      "\tspeed: 0.0367s/iter; left time: 134.7763s\n",
      "\titers: 200, epoch: 4 | loss: 0.0830633\n",
      "\tspeed: 0.0166s/iter; left time: 59.1893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0822834 Vali Loss: 0.0789649 Test Loss: 0.0910162\n",
      "Validation loss decreased (0.080654 --> 0.078965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0768529\n",
      "\tspeed: 0.0362s/iter; left time: 125.0620s\n",
      "\titers: 200, epoch: 5 | loss: 0.0789720\n",
      "\tspeed: 0.0165s/iter; left time: 55.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0804274 Vali Loss: 0.0782210 Test Loss: 0.0894947\n",
      "Validation loss decreased (0.078965 --> 0.078221).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749856\n",
      "\tspeed: 0.0363s/iter; left time: 117.2226s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800525\n",
      "\tspeed: 0.0166s/iter; left time: 51.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0790466 Vali Loss: 0.0770681 Test Loss: 0.0889147\n",
      "Validation loss decreased (0.078221 --> 0.077068).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0778470\n",
      "\tspeed: 0.0367s/iter; left time: 110.3294s\n",
      "\titers: 200, epoch: 7 | loss: 0.0764591\n",
      "\tspeed: 0.0166s/iter; left time: 48.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0780620 Vali Loss: 0.0770800 Test Loss: 0.0882575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761395\n",
      "\tspeed: 0.0359s/iter; left time: 100.0392s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761275\n",
      "\tspeed: 0.0165s/iter; left time: 44.4483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0773584 Vali Loss: 0.0764647 Test Loss: 0.0884067\n",
      "Validation loss decreased (0.077068 --> 0.076465).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758509\n",
      "\tspeed: 0.0367s/iter; left time: 94.1422s\n",
      "\titers: 200, epoch: 9 | loss: 0.0754697\n",
      "\tspeed: 0.0166s/iter; left time: 40.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0766769 Vali Loss: 0.0765209 Test Loss: 0.0880247\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777909\n",
      "\tspeed: 0.0355s/iter; left time: 83.2139s\n",
      "\titers: 200, epoch: 10 | loss: 0.0743774\n",
      "\tspeed: 0.0160s/iter; left time: 35.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0761345 Vali Loss: 0.0761065 Test Loss: 0.0884370\n",
      "Validation loss decreased (0.076465 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781779\n",
      "\tspeed: 0.0366s/iter; left time: 77.5590s\n",
      "\titers: 200, epoch: 11 | loss: 0.0781140\n",
      "\tspeed: 0.0166s/iter; left time: 33.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0756517 Vali Loss: 0.0762509 Test Loss: 0.0878481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758330\n",
      "\tspeed: 0.0360s/iter; left time: 68.3632s\n",
      "\titers: 200, epoch: 12 | loss: 0.0747232\n",
      "\tspeed: 0.0165s/iter; left time: 29.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0751902 Vali Loss: 0.0762376 Test Loss: 0.0878943\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0750675\n",
      "\tspeed: 0.0357s/iter; left time: 59.8132s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719781\n",
      "\tspeed: 0.0165s/iter; left time: 26.0753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0748755 Vali Loss: 0.0764348 Test Loss: 0.0878604\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734775\n",
      "\tspeed: 0.0361s/iter; left time: 52.4920s\n",
      "\titers: 200, epoch: 14 | loss: 0.0739771\n",
      "\tspeed: 0.0166s/iter; left time: 22.4688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0744408 Vali Loss: 0.0763637 Test Loss: 0.0873832\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0743827\n",
      "\tspeed: 0.0372s/iter; left time: 45.8946s\n",
      "\titers: 200, epoch: 15 | loss: 0.0768726\n",
      "\tspeed: 0.0165s/iter; left time: 18.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0741297 Vali Loss: 0.0766998 Test Loss: 0.0875579\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018726512789726257, rmse:0.13684484362602234, mae:0.0884370505809784, rse:0.402008980512619\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:49.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1420207\n",
      "\tspeed: 0.0367s/iter; left time: 159.1286s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220062\n",
      "\tspeed: 0.0164s/iter; left time: 69.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.1459882 Vali Loss: 0.1142418 Test Loss: 0.1288368\n",
      "Validation loss decreased (inf --> 0.114242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938779\n",
      "\tspeed: 0.0367s/iter; left time: 151.1914s\n",
      "\titers: 200, epoch: 2 | loss: 0.0906986\n",
      "\tspeed: 0.0163s/iter; left time: 65.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0986648 Vali Loss: 0.0893049 Test Loss: 0.1028076\n",
      "Validation loss decreased (0.114242 --> 0.089305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886885\n",
      "\tspeed: 0.0380s/iter; left time: 148.0387s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865253\n",
      "\tspeed: 0.0164s/iter; left time: 62.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0898190 Vali Loss: 0.0859340 Test Loss: 0.0980160\n",
      "Validation loss decreased (0.089305 --> 0.085934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0852806\n",
      "\tspeed: 0.0366s/iter; left time: 134.6612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859492\n",
      "\tspeed: 0.0164s/iter; left time: 58.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0869044 Vali Loss: 0.0841650 Test Loss: 0.0958709\n",
      "Validation loss decreased (0.085934 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888405\n",
      "\tspeed: 0.0361s/iter; left time: 124.5844s\n",
      "\titers: 200, epoch: 5 | loss: 0.0867904\n",
      "\tspeed: 0.0162s/iter; left time: 54.3151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0850048 Vali Loss: 0.0835832 Test Loss: 0.0956103\n",
      "Validation loss decreased (0.084165 --> 0.083583).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844916\n",
      "\tspeed: 0.0383s/iter; left time: 123.7300s\n",
      "\titers: 200, epoch: 6 | loss: 0.0805309\n",
      "\tspeed: 0.0162s/iter; left time: 50.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0836529 Vali Loss: 0.0832231 Test Loss: 0.0952673\n",
      "Validation loss decreased (0.083583 --> 0.083223).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847475\n",
      "\tspeed: 0.0368s/iter; left time: 110.8086s\n",
      "\titers: 200, epoch: 7 | loss: 0.0842363\n",
      "\tspeed: 0.0162s/iter; left time: 47.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0825565 Vali Loss: 0.0831752 Test Loss: 0.0948034\n",
      "Validation loss decreased (0.083223 --> 0.083175).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815429\n",
      "\tspeed: 0.0372s/iter; left time: 103.7756s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795956\n",
      "\tspeed: 0.0162s/iter; left time: 43.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0816194 Vali Loss: 0.0834158 Test Loss: 0.0945200\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805828\n",
      "\tspeed: 0.0356s/iter; left time: 91.3756s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785723\n",
      "\tspeed: 0.0164s/iter; left time: 40.4454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0808371 Vali Loss: 0.0834359 Test Loss: 0.0951119\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788970\n",
      "\tspeed: 0.0364s/iter; left time: 85.1798s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791808\n",
      "\tspeed: 0.0162s/iter; left time: 36.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0801603 Vali Loss: 0.0837579 Test Loss: 0.0949604\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781882\n",
      "\tspeed: 0.0365s/iter; left time: 77.5082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749253\n",
      "\tspeed: 0.0162s/iter; left time: 32.6774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0795041 Vali Loss: 0.0836973 Test Loss: 0.0950555\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0820172\n",
      "\tspeed: 0.0355s/iter; left time: 67.4894s\n",
      "\titers: 200, epoch: 12 | loss: 0.0827949\n",
      "\tspeed: 0.0162s/iter; left time: 29.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0790387 Vali Loss: 0.0843834 Test Loss: 0.0948036\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02094191126525402, rmse:0.14471320807933807, mae:0.09480340778827667, rse:0.4251543879508972\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1496143\n",
      "\tspeed: 0.0188s/iter; left time: 81.7257s\n",
      "\titers: 200, epoch: 1 | loss: 0.1239623\n",
      "\tspeed: 0.0164s/iter; left time: 69.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.1494615 Vali Loss: 0.1163782 Test Loss: 0.1309904\n",
      "Validation loss decreased (inf --> 0.116378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0963073\n",
      "\tspeed: 0.0363s/iter; left time: 149.6607s\n",
      "\titers: 200, epoch: 2 | loss: 0.0907201\n",
      "\tspeed: 0.0164s/iter; left time: 65.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0985604 Vali Loss: 0.0897975 Test Loss: 0.1030184\n",
      "Validation loss decreased (0.116378 --> 0.089797).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0908636\n",
      "\tspeed: 0.0383s/iter; left time: 149.2550s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888883\n",
      "\tspeed: 0.0164s/iter; left time: 62.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0900136 Vali Loss: 0.0864137 Test Loss: 0.0986794\n",
      "Validation loss decreased (0.089797 --> 0.086414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853538\n",
      "\tspeed: 0.0365s/iter; left time: 134.1591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859582\n",
      "\tspeed: 0.0162s/iter; left time: 57.7471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0870681 Vali Loss: 0.0853866 Test Loss: 0.0963003\n",
      "Validation loss decreased (0.086414 --> 0.085387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824069\n",
      "\tspeed: 0.0382s/iter; left time: 131.9430s\n",
      "\titers: 200, epoch: 5 | loss: 0.0809987\n",
      "\tspeed: 0.0164s/iter; left time: 54.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0851098 Vali Loss: 0.0841634 Test Loss: 0.0957687\n",
      "Validation loss decreased (0.085387 --> 0.084163).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0813394\n",
      "\tspeed: 0.0371s/iter; left time: 119.8784s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816348\n",
      "\tspeed: 0.0162s/iter; left time: 50.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0836742 Vali Loss: 0.0833399 Test Loss: 0.0949330\n",
      "Validation loss decreased (0.084163 --> 0.083340).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828306\n",
      "\tspeed: 0.0357s/iter; left time: 107.2841s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830407\n",
      "\tspeed: 0.0162s/iter; left time: 47.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0824505 Vali Loss: 0.0835392 Test Loss: 0.0949280\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0814650\n",
      "\tspeed: 0.0359s/iter; left time: 100.0302s\n",
      "\titers: 200, epoch: 8 | loss: 0.0808381\n",
      "\tspeed: 0.0163s/iter; left time: 43.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0814993 Vali Loss: 0.0834557 Test Loss: 0.0947734\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787199\n",
      "\tspeed: 0.0355s/iter; left time: 91.1109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0799115\n",
      "\tspeed: 0.0163s/iter; left time: 40.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0805486 Vali Loss: 0.0833337 Test Loss: 0.0949287\n",
      "Validation loss decreased (0.083340 --> 0.083334).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0836201\n",
      "\tspeed: 0.0371s/iter; left time: 86.8456s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804693\n",
      "\tspeed: 0.0162s/iter; left time: 36.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0798706 Vali Loss: 0.0834730 Test Loss: 0.0946220\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0760122\n",
      "\tspeed: 0.0356s/iter; left time: 75.4284s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766698\n",
      "\tspeed: 0.0162s/iter; left time: 32.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0791417 Vali Loss: 0.0835872 Test Loss: 0.0949908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815300\n",
      "\tspeed: 0.0353s/iter; left time: 66.9741s\n",
      "\titers: 200, epoch: 12 | loss: 0.0771889\n",
      "\tspeed: 0.0162s/iter; left time: 29.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0786277 Vali Loss: 0.0843396 Test Loss: 0.0952377\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0792111\n",
      "\tspeed: 0.0361s/iter; left time: 60.5570s\n",
      "\titers: 200, epoch: 13 | loss: 0.0796132\n",
      "\tspeed: 0.0162s/iter; left time: 25.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0781316 Vali Loss: 0.0841842 Test Loss: 0.0952322\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0786563\n",
      "\tspeed: 0.0361s/iter; left time: 52.5267s\n",
      "\titers: 200, epoch: 14 | loss: 0.0782091\n",
      "\tspeed: 0.0163s/iter; left time: 22.0380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0776963 Vali Loss: 0.0846619 Test Loss: 0.0959198\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021230584010481834, rmse:0.14570719003677368, mae:0.09492865204811096, rse:0.42807459831237793\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:27.45s\n",
      "Intermediate time for ES: 00h:08m:54.49s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975797\n",
      "\tspeed: 0.0378s/iter; left time: 164.7804s\n",
      "\titers: 200, epoch: 1 | loss: 0.0836335\n",
      "\tspeed: 0.0160s/iter; left time: 68.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1024391 Vali Loss: 0.0872047 Test Loss: 0.0960801\n",
      "Validation loss decreased (inf --> 0.087205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0558590\n",
      "\tspeed: 0.0341s/iter; left time: 141.2197s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529639\n",
      "\tspeed: 0.0159s/iter; left time: 64.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0578774 Vali Loss: 0.0587300 Test Loss: 0.0621037\n",
      "Validation loss decreased (0.087205 --> 0.058730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0464267\n",
      "\tspeed: 0.0342s/iter; left time: 133.9868s\n",
      "\titers: 200, epoch: 3 | loss: 0.0519227\n",
      "\tspeed: 0.0159s/iter; left time: 60.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0499244 Vali Loss: 0.0564306 Test Loss: 0.0598956\n",
      "Validation loss decreased (0.058730 --> 0.056431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0491055\n",
      "\tspeed: 0.0350s/iter; left time: 129.3276s\n",
      "\titers: 200, epoch: 4 | loss: 0.0485278\n",
      "\tspeed: 0.0158s/iter; left time: 56.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0479141 Vali Loss: 0.0552515 Test Loss: 0.0584848\n",
      "Validation loss decreased (0.056431 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461720\n",
      "\tspeed: 0.0344s/iter; left time: 119.3583s\n",
      "\titers: 200, epoch: 5 | loss: 0.0457155\n",
      "\tspeed: 0.0158s/iter; left time: 53.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0465824 Vali Loss: 0.0546872 Test Loss: 0.0577522\n",
      "Validation loss decreased (0.055251 --> 0.054687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473171\n",
      "\tspeed: 0.0342s/iter; left time: 111.0197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0413529\n",
      "\tspeed: 0.0159s/iter; left time: 49.8851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0456244 Vali Loss: 0.0540799 Test Loss: 0.0576998\n",
      "Validation loss decreased (0.054687 --> 0.054080).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445942\n",
      "\tspeed: 0.0346s/iter; left time: 104.4969s\n",
      "\titers: 200, epoch: 7 | loss: 0.0474015\n",
      "\tspeed: 0.0158s/iter; left time: 46.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0449627 Vali Loss: 0.0533268 Test Loss: 0.0570868\n",
      "Validation loss decreased (0.054080 --> 0.053327).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0458883\n",
      "\tspeed: 0.0343s/iter; left time: 96.1273s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440469\n",
      "\tspeed: 0.0159s/iter; left time: 42.8445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0443844 Vali Loss: 0.0530725 Test Loss: 0.0570844\n",
      "Validation loss decreased (0.053327 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0468748\n",
      "\tspeed: 0.0348s/iter; left time: 89.6174s\n",
      "\titers: 200, epoch: 9 | loss: 0.0448973\n",
      "\tspeed: 0.0160s/iter; left time: 39.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0439861 Vali Loss: 0.0528239 Test Loss: 0.0568019\n",
      "Validation loss decreased (0.053073 --> 0.052824).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0420790\n",
      "\tspeed: 0.0349s/iter; left time: 82.0910s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407695\n",
      "\tspeed: 0.0160s/iter; left time: 36.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0435386 Vali Loss: 0.0526597 Test Loss: 0.0562937\n",
      "Validation loss decreased (0.052824 --> 0.052660).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0412320\n",
      "\tspeed: 0.0343s/iter; left time: 73.1397s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465333\n",
      "\tspeed: 0.0158s/iter; left time: 32.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0433083 Vali Loss: 0.0523613 Test Loss: 0.0560849\n",
      "Validation loss decreased (0.052660 --> 0.052361).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0417468\n",
      "\tspeed: 0.0346s/iter; left time: 66.1049s\n",
      "\titers: 200, epoch: 12 | loss: 0.0436344\n",
      "\tspeed: 0.0159s/iter; left time: 28.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0430509 Vali Loss: 0.0523960 Test Loss: 0.0563496\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463760\n",
      "\tspeed: 0.0343s/iter; left time: 57.8467s\n",
      "\titers: 200, epoch: 13 | loss: 0.0398072\n",
      "\tspeed: 0.0158s/iter; left time: 25.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0427942 Vali Loss: 0.0523807 Test Loss: 0.0562546\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0441464\n",
      "\tspeed: 0.0340s/iter; left time: 49.6417s\n",
      "\titers: 200, epoch: 14 | loss: 0.0437662\n",
      "\tspeed: 0.0158s/iter; left time: 21.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0426049 Vali Loss: 0.0519577 Test Loss: 0.0558820\n",
      "Validation loss decreased (0.052361 --> 0.051958).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0397336\n",
      "\tspeed: 0.0349s/iter; left time: 43.2493s\n",
      "\titers: 200, epoch: 15 | loss: 0.0388149\n",
      "\tspeed: 0.0158s/iter; left time: 18.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0424205 Vali Loss: 0.0520772 Test Loss: 0.0560981\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0439926\n",
      "\tspeed: 0.0338s/iter; left time: 34.3309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0399195\n",
      "\tspeed: 0.0159s/iter; left time: 14.5235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0422887 Vali Loss: 0.0519859 Test Loss: 0.0558941\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0427168\n",
      "\tspeed: 0.0339s/iter; left time: 26.8546s\n",
      "\titers: 200, epoch: 17 | loss: 0.0386291\n",
      "\tspeed: 0.0158s/iter; left time: 10.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0421217 Vali Loss: 0.0517315 Test Loss: 0.0557642\n",
      "Validation loss decreased (0.051958 --> 0.051731).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0424594\n",
      "\tspeed: 0.0348s/iter; left time: 19.8479s\n",
      "\titers: 200, epoch: 18 | loss: 0.0416625\n",
      "\tspeed: 0.0160s/iter; left time: 7.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0419993 Vali Loss: 0.0518133 Test Loss: 0.0558669\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458638\n",
      "\tspeed: 0.0345s/iter; left time: 11.9865s\n",
      "\titers: 200, epoch: 19 | loss: 0.0417649\n",
      "\tspeed: 0.0159s/iter; left time: 3.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0419249 Vali Loss: 0.0517524 Test Loss: 0.0559174\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0395100\n",
      "\tspeed: 0.0346s/iter; left time: 4.2845s\n",
      "\titers: 200, epoch: 20 | loss: 0.0389466\n",
      "\tspeed: 0.0158s/iter; left time: 0.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0418182 Vali Loss: 0.0516136 Test Loss: 0.0558284\n",
      "Validation loss decreased (0.051731 --> 0.051614).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010105066001415253, rmse:0.10052395612001419, mae:0.05582839623093605, rse:0.3878186345100403\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0966236\n",
      "\tspeed: 0.0182s/iter; left time: 79.5105s\n",
      "\titers: 200, epoch: 1 | loss: 0.0831524\n",
      "\tspeed: 0.0159s/iter; left time: 67.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0996807 Vali Loss: 0.0866263 Test Loss: 0.0948209\n",
      "Validation loss decreased (inf --> 0.086626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0560986\n",
      "\tspeed: 0.0339s/iter; left time: 140.0796s\n",
      "\titers: 200, epoch: 2 | loss: 0.0508434\n",
      "\tspeed: 0.0161s/iter; left time: 64.8636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0576257 Vali Loss: 0.0589958 Test Loss: 0.0621614\n",
      "Validation loss decreased (0.086626 --> 0.058996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0485006\n",
      "\tspeed: 0.0342s/iter; left time: 133.7562s\n",
      "\titers: 200, epoch: 3 | loss: 0.0468709\n",
      "\tspeed: 0.0158s/iter; left time: 60.4264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0497620 Vali Loss: 0.0565754 Test Loss: 0.0597500\n",
      "Validation loss decreased (0.058996 --> 0.056575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0507864\n",
      "\tspeed: 0.0342s/iter; left time: 126.2259s\n",
      "\titers: 200, epoch: 4 | loss: 0.0469318\n",
      "\tspeed: 0.0160s/iter; left time: 57.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0478137 Vali Loss: 0.0554897 Test Loss: 0.0588700\n",
      "Validation loss decreased (0.056575 --> 0.055490).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0535418\n",
      "\tspeed: 0.0342s/iter; left time: 118.6495s\n",
      "\titers: 200, epoch: 5 | loss: 0.0447104\n",
      "\tspeed: 0.0159s/iter; left time: 53.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0465286 Vali Loss: 0.0546580 Test Loss: 0.0579263\n",
      "Validation loss decreased (0.055490 --> 0.054658).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0462863\n",
      "\tspeed: 0.0337s/iter; left time: 109.3456s\n",
      "\titers: 200, epoch: 6 | loss: 0.0456071\n",
      "\tspeed: 0.0158s/iter; left time: 49.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0455566 Vali Loss: 0.0539158 Test Loss: 0.0573759\n",
      "Validation loss decreased (0.054658 --> 0.053916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0444433\n",
      "\tspeed: 0.0336s/iter; left time: 101.7017s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428787\n",
      "\tspeed: 0.0159s/iter; left time: 46.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0448679 Vali Loss: 0.0532714 Test Loss: 0.0572128\n",
      "Validation loss decreased (0.053916 --> 0.053271).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460071\n",
      "\tspeed: 0.0338s/iter; left time: 94.7605s\n",
      "\titers: 200, epoch: 8 | loss: 0.0459002\n",
      "\tspeed: 0.0160s/iter; left time: 43.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0443385 Vali Loss: 0.0529571 Test Loss: 0.0568479\n",
      "Validation loss decreased (0.053271 --> 0.052957).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0424217\n",
      "\tspeed: 0.0337s/iter; left time: 86.8745s\n",
      "\titers: 200, epoch: 9 | loss: 0.0430727\n",
      "\tspeed: 0.0159s/iter; left time: 39.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0438715 Vali Loss: 0.0525021 Test Loss: 0.0568678\n",
      "Validation loss decreased (0.052957 --> 0.052502).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457912\n",
      "\tspeed: 0.0340s/iter; left time: 80.0129s\n",
      "\titers: 200, epoch: 10 | loss: 0.0435112\n",
      "\tspeed: 0.0158s/iter; left time: 35.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0434994 Vali Loss: 0.0523804 Test Loss: 0.0565236\n",
      "Validation loss decreased (0.052502 --> 0.052380).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424530\n",
      "\tspeed: 0.0348s/iter; left time: 74.2307s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401238\n",
      "\tspeed: 0.0159s/iter; left time: 32.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0431947 Vali Loss: 0.0520191 Test Loss: 0.0563543\n",
      "Validation loss decreased (0.052380 --> 0.052019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0404953\n",
      "\tspeed: 0.0337s/iter; left time: 64.2675s\n",
      "\titers: 200, epoch: 12 | loss: 0.0433915\n",
      "\tspeed: 0.0158s/iter; left time: 28.5523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0429699 Vali Loss: 0.0522495 Test Loss: 0.0565029\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0419378\n",
      "\tspeed: 0.0333s/iter; left time: 56.1313s\n",
      "\titers: 200, epoch: 13 | loss: 0.0411598\n",
      "\tspeed: 0.0158s/iter; left time: 25.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0426828 Vali Loss: 0.0520837 Test Loss: 0.0565030\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0409010\n",
      "\tspeed: 0.0334s/iter; left time: 48.8928s\n",
      "\titers: 200, epoch: 14 | loss: 0.0416713\n",
      "\tspeed: 0.0160s/iter; left time: 21.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0425600 Vali Loss: 0.0519739 Test Loss: 0.0559947\n",
      "Validation loss decreased (0.052019 --> 0.051974).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0412968\n",
      "\tspeed: 0.0344s/iter; left time: 42.6796s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421452\n",
      "\tspeed: 0.0159s/iter; left time: 18.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0423573 Vali Loss: 0.0517680 Test Loss: 0.0560328\n",
      "Validation loss decreased (0.051974 --> 0.051768).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0413271\n",
      "\tspeed: 0.0337s/iter; left time: 34.2554s\n",
      "\titers: 200, epoch: 16 | loss: 0.0467588\n",
      "\tspeed: 0.0158s/iter; left time: 14.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0421538 Vali Loss: 0.0516503 Test Loss: 0.0558049\n",
      "Validation loss decreased (0.051768 --> 0.051650).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423275\n",
      "\tspeed: 0.0339s/iter; left time: 26.9066s\n",
      "\titers: 200, epoch: 17 | loss: 0.0465122\n",
      "\tspeed: 0.0158s/iter; left time: 10.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0421002 Vali Loss: 0.0517575 Test Loss: 0.0560114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0405653\n",
      "\tspeed: 0.0336s/iter; left time: 19.1664s\n",
      "\titers: 200, epoch: 18 | loss: 0.0397078\n",
      "\tspeed: 0.0159s/iter; left time: 7.4614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0419517 Vali Loss: 0.0514324 Test Loss: 0.0559192\n",
      "Validation loss decreased (0.051650 --> 0.051432).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0389818\n",
      "\tspeed: 0.0344s/iter; left time: 11.9218s\n",
      "\titers: 200, epoch: 19 | loss: 0.0445144\n",
      "\tspeed: 0.0159s/iter; left time: 3.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0418684 Vali Loss: 0.0514152 Test Loss: 0.0559219\n",
      "Validation loss decreased (0.051432 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0429346\n",
      "\tspeed: 0.0340s/iter; left time: 4.2139s\n",
      "\titers: 200, epoch: 20 | loss: 0.0440913\n",
      "\tspeed: 0.0158s/iter; left time: 0.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0417579 Vali Loss: 0.0515154 Test Loss: 0.0558122\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010080426931381226, rmse:0.10040132701396942, mae:0.055921897292137146, rse:0.387345552444458\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:30.31s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1062729\n",
      "\tspeed: 0.0359s/iter; left time: 155.6992s\n",
      "\titers: 200, epoch: 1 | loss: 0.0912535\n",
      "\tspeed: 0.0161s/iter; left time: 68.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.1059553 Vali Loss: 0.0940188 Test Loss: 0.1034623\n",
      "Validation loss decreased (inf --> 0.094019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692657\n",
      "\tspeed: 0.0354s/iter; left time: 145.9809s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679127\n",
      "\tspeed: 0.0160s/iter; left time: 64.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0712136 Vali Loss: 0.0755337 Test Loss: 0.0831639\n",
      "Validation loss decreased (0.094019 --> 0.075534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0644198\n",
      "\tspeed: 0.0351s/iter; left time: 136.8146s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641778\n",
      "\tspeed: 0.0160s/iter; left time: 60.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0641186 Vali Loss: 0.0729066 Test Loss: 0.0819365\n",
      "Validation loss decreased (0.075534 --> 0.072907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0631415\n",
      "\tspeed: 0.0350s/iter; left time: 128.7882s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631826\n",
      "\tspeed: 0.0160s/iter; left time: 57.1395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0622656 Vali Loss: 0.0719733 Test Loss: 0.0818505\n",
      "Validation loss decreased (0.072907 --> 0.071973).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571297\n",
      "\tspeed: 0.0348s/iter; left time: 120.1803s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588143\n",
      "\tspeed: 0.0159s/iter; left time: 53.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0612333 Vali Loss: 0.0714952 Test Loss: 0.0811877\n",
      "Validation loss decreased (0.071973 --> 0.071495).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595467\n",
      "\tspeed: 0.0357s/iter; left time: 115.2153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0609350\n",
      "\tspeed: 0.0160s/iter; left time: 50.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0604214 Vali Loss: 0.0708795 Test Loss: 0.0811347\n",
      "Validation loss decreased (0.071495 --> 0.070879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608792\n",
      "\tspeed: 0.0347s/iter; left time: 104.5403s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585211\n",
      "\tspeed: 0.0159s/iter; left time: 46.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0597737 Vali Loss: 0.0705817 Test Loss: 0.0810214\n",
      "Validation loss decreased (0.070879 --> 0.070582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0610314\n",
      "\tspeed: 0.0355s/iter; left time: 98.9216s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618555\n",
      "\tspeed: 0.0160s/iter; left time: 42.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0592500 Vali Loss: 0.0704232 Test Loss: 0.0813442\n",
      "Validation loss decreased (0.070582 --> 0.070423).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571530\n",
      "\tspeed: 0.0362s/iter; left time: 92.7466s\n",
      "\titers: 200, epoch: 9 | loss: 0.0578120\n",
      "\tspeed: 0.0160s/iter; left time: 39.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0587209 Vali Loss: 0.0699692 Test Loss: 0.0809877\n",
      "Validation loss decreased (0.070423 --> 0.069969).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548690\n",
      "\tspeed: 0.0349s/iter; left time: 81.8591s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623343\n",
      "\tspeed: 0.0160s/iter; left time: 35.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0583109 Vali Loss: 0.0701566 Test Loss: 0.0808541\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622497\n",
      "\tspeed: 0.0352s/iter; left time: 74.7248s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519874\n",
      "\tspeed: 0.0159s/iter; left time: 32.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0579716 Vali Loss: 0.0699671 Test Loss: 0.0806739\n",
      "Validation loss decreased (0.069969 --> 0.069967).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0575550\n",
      "\tspeed: 0.0355s/iter; left time: 67.4563s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585573\n",
      "\tspeed: 0.0160s/iter; left time: 28.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0576525 Vali Loss: 0.0699727 Test Loss: 0.0805810\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0560351\n",
      "\tspeed: 0.0343s/iter; left time: 57.6002s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602073\n",
      "\tspeed: 0.0160s/iter; left time: 25.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0573944 Vali Loss: 0.0700975 Test Loss: 0.0805544\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0595173\n",
      "\tspeed: 0.0351s/iter; left time: 51.0643s\n",
      "\titers: 200, epoch: 14 | loss: 0.0593522\n",
      "\tspeed: 0.0160s/iter; left time: 21.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0570652 Vali Loss: 0.0699457 Test Loss: 0.0812258\n",
      "Validation loss decreased (0.069967 --> 0.069946).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574924\n",
      "\tspeed: 0.0348s/iter; left time: 42.9645s\n",
      "\titers: 200, epoch: 15 | loss: 0.0550430\n",
      "\tspeed: 0.0160s/iter; left time: 18.1093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0568423 Vali Loss: 0.0700274 Test Loss: 0.0809713\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0535070\n",
      "\tspeed: 0.0350s/iter; left time: 35.4056s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542754\n",
      "\tspeed: 0.0160s/iter; left time: 14.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0566337 Vali Loss: 0.0701664 Test Loss: 0.0816400\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0580005\n",
      "\tspeed: 0.0345s/iter; left time: 27.2490s\n",
      "\titers: 200, epoch: 17 | loss: 0.0568877\n",
      "\tspeed: 0.0159s/iter; left time: 10.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0564597 Vali Loss: 0.0703682 Test Loss: 0.0816390\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549882\n",
      "\tspeed: 0.0348s/iter; left time: 19.7149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0590507\n",
      "\tspeed: 0.0160s/iter; left time: 7.4582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0562345 Vali Loss: 0.0703658 Test Loss: 0.0810546\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550113\n",
      "\tspeed: 0.0342s/iter; left time: 11.8030s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547352\n",
      "\tspeed: 0.0160s/iter; left time: 3.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0560780 Vali Loss: 0.0702507 Test Loss: 0.0813001\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01962335966527462, rmse:0.1400834023952484, mae:0.08122573792934418, rse:0.5418798327445984\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1078227\n",
      "\tspeed: 0.0180s/iter; left time: 78.0620s\n",
      "\titers: 200, epoch: 1 | loss: 0.0919140\n",
      "\tspeed: 0.0160s/iter; left time: 67.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.1105704 Vali Loss: 0.0957569 Test Loss: 0.1053015\n",
      "Validation loss decreased (inf --> 0.095757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0682901\n",
      "\tspeed: 0.0397s/iter; left time: 163.5504s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670406\n",
      "\tspeed: 0.0160s/iter; left time: 64.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0716458 Vali Loss: 0.0761554 Test Loss: 0.0831043\n",
      "Validation loss decreased (0.095757 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646815\n",
      "\tspeed: 0.0358s/iter; left time: 139.5242s\n",
      "\titers: 200, epoch: 3 | loss: 0.0648520\n",
      "\tspeed: 0.0160s/iter; left time: 60.8137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0644725 Vali Loss: 0.0730400 Test Loss: 0.0815544\n",
      "Validation loss decreased (0.076155 --> 0.073040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611014\n",
      "\tspeed: 0.0355s/iter; left time: 130.4014s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635274\n",
      "\tspeed: 0.0160s/iter; left time: 57.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0622755 Vali Loss: 0.0722037 Test Loss: 0.0812116\n",
      "Validation loss decreased (0.073040 --> 0.072204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0589142\n",
      "\tspeed: 0.0351s/iter; left time: 121.1258s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596506\n",
      "\tspeed: 0.0159s/iter; left time: 53.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0610804 Vali Loss: 0.0714846 Test Loss: 0.0806093\n",
      "Validation loss decreased (0.072204 --> 0.071485).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605698\n",
      "\tspeed: 0.0351s/iter; left time: 113.3552s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608675\n",
      "\tspeed: 0.0160s/iter; left time: 50.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0601794 Vali Loss: 0.0713318 Test Loss: 0.0810132\n",
      "Validation loss decreased (0.071485 --> 0.071332).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621530\n",
      "\tspeed: 0.0357s/iter; left time: 107.4047s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595966\n",
      "\tspeed: 0.0159s/iter; left time: 46.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0595918 Vali Loss: 0.0705500 Test Loss: 0.0805443\n",
      "Validation loss decreased (0.071332 --> 0.070550).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580288\n",
      "\tspeed: 0.0350s/iter; left time: 97.6625s\n",
      "\titers: 200, epoch: 8 | loss: 0.0600862\n",
      "\tspeed: 0.0160s/iter; left time: 42.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0590850 Vali Loss: 0.0703057 Test Loss: 0.0803361\n",
      "Validation loss decreased (0.070550 --> 0.070306).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0597476\n",
      "\tspeed: 0.0351s/iter; left time: 90.1559s\n",
      "\titers: 200, epoch: 9 | loss: 0.0554207\n",
      "\tspeed: 0.0160s/iter; left time: 39.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0585846 Vali Loss: 0.0704701 Test Loss: 0.0806231\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590830\n",
      "\tspeed: 0.0346s/iter; left time: 81.1780s\n",
      "\titers: 200, epoch: 10 | loss: 0.0564615\n",
      "\tspeed: 0.0160s/iter; left time: 35.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0582434 Vali Loss: 0.0699931 Test Loss: 0.0800337\n",
      "Validation loss decreased (0.070306 --> 0.069993).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569817\n",
      "\tspeed: 0.0353s/iter; left time: 74.8217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0594220\n",
      "\tspeed: 0.0159s/iter; left time: 32.2050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0578705 Vali Loss: 0.0699769 Test Loss: 0.0801870\n",
      "Validation loss decreased (0.069993 --> 0.069977).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0588046\n",
      "\tspeed: 0.0350s/iter; left time: 66.4214s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607358\n",
      "\tspeed: 0.0160s/iter; left time: 28.7534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0575100 Vali Loss: 0.0699266 Test Loss: 0.0803907\n",
      "Validation loss decreased (0.069977 --> 0.069927).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0585321\n",
      "\tspeed: 0.0355s/iter; left time: 59.4517s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579361\n",
      "\tspeed: 0.0160s/iter; left time: 25.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0572901 Vali Loss: 0.0701751 Test Loss: 0.0807457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0538667\n",
      "\tspeed: 0.0352s/iter; left time: 51.1925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0604858\n",
      "\tspeed: 0.0160s/iter; left time: 21.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0569633 Vali Loss: 0.0702045 Test Loss: 0.0805202\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0575523\n",
      "\tspeed: 0.0347s/iter; left time: 42.8014s\n",
      "\titers: 200, epoch: 15 | loss: 0.0541610\n",
      "\tspeed: 0.0160s/iter; left time: 18.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0567761 Vali Loss: 0.0700288 Test Loss: 0.0802097\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0554736\n",
      "\tspeed: 0.0350s/iter; left time: 35.3416s\n",
      "\titers: 200, epoch: 16 | loss: 0.0513818\n",
      "\tspeed: 0.0160s/iter; left time: 14.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0565431 Vali Loss: 0.0701111 Test Loss: 0.0806726\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571790\n",
      "\tspeed: 0.0352s/iter; left time: 27.7666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549147\n",
      "\tspeed: 0.0160s/iter; left time: 10.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0564075 Vali Loss: 0.0702400 Test Loss: 0.0804368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01921806111931801, rmse:0.1386292278766632, mae:0.08039069920778275, rse:0.5362547039985657\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:13.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1038085\n",
      "\tspeed: 0.0377s/iter; left time: 163.5113s\n",
      "\titers: 200, epoch: 1 | loss: 0.0886158\n",
      "\tspeed: 0.0163s/iter; left time: 68.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.1091605 Vali Loss: 0.0966437 Test Loss: 0.1046350\n",
      "Validation loss decreased (inf --> 0.096644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0697438\n",
      "\tspeed: 0.0360s/iter; left time: 148.2359s\n",
      "\titers: 200, epoch: 2 | loss: 0.0691064\n",
      "\tspeed: 0.0163s/iter; left time: 65.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0750519 Vali Loss: 0.0789187 Test Loss: 0.0872487\n",
      "Validation loss decreased (0.096644 --> 0.078919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0678330\n",
      "\tspeed: 0.0364s/iter; left time: 141.7553s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678092\n",
      "\tspeed: 0.0163s/iter; left time: 62.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0678947 Vali Loss: 0.0768626 Test Loss: 0.0861012\n",
      "Validation loss decreased (0.078919 --> 0.076863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657281\n",
      "\tspeed: 0.0368s/iter; left time: 135.1291s\n",
      "\titers: 200, epoch: 4 | loss: 0.0660678\n",
      "\tspeed: 0.0164s/iter; left time: 58.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0660797 Vali Loss: 0.0759090 Test Loss: 0.0861572\n",
      "Validation loss decreased (0.076863 --> 0.075909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0692789\n",
      "\tspeed: 0.0368s/iter; left time: 127.1159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646435\n",
      "\tspeed: 0.0164s/iter; left time: 54.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0650898 Vali Loss: 0.0755803 Test Loss: 0.0858476\n",
      "Validation loss decreased (0.075909 --> 0.075580).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0632229\n",
      "\tspeed: 0.0370s/iter; left time: 119.4200s\n",
      "\titers: 200, epoch: 6 | loss: 0.0647839\n",
      "\tspeed: 0.0163s/iter; left time: 51.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0642895 Vali Loss: 0.0752362 Test Loss: 0.0858734\n",
      "Validation loss decreased (0.075580 --> 0.075236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630247\n",
      "\tspeed: 0.0367s/iter; left time: 110.3919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0642375\n",
      "\tspeed: 0.0164s/iter; left time: 47.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0636251 Vali Loss: 0.0747174 Test Loss: 0.0859729\n",
      "Validation loss decreased (0.075236 --> 0.074717).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0634076\n",
      "\tspeed: 0.0369s/iter; left time: 102.9495s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629932\n",
      "\tspeed: 0.0164s/iter; left time: 43.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0630702 Vali Loss: 0.0744353 Test Loss: 0.0859410\n",
      "Validation loss decreased (0.074717 --> 0.074435).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623881\n",
      "\tspeed: 0.0369s/iter; left time: 94.6838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627867\n",
      "\tspeed: 0.0164s/iter; left time: 40.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0625488 Vali Loss: 0.0742188 Test Loss: 0.0858460\n",
      "Validation loss decreased (0.074435 --> 0.074219).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612790\n",
      "\tspeed: 0.0368s/iter; left time: 86.3386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0607237\n",
      "\tspeed: 0.0162s/iter; left time: 36.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0621399 Vali Loss: 0.0741986 Test Loss: 0.0865132\n",
      "Validation loss decreased (0.074219 --> 0.074199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0644236\n",
      "\tspeed: 0.0367s/iter; left time: 77.8404s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592703\n",
      "\tspeed: 0.0162s/iter; left time: 32.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0617343 Vali Loss: 0.0741677 Test Loss: 0.0863853\n",
      "Validation loss decreased (0.074199 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644370\n",
      "\tspeed: 0.0354s/iter; left time: 67.1966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0639723\n",
      "\tspeed: 0.0164s/iter; left time: 29.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0613191 Vali Loss: 0.0743162 Test Loss: 0.0861957\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559229\n",
      "\tspeed: 0.0355s/iter; left time: 59.4999s\n",
      "\titers: 200, epoch: 13 | loss: 0.0556470\n",
      "\tspeed: 0.0164s/iter; left time: 25.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0609983 Vali Loss: 0.0742826 Test Loss: 0.0860600\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603098\n",
      "\tspeed: 0.0372s/iter; left time: 54.0824s\n",
      "\titers: 200, epoch: 14 | loss: 0.0619693\n",
      "\tspeed: 0.0163s/iter; left time: 22.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0607090 Vali Loss: 0.0742746 Test Loss: 0.0869348\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0594293\n",
      "\tspeed: 0.0365s/iter; left time: 45.0203s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618856\n",
      "\tspeed: 0.0163s/iter; left time: 18.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0604436 Vali Loss: 0.0745566 Test Loss: 0.0866983\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0625551\n",
      "\tspeed: 0.0363s/iter; left time: 36.7402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558443\n",
      "\tspeed: 0.0162s/iter; left time: 14.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0601866 Vali Loss: 0.0745793 Test Loss: 0.0866429\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021192140877246857, rmse:0.14557521045207977, mae:0.08638525754213333, rse:0.5638265609741211\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1135118\n",
      "\tspeed: 0.0188s/iter; left time: 81.6290s\n",
      "\titers: 200, epoch: 1 | loss: 0.0940110\n",
      "\tspeed: 0.0163s/iter; left time: 69.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.1127467 Vali Loss: 0.0989019 Test Loss: 0.1072703\n",
      "Validation loss decreased (inf --> 0.098902).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0719645\n",
      "\tspeed: 0.0365s/iter; left time: 150.4048s\n",
      "\titers: 200, epoch: 2 | loss: 0.0684651\n",
      "\tspeed: 0.0162s/iter; left time: 65.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0751835 Vali Loss: 0.0800323 Test Loss: 0.0873625\n",
      "Validation loss decreased (0.098902 --> 0.080032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689290\n",
      "\tspeed: 0.0359s/iter; left time: 139.7419s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709937\n",
      "\tspeed: 0.0163s/iter; left time: 61.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0680559 Vali Loss: 0.0771532 Test Loss: 0.0864900\n",
      "Validation loss decreased (0.080032 --> 0.077153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659223\n",
      "\tspeed: 0.0357s/iter; left time: 131.1153s\n",
      "\titers: 200, epoch: 4 | loss: 0.0657936\n",
      "\tspeed: 0.0162s/iter; left time: 57.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0660471 Vali Loss: 0.0762054 Test Loss: 0.0858534\n",
      "Validation loss decreased (0.077153 --> 0.076205).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649723\n",
      "\tspeed: 0.0361s/iter; left time: 124.6838s\n",
      "\titers: 200, epoch: 5 | loss: 0.0645800\n",
      "\tspeed: 0.0162s/iter; left time: 54.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0649682 Vali Loss: 0.0755172 Test Loss: 0.0858298\n",
      "Validation loss decreased (0.076205 --> 0.075517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638525\n",
      "\tspeed: 0.0361s/iter; left time: 116.6168s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692233\n",
      "\tspeed: 0.0162s/iter; left time: 50.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0641383 Vali Loss: 0.0747725 Test Loss: 0.0852236\n",
      "Validation loss decreased (0.075517 --> 0.074772).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0632401\n",
      "\tspeed: 0.0362s/iter; left time: 108.8773s\n",
      "\titers: 200, epoch: 7 | loss: 0.0642724\n",
      "\tspeed: 0.0161s/iter; left time: 46.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0635255 Vali Loss: 0.0748693 Test Loss: 0.0857978\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0645528\n",
      "\tspeed: 0.0352s/iter; left time: 98.0240s\n",
      "\titers: 200, epoch: 8 | loss: 0.0622234\n",
      "\tspeed: 0.0162s/iter; left time: 43.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0629626 Vali Loss: 0.0748626 Test Loss: 0.0853991\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0617922\n",
      "\tspeed: 0.0354s/iter; left time: 90.7450s\n",
      "\titers: 200, epoch: 9 | loss: 0.0606463\n",
      "\tspeed: 0.0163s/iter; left time: 40.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0624070 Vali Loss: 0.0747745 Test Loss: 0.0854686\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615385\n",
      "\tspeed: 0.0355s/iter; left time: 83.2530s\n",
      "\titers: 200, epoch: 10 | loss: 0.0650223\n",
      "\tspeed: 0.0162s/iter; left time: 36.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0618398 Vali Loss: 0.0752747 Test Loss: 0.0857516\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0613751\n",
      "\tspeed: 0.0354s/iter; left time: 74.9882s\n",
      "\titers: 200, epoch: 11 | loss: 0.0621263\n",
      "\tspeed: 0.0162s/iter; left time: 32.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0614129 Vali Loss: 0.0749968 Test Loss: 0.0854146\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020490793511271477, rmse:0.14314605295658112, mae:0.08522367477416992, rse:0.5544182062149048\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:32.45s\n",
      "Intermediate time for FR: 00h:09m:16.54s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1427019\n",
      "\tspeed: 0.0363s/iter; left time: 158.1655s\n",
      "\titers: 200, epoch: 1 | loss: 0.1210744\n",
      "\tspeed: 0.0159s/iter; left time: 67.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1474612 Vali Loss: 0.1040003 Test Loss: 0.1061004\n",
      "Validation loss decreased (inf --> 0.104000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786053\n",
      "\tspeed: 0.0344s/iter; left time: 142.4891s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688016\n",
      "\tspeed: 0.0158s/iter; left time: 63.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0795060 Vali Loss: 0.0627535 Test Loss: 0.0660522\n",
      "Validation loss decreased (0.104000 --> 0.062754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0712326\n",
      "\tspeed: 0.0339s/iter; left time: 132.5366s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645262\n",
      "\tspeed: 0.0158s/iter; left time: 60.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0662299 Vali Loss: 0.0600951 Test Loss: 0.0631527\n",
      "Validation loss decreased (0.062754 --> 0.060095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637566\n",
      "\tspeed: 0.0338s/iter; left time: 124.6487s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638368\n",
      "\tspeed: 0.0158s/iter; left time: 56.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0632282 Vali Loss: 0.0587887 Test Loss: 0.0614277\n",
      "Validation loss decreased (0.060095 --> 0.058789).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0593576\n",
      "\tspeed: 0.0356s/iter; left time: 123.3242s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606443\n",
      "\tspeed: 0.0159s/iter; left time: 53.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0614621 Vali Loss: 0.0578707 Test Loss: 0.0606217\n",
      "Validation loss decreased (0.058789 --> 0.057871).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630265\n",
      "\tspeed: 0.0348s/iter; left time: 112.8025s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619991\n",
      "\tspeed: 0.0159s/iter; left time: 49.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0602812 Vali Loss: 0.0573779 Test Loss: 0.0601057\n",
      "Validation loss decreased (0.057871 --> 0.057378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639013\n",
      "\tspeed: 0.0345s/iter; left time: 104.4238s\n",
      "\titers: 200, epoch: 7 | loss: 0.0623509\n",
      "\tspeed: 0.0159s/iter; left time: 46.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0593809 Vali Loss: 0.0566655 Test Loss: 0.0593408\n",
      "Validation loss decreased (0.057378 --> 0.056665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575579\n",
      "\tspeed: 0.0344s/iter; left time: 96.3420s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638874\n",
      "\tspeed: 0.0159s/iter; left time: 42.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0586741 Vali Loss: 0.0564011 Test Loss: 0.0590913\n",
      "Validation loss decreased (0.056665 --> 0.056401).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0573168\n",
      "\tspeed: 0.0343s/iter; left time: 88.4229s\n",
      "\titers: 200, epoch: 9 | loss: 0.0594589\n",
      "\tspeed: 0.0158s/iter; left time: 39.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0580785 Vali Loss: 0.0563285 Test Loss: 0.0593507\n",
      "Validation loss decreased (0.056401 --> 0.056329).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577093\n",
      "\tspeed: 0.0345s/iter; left time: 81.3092s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602368\n",
      "\tspeed: 0.0159s/iter; left time: 35.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0576331 Vali Loss: 0.0557669 Test Loss: 0.0586965\n",
      "Validation loss decreased (0.056329 --> 0.055767).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583503\n",
      "\tspeed: 0.0347s/iter; left time: 74.0092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567511\n",
      "\tspeed: 0.0159s/iter; left time: 32.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0572207 Vali Loss: 0.0557464 Test Loss: 0.0586863\n",
      "Validation loss decreased (0.055767 --> 0.055746).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0557410\n",
      "\tspeed: 0.0341s/iter; left time: 65.1030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559181\n",
      "\tspeed: 0.0158s/iter; left time: 28.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0568358 Vali Loss: 0.0554589 Test Loss: 0.0583942\n",
      "Validation loss decreased (0.055746 --> 0.055459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571601\n",
      "\tspeed: 0.0350s/iter; left time: 58.9732s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576887\n",
      "\tspeed: 0.0159s/iter; left time: 25.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0564875 Vali Loss: 0.0554860 Test Loss: 0.0581893\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0531539\n",
      "\tspeed: 0.0346s/iter; left time: 50.5925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590748\n",
      "\tspeed: 0.0159s/iter; left time: 21.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0563151 Vali Loss: 0.0553224 Test Loss: 0.0581858\n",
      "Validation loss decreased (0.055459 --> 0.055322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506413\n",
      "\tspeed: 0.0344s/iter; left time: 42.6145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539879\n",
      "\tspeed: 0.0159s/iter; left time: 18.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0560368 Vali Loss: 0.0551295 Test Loss: 0.0582475\n",
      "Validation loss decreased (0.055322 --> 0.055130).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0581412\n",
      "\tspeed: 0.0344s/iter; left time: 34.9065s\n",
      "\titers: 200, epoch: 16 | loss: 0.0519915\n",
      "\tspeed: 0.0159s/iter; left time: 14.5507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0557948 Vali Loss: 0.0549986 Test Loss: 0.0579295\n",
      "Validation loss decreased (0.055130 --> 0.054999).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0555389\n",
      "\tspeed: 0.0344s/iter; left time: 27.2697s\n",
      "\titers: 200, epoch: 17 | loss: 0.0499771\n",
      "\tspeed: 0.0158s/iter; left time: 10.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0556709 Vali Loss: 0.0548981 Test Loss: 0.0580050\n",
      "Validation loss decreased (0.054999 --> 0.054898).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0559821\n",
      "\tspeed: 0.0343s/iter; left time: 19.5616s\n",
      "\titers: 200, epoch: 18 | loss: 0.0539320\n",
      "\tspeed: 0.0159s/iter; left time: 7.4639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0554450 Vali Loss: 0.0548618 Test Loss: 0.0578751\n",
      "Validation loss decreased (0.054898 --> 0.054862).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0516250\n",
      "\tspeed: 0.0358s/iter; left time: 12.4264s\n",
      "\titers: 200, epoch: 19 | loss: 0.0590425\n",
      "\tspeed: 0.0159s/iter; left time: 3.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0553374 Vali Loss: 0.0548607 Test Loss: 0.0577288\n",
      "Validation loss decreased (0.054862 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0521452\n",
      "\tspeed: 0.0343s/iter; left time: 4.2583s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546899\n",
      "\tspeed: 0.0158s/iter; left time: 0.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0552047 Vali Loss: 0.0547884 Test Loss: 0.0577962\n",
      "Validation loss decreased (0.054861 --> 0.054788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010150963440537453, rmse:0.10075198858976364, mae:0.05779622495174408, rse:0.38069215416908264\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1419829\n",
      "\tspeed: 0.0176s/iter; left time: 76.7770s\n",
      "\titers: 200, epoch: 1 | loss: 0.1163189\n",
      "\tspeed: 0.0158s/iter; left time: 67.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1425949 Vali Loss: 0.1023602 Test Loss: 0.1041683\n",
      "Validation loss decreased (inf --> 0.102360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0783880\n",
      "\tspeed: 0.0339s/iter; left time: 140.2696s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679684\n",
      "\tspeed: 0.0159s/iter; left time: 64.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0789644 Vali Loss: 0.0629243 Test Loss: 0.0656664\n",
      "Validation loss decreased (0.102360 --> 0.062924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0616162\n",
      "\tspeed: 0.0341s/iter; left time: 133.5815s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671688\n",
      "\tspeed: 0.0159s/iter; left time: 60.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0660889 Vali Loss: 0.0599624 Test Loss: 0.0629551\n",
      "Validation loss decreased (0.062924 --> 0.059962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610458\n",
      "\tspeed: 0.0337s/iter; left time: 124.3400s\n",
      "\titers: 200, epoch: 4 | loss: 0.0610312\n",
      "\tspeed: 0.0159s/iter; left time: 57.0153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0630342 Vali Loss: 0.0586474 Test Loss: 0.0616444\n",
      "Validation loss decreased (0.059962 --> 0.058647).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571282\n",
      "\tspeed: 0.0336s/iter; left time: 116.7024s\n",
      "\titers: 200, epoch: 5 | loss: 0.0562831\n",
      "\tspeed: 0.0159s/iter; left time: 53.4386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0612929 Vali Loss: 0.0577459 Test Loss: 0.0603331\n",
      "Validation loss decreased (0.058647 --> 0.057746).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608607\n",
      "\tspeed: 0.0341s/iter; left time: 110.5712s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626487\n",
      "\tspeed: 0.0159s/iter; left time: 49.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0600615 Vali Loss: 0.0573048 Test Loss: 0.0600555\n",
      "Validation loss decreased (0.057746 --> 0.057305).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581606\n",
      "\tspeed: 0.0343s/iter; left time: 103.6463s\n",
      "\titers: 200, epoch: 7 | loss: 0.0609005\n",
      "\tspeed: 0.0158s/iter; left time: 46.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0591594 Vali Loss: 0.0566136 Test Loss: 0.0596915\n",
      "Validation loss decreased (0.057305 --> 0.056614).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0592040\n",
      "\tspeed: 0.0344s/iter; left time: 96.1815s\n",
      "\titers: 200, epoch: 8 | loss: 0.0604212\n",
      "\tspeed: 0.0159s/iter; left time: 42.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0584775 Vali Loss: 0.0565187 Test Loss: 0.0593163\n",
      "Validation loss decreased (0.056614 --> 0.056519).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0590639\n",
      "\tspeed: 0.0340s/iter; left time: 87.6995s\n",
      "\titers: 200, epoch: 9 | loss: 0.0605114\n",
      "\tspeed: 0.0159s/iter; left time: 39.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0579033 Vali Loss: 0.0563604 Test Loss: 0.0590891\n",
      "Validation loss decreased (0.056519 --> 0.056360).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0603953\n",
      "\tspeed: 0.0340s/iter; left time: 80.0911s\n",
      "\titers: 200, epoch: 10 | loss: 0.0575978\n",
      "\tspeed: 0.0158s/iter; left time: 35.6807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0574486 Vali Loss: 0.0557433 Test Loss: 0.0589160\n",
      "Validation loss decreased (0.056360 --> 0.055743).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0571903\n",
      "\tspeed: 0.0343s/iter; left time: 73.1867s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529450\n",
      "\tspeed: 0.0158s/iter; left time: 32.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0570072 Vali Loss: 0.0554434 Test Loss: 0.0585258\n",
      "Validation loss decreased (0.055743 --> 0.055443).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591192\n",
      "\tspeed: 0.0337s/iter; left time: 64.3015s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585950\n",
      "\tspeed: 0.0159s/iter; left time: 28.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0567224 Vali Loss: 0.0554773 Test Loss: 0.0584189\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559475\n",
      "\tspeed: 0.0334s/iter; left time: 56.2506s\n",
      "\titers: 200, epoch: 13 | loss: 0.0567616\n",
      "\tspeed: 0.0158s/iter; left time: 25.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0563565 Vali Loss: 0.0550969 Test Loss: 0.0582760\n",
      "Validation loss decreased (0.055443 --> 0.055097).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0556220\n",
      "\tspeed: 0.0338s/iter; left time: 49.4329s\n",
      "\titers: 200, epoch: 14 | loss: 0.0526725\n",
      "\tspeed: 0.0158s/iter; left time: 21.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0560953 Vali Loss: 0.0550480 Test Loss: 0.0581160\n",
      "Validation loss decreased (0.055097 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0577325\n",
      "\tspeed: 0.0343s/iter; left time: 42.4834s\n",
      "\titers: 200, epoch: 15 | loss: 0.0528219\n",
      "\tspeed: 0.0159s/iter; left time: 18.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0559282 Vali Loss: 0.0551110 Test Loss: 0.0581104\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0570617\n",
      "\tspeed: 0.0338s/iter; left time: 34.3473s\n",
      "\titers: 200, epoch: 16 | loss: 0.0573260\n",
      "\tspeed: 0.0158s/iter; left time: 14.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0556951 Vali Loss: 0.0549273 Test Loss: 0.0579408\n",
      "Validation loss decreased (0.055048 --> 0.054927).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0549826\n",
      "\tspeed: 0.0343s/iter; left time: 27.2352s\n",
      "\titers: 200, epoch: 17 | loss: 0.0620541\n",
      "\tspeed: 0.0159s/iter; left time: 11.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0555529 Vali Loss: 0.0548897 Test Loss: 0.0581434\n",
      "Validation loss decreased (0.054927 --> 0.054890).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578782\n",
      "\tspeed: 0.0343s/iter; left time: 19.5326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0545308\n",
      "\tspeed: 0.0158s/iter; left time: 7.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0553632 Vali Loss: 0.0548129 Test Loss: 0.0578101\n",
      "Validation loss decreased (0.054890 --> 0.054813).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525388\n",
      "\tspeed: 0.0341s/iter; left time: 11.8205s\n",
      "\titers: 200, epoch: 19 | loss: 0.0566175\n",
      "\tspeed: 0.0158s/iter; left time: 3.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0552520 Vali Loss: 0.0546502 Test Loss: 0.0578146\n",
      "Validation loss decreased (0.054813 --> 0.054650).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0588491\n",
      "\tspeed: 0.0341s/iter; left time: 4.2281s\n",
      "\titers: 200, epoch: 20 | loss: 0.0545695\n",
      "\tspeed: 0.0159s/iter; left time: 0.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0551397 Vali Loss: 0.0546082 Test Loss: 0.0578759\n",
      "Validation loss decreased (0.054650 --> 0.054608).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010188685730099678, rmse:0.10093902051448822, mae:0.05787594988942146, rse:0.38139885663986206\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:29.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1480092\n",
      "\tspeed: 0.0370s/iter; left time: 160.4701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1285040\n",
      "\tspeed: 0.0162s/iter; left time: 68.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.1509507 Vali Loss: 0.1113291 Test Loss: 0.1137491\n",
      "Validation loss decreased (inf --> 0.111329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0946910\n",
      "\tspeed: 0.0357s/iter; left time: 146.8925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0880413\n",
      "\tspeed: 0.0160s/iter; left time: 64.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0966951 Vali Loss: 0.0821402 Test Loss: 0.0859240\n",
      "Validation loss decreased (0.111329 --> 0.082140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0857038\n",
      "\tspeed: 0.0361s/iter; left time: 140.5135s\n",
      "\titers: 200, epoch: 3 | loss: 0.0834037\n",
      "\tspeed: 0.0162s/iter; left time: 61.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0849271 Vali Loss: 0.0798710 Test Loss: 0.0837083\n",
      "Validation loss decreased (0.082140 --> 0.079871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806999\n",
      "\tspeed: 0.0355s/iter; left time: 130.3716s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802332\n",
      "\tspeed: 0.0161s/iter; left time: 57.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0820312 Vali Loss: 0.0793059 Test Loss: 0.0828319\n",
      "Validation loss decreased (0.079871 --> 0.079306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0756191\n",
      "\tspeed: 0.0364s/iter; left time: 125.6975s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793900\n",
      "\tspeed: 0.0162s/iter; left time: 54.3952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0802160 Vali Loss: 0.0782365 Test Loss: 0.0818849\n",
      "Validation loss decreased (0.079306 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778672\n",
      "\tspeed: 0.0356s/iter; left time: 114.9772s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811385\n",
      "\tspeed: 0.0160s/iter; left time: 50.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0789857 Vali Loss: 0.0778599 Test Loss: 0.0823483\n",
      "Validation loss decreased (0.078237 --> 0.077860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0805226\n",
      "\tspeed: 0.0352s/iter; left time: 105.8812s\n",
      "\titers: 200, epoch: 7 | loss: 0.0763721\n",
      "\tspeed: 0.0159s/iter; left time: 46.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0780315 Vali Loss: 0.0776080 Test Loss: 0.0814997\n",
      "Validation loss decreased (0.077860 --> 0.077608).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774337\n",
      "\tspeed: 0.0362s/iter; left time: 100.8269s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790309\n",
      "\tspeed: 0.0160s/iter; left time: 43.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0772947 Vali Loss: 0.0778682 Test Loss: 0.0816363\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766557\n",
      "\tspeed: 0.0353s/iter; left time: 90.5842s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757727\n",
      "\tspeed: 0.0159s/iter; left time: 39.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0766040 Vali Loss: 0.0773319 Test Loss: 0.0813767\n",
      "Validation loss decreased (0.077608 --> 0.077332).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735397\n",
      "\tspeed: 0.0357s/iter; left time: 83.7234s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794665\n",
      "\tspeed: 0.0161s/iter; left time: 36.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0760296 Vali Loss: 0.0770209 Test Loss: 0.0814560\n",
      "Validation loss decreased (0.077332 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747499\n",
      "\tspeed: 0.0362s/iter; left time: 76.8261s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756375\n",
      "\tspeed: 0.0160s/iter; left time: 32.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0754948 Vali Loss: 0.0773987 Test Loss: 0.0817112\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0736938\n",
      "\tspeed: 0.0354s/iter; left time: 67.1702s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756246\n",
      "\tspeed: 0.0161s/iter; left time: 29.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0751052 Vali Loss: 0.0768902 Test Loss: 0.0815840\n",
      "Validation loss decreased (0.077021 --> 0.076890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766086\n",
      "\tspeed: 0.0360s/iter; left time: 60.4472s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705611\n",
      "\tspeed: 0.0160s/iter; left time: 25.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0746385 Vali Loss: 0.0769166 Test Loss: 0.0817023\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752744\n",
      "\tspeed: 0.0350s/iter; left time: 50.8896s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727744\n",
      "\tspeed: 0.0161s/iter; left time: 21.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0742598 Vali Loss: 0.0771264 Test Loss: 0.0818628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718330\n",
      "\tspeed: 0.0355s/iter; left time: 43.8115s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762048\n",
      "\tspeed: 0.0160s/iter; left time: 18.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0739807 Vali Loss: 0.0771396 Test Loss: 0.0821665\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717527\n",
      "\tspeed: 0.0350s/iter; left time: 35.3380s\n",
      "\titers: 200, epoch: 16 | loss: 0.0717268\n",
      "\tspeed: 0.0160s/iter; left time: 14.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0736803 Vali Loss: 0.0769131 Test Loss: 0.0820079\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754391\n",
      "\tspeed: 0.0350s/iter; left time: 27.6282s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759702\n",
      "\tspeed: 0.0161s/iter; left time: 11.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0734304 Vali Loss: 0.0771116 Test Loss: 0.0819217\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01853265054523945, rmse:0.13613468408584595, mae:0.08158402144908905, rse:0.5147398710250854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1507262\n",
      "\tspeed: 0.0182s/iter; left time: 78.9177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1296732\n",
      "\tspeed: 0.0161s/iter; left time: 68.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.1529816 Vali Loss: 0.1123396 Test Loss: 0.1146337\n",
      "Validation loss decreased (inf --> 0.112340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0957740\n",
      "\tspeed: 0.0353s/iter; left time: 145.3642s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912199\n",
      "\tspeed: 0.0161s/iter; left time: 64.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0967408 Vali Loss: 0.0821385 Test Loss: 0.0859979\n",
      "Validation loss decreased (0.112340 --> 0.082139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0844245\n",
      "\tspeed: 0.0355s/iter; left time: 138.3264s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819175\n",
      "\tspeed: 0.0160s/iter; left time: 60.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0851410 Vali Loss: 0.0801685 Test Loss: 0.0838451\n",
      "Validation loss decreased (0.082139 --> 0.080168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814081\n",
      "\tspeed: 0.0409s/iter; left time: 150.4567s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809551\n",
      "\tspeed: 0.0160s/iter; left time: 57.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0821676 Vali Loss: 0.0793425 Test Loss: 0.0831998\n",
      "Validation loss decreased (0.080168 --> 0.079343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829052\n",
      "\tspeed: 0.0353s/iter; left time: 121.7924s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803125\n",
      "\tspeed: 0.0160s/iter; left time: 53.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0804876 Vali Loss: 0.0786416 Test Loss: 0.0830506\n",
      "Validation loss decreased (0.079343 --> 0.078642).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778762\n",
      "\tspeed: 0.0353s/iter; left time: 114.0085s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792146\n",
      "\tspeed: 0.0160s/iter; left time: 50.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0793187 Vali Loss: 0.0780971 Test Loss: 0.0822130\n",
      "Validation loss decreased (0.078642 --> 0.078097).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764227\n",
      "\tspeed: 0.0364s/iter; left time: 109.6671s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742595\n",
      "\tspeed: 0.0160s/iter; left time: 46.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0782462 Vali Loss: 0.0779555 Test Loss: 0.0821601\n",
      "Validation loss decreased (0.078097 --> 0.077956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778910\n",
      "\tspeed: 0.0352s/iter; left time: 97.9670s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733860\n",
      "\tspeed: 0.0159s/iter; left time: 42.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0773523 Vali Loss: 0.0774524 Test Loss: 0.0818950\n",
      "Validation loss decreased (0.077956 --> 0.077452).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808572\n",
      "\tspeed: 0.0351s/iter; left time: 90.1073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805296\n",
      "\tspeed: 0.0159s/iter; left time: 39.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0766624 Vali Loss: 0.0771591 Test Loss: 0.0819085\n",
      "Validation loss decreased (0.077452 --> 0.077159).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751476\n",
      "\tspeed: 0.0354s/iter; left time: 82.9250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0752530\n",
      "\tspeed: 0.0160s/iter; left time: 35.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0759507 Vali Loss: 0.0773464 Test Loss: 0.0817901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720942\n",
      "\tspeed: 0.0352s/iter; left time: 74.6418s\n",
      "\titers: 200, epoch: 11 | loss: 0.0721641\n",
      "\tspeed: 0.0160s/iter; left time: 32.3252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0754021 Vali Loss: 0.0770691 Test Loss: 0.0819440\n",
      "Validation loss decreased (0.077159 --> 0.077069).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0719355\n",
      "\tspeed: 0.0350s/iter; left time: 66.4300s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729342\n",
      "\tspeed: 0.0159s/iter; left time: 28.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0748713 Vali Loss: 0.0770017 Test Loss: 0.0820037\n",
      "Validation loss decreased (0.077069 --> 0.077002).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721806\n",
      "\tspeed: 0.0349s/iter; left time: 58.6059s\n",
      "\titers: 200, epoch: 13 | loss: 0.0732604\n",
      "\tspeed: 0.0160s/iter; left time: 25.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0744331 Vali Loss: 0.0770994 Test Loss: 0.0822397\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719807\n",
      "\tspeed: 0.0345s/iter; left time: 50.2128s\n",
      "\titers: 200, epoch: 14 | loss: 0.0775819\n",
      "\tspeed: 0.0160s/iter; left time: 21.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0740726 Vali Loss: 0.0769238 Test Loss: 0.0821027\n",
      "Validation loss decreased (0.077002 --> 0.076924).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717604\n",
      "\tspeed: 0.0353s/iter; left time: 43.5640s\n",
      "\titers: 200, epoch: 15 | loss: 0.0755598\n",
      "\tspeed: 0.0159s/iter; left time: 18.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0737268 Vali Loss: 0.0769512 Test Loss: 0.0821619\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746530\n",
      "\tspeed: 0.0345s/iter; left time: 34.8773s\n",
      "\titers: 200, epoch: 16 | loss: 0.0711408\n",
      "\tspeed: 0.0160s/iter; left time: 14.5329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0733967 Vali Loss: 0.0770700 Test Loss: 0.0824194\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733515\n",
      "\tspeed: 0.0344s/iter; left time: 27.1721s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706123\n",
      "\tspeed: 0.0160s/iter; left time: 11.0030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0732017 Vali Loss: 0.0769774 Test Loss: 0.0821647\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706411\n",
      "\tspeed: 0.0345s/iter; left time: 19.5486s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706335\n",
      "\tspeed: 0.0160s/iter; left time: 7.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0728884 Vali Loss: 0.0773300 Test Loss: 0.0823716\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711207\n",
      "\tspeed: 0.0349s/iter; left time: 12.0295s\n",
      "\titers: 200, epoch: 19 | loss: 0.0657455\n",
      "\tspeed: 0.0160s/iter; left time: 3.9181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0727352 Vali Loss: 0.0772174 Test Loss: 0.0821281\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01893829181790352, rmse:0.13761647045612335, mae:0.0821027159690857, rse:0.5203427076339722\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:15.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1507905\n",
      "\tspeed: 0.0382s/iter; left time: 165.8940s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282871\n",
      "\tspeed: 0.0162s/iter; left time: 68.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.1545451 Vali Loss: 0.1136977 Test Loss: 0.1152371\n",
      "Validation loss decreased (inf --> 0.113698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0970599\n",
      "\tspeed: 0.0389s/iter; left time: 160.2516s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932366\n",
      "\tspeed: 0.0159s/iter; left time: 64.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.1000816 Vali Loss: 0.0867449 Test Loss: 0.0896152\n",
      "Validation loss decreased (0.113698 --> 0.086745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0901877\n",
      "\tspeed: 0.0371s/iter; left time: 144.4261s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865992\n",
      "\tspeed: 0.0160s/iter; left time: 60.8075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0889035 Vali Loss: 0.0849238 Test Loss: 0.0875093\n",
      "Validation loss decreased (0.086745 --> 0.084924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845438\n",
      "\tspeed: 0.0367s/iter; left time: 134.9906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829936\n",
      "\tspeed: 0.0162s/iter; left time: 58.0186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0859813 Vali Loss: 0.0839607 Test Loss: 0.0871231\n",
      "Validation loss decreased (0.084924 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0876910\n",
      "\tspeed: 0.0380s/iter; left time: 131.1932s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828706\n",
      "\tspeed: 0.0160s/iter; left time: 53.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0842898 Vali Loss: 0.0835059 Test Loss: 0.0865171\n",
      "Validation loss decreased (0.083961 --> 0.083506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0829766\n",
      "\tspeed: 0.0365s/iter; left time: 117.8530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0801894\n",
      "\tspeed: 0.0162s/iter; left time: 50.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0830918 Vali Loss: 0.0831982 Test Loss: 0.0865383\n",
      "Validation loss decreased (0.083506 --> 0.083198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0817649\n",
      "\tspeed: 0.0367s/iter; left time: 110.5703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810547\n",
      "\tspeed: 0.0162s/iter; left time: 47.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0820679 Vali Loss: 0.0825729 Test Loss: 0.0865927\n",
      "Validation loss decreased (0.083198 --> 0.082573).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778579\n",
      "\tspeed: 0.0364s/iter; left time: 101.5478s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810552\n",
      "\tspeed: 0.0159s/iter; left time: 42.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0811687 Vali Loss: 0.0825304 Test Loss: 0.0868129\n",
      "Validation loss decreased (0.082573 --> 0.082530).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791721\n",
      "\tspeed: 0.0356s/iter; left time: 91.2990s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805860\n",
      "\tspeed: 0.0160s/iter; left time: 39.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0804634 Vali Loss: 0.0822290 Test Loss: 0.0871206\n",
      "Validation loss decreased (0.082530 --> 0.082229).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794385\n",
      "\tspeed: 0.0358s/iter; left time: 83.8616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797314\n",
      "\tspeed: 0.0160s/iter; left time: 35.8592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0798415 Vali Loss: 0.0824751 Test Loss: 0.0871971\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0778659\n",
      "\tspeed: 0.0364s/iter; left time: 77.2216s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769867\n",
      "\tspeed: 0.0160s/iter; left time: 32.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0792664 Vali Loss: 0.0825735 Test Loss: 0.0874378\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774243\n",
      "\tspeed: 0.0362s/iter; left time: 68.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788503\n",
      "\tspeed: 0.0161s/iter; left time: 28.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0787563 Vali Loss: 0.0823296 Test Loss: 0.0874938\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766882\n",
      "\tspeed: 0.0354s/iter; left time: 59.3662s\n",
      "\titers: 200, epoch: 13 | loss: 0.0737316\n",
      "\tspeed: 0.0159s/iter; left time: 25.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0782796 Vali Loss: 0.0822701 Test Loss: 0.0875234\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0788106\n",
      "\tspeed: 0.0364s/iter; left time: 52.9319s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772315\n",
      "\tspeed: 0.0159s/iter; left time: 21.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0779511 Vali Loss: 0.0826971 Test Loss: 0.0877752\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020352747291326523, rmse:0.14266306161880493, mae:0.08712056279182434, rse:0.5399256944656372\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1526684\n",
      "\tspeed: 0.0183s/iter; left time: 79.3003s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311747\n",
      "\tspeed: 0.0161s/iter; left time: 68.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.1564753 Vali Loss: 0.1150082 Test Loss: 0.1166594\n",
      "Validation loss decreased (inf --> 0.115008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0977032\n",
      "\tspeed: 0.0395s/iter; left time: 162.7381s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905012\n",
      "\tspeed: 0.0160s/iter; left time: 64.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.1002000 Vali Loss: 0.0867223 Test Loss: 0.0897312\n",
      "Validation loss decreased (0.115008 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890371\n",
      "\tspeed: 0.0389s/iter; left time: 151.6035s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867550\n",
      "\tspeed: 0.0162s/iter; left time: 61.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0889192 Vali Loss: 0.0850469 Test Loss: 0.0879137\n",
      "Validation loss decreased (0.086722 --> 0.085047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891485\n",
      "\tspeed: 0.0370s/iter; left time: 135.9238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815158\n",
      "\tspeed: 0.0160s/iter; left time: 57.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0859408 Vali Loss: 0.0841075 Test Loss: 0.0872612\n",
      "Validation loss decreased (0.085047 --> 0.084107).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0826774\n",
      "\tspeed: 0.0356s/iter; left time: 122.9527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0841416\n",
      "\tspeed: 0.0160s/iter; left time: 53.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0842623 Vali Loss: 0.0834419 Test Loss: 0.0871409\n",
      "Validation loss decreased (0.084107 --> 0.083442).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808090\n",
      "\tspeed: 0.0362s/iter; left time: 116.9152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0833669\n",
      "\tspeed: 0.0159s/iter; left time: 49.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0829583 Vali Loss: 0.0833017 Test Loss: 0.0873386\n",
      "Validation loss decreased (0.083442 --> 0.083302).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0808285\n",
      "\tspeed: 0.0360s/iter; left time: 108.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819444\n",
      "\tspeed: 0.0159s/iter; left time: 46.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0818957 Vali Loss: 0.0827835 Test Loss: 0.0874482\n",
      "Validation loss decreased (0.083302 --> 0.082784).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798510\n",
      "\tspeed: 0.0363s/iter; left time: 101.1142s\n",
      "\titers: 200, epoch: 8 | loss: 0.0841702\n",
      "\tspeed: 0.0160s/iter; left time: 42.8762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0810556 Vali Loss: 0.0825696 Test Loss: 0.0878618\n",
      "Validation loss decreased (0.082784 --> 0.082570).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0796948\n",
      "\tspeed: 0.0367s/iter; left time: 94.2567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0822921\n",
      "\tspeed: 0.0160s/iter; left time: 39.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0803224 Vali Loss: 0.0825211 Test Loss: 0.0879151\n",
      "Validation loss decreased (0.082570 --> 0.082521).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0815537\n",
      "\tspeed: 0.0368s/iter; left time: 86.3298s\n",
      "\titers: 200, epoch: 10 | loss: 0.0789126\n",
      "\tspeed: 0.0159s/iter; left time: 35.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0796628 Vali Loss: 0.0826349 Test Loss: 0.0882702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774733\n",
      "\tspeed: 0.0353s/iter; left time: 74.8843s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789419\n",
      "\tspeed: 0.0160s/iter; left time: 32.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0791495 Vali Loss: 0.0825843 Test Loss: 0.0884511\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0768253\n",
      "\tspeed: 0.0367s/iter; left time: 69.7540s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767774\n",
      "\tspeed: 0.0166s/iter; left time: 29.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0786895 Vali Loss: 0.0824840 Test Loss: 0.0886010\n",
      "Validation loss decreased (0.082521 --> 0.082484).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0760532\n",
      "\tspeed: 0.0395s/iter; left time: 66.2393s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761733\n",
      "\tspeed: 0.0166s/iter; left time: 26.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0782589 Vali Loss: 0.0823821 Test Loss: 0.0887045\n",
      "Validation loss decreased (0.082484 --> 0.082382).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792271\n",
      "\tspeed: 0.0368s/iter; left time: 53.4763s\n",
      "\titers: 200, epoch: 14 | loss: 0.0803011\n",
      "\tspeed: 0.0163s/iter; left time: 22.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0778286 Vali Loss: 0.0829973 Test Loss: 0.0891749\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0775219\n",
      "\tspeed: 0.0361s/iter; left time: 44.4502s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753181\n",
      "\tspeed: 0.0163s/iter; left time: 18.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0774740 Vali Loss: 0.0826449 Test Loss: 0.0890899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0795973\n",
      "\tspeed: 0.0359s/iter; left time: 36.2615s\n",
      "\titers: 200, epoch: 16 | loss: 0.0796113\n",
      "\tspeed: 0.0161s/iter; left time: 14.6412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0771568 Vali Loss: 0.0827013 Test Loss: 0.0891609\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0772035\n",
      "\tspeed: 0.0371s/iter; left time: 29.2922s\n",
      "\titers: 200, epoch: 17 | loss: 0.0795510\n",
      "\tspeed: 0.0161s/iter; left time: 11.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0768850 Vali Loss: 0.0824970 Test Loss: 0.0890725\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726247\n",
      "\tspeed: 0.0363s/iter; left time: 20.5576s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752741\n",
      "\tspeed: 0.0160s/iter; left time: 7.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0766348 Vali Loss: 0.0827873 Test Loss: 0.0893452\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021211443468928337, rmse:0.14564149081707, mae:0.08870448172092438, rse:0.55119788646698\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:59.61s\n",
      "Intermediate time for IT: 00h:09m:45.16s\n",
      "Total time: 00h:49m:49.23s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0211  0.1453  0.0884\n",
       "        96         0.0364  0.1906  0.1266\n",
       "        168        0.0386  0.1965  0.1334\n",
       "ES      24         0.0099  0.0994  0.0604\n",
       "        96         0.0186  0.1366  0.0882\n",
       "        168        0.0210  0.1452  0.0948\n",
       "FR      24         0.0101  0.1005  0.0558\n",
       "        96         0.0194  0.1394  0.0808\n",
       "        168        0.0208  0.1444  0.0858\n",
       "GB      24         0.0252  0.1587  0.1002\n",
       "        96         0.0416  0.2040  0.1390\n",
       "        168        0.0446  0.2112  0.1464\n",
       "IT      24         0.0102  0.1008  0.0578\n",
       "        96         0.0187  0.1368  0.0819\n",
       "        168        0.0208  0.1442  0.0879"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
