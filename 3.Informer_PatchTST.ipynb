{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 336](#3-patchtst-336)\n",
    "- [4. PatchTST 512](#4-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with seq_len = 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2193371\n",
      "\tspeed: 0.0714s/iter; left time: 1287.1992s\n",
      "\titers: 200, epoch: 1 | loss: 0.1977215\n",
      "\tspeed: 0.0469s/iter; left time: 840.3139s\n",
      "\titers: 300, epoch: 1 | loss: 0.1884996\n",
      "\tspeed: 0.0462s/iter; left time: 823.0834s\n",
      "\titers: 400, epoch: 1 | loss: 0.1732073\n",
      "\tspeed: 0.0462s/iter; left time: 819.1487s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717234\n",
      "\tspeed: 0.0469s/iter; left time: 825.5600s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616005\n",
      "\tspeed: 0.0463s/iter; left time: 810.7936s\n",
      "\titers: 700, epoch: 1 | loss: 0.1801115\n",
      "\tspeed: 0.0449s/iter; left time: 782.4467s\n",
      "\titers: 800, epoch: 1 | loss: 0.1560573\n",
      "\tspeed: 0.0454s/iter; left time: 786.0068s\n",
      "\titers: 900, epoch: 1 | loss: 0.1495997\n",
      "\tspeed: 0.0432s/iter; left time: 743.1248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 906 | Train Loss: 0.1847156 Vali Loss: 0.1656234 Test Loss: 0.1741142\n",
      "Validation loss decreased (inf --> 0.165623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349597\n",
      "\tspeed: 0.1094s/iter; left time: 1872.9680s\n",
      "\titers: 200, epoch: 2 | loss: 0.1336994\n",
      "\tspeed: 0.0434s/iter; left time: 738.8111s\n",
      "\titers: 300, epoch: 2 | loss: 0.1209916\n",
      "\tspeed: 0.0441s/iter; left time: 746.2628s\n",
      "\titers: 400, epoch: 2 | loss: 0.1125416\n",
      "\tspeed: 0.0437s/iter; left time: 734.8755s\n",
      "\titers: 500, epoch: 2 | loss: 0.1105493\n",
      "\tspeed: 0.0468s/iter; left time: 781.9179s\n",
      "\titers: 600, epoch: 2 | loss: 0.0970625\n",
      "\tspeed: 0.0459s/iter; left time: 763.1726s\n",
      "\titers: 700, epoch: 2 | loss: 0.1116746\n",
      "\tspeed: 0.0454s/iter; left time: 749.6724s\n",
      "\titers: 800, epoch: 2 | loss: 0.1117832\n",
      "\tspeed: 0.0460s/iter; left time: 755.6707s\n",
      "\titers: 900, epoch: 2 | loss: 0.1020986\n",
      "\tspeed: 0.0455s/iter; left time: 741.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.04s\n",
      "Steps: 906 | Train Loss: 0.1192016 Vali Loss: 0.1266201 Test Loss: 0.1359189\n",
      "Validation loss decreased (0.165623 --> 0.126620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1158968\n",
      "\tspeed: 0.1116s/iter; left time: 1809.0700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924040\n",
      "\tspeed: 0.0461s/iter; left time: 742.6047s\n",
      "\titers: 300, epoch: 3 | loss: 0.0899346\n",
      "\tspeed: 0.0459s/iter; left time: 735.5361s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857698\n",
      "\tspeed: 0.0459s/iter; left time: 730.5781s\n",
      "\titers: 500, epoch: 3 | loss: 0.0861939\n",
      "\tspeed: 0.0463s/iter; left time: 731.6099s\n",
      "\titers: 600, epoch: 3 | loss: 0.0858602\n",
      "\tspeed: 0.0458s/iter; left time: 719.1868s\n",
      "\titers: 700, epoch: 3 | loss: 0.0784063\n",
      "\tspeed: 0.0465s/iter; left time: 725.0837s\n",
      "\titers: 800, epoch: 3 | loss: 0.0878744\n",
      "\tspeed: 0.0464s/iter; left time: 718.9662s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808627\n",
      "\tspeed: 0.0462s/iter; left time: 711.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0885531 Vali Loss: 0.1016488 Test Loss: 0.1044472\n",
      "Validation loss decreased (0.126620 --> 0.101649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0792848\n",
      "\tspeed: 0.1104s/iter; left time: 1688.8833s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834116\n",
      "\tspeed: 0.0460s/iter; left time: 699.3593s\n",
      "\titers: 300, epoch: 4 | loss: 0.0808930\n",
      "\tspeed: 0.0458s/iter; left time: 692.4186s\n",
      "\titers: 400, epoch: 4 | loss: 0.0806404\n",
      "\tspeed: 0.0459s/iter; left time: 688.1414s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863321\n",
      "\tspeed: 0.0459s/iter; left time: 683.8630s\n",
      "\titers: 600, epoch: 4 | loss: 0.0819875\n",
      "\tspeed: 0.0453s/iter; left time: 670.6085s\n",
      "\titers: 700, epoch: 4 | loss: 0.0820523\n",
      "\tspeed: 0.0461s/iter; left time: 677.6576s\n",
      "\titers: 800, epoch: 4 | loss: 0.0829418\n",
      "\tspeed: 0.0459s/iter; left time: 670.5115s\n",
      "\titers: 900, epoch: 4 | loss: 0.0640380\n",
      "\tspeed: 0.0460s/iter; left time: 667.5169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.69s\n",
      "Steps: 906 | Train Loss: 0.0792295 Vali Loss: 0.0987642 Test Loss: 0.0995154\n",
      "Validation loss decreased (0.101649 --> 0.098764).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736899\n",
      "\tspeed: 0.1167s/iter; left time: 1679.6907s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741243\n",
      "\tspeed: 0.0506s/iter; left time: 723.5414s\n",
      "\titers: 300, epoch: 5 | loss: 0.0739710\n",
      "\tspeed: 0.0497s/iter; left time: 706.2031s\n",
      "\titers: 400, epoch: 5 | loss: 0.0845009\n",
      "\tspeed: 0.0505s/iter; left time: 712.0110s\n",
      "\titers: 500, epoch: 5 | loss: 0.0734567\n",
      "\tspeed: 0.0497s/iter; left time: 695.1420s\n",
      "\titers: 600, epoch: 5 | loss: 0.0848674\n",
      "\tspeed: 0.0496s/iter; left time: 689.8321s\n",
      "\titers: 700, epoch: 5 | loss: 0.0792132\n",
      "\tspeed: 0.0471s/iter; left time: 649.5918s\n",
      "\titers: 800, epoch: 5 | loss: 0.0796287\n",
      "\tspeed: 0.0507s/iter; left time: 694.5913s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893356\n",
      "\tspeed: 0.0485s/iter; left time: 659.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.25s\n",
      "Steps: 906 | Train Loss: 0.0754891 Vali Loss: 0.0970423 Test Loss: 0.1023288\n",
      "Validation loss decreased (0.098764 --> 0.097042).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770415\n",
      "\tspeed: 0.1176s/iter; left time: 1586.2269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0650214\n",
      "\tspeed: 0.0505s/iter; left time: 676.7536s\n",
      "\titers: 300, epoch: 6 | loss: 0.0709342\n",
      "\tspeed: 0.0504s/iter; left time: 669.6138s\n",
      "\titers: 400, epoch: 6 | loss: 0.0764454\n",
      "\tspeed: 0.0472s/iter; left time: 622.6767s\n",
      "\titers: 500, epoch: 6 | loss: 0.0718121\n",
      "\tspeed: 0.0477s/iter; left time: 624.7120s\n",
      "\titers: 600, epoch: 6 | loss: 0.0657555\n",
      "\tspeed: 0.0479s/iter; left time: 622.6301s\n",
      "\titers: 700, epoch: 6 | loss: 0.0661870\n",
      "\tspeed: 0.0477s/iter; left time: 615.4995s\n",
      "\titers: 800, epoch: 6 | loss: 0.0700175\n",
      "\tspeed: 0.0478s/iter; left time: 611.4614s\n",
      "\titers: 900, epoch: 6 | loss: 0.0714951\n",
      "\tspeed: 0.0478s/iter; left time: 606.2062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.31s\n",
      "Steps: 906 | Train Loss: 0.0722549 Vali Loss: 0.0961112 Test Loss: 0.1040979\n",
      "Validation loss decreased (0.097042 --> 0.096111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0660138\n",
      "\tspeed: 0.1136s/iter; left time: 1429.8950s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665872\n",
      "\tspeed: 0.0474s/iter; left time: 591.6264s\n",
      "\titers: 300, epoch: 7 | loss: 0.0691996\n",
      "\tspeed: 0.0462s/iter; left time: 572.1310s\n",
      "\titers: 400, epoch: 7 | loss: 0.0673207\n",
      "\tspeed: 0.0458s/iter; left time: 562.7136s\n",
      "\titers: 500, epoch: 7 | loss: 0.0736774\n",
      "\tspeed: 0.0457s/iter; left time: 557.0006s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582451\n",
      "\tspeed: 0.0463s/iter; left time: 559.5402s\n",
      "\titers: 700, epoch: 7 | loss: 0.0747162\n",
      "\tspeed: 0.0477s/iter; left time: 571.1265s\n",
      "\titers: 800, epoch: 7 | loss: 0.0575175\n",
      "\tspeed: 0.0456s/iter; left time: 541.5130s\n",
      "\titers: 900, epoch: 7 | loss: 0.0671092\n",
      "\tspeed: 0.0487s/iter; left time: 574.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.57s\n",
      "Steps: 906 | Train Loss: 0.0692671 Vali Loss: 0.0940558 Test Loss: 0.1026407\n",
      "Validation loss decreased (0.096111 --> 0.094056).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0589510\n",
      "\tspeed: 0.1225s/iter; left time: 1430.7593s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728251\n",
      "\tspeed: 0.0504s/iter; left time: 583.9179s\n",
      "\titers: 300, epoch: 8 | loss: 0.0642487\n",
      "\tspeed: 0.0476s/iter; left time: 546.2037s\n",
      "\titers: 400, epoch: 8 | loss: 0.0674729\n",
      "\tspeed: 0.0475s/iter; left time: 540.7638s\n",
      "\titers: 500, epoch: 8 | loss: 0.0671887\n",
      "\tspeed: 0.0475s/iter; left time: 536.1497s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739231\n",
      "\tspeed: 0.0496s/iter; left time: 554.6824s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576856\n",
      "\tspeed: 0.0478s/iter; left time: 529.9790s\n",
      "\titers: 800, epoch: 8 | loss: 0.0614317\n",
      "\tspeed: 0.0480s/iter; left time: 527.0374s\n",
      "\titers: 900, epoch: 8 | loss: 0.0775866\n",
      "\tspeed: 0.0484s/iter; left time: 526.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.35s\n",
      "Steps: 906 | Train Loss: 0.0661331 Vali Loss: 0.0988925 Test Loss: 0.1027935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666226\n",
      "\tspeed: 0.1118s/iter; left time: 1204.6813s\n",
      "\titers: 200, epoch: 9 | loss: 0.0640848\n",
      "\tspeed: 0.0476s/iter; left time: 508.3489s\n",
      "\titers: 300, epoch: 9 | loss: 0.0630905\n",
      "\tspeed: 0.0479s/iter; left time: 505.9449s\n",
      "\titers: 400, epoch: 9 | loss: 0.0661945\n",
      "\tspeed: 0.0476s/iter; left time: 498.7793s\n",
      "\titers: 500, epoch: 9 | loss: 0.0665071\n",
      "\tspeed: 0.0478s/iter; left time: 495.6331s\n",
      "\titers: 600, epoch: 9 | loss: 0.0685818\n",
      "\tspeed: 0.0479s/iter; left time: 492.4401s\n",
      "\titers: 700, epoch: 9 | loss: 0.0656188\n",
      "\tspeed: 0.0474s/iter; left time: 482.3368s\n",
      "\titers: 800, epoch: 9 | loss: 0.0669846\n",
      "\tspeed: 0.0479s/iter; left time: 482.9493s\n",
      "\titers: 900, epoch: 9 | loss: 0.0599250\n",
      "\tspeed: 0.0476s/iter; left time: 474.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 906 | Train Loss: 0.0637068 Vali Loss: 0.0966993 Test Loss: 0.1047861\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632723\n",
      "\tspeed: 0.1101s/iter; left time: 1086.0442s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692926\n",
      "\tspeed: 0.0477s/iter; left time: 466.1071s\n",
      "\titers: 300, epoch: 10 | loss: 0.0645902\n",
      "\tspeed: 0.0480s/iter; left time: 463.7953s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728916\n",
      "\tspeed: 0.0477s/iter; left time: 456.3795s\n",
      "\titers: 500, epoch: 10 | loss: 0.0589608\n",
      "\tspeed: 0.0492s/iter; left time: 465.6830s\n",
      "\titers: 600, epoch: 10 | loss: 0.0589466\n",
      "\tspeed: 0.0470s/iter; left time: 439.7960s\n",
      "\titers: 700, epoch: 10 | loss: 0.0540567\n",
      "\tspeed: 0.0495s/iter; left time: 458.7852s\n",
      "\titers: 800, epoch: 10 | loss: 0.0578213\n",
      "\tspeed: 0.0505s/iter; left time: 462.4800s\n",
      "\titers: 900, epoch: 10 | loss: 0.0561226\n",
      "\tspeed: 0.0483s/iter; left time: 438.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.07s\n",
      "Steps: 906 | Train Loss: 0.0611027 Vali Loss: 0.0954745 Test Loss: 0.1028340\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0608129\n",
      "\tspeed: 0.1144s/iter; left time: 1025.2268s\n",
      "\titers: 200, epoch: 11 | loss: 0.0599368\n",
      "\tspeed: 0.0506s/iter; left time: 448.1623s\n",
      "\titers: 300, epoch: 11 | loss: 0.0558104\n",
      "\tspeed: 0.0503s/iter; left time: 440.2885s\n",
      "\titers: 400, epoch: 11 | loss: 0.0515542\n",
      "\tspeed: 0.0505s/iter; left time: 437.7860s\n",
      "\titers: 500, epoch: 11 | loss: 0.0650875\n",
      "\tspeed: 0.0497s/iter; left time: 425.4352s\n",
      "\titers: 600, epoch: 11 | loss: 0.0647349\n",
      "\tspeed: 0.0491s/iter; left time: 415.7389s\n",
      "\titers: 700, epoch: 11 | loss: 0.0569948\n",
      "\tspeed: 0.0478s/iter; left time: 399.6781s\n",
      "\titers: 800, epoch: 11 | loss: 0.0515813\n",
      "\tspeed: 0.0504s/iter; left time: 416.4456s\n",
      "\titers: 900, epoch: 11 | loss: 0.0487354\n",
      "\tspeed: 0.0495s/iter; left time: 403.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.37s\n",
      "Steps: 906 | Train Loss: 0.0585829 Vali Loss: 0.0957306 Test Loss: 0.1064269\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0584590\n",
      "\tspeed: 0.1124s/iter; left time: 905.5042s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584398\n",
      "\tspeed: 0.0492s/iter; left time: 391.1544s\n",
      "\titers: 300, epoch: 12 | loss: 0.0573530\n",
      "\tspeed: 0.0505s/iter; left time: 396.7801s\n",
      "\titers: 400, epoch: 12 | loss: 0.0605661\n",
      "\tspeed: 0.0467s/iter; left time: 361.8423s\n",
      "\titers: 500, epoch: 12 | loss: 0.0548147\n",
      "\tspeed: 0.0460s/iter; left time: 351.8984s\n",
      "\titers: 600, epoch: 12 | loss: 0.0529713\n",
      "\tspeed: 0.0461s/iter; left time: 348.0106s\n",
      "\titers: 700, epoch: 12 | loss: 0.0574244\n",
      "\tspeed: 0.0458s/iter; left time: 341.5892s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501836\n",
      "\tspeed: 0.0458s/iter; left time: 336.7705s\n",
      "\titers: 900, epoch: 12 | loss: 0.0584249\n",
      "\tspeed: 0.0482s/iter; left time: 349.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 906 | Train Loss: 0.0567967 Vali Loss: 0.0991605 Test Loss: 0.1062757\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02503511682152748, rmse:0.1582248955965042, mae:0.10250058770179749, rse:0.5587754845619202\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2209228\n",
      "\tspeed: 0.0527s/iter; left time: 950.4787s\n",
      "\titers: 200, epoch: 1 | loss: 0.1902164\n",
      "\tspeed: 0.0506s/iter; left time: 907.1320s\n",
      "\titers: 300, epoch: 1 | loss: 0.1861653\n",
      "\tspeed: 0.0493s/iter; left time: 878.7219s\n",
      "\titers: 400, epoch: 1 | loss: 0.1823416\n",
      "\tspeed: 0.0477s/iter; left time: 844.5619s\n",
      "\titers: 500, epoch: 1 | loss: 0.1792150\n",
      "\tspeed: 0.0511s/iter; left time: 900.1851s\n",
      "\titers: 600, epoch: 1 | loss: 0.1767687\n",
      "\tspeed: 0.0497s/iter; left time: 870.1305s\n",
      "\titers: 700, epoch: 1 | loss: 0.1690864\n",
      "\tspeed: 0.0480s/iter; left time: 836.8974s\n",
      "\titers: 800, epoch: 1 | loss: 0.1706984\n",
      "\tspeed: 0.0501s/iter; left time: 868.4686s\n",
      "\titers: 900, epoch: 1 | loss: 0.1513919\n",
      "\tspeed: 0.0495s/iter; left time: 852.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.24s\n",
      "Steps: 906 | Train Loss: 0.1882799 Vali Loss: 0.1665931 Test Loss: 0.1768704\n",
      "Validation loss decreased (inf --> 0.166593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1368255\n",
      "\tspeed: 0.1188s/iter; left time: 2033.1831s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390444\n",
      "\tspeed: 0.0504s/iter; left time: 857.5371s\n",
      "\titers: 300, epoch: 2 | loss: 0.1252545\n",
      "\tspeed: 0.0479s/iter; left time: 810.0550s\n",
      "\titers: 400, epoch: 2 | loss: 0.1175311\n",
      "\tspeed: 0.0480s/iter; left time: 806.2912s\n",
      "\titers: 500, epoch: 2 | loss: 0.1201848\n",
      "\tspeed: 0.0492s/iter; left time: 822.8948s\n",
      "\titers: 600, epoch: 2 | loss: 0.1047623\n",
      "\tspeed: 0.0467s/iter; left time: 775.8895s\n",
      "\titers: 700, epoch: 2 | loss: 0.1203549\n",
      "\tspeed: 0.0481s/iter; left time: 793.9460s\n",
      "\titers: 800, epoch: 2 | loss: 0.0944271\n",
      "\tspeed: 0.0484s/iter; left time: 793.6972s\n",
      "\titers: 900, epoch: 2 | loss: 0.1203178\n",
      "\tspeed: 0.0491s/iter; left time: 800.9743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.33s\n",
      "Steps: 906 | Train Loss: 0.1226015 Vali Loss: 0.1264837 Test Loss: 0.1367266\n",
      "Validation loss decreased (0.166593 --> 0.126484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049845\n",
      "\tspeed: 0.1174s/iter; left time: 1903.4723s\n",
      "\titers: 200, epoch: 3 | loss: 0.1047302\n",
      "\tspeed: 0.0487s/iter; left time: 784.1103s\n",
      "\titers: 300, epoch: 3 | loss: 0.0955707\n",
      "\tspeed: 0.0507s/iter; left time: 812.3723s\n",
      "\titers: 400, epoch: 3 | loss: 0.1100043\n",
      "\tspeed: 0.0479s/iter; left time: 761.5696s\n",
      "\titers: 500, epoch: 3 | loss: 0.1044606\n",
      "\tspeed: 0.0484s/iter; left time: 765.5962s\n",
      "\titers: 600, epoch: 3 | loss: 0.0991454\n",
      "\tspeed: 0.0479s/iter; left time: 751.7801s\n",
      "\titers: 700, epoch: 3 | loss: 0.1010945\n",
      "\tspeed: 0.0476s/iter; left time: 743.2149s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062495\n",
      "\tspeed: 0.0481s/iter; left time: 746.3202s\n",
      "\titers: 900, epoch: 3 | loss: 0.1075993\n",
      "\tspeed: 0.0479s/iter; left time: 737.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.12s\n",
      "Steps: 906 | Train Loss: 0.1036576 Vali Loss: 0.1235929 Test Loss: 0.1351364\n",
      "Validation loss decreased (0.126484 --> 0.123593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985526\n",
      "\tspeed: 0.1157s/iter; left time: 1770.2254s\n",
      "\titers: 200, epoch: 4 | loss: 0.1032197\n",
      "\tspeed: 0.0479s/iter; left time: 727.8057s\n",
      "\titers: 300, epoch: 4 | loss: 0.0960748\n",
      "\tspeed: 0.0477s/iter; left time: 720.0805s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083821\n",
      "\tspeed: 0.0481s/iter; left time: 721.6511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976141\n",
      "\tspeed: 0.0474s/iter; left time: 706.9866s\n",
      "\titers: 600, epoch: 4 | loss: 0.0889361\n",
      "\tspeed: 0.0475s/iter; left time: 703.5839s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876954\n",
      "\tspeed: 0.0470s/iter; left time: 691.4759s\n",
      "\titers: 800, epoch: 4 | loss: 0.0864828\n",
      "\tspeed: 0.0486s/iter; left time: 708.9860s\n",
      "\titers: 900, epoch: 4 | loss: 0.0808749\n",
      "\tspeed: 0.0479s/iter; left time: 695.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.63s\n",
      "Steps: 906 | Train Loss: 0.0955038 Vali Loss: 0.0984326 Test Loss: 0.1020987\n",
      "Validation loss decreased (0.123593 --> 0.098433).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693327\n",
      "\tspeed: 0.1154s/iter; left time: 1661.8658s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791737\n",
      "\tspeed: 0.0475s/iter; left time: 678.6257s\n",
      "\titers: 300, epoch: 5 | loss: 0.0842561\n",
      "\tspeed: 0.0458s/iter; left time: 650.7087s\n",
      "\titers: 400, epoch: 5 | loss: 0.0753921\n",
      "\tspeed: 0.0471s/iter; left time: 663.8060s\n",
      "\titers: 500, epoch: 5 | loss: 0.0805455\n",
      "\tspeed: 0.0471s/iter; left time: 659.2575s\n",
      "\titers: 600, epoch: 5 | loss: 0.0652466\n",
      "\tspeed: 0.0493s/iter; left time: 684.6148s\n",
      "\titers: 700, epoch: 5 | loss: 0.0767411\n",
      "\tspeed: 0.0477s/iter; left time: 657.5715s\n",
      "\titers: 800, epoch: 5 | loss: 0.0734380\n",
      "\tspeed: 0.0491s/iter; left time: 673.1081s\n",
      "\titers: 900, epoch: 5 | loss: 0.0672268\n",
      "\tspeed: 0.0484s/iter; left time: 658.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.57s\n",
      "Steps: 906 | Train Loss: 0.0775636 Vali Loss: 0.0965865 Test Loss: 0.1022946\n",
      "Validation loss decreased (0.098433 --> 0.096587).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776920\n",
      "\tspeed: 0.1146s/iter; left time: 1546.6984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689330\n",
      "\tspeed: 0.0481s/iter; left time: 644.1956s\n",
      "\titers: 300, epoch: 6 | loss: 0.0715801\n",
      "\tspeed: 0.0482s/iter; left time: 640.5671s\n",
      "\titers: 400, epoch: 6 | loss: 0.0735732\n",
      "\tspeed: 0.0452s/iter; left time: 596.8024s\n",
      "\titers: 500, epoch: 6 | loss: 0.0734075\n",
      "\tspeed: 0.0465s/iter; left time: 608.4918s\n",
      "\titers: 600, epoch: 6 | loss: 0.0756910\n",
      "\tspeed: 0.0466s/iter; left time: 605.6275s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700148\n",
      "\tspeed: 0.0481s/iter; left time: 619.8771s\n",
      "\titers: 800, epoch: 6 | loss: 0.0713590\n",
      "\tspeed: 0.0481s/iter; left time: 615.4595s\n",
      "\titers: 900, epoch: 6 | loss: 0.0711626\n",
      "\tspeed: 0.0455s/iter; left time: 578.0040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.02s\n",
      "Steps: 906 | Train Loss: 0.0737180 Vali Loss: 0.0977053 Test Loss: 0.1045457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0707487\n",
      "\tspeed: 0.1092s/iter; left time: 1373.7280s\n",
      "\titers: 200, epoch: 7 | loss: 0.0672919\n",
      "\tspeed: 0.0457s/iter; left time: 570.9540s\n",
      "\titers: 300, epoch: 7 | loss: 0.0736401\n",
      "\tspeed: 0.0461s/iter; left time: 570.3844s\n",
      "\titers: 400, epoch: 7 | loss: 0.0677582\n",
      "\tspeed: 0.0457s/iter; left time: 561.3001s\n",
      "\titers: 500, epoch: 7 | loss: 0.0748733\n",
      "\tspeed: 0.0462s/iter; left time: 562.8405s\n",
      "\titers: 600, epoch: 7 | loss: 0.0729828\n",
      "\tspeed: 0.0462s/iter; left time: 558.1090s\n",
      "\titers: 700, epoch: 7 | loss: 0.0575399\n",
      "\tspeed: 0.0464s/iter; left time: 555.8893s\n",
      "\titers: 800, epoch: 7 | loss: 0.0780056\n",
      "\tspeed: 0.0462s/iter; left time: 549.4186s\n",
      "\titers: 900, epoch: 7 | loss: 0.0625338\n",
      "\tspeed: 0.0455s/iter; left time: 535.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 906 | Train Loss: 0.0701726 Vali Loss: 0.0972105 Test Loss: 0.1042383\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0615204\n",
      "\tspeed: 0.1092s/iter; left time: 1275.3097s\n",
      "\titers: 200, epoch: 8 | loss: 0.0659045\n",
      "\tspeed: 0.0457s/iter; left time: 529.3296s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652609\n",
      "\tspeed: 0.0460s/iter; left time: 528.0945s\n",
      "\titers: 400, epoch: 8 | loss: 0.0691719\n",
      "\tspeed: 0.0461s/iter; left time: 524.5279s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823549\n",
      "\tspeed: 0.0462s/iter; left time: 521.5199s\n",
      "\titers: 600, epoch: 8 | loss: 0.0681711\n",
      "\tspeed: 0.0460s/iter; left time: 513.8483s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681319\n",
      "\tspeed: 0.0457s/iter; left time: 506.4419s\n",
      "\titers: 800, epoch: 8 | loss: 0.0736955\n",
      "\tspeed: 0.0457s/iter; left time: 502.2795s\n",
      "\titers: 900, epoch: 8 | loss: 0.0596028\n",
      "\tspeed: 0.0460s/iter; left time: 500.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 906 | Train Loss: 0.0674239 Vali Loss: 0.0962781 Test Loss: 0.1040185\n",
      "Validation loss decreased (0.096587 --> 0.096278).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0616742\n",
      "\tspeed: 0.1126s/iter; left time: 1212.8309s\n",
      "\titers: 200, epoch: 9 | loss: 0.0522444\n",
      "\tspeed: 0.0451s/iter; left time: 480.9247s\n",
      "\titers: 300, epoch: 9 | loss: 0.0629223\n",
      "\tspeed: 0.0457s/iter; left time: 483.3403s\n",
      "\titers: 400, epoch: 9 | loss: 0.0630886\n",
      "\tspeed: 0.0460s/iter; left time: 482.1895s\n",
      "\titers: 500, epoch: 9 | loss: 0.0573699\n",
      "\tspeed: 0.0460s/iter; left time: 477.1239s\n",
      "\titers: 600, epoch: 9 | loss: 0.0559906\n",
      "\tspeed: 0.0457s/iter; left time: 469.7802s\n",
      "\titers: 700, epoch: 9 | loss: 0.0674314\n",
      "\tspeed: 0.0456s/iter; left time: 464.3792s\n",
      "\titers: 800, epoch: 9 | loss: 0.0620898\n",
      "\tspeed: 0.0464s/iter; left time: 467.1048s\n",
      "\titers: 900, epoch: 9 | loss: 0.0567981\n",
      "\tspeed: 0.0459s/iter; left time: 457.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0646134 Vali Loss: 0.0964188 Test Loss: 0.1026151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548026\n",
      "\tspeed: 0.1089s/iter; left time: 1074.7403s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589220\n",
      "\tspeed: 0.0463s/iter; left time: 452.1062s\n",
      "\titers: 300, epoch: 10 | loss: 0.0606921\n",
      "\tspeed: 0.0463s/iter; left time: 448.0388s\n",
      "\titers: 400, epoch: 10 | loss: 0.0613493\n",
      "\tspeed: 0.0460s/iter; left time: 440.3171s\n",
      "\titers: 500, epoch: 10 | loss: 0.0667166\n",
      "\tspeed: 0.0466s/iter; left time: 440.7466s\n",
      "\titers: 600, epoch: 10 | loss: 0.0655026\n",
      "\tspeed: 0.0460s/iter; left time: 430.7230s\n",
      "\titers: 700, epoch: 10 | loss: 0.0616325\n",
      "\tspeed: 0.0453s/iter; left time: 419.6195s\n",
      "\titers: 800, epoch: 10 | loss: 0.0592780\n",
      "\tspeed: 0.0459s/iter; left time: 420.6660s\n",
      "\titers: 900, epoch: 10 | loss: 0.0651274\n",
      "\tspeed: 0.0449s/iter; left time: 407.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.0621331 Vali Loss: 0.0966932 Test Loss: 0.1082848\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0611093\n",
      "\tspeed: 0.1081s/iter; left time: 968.6472s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578680\n",
      "\tspeed: 0.0470s/iter; left time: 416.3009s\n",
      "\titers: 300, epoch: 11 | loss: 0.0573885\n",
      "\tspeed: 0.0472s/iter; left time: 413.0860s\n",
      "\titers: 400, epoch: 11 | loss: 0.0532788\n",
      "\tspeed: 0.0474s/iter; left time: 410.2725s\n",
      "\titers: 500, epoch: 11 | loss: 0.0575405\n",
      "\tspeed: 0.0493s/iter; left time: 422.3598s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601803\n",
      "\tspeed: 0.0492s/iter; left time: 416.4425s\n",
      "\titers: 700, epoch: 11 | loss: 0.0570868\n",
      "\tspeed: 0.0490s/iter; left time: 409.3627s\n",
      "\titers: 800, epoch: 11 | loss: 0.0665489\n",
      "\tspeed: 0.0494s/iter; left time: 407.8504s\n",
      "\titers: 900, epoch: 11 | loss: 0.0546679\n",
      "\tspeed: 0.0492s/iter; left time: 401.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.86s\n",
      "Steps: 906 | Train Loss: 0.0597120 Vali Loss: 0.0936789 Test Loss: 0.1029847\n",
      "Validation loss decreased (0.096278 --> 0.093679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0630511\n",
      "\tspeed: 0.1138s/iter; left time: 916.7436s\n",
      "\titers: 200, epoch: 12 | loss: 0.0615881\n",
      "\tspeed: 0.0464s/iter; left time: 369.1782s\n",
      "\titers: 300, epoch: 12 | loss: 0.0559201\n",
      "\tspeed: 0.0464s/iter; left time: 364.2414s\n",
      "\titers: 400, epoch: 12 | loss: 0.0519277\n",
      "\tspeed: 0.0466s/iter; left time: 361.7202s\n",
      "\titers: 500, epoch: 12 | loss: 0.0599991\n",
      "\tspeed: 0.0465s/iter; left time: 355.9195s\n",
      "\titers: 600, epoch: 12 | loss: 0.0630212\n",
      "\tspeed: 0.0461s/iter; left time: 348.1366s\n",
      "\titers: 700, epoch: 12 | loss: 0.0543649\n",
      "\tspeed: 0.0466s/iter; left time: 347.3715s\n",
      "\titers: 800, epoch: 12 | loss: 0.0606494\n",
      "\tspeed: 0.0463s/iter; left time: 340.7000s\n",
      "\titers: 900, epoch: 12 | loss: 0.0567524\n",
      "\tspeed: 0.0463s/iter; left time: 336.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 906 | Train Loss: 0.0571922 Vali Loss: 0.0974627 Test Loss: 0.1070443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0593928\n",
      "\tspeed: 0.1106s/iter; left time: 790.7263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506865\n",
      "\tspeed: 0.0457s/iter; left time: 322.1822s\n",
      "\titers: 300, epoch: 13 | loss: 0.0564607\n",
      "\tspeed: 0.0459s/iter; left time: 318.9464s\n",
      "\titers: 400, epoch: 13 | loss: 0.0527917\n",
      "\tspeed: 0.0460s/iter; left time: 315.2981s\n",
      "\titers: 500, epoch: 13 | loss: 0.0548141\n",
      "\tspeed: 0.0457s/iter; left time: 308.2119s\n",
      "\titers: 600, epoch: 13 | loss: 0.0536862\n",
      "\tspeed: 0.0461s/iter; left time: 306.3054s\n",
      "\titers: 700, epoch: 13 | loss: 0.0593105\n",
      "\tspeed: 0.0459s/iter; left time: 300.4360s\n",
      "\titers: 800, epoch: 13 | loss: 0.0583405\n",
      "\tspeed: 0.0463s/iter; left time: 298.4591s\n",
      "\titers: 900, epoch: 13 | loss: 0.0595543\n",
      "\tspeed: 0.0461s/iter; left time: 292.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.90s\n",
      "Steps: 906 | Train Loss: 0.0552700 Vali Loss: 0.0980769 Test Loss: 0.1070963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560386\n",
      "\tspeed: 0.1087s/iter; left time: 678.7218s\n",
      "\titers: 200, epoch: 14 | loss: 0.0519739\n",
      "\tspeed: 0.0459s/iter; left time: 281.9883s\n",
      "\titers: 300, epoch: 14 | loss: 0.0482483\n",
      "\tspeed: 0.0463s/iter; left time: 279.8914s\n",
      "\titers: 400, epoch: 14 | loss: 0.0503040\n",
      "\tspeed: 0.0459s/iter; left time: 273.0089s\n",
      "\titers: 500, epoch: 14 | loss: 0.0518296\n",
      "\tspeed: 0.0460s/iter; left time: 269.0467s\n",
      "\titers: 600, epoch: 14 | loss: 0.0475292\n",
      "\tspeed: 0.0460s/iter; left time: 263.9798s\n",
      "\titers: 700, epoch: 14 | loss: 0.0490515\n",
      "\tspeed: 0.0437s/iter; left time: 246.4102s\n",
      "\titers: 800, epoch: 14 | loss: 0.0554480\n",
      "\tspeed: 0.0461s/iter; left time: 255.3968s\n",
      "\titers: 900, epoch: 14 | loss: 0.0600134\n",
      "\tspeed: 0.0461s/iter; left time: 251.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 906 | Train Loss: 0.0535541 Vali Loss: 0.0998057 Test Loss: 0.1077985\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0498628\n",
      "\tspeed: 0.1094s/iter; left time: 584.0404s\n",
      "\titers: 200, epoch: 15 | loss: 0.0509019\n",
      "\tspeed: 0.0469s/iter; left time: 245.8367s\n",
      "\titers: 300, epoch: 15 | loss: 0.0491260\n",
      "\tspeed: 0.0496s/iter; left time: 254.6633s\n",
      "\titers: 400, epoch: 15 | loss: 0.0523825\n",
      "\tspeed: 0.0494s/iter; left time: 248.8739s\n",
      "\titers: 500, epoch: 15 | loss: 0.0568884\n",
      "\tspeed: 0.0497s/iter; left time: 245.5476s\n",
      "\titers: 600, epoch: 15 | loss: 0.0534033\n",
      "\tspeed: 0.0494s/iter; left time: 239.1020s\n",
      "\titers: 700, epoch: 15 | loss: 0.0473140\n",
      "\tspeed: 0.0497s/iter; left time: 235.5965s\n",
      "\titers: 800, epoch: 15 | loss: 0.0530336\n",
      "\tspeed: 0.0493s/iter; left time: 228.5697s\n",
      "\titers: 900, epoch: 15 | loss: 0.0458356\n",
      "\tspeed: 0.0433s/iter; left time: 196.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 906 | Train Loss: 0.0519952 Vali Loss: 0.0975314 Test Loss: 0.1075522\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0488202\n",
      "\tspeed: 0.1086s/iter; left time: 481.3592s\n",
      "\titers: 200, epoch: 16 | loss: 0.0530199\n",
      "\tspeed: 0.0440s/iter; left time: 190.5993s\n",
      "\titers: 300, epoch: 16 | loss: 0.0499976\n",
      "\tspeed: 0.0437s/iter; left time: 184.9680s\n",
      "\titers: 400, epoch: 16 | loss: 0.0442361\n",
      "\tspeed: 0.0450s/iter; left time: 185.7208s\n",
      "\titers: 500, epoch: 16 | loss: 0.0529236\n",
      "\tspeed: 0.0442s/iter; left time: 177.9981s\n",
      "\titers: 600, epoch: 16 | loss: 0.0488371\n",
      "\tspeed: 0.0441s/iter; left time: 173.2902s\n",
      "\titers: 700, epoch: 16 | loss: 0.0491037\n",
      "\tspeed: 0.0448s/iter; left time: 171.7604s\n",
      "\titers: 800, epoch: 16 | loss: 0.0455605\n",
      "\tspeed: 0.0460s/iter; left time: 171.6779s\n",
      "\titers: 900, epoch: 16 | loss: 0.0486577\n",
      "\tspeed: 0.0458s/iter; left time: 166.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.66s\n",
      "Steps: 906 | Train Loss: 0.0508140 Vali Loss: 0.0993314 Test Loss: 0.1080995\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026359017938375473, rmse:0.16235460340976715, mae:0.10303153097629547, rse:0.5733596682548523\n",
      "Intermediate time for DE and pred_len 24: 00h:23m:11.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2211680\n",
      "\tspeed: 0.0648s/iter; left time: 1165.6347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2124181\n",
      "\tspeed: 0.0504s/iter; left time: 901.9235s\n",
      "\titers: 300, epoch: 1 | loss: 0.2027560\n",
      "\tspeed: 0.0507s/iter; left time: 902.0542s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934510\n",
      "\tspeed: 0.0505s/iter; left time: 893.4285s\n",
      "\titers: 500, epoch: 1 | loss: 0.1852765\n",
      "\tspeed: 0.0504s/iter; left time: 886.4453s\n",
      "\titers: 600, epoch: 1 | loss: 0.1785509\n",
      "\tspeed: 0.0506s/iter; left time: 883.8930s\n",
      "\titers: 700, epoch: 1 | loss: 0.1699531\n",
      "\tspeed: 0.0505s/iter; left time: 877.7730s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744952\n",
      "\tspeed: 0.0505s/iter; left time: 873.0484s\n",
      "\titers: 900, epoch: 1 | loss: 0.1717111\n",
      "\tspeed: 0.0507s/iter; left time: 871.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.45s\n",
      "Steps: 904 | Train Loss: 0.1950607 Vali Loss: 0.1829108 Test Loss: 0.2037840\n",
      "Validation loss decreased (inf --> 0.182911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1621778\n",
      "\tspeed: 0.1254s/iter; left time: 2141.9602s\n",
      "\titers: 200, epoch: 2 | loss: 0.1427496\n",
      "\tspeed: 0.0506s/iter; left time: 859.0954s\n",
      "\titers: 300, epoch: 2 | loss: 0.1401429\n",
      "\tspeed: 0.0505s/iter; left time: 851.4984s\n",
      "\titers: 400, epoch: 2 | loss: 0.1463907\n",
      "\tspeed: 0.0506s/iter; left time: 849.3159s\n",
      "\titers: 500, epoch: 2 | loss: 0.1395933\n",
      "\tspeed: 0.0503s/iter; left time: 838.9343s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227748\n",
      "\tspeed: 0.0505s/iter; left time: 837.4684s\n",
      "\titers: 700, epoch: 2 | loss: 0.1235877\n",
      "\tspeed: 0.0505s/iter; left time: 831.3733s\n",
      "\titers: 800, epoch: 2 | loss: 0.1240215\n",
      "\tspeed: 0.0506s/iter; left time: 828.0348s\n",
      "\titers: 900, epoch: 2 | loss: 0.1336349\n",
      "\tspeed: 0.0508s/iter; left time: 827.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.1377187 Vali Loss: 0.1409242 Test Loss: 0.1577245\n",
      "Validation loss decreased (0.182911 --> 0.140924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216025\n",
      "\tspeed: 0.1306s/iter; left time: 2112.0608s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104100\n",
      "\tspeed: 0.0508s/iter; left time: 815.7676s\n",
      "\titers: 300, epoch: 3 | loss: 0.1143406\n",
      "\tspeed: 0.0509s/iter; left time: 812.6594s\n",
      "\titers: 400, epoch: 3 | loss: 0.1088113\n",
      "\tspeed: 0.0507s/iter; left time: 804.6677s\n",
      "\titers: 500, epoch: 3 | loss: 0.1070392\n",
      "\tspeed: 0.0509s/iter; left time: 803.5037s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047399\n",
      "\tspeed: 0.0506s/iter; left time: 793.8004s\n",
      "\titers: 700, epoch: 3 | loss: 0.1145064\n",
      "\tspeed: 0.0507s/iter; left time: 790.3216s\n",
      "\titers: 800, epoch: 3 | loss: 0.0987913\n",
      "\tspeed: 0.0507s/iter; left time: 784.6588s\n",
      "\titers: 900, epoch: 3 | loss: 0.1122302\n",
      "\tspeed: 0.0507s/iter; left time: 779.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 904 | Train Loss: 0.1095338 Vali Loss: 0.1256561 Test Loss: 0.1422735\n",
      "Validation loss decreased (0.140924 --> 0.125656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153372\n",
      "\tspeed: 0.1259s/iter; left time: 1922.6719s\n",
      "\titers: 200, epoch: 4 | loss: 0.1000890\n",
      "\tspeed: 0.0506s/iter; left time: 766.8459s\n",
      "\titers: 300, epoch: 4 | loss: 0.1141460\n",
      "\tspeed: 0.0506s/iter; left time: 762.1526s\n",
      "\titers: 400, epoch: 4 | loss: 0.0980017\n",
      "\tspeed: 0.0505s/iter; left time: 756.5649s\n",
      "\titers: 500, epoch: 4 | loss: 0.1069045\n",
      "\tspeed: 0.0504s/iter; left time: 749.2749s\n",
      "\titers: 600, epoch: 4 | loss: 0.1010115\n",
      "\tspeed: 0.0504s/iter; left time: 744.9523s\n",
      "\titers: 700, epoch: 4 | loss: 0.1052074\n",
      "\tspeed: 0.0505s/iter; left time: 740.7146s\n",
      "\titers: 800, epoch: 4 | loss: 0.0944677\n",
      "\tspeed: 0.0506s/iter; left time: 736.7107s\n",
      "\titers: 900, epoch: 4 | loss: 0.0917887\n",
      "\tspeed: 0.0502s/iter; left time: 726.9954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.1004663 Vali Loss: 0.1298832 Test Loss: 0.1427613\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909345\n",
      "\tspeed: 0.1222s/iter; left time: 1755.5241s\n",
      "\titers: 200, epoch: 5 | loss: 0.0933988\n",
      "\tspeed: 0.0498s/iter; left time: 710.5553s\n",
      "\titers: 300, epoch: 5 | loss: 0.0942662\n",
      "\tspeed: 0.0497s/iter; left time: 703.4652s\n",
      "\titers: 400, epoch: 5 | loss: 0.1026393\n",
      "\tspeed: 0.0498s/iter; left time: 700.3141s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877419\n",
      "\tspeed: 0.0499s/iter; left time: 697.3258s\n",
      "\titers: 600, epoch: 5 | loss: 0.0984881\n",
      "\tspeed: 0.0499s/iter; left time: 691.5958s\n",
      "\titers: 700, epoch: 5 | loss: 0.0965933\n",
      "\tspeed: 0.0503s/iter; left time: 692.6762s\n",
      "\titers: 800, epoch: 5 | loss: 0.0884743\n",
      "\tspeed: 0.0506s/iter; left time: 691.5599s\n",
      "\titers: 900, epoch: 5 | loss: 0.0875624\n",
      "\tspeed: 0.0507s/iter; left time: 687.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 904 | Train Loss: 0.0937394 Vali Loss: 0.1292347 Test Loss: 0.1464715\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844789\n",
      "\tspeed: 0.1223s/iter; left time: 1645.7527s\n",
      "\titers: 200, epoch: 6 | loss: 0.0831305\n",
      "\tspeed: 0.0504s/iter; left time: 673.0533s\n",
      "\titers: 300, epoch: 6 | loss: 0.0890788\n",
      "\tspeed: 0.0506s/iter; left time: 670.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0890178\n",
      "\tspeed: 0.0505s/iter; left time: 664.6019s\n",
      "\titers: 500, epoch: 6 | loss: 0.0872497\n",
      "\tspeed: 0.0504s/iter; left time: 658.8941s\n",
      "\titers: 600, epoch: 6 | loss: 0.0838243\n",
      "\tspeed: 0.0504s/iter; left time: 653.2431s\n",
      "\titers: 700, epoch: 6 | loss: 0.0790157\n",
      "\tspeed: 0.0506s/iter; left time: 650.2091s\n",
      "\titers: 800, epoch: 6 | loss: 0.0860724\n",
      "\tspeed: 0.0505s/iter; left time: 644.8071s\n",
      "\titers: 900, epoch: 6 | loss: 0.0885994\n",
      "\tspeed: 0.0507s/iter; left time: 642.4027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.0874963 Vali Loss: 0.1259206 Test Loss: 0.1465154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867068\n",
      "\tspeed: 0.1235s/iter; left time: 1551.3603s\n",
      "\titers: 200, epoch: 7 | loss: 0.0808286\n",
      "\tspeed: 0.0505s/iter; left time: 629.6850s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818731\n",
      "\tspeed: 0.0506s/iter; left time: 624.7183s\n",
      "\titers: 400, epoch: 7 | loss: 0.0807535\n",
      "\tspeed: 0.0505s/iter; left time: 619.3385s\n",
      "\titers: 500, epoch: 7 | loss: 0.0798821\n",
      "\tspeed: 0.0504s/iter; left time: 613.2336s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856204\n",
      "\tspeed: 0.0505s/iter; left time: 608.7922s\n",
      "\titers: 700, epoch: 7 | loss: 0.0826759\n",
      "\tspeed: 0.0506s/iter; left time: 604.5178s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764204\n",
      "\tspeed: 0.0509s/iter; left time: 603.1849s\n",
      "\titers: 900, epoch: 7 | loss: 0.0779424\n",
      "\tspeed: 0.0516s/iter; left time: 606.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.0820894 Vali Loss: 0.1282384 Test Loss: 0.1467834\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753770\n",
      "\tspeed: 0.1238s/iter; left time: 1442.5740s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761234\n",
      "\tspeed: 0.0508s/iter; left time: 587.3618s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806233\n",
      "\tspeed: 0.0511s/iter; left time: 584.7093s\n",
      "\titers: 400, epoch: 8 | loss: 0.0802709\n",
      "\tspeed: 0.0508s/iter; left time: 576.8260s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798946\n",
      "\tspeed: 0.0506s/iter; left time: 569.6456s\n",
      "\titers: 600, epoch: 8 | loss: 0.0823787\n",
      "\tspeed: 0.0507s/iter; left time: 565.9418s\n",
      "\titers: 700, epoch: 8 | loss: 0.0790553\n",
      "\tspeed: 0.0505s/iter; left time: 558.3500s\n",
      "\titers: 800, epoch: 8 | loss: 0.0728498\n",
      "\tspeed: 0.0504s/iter; left time: 551.8289s\n",
      "\titers: 900, epoch: 8 | loss: 0.0717074\n",
      "\tspeed: 0.0505s/iter; left time: 548.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0772998 Vali Loss: 0.1293028 Test Loss: 0.1479542\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04122032970190048, rmse:0.2030279040336609, mae:0.14230172336101532, rse:0.7189628481864929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2228246\n",
      "\tspeed: 0.0539s/iter; left time: 970.0559s\n",
      "\titers: 200, epoch: 1 | loss: 0.1975601\n",
      "\tspeed: 0.0515s/iter; left time: 920.7280s\n",
      "\titers: 300, epoch: 1 | loss: 0.1984413\n",
      "\tspeed: 0.0519s/iter; left time: 923.1705s\n",
      "\titers: 400, epoch: 1 | loss: 0.1955372\n",
      "\tspeed: 0.0510s/iter; left time: 902.3944s\n",
      "\titers: 500, epoch: 1 | loss: 0.2015178\n",
      "\tspeed: 0.0507s/iter; left time: 891.0008s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833165\n",
      "\tspeed: 0.0515s/iter; left time: 899.6854s\n",
      "\titers: 700, epoch: 1 | loss: 0.1784639\n",
      "\tspeed: 0.0513s/iter; left time: 892.2272s\n",
      "\titers: 800, epoch: 1 | loss: 0.1788543\n",
      "\tspeed: 0.0511s/iter; left time: 882.4433s\n",
      "\titers: 900, epoch: 1 | loss: 0.1769701\n",
      "\tspeed: 0.0510s/iter; left time: 876.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 904 | Train Loss: 0.1982861 Vali Loss: 0.1791447 Test Loss: 0.1982348\n",
      "Validation loss decreased (inf --> 0.179145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626676\n",
      "\tspeed: 0.1329s/iter; left time: 2269.5882s\n",
      "\titers: 200, epoch: 2 | loss: 0.1418535\n",
      "\tspeed: 0.0505s/iter; left time: 858.1362s\n",
      "\titers: 300, epoch: 2 | loss: 0.1512545\n",
      "\tspeed: 0.0499s/iter; left time: 842.1955s\n",
      "\titers: 400, epoch: 2 | loss: 0.1388979\n",
      "\tspeed: 0.0504s/iter; left time: 845.9797s\n",
      "\titers: 500, epoch: 2 | loss: 0.1387800\n",
      "\tspeed: 0.0505s/iter; left time: 842.1882s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259172\n",
      "\tspeed: 0.0506s/iter; left time: 838.1134s\n",
      "\titers: 700, epoch: 2 | loss: 0.1274560\n",
      "\tspeed: 0.0506s/iter; left time: 833.1670s\n",
      "\titers: 800, epoch: 2 | loss: 0.1289226\n",
      "\tspeed: 0.0503s/iter; left time: 823.2668s\n",
      "\titers: 900, epoch: 2 | loss: 0.1202111\n",
      "\tspeed: 0.0504s/iter; left time: 820.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.1396447 Vali Loss: 0.1410816 Test Loss: 0.1541430\n",
      "Validation loss decreased (0.179145 --> 0.141082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146321\n",
      "\tspeed: 0.1263s/iter; left time: 2041.8913s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086231\n",
      "\tspeed: 0.0510s/iter; left time: 819.1945s\n",
      "\titers: 300, epoch: 3 | loss: 0.1190881\n",
      "\tspeed: 0.0506s/iter; left time: 808.7020s\n",
      "\titers: 400, epoch: 3 | loss: 0.1126139\n",
      "\tspeed: 0.0508s/iter; left time: 806.6522s\n",
      "\titers: 500, epoch: 3 | loss: 0.1115104\n",
      "\tspeed: 0.0507s/iter; left time: 799.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1236731\n",
      "\tspeed: 0.0508s/iter; left time: 796.1503s\n",
      "\titers: 700, epoch: 3 | loss: 0.1179141\n",
      "\tspeed: 0.0507s/iter; left time: 788.9702s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989130\n",
      "\tspeed: 0.0505s/iter; left time: 781.9919s\n",
      "\titers: 900, epoch: 3 | loss: 0.1097365\n",
      "\tspeed: 0.0507s/iter; left time: 779.0321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.1114375 Vali Loss: 0.1281263 Test Loss: 0.1431220\n",
      "Validation loss decreased (0.141082 --> 0.128126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1071102\n",
      "\tspeed: 0.1263s/iter; left time: 1928.5441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969764\n",
      "\tspeed: 0.0501s/iter; left time: 759.9733s\n",
      "\titers: 300, epoch: 4 | loss: 0.1046718\n",
      "\tspeed: 0.0497s/iter; left time: 748.8859s\n",
      "\titers: 400, epoch: 4 | loss: 0.0977541\n",
      "\tspeed: 0.0487s/iter; left time: 729.1974s\n",
      "\titers: 500, epoch: 4 | loss: 0.0945625\n",
      "\tspeed: 0.0481s/iter; left time: 715.8269s\n",
      "\titers: 600, epoch: 4 | loss: 0.0986999\n",
      "\tspeed: 0.0482s/iter; left time: 711.8072s\n",
      "\titers: 700, epoch: 4 | loss: 0.1048499\n",
      "\tspeed: 0.0464s/iter; left time: 680.4869s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994669\n",
      "\tspeed: 0.0460s/iter; left time: 669.8954s\n",
      "\titers: 900, epoch: 4 | loss: 0.0925757\n",
      "\tspeed: 0.0458s/iter; left time: 662.1553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.82s\n",
      "Steps: 904 | Train Loss: 0.1004518 Vali Loss: 0.1291285 Test Loss: 0.1425716\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874742\n",
      "\tspeed: 0.1234s/iter; left time: 1772.0865s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963328\n",
      "\tspeed: 0.0494s/iter; left time: 704.9113s\n",
      "\titers: 300, epoch: 5 | loss: 0.1027813\n",
      "\tspeed: 0.0481s/iter; left time: 681.6077s\n",
      "\titers: 400, epoch: 5 | loss: 0.0895675\n",
      "\tspeed: 0.0478s/iter; left time: 672.6313s\n",
      "\titers: 500, epoch: 5 | loss: 0.0993130\n",
      "\tspeed: 0.0483s/iter; left time: 674.5254s\n",
      "\titers: 600, epoch: 5 | loss: 0.0953645\n",
      "\tspeed: 0.0483s/iter; left time: 669.3154s\n",
      "\titers: 700, epoch: 5 | loss: 0.0892349\n",
      "\tspeed: 0.0480s/iter; left time: 661.2226s\n",
      "\titers: 800, epoch: 5 | loss: 0.0873532\n",
      "\tspeed: 0.0473s/iter; left time: 646.7451s\n",
      "\titers: 900, epoch: 5 | loss: 0.0934440\n",
      "\tspeed: 0.0476s/iter; left time: 645.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.86s\n",
      "Steps: 904 | Train Loss: 0.0931581 Vali Loss: 0.1246601 Test Loss: 0.1443280\n",
      "Validation loss decreased (0.128126 --> 0.124660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961268\n",
      "\tspeed: 0.1241s/iter; left time: 1671.0917s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822272\n",
      "\tspeed: 0.0479s/iter; left time: 639.8865s\n",
      "\titers: 300, epoch: 6 | loss: 0.0832755\n",
      "\tspeed: 0.0491s/iter; left time: 650.9443s\n",
      "\titers: 400, epoch: 6 | loss: 0.0851639\n",
      "\tspeed: 0.0485s/iter; left time: 638.7219s\n",
      "\titers: 500, epoch: 6 | loss: 0.0906663\n",
      "\tspeed: 0.0492s/iter; left time: 642.2392s\n",
      "\titers: 600, epoch: 6 | loss: 0.0864622\n",
      "\tspeed: 0.0490s/iter; left time: 634.4529s\n",
      "\titers: 700, epoch: 6 | loss: 0.0848670\n",
      "\tspeed: 0.0479s/iter; left time: 616.3213s\n",
      "\titers: 800, epoch: 6 | loss: 0.0853517\n",
      "\tspeed: 0.0480s/iter; left time: 612.5557s\n",
      "\titers: 900, epoch: 6 | loss: 0.0898180\n",
      "\tspeed: 0.0475s/iter; left time: 601.2113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.07s\n",
      "Steps: 904 | Train Loss: 0.0864279 Vali Loss: 0.1263104 Test Loss: 0.1436411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830620\n",
      "\tspeed: 0.1228s/iter; left time: 1541.9198s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811775\n",
      "\tspeed: 0.0493s/iter; left time: 614.3111s\n",
      "\titers: 300, epoch: 7 | loss: 0.0790765\n",
      "\tspeed: 0.0501s/iter; left time: 618.8201s\n",
      "\titers: 400, epoch: 7 | loss: 0.0794355\n",
      "\tspeed: 0.0474s/iter; left time: 580.4377s\n",
      "\titers: 500, epoch: 7 | loss: 0.0733461\n",
      "\tspeed: 0.0462s/iter; left time: 562.0339s\n",
      "\titers: 600, epoch: 7 | loss: 0.0799207\n",
      "\tspeed: 0.0473s/iter; left time: 570.7959s\n",
      "\titers: 700, epoch: 7 | loss: 0.0805053\n",
      "\tspeed: 0.0473s/iter; left time: 565.9712s\n",
      "\titers: 800, epoch: 7 | loss: 0.0797424\n",
      "\tspeed: 0.0495s/iter; left time: 586.3928s\n",
      "\titers: 900, epoch: 7 | loss: 0.0868520\n",
      "\tspeed: 0.0490s/iter; left time: 575.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.99s\n",
      "Steps: 904 | Train Loss: 0.0807042 Vali Loss: 0.1286382 Test Loss: 0.1478058\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758880\n",
      "\tspeed: 0.1225s/iter; left time: 1427.6468s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756853\n",
      "\tspeed: 0.0491s/iter; left time: 567.2607s\n",
      "\titers: 300, epoch: 8 | loss: 0.0763412\n",
      "\tspeed: 0.0491s/iter; left time: 562.6049s\n",
      "\titers: 400, epoch: 8 | loss: 0.0878913\n",
      "\tspeed: 0.0484s/iter; left time: 549.1304s\n",
      "\titers: 500, epoch: 8 | loss: 0.0778655\n",
      "\tspeed: 0.0464s/iter; left time: 522.5519s\n",
      "\titers: 600, epoch: 8 | loss: 0.0781955\n",
      "\tspeed: 0.0477s/iter; left time: 531.6148s\n",
      "\titers: 700, epoch: 8 | loss: 0.0686648\n",
      "\tspeed: 0.0472s/iter; left time: 521.6567s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766425\n",
      "\tspeed: 0.0485s/iter; left time: 531.7621s\n",
      "\titers: 900, epoch: 8 | loss: 0.0713768\n",
      "\tspeed: 0.0489s/iter; left time: 530.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.91s\n",
      "Steps: 904 | Train Loss: 0.0758714 Vali Loss: 0.1294556 Test Loss: 0.1475389\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722367\n",
      "\tspeed: 0.1229s/iter; left time: 1320.8477s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719918\n",
      "\tspeed: 0.0495s/iter; left time: 526.7517s\n",
      "\titers: 300, epoch: 9 | loss: 0.0682079\n",
      "\tspeed: 0.0496s/iter; left time: 523.0136s\n",
      "\titers: 400, epoch: 9 | loss: 0.0657540\n",
      "\tspeed: 0.0478s/iter; left time: 499.3316s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733435\n",
      "\tspeed: 0.0439s/iter; left time: 454.2869s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733633\n",
      "\tspeed: 0.0392s/iter; left time: 401.9972s\n",
      "\titers: 700, epoch: 9 | loss: 0.0705372\n",
      "\tspeed: 0.0392s/iter; left time: 397.7362s\n",
      "\titers: 800, epoch: 9 | loss: 0.0677424\n",
      "\tspeed: 0.0406s/iter; left time: 407.6280s\n",
      "\titers: 900, epoch: 9 | loss: 0.0660145\n",
      "\tspeed: 0.0490s/iter; left time: 487.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.16s\n",
      "Steps: 904 | Train Loss: 0.0715858 Vali Loss: 0.1315246 Test Loss: 0.1502602\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692005\n",
      "\tspeed: 0.1231s/iter; left time: 1211.8496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0691886\n",
      "\tspeed: 0.0497s/iter; left time: 484.6451s\n",
      "\titers: 300, epoch: 10 | loss: 0.0687930\n",
      "\tspeed: 0.0496s/iter; left time: 478.5733s\n",
      "\titers: 400, epoch: 10 | loss: 0.0692857\n",
      "\tspeed: 0.0496s/iter; left time: 473.8368s\n",
      "\titers: 500, epoch: 10 | loss: 0.0661787\n",
      "\tspeed: 0.0481s/iter; left time: 453.9018s\n",
      "\titers: 600, epoch: 10 | loss: 0.0713165\n",
      "\tspeed: 0.0485s/iter; left time: 452.8791s\n",
      "\titers: 700, epoch: 10 | loss: 0.0668727\n",
      "\tspeed: 0.0492s/iter; left time: 455.2827s\n",
      "\titers: 800, epoch: 10 | loss: 0.0665657\n",
      "\tspeed: 0.0499s/iter; left time: 456.4630s\n",
      "\titers: 900, epoch: 10 | loss: 0.0688492\n",
      "\tspeed: 0.0500s/iter; left time: 452.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.92s\n",
      "Steps: 904 | Train Loss: 0.0680333 Vali Loss: 0.1297180 Test Loss: 0.1483256\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04413595050573349, rmse:0.21008558571338654, mae:0.14426378905773163, rse:0.7439554929733276\n",
      "Intermediate time for DE and pred_len 96: 00h:15m:54.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2143676\n",
      "\tspeed: 0.0820s/iter; left time: 1471.3804s\n",
      "\titers: 200, epoch: 1 | loss: 0.2117515\n",
      "\tspeed: 0.0541s/iter; left time: 964.8795s\n",
      "\titers: 300, epoch: 1 | loss: 0.1927727\n",
      "\tspeed: 0.0542s/iter; left time: 961.0873s\n",
      "\titers: 400, epoch: 1 | loss: 0.1908412\n",
      "\tspeed: 0.0522s/iter; left time: 921.2835s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840956\n",
      "\tspeed: 0.0499s/iter; left time: 874.5126s\n",
      "\titers: 600, epoch: 1 | loss: 0.1887111\n",
      "\tspeed: 0.0512s/iter; left time: 892.9617s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783495\n",
      "\tspeed: 0.0503s/iter; left time: 873.0014s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741387\n",
      "\tspeed: 0.0520s/iter; left time: 896.5666s\n",
      "\titers: 900, epoch: 1 | loss: 0.1796458\n",
      "\tspeed: 0.0537s/iter; left time: 919.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.96s\n",
      "Steps: 902 | Train Loss: 0.1965990 Vali Loss: 0.1828116 Test Loss: 0.2071697\n",
      "Validation loss decreased (inf --> 0.182812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720107\n",
      "\tspeed: 0.1447s/iter; left time: 2465.7182s\n",
      "\titers: 200, epoch: 2 | loss: 0.1494585\n",
      "\tspeed: 0.0511s/iter; left time: 865.5099s\n",
      "\titers: 300, epoch: 2 | loss: 0.1520132\n",
      "\tspeed: 0.0537s/iter; left time: 903.8573s\n",
      "\titers: 400, epoch: 2 | loss: 0.1517190\n",
      "\tspeed: 0.0529s/iter; left time: 885.2461s\n",
      "\titers: 500, epoch: 2 | loss: 0.1381914\n",
      "\tspeed: 0.0521s/iter; left time: 867.5654s\n",
      "\titers: 600, epoch: 2 | loss: 0.1325774\n",
      "\tspeed: 0.0521s/iter; left time: 862.1610s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320532\n",
      "\tspeed: 0.0505s/iter; left time: 830.5142s\n",
      "\titers: 800, epoch: 2 | loss: 0.1355543\n",
      "\tspeed: 0.0538s/iter; left time: 879.6082s\n",
      "\titers: 900, epoch: 2 | loss: 0.1268250\n",
      "\tspeed: 0.0512s/iter; left time: 831.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.1479768 Vali Loss: 0.1571483 Test Loss: 0.1725036\n",
      "Validation loss decreased (0.182812 --> 0.157148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1298213\n",
      "\tspeed: 0.1461s/iter; left time: 2357.3305s\n",
      "\titers: 200, epoch: 3 | loss: 0.1270678\n",
      "\tspeed: 0.0546s/iter; left time: 875.0936s\n",
      "\titers: 300, epoch: 3 | loss: 0.1299838\n",
      "\tspeed: 0.0535s/iter; left time: 853.0007s\n",
      "\titers: 400, epoch: 3 | loss: 0.1339503\n",
      "\tspeed: 0.0493s/iter; left time: 781.4377s\n",
      "\titers: 500, epoch: 3 | loss: 0.1283429\n",
      "\tspeed: 0.0510s/iter; left time: 802.0874s\n",
      "\titers: 600, epoch: 3 | loss: 0.1257501\n",
      "\tspeed: 0.0504s/iter; left time: 788.4874s\n",
      "\titers: 700, epoch: 3 | loss: 0.1190765\n",
      "\tspeed: 0.0520s/iter; left time: 807.5495s\n",
      "\titers: 800, epoch: 3 | loss: 0.1205630\n",
      "\tspeed: 0.0524s/iter; left time: 809.0160s\n",
      "\titers: 900, epoch: 3 | loss: 0.1183924\n",
      "\tspeed: 0.0528s/iter; left time: 810.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.26s\n",
      "Steps: 902 | Train Loss: 0.1263652 Vali Loss: 0.1494838 Test Loss: 0.1698276\n",
      "Validation loss decreased (0.157148 --> 0.149484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1155508\n",
      "\tspeed: 0.1451s/iter; left time: 2210.5872s\n",
      "\titers: 200, epoch: 4 | loss: 0.1041115\n",
      "\tspeed: 0.0531s/iter; left time: 803.5858s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034060\n",
      "\tspeed: 0.0517s/iter; left time: 776.7251s\n",
      "\titers: 400, epoch: 4 | loss: 0.1053993\n",
      "\tspeed: 0.0525s/iter; left time: 784.4898s\n",
      "\titers: 500, epoch: 4 | loss: 0.1018088\n",
      "\tspeed: 0.0540s/iter; left time: 800.4178s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077380\n",
      "\tspeed: 0.0512s/iter; left time: 754.3121s\n",
      "\titers: 700, epoch: 4 | loss: 0.1009760\n",
      "\tspeed: 0.0532s/iter; left time: 778.8151s\n",
      "\titers: 800, epoch: 4 | loss: 0.1029728\n",
      "\tspeed: 0.0534s/iter; left time: 776.1374s\n",
      "\titers: 900, epoch: 4 | loss: 0.0969269\n",
      "\tspeed: 0.0532s/iter; left time: 767.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.1071249 Vali Loss: 0.1498666 Test Loss: 0.1581961\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0921835\n",
      "\tspeed: 0.1430s/iter; left time: 2049.5515s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946247\n",
      "\tspeed: 0.0525s/iter; left time: 746.5413s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958237\n",
      "\tspeed: 0.0517s/iter; left time: 730.5790s\n",
      "\titers: 400, epoch: 5 | loss: 0.1009195\n",
      "\tspeed: 0.0515s/iter; left time: 723.2145s\n",
      "\titers: 500, epoch: 5 | loss: 0.0915284\n",
      "\tspeed: 0.0509s/iter; left time: 709.7851s\n",
      "\titers: 600, epoch: 5 | loss: 0.0905648\n",
      "\tspeed: 0.0539s/iter; left time: 745.2481s\n",
      "\titers: 700, epoch: 5 | loss: 0.0927724\n",
      "\tspeed: 0.0517s/iter; left time: 709.6732s\n",
      "\titers: 800, epoch: 5 | loss: 0.1016190\n",
      "\tspeed: 0.0519s/iter; left time: 707.5892s\n",
      "\titers: 900, epoch: 5 | loss: 0.0944772\n",
      "\tspeed: 0.0510s/iter; left time: 689.8998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 902 | Train Loss: 0.0974058 Vali Loss: 0.1408406 Test Loss: 0.1551649\n",
      "Validation loss decreased (0.149484 --> 0.140841).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932021\n",
      "\tspeed: 0.1444s/iter; left time: 1939.6463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926236\n",
      "\tspeed: 0.0513s/iter; left time: 683.9999s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907288\n",
      "\tspeed: 0.0514s/iter; left time: 679.4473s\n",
      "\titers: 400, epoch: 6 | loss: 0.0978973\n",
      "\tspeed: 0.0515s/iter; left time: 676.2422s\n",
      "\titers: 500, epoch: 6 | loss: 0.0956134\n",
      "\tspeed: 0.0520s/iter; left time: 677.8161s\n",
      "\titers: 600, epoch: 6 | loss: 0.0908729\n",
      "\tspeed: 0.0534s/iter; left time: 690.1336s\n",
      "\titers: 700, epoch: 6 | loss: 0.0814253\n",
      "\tspeed: 0.0546s/iter; left time: 700.4772s\n",
      "\titers: 800, epoch: 6 | loss: 0.0882680\n",
      "\tspeed: 0.0523s/iter; left time: 665.8617s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903395\n",
      "\tspeed: 0.0508s/iter; left time: 641.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.31s\n",
      "Steps: 902 | Train Loss: 0.0906075 Vali Loss: 0.1435234 Test Loss: 0.1569311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823340\n",
      "\tspeed: 0.1391s/iter; left time: 1742.3315s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836407\n",
      "\tspeed: 0.0529s/iter; left time: 657.3346s\n",
      "\titers: 300, epoch: 7 | loss: 0.0852123\n",
      "\tspeed: 0.0507s/iter; left time: 624.9028s\n",
      "\titers: 400, epoch: 7 | loss: 0.0818945\n",
      "\tspeed: 0.0509s/iter; left time: 623.0208s\n",
      "\titers: 500, epoch: 7 | loss: 0.0864603\n",
      "\tspeed: 0.0505s/iter; left time: 612.8087s\n",
      "\titers: 600, epoch: 7 | loss: 0.0815249\n",
      "\tspeed: 0.0514s/iter; left time: 618.5077s\n",
      "\titers: 700, epoch: 7 | loss: 0.0842814\n",
      "\tspeed: 0.0520s/iter; left time: 620.0365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859686\n",
      "\tspeed: 0.0533s/iter; left time: 630.4007s\n",
      "\titers: 900, epoch: 7 | loss: 0.0876295\n",
      "\tspeed: 0.0501s/iter; left time: 587.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 902 | Train Loss: 0.0842573 Vali Loss: 0.1383368 Test Loss: 0.1558025\n",
      "Validation loss decreased (0.140841 --> 0.138337).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780885\n",
      "\tspeed: 0.1414s/iter; left time: 1643.8187s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838111\n",
      "\tspeed: 0.0547s/iter; left time: 630.7864s\n",
      "\titers: 300, epoch: 8 | loss: 0.0805265\n",
      "\tspeed: 0.0525s/iter; left time: 599.7626s\n",
      "\titers: 400, epoch: 8 | loss: 0.0790132\n",
      "\tspeed: 0.0541s/iter; left time: 612.3716s\n",
      "\titers: 500, epoch: 8 | loss: 0.0785694\n",
      "\tspeed: 0.0533s/iter; left time: 598.6110s\n",
      "\titers: 600, epoch: 8 | loss: 0.0750216\n",
      "\tspeed: 0.0512s/iter; left time: 570.0028s\n",
      "\titers: 700, epoch: 8 | loss: 0.0776697\n",
      "\tspeed: 0.0533s/iter; left time: 587.8262s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769325\n",
      "\tspeed: 0.0520s/iter; left time: 568.6005s\n",
      "\titers: 900, epoch: 8 | loss: 0.0747403\n",
      "\tspeed: 0.0522s/iter; left time: 565.2420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 902 | Train Loss: 0.0794519 Vali Loss: 0.1417993 Test Loss: 0.1582901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711918\n",
      "\tspeed: 0.1426s/iter; left time: 1529.4387s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793033\n",
      "\tspeed: 0.0523s/iter; left time: 556.2177s\n",
      "\titers: 300, epoch: 9 | loss: 0.0817263\n",
      "\tspeed: 0.0510s/iter; left time: 536.9984s\n",
      "\titers: 400, epoch: 9 | loss: 0.0761158\n",
      "\tspeed: 0.0503s/iter; left time: 524.3522s\n",
      "\titers: 500, epoch: 9 | loss: 0.0807231\n",
      "\tspeed: 0.0513s/iter; left time: 529.6941s\n",
      "\titers: 600, epoch: 9 | loss: 0.0731832\n",
      "\tspeed: 0.0530s/iter; left time: 541.7852s\n",
      "\titers: 700, epoch: 9 | loss: 0.0774617\n",
      "\tspeed: 0.0534s/iter; left time: 540.2211s\n",
      "\titers: 800, epoch: 9 | loss: 0.0772811\n",
      "\tspeed: 0.0507s/iter; left time: 508.4414s\n",
      "\titers: 900, epoch: 9 | loss: 0.0736872\n",
      "\tspeed: 0.0511s/iter; left time: 506.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.90s\n",
      "Steps: 902 | Train Loss: 0.0751518 Vali Loss: 0.1422561 Test Loss: 0.1584524\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0668368\n",
      "\tspeed: 0.1405s/iter; left time: 1380.2370s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728021\n",
      "\tspeed: 0.0537s/iter; left time: 522.3645s\n",
      "\titers: 300, epoch: 10 | loss: 0.0750305\n",
      "\tspeed: 0.0516s/iter; left time: 496.2423s\n",
      "\titers: 400, epoch: 10 | loss: 0.0713177\n",
      "\tspeed: 0.0503s/iter; left time: 478.9749s\n",
      "\titers: 500, epoch: 10 | loss: 0.0725282\n",
      "\tspeed: 0.0509s/iter; left time: 479.8414s\n",
      "\titers: 600, epoch: 10 | loss: 0.0728812\n",
      "\tspeed: 0.0520s/iter; left time: 484.8407s\n",
      "\titers: 700, epoch: 10 | loss: 0.0732005\n",
      "\tspeed: 0.0547s/iter; left time: 504.3343s\n",
      "\titers: 800, epoch: 10 | loss: 0.0709999\n",
      "\tspeed: 0.0508s/iter; left time: 463.7888s\n",
      "\titers: 900, epoch: 10 | loss: 0.0734219\n",
      "\tspeed: 0.0518s/iter; left time: 467.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 902 | Train Loss: 0.0715689 Vali Loss: 0.1426778 Test Loss: 0.1605491\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0681446\n",
      "\tspeed: 0.1401s/iter; left time: 1250.2348s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697667\n",
      "\tspeed: 0.0539s/iter; left time: 475.1983s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655064\n",
      "\tspeed: 0.0543s/iter; left time: 473.5026s\n",
      "\titers: 400, epoch: 11 | loss: 0.0666977\n",
      "\tspeed: 0.0539s/iter; left time: 464.6365s\n",
      "\titers: 500, epoch: 11 | loss: 0.0786548\n",
      "\tspeed: 0.0513s/iter; left time: 437.2385s\n",
      "\titers: 600, epoch: 11 | loss: 0.0678788\n",
      "\tspeed: 0.0533s/iter; left time: 448.4274s\n",
      "\titers: 700, epoch: 11 | loss: 0.0705262\n",
      "\tspeed: 0.0522s/iter; left time: 434.7655s\n",
      "\titers: 800, epoch: 11 | loss: 0.0674626\n",
      "\tspeed: 0.0519s/iter; left time: 426.9802s\n",
      "\titers: 900, epoch: 11 | loss: 0.0651507\n",
      "\tspeed: 0.0507s/iter; left time: 411.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0687391 Vali Loss: 0.1402910 Test Loss: 0.1587802\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0653112\n",
      "\tspeed: 0.1421s/iter; left time: 1139.5528s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699357\n",
      "\tspeed: 0.0524s/iter; left time: 415.3268s\n",
      "\titers: 300, epoch: 12 | loss: 0.0649073\n",
      "\tspeed: 0.0514s/iter; left time: 402.1268s\n",
      "\titers: 400, epoch: 12 | loss: 0.0659068\n",
      "\tspeed: 0.0516s/iter; left time: 398.6303s\n",
      "\titers: 500, epoch: 12 | loss: 0.0660025\n",
      "\tspeed: 0.0516s/iter; left time: 393.3168s\n",
      "\titers: 600, epoch: 12 | loss: 0.0685619\n",
      "\tspeed: 0.0531s/iter; left time: 399.5968s\n",
      "\titers: 700, epoch: 12 | loss: 0.0702067\n",
      "\tspeed: 0.0517s/iter; left time: 383.4869s\n",
      "\titers: 800, epoch: 12 | loss: 0.0664895\n",
      "\tspeed: 0.0525s/iter; left time: 384.2946s\n",
      "\titers: 900, epoch: 12 | loss: 0.0690533\n",
      "\tspeed: 0.0515s/iter; left time: 371.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.0663095 Vali Loss: 0.1424346 Test Loss: 0.1606143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.053022854030132294, rmse:0.23026691377162933, mae:0.15602098405361176, rse:0.8157663345336914\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2201324\n",
      "\tspeed: 0.0549s/iter; left time: 985.7384s\n",
      "\titers: 200, epoch: 1 | loss: 0.2001715\n",
      "\tspeed: 0.0508s/iter; left time: 907.0274s\n",
      "\titers: 300, epoch: 1 | loss: 0.1991532\n",
      "\tspeed: 0.0512s/iter; left time: 907.5192s\n",
      "\titers: 400, epoch: 1 | loss: 0.1883941\n",
      "\tspeed: 0.0532s/iter; left time: 937.7628s\n",
      "\titers: 500, epoch: 1 | loss: 0.1873800\n",
      "\tspeed: 0.0524s/iter; left time: 918.5607s\n",
      "\titers: 600, epoch: 1 | loss: 0.1834275\n",
      "\tspeed: 0.0520s/iter; left time: 906.7906s\n",
      "\titers: 700, epoch: 1 | loss: 0.1915931\n",
      "\tspeed: 0.0527s/iter; left time: 913.7041s\n",
      "\titers: 800, epoch: 1 | loss: 0.1855758\n",
      "\tspeed: 0.0512s/iter; left time: 883.2315s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799206\n",
      "\tspeed: 0.0530s/iter; left time: 909.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.32s\n",
      "Steps: 902 | Train Loss: 0.1969401 Vali Loss: 0.1832115 Test Loss: 0.2068883\n",
      "Validation loss decreased (inf --> 0.183212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1596465\n",
      "\tspeed: 0.1500s/iter; left time: 2555.6245s\n",
      "\titers: 200, epoch: 2 | loss: 0.1578218\n",
      "\tspeed: 0.0529s/iter; left time: 895.9734s\n",
      "\titers: 300, epoch: 2 | loss: 0.1497701\n",
      "\tspeed: 0.0527s/iter; left time: 886.7183s\n",
      "\titers: 400, epoch: 2 | loss: 0.1531094\n",
      "\tspeed: 0.0537s/iter; left time: 899.0457s\n",
      "\titers: 500, epoch: 2 | loss: 0.1408316\n",
      "\tspeed: 0.0526s/iter; left time: 874.7931s\n",
      "\titers: 600, epoch: 2 | loss: 0.1419959\n",
      "\tspeed: 0.0514s/iter; left time: 849.4059s\n",
      "\titers: 700, epoch: 2 | loss: 0.1315546\n",
      "\tspeed: 0.0525s/iter; left time: 863.3601s\n",
      "\titers: 800, epoch: 2 | loss: 0.1384183\n",
      "\tspeed: 0.0521s/iter; left time: 850.4561s\n",
      "\titers: 900, epoch: 2 | loss: 0.1377827\n",
      "\tspeed: 0.0547s/iter; left time: 888.2332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.02s\n",
      "Steps: 902 | Train Loss: 0.1480785 Vali Loss: 0.1684496 Test Loss: 0.1873153\n",
      "Validation loss decreased (0.183212 --> 0.168450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1325896\n",
      "\tspeed: 0.1599s/iter; left time: 2580.1987s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413253\n",
      "\tspeed: 0.0502s/iter; left time: 805.2850s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303057\n",
      "\tspeed: 0.0536s/iter; left time: 853.9547s\n",
      "\titers: 400, epoch: 3 | loss: 0.1383175\n",
      "\tspeed: 0.0536s/iter; left time: 849.2935s\n",
      "\titers: 500, epoch: 3 | loss: 0.1243712\n",
      "\tspeed: 0.0523s/iter; left time: 822.8319s\n",
      "\titers: 600, epoch: 3 | loss: 0.1304547\n",
      "\tspeed: 0.0506s/iter; left time: 791.8153s\n",
      "\titers: 700, epoch: 3 | loss: 0.1181477\n",
      "\tspeed: 0.0524s/iter; left time: 814.8231s\n",
      "\titers: 800, epoch: 3 | loss: 0.1223750\n",
      "\tspeed: 0.0523s/iter; left time: 806.8879s\n",
      "\titers: 900, epoch: 3 | loss: 0.1114032\n",
      "\tspeed: 0.0535s/iter; left time: 821.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.48s\n",
      "Steps: 902 | Train Loss: 0.1275883 Vali Loss: 0.1371416 Test Loss: 0.1529757\n",
      "Validation loss decreased (0.168450 --> 0.137142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1154191\n",
      "\tspeed: 0.1555s/iter; left time: 2368.4512s\n",
      "\titers: 200, epoch: 4 | loss: 0.1040316\n",
      "\tspeed: 0.0543s/iter; left time: 822.3829s\n",
      "\titers: 300, epoch: 4 | loss: 0.0999732\n",
      "\tspeed: 0.0532s/iter; left time: 799.2403s\n",
      "\titers: 400, epoch: 4 | loss: 0.1075287\n",
      "\tspeed: 0.0527s/iter; left time: 787.3995s\n",
      "\titers: 500, epoch: 4 | loss: 0.1019707\n",
      "\tspeed: 0.0531s/iter; left time: 788.0533s\n",
      "\titers: 600, epoch: 4 | loss: 0.0993232\n",
      "\tspeed: 0.0512s/iter; left time: 753.8756s\n",
      "\titers: 700, epoch: 4 | loss: 0.1015184\n",
      "\tspeed: 0.0521s/iter; left time: 762.3818s\n",
      "\titers: 800, epoch: 4 | loss: 0.1015958\n",
      "\tspeed: 0.0543s/iter; left time: 789.3634s\n",
      "\titers: 900, epoch: 4 | loss: 0.1020327\n",
      "\tspeed: 0.0534s/iter; left time: 770.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.07s\n",
      "Steps: 902 | Train Loss: 0.1058670 Vali Loss: 0.1376515 Test Loss: 0.1540516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1028747\n",
      "\tspeed: 0.1407s/iter; left time: 2016.4449s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934217\n",
      "\tspeed: 0.0523s/iter; left time: 744.2220s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986301\n",
      "\tspeed: 0.0548s/iter; left time: 774.7619s\n",
      "\titers: 400, epoch: 5 | loss: 0.0986802\n",
      "\tspeed: 0.0525s/iter; left time: 737.0377s\n",
      "\titers: 500, epoch: 5 | loss: 0.0942053\n",
      "\tspeed: 0.0510s/iter; left time: 710.3399s\n",
      "\titers: 600, epoch: 5 | loss: 0.1024459\n",
      "\tspeed: 0.0522s/iter; left time: 722.4331s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918240\n",
      "\tspeed: 0.0500s/iter; left time: 687.0377s\n",
      "\titers: 800, epoch: 5 | loss: 0.0978398\n",
      "\tspeed: 0.0525s/iter; left time: 716.1805s\n",
      "\titers: 900, epoch: 5 | loss: 0.1018387\n",
      "\tspeed: 0.0531s/iter; left time: 718.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.0971580 Vali Loss: 0.1384684 Test Loss: 0.1528751\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0907427\n",
      "\tspeed: 0.1408s/iter; left time: 1891.0171s\n",
      "\titers: 200, epoch: 6 | loss: 0.1008368\n",
      "\tspeed: 0.0523s/iter; left time: 696.6930s\n",
      "\titers: 300, epoch: 6 | loss: 0.0912324\n",
      "\tspeed: 0.0538s/iter; left time: 712.1977s\n",
      "\titers: 400, epoch: 6 | loss: 0.0817516\n",
      "\tspeed: 0.0523s/iter; left time: 686.7482s\n",
      "\titers: 500, epoch: 6 | loss: 0.0888023\n",
      "\tspeed: 0.0527s/iter; left time: 686.2675s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920842\n",
      "\tspeed: 0.0534s/iter; left time: 689.9907s\n",
      "\titers: 700, epoch: 6 | loss: 0.0880135\n",
      "\tspeed: 0.0531s/iter; left time: 681.5950s\n",
      "\titers: 800, epoch: 6 | loss: 0.0896069\n",
      "\tspeed: 0.0533s/iter; left time: 678.5904s\n",
      "\titers: 900, epoch: 6 | loss: 0.0879484\n",
      "\tspeed: 0.0526s/iter; left time: 664.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.86s\n",
      "Steps: 902 | Train Loss: 0.0902217 Vali Loss: 0.1371762 Test Loss: 0.1525187\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811038\n",
      "\tspeed: 0.1415s/iter; left time: 1773.0703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820944\n",
      "\tspeed: 0.0543s/iter; left time: 674.6802s\n",
      "\titers: 300, epoch: 7 | loss: 0.0783249\n",
      "\tspeed: 0.0532s/iter; left time: 655.8493s\n",
      "\titers: 400, epoch: 7 | loss: 0.0892762\n",
      "\tspeed: 0.0524s/iter; left time: 640.3938s\n",
      "\titers: 500, epoch: 7 | loss: 0.0804740\n",
      "\tspeed: 0.0512s/iter; left time: 621.2167s\n",
      "\titers: 600, epoch: 7 | loss: 0.0863952\n",
      "\tspeed: 0.0507s/iter; left time: 609.4150s\n",
      "\titers: 700, epoch: 7 | loss: 0.0759322\n",
      "\tspeed: 0.0515s/iter; left time: 614.6421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0835908\n",
      "\tspeed: 0.0540s/iter; left time: 639.0590s\n",
      "\titers: 900, epoch: 7 | loss: 0.0783999\n",
      "\tspeed: 0.0515s/iter; left time: 603.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.0839978 Vali Loss: 0.1375310 Test Loss: 0.1532999\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0879491\n",
      "\tspeed: 0.1431s/iter; left time: 1663.8212s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793215\n",
      "\tspeed: 0.0533s/iter; left time: 614.3369s\n",
      "\titers: 300, epoch: 8 | loss: 0.0858402\n",
      "\tspeed: 0.0513s/iter; left time: 585.9446s\n",
      "\titers: 400, epoch: 8 | loss: 0.0771001\n",
      "\tspeed: 0.0505s/iter; left time: 572.1057s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798749\n",
      "\tspeed: 0.0512s/iter; left time: 574.7575s\n",
      "\titers: 600, epoch: 8 | loss: 0.0801735\n",
      "\tspeed: 0.0510s/iter; left time: 567.2209s\n",
      "\titers: 700, epoch: 8 | loss: 0.0771784\n",
      "\tspeed: 0.0541s/iter; left time: 596.3842s\n",
      "\titers: 800, epoch: 8 | loss: 0.0812665\n",
      "\tspeed: 0.0542s/iter; left time: 592.2885s\n",
      "\titers: 900, epoch: 8 | loss: 0.0811051\n",
      "\tspeed: 0.0526s/iter; left time: 569.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.37s\n",
      "Steps: 902 | Train Loss: 0.0789480 Vali Loss: 0.1395975 Test Loss: 0.1572920\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04767633229494095, rmse:0.21834909915924072, mae:0.15297505259513855, rse:0.7735451459884644\n",
      "Intermediate time for DE and pred_len 168: 00h:19m:10.24s\n",
      "Intermediate time for DE: 00h:58m:16.29s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2113341\n",
      "\tspeed: 0.0701s/iter; left time: 1262.4581s\n",
      "\titers: 200, epoch: 1 | loss: 0.1939111\n",
      "\tspeed: 0.0412s/iter; left time: 737.6089s\n",
      "\titers: 300, epoch: 1 | loss: 0.1798092\n",
      "\tspeed: 0.0415s/iter; left time: 740.1921s\n",
      "\titers: 400, epoch: 1 | loss: 0.1744348\n",
      "\tspeed: 0.0419s/iter; left time: 741.9444s\n",
      "\titers: 500, epoch: 1 | loss: 0.1593372\n",
      "\tspeed: 0.0389s/iter; left time: 685.9671s\n",
      "\titers: 600, epoch: 1 | loss: 0.1606529\n",
      "\tspeed: 0.0387s/iter; left time: 677.4012s\n",
      "\titers: 700, epoch: 1 | loss: 0.1555635\n",
      "\tspeed: 0.0333s/iter; left time: 579.9983s\n",
      "\titers: 800, epoch: 1 | loss: 0.1435576\n",
      "\tspeed: 0.0390s/iter; left time: 675.5177s\n",
      "\titers: 900, epoch: 1 | loss: 0.1427359\n",
      "\tspeed: 0.0426s/iter; left time: 733.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.1802784 Vali Loss: 0.1541678 Test Loss: 0.1811512\n",
      "Validation loss decreased (inf --> 0.154168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1370904\n",
      "\tspeed: 0.1038s/iter; left time: 1777.0264s\n",
      "\titers: 200, epoch: 2 | loss: 0.1191782\n",
      "\tspeed: 0.0405s/iter; left time: 688.9864s\n",
      "\titers: 300, epoch: 2 | loss: 0.1010349\n",
      "\tspeed: 0.0414s/iter; left time: 700.8579s\n",
      "\titers: 400, epoch: 2 | loss: 0.1107639\n",
      "\tspeed: 0.0402s/iter; left time: 675.4996s\n",
      "\titers: 500, epoch: 2 | loss: 0.1140048\n",
      "\tspeed: 0.0412s/iter; left time: 688.6519s\n",
      "\titers: 600, epoch: 2 | loss: 0.0916289\n",
      "\tspeed: 0.0416s/iter; left time: 690.5227s\n",
      "\titers: 700, epoch: 2 | loss: 0.1156958\n",
      "\tspeed: 0.0393s/iter; left time: 648.4811s\n",
      "\titers: 800, epoch: 2 | loss: 0.1135648\n",
      "\tspeed: 0.0391s/iter; left time: 641.3358s\n",
      "\titers: 900, epoch: 2 | loss: 0.1022947\n",
      "\tspeed: 0.0410s/iter; left time: 669.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.1129938 Vali Loss: 0.1188597 Test Loss: 0.1426858\n",
      "Validation loss decreased (0.154168 --> 0.118860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034873\n",
      "\tspeed: 0.1066s/iter; left time: 1728.4544s\n",
      "\titers: 200, epoch: 3 | loss: 0.1002087\n",
      "\tspeed: 0.0408s/iter; left time: 657.6068s\n",
      "\titers: 300, epoch: 3 | loss: 0.1054211\n",
      "\tspeed: 0.0413s/iter; left time: 660.8803s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004911\n",
      "\tspeed: 0.0403s/iter; left time: 640.7331s\n",
      "\titers: 500, epoch: 3 | loss: 0.1002003\n",
      "\tspeed: 0.0416s/iter; left time: 657.6786s\n",
      "\titers: 600, epoch: 3 | loss: 0.0996972\n",
      "\tspeed: 0.0428s/iter; left time: 671.5825s\n",
      "\titers: 700, epoch: 3 | loss: 0.0997507\n",
      "\tspeed: 0.0431s/iter; left time: 673.3459s\n",
      "\titers: 800, epoch: 3 | loss: 0.0918966\n",
      "\tspeed: 0.0423s/iter; left time: 655.8219s\n",
      "\titers: 900, epoch: 3 | loss: 0.1007679\n",
      "\tspeed: 0.0443s/iter; left time: 682.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.1001998 Vali Loss: 0.1145102 Test Loss: 0.1382046\n",
      "Validation loss decreased (0.118860 --> 0.114510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881878\n",
      "\tspeed: 0.1107s/iter; left time: 1693.5830s\n",
      "\titers: 200, epoch: 4 | loss: 0.1034280\n",
      "\tspeed: 0.0424s/iter; left time: 644.1938s\n",
      "\titers: 300, epoch: 4 | loss: 0.0962766\n",
      "\tspeed: 0.0427s/iter; left time: 644.8530s\n",
      "\titers: 400, epoch: 4 | loss: 0.1010057\n",
      "\tspeed: 0.0409s/iter; left time: 613.6448s\n",
      "\titers: 500, epoch: 4 | loss: 0.1161118\n",
      "\tspeed: 0.0428s/iter; left time: 638.1229s\n",
      "\titers: 600, epoch: 4 | loss: 0.1033959\n",
      "\tspeed: 0.0417s/iter; left time: 617.8816s\n",
      "\titers: 700, epoch: 4 | loss: 0.0912785\n",
      "\tspeed: 0.0405s/iter; left time: 595.4116s\n",
      "\titers: 800, epoch: 4 | loss: 0.0965739\n",
      "\tspeed: 0.0448s/iter; left time: 653.5074s\n",
      "\titers: 900, epoch: 4 | loss: 0.0967808\n",
      "\tspeed: 0.0425s/iter; left time: 616.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 906 | Train Loss: 0.0968959 Vali Loss: 0.1142993 Test Loss: 0.1342016\n",
      "Validation loss decreased (0.114510 --> 0.114299).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1075176\n",
      "\tspeed: 0.1107s/iter; left time: 1594.0732s\n",
      "\titers: 200, epoch: 5 | loss: 0.0871575\n",
      "\tspeed: 0.0442s/iter; left time: 631.5174s\n",
      "\titers: 300, epoch: 5 | loss: 0.0921738\n",
      "\tspeed: 0.0445s/iter; left time: 631.4813s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033385\n",
      "\tspeed: 0.0444s/iter; left time: 626.1897s\n",
      "\titers: 500, epoch: 5 | loss: 0.0857381\n",
      "\tspeed: 0.0444s/iter; left time: 621.2835s\n",
      "\titers: 600, epoch: 5 | loss: 0.0873333\n",
      "\tspeed: 0.0444s/iter; left time: 616.8172s\n",
      "\titers: 700, epoch: 5 | loss: 0.1015887\n",
      "\tspeed: 0.0444s/iter; left time: 612.7377s\n",
      "\titers: 800, epoch: 5 | loss: 0.1003189\n",
      "\tspeed: 0.0423s/iter; left time: 579.9755s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849322\n",
      "\tspeed: 0.0432s/iter; left time: 586.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.12s\n",
      "Steps: 906 | Train Loss: 0.0941614 Vali Loss: 0.1160385 Test Loss: 0.1400663\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0940297\n",
      "\tspeed: 0.1059s/iter; left time: 1429.1392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987860\n",
      "\tspeed: 0.0445s/iter; left time: 595.6223s\n",
      "\titers: 300, epoch: 6 | loss: 0.0889130\n",
      "\tspeed: 0.0446s/iter; left time: 592.4184s\n",
      "\titers: 400, epoch: 6 | loss: 0.0926011\n",
      "\tspeed: 0.0417s/iter; left time: 549.4123s\n",
      "\titers: 500, epoch: 6 | loss: 0.0948536\n",
      "\tspeed: 0.0440s/iter; left time: 575.4568s\n",
      "\titers: 600, epoch: 6 | loss: 0.0864705\n",
      "\tspeed: 0.0425s/iter; left time: 552.6601s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910312\n",
      "\tspeed: 0.0424s/iter; left time: 546.1583s\n",
      "\titers: 800, epoch: 6 | loss: 0.0813692\n",
      "\tspeed: 0.0414s/iter; left time: 529.6876s\n",
      "\titers: 900, epoch: 6 | loss: 0.0944316\n",
      "\tspeed: 0.0414s/iter; left time: 525.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.12s\n",
      "Steps: 906 | Train Loss: 0.0914372 Vali Loss: 0.1205823 Test Loss: 0.1484592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0804197\n",
      "\tspeed: 0.1045s/iter; left time: 1315.6964s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928350\n",
      "\tspeed: 0.0437s/iter; left time: 545.6758s\n",
      "\titers: 300, epoch: 7 | loss: 0.0895849\n",
      "\tspeed: 0.0419s/iter; left time: 518.6997s\n",
      "\titers: 400, epoch: 7 | loss: 0.0982223\n",
      "\tspeed: 0.0418s/iter; left time: 513.5580s\n",
      "\titers: 500, epoch: 7 | loss: 0.0866589\n",
      "\tspeed: 0.0423s/iter; left time: 515.3725s\n",
      "\titers: 600, epoch: 7 | loss: 0.0716318\n",
      "\tspeed: 0.0414s/iter; left time: 499.8829s\n",
      "\titers: 700, epoch: 7 | loss: 0.0926144\n",
      "\tspeed: 0.0419s/iter; left time: 501.9940s\n",
      "\titers: 800, epoch: 7 | loss: 0.0887576\n",
      "\tspeed: 0.0408s/iter; left time: 484.6865s\n",
      "\titers: 900, epoch: 7 | loss: 0.0910463\n",
      "\tspeed: 0.0414s/iter; left time: 487.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 906 | Train Loss: 0.0883436 Vali Loss: 0.1165588 Test Loss: 0.1441727\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863066\n",
      "\tspeed: 0.1025s/iter; left time: 1196.8469s\n",
      "\titers: 200, epoch: 8 | loss: 0.0772502\n",
      "\tspeed: 0.0410s/iter; left time: 474.2303s\n",
      "\titers: 300, epoch: 8 | loss: 0.0882930\n",
      "\tspeed: 0.0394s/iter; left time: 452.6075s\n",
      "\titers: 400, epoch: 8 | loss: 0.0815420\n",
      "\tspeed: 0.0423s/iter; left time: 480.8114s\n",
      "\titers: 500, epoch: 8 | loss: 0.0907906\n",
      "\tspeed: 0.0427s/iter; left time: 481.6264s\n",
      "\titers: 600, epoch: 8 | loss: 0.0891234\n",
      "\tspeed: 0.0442s/iter; left time: 493.6791s\n",
      "\titers: 700, epoch: 8 | loss: 0.0826091\n",
      "\tspeed: 0.0396s/iter; left time: 439.1934s\n",
      "\titers: 800, epoch: 8 | loss: 0.0899871\n",
      "\tspeed: 0.0416s/iter; left time: 457.0302s\n",
      "\titers: 900, epoch: 8 | loss: 0.0860059\n",
      "\tspeed: 0.0405s/iter; left time: 440.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.0858847 Vali Loss: 0.1204836 Test Loss: 0.1483876\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0906029\n",
      "\tspeed: 0.1031s/iter; left time: 1110.9823s\n",
      "\titers: 200, epoch: 9 | loss: 0.0865637\n",
      "\tspeed: 0.0429s/iter; left time: 457.6632s\n",
      "\titers: 300, epoch: 9 | loss: 0.0798166\n",
      "\tspeed: 0.0431s/iter; left time: 456.1773s\n",
      "\titers: 400, epoch: 9 | loss: 0.0883184\n",
      "\tspeed: 0.0441s/iter; left time: 461.4484s\n",
      "\titers: 500, epoch: 9 | loss: 0.0839940\n",
      "\tspeed: 0.0414s/iter; left time: 429.4434s\n",
      "\titers: 600, epoch: 9 | loss: 0.0735761\n",
      "\tspeed: 0.0405s/iter; left time: 415.7908s\n",
      "\titers: 700, epoch: 9 | loss: 0.0817910\n",
      "\tspeed: 0.0436s/iter; left time: 444.0454s\n",
      "\titers: 800, epoch: 9 | loss: 0.0895841\n",
      "\tspeed: 0.0445s/iter; left time: 447.8942s\n",
      "\titers: 900, epoch: 9 | loss: 0.0737404\n",
      "\tspeed: 0.0442s/iter; left time: 440.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.02s\n",
      "Steps: 906 | Train Loss: 0.0833755 Vali Loss: 0.1193913 Test Loss: 0.1506973\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.044055793434381485, rmse:0.20989471673965454, mae:0.13415901362895966, rse:0.7237120866775513\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2428235\n",
      "\tspeed: 0.0445s/iter; left time: 801.2211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2057789\n",
      "\tspeed: 0.0447s/iter; left time: 801.8210s\n",
      "\titers: 300, epoch: 1 | loss: 0.1798792\n",
      "\tspeed: 0.0430s/iter; left time: 766.3847s\n",
      "\titers: 400, epoch: 1 | loss: 0.1719038\n",
      "\tspeed: 0.0432s/iter; left time: 766.0828s\n",
      "\titers: 500, epoch: 1 | loss: 0.1708177\n",
      "\tspeed: 0.0423s/iter; left time: 745.8599s\n",
      "\titers: 600, epoch: 1 | loss: 0.1570417\n",
      "\tspeed: 0.0402s/iter; left time: 703.6126s\n",
      "\titers: 700, epoch: 1 | loss: 0.1589757\n",
      "\tspeed: 0.0405s/iter; left time: 705.9459s\n",
      "\titers: 800, epoch: 1 | loss: 0.1546320\n",
      "\tspeed: 0.0409s/iter; left time: 708.4729s\n",
      "\titers: 900, epoch: 1 | loss: 0.1549362\n",
      "\tspeed: 0.0431s/iter; left time: 742.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 906 | Train Loss: 0.1875353 Vali Loss: 0.1492720 Test Loss: 0.1801390\n",
      "Validation loss decreased (inf --> 0.149272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348393\n",
      "\tspeed: 0.1091s/iter; left time: 1868.0824s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083008\n",
      "\tspeed: 0.0420s/iter; left time: 714.3792s\n",
      "\titers: 300, epoch: 2 | loss: 0.1321781\n",
      "\tspeed: 0.0441s/iter; left time: 745.2249s\n",
      "\titers: 400, epoch: 2 | loss: 0.1061094\n",
      "\tspeed: 0.0429s/iter; left time: 721.9750s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231315\n",
      "\tspeed: 0.0441s/iter; left time: 737.6438s\n",
      "\titers: 600, epoch: 2 | loss: 0.1052596\n",
      "\tspeed: 0.0407s/iter; left time: 676.1413s\n",
      "\titers: 700, epoch: 2 | loss: 0.0950724\n",
      "\tspeed: 0.0410s/iter; left time: 677.7413s\n",
      "\titers: 800, epoch: 2 | loss: 0.0955931\n",
      "\tspeed: 0.0414s/iter; left time: 680.3324s\n",
      "\titers: 900, epoch: 2 | loss: 0.0924762\n",
      "\tspeed: 0.0375s/iter; left time: 611.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 906 | Train Loss: 0.1110337 Vali Loss: 0.1099066 Test Loss: 0.1318764\n",
      "Validation loss decreased (0.149272 --> 0.109907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0923405\n",
      "\tspeed: 0.1100s/iter; left time: 1783.7845s\n",
      "\titers: 200, epoch: 3 | loss: 0.0813107\n",
      "\tspeed: 0.0420s/iter; left time: 677.0576s\n",
      "\titers: 300, epoch: 3 | loss: 0.0849250\n",
      "\tspeed: 0.0414s/iter; left time: 662.2659s\n",
      "\titers: 400, epoch: 3 | loss: 0.0939740\n",
      "\tspeed: 0.0416s/iter; left time: 662.1010s\n",
      "\titers: 500, epoch: 3 | loss: 0.0956512\n",
      "\tspeed: 0.0437s/iter; left time: 690.4079s\n",
      "\titers: 600, epoch: 3 | loss: 0.0800993\n",
      "\tspeed: 0.0404s/iter; left time: 634.7718s\n",
      "\titers: 700, epoch: 3 | loss: 0.0859409\n",
      "\tspeed: 0.0412s/iter; left time: 643.2578s\n",
      "\titers: 800, epoch: 3 | loss: 0.0766279\n",
      "\tspeed: 0.0414s/iter; left time: 641.3931s\n",
      "\titers: 900, epoch: 3 | loss: 0.0780128\n",
      "\tspeed: 0.0424s/iter; left time: 653.6682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 906 | Train Loss: 0.0860765 Vali Loss: 0.0999773 Test Loss: 0.1211452\n",
      "Validation loss decreased (0.109907 --> 0.099977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0768543\n",
      "\tspeed: 0.1074s/iter; left time: 1643.2586s\n",
      "\titers: 200, epoch: 4 | loss: 0.0715280\n",
      "\tspeed: 0.0414s/iter; left time: 628.8105s\n",
      "\titers: 300, epoch: 4 | loss: 0.0677910\n",
      "\tspeed: 0.0416s/iter; left time: 628.0141s\n",
      "\titers: 400, epoch: 4 | loss: 0.0670909\n",
      "\tspeed: 0.0421s/iter; left time: 632.3553s\n",
      "\titers: 500, epoch: 4 | loss: 0.0756935\n",
      "\tspeed: 0.0431s/iter; left time: 642.7114s\n",
      "\titers: 600, epoch: 4 | loss: 0.0924990\n",
      "\tspeed: 0.0431s/iter; left time: 637.7754s\n",
      "\titers: 700, epoch: 4 | loss: 0.0793719\n",
      "\tspeed: 0.0417s/iter; left time: 612.7837s\n",
      "\titers: 800, epoch: 4 | loss: 0.0839831\n",
      "\tspeed: 0.0408s/iter; left time: 595.3371s\n",
      "\titers: 900, epoch: 4 | loss: 0.0862410\n",
      "\tspeed: 0.0419s/iter; left time: 607.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 906 | Train Loss: 0.0813469 Vali Loss: 0.0994681 Test Loss: 0.1163621\n",
      "Validation loss decreased (0.099977 --> 0.099468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788396\n",
      "\tspeed: 0.1082s/iter; left time: 1557.1563s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773479\n",
      "\tspeed: 0.0439s/iter; left time: 628.0851s\n",
      "\titers: 300, epoch: 5 | loss: 0.0841149\n",
      "\tspeed: 0.0434s/iter; left time: 616.1047s\n",
      "\titers: 400, epoch: 5 | loss: 0.0781510\n",
      "\tspeed: 0.0405s/iter; left time: 571.4702s\n",
      "\titers: 500, epoch: 5 | loss: 0.0816887\n",
      "\tspeed: 0.0410s/iter; left time: 574.1494s\n",
      "\titers: 600, epoch: 5 | loss: 0.0724723\n",
      "\tspeed: 0.0413s/iter; left time: 574.4166s\n",
      "\titers: 700, epoch: 5 | loss: 0.0761333\n",
      "\tspeed: 0.0424s/iter; left time: 585.2206s\n",
      "\titers: 800, epoch: 5 | loss: 0.0673740\n",
      "\tspeed: 0.0447s/iter; left time: 612.4852s\n",
      "\titers: 900, epoch: 5 | loss: 0.0788379\n",
      "\tspeed: 0.0436s/iter; left time: 592.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 906 | Train Loss: 0.0774063 Vali Loss: 0.0963497 Test Loss: 0.1142610\n",
      "Validation loss decreased (0.099468 --> 0.096350).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0804996\n",
      "\tspeed: 0.1114s/iter; left time: 1503.3126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841669\n",
      "\tspeed: 0.0413s/iter; left time: 553.5008s\n",
      "\titers: 300, epoch: 6 | loss: 0.0667240\n",
      "\tspeed: 0.0414s/iter; left time: 550.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776014\n",
      "\tspeed: 0.0419s/iter; left time: 552.4822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827275\n",
      "\tspeed: 0.0409s/iter; left time: 535.5406s\n",
      "\titers: 600, epoch: 6 | loss: 0.0766752\n",
      "\tspeed: 0.0433s/iter; left time: 563.0475s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804901\n",
      "\tspeed: 0.0447s/iter; left time: 575.7711s\n",
      "\titers: 800, epoch: 6 | loss: 0.0744671\n",
      "\tspeed: 0.0437s/iter; left time: 559.4921s\n",
      "\titers: 900, epoch: 6 | loss: 0.0781589\n",
      "\tspeed: 0.0445s/iter; left time: 564.1290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.09s\n",
      "Steps: 906 | Train Loss: 0.0746976 Vali Loss: 0.1017625 Test Loss: 0.1222291\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741962\n",
      "\tspeed: 0.1046s/iter; left time: 1316.8960s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620469\n",
      "\tspeed: 0.0436s/iter; left time: 544.0424s\n",
      "\titers: 300, epoch: 7 | loss: 0.0721050\n",
      "\tspeed: 0.0400s/iter; left time: 495.6921s\n",
      "\titers: 400, epoch: 7 | loss: 0.0632480\n",
      "\tspeed: 0.0423s/iter; left time: 519.5903s\n",
      "\titers: 500, epoch: 7 | loss: 0.0664979\n",
      "\tspeed: 0.0421s/iter; left time: 512.6556s\n",
      "\titers: 600, epoch: 7 | loss: 0.0662618\n",
      "\tspeed: 0.0421s/iter; left time: 508.3690s\n",
      "\titers: 700, epoch: 7 | loss: 0.0720267\n",
      "\tspeed: 0.0419s/iter; left time: 501.8393s\n",
      "\titers: 800, epoch: 7 | loss: 0.0630545\n",
      "\tspeed: 0.0404s/iter; left time: 479.9848s\n",
      "\titers: 900, epoch: 7 | loss: 0.0800700\n",
      "\tspeed: 0.0434s/iter; left time: 511.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 906 | Train Loss: 0.0715346 Vali Loss: 0.0970577 Test Loss: 0.1188241\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696932\n",
      "\tspeed: 0.1051s/iter; left time: 1227.3248s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695751\n",
      "\tspeed: 0.0447s/iter; left time: 517.6313s\n",
      "\titers: 300, epoch: 8 | loss: 0.0621481\n",
      "\tspeed: 0.0428s/iter; left time: 491.1447s\n",
      "\titers: 400, epoch: 8 | loss: 0.0656600\n",
      "\tspeed: 0.0424s/iter; left time: 482.9614s\n",
      "\titers: 500, epoch: 8 | loss: 0.0610848\n",
      "\tspeed: 0.0409s/iter; left time: 461.1994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0668859\n",
      "\tspeed: 0.0404s/iter; left time: 452.0429s\n",
      "\titers: 700, epoch: 8 | loss: 0.0636075\n",
      "\tspeed: 0.0407s/iter; left time: 450.4026s\n",
      "\titers: 800, epoch: 8 | loss: 0.0669452\n",
      "\tspeed: 0.0405s/iter; left time: 444.3156s\n",
      "\titers: 900, epoch: 8 | loss: 0.0670184\n",
      "\tspeed: 0.0426s/iter; left time: 463.7058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 906 | Train Loss: 0.0684857 Vali Loss: 0.1010585 Test Loss: 0.1231407\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604522\n",
      "\tspeed: 0.1046s/iter; left time: 1126.7267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733324\n",
      "\tspeed: 0.0413s/iter; left time: 441.2302s\n",
      "\titers: 300, epoch: 9 | loss: 0.0743875\n",
      "\tspeed: 0.0402s/iter; left time: 424.8030s\n",
      "\titers: 400, epoch: 9 | loss: 0.0751797\n",
      "\tspeed: 0.0405s/iter; left time: 424.4039s\n",
      "\titers: 500, epoch: 9 | loss: 0.0547750\n",
      "\tspeed: 0.0409s/iter; left time: 423.8305s\n",
      "\titers: 600, epoch: 9 | loss: 0.0654884\n",
      "\tspeed: 0.0415s/iter; left time: 426.4317s\n",
      "\titers: 700, epoch: 9 | loss: 0.0635630\n",
      "\tspeed: 0.0409s/iter; left time: 416.3660s\n",
      "\titers: 800, epoch: 9 | loss: 0.0642100\n",
      "\tspeed: 0.0409s/iter; left time: 412.0046s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658764\n",
      "\tspeed: 0.0410s/iter; left time: 408.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.36s\n",
      "Steps: 906 | Train Loss: 0.0650878 Vali Loss: 0.0995909 Test Loss: 0.1241297\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591552\n",
      "\tspeed: 0.1033s/iter; left time: 1018.7953s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584013\n",
      "\tspeed: 0.0408s/iter; left time: 398.4046s\n",
      "\titers: 300, epoch: 10 | loss: 0.0595871\n",
      "\tspeed: 0.0398s/iter; left time: 384.3685s\n",
      "\titers: 400, epoch: 10 | loss: 0.0590385\n",
      "\tspeed: 0.0415s/iter; left time: 396.9675s\n",
      "\titers: 500, epoch: 10 | loss: 0.0603983\n",
      "\tspeed: 0.0430s/iter; left time: 407.0963s\n",
      "\titers: 600, epoch: 10 | loss: 0.0631428\n",
      "\tspeed: 0.0430s/iter; left time: 402.5342s\n",
      "\titers: 700, epoch: 10 | loss: 0.0578520\n",
      "\tspeed: 0.0446s/iter; left time: 413.6800s\n",
      "\titers: 800, epoch: 10 | loss: 0.0694408\n",
      "\tspeed: 0.0395s/iter; left time: 362.2236s\n",
      "\titers: 900, epoch: 10 | loss: 0.0650614\n",
      "\tspeed: 0.0397s/iter; left time: 360.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 906 | Train Loss: 0.0625472 Vali Loss: 0.1016852 Test Loss: 0.1267304\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029107721522450447, rmse:0.17060984671115875, mae:0.11423589289188385, rse:0.5882587432861328\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:17.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2255687\n",
      "\tspeed: 0.0760s/iter; left time: 1366.0204s\n",
      "\titers: 200, epoch: 1 | loss: 0.1969440\n",
      "\tspeed: 0.0470s/iter; left time: 840.5014s\n",
      "\titers: 300, epoch: 1 | loss: 0.1951265\n",
      "\tspeed: 0.0474s/iter; left time: 843.4782s\n",
      "\titers: 400, epoch: 1 | loss: 0.1910113\n",
      "\tspeed: 0.0477s/iter; left time: 843.7551s\n",
      "\titers: 500, epoch: 1 | loss: 0.1806086\n",
      "\tspeed: 0.0486s/iter; left time: 854.9877s\n",
      "\titers: 600, epoch: 1 | loss: 0.1724181\n",
      "\tspeed: 0.0467s/iter; left time: 816.8248s\n",
      "\titers: 700, epoch: 1 | loss: 0.1663875\n",
      "\tspeed: 0.0452s/iter; left time: 785.5107s\n",
      "\titers: 800, epoch: 1 | loss: 0.1705200\n",
      "\tspeed: 0.0464s/iter; left time: 802.5584s\n",
      "\titers: 900, epoch: 1 | loss: 0.1639884\n",
      "\tspeed: 0.0477s/iter; left time: 819.0618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.1898295 Vali Loss: 0.1726514 Test Loss: 0.2125144\n",
      "Validation loss decreased (inf --> 0.172651).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1466748\n",
      "\tspeed: 0.1232s/iter; left time: 2104.0705s\n",
      "\titers: 200, epoch: 2 | loss: 0.1372828\n",
      "\tspeed: 0.0454s/iter; left time: 770.4328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1329548\n",
      "\tspeed: 0.0464s/iter; left time: 783.2295s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341645\n",
      "\tspeed: 0.0491s/iter; left time: 823.2519s\n",
      "\titers: 500, epoch: 2 | loss: 0.1367194\n",
      "\tspeed: 0.0497s/iter; left time: 828.0430s\n",
      "\titers: 600, epoch: 2 | loss: 0.1326677\n",
      "\tspeed: 0.0496s/iter; left time: 821.6464s\n",
      "\titers: 700, epoch: 2 | loss: 0.1257785\n",
      "\tspeed: 0.0491s/iter; left time: 808.5336s\n",
      "\titers: 800, epoch: 2 | loss: 0.1244963\n",
      "\tspeed: 0.0449s/iter; left time: 734.5305s\n",
      "\titers: 900, epoch: 2 | loss: 0.1313370\n",
      "\tspeed: 0.0477s/iter; left time: 776.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 904 | Train Loss: 0.1353561 Vali Loss: 0.1446950 Test Loss: 0.1772607\n",
      "Validation loss decreased (0.172651 --> 0.144695).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1177422\n",
      "\tspeed: 0.1245s/iter; left time: 2014.1480s\n",
      "\titers: 200, epoch: 3 | loss: 0.1186227\n",
      "\tspeed: 0.0488s/iter; left time: 783.6847s\n",
      "\titers: 300, epoch: 3 | loss: 0.1157690\n",
      "\tspeed: 0.0471s/iter; left time: 752.5161s\n",
      "\titers: 400, epoch: 3 | loss: 0.1103611\n",
      "\tspeed: 0.0478s/iter; left time: 759.2433s\n",
      "\titers: 500, epoch: 3 | loss: 0.1088090\n",
      "\tspeed: 0.0490s/iter; left time: 772.1911s\n",
      "\titers: 600, epoch: 3 | loss: 0.1162299\n",
      "\tspeed: 0.0488s/iter; left time: 765.0206s\n",
      "\titers: 700, epoch: 3 | loss: 0.1067353\n",
      "\tspeed: 0.0495s/iter; left time: 770.6839s\n",
      "\titers: 800, epoch: 3 | loss: 0.1024203\n",
      "\tspeed: 0.0494s/iter; left time: 763.6034s\n",
      "\titers: 900, epoch: 3 | loss: 0.1095797\n",
      "\tspeed: 0.0477s/iter; left time: 733.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.16s\n",
      "Steps: 904 | Train Loss: 0.1113961 Vali Loss: 0.1269721 Test Loss: 0.1567219\n",
      "Validation loss decreased (0.144695 --> 0.126972).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1150751\n",
      "\tspeed: 0.1260s/iter; left time: 1923.2966s\n",
      "\titers: 200, epoch: 4 | loss: 0.1073310\n",
      "\tspeed: 0.0500s/iter; left time: 758.2552s\n",
      "\titers: 300, epoch: 4 | loss: 0.1104820\n",
      "\tspeed: 0.0475s/iter; left time: 715.5529s\n",
      "\titers: 400, epoch: 4 | loss: 0.1005932\n",
      "\tspeed: 0.0419s/iter; left time: 627.5319s\n",
      "\titers: 500, epoch: 4 | loss: 0.0951388\n",
      "\tspeed: 0.0499s/iter; left time: 741.4723s\n",
      "\titers: 600, epoch: 4 | loss: 0.0997509\n",
      "\tspeed: 0.0493s/iter; left time: 728.4661s\n",
      "\titers: 700, epoch: 4 | loss: 0.0984313\n",
      "\tspeed: 0.0497s/iter; left time: 728.9388s\n",
      "\titers: 800, epoch: 4 | loss: 0.1034888\n",
      "\tspeed: 0.0497s/iter; left time: 724.1530s\n",
      "\titers: 900, epoch: 4 | loss: 0.1050800\n",
      "\tspeed: 0.0439s/iter; left time: 635.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.62s\n",
      "Steps: 904 | Train Loss: 0.1017109 Vali Loss: 0.1283327 Test Loss: 0.1621235\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948988\n",
      "\tspeed: 0.1224s/iter; left time: 1758.2687s\n",
      "\titers: 200, epoch: 5 | loss: 0.0923659\n",
      "\tspeed: 0.0495s/iter; left time: 706.0892s\n",
      "\titers: 300, epoch: 5 | loss: 0.0939323\n",
      "\tspeed: 0.0491s/iter; left time: 694.9450s\n",
      "\titers: 400, epoch: 5 | loss: 0.1048447\n",
      "\tspeed: 0.0456s/iter; left time: 641.6971s\n",
      "\titers: 500, epoch: 5 | loss: 0.0898416\n",
      "\tspeed: 0.0493s/iter; left time: 689.1189s\n",
      "\titers: 600, epoch: 5 | loss: 0.1012730\n",
      "\tspeed: 0.0496s/iter; left time: 687.9547s\n",
      "\titers: 700, epoch: 5 | loss: 0.1037022\n",
      "\tspeed: 0.0499s/iter; left time: 686.8058s\n",
      "\titers: 800, epoch: 5 | loss: 0.1009622\n",
      "\tspeed: 0.0503s/iter; left time: 687.8192s\n",
      "\titers: 900, epoch: 5 | loss: 0.1010886\n",
      "\tspeed: 0.0499s/iter; left time: 676.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.70s\n",
      "Steps: 904 | Train Loss: 0.0953739 Vali Loss: 0.1267609 Test Loss: 0.1637363\n",
      "Validation loss decreased (0.126972 --> 0.126761).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918601\n",
      "\tspeed: 0.1237s/iter; left time: 1664.8794s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857725\n",
      "\tspeed: 0.0489s/iter; left time: 652.8306s\n",
      "\titers: 300, epoch: 6 | loss: 0.0888586\n",
      "\tspeed: 0.0502s/iter; left time: 666.1765s\n",
      "\titers: 400, epoch: 6 | loss: 0.0926645\n",
      "\tspeed: 0.0481s/iter; left time: 633.3903s\n",
      "\titers: 500, epoch: 6 | loss: 0.0844825\n",
      "\tspeed: 0.0465s/iter; left time: 607.8722s\n",
      "\titers: 600, epoch: 6 | loss: 0.0870649\n",
      "\tspeed: 0.0488s/iter; left time: 632.7013s\n",
      "\titers: 700, epoch: 6 | loss: 0.0815338\n",
      "\tspeed: 0.0499s/iter; left time: 641.7445s\n",
      "\titers: 800, epoch: 6 | loss: 0.0904821\n",
      "\tspeed: 0.0467s/iter; left time: 595.5603s\n",
      "\titers: 900, epoch: 6 | loss: 0.0895468\n",
      "\tspeed: 0.0503s/iter; left time: 636.2876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.17s\n",
      "Steps: 904 | Train Loss: 0.0891392 Vali Loss: 0.1326915 Test Loss: 0.1757692\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0813128\n",
      "\tspeed: 0.1216s/iter; left time: 1527.0185s\n",
      "\titers: 200, epoch: 7 | loss: 0.0833745\n",
      "\tspeed: 0.0498s/iter; left time: 619.8049s\n",
      "\titers: 300, epoch: 7 | loss: 0.0761775\n",
      "\tspeed: 0.0500s/iter; left time: 618.4654s\n",
      "\titers: 400, epoch: 7 | loss: 0.0891688\n",
      "\tspeed: 0.0497s/iter; left time: 608.6677s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869506\n",
      "\tspeed: 0.0468s/iter; left time: 568.7626s\n",
      "\titers: 600, epoch: 7 | loss: 0.0887999\n",
      "\tspeed: 0.0495s/iter; left time: 596.4220s\n",
      "\titers: 700, epoch: 7 | loss: 0.0896799\n",
      "\tspeed: 0.0494s/iter; left time: 590.2693s\n",
      "\titers: 800, epoch: 7 | loss: 0.0758964\n",
      "\tspeed: 0.0499s/iter; left time: 592.0330s\n",
      "\titers: 900, epoch: 7 | loss: 0.0829648\n",
      "\tspeed: 0.0497s/iter; left time: 584.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.84s\n",
      "Steps: 904 | Train Loss: 0.0835469 Vali Loss: 0.1329960 Test Loss: 0.1782949\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0797158\n",
      "\tspeed: 0.1201s/iter; left time: 1400.0702s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767336\n",
      "\tspeed: 0.0490s/iter; left time: 566.0544s\n",
      "\titers: 300, epoch: 8 | loss: 0.0795722\n",
      "\tspeed: 0.0498s/iter; left time: 570.3941s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774469\n",
      "\tspeed: 0.0491s/iter; left time: 557.0942s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814914\n",
      "\tspeed: 0.0472s/iter; left time: 531.0827s\n",
      "\titers: 600, epoch: 8 | loss: 0.0761013\n",
      "\tspeed: 0.0470s/iter; left time: 524.5450s\n",
      "\titers: 700, epoch: 8 | loss: 0.0786306\n",
      "\tspeed: 0.0420s/iter; left time: 464.6564s\n",
      "\titers: 800, epoch: 8 | loss: 0.0797036\n",
      "\tspeed: 0.0393s/iter; left time: 430.4928s\n",
      "\titers: 900, epoch: 8 | loss: 0.0819933\n",
      "\tspeed: 0.0393s/iter; left time: 426.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 904 | Train Loss: 0.0788386 Vali Loss: 0.1321585 Test Loss: 0.1784511\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0827697\n",
      "\tspeed: 0.1172s/iter; left time: 1260.1794s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719339\n",
      "\tspeed: 0.0492s/iter; left time: 523.6987s\n",
      "\titers: 300, epoch: 9 | loss: 0.0696444\n",
      "\tspeed: 0.0497s/iter; left time: 523.8967s\n",
      "\titers: 400, epoch: 9 | loss: 0.0856322\n",
      "\tspeed: 0.0502s/iter; left time: 524.6049s\n",
      "\titers: 500, epoch: 9 | loss: 0.0722203\n",
      "\tspeed: 0.0500s/iter; left time: 517.4286s\n",
      "\titers: 600, epoch: 9 | loss: 0.0815830\n",
      "\tspeed: 0.0482s/iter; left time: 493.8630s\n",
      "\titers: 700, epoch: 9 | loss: 0.0667963\n",
      "\tspeed: 0.0498s/iter; left time: 505.2123s\n",
      "\titers: 800, epoch: 9 | loss: 0.0706898\n",
      "\tspeed: 0.0500s/iter; left time: 502.6801s\n",
      "\titers: 900, epoch: 9 | loss: 0.0754192\n",
      "\tspeed: 0.0500s/iter; left time: 497.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 904 | Train Loss: 0.0747280 Vali Loss: 0.1316066 Test Loss: 0.1729603\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0694733\n",
      "\tspeed: 0.1183s/iter; left time: 1165.1138s\n",
      "\titers: 200, epoch: 10 | loss: 0.0695997\n",
      "\tspeed: 0.0495s/iter; left time: 482.0890s\n",
      "\titers: 300, epoch: 10 | loss: 0.0735394\n",
      "\tspeed: 0.0394s/iter; left time: 379.6764s\n",
      "\titers: 400, epoch: 10 | loss: 0.0671492\n",
      "\tspeed: 0.0393s/iter; left time: 375.2100s\n",
      "\titers: 500, epoch: 10 | loss: 0.0740291\n",
      "\tspeed: 0.0431s/iter; left time: 407.5482s\n",
      "\titers: 600, epoch: 10 | loss: 0.0708412\n",
      "\tspeed: 0.0500s/iter; left time: 467.2188s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724577\n",
      "\tspeed: 0.0493s/iter; left time: 455.6526s\n",
      "\titers: 800, epoch: 10 | loss: 0.0702263\n",
      "\tspeed: 0.0454s/iter; left time: 415.4378s\n",
      "\titers: 900, epoch: 10 | loss: 0.0671190\n",
      "\tspeed: 0.0392s/iter; left time: 354.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.60s\n",
      "Steps: 904 | Train Loss: 0.0708816 Vali Loss: 0.1308677 Test Loss: 0.1720753\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.057526689022779465, rmse:0.23984721302986145, mae:0.16363422572612762, rse:0.8294250965118408\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2361504\n",
      "\tspeed: 0.0498s/iter; left time: 895.9571s\n",
      "\titers: 200, epoch: 1 | loss: 0.2048126\n",
      "\tspeed: 0.0461s/iter; left time: 823.9144s\n",
      "\titers: 300, epoch: 1 | loss: 0.1914368\n",
      "\tspeed: 0.0502s/iter; left time: 893.4788s\n",
      "\titers: 400, epoch: 1 | loss: 0.1891696\n",
      "\tspeed: 0.0505s/iter; left time: 892.0573s\n",
      "\titers: 500, epoch: 1 | loss: 0.1742566\n",
      "\tspeed: 0.0491s/iter; left time: 863.8785s\n",
      "\titers: 600, epoch: 1 | loss: 0.1876671\n",
      "\tspeed: 0.0506s/iter; left time: 884.6296s\n",
      "\titers: 700, epoch: 1 | loss: 0.1831172\n",
      "\tspeed: 0.0490s/iter; left time: 851.7845s\n",
      "\titers: 800, epoch: 1 | loss: 0.1632556\n",
      "\tspeed: 0.0423s/iter; left time: 731.4180s\n",
      "\titers: 900, epoch: 1 | loss: 0.1665270\n",
      "\tspeed: 0.0406s/iter; left time: 696.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.1935472 Vali Loss: 0.1648111 Test Loss: 0.2020273\n",
      "Validation loss decreased (inf --> 0.164811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431796\n",
      "\tspeed: 0.1241s/iter; left time: 2118.5508s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429133\n",
      "\tspeed: 0.0474s/iter; left time: 804.9371s\n",
      "\titers: 300, epoch: 2 | loss: 0.1351413\n",
      "\tspeed: 0.0502s/iter; left time: 846.9771s\n",
      "\titers: 400, epoch: 2 | loss: 0.1290429\n",
      "\tspeed: 0.0500s/iter; left time: 839.2104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1320884\n",
      "\tspeed: 0.0489s/iter; left time: 814.8222s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265727\n",
      "\tspeed: 0.0496s/iter; left time: 822.6283s\n",
      "\titers: 700, epoch: 2 | loss: 0.1288902\n",
      "\tspeed: 0.0496s/iter; left time: 816.7460s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242642\n",
      "\tspeed: 0.0458s/iter; left time: 750.2946s\n",
      "\titers: 900, epoch: 2 | loss: 0.1087183\n",
      "\tspeed: 0.0488s/iter; left time: 794.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.43s\n",
      "Steps: 904 | Train Loss: 0.1333465 Vali Loss: 0.1431034 Test Loss: 0.1751640\n",
      "Validation loss decreased (0.164811 --> 0.143103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1197574\n",
      "\tspeed: 0.1241s/iter; left time: 2006.6691s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244095\n",
      "\tspeed: 0.0500s/iter; left time: 803.0443s\n",
      "\titers: 300, epoch: 3 | loss: 0.1182540\n",
      "\tspeed: 0.0483s/iter; left time: 770.7792s\n",
      "\titers: 400, epoch: 3 | loss: 0.1185170\n",
      "\tspeed: 0.0485s/iter; left time: 769.2513s\n",
      "\titers: 500, epoch: 3 | loss: 0.1217805\n",
      "\tspeed: 0.0464s/iter; left time: 731.8833s\n",
      "\titers: 600, epoch: 3 | loss: 0.1079377\n",
      "\tspeed: 0.0502s/iter; left time: 787.3178s\n",
      "\titers: 700, epoch: 3 | loss: 0.1133052\n",
      "\tspeed: 0.0506s/iter; left time: 787.3524s\n",
      "\titers: 800, epoch: 3 | loss: 0.1056479\n",
      "\tspeed: 0.0499s/iter; left time: 771.7006s\n",
      "\titers: 900, epoch: 3 | loss: 0.1042594\n",
      "\tspeed: 0.0498s/iter; left time: 765.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.64s\n",
      "Steps: 904 | Train Loss: 0.1136956 Vali Loss: 0.1303343 Test Loss: 0.1621740\n",
      "Validation loss decreased (0.143103 --> 0.130334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1131616\n",
      "\tspeed: 0.1244s/iter; left time: 1900.2076s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025617\n",
      "\tspeed: 0.0493s/iter; left time: 748.2143s\n",
      "\titers: 300, epoch: 4 | loss: 0.1044936\n",
      "\tspeed: 0.0464s/iter; left time: 699.4243s\n",
      "\titers: 400, epoch: 4 | loss: 0.1040315\n",
      "\tspeed: 0.0480s/iter; left time: 719.1333s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039687\n",
      "\tspeed: 0.0497s/iter; left time: 738.9866s\n",
      "\titers: 600, epoch: 4 | loss: 0.1011319\n",
      "\tspeed: 0.0505s/iter; left time: 745.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0994408\n",
      "\tspeed: 0.0499s/iter; left time: 731.8844s\n",
      "\titers: 800, epoch: 4 | loss: 0.1095860\n",
      "\tspeed: 0.0497s/iter; left time: 723.7528s\n",
      "\titers: 900, epoch: 4 | loss: 0.1097626\n",
      "\tspeed: 0.0484s/iter; left time: 699.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.52s\n",
      "Steps: 904 | Train Loss: 0.1034935 Vali Loss: 0.1326608 Test Loss: 0.1598699\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1011364\n",
      "\tspeed: 0.1215s/iter; left time: 1744.9263s\n",
      "\titers: 200, epoch: 5 | loss: 0.0990633\n",
      "\tspeed: 0.0502s/iter; left time: 716.2142s\n",
      "\titers: 300, epoch: 5 | loss: 0.0947605\n",
      "\tspeed: 0.0501s/iter; left time: 709.5710s\n",
      "\titers: 400, epoch: 5 | loss: 0.0896447\n",
      "\tspeed: 0.0462s/iter; left time: 649.6339s\n",
      "\titers: 500, epoch: 5 | loss: 0.0950052\n",
      "\tspeed: 0.0494s/iter; left time: 689.3587s\n",
      "\titers: 600, epoch: 5 | loss: 0.0931334\n",
      "\tspeed: 0.0480s/iter; left time: 665.7597s\n",
      "\titers: 700, epoch: 5 | loss: 0.1013913\n",
      "\tspeed: 0.0497s/iter; left time: 683.9799s\n",
      "\titers: 800, epoch: 5 | loss: 0.0912395\n",
      "\tspeed: 0.0503s/iter; left time: 686.8013s\n",
      "\titers: 900, epoch: 5 | loss: 0.1009830\n",
      "\tspeed: 0.0500s/iter; left time: 678.3845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 904 | Train Loss: 0.0965961 Vali Loss: 0.1320217 Test Loss: 0.1635417\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990747\n",
      "\tspeed: 0.1224s/iter; left time: 1648.1692s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899862\n",
      "\tspeed: 0.0504s/iter; left time: 673.0483s\n",
      "\titers: 300, epoch: 6 | loss: 0.0861572\n",
      "\tspeed: 0.0501s/iter; left time: 663.8115s\n",
      "\titers: 400, epoch: 6 | loss: 0.0965549\n",
      "\tspeed: 0.0490s/iter; left time: 644.8868s\n",
      "\titers: 500, epoch: 6 | loss: 0.0914424\n",
      "\tspeed: 0.0419s/iter; left time: 547.6008s\n",
      "\titers: 600, epoch: 6 | loss: 0.0866498\n",
      "\tspeed: 0.0394s/iter; left time: 510.1331s\n",
      "\titers: 700, epoch: 6 | loss: 0.0789218\n",
      "\tspeed: 0.0394s/iter; left time: 506.2884s\n",
      "\titers: 800, epoch: 6 | loss: 0.0881015\n",
      "\tspeed: 0.0394s/iter; left time: 503.1789s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933495\n",
      "\tspeed: 0.0394s/iter; left time: 498.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 904 | Train Loss: 0.0900866 Vali Loss: 0.1291286 Test Loss: 0.1623160\n",
      "Validation loss decreased (0.130334 --> 0.129129).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832615\n",
      "\tspeed: 0.1258s/iter; left time: 1579.4167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0875159\n",
      "\tspeed: 0.0500s/iter; left time: 622.3463s\n",
      "\titers: 300, epoch: 7 | loss: 0.0784433\n",
      "\tspeed: 0.0499s/iter; left time: 616.8860s\n",
      "\titers: 400, epoch: 7 | loss: 0.0793963\n",
      "\tspeed: 0.0499s/iter; left time: 612.1079s\n",
      "\titers: 500, epoch: 7 | loss: 0.0825817\n",
      "\tspeed: 0.0492s/iter; left time: 597.9757s\n",
      "\titers: 600, epoch: 7 | loss: 0.0923625\n",
      "\tspeed: 0.0479s/iter; left time: 577.8367s\n",
      "\titers: 700, epoch: 7 | loss: 0.0802216\n",
      "\tspeed: 0.0486s/iter; left time: 580.5910s\n",
      "\titers: 800, epoch: 7 | loss: 0.0863001\n",
      "\tspeed: 0.0476s/iter; left time: 563.8489s\n",
      "\titers: 900, epoch: 7 | loss: 0.0720519\n",
      "\tspeed: 0.0494s/iter; left time: 581.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.70s\n",
      "Steps: 904 | Train Loss: 0.0840416 Vali Loss: 0.1331552 Test Loss: 0.1622402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839713\n",
      "\tspeed: 0.1211s/iter; left time: 1411.4648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806477\n",
      "\tspeed: 0.0497s/iter; left time: 574.1412s\n",
      "\titers: 300, epoch: 8 | loss: 0.0809879\n",
      "\tspeed: 0.0502s/iter; left time: 574.9612s\n",
      "\titers: 400, epoch: 8 | loss: 0.0778002\n",
      "\tspeed: 0.0499s/iter; left time: 566.2249s\n",
      "\titers: 500, epoch: 8 | loss: 0.0738605\n",
      "\tspeed: 0.0489s/iter; left time: 549.8237s\n",
      "\titers: 600, epoch: 8 | loss: 0.0788250\n",
      "\tspeed: 0.0453s/iter; left time: 505.2189s\n",
      "\titers: 700, epoch: 8 | loss: 0.0782335\n",
      "\tspeed: 0.0481s/iter; left time: 531.3415s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746135\n",
      "\tspeed: 0.0502s/iter; left time: 550.1797s\n",
      "\titers: 900, epoch: 8 | loss: 0.0734857\n",
      "\tspeed: 0.0500s/iter; left time: 542.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.51s\n",
      "Steps: 904 | Train Loss: 0.0792389 Vali Loss: 0.1388449 Test Loss: 0.1700458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769500\n",
      "\tspeed: 0.1220s/iter; left time: 1311.1650s\n",
      "\titers: 200, epoch: 9 | loss: 0.0726015\n",
      "\tspeed: 0.0503s/iter; left time: 535.9565s\n",
      "\titers: 300, epoch: 9 | loss: 0.0833335\n",
      "\tspeed: 0.0488s/iter; left time: 514.8115s\n",
      "\titers: 400, epoch: 9 | loss: 0.0767504\n",
      "\tspeed: 0.0495s/iter; left time: 517.1847s\n",
      "\titers: 500, epoch: 9 | loss: 0.0797865\n",
      "\tspeed: 0.0502s/iter; left time: 519.9004s\n",
      "\titers: 600, epoch: 9 | loss: 0.0723531\n",
      "\tspeed: 0.0495s/iter; left time: 507.4686s\n",
      "\titers: 700, epoch: 9 | loss: 0.0742085\n",
      "\tspeed: 0.0470s/iter; left time: 476.5912s\n",
      "\titers: 800, epoch: 9 | loss: 0.0727802\n",
      "\tspeed: 0.0468s/iter; left time: 470.1330s\n",
      "\titers: 900, epoch: 9 | loss: 0.0761377\n",
      "\tspeed: 0.0499s/iter; left time: 496.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.61s\n",
      "Steps: 904 | Train Loss: 0.0747473 Vali Loss: 0.1365098 Test Loss: 0.1709515\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0697394\n",
      "\tspeed: 0.1220s/iter; left time: 1200.8540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0761079\n",
      "\tspeed: 0.0496s/iter; left time: 483.6980s\n",
      "\titers: 300, epoch: 10 | loss: 0.0721913\n",
      "\tspeed: 0.0496s/iter; left time: 478.8330s\n",
      "\titers: 400, epoch: 10 | loss: 0.0689166\n",
      "\tspeed: 0.0489s/iter; left time: 466.3007s\n",
      "\titers: 500, epoch: 10 | loss: 0.0677448\n",
      "\tspeed: 0.0491s/iter; left time: 463.5784s\n",
      "\titers: 600, epoch: 10 | loss: 0.0659904\n",
      "\tspeed: 0.0505s/iter; left time: 472.2652s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724253\n",
      "\tspeed: 0.0503s/iter; left time: 465.3886s\n",
      "\titers: 800, epoch: 10 | loss: 0.0667000\n",
      "\tspeed: 0.0503s/iter; left time: 459.9471s\n",
      "\titers: 900, epoch: 10 | loss: 0.0637502\n",
      "\tspeed: 0.0494s/iter; left time: 447.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.17s\n",
      "Steps: 904 | Train Loss: 0.0710539 Vali Loss: 0.1381611 Test Loss: 0.1748331\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0691393\n",
      "\tspeed: 0.1195s/iter; left time: 1068.0460s\n",
      "\titers: 200, epoch: 11 | loss: 0.0713970\n",
      "\tspeed: 0.0463s/iter; left time: 409.7231s\n",
      "\titers: 300, epoch: 11 | loss: 0.0708896\n",
      "\tspeed: 0.0487s/iter; left time: 426.0248s\n",
      "\titers: 400, epoch: 11 | loss: 0.0681953\n",
      "\tspeed: 0.0493s/iter; left time: 425.5716s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624288\n",
      "\tspeed: 0.0454s/iter; left time: 388.1189s\n",
      "\titers: 600, epoch: 11 | loss: 0.0698107\n",
      "\tspeed: 0.0479s/iter; left time: 403.9841s\n",
      "\titers: 700, epoch: 11 | loss: 0.0659833\n",
      "\tspeed: 0.0501s/iter; left time: 417.5273s\n",
      "\titers: 800, epoch: 11 | loss: 0.0641235\n",
      "\tspeed: 0.0495s/iter; left time: 407.5696s\n",
      "\titers: 900, epoch: 11 | loss: 0.0661707\n",
      "\tspeed: 0.0470s/iter; left time: 382.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.51s\n",
      "Steps: 904 | Train Loss: 0.0677608 Vali Loss: 0.1354970 Test Loss: 0.1686172\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0539480485022068, rmse:0.23226718604564667, mae:0.1623077541589737, rse:0.8032123446464539\n",
      "Intermediate time for GB and pred_len 96: 00h:18m:03.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2130859\n",
      "\tspeed: 0.0801s/iter; left time: 1437.9426s\n",
      "\titers: 200, epoch: 1 | loss: 0.2044703\n",
      "\tspeed: 0.0520s/iter; left time: 928.4471s\n",
      "\titers: 300, epoch: 1 | loss: 0.1846589\n",
      "\tspeed: 0.0526s/iter; left time: 934.0526s\n",
      "\titers: 400, epoch: 1 | loss: 0.1825477\n",
      "\tspeed: 0.0509s/iter; left time: 898.1736s\n",
      "\titers: 500, epoch: 1 | loss: 0.1851541\n",
      "\tspeed: 0.0505s/iter; left time: 885.0862s\n",
      "\titers: 600, epoch: 1 | loss: 0.1808470\n",
      "\tspeed: 0.0508s/iter; left time: 886.7237s\n",
      "\titers: 700, epoch: 1 | loss: 0.1705929\n",
      "\tspeed: 0.0511s/iter; left time: 885.9569s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668541\n",
      "\tspeed: 0.0536s/iter; left time: 923.3948s\n",
      "\titers: 900, epoch: 1 | loss: 0.1636396\n",
      "\tspeed: 0.0521s/iter; left time: 892.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.1903320 Vali Loss: 0.1756451 Test Loss: 0.2138607\n",
      "Validation loss decreased (inf --> 0.175645).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1547550\n",
      "\tspeed: 0.1444s/iter; left time: 2460.4023s\n",
      "\titers: 200, epoch: 2 | loss: 0.1449682\n",
      "\tspeed: 0.0527s/iter; left time: 891.8606s\n",
      "\titers: 300, epoch: 2 | loss: 0.1423143\n",
      "\tspeed: 0.0530s/iter; left time: 892.0081s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334532\n",
      "\tspeed: 0.0510s/iter; left time: 852.9795s\n",
      "\titers: 500, epoch: 2 | loss: 0.1304843\n",
      "\tspeed: 0.0495s/iter; left time: 824.2904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1366739\n",
      "\tspeed: 0.0501s/iter; left time: 828.2109s\n",
      "\titers: 700, epoch: 2 | loss: 0.1369409\n",
      "\tspeed: 0.0528s/iter; left time: 868.6764s\n",
      "\titers: 800, epoch: 2 | loss: 0.1349143\n",
      "\tspeed: 0.0544s/iter; left time: 889.0884s\n",
      "\titers: 900, epoch: 2 | loss: 0.1402102\n",
      "\tspeed: 0.0524s/iter; left time: 851.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.22s\n",
      "Steps: 902 | Train Loss: 0.1414546 Vali Loss: 0.1560951 Test Loss: 0.1947084\n",
      "Validation loss decreased (0.175645 --> 0.156095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1330463\n",
      "\tspeed: 0.1432s/iter; left time: 2310.8407s\n",
      "\titers: 200, epoch: 3 | loss: 0.1262971\n",
      "\tspeed: 0.0532s/iter; left time: 853.7685s\n",
      "\titers: 300, epoch: 3 | loss: 0.1371024\n",
      "\tspeed: 0.0530s/iter; left time: 844.4728s\n",
      "\titers: 400, epoch: 3 | loss: 0.1289511\n",
      "\tspeed: 0.0515s/iter; left time: 815.3481s\n",
      "\titers: 500, epoch: 3 | loss: 0.1287059\n",
      "\tspeed: 0.0514s/iter; left time: 808.8543s\n",
      "\titers: 600, epoch: 3 | loss: 0.1410395\n",
      "\tspeed: 0.0507s/iter; left time: 793.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.1244261\n",
      "\tspeed: 0.0509s/iter; left time: 791.0376s\n",
      "\titers: 800, epoch: 3 | loss: 0.1227208\n",
      "\tspeed: 0.0528s/iter; left time: 815.8293s\n",
      "\titers: 900, epoch: 3 | loss: 0.1195739\n",
      "\tspeed: 0.0517s/iter; left time: 792.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.1292438 Vali Loss: 0.1511649 Test Loss: 0.1915466\n",
      "Validation loss decreased (0.156095 --> 0.151165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1260634\n",
      "\tspeed: 0.1443s/iter; left time: 2198.7220s\n",
      "\titers: 200, epoch: 4 | loss: 0.1137747\n",
      "\tspeed: 0.0531s/iter; left time: 804.1276s\n",
      "\titers: 300, epoch: 4 | loss: 0.1182747\n",
      "\tspeed: 0.0526s/iter; left time: 791.5067s\n",
      "\titers: 400, epoch: 4 | loss: 0.1119198\n",
      "\tspeed: 0.0506s/iter; left time: 755.7425s\n",
      "\titers: 500, epoch: 4 | loss: 0.1041145\n",
      "\tspeed: 0.0526s/iter; left time: 779.9608s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054148\n",
      "\tspeed: 0.0526s/iter; left time: 775.5622s\n",
      "\titers: 700, epoch: 4 | loss: 0.1080971\n",
      "\tspeed: 0.0532s/iter; left time: 778.4536s\n",
      "\titers: 800, epoch: 4 | loss: 0.1017381\n",
      "\tspeed: 0.0557s/iter; left time: 809.0875s\n",
      "\titers: 900, epoch: 4 | loss: 0.0959649\n",
      "\tspeed: 0.0512s/iter; left time: 738.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.74s\n",
      "Steps: 902 | Train Loss: 0.1106928 Vali Loss: 0.1285962 Test Loss: 0.1634130\n",
      "Validation loss decreased (0.151165 --> 0.128596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0952113\n",
      "\tspeed: 0.1457s/iter; left time: 2088.5928s\n",
      "\titers: 200, epoch: 5 | loss: 0.1024759\n",
      "\tspeed: 0.0550s/iter; left time: 782.2679s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958942\n",
      "\tspeed: 0.0531s/iter; left time: 750.0315s\n",
      "\titers: 400, epoch: 5 | loss: 0.0972925\n",
      "\tspeed: 0.0511s/iter; left time: 716.4114s\n",
      "\titers: 500, epoch: 5 | loss: 0.0980621\n",
      "\tspeed: 0.0505s/iter; left time: 703.1414s\n",
      "\titers: 600, epoch: 5 | loss: 0.0946259\n",
      "\tspeed: 0.0513s/iter; left time: 708.9646s\n",
      "\titers: 700, epoch: 5 | loss: 0.0907413\n",
      "\tspeed: 0.0517s/iter; left time: 710.3315s\n",
      "\titers: 800, epoch: 5 | loss: 0.1015313\n",
      "\tspeed: 0.0533s/iter; left time: 727.1556s\n",
      "\titers: 900, epoch: 5 | loss: 0.0984497\n",
      "\tspeed: 0.0519s/iter; left time: 702.5039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.0976338 Vali Loss: 0.1314606 Test Loss: 0.1745053\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0966667\n",
      "\tspeed: 0.1382s/iter; left time: 1856.1035s\n",
      "\titers: 200, epoch: 6 | loss: 0.0976619\n",
      "\tspeed: 0.0517s/iter; left time: 688.6140s\n",
      "\titers: 300, epoch: 6 | loss: 0.0869687\n",
      "\tspeed: 0.0526s/iter; left time: 696.2543s\n",
      "\titers: 400, epoch: 6 | loss: 0.0888621\n",
      "\tspeed: 0.0532s/iter; left time: 698.1760s\n",
      "\titers: 500, epoch: 6 | loss: 0.0968440\n",
      "\tspeed: 0.0504s/iter; left time: 657.1023s\n",
      "\titers: 600, epoch: 6 | loss: 0.0900905\n",
      "\tspeed: 0.0521s/iter; left time: 673.8527s\n",
      "\titers: 700, epoch: 6 | loss: 0.0819179\n",
      "\tspeed: 0.0530s/iter; left time: 680.2167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0874333\n",
      "\tspeed: 0.0541s/iter; left time: 689.0741s\n",
      "\titers: 900, epoch: 6 | loss: 0.0866565\n",
      "\tspeed: 0.0519s/iter; left time: 655.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.0908995 Vali Loss: 0.1360142 Test Loss: 0.1832639\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927695\n",
      "\tspeed: 0.1442s/iter; left time: 1806.6140s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865635\n",
      "\tspeed: 0.0528s/iter; left time: 656.2294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0894563\n",
      "\tspeed: 0.0539s/iter; left time: 664.3774s\n",
      "\titers: 400, epoch: 7 | loss: 0.0827512\n",
      "\tspeed: 0.0519s/iter; left time: 635.2403s\n",
      "\titers: 500, epoch: 7 | loss: 0.0833580\n",
      "\tspeed: 0.0529s/iter; left time: 641.5303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0800363\n",
      "\tspeed: 0.0505s/iter; left time: 607.8582s\n",
      "\titers: 700, epoch: 7 | loss: 0.0868889\n",
      "\tspeed: 0.0513s/iter; left time: 611.4840s\n",
      "\titers: 800, epoch: 7 | loss: 0.0773531\n",
      "\tspeed: 0.0539s/iter; left time: 637.3197s\n",
      "\titers: 900, epoch: 7 | loss: 0.0926475\n",
      "\tspeed: 0.0531s/iter; left time: 622.9517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 902 | Train Loss: 0.0848858 Vali Loss: 0.1352109 Test Loss: 0.1852673\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0755614\n",
      "\tspeed: 0.1423s/iter; left time: 1654.1070s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805938\n",
      "\tspeed: 0.0541s/iter; left time: 623.5909s\n",
      "\titers: 300, epoch: 8 | loss: 0.0836685\n",
      "\tspeed: 0.0548s/iter; left time: 626.1680s\n",
      "\titers: 400, epoch: 8 | loss: 0.0779296\n",
      "\tspeed: 0.0528s/iter; left time: 597.7990s\n",
      "\titers: 500, epoch: 8 | loss: 0.0806055\n",
      "\tspeed: 0.0535s/iter; left time: 601.0736s\n",
      "\titers: 600, epoch: 8 | loss: 0.0807745\n",
      "\tspeed: 0.0514s/iter; left time: 572.0249s\n",
      "\titers: 700, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0503s/iter; left time: 555.0761s\n",
      "\titers: 800, epoch: 8 | loss: 0.0767200\n",
      "\tspeed: 0.0523s/iter; left time: 570.9957s\n",
      "\titers: 900, epoch: 8 | loss: 0.0766900\n",
      "\tspeed: 0.0525s/iter; left time: 568.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0802573 Vali Loss: 0.1368492 Test Loss: 0.1828096\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0760837\n",
      "\tspeed: 0.1425s/iter; left time: 1528.2360s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796131\n",
      "\tspeed: 0.0511s/iter; left time: 542.4394s\n",
      "\titers: 300, epoch: 9 | loss: 0.0798605\n",
      "\tspeed: 0.0527s/iter; left time: 554.6883s\n",
      "\titers: 400, epoch: 9 | loss: 0.0712618\n",
      "\tspeed: 0.0515s/iter; left time: 537.1907s\n",
      "\titers: 500, epoch: 9 | loss: 0.0777337\n",
      "\tspeed: 0.0522s/iter; left time: 539.3689s\n",
      "\titers: 600, epoch: 9 | loss: 0.0738964\n",
      "\tspeed: 0.0515s/iter; left time: 526.6045s\n",
      "\titers: 700, epoch: 9 | loss: 0.0785224\n",
      "\tspeed: 0.0516s/iter; left time: 522.3886s\n",
      "\titers: 800, epoch: 9 | loss: 0.0810030\n",
      "\tspeed: 0.0523s/iter; left time: 524.7185s\n",
      "\titers: 900, epoch: 9 | loss: 0.0730407\n",
      "\tspeed: 0.0526s/iter; left time: 521.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 902 | Train Loss: 0.0763414 Vali Loss: 0.1352318 Test Loss: 0.1789316\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05394035950303078, rmse:0.2322506457567215, mae:0.1633959710597992, rse:0.8051829934120178\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2134379\n",
      "\tspeed: 0.0546s/iter; left time: 980.1405s\n",
      "\titers: 200, epoch: 1 | loss: 0.1971535\n",
      "\tspeed: 0.0527s/iter; left time: 940.0564s\n",
      "\titers: 300, epoch: 1 | loss: 0.1917784\n",
      "\tspeed: 0.0512s/iter; left time: 908.9878s\n",
      "\titers: 400, epoch: 1 | loss: 0.1900738\n",
      "\tspeed: 0.0514s/iter; left time: 906.8844s\n",
      "\titers: 500, epoch: 1 | loss: 0.1847131\n",
      "\tspeed: 0.0529s/iter; left time: 928.6681s\n",
      "\titers: 600, epoch: 1 | loss: 0.1781364\n",
      "\tspeed: 0.0521s/iter; left time: 908.0999s\n",
      "\titers: 700, epoch: 1 | loss: 0.1814755\n",
      "\tspeed: 0.0552s/iter; left time: 957.7139s\n",
      "\titers: 800, epoch: 1 | loss: 0.1737877\n",
      "\tspeed: 0.0519s/iter; left time: 894.5888s\n",
      "\titers: 900, epoch: 1 | loss: 0.1653976\n",
      "\tspeed: 0.0524s/iter; left time: 898.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.63s\n",
      "Steps: 902 | Train Loss: 0.1889060 Vali Loss: 0.1745365 Test Loss: 0.2131111\n",
      "Validation loss decreased (inf --> 0.174537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1515991\n",
      "\tspeed: 0.1439s/iter; left time: 2452.6231s\n",
      "\titers: 200, epoch: 2 | loss: 0.1437050\n",
      "\tspeed: 0.0534s/iter; left time: 904.9235s\n",
      "\titers: 300, epoch: 2 | loss: 0.1358945\n",
      "\tspeed: 0.0518s/iter; left time: 871.8788s\n",
      "\titers: 400, epoch: 2 | loss: 0.1331195\n",
      "\tspeed: 0.0515s/iter; left time: 861.6693s\n",
      "\titers: 500, epoch: 2 | loss: 0.1422927\n",
      "\tspeed: 0.0517s/iter; left time: 860.2230s\n",
      "\titers: 600, epoch: 2 | loss: 0.1329440\n",
      "\tspeed: 0.0531s/iter; left time: 878.1795s\n",
      "\titers: 700, epoch: 2 | loss: 0.1398292\n",
      "\tspeed: 0.0526s/iter; left time: 865.2574s\n",
      "\titers: 800, epoch: 2 | loss: 0.1418460\n",
      "\tspeed: 0.0518s/iter; left time: 845.8023s\n",
      "\titers: 900, epoch: 2 | loss: 0.1426569\n",
      "\tspeed: 0.0515s/iter; left time: 836.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.1400078 Vali Loss: 0.1543211 Test Loss: 0.1984515\n",
      "Validation loss decreased (0.174537 --> 0.154321).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1326267\n",
      "\tspeed: 0.1486s/iter; left time: 2397.9671s\n",
      "\titers: 200, epoch: 3 | loss: 0.1332973\n",
      "\tspeed: 0.0537s/iter; left time: 860.7941s\n",
      "\titers: 300, epoch: 3 | loss: 0.1251836\n",
      "\tspeed: 0.0516s/iter; left time: 821.8738s\n",
      "\titers: 400, epoch: 3 | loss: 0.1309564\n",
      "\tspeed: 0.0518s/iter; left time: 820.7354s\n",
      "\titers: 500, epoch: 3 | loss: 0.1188614\n",
      "\tspeed: 0.0529s/iter; left time: 832.2934s\n",
      "\titers: 600, epoch: 3 | loss: 0.1249987\n",
      "\tspeed: 0.0535s/iter; left time: 836.6307s\n",
      "\titers: 700, epoch: 3 | loss: 0.1272221\n",
      "\tspeed: 0.0503s/iter; left time: 780.8602s\n",
      "\titers: 800, epoch: 3 | loss: 0.1237295\n",
      "\tspeed: 0.0508s/iter; left time: 784.1184s\n",
      "\titers: 900, epoch: 3 | loss: 0.1169028\n",
      "\tspeed: 0.0511s/iter; left time: 783.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.59s\n",
      "Steps: 902 | Train Loss: 0.1270497 Vali Loss: 0.1489277 Test Loss: 0.1829660\n",
      "Validation loss decreased (0.154321 --> 0.148928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1184739\n",
      "\tspeed: 0.1450s/iter; left time: 2209.5418s\n",
      "\titers: 200, epoch: 4 | loss: 0.1167085\n",
      "\tspeed: 0.0522s/iter; left time: 789.6788s\n",
      "\titers: 300, epoch: 4 | loss: 0.1232799\n",
      "\tspeed: 0.0517s/iter; left time: 777.2280s\n",
      "\titers: 400, epoch: 4 | loss: 0.1110598\n",
      "\tspeed: 0.0509s/iter; left time: 759.5673s\n",
      "\titers: 500, epoch: 4 | loss: 0.1131461\n",
      "\tspeed: 0.0519s/iter; left time: 769.6613s\n",
      "\titers: 600, epoch: 4 | loss: 0.1031046\n",
      "\tspeed: 0.0548s/iter; left time: 808.0670s\n",
      "\titers: 700, epoch: 4 | loss: 0.1132229\n",
      "\tspeed: 0.0516s/iter; left time: 755.0190s\n",
      "\titers: 800, epoch: 4 | loss: 0.1058731\n",
      "\tspeed: 0.0514s/iter; left time: 746.6952s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973919\n",
      "\tspeed: 0.0518s/iter; left time: 748.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.1107167 Vali Loss: 0.1337407 Test Loss: 0.1688370\n",
      "Validation loss decreased (0.148928 --> 0.133741).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0961302\n",
      "\tspeed: 0.1466s/iter; left time: 2101.8889s\n",
      "\titers: 200, epoch: 5 | loss: 0.1058981\n",
      "\tspeed: 0.0514s/iter; left time: 731.8937s\n",
      "\titers: 300, epoch: 5 | loss: 0.1043737\n",
      "\tspeed: 0.0524s/iter; left time: 740.5619s\n",
      "\titers: 400, epoch: 5 | loss: 0.1017848\n",
      "\tspeed: 0.0523s/iter; left time: 734.0867s\n",
      "\titers: 500, epoch: 5 | loss: 0.0923788\n",
      "\tspeed: 0.0538s/iter; left time: 749.2453s\n",
      "\titers: 600, epoch: 5 | loss: 0.1001138\n",
      "\tspeed: 0.0535s/iter; left time: 740.2166s\n",
      "\titers: 700, epoch: 5 | loss: 0.0901133\n",
      "\tspeed: 0.0512s/iter; left time: 703.3624s\n",
      "\titers: 800, epoch: 5 | loss: 0.0911202\n",
      "\tspeed: 0.0514s/iter; left time: 701.3377s\n",
      "\titers: 900, epoch: 5 | loss: 0.0951924\n",
      "\tspeed: 0.0517s/iter; left time: 699.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.0978547 Vali Loss: 0.1347397 Test Loss: 0.1750676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916292\n",
      "\tspeed: 0.1457s/iter; left time: 1956.8987s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926998\n",
      "\tspeed: 0.0522s/iter; left time: 695.8473s\n",
      "\titers: 300, epoch: 6 | loss: 0.0945397\n",
      "\tspeed: 0.0524s/iter; left time: 693.5252s\n",
      "\titers: 400, epoch: 6 | loss: 0.0976250\n",
      "\tspeed: 0.0514s/iter; left time: 674.3577s\n",
      "\titers: 500, epoch: 6 | loss: 0.0917374\n",
      "\tspeed: 0.0538s/iter; left time: 701.1080s\n",
      "\titers: 600, epoch: 6 | loss: 0.0943440\n",
      "\tspeed: 0.0524s/iter; left time: 677.6103s\n",
      "\titers: 700, epoch: 6 | loss: 0.0875346\n",
      "\tspeed: 0.0520s/iter; left time: 667.8072s\n",
      "\titers: 800, epoch: 6 | loss: 0.0911442\n",
      "\tspeed: 0.0513s/iter; left time: 652.8994s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831802\n",
      "\tspeed: 0.0508s/iter; left time: 641.1983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.34s\n",
      "Steps: 902 | Train Loss: 0.0912941 Vali Loss: 0.1359846 Test Loss: 0.1837453\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0986938\n",
      "\tspeed: 0.1442s/iter; left time: 1807.2877s\n",
      "\titers: 200, epoch: 7 | loss: 0.0869653\n",
      "\tspeed: 0.0535s/iter; left time: 664.7790s\n",
      "\titers: 300, epoch: 7 | loss: 0.0861455\n",
      "\tspeed: 0.0514s/iter; left time: 633.2277s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878249\n",
      "\tspeed: 0.0509s/iter; left time: 622.1452s\n",
      "\titers: 500, epoch: 7 | loss: 0.0846415\n",
      "\tspeed: 0.0542s/iter; left time: 656.9875s\n",
      "\titers: 600, epoch: 7 | loss: 0.0866977\n",
      "\tspeed: 0.0527s/iter; left time: 634.2609s\n",
      "\titers: 700, epoch: 7 | loss: 0.0845247\n",
      "\tspeed: 0.0520s/iter; left time: 620.5286s\n",
      "\titers: 800, epoch: 7 | loss: 0.0829732\n",
      "\tspeed: 0.0514s/iter; left time: 607.7360s\n",
      "\titers: 900, epoch: 7 | loss: 0.0763239\n",
      "\tspeed: 0.0524s/iter; left time: 614.7106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.0856306 Vali Loss: 0.1405071 Test Loss: 0.1843889\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805372\n",
      "\tspeed: 0.1447s/iter; left time: 1682.0709s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753312\n",
      "\tspeed: 0.0508s/iter; left time: 586.1102s\n",
      "\titers: 300, epoch: 8 | loss: 0.0841432\n",
      "\tspeed: 0.0520s/iter; left time: 594.2269s\n",
      "\titers: 400, epoch: 8 | loss: 0.0836814\n",
      "\tspeed: 0.0528s/iter; left time: 597.5900s\n",
      "\titers: 500, epoch: 8 | loss: 0.0760510\n",
      "\tspeed: 0.0547s/iter; left time: 614.1696s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825711\n",
      "\tspeed: 0.0522s/iter; left time: 580.4889s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778928\n",
      "\tspeed: 0.0532s/iter; left time: 586.9057s\n",
      "\titers: 800, epoch: 8 | loss: 0.0787227\n",
      "\tspeed: 0.0529s/iter; left time: 577.7233s\n",
      "\titers: 900, epoch: 8 | loss: 0.0812062\n",
      "\tspeed: 0.0520s/iter; left time: 563.0336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.72s\n",
      "Steps: 902 | Train Loss: 0.0805182 Vali Loss: 0.1401425 Test Loss: 0.1808053\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0783460\n",
      "\tspeed: 0.1457s/iter; left time: 1562.9836s\n",
      "\titers: 200, epoch: 9 | loss: 0.0771335\n",
      "\tspeed: 0.0519s/iter; left time: 551.4203s\n",
      "\titers: 300, epoch: 9 | loss: 0.0708805\n",
      "\tspeed: 0.0522s/iter; left time: 549.4704s\n",
      "\titers: 400, epoch: 9 | loss: 0.0755136\n",
      "\tspeed: 0.0517s/iter; left time: 538.7829s\n",
      "\titers: 500, epoch: 9 | loss: 0.0766300\n",
      "\tspeed: 0.0525s/iter; left time: 542.4813s\n",
      "\titers: 600, epoch: 9 | loss: 0.0769121\n",
      "\tspeed: 0.0524s/iter; left time: 535.4238s\n",
      "\titers: 700, epoch: 9 | loss: 0.0734445\n",
      "\tspeed: 0.0515s/iter; left time: 521.3565s\n",
      "\titers: 800, epoch: 9 | loss: 0.0742932\n",
      "\tspeed: 0.0528s/iter; left time: 529.1895s\n",
      "\titers: 900, epoch: 9 | loss: 0.0711582\n",
      "\tspeed: 0.0516s/iter; left time: 511.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.0761055 Vali Loss: 0.1382257 Test Loss: 0.1815997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.060001105070114136, rmse:0.24495123326778412, mae:0.1687474101781845, rse:0.8492143154144287\n",
      "Intermediate time for GB and pred_len 168: 00h:17m:13.10s\n",
      "Intermediate time for GB: 00h:49m:34.57s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2225701\n",
      "\tspeed: 0.0727s/iter; left time: 1310.9185s\n",
      "\titers: 200, epoch: 1 | loss: 0.2311551\n",
      "\tspeed: 0.0439s/iter; left time: 786.6421s\n",
      "\titers: 300, epoch: 1 | loss: 0.1908760\n",
      "\tspeed: 0.0430s/iter; left time: 765.7375s\n",
      "\titers: 400, epoch: 1 | loss: 0.1898048\n",
      "\tspeed: 0.0438s/iter; left time: 776.0223s\n",
      "\titers: 500, epoch: 1 | loss: 0.1737094\n",
      "\tspeed: 0.0443s/iter; left time: 779.9809s\n",
      "\titers: 600, epoch: 1 | loss: 0.1705023\n",
      "\tspeed: 0.0436s/iter; left time: 764.7088s\n",
      "\titers: 700, epoch: 1 | loss: 0.1603696\n",
      "\tspeed: 0.0446s/iter; left time: 777.7191s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485734\n",
      "\tspeed: 0.0437s/iter; left time: 756.6431s\n",
      "\titers: 900, epoch: 1 | loss: 0.1428652\n",
      "\tspeed: 0.0332s/iter; left time: 571.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.38s\n",
      "Steps: 906 | Train Loss: 0.1848827 Vali Loss: 0.1115890 Test Loss: 0.1317366\n",
      "Validation loss decreased (inf --> 0.111589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1037941\n",
      "\tspeed: 0.1152s/iter; left time: 1971.9039s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033034\n",
      "\tspeed: 0.0438s/iter; left time: 745.8017s\n",
      "\titers: 300, epoch: 2 | loss: 0.0906658\n",
      "\tspeed: 0.0445s/iter; left time: 751.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.0915393\n",
      "\tspeed: 0.0437s/iter; left time: 735.1874s\n",
      "\titers: 500, epoch: 2 | loss: 0.0821387\n",
      "\tspeed: 0.0404s/iter; left time: 676.1150s\n",
      "\titers: 600, epoch: 2 | loss: 0.0891824\n",
      "\tspeed: 0.0419s/iter; left time: 696.6666s\n",
      "\titers: 700, epoch: 2 | loss: 0.0815542\n",
      "\tspeed: 0.0436s/iter; left time: 720.7095s\n",
      "\titers: 800, epoch: 2 | loss: 0.0823997\n",
      "\tspeed: 0.0445s/iter; left time: 730.3242s\n",
      "\titers: 900, epoch: 2 | loss: 0.0749999\n",
      "\tspeed: 0.0444s/iter; left time: 724.8776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 906 | Train Loss: 0.0931591 Vali Loss: 0.0782987 Test Loss: 0.1036240\n",
      "Validation loss decreased (0.111589 --> 0.078299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846602\n",
      "\tspeed: 0.1074s/iter; left time: 1740.3452s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805954\n",
      "\tspeed: 0.0402s/iter; left time: 647.2998s\n",
      "\titers: 300, epoch: 3 | loss: 0.0780625\n",
      "\tspeed: 0.0367s/iter; left time: 587.7092s\n",
      "\titers: 400, epoch: 3 | loss: 0.0678523\n",
      "\tspeed: 0.0447s/iter; left time: 711.1884s\n",
      "\titers: 500, epoch: 3 | loss: 0.0754667\n",
      "\tspeed: 0.0446s/iter; left time: 705.7935s\n",
      "\titers: 600, epoch: 3 | loss: 0.0654097\n",
      "\tspeed: 0.0436s/iter; left time: 684.1337s\n",
      "\titers: 700, epoch: 3 | loss: 0.0704309\n",
      "\tspeed: 0.0427s/iter; left time: 666.1056s\n",
      "\titers: 800, epoch: 3 | loss: 0.0754049\n",
      "\tspeed: 0.0441s/iter; left time: 684.0873s\n",
      "\titers: 900, epoch: 3 | loss: 0.0711015\n",
      "\tspeed: 0.0414s/iter; left time: 638.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 906 | Train Loss: 0.0721747 Vali Loss: 0.0701697 Test Loss: 0.0977866\n",
      "Validation loss decreased (0.078299 --> 0.070170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676409\n",
      "\tspeed: 0.1091s/iter; left time: 1670.0650s\n",
      "\titers: 200, epoch: 4 | loss: 0.0728024\n",
      "\tspeed: 0.0423s/iter; left time: 643.2116s\n",
      "\titers: 300, epoch: 4 | loss: 0.0679015\n",
      "\tspeed: 0.0448s/iter; left time: 676.8852s\n",
      "\titers: 400, epoch: 4 | loss: 0.0694085\n",
      "\tspeed: 0.0426s/iter; left time: 638.4820s\n",
      "\titers: 500, epoch: 4 | loss: 0.0613866\n",
      "\tspeed: 0.0415s/iter; left time: 618.9653s\n",
      "\titers: 600, epoch: 4 | loss: 0.0619529\n",
      "\tspeed: 0.0421s/iter; left time: 623.3358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0728609\n",
      "\tspeed: 0.0424s/iter; left time: 623.2545s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630194\n",
      "\tspeed: 0.0436s/iter; left time: 636.1329s\n",
      "\titers: 900, epoch: 4 | loss: 0.0703440\n",
      "\tspeed: 0.0443s/iter; left time: 642.0026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.26s\n",
      "Steps: 906 | Train Loss: 0.0664020 Vali Loss: 0.0661063 Test Loss: 0.0966524\n",
      "Validation loss decreased (0.070170 --> 0.066106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0660200\n",
      "\tspeed: 0.1053s/iter; left time: 1515.7127s\n",
      "\titers: 200, epoch: 5 | loss: 0.0623797\n",
      "\tspeed: 0.0418s/iter; left time: 597.9801s\n",
      "\titers: 300, epoch: 5 | loss: 0.0559764\n",
      "\tspeed: 0.0424s/iter; left time: 602.5398s\n",
      "\titers: 400, epoch: 5 | loss: 0.0630376\n",
      "\tspeed: 0.0425s/iter; left time: 599.2109s\n",
      "\titers: 500, epoch: 5 | loss: 0.0590218\n",
      "\tspeed: 0.0433s/iter; left time: 605.6838s\n",
      "\titers: 600, epoch: 5 | loss: 0.0610482\n",
      "\tspeed: 0.0339s/iter; left time: 470.5150s\n",
      "\titers: 700, epoch: 5 | loss: 0.0674176\n",
      "\tspeed: 0.0351s/iter; left time: 484.3692s\n",
      "\titers: 800, epoch: 5 | loss: 0.0588276\n",
      "\tspeed: 0.0338s/iter; left time: 463.3978s\n",
      "\titers: 900, epoch: 5 | loss: 0.0639992\n",
      "\tspeed: 0.0337s/iter; left time: 458.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:35.15s\n",
      "Steps: 906 | Train Loss: 0.0626899 Vali Loss: 0.0615744 Test Loss: 0.0916710\n",
      "Validation loss decreased (0.066106 --> 0.061574).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637254\n",
      "\tspeed: 0.1109s/iter; left time: 1495.9127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539645\n",
      "\tspeed: 0.0452s/iter; left time: 604.9319s\n",
      "\titers: 300, epoch: 6 | loss: 0.0630191\n",
      "\tspeed: 0.0418s/iter; left time: 556.1302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0613206\n",
      "\tspeed: 0.0450s/iter; left time: 593.1957s\n",
      "\titers: 500, epoch: 6 | loss: 0.0591853\n",
      "\tspeed: 0.0443s/iter; left time: 579.8375s\n",
      "\titers: 600, epoch: 6 | loss: 0.0613972\n",
      "\tspeed: 0.0436s/iter; left time: 566.2449s\n",
      "\titers: 700, epoch: 6 | loss: 0.0573764\n",
      "\tspeed: 0.0419s/iter; left time: 539.7953s\n",
      "\titers: 800, epoch: 6 | loss: 0.0631472\n",
      "\tspeed: 0.0444s/iter; left time: 567.6297s\n",
      "\titers: 900, epoch: 6 | loss: 0.0627898\n",
      "\tspeed: 0.0434s/iter; left time: 550.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 906 | Train Loss: 0.0592335 Vali Loss: 0.0626371 Test Loss: 0.0960112\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577794\n",
      "\tspeed: 0.1036s/iter; left time: 1303.2274s\n",
      "\titers: 200, epoch: 7 | loss: 0.0618888\n",
      "\tspeed: 0.0433s/iter; left time: 540.1234s\n",
      "\titers: 300, epoch: 7 | loss: 0.0594594\n",
      "\tspeed: 0.0445s/iter; left time: 551.1106s\n",
      "\titers: 400, epoch: 7 | loss: 0.0554541\n",
      "\tspeed: 0.0424s/iter; left time: 520.5314s\n",
      "\titers: 500, epoch: 7 | loss: 0.0584475\n",
      "\tspeed: 0.0428s/iter; left time: 520.9703s\n",
      "\titers: 600, epoch: 7 | loss: 0.0496468\n",
      "\tspeed: 0.0449s/iter; left time: 542.7406s\n",
      "\titers: 700, epoch: 7 | loss: 0.0529550\n",
      "\tspeed: 0.0450s/iter; left time: 539.8121s\n",
      "\titers: 800, epoch: 7 | loss: 0.0549940\n",
      "\tspeed: 0.0430s/iter; left time: 511.3768s\n",
      "\titers: 900, epoch: 7 | loss: 0.0590899\n",
      "\tspeed: 0.0440s/iter; left time: 519.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 906 | Train Loss: 0.0570599 Vali Loss: 0.0583242 Test Loss: 0.0939164\n",
      "Validation loss decreased (0.061574 --> 0.058324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0526088\n",
      "\tspeed: 0.1114s/iter; left time: 1301.2578s\n",
      "\titers: 200, epoch: 8 | loss: 0.0522844\n",
      "\tspeed: 0.0437s/iter; left time: 506.5009s\n",
      "\titers: 300, epoch: 8 | loss: 0.0492625\n",
      "\tspeed: 0.0443s/iter; left time: 508.7455s\n",
      "\titers: 400, epoch: 8 | loss: 0.0537116\n",
      "\tspeed: 0.0441s/iter; left time: 502.1380s\n",
      "\titers: 500, epoch: 8 | loss: 0.0549990\n",
      "\tspeed: 0.0442s/iter; left time: 499.0563s\n",
      "\titers: 600, epoch: 8 | loss: 0.0550420\n",
      "\tspeed: 0.0441s/iter; left time: 492.5384s\n",
      "\titers: 700, epoch: 8 | loss: 0.0603805\n",
      "\tspeed: 0.0423s/iter; left time: 468.2148s\n",
      "\titers: 800, epoch: 8 | loss: 0.0563873\n",
      "\tspeed: 0.0432s/iter; left time: 473.8128s\n",
      "\titers: 900, epoch: 8 | loss: 0.0567774\n",
      "\tspeed: 0.0441s/iter; left time: 480.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.0550604 Vali Loss: 0.0584201 Test Loss: 0.1015700\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0514966\n",
      "\tspeed: 0.1069s/iter; left time: 1151.7819s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532569\n",
      "\tspeed: 0.0438s/iter; left time: 467.8942s\n",
      "\titers: 300, epoch: 9 | loss: 0.0562458\n",
      "\tspeed: 0.0438s/iter; left time: 463.4605s\n",
      "\titers: 400, epoch: 9 | loss: 0.0574775\n",
      "\tspeed: 0.0411s/iter; left time: 429.9765s\n",
      "\titers: 500, epoch: 9 | loss: 0.0569222\n",
      "\tspeed: 0.0432s/iter; left time: 447.8125s\n",
      "\titers: 600, epoch: 9 | loss: 0.0562265\n",
      "\tspeed: 0.0443s/iter; left time: 454.7354s\n",
      "\titers: 700, epoch: 9 | loss: 0.0513619\n",
      "\tspeed: 0.0445s/iter; left time: 452.5811s\n",
      "\titers: 800, epoch: 9 | loss: 0.0531737\n",
      "\tspeed: 0.0445s/iter; left time: 448.1868s\n",
      "\titers: 900, epoch: 9 | loss: 0.0442144\n",
      "\tspeed: 0.0437s/iter; left time: 435.8113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.80s\n",
      "Steps: 906 | Train Loss: 0.0536022 Vali Loss: 0.0577300 Test Loss: 0.0931803\n",
      "Validation loss decreased (0.058324 --> 0.057730).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0552977\n",
      "\tspeed: 0.1108s/iter; left time: 1092.7721s\n",
      "\titers: 200, epoch: 10 | loss: 0.0540405\n",
      "\tspeed: 0.0439s/iter; left time: 429.2381s\n",
      "\titers: 300, epoch: 10 | loss: 0.0559633\n",
      "\tspeed: 0.0442s/iter; left time: 427.1885s\n",
      "\titers: 400, epoch: 10 | loss: 0.0634846\n",
      "\tspeed: 0.0411s/iter; left time: 392.7908s\n",
      "\titers: 500, epoch: 10 | loss: 0.0543671\n",
      "\tspeed: 0.0368s/iter; left time: 348.4556s\n",
      "\titers: 600, epoch: 10 | loss: 0.0492467\n",
      "\tspeed: 0.0451s/iter; left time: 422.2585s\n",
      "\titers: 700, epoch: 10 | loss: 0.0576616\n",
      "\tspeed: 0.0446s/iter; left time: 413.7546s\n",
      "\titers: 800, epoch: 10 | loss: 0.0450681\n",
      "\tspeed: 0.0445s/iter; left time: 408.3804s\n",
      "\titers: 900, epoch: 10 | loss: 0.0514902\n",
      "\tspeed: 0.0445s/iter; left time: 403.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.36s\n",
      "Steps: 906 | Train Loss: 0.0522438 Vali Loss: 0.0580221 Test Loss: 0.0941721\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514877\n",
      "\tspeed: 0.1046s/iter; left time: 937.0919s\n",
      "\titers: 200, epoch: 11 | loss: 0.0466050\n",
      "\tspeed: 0.0414s/iter; left time: 366.9040s\n",
      "\titers: 300, epoch: 11 | loss: 0.0494588\n",
      "\tspeed: 0.0443s/iter; left time: 387.8879s\n",
      "\titers: 400, epoch: 11 | loss: 0.0483637\n",
      "\tspeed: 0.0434s/iter; left time: 375.5540s\n",
      "\titers: 500, epoch: 11 | loss: 0.0525916\n",
      "\tspeed: 0.0412s/iter; left time: 352.3961s\n",
      "\titers: 600, epoch: 11 | loss: 0.0529519\n",
      "\tspeed: 0.0445s/iter; left time: 376.4178s\n",
      "\titers: 700, epoch: 11 | loss: 0.0522642\n",
      "\tspeed: 0.0391s/iter; left time: 326.8741s\n",
      "\titers: 800, epoch: 11 | loss: 0.0520713\n",
      "\tspeed: 0.0401s/iter; left time: 330.9780s\n",
      "\titers: 900, epoch: 11 | loss: 0.0516929\n",
      "\tspeed: 0.0432s/iter; left time: 352.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.0511752 Vali Loss: 0.0579007 Test Loss: 0.0985341\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0533170\n",
      "\tspeed: 0.1059s/iter; left time: 853.2523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521227\n",
      "\tspeed: 0.0443s/iter; left time: 352.4597s\n",
      "\titers: 300, epoch: 12 | loss: 0.0496030\n",
      "\tspeed: 0.0444s/iter; left time: 348.7598s\n",
      "\titers: 400, epoch: 12 | loss: 0.0584046\n",
      "\tspeed: 0.0436s/iter; left time: 338.0204s\n",
      "\titers: 500, epoch: 12 | loss: 0.0521255\n",
      "\tspeed: 0.0445s/iter; left time: 340.4598s\n",
      "\titers: 600, epoch: 12 | loss: 0.0469644\n",
      "\tspeed: 0.0442s/iter; left time: 333.6560s\n",
      "\titers: 700, epoch: 12 | loss: 0.0461116\n",
      "\tspeed: 0.0440s/iter; left time: 327.6579s\n",
      "\titers: 800, epoch: 12 | loss: 0.0504953\n",
      "\tspeed: 0.0437s/iter; left time: 321.6752s\n",
      "\titers: 900, epoch: 12 | loss: 0.0466300\n",
      "\tspeed: 0.0442s/iter; left time: 320.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 906 | Train Loss: 0.0499998 Vali Loss: 0.0585769 Test Loss: 0.1037559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465140\n",
      "\tspeed: 0.1053s/iter; left time: 752.7390s\n",
      "\titers: 200, epoch: 13 | loss: 0.0493444\n",
      "\tspeed: 0.0443s/iter; left time: 312.5628s\n",
      "\titers: 300, epoch: 13 | loss: 0.0551908\n",
      "\tspeed: 0.0439s/iter; left time: 305.3742s\n",
      "\titers: 400, epoch: 13 | loss: 0.0452325\n",
      "\tspeed: 0.0444s/iter; left time: 304.4194s\n",
      "\titers: 500, epoch: 13 | loss: 0.0501908\n",
      "\tspeed: 0.0439s/iter; left time: 296.1353s\n",
      "\titers: 600, epoch: 13 | loss: 0.0472432\n",
      "\tspeed: 0.0439s/iter; left time: 291.8602s\n",
      "\titers: 700, epoch: 13 | loss: 0.0494244\n",
      "\tspeed: 0.0435s/iter; left time: 284.6929s\n",
      "\titers: 800, epoch: 13 | loss: 0.0481905\n",
      "\tspeed: 0.0447s/iter; left time: 288.1406s\n",
      "\titers: 900, epoch: 13 | loss: 0.0470515\n",
      "\tspeed: 0.0438s/iter; left time: 277.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 906 | Train Loss: 0.0489971 Vali Loss: 0.0568892 Test Loss: 0.0995678\n",
      "Validation loss decreased (0.057730 --> 0.056889).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0508224\n",
      "\tspeed: 0.1092s/iter; left time: 681.6769s\n",
      "\titers: 200, epoch: 14 | loss: 0.0500584\n",
      "\tspeed: 0.0430s/iter; left time: 264.2501s\n",
      "\titers: 300, epoch: 14 | loss: 0.0461346\n",
      "\tspeed: 0.0414s/iter; left time: 250.2527s\n",
      "\titers: 400, epoch: 14 | loss: 0.0485840\n",
      "\tspeed: 0.0433s/iter; left time: 257.4673s\n",
      "\titers: 500, epoch: 14 | loss: 0.0415537\n",
      "\tspeed: 0.0433s/iter; left time: 253.0303s\n",
      "\titers: 600, epoch: 14 | loss: 0.0460557\n",
      "\tspeed: 0.0431s/iter; left time: 247.4043s\n",
      "\titers: 700, epoch: 14 | loss: 0.0503677\n",
      "\tspeed: 0.0441s/iter; left time: 248.7186s\n",
      "\titers: 800, epoch: 14 | loss: 0.0574076\n",
      "\tspeed: 0.0427s/iter; left time: 236.4133s\n",
      "\titers: 900, epoch: 14 | loss: 0.0483416\n",
      "\tspeed: 0.0430s/iter; left time: 233.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.17s\n",
      "Steps: 906 | Train Loss: 0.0481233 Vali Loss: 0.0570113 Test Loss: 0.1011703\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0470948\n",
      "\tspeed: 0.1063s/iter; left time: 567.2351s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453737\n",
      "\tspeed: 0.0436s/iter; left time: 228.2719s\n",
      "\titers: 300, epoch: 15 | loss: 0.0432208\n",
      "\tspeed: 0.0441s/iter; left time: 226.3564s\n",
      "\titers: 400, epoch: 15 | loss: 0.0495395\n",
      "\tspeed: 0.0437s/iter; left time: 220.2631s\n",
      "\titers: 500, epoch: 15 | loss: 0.0489155\n",
      "\tspeed: 0.0412s/iter; left time: 203.2721s\n",
      "\titers: 600, epoch: 15 | loss: 0.0499997\n",
      "\tspeed: 0.0424s/iter; left time: 205.0388s\n",
      "\titers: 700, epoch: 15 | loss: 0.0444094\n",
      "\tspeed: 0.0412s/iter; left time: 195.1046s\n",
      "\titers: 800, epoch: 15 | loss: 0.0409945\n",
      "\tspeed: 0.0439s/iter; left time: 203.7290s\n",
      "\titers: 900, epoch: 15 | loss: 0.0468104\n",
      "\tspeed: 0.0418s/iter; left time: 189.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.06s\n",
      "Steps: 906 | Train Loss: 0.0473649 Vali Loss: 0.0571158 Test Loss: 0.1002323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541349\n",
      "\tspeed: 0.1065s/iter; left time: 471.6943s\n",
      "\titers: 200, epoch: 16 | loss: 0.0523621\n",
      "\tspeed: 0.0447s/iter; left time: 193.6216s\n",
      "\titers: 300, epoch: 16 | loss: 0.0414441\n",
      "\tspeed: 0.0435s/iter; left time: 184.1119s\n",
      "\titers: 400, epoch: 16 | loss: 0.0472221\n",
      "\tspeed: 0.0443s/iter; left time: 183.0606s\n",
      "\titers: 500, epoch: 16 | loss: 0.0470437\n",
      "\tspeed: 0.0445s/iter; left time: 179.2041s\n",
      "\titers: 600, epoch: 16 | loss: 0.0411740\n",
      "\tspeed: 0.0409s/iter; left time: 160.6773s\n",
      "\titers: 700, epoch: 16 | loss: 0.0513565\n",
      "\tspeed: 0.0421s/iter; left time: 161.1572s\n",
      "\titers: 800, epoch: 16 | loss: 0.0425249\n",
      "\tspeed: 0.0416s/iter; left time: 155.3568s\n",
      "\titers: 900, epoch: 16 | loss: 0.0494811\n",
      "\tspeed: 0.0416s/iter; left time: 151.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.20s\n",
      "Steps: 906 | Train Loss: 0.0464900 Vali Loss: 0.0573784 Test Loss: 0.1039492\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0428713\n",
      "\tspeed: 0.1056s/iter; left time: 372.2612s\n",
      "\titers: 200, epoch: 17 | loss: 0.0463484\n",
      "\tspeed: 0.0429s/iter; left time: 146.9456s\n",
      "\titers: 300, epoch: 17 | loss: 0.0401853\n",
      "\tspeed: 0.0403s/iter; left time: 133.9143s\n",
      "\titers: 400, epoch: 17 | loss: 0.0488955\n",
      "\tspeed: 0.0422s/iter; left time: 136.2322s\n",
      "\titers: 500, epoch: 17 | loss: 0.0493908\n",
      "\tspeed: 0.0446s/iter; left time: 139.3483s\n",
      "\titers: 600, epoch: 17 | loss: 0.0440601\n",
      "\tspeed: 0.0445s/iter; left time: 134.5869s\n",
      "\titers: 700, epoch: 17 | loss: 0.0442597\n",
      "\tspeed: 0.0448s/iter; left time: 130.9255s\n",
      "\titers: 800, epoch: 17 | loss: 0.0541522\n",
      "\tspeed: 0.0436s/iter; left time: 123.0634s\n",
      "\titers: 900, epoch: 17 | loss: 0.0446799\n",
      "\tspeed: 0.0437s/iter; left time: 118.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.51s\n",
      "Steps: 906 | Train Loss: 0.0457837 Vali Loss: 0.0572614 Test Loss: 0.1043900\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0476238\n",
      "\tspeed: 0.0962s/iter; left time: 251.9674s\n",
      "\titers: 200, epoch: 18 | loss: 0.0440719\n",
      "\tspeed: 0.0380s/iter; left time: 95.6193s\n",
      "\titers: 300, epoch: 18 | loss: 0.0421719\n",
      "\tspeed: 0.0439s/iter; left time: 106.1420s\n",
      "\titers: 400, epoch: 18 | loss: 0.0431837\n",
      "\tspeed: 0.0422s/iter; left time: 97.9044s\n",
      "\titers: 500, epoch: 18 | loss: 0.0495908\n",
      "\tspeed: 0.0430s/iter; left time: 95.3876s\n",
      "\titers: 600, epoch: 18 | loss: 0.0416300\n",
      "\tspeed: 0.0436s/iter; left time: 92.3151s\n",
      "\titers: 700, epoch: 18 | loss: 0.0489602\n",
      "\tspeed: 0.0443s/iter; left time: 89.4259s\n",
      "\titers: 800, epoch: 18 | loss: 0.0421391\n",
      "\tspeed: 0.0429s/iter; left time: 82.3183s\n",
      "\titers: 900, epoch: 18 | loss: 0.0424431\n",
      "\tspeed: 0.0433s/iter; left time: 78.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.0453538 Vali Loss: 0.0578796 Test Loss: 0.1050055\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028536172583699226, rmse:0.16892653703689575, mae:0.09957146644592285, rse:0.4963572025299072\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2313316\n",
      "\tspeed: 0.0443s/iter; left time: 798.8098s\n",
      "\titers: 200, epoch: 1 | loss: 0.2083366\n",
      "\tspeed: 0.0444s/iter; left time: 796.5518s\n",
      "\titers: 300, epoch: 1 | loss: 0.2007164\n",
      "\tspeed: 0.0444s/iter; left time: 792.1386s\n",
      "\titers: 400, epoch: 1 | loss: 0.1766935\n",
      "\tspeed: 0.0438s/iter; left time: 776.5220s\n",
      "\titers: 500, epoch: 1 | loss: 0.1663704\n",
      "\tspeed: 0.0439s/iter; left time: 773.8722s\n",
      "\titers: 600, epoch: 1 | loss: 0.1537390\n",
      "\tspeed: 0.0354s/iter; left time: 619.4099s\n",
      "\titers: 700, epoch: 1 | loss: 0.1531670\n",
      "\tspeed: 0.0386s/iter; left time: 672.2683s\n",
      "\titers: 800, epoch: 1 | loss: 0.1397817\n",
      "\tspeed: 0.0386s/iter; left time: 667.7462s\n",
      "\titers: 900, epoch: 1 | loss: 0.1367912\n",
      "\tspeed: 0.0409s/iter; left time: 704.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1826177 Vali Loss: 0.1168092 Test Loss: 0.1326445\n",
      "Validation loss decreased (inf --> 0.116809).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1116118\n",
      "\tspeed: 0.1068s/iter; left time: 1827.2371s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123900\n",
      "\tspeed: 0.0402s/iter; left time: 684.4131s\n",
      "\titers: 300, epoch: 2 | loss: 0.0865321\n",
      "\tspeed: 0.0449s/iter; left time: 758.9397s\n",
      "\titers: 400, epoch: 2 | loss: 0.0858704\n",
      "\tspeed: 0.0452s/iter; left time: 759.6655s\n",
      "\titers: 500, epoch: 2 | loss: 0.0826757\n",
      "\tspeed: 0.0451s/iter; left time: 754.2646s\n",
      "\titers: 600, epoch: 2 | loss: 0.0818717\n",
      "\tspeed: 0.0445s/iter; left time: 740.0103s\n",
      "\titers: 700, epoch: 2 | loss: 0.0779352\n",
      "\tspeed: 0.0439s/iter; left time: 725.2402s\n",
      "\titers: 800, epoch: 2 | loss: 0.0921536\n",
      "\tspeed: 0.0425s/iter; left time: 697.0326s\n",
      "\titers: 900, epoch: 2 | loss: 0.0730876\n",
      "\tspeed: 0.0405s/iter; left time: 661.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.25s\n",
      "Steps: 906 | Train Loss: 0.0939332 Vali Loss: 0.0757749 Test Loss: 0.0978310\n",
      "Validation loss decreased (0.116809 --> 0.075775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0707570\n",
      "\tspeed: 0.1104s/iter; left time: 1789.0318s\n",
      "\titers: 200, epoch: 3 | loss: 0.0873234\n",
      "\tspeed: 0.0441s/iter; left time: 710.5997s\n",
      "\titers: 300, epoch: 3 | loss: 0.0727585\n",
      "\tspeed: 0.0412s/iter; left time: 659.4728s\n",
      "\titers: 400, epoch: 3 | loss: 0.0726301\n",
      "\tspeed: 0.0416s/iter; left time: 661.2546s\n",
      "\titers: 500, epoch: 3 | loss: 0.0729856\n",
      "\tspeed: 0.0416s/iter; left time: 658.1341s\n",
      "\titers: 600, epoch: 3 | loss: 0.0740381\n",
      "\tspeed: 0.0422s/iter; left time: 663.0867s\n",
      "\titers: 700, epoch: 3 | loss: 0.0687820\n",
      "\tspeed: 0.0410s/iter; left time: 639.3882s\n",
      "\titers: 800, epoch: 3 | loss: 0.0763161\n",
      "\tspeed: 0.0418s/iter; left time: 647.7640s\n",
      "\titers: 900, epoch: 3 | loss: 0.0734477\n",
      "\tspeed: 0.0412s/iter; left time: 635.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 906 | Train Loss: 0.0723015 Vali Loss: 0.0702711 Test Loss: 0.0914330\n",
      "Validation loss decreased (0.075775 --> 0.070271).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619542\n",
      "\tspeed: 0.1129s/iter; left time: 1727.7937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0599128\n",
      "\tspeed: 0.0436s/iter; left time: 663.2738s\n",
      "\titers: 300, epoch: 4 | loss: 0.0723603\n",
      "\tspeed: 0.0445s/iter; left time: 671.9057s\n",
      "\titers: 400, epoch: 4 | loss: 0.0708914\n",
      "\tspeed: 0.0450s/iter; left time: 675.0391s\n",
      "\titers: 500, epoch: 4 | loss: 0.0703685\n",
      "\tspeed: 0.0426s/iter; left time: 635.3699s\n",
      "\titers: 600, epoch: 4 | loss: 0.0644621\n",
      "\tspeed: 0.0410s/iter; left time: 607.2016s\n",
      "\titers: 700, epoch: 4 | loss: 0.0626157\n",
      "\tspeed: 0.0449s/iter; left time: 659.7139s\n",
      "\titers: 800, epoch: 4 | loss: 0.0553676\n",
      "\tspeed: 0.0458s/iter; left time: 669.4363s\n",
      "\titers: 900, epoch: 4 | loss: 0.0617898\n",
      "\tspeed: 0.0445s/iter; left time: 645.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.0659040 Vali Loss: 0.0740883 Test Loss: 0.0980233\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598068\n",
      "\tspeed: 0.1086s/iter; left time: 1563.6838s\n",
      "\titers: 200, epoch: 5 | loss: 0.0649589\n",
      "\tspeed: 0.0444s/iter; left time: 634.5112s\n",
      "\titers: 300, epoch: 5 | loss: 0.0586884\n",
      "\tspeed: 0.0445s/iter; left time: 632.1882s\n",
      "\titers: 400, epoch: 5 | loss: 0.0771512\n",
      "\tspeed: 0.0405s/iter; left time: 571.2332s\n",
      "\titers: 500, epoch: 5 | loss: 0.0645529\n",
      "\tspeed: 0.0369s/iter; left time: 516.0967s\n",
      "\titers: 600, epoch: 5 | loss: 0.0685468\n",
      "\tspeed: 0.0448s/iter; left time: 623.0498s\n",
      "\titers: 700, epoch: 5 | loss: 0.0685796\n",
      "\tspeed: 0.0456s/iter; left time: 629.0955s\n",
      "\titers: 800, epoch: 5 | loss: 0.0585045\n",
      "\tspeed: 0.0443s/iter; left time: 606.3994s\n",
      "\titers: 900, epoch: 5 | loss: 0.0589975\n",
      "\tspeed: 0.0381s/iter; left time: 518.3554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 906 | Train Loss: 0.0619781 Vali Loss: 0.0643090 Test Loss: 0.0918030\n",
      "Validation loss decreased (0.070271 --> 0.064309).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0677534\n",
      "\tspeed: 0.1137s/iter; left time: 1533.6194s\n",
      "\titers: 200, epoch: 6 | loss: 0.0530176\n",
      "\tspeed: 0.0456s/iter; left time: 610.4104s\n",
      "\titers: 300, epoch: 6 | loss: 0.0548486\n",
      "\tspeed: 0.0456s/iter; left time: 605.8501s\n",
      "\titers: 400, epoch: 6 | loss: 0.0547553\n",
      "\tspeed: 0.0463s/iter; left time: 611.4028s\n",
      "\titers: 500, epoch: 6 | loss: 0.0612377\n",
      "\tspeed: 0.0450s/iter; left time: 589.1144s\n",
      "\titers: 600, epoch: 6 | loss: 0.0533771\n",
      "\tspeed: 0.0443s/iter; left time: 576.0056s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555436\n",
      "\tspeed: 0.0425s/iter; left time: 547.8653s\n",
      "\titers: 800, epoch: 6 | loss: 0.0503458\n",
      "\tspeed: 0.0425s/iter; left time: 543.2555s\n",
      "\titers: 900, epoch: 6 | loss: 0.0532720\n",
      "\tspeed: 0.0434s/iter; left time: 551.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.56s\n",
      "Steps: 906 | Train Loss: 0.0591056 Vali Loss: 0.0622354 Test Loss: 0.0924892\n",
      "Validation loss decreased (0.064309 --> 0.062235).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528733\n",
      "\tspeed: 0.1125s/iter; left time: 1415.3072s\n",
      "\titers: 200, epoch: 7 | loss: 0.0529910\n",
      "\tspeed: 0.0446s/iter; left time: 556.4089s\n",
      "\titers: 300, epoch: 7 | loss: 0.0598943\n",
      "\tspeed: 0.0438s/iter; left time: 542.9925s\n",
      "\titers: 400, epoch: 7 | loss: 0.0604081\n",
      "\tspeed: 0.0433s/iter; left time: 531.8548s\n",
      "\titers: 500, epoch: 7 | loss: 0.0523877\n",
      "\tspeed: 0.0442s/iter; left time: 538.9786s\n",
      "\titers: 600, epoch: 7 | loss: 0.0515208\n",
      "\tspeed: 0.0426s/iter; left time: 514.7054s\n",
      "\titers: 700, epoch: 7 | loss: 0.0524358\n",
      "\tspeed: 0.0420s/iter; left time: 502.8734s\n",
      "\titers: 800, epoch: 7 | loss: 0.0512721\n",
      "\tspeed: 0.0439s/iter; left time: 521.8643s\n",
      "\titers: 900, epoch: 7 | loss: 0.0596220\n",
      "\tspeed: 0.0430s/iter; left time: 506.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.65s\n",
      "Steps: 906 | Train Loss: 0.0569564 Vali Loss: 0.0586430 Test Loss: 0.0882417\n",
      "Validation loss decreased (0.062235 --> 0.058643).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0517399\n",
      "\tspeed: 0.1236s/iter; left time: 1443.9657s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589598\n",
      "\tspeed: 0.0444s/iter; left time: 514.2482s\n",
      "\titers: 300, epoch: 8 | loss: 0.0577127\n",
      "\tspeed: 0.0414s/iter; left time: 474.9538s\n",
      "\titers: 400, epoch: 8 | loss: 0.0532096\n",
      "\tspeed: 0.0430s/iter; left time: 489.5803s\n",
      "\titers: 500, epoch: 8 | loss: 0.0528615\n",
      "\tspeed: 0.0449s/iter; left time: 506.1521s\n",
      "\titers: 600, epoch: 8 | loss: 0.0566781\n",
      "\tspeed: 0.0429s/iter; left time: 479.3895s\n",
      "\titers: 700, epoch: 8 | loss: 0.0528790\n",
      "\tspeed: 0.0443s/iter; left time: 490.4175s\n",
      "\titers: 800, epoch: 8 | loss: 0.0491190\n",
      "\tspeed: 0.0362s/iter; left time: 397.1890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0502336\n",
      "\tspeed: 0.0435s/iter; left time: 472.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.86s\n",
      "Steps: 906 | Train Loss: 0.0550019 Vali Loss: 0.0594650 Test Loss: 0.0909620\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0540753\n",
      "\tspeed: 0.0977s/iter; left time: 1052.1611s\n",
      "\titers: 200, epoch: 9 | loss: 0.0531044\n",
      "\tspeed: 0.0337s/iter; left time: 359.7026s\n",
      "\titers: 300, epoch: 9 | loss: 0.0522201\n",
      "\tspeed: 0.0383s/iter; left time: 404.8255s\n",
      "\titers: 400, epoch: 9 | loss: 0.0586018\n",
      "\tspeed: 0.0455s/iter; left time: 476.4605s\n",
      "\titers: 500, epoch: 9 | loss: 0.0518451\n",
      "\tspeed: 0.0428s/iter; left time: 443.8353s\n",
      "\titers: 600, epoch: 9 | loss: 0.0535643\n",
      "\tspeed: 0.0420s/iter; left time: 431.5549s\n",
      "\titers: 700, epoch: 9 | loss: 0.0501714\n",
      "\tspeed: 0.0424s/iter; left time: 431.6363s\n",
      "\titers: 800, epoch: 9 | loss: 0.0548880\n",
      "\tspeed: 0.0429s/iter; left time: 432.4512s\n",
      "\titers: 900, epoch: 9 | loss: 0.0576162\n",
      "\tspeed: 0.0409s/iter; left time: 407.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.79s\n",
      "Steps: 906 | Train Loss: 0.0536402 Vali Loss: 0.0601242 Test Loss: 0.0902880\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0518997\n",
      "\tspeed: 0.1075s/iter; left time: 1060.5678s\n",
      "\titers: 200, epoch: 10 | loss: 0.0513844\n",
      "\tspeed: 0.0431s/iter; left time: 420.5070s\n",
      "\titers: 300, epoch: 10 | loss: 0.0480083\n",
      "\tspeed: 0.0439s/iter; left time: 424.2366s\n",
      "\titers: 400, epoch: 10 | loss: 0.0492702\n",
      "\tspeed: 0.0433s/iter; left time: 414.0125s\n",
      "\titers: 500, epoch: 10 | loss: 0.0519252\n",
      "\tspeed: 0.0435s/iter; left time: 411.8603s\n",
      "\titers: 600, epoch: 10 | loss: 0.0542450\n",
      "\tspeed: 0.0427s/iter; left time: 399.5325s\n",
      "\titers: 700, epoch: 10 | loss: 0.0535993\n",
      "\tspeed: 0.0419s/iter; left time: 388.2285s\n",
      "\titers: 800, epoch: 10 | loss: 0.0548232\n",
      "\tspeed: 0.0405s/iter; left time: 371.5101s\n",
      "\titers: 900, epoch: 10 | loss: 0.0558516\n",
      "\tspeed: 0.0425s/iter; left time: 385.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.00s\n",
      "Steps: 906 | Train Loss: 0.0521639 Vali Loss: 0.0586735 Test Loss: 0.0904036\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0520976\n",
      "\tspeed: 0.1082s/iter; left time: 969.6206s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546211\n",
      "\tspeed: 0.0438s/iter; left time: 387.6893s\n",
      "\titers: 300, epoch: 11 | loss: 0.0537416\n",
      "\tspeed: 0.0452s/iter; left time: 395.9296s\n",
      "\titers: 400, epoch: 11 | loss: 0.0576245\n",
      "\tspeed: 0.0439s/iter; left time: 380.5025s\n",
      "\titers: 500, epoch: 11 | loss: 0.0557026\n",
      "\tspeed: 0.0430s/iter; left time: 368.5508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0542328\n",
      "\tspeed: 0.0425s/iter; left time: 359.4589s\n",
      "\titers: 700, epoch: 11 | loss: 0.0465595\n",
      "\tspeed: 0.0424s/iter; left time: 354.6454s\n",
      "\titers: 800, epoch: 11 | loss: 0.0529933\n",
      "\tspeed: 0.0426s/iter; left time: 351.6369s\n",
      "\titers: 900, epoch: 11 | loss: 0.0521689\n",
      "\tspeed: 0.0431s/iter; left time: 352.0106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.64s\n",
      "Steps: 906 | Train Loss: 0.0511675 Vali Loss: 0.0598988 Test Loss: 0.0922994\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0543974\n",
      "\tspeed: 0.1079s/iter; left time: 869.1142s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558931\n",
      "\tspeed: 0.0439s/iter; left time: 349.4350s\n",
      "\titers: 300, epoch: 12 | loss: 0.0536673\n",
      "\tspeed: 0.0418s/iter; left time: 328.6495s\n",
      "\titers: 400, epoch: 12 | loss: 0.0493185\n",
      "\tspeed: 0.0395s/iter; left time: 306.6525s\n",
      "\titers: 500, epoch: 12 | loss: 0.0480766\n",
      "\tspeed: 0.0454s/iter; left time: 347.6258s\n",
      "\titers: 600, epoch: 12 | loss: 0.0496297\n",
      "\tspeed: 0.0390s/iter; left time: 294.4691s\n",
      "\titers: 700, epoch: 12 | loss: 0.0478737\n",
      "\tspeed: 0.0359s/iter; left time: 267.5886s\n",
      "\titers: 800, epoch: 12 | loss: 0.0538624\n",
      "\tspeed: 0.0367s/iter; left time: 269.8622s\n",
      "\titers: 900, epoch: 12 | loss: 0.0532948\n",
      "\tspeed: 0.0437s/iter; left time: 316.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0501974 Vali Loss: 0.0584733 Test Loss: 0.0908385\n",
      "Validation loss decreased (0.058643 --> 0.058473).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0446094\n",
      "\tspeed: 0.1131s/iter; left time: 808.5172s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457311\n",
      "\tspeed: 0.0427s/iter; left time: 301.0601s\n",
      "\titers: 300, epoch: 13 | loss: 0.0506537\n",
      "\tspeed: 0.0439s/iter; left time: 305.4049s\n",
      "\titers: 400, epoch: 13 | loss: 0.0511733\n",
      "\tspeed: 0.0442s/iter; left time: 302.9935s\n",
      "\titers: 500, epoch: 13 | loss: 0.0539472\n",
      "\tspeed: 0.0427s/iter; left time: 288.3194s\n",
      "\titers: 600, epoch: 13 | loss: 0.0441267\n",
      "\tspeed: 0.0428s/iter; left time: 284.5521s\n",
      "\titers: 700, epoch: 13 | loss: 0.0492516\n",
      "\tspeed: 0.0415s/iter; left time: 271.6041s\n",
      "\titers: 800, epoch: 13 | loss: 0.0561598\n",
      "\tspeed: 0.0421s/iter; left time: 271.8197s\n",
      "\titers: 900, epoch: 13 | loss: 0.0472484\n",
      "\tspeed: 0.0429s/iter; left time: 272.4937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.07s\n",
      "Steps: 906 | Train Loss: 0.0491326 Vali Loss: 0.0594089 Test Loss: 0.0963262\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530333\n",
      "\tspeed: 0.1069s/iter; left time: 667.6597s\n",
      "\titers: 200, epoch: 14 | loss: 0.0487412\n",
      "\tspeed: 0.0420s/iter; left time: 258.1694s\n",
      "\titers: 300, epoch: 14 | loss: 0.0453941\n",
      "\tspeed: 0.0417s/iter; left time: 252.0604s\n",
      "\titers: 400, epoch: 14 | loss: 0.0444784\n",
      "\tspeed: 0.0425s/iter; left time: 252.3848s\n",
      "\titers: 500, epoch: 14 | loss: 0.0439628\n",
      "\tspeed: 0.0417s/iter; left time: 243.8408s\n",
      "\titers: 600, epoch: 14 | loss: 0.0476262\n",
      "\tspeed: 0.0443s/iter; left time: 254.2760s\n",
      "\titers: 700, epoch: 14 | loss: 0.0483886\n",
      "\tspeed: 0.0433s/iter; left time: 244.3192s\n",
      "\titers: 800, epoch: 14 | loss: 0.0529764\n",
      "\tspeed: 0.0427s/iter; left time: 236.8726s\n",
      "\titers: 900, epoch: 14 | loss: 0.0472643\n",
      "\tspeed: 0.0402s/iter; left time: 218.5852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 906 | Train Loss: 0.0482440 Vali Loss: 0.0596548 Test Loss: 0.0971809\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0510043\n",
      "\tspeed: 0.1068s/iter; left time: 570.2174s\n",
      "\titers: 200, epoch: 15 | loss: 0.0419200\n",
      "\tspeed: 0.0436s/iter; left time: 228.5415s\n",
      "\titers: 300, epoch: 15 | loss: 0.0468224\n",
      "\tspeed: 0.0453s/iter; left time: 232.8411s\n",
      "\titers: 400, epoch: 15 | loss: 0.0428927\n",
      "\tspeed: 0.0424s/iter; left time: 213.5581s\n",
      "\titers: 500, epoch: 15 | loss: 0.0499197\n",
      "\tspeed: 0.0423s/iter; left time: 208.6248s\n",
      "\titers: 600, epoch: 15 | loss: 0.0496863\n",
      "\tspeed: 0.0454s/iter; left time: 219.5392s\n",
      "\titers: 700, epoch: 15 | loss: 0.0491264\n",
      "\tspeed: 0.0446s/iter; left time: 211.1205s\n",
      "\titers: 800, epoch: 15 | loss: 0.0506055\n",
      "\tspeed: 0.0435s/iter; left time: 201.9092s\n",
      "\titers: 900, epoch: 15 | loss: 0.0496673\n",
      "\tspeed: 0.0442s/iter; left time: 200.6103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.96s\n",
      "Steps: 906 | Train Loss: 0.0474373 Vali Loss: 0.0577796 Test Loss: 0.0971414\n",
      "Validation loss decreased (0.058473 --> 0.057780).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0438764\n",
      "\tspeed: 0.1129s/iter; left time: 500.1458s\n",
      "\titers: 200, epoch: 16 | loss: 0.0438639\n",
      "\tspeed: 0.0432s/iter; left time: 187.0524s\n",
      "\titers: 300, epoch: 16 | loss: 0.0494521\n",
      "\tspeed: 0.0438s/iter; left time: 185.1173s\n",
      "\titers: 400, epoch: 16 | loss: 0.0448913\n",
      "\tspeed: 0.0420s/iter; left time: 173.6705s\n",
      "\titers: 500, epoch: 16 | loss: 0.0451118\n",
      "\tspeed: 0.0422s/iter; left time: 170.1019s\n",
      "\titers: 600, epoch: 16 | loss: 0.0447474\n",
      "\tspeed: 0.0421s/iter; left time: 165.4212s\n",
      "\titers: 700, epoch: 16 | loss: 0.0474475\n",
      "\tspeed: 0.0425s/iter; left time: 162.9229s\n",
      "\titers: 800, epoch: 16 | loss: 0.0469913\n",
      "\tspeed: 0.0420s/iter; left time: 156.6235s\n",
      "\titers: 900, epoch: 16 | loss: 0.0424623\n",
      "\tspeed: 0.0447s/iter; left time: 162.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.02s\n",
      "Steps: 906 | Train Loss: 0.0466344 Vali Loss: 0.0593383 Test Loss: 0.0970664\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0495520\n",
      "\tspeed: 0.1067s/iter; left time: 375.9424s\n",
      "\titers: 200, epoch: 17 | loss: 0.0392627\n",
      "\tspeed: 0.0402s/iter; left time: 137.6641s\n",
      "\titers: 300, epoch: 17 | loss: 0.0440726\n",
      "\tspeed: 0.0432s/iter; left time: 143.6500s\n",
      "\titers: 400, epoch: 17 | loss: 0.0480871\n",
      "\tspeed: 0.0445s/iter; left time: 143.5580s\n",
      "\titers: 500, epoch: 17 | loss: 0.0463579\n",
      "\tspeed: 0.0449s/iter; left time: 140.3851s\n",
      "\titers: 600, epoch: 17 | loss: 0.0517737\n",
      "\tspeed: 0.0447s/iter; left time: 135.2138s\n",
      "\titers: 700, epoch: 17 | loss: 0.0455615\n",
      "\tspeed: 0.0437s/iter; left time: 127.8104s\n",
      "\titers: 800, epoch: 17 | loss: 0.0434252\n",
      "\tspeed: 0.0444s/iter; left time: 125.5193s\n",
      "\titers: 900, epoch: 17 | loss: 0.0463968\n",
      "\tspeed: 0.0449s/iter; left time: 122.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.85s\n",
      "Steps: 906 | Train Loss: 0.0458945 Vali Loss: 0.0584379 Test Loss: 0.0950533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0485099\n",
      "\tspeed: 0.1074s/iter; left time: 281.2153s\n",
      "\titers: 200, epoch: 18 | loss: 0.0528042\n",
      "\tspeed: 0.0427s/iter; left time: 107.6323s\n",
      "\titers: 300, epoch: 18 | loss: 0.0441985\n",
      "\tspeed: 0.0432s/iter; left time: 104.4056s\n",
      "\titers: 400, epoch: 18 | loss: 0.0439317\n",
      "\tspeed: 0.0430s/iter; left time: 99.8201s\n",
      "\titers: 500, epoch: 18 | loss: 0.0448917\n",
      "\tspeed: 0.0428s/iter; left time: 94.8984s\n",
      "\titers: 600, epoch: 18 | loss: 0.0403514\n",
      "\tspeed: 0.0423s/iter; left time: 89.6848s\n",
      "\titers: 700, epoch: 18 | loss: 0.0424764\n",
      "\tspeed: 0.0413s/iter; left time: 83.4820s\n",
      "\titers: 800, epoch: 18 | loss: 0.0437762\n",
      "\tspeed: 0.0437s/iter; left time: 83.8336s\n",
      "\titers: 900, epoch: 18 | loss: 0.0481154\n",
      "\tspeed: 0.0411s/iter; left time: 74.7502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 906 | Train Loss: 0.0453132 Vali Loss: 0.0576576 Test Loss: 0.0957833\n",
      "Validation loss decreased (0.057780 --> 0.057658).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525963\n",
      "\tspeed: 0.1144s/iter; left time: 195.9725s\n",
      "\titers: 200, epoch: 19 | loss: 0.0475755\n",
      "\tspeed: 0.0437s/iter; left time: 70.5220s\n",
      "\titers: 300, epoch: 19 | loss: 0.0504941\n",
      "\tspeed: 0.0452s/iter; left time: 68.4124s\n",
      "\titers: 400, epoch: 19 | loss: 0.0391003\n",
      "\tspeed: 0.0451s/iter; left time: 63.7487s\n",
      "\titers: 500, epoch: 19 | loss: 0.0436999\n",
      "\tspeed: 0.0435s/iter; left time: 57.1626s\n",
      "\titers: 600, epoch: 19 | loss: 0.0416488\n",
      "\tspeed: 0.0434s/iter; left time: 52.6032s\n",
      "\titers: 700, epoch: 19 | loss: 0.0458390\n",
      "\tspeed: 0.0448s/iter; left time: 49.8677s\n",
      "\titers: 800, epoch: 19 | loss: 0.0466240\n",
      "\tspeed: 0.0436s/iter; left time: 44.1246s\n",
      "\titers: 900, epoch: 19 | loss: 0.0424584\n",
      "\tspeed: 0.0448s/iter; left time: 40.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 906 | Train Loss: 0.0446740 Vali Loss: 0.0614819 Test Loss: 0.1065742\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0435882\n",
      "\tspeed: 0.1066s/iter; left time: 86.0427s\n",
      "\titers: 200, epoch: 20 | loss: 0.0435573\n",
      "\tspeed: 0.0434s/iter; left time: 30.6982s\n",
      "\titers: 300, epoch: 20 | loss: 0.0418303\n",
      "\tspeed: 0.0439s/iter; left time: 26.6183s\n",
      "\titers: 400, epoch: 20 | loss: 0.0441725\n",
      "\tspeed: 0.0450s/iter; left time: 22.8326s\n",
      "\titers: 500, epoch: 20 | loss: 0.0432206\n",
      "\tspeed: 0.0442s/iter; left time: 17.9906s\n",
      "\titers: 600, epoch: 20 | loss: 0.0425618\n",
      "\tspeed: 0.0452s/iter; left time: 13.8630s\n",
      "\titers: 700, epoch: 20 | loss: 0.0430357\n",
      "\tspeed: 0.0438s/iter; left time: 9.0677s\n",
      "\titers: 800, epoch: 20 | loss: 0.0425836\n",
      "\tspeed: 0.0454s/iter; left time: 4.8576s\n",
      "\titers: 900, epoch: 20 | loss: 0.0451035\n",
      "\tspeed: 0.0437s/iter; left time: 0.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:40.24s\n",
      "Steps: 906 | Train Loss: 0.0442419 Vali Loss: 0.0586618 Test Loss: 0.0996176\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024789901450276375, rmse:0.15744809806346893, mae:0.09591271728277206, rse:0.46263009309768677\n",
      "Intermediate time for ES and pred_len 24: 00h:28m:53.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2384515\n",
      "\tspeed: 0.0755s/iter; left time: 1357.3714s\n",
      "\titers: 200, epoch: 1 | loss: 0.2146414\n",
      "\tspeed: 0.0450s/iter; left time: 805.1458s\n",
      "\titers: 300, epoch: 1 | loss: 0.2180060\n",
      "\tspeed: 0.0479s/iter; left time: 851.3699s\n",
      "\titers: 400, epoch: 1 | loss: 0.2053107\n",
      "\tspeed: 0.0487s/iter; left time: 860.2883s\n",
      "\titers: 500, epoch: 1 | loss: 0.1972545\n",
      "\tspeed: 0.0493s/iter; left time: 867.6185s\n",
      "\titers: 600, epoch: 1 | loss: 0.1857185\n",
      "\tspeed: 0.0492s/iter; left time: 860.0796s\n",
      "\titers: 700, epoch: 1 | loss: 0.1904936\n",
      "\tspeed: 0.0462s/iter; left time: 802.1456s\n",
      "\titers: 800, epoch: 1 | loss: 0.1748629\n",
      "\tspeed: 0.0469s/iter; left time: 810.8537s\n",
      "\titers: 900, epoch: 1 | loss: 0.1777007\n",
      "\tspeed: 0.0487s/iter; left time: 837.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 904 | Train Loss: 0.2054805 Vali Loss: 0.1695710 Test Loss: 0.2078795\n",
      "Validation loss decreased (inf --> 0.169571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453836\n",
      "\tspeed: 0.1268s/iter; left time: 2165.3349s\n",
      "\titers: 200, epoch: 2 | loss: 0.1358089\n",
      "\tspeed: 0.0493s/iter; left time: 836.4676s\n",
      "\titers: 300, epoch: 2 | loss: 0.1296715\n",
      "\tspeed: 0.0475s/iter; left time: 802.3977s\n",
      "\titers: 400, epoch: 2 | loss: 0.1144006\n",
      "\tspeed: 0.0476s/iter; left time: 797.8862s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037235\n",
      "\tspeed: 0.0481s/iter; left time: 802.9475s\n",
      "\titers: 600, epoch: 2 | loss: 0.1101244\n",
      "\tspeed: 0.0471s/iter; left time: 780.4448s\n",
      "\titers: 700, epoch: 2 | loss: 0.0999445\n",
      "\tspeed: 0.0465s/iter; left time: 766.4905s\n",
      "\titers: 800, epoch: 2 | loss: 0.0935427\n",
      "\tspeed: 0.0426s/iter; left time: 697.7491s\n",
      "\titers: 900, epoch: 2 | loss: 0.0998164\n",
      "\tspeed: 0.0472s/iter; left time: 768.8985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.1199355 Vali Loss: 0.0985261 Test Loss: 0.1282562\n",
      "Validation loss decreased (0.169571 --> 0.098526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954515\n",
      "\tspeed: 0.1243s/iter; left time: 2009.5040s\n",
      "\titers: 200, epoch: 3 | loss: 0.0912124\n",
      "\tspeed: 0.0482s/iter; left time: 774.2395s\n",
      "\titers: 300, epoch: 3 | loss: 0.0960256\n",
      "\tspeed: 0.0451s/iter; left time: 720.6675s\n",
      "\titers: 400, epoch: 3 | loss: 0.0962705\n",
      "\tspeed: 0.0487s/iter; left time: 773.1858s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870261\n",
      "\tspeed: 0.0473s/iter; left time: 746.7124s\n",
      "\titers: 600, epoch: 3 | loss: 0.0912619\n",
      "\tspeed: 0.0471s/iter; left time: 738.9021s\n",
      "\titers: 700, epoch: 3 | loss: 0.0945015\n",
      "\tspeed: 0.0482s/iter; left time: 750.6099s\n",
      "\titers: 800, epoch: 3 | loss: 0.0904101\n",
      "\tspeed: 0.0474s/iter; left time: 734.0817s\n",
      "\titers: 900, epoch: 3 | loss: 0.0849228\n",
      "\tspeed: 0.0459s/iter; left time: 705.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.0920878 Vali Loss: 0.0895598 Test Loss: 0.1295949\n",
      "Validation loss decreased (0.098526 --> 0.089560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842967\n",
      "\tspeed: 0.1262s/iter; left time: 1926.6401s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829929\n",
      "\tspeed: 0.0458s/iter; left time: 694.3825s\n",
      "\titers: 300, epoch: 4 | loss: 0.0879289\n",
      "\tspeed: 0.0486s/iter; left time: 732.9298s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827095\n",
      "\tspeed: 0.0437s/iter; left time: 654.4887s\n",
      "\titers: 500, epoch: 4 | loss: 0.0913868\n",
      "\tspeed: 0.0462s/iter; left time: 686.5412s\n",
      "\titers: 600, epoch: 4 | loss: 0.0841849\n",
      "\tspeed: 0.0395s/iter; left time: 582.7696s\n",
      "\titers: 700, epoch: 4 | loss: 0.0793578\n",
      "\tspeed: 0.0395s/iter; left time: 578.7119s\n",
      "\titers: 800, epoch: 4 | loss: 0.0784055\n",
      "\tspeed: 0.0394s/iter; left time: 573.7781s\n",
      "\titers: 900, epoch: 4 | loss: 0.0885338\n",
      "\tspeed: 0.0396s/iter; left time: 572.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.42s\n",
      "Steps: 904 | Train Loss: 0.0862932 Vali Loss: 0.0881228 Test Loss: 0.1295835\n",
      "Validation loss decreased (0.089560 --> 0.088123).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0864483\n",
      "\tspeed: 0.1246s/iter; left time: 1789.4260s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811242\n",
      "\tspeed: 0.0477s/iter; left time: 681.1017s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844520\n",
      "\tspeed: 0.0492s/iter; left time: 697.5070s\n",
      "\titers: 400, epoch: 5 | loss: 0.0801701\n",
      "\tspeed: 0.0497s/iter; left time: 699.4853s\n",
      "\titers: 500, epoch: 5 | loss: 0.0795058\n",
      "\tspeed: 0.0447s/iter; left time: 624.6874s\n",
      "\titers: 600, epoch: 5 | loss: 0.0792065\n",
      "\tspeed: 0.0460s/iter; left time: 637.8333s\n",
      "\titers: 700, epoch: 5 | loss: 0.0809612\n",
      "\tspeed: 0.0486s/iter; left time: 669.5296s\n",
      "\titers: 800, epoch: 5 | loss: 0.0837107\n",
      "\tspeed: 0.0408s/iter; left time: 556.9969s\n",
      "\titers: 900, epoch: 5 | loss: 0.0820203\n",
      "\tspeed: 0.0393s/iter; left time: 532.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 904 | Train Loss: 0.0817486 Vali Loss: 0.0859961 Test Loss: 0.1347349\n",
      "Validation loss decreased (0.088123 --> 0.085996).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0823008\n",
      "\tspeed: 0.1355s/iter; left time: 1823.9726s\n",
      "\titers: 200, epoch: 6 | loss: 0.0809554\n",
      "\tspeed: 0.0482s/iter; left time: 643.9127s\n",
      "\titers: 300, epoch: 6 | loss: 0.0802722\n",
      "\tspeed: 0.0482s/iter; left time: 639.5823s\n",
      "\titers: 400, epoch: 6 | loss: 0.0778541\n",
      "\tspeed: 0.0451s/iter; left time: 593.9421s\n",
      "\titers: 500, epoch: 6 | loss: 0.0792405\n",
      "\tspeed: 0.0395s/iter; left time: 515.3884s\n",
      "\titers: 600, epoch: 6 | loss: 0.0772906\n",
      "\tspeed: 0.0405s/iter; left time: 524.7475s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781953\n",
      "\tspeed: 0.0448s/iter; left time: 575.9904s\n",
      "\titers: 800, epoch: 6 | loss: 0.0805445\n",
      "\tspeed: 0.0466s/iter; left time: 595.1949s\n",
      "\titers: 900, epoch: 6 | loss: 0.0751942\n",
      "\tspeed: 0.0455s/iter; left time: 575.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.98s\n",
      "Steps: 904 | Train Loss: 0.0782990 Vali Loss: 0.0867788 Test Loss: 0.1433721\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756937\n",
      "\tspeed: 0.1192s/iter; left time: 1496.2755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0780173\n",
      "\tspeed: 0.0473s/iter; left time: 589.0204s\n",
      "\titers: 300, epoch: 7 | loss: 0.0782186\n",
      "\tspeed: 0.0461s/iter; left time: 569.3580s\n",
      "\titers: 400, epoch: 7 | loss: 0.0780234\n",
      "\tspeed: 0.0494s/iter; left time: 605.4380s\n",
      "\titers: 500, epoch: 7 | loss: 0.0733429\n",
      "\tspeed: 0.0497s/iter; left time: 604.7322s\n",
      "\titers: 600, epoch: 7 | loss: 0.0655437\n",
      "\tspeed: 0.0467s/iter; left time: 563.6244s\n",
      "\titers: 700, epoch: 7 | loss: 0.0745077\n",
      "\tspeed: 0.0454s/iter; left time: 542.5678s\n",
      "\titers: 800, epoch: 7 | loss: 0.0771893\n",
      "\tspeed: 0.0444s/iter; left time: 526.2926s\n",
      "\titers: 900, epoch: 7 | loss: 0.0747498\n",
      "\tspeed: 0.0488s/iter; left time: 574.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.04s\n",
      "Steps: 904 | Train Loss: 0.0750828 Vali Loss: 0.0865508 Test Loss: 0.1437815\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0779755\n",
      "\tspeed: 0.1184s/iter; left time: 1379.1875s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732990\n",
      "\tspeed: 0.0487s/iter; left time: 562.9374s\n",
      "\titers: 300, epoch: 8 | loss: 0.0715991\n",
      "\tspeed: 0.0461s/iter; left time: 527.4743s\n",
      "\titers: 400, epoch: 8 | loss: 0.0711120\n",
      "\tspeed: 0.0475s/iter; left time: 539.0710s\n",
      "\titers: 500, epoch: 8 | loss: 0.0711963\n",
      "\tspeed: 0.0470s/iter; left time: 528.7458s\n",
      "\titers: 600, epoch: 8 | loss: 0.0720228\n",
      "\tspeed: 0.0488s/iter; left time: 543.8609s\n",
      "\titers: 700, epoch: 8 | loss: 0.0637291\n",
      "\tspeed: 0.0483s/iter; left time: 534.1236s\n",
      "\titers: 800, epoch: 8 | loss: 0.0720645\n",
      "\tspeed: 0.0468s/iter; left time: 512.2591s\n",
      "\titers: 900, epoch: 8 | loss: 0.0679686\n",
      "\tspeed: 0.0459s/iter; left time: 498.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0717168 Vali Loss: 0.0864078 Test Loss: 0.1496538\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685663\n",
      "\tspeed: 0.1174s/iter; left time: 1261.8858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717570\n",
      "\tspeed: 0.0485s/iter; left time: 516.6176s\n",
      "\titers: 300, epoch: 9 | loss: 0.0695549\n",
      "\tspeed: 0.0476s/iter; left time: 501.6224s\n",
      "\titers: 400, epoch: 9 | loss: 0.0646989\n",
      "\tspeed: 0.0437s/iter; left time: 456.6713s\n",
      "\titers: 500, epoch: 9 | loss: 0.0739497\n",
      "\tspeed: 0.0463s/iter; left time: 478.8910s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717835\n",
      "\tspeed: 0.0474s/iter; left time: 485.9519s\n",
      "\titers: 700, epoch: 9 | loss: 0.0680621\n",
      "\tspeed: 0.0490s/iter; left time: 497.0983s\n",
      "\titers: 800, epoch: 9 | loss: 0.0682900\n",
      "\tspeed: 0.0492s/iter; left time: 494.7125s\n",
      "\titers: 900, epoch: 9 | loss: 0.0699611\n",
      "\tspeed: 0.0483s/iter; left time: 480.8239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.0691861 Vali Loss: 0.0879675 Test Loss: 0.1634988\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669832\n",
      "\tspeed: 0.1221s/iter; left time: 1202.3295s\n",
      "\titers: 200, epoch: 10 | loss: 0.0653438\n",
      "\tspeed: 0.0483s/iter; left time: 470.2072s\n",
      "\titers: 300, epoch: 10 | loss: 0.0653087\n",
      "\tspeed: 0.0454s/iter; left time: 438.3002s\n",
      "\titers: 400, epoch: 10 | loss: 0.0681388\n",
      "\tspeed: 0.0458s/iter; left time: 436.9722s\n",
      "\titers: 500, epoch: 10 | loss: 0.0653993\n",
      "\tspeed: 0.0474s/iter; left time: 447.6120s\n",
      "\titers: 600, epoch: 10 | loss: 0.0670908\n",
      "\tspeed: 0.0473s/iter; left time: 441.5982s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699330\n",
      "\tspeed: 0.0449s/iter; left time: 414.8412s\n",
      "\titers: 800, epoch: 10 | loss: 0.0599767\n",
      "\tspeed: 0.0473s/iter; left time: 432.6973s\n",
      "\titers: 900, epoch: 10 | loss: 0.0634191\n",
      "\tspeed: 0.0481s/iter; left time: 435.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.0664865 Vali Loss: 0.0859074 Test Loss: 0.1562858\n",
      "Validation loss decreased (0.085996 --> 0.085907).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657937\n",
      "\tspeed: 0.1283s/iter; left time: 1146.9509s\n",
      "\titers: 200, epoch: 11 | loss: 0.0644366\n",
      "\tspeed: 0.0497s/iter; left time: 439.1246s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647984\n",
      "\tspeed: 0.0504s/iter; left time: 440.3506s\n",
      "\titers: 400, epoch: 11 | loss: 0.0712598\n",
      "\tspeed: 0.0504s/iter; left time: 435.4275s\n",
      "\titers: 500, epoch: 11 | loss: 0.0661000\n",
      "\tspeed: 0.0480s/iter; left time: 409.7563s\n",
      "\titers: 600, epoch: 11 | loss: 0.0673678\n",
      "\tspeed: 0.0489s/iter; left time: 412.8401s\n",
      "\titers: 700, epoch: 11 | loss: 0.0654028\n",
      "\tspeed: 0.0471s/iter; left time: 392.8196s\n",
      "\titers: 800, epoch: 11 | loss: 0.0609792\n",
      "\tspeed: 0.0482s/iter; left time: 396.8505s\n",
      "\titers: 900, epoch: 11 | loss: 0.0600154\n",
      "\tspeed: 0.0423s/iter; left time: 344.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.82s\n",
      "Steps: 904 | Train Loss: 0.0644636 Vali Loss: 0.0866142 Test Loss: 0.1615575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583775\n",
      "\tspeed: 0.1204s/iter; left time: 967.7340s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650353\n",
      "\tspeed: 0.0505s/iter; left time: 400.7761s\n",
      "\titers: 300, epoch: 12 | loss: 0.0610544\n",
      "\tspeed: 0.0496s/iter; left time: 388.4153s\n",
      "\titers: 400, epoch: 12 | loss: 0.0564006\n",
      "\tspeed: 0.0481s/iter; left time: 372.0864s\n",
      "\titers: 500, epoch: 12 | loss: 0.0640808\n",
      "\tspeed: 0.0493s/iter; left time: 376.1323s\n",
      "\titers: 600, epoch: 12 | loss: 0.0569968\n",
      "\tspeed: 0.0485s/iter; left time: 365.4635s\n",
      "\titers: 700, epoch: 12 | loss: 0.0635740\n",
      "\tspeed: 0.0481s/iter; left time: 357.8909s\n",
      "\titers: 800, epoch: 12 | loss: 0.0614182\n",
      "\tspeed: 0.0479s/iter; left time: 351.5626s\n",
      "\titers: 900, epoch: 12 | loss: 0.0595840\n",
      "\tspeed: 0.0465s/iter; left time: 336.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 904 | Train Loss: 0.0623148 Vali Loss: 0.0865320 Test Loss: 0.1586662\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0612977\n",
      "\tspeed: 0.1180s/iter; left time: 841.9289s\n",
      "\titers: 200, epoch: 13 | loss: 0.0587642\n",
      "\tspeed: 0.0479s/iter; left time: 336.9320s\n",
      "\titers: 300, epoch: 13 | loss: 0.0563776\n",
      "\tspeed: 0.0487s/iter; left time: 337.8501s\n",
      "\titers: 400, epoch: 13 | loss: 0.0562836\n",
      "\tspeed: 0.0428s/iter; left time: 292.3383s\n",
      "\titers: 500, epoch: 13 | loss: 0.0634416\n",
      "\tspeed: 0.0477s/iter; left time: 320.9856s\n",
      "\titers: 600, epoch: 13 | loss: 0.0640421\n",
      "\tspeed: 0.0471s/iter; left time: 312.0883s\n",
      "\titers: 700, epoch: 13 | loss: 0.0602080\n",
      "\tspeed: 0.0476s/iter; left time: 310.6758s\n",
      "\titers: 800, epoch: 13 | loss: 0.0640807\n",
      "\tspeed: 0.0480s/iter; left time: 308.8975s\n",
      "\titers: 900, epoch: 13 | loss: 0.0604606\n",
      "\tspeed: 0.0470s/iter; left time: 297.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.79s\n",
      "Steps: 904 | Train Loss: 0.0603249 Vali Loss: 0.0876123 Test Loss: 0.1657297\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0609293\n",
      "\tspeed: 0.1219s/iter; left time: 759.5451s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600787\n",
      "\tspeed: 0.0500s/iter; left time: 306.4939s\n",
      "\titers: 300, epoch: 14 | loss: 0.0579149\n",
      "\tspeed: 0.0495s/iter; left time: 298.2846s\n",
      "\titers: 400, epoch: 14 | loss: 0.0552511\n",
      "\tspeed: 0.0483s/iter; left time: 286.3759s\n",
      "\titers: 500, epoch: 14 | loss: 0.0606611\n",
      "\tspeed: 0.0468s/iter; left time: 272.5752s\n",
      "\titers: 600, epoch: 14 | loss: 0.0585283\n",
      "\tspeed: 0.0475s/iter; left time: 272.0598s\n",
      "\titers: 700, epoch: 14 | loss: 0.0589618\n",
      "\tspeed: 0.0483s/iter; left time: 271.7281s\n",
      "\titers: 800, epoch: 14 | loss: 0.0589674\n",
      "\tspeed: 0.0461s/iter; left time: 254.7387s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592620\n",
      "\tspeed: 0.0471s/iter; left time: 255.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:43.80s\n",
      "Steps: 904 | Train Loss: 0.0586510 Vali Loss: 0.0880812 Test Loss: 0.1672379\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0616658\n",
      "\tspeed: 0.1191s/iter; left time: 634.1412s\n",
      "\titers: 200, epoch: 15 | loss: 0.0599181\n",
      "\tspeed: 0.0488s/iter; left time: 254.9005s\n",
      "\titers: 300, epoch: 15 | loss: 0.0558654\n",
      "\tspeed: 0.0466s/iter; left time: 238.9213s\n",
      "\titers: 400, epoch: 15 | loss: 0.0597988\n",
      "\tspeed: 0.0474s/iter; left time: 237.9652s\n",
      "\titers: 500, epoch: 15 | loss: 0.0576043\n",
      "\tspeed: 0.0451s/iter; left time: 222.1081s\n",
      "\titers: 600, epoch: 15 | loss: 0.0592206\n",
      "\tspeed: 0.0479s/iter; left time: 231.2219s\n",
      "\titers: 700, epoch: 15 | loss: 0.0582772\n",
      "\tspeed: 0.0463s/iter; left time: 218.8288s\n",
      "\titers: 800, epoch: 15 | loss: 0.0593535\n",
      "\tspeed: 0.0487s/iter; left time: 225.1337s\n",
      "\titers: 900, epoch: 15 | loss: 0.0618834\n",
      "\tspeed: 0.0499s/iter; left time: 225.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.0570594 Vali Loss: 0.0870935 Test Loss: 0.1662657\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0621136911213398, rmse:0.2492261826992035, mae:0.1562231183052063, rse:0.7321515083312988\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2404172\n",
      "\tspeed: 0.0508s/iter; left time: 913.9292s\n",
      "\titers: 200, epoch: 1 | loss: 0.2201424\n",
      "\tspeed: 0.0500s/iter; left time: 893.3608s\n",
      "\titers: 300, epoch: 1 | loss: 0.2063731\n",
      "\tspeed: 0.0475s/iter; left time: 845.1072s\n",
      "\titers: 400, epoch: 1 | loss: 0.2057976\n",
      "\tspeed: 0.0489s/iter; left time: 864.5590s\n",
      "\titers: 500, epoch: 1 | loss: 0.2004143\n",
      "\tspeed: 0.0443s/iter; left time: 778.8122s\n",
      "\titers: 600, epoch: 1 | loss: 0.2004972\n",
      "\tspeed: 0.0475s/iter; left time: 830.1881s\n",
      "\titers: 700, epoch: 1 | loss: 0.1928217\n",
      "\tspeed: 0.0473s/iter; left time: 822.9813s\n",
      "\titers: 800, epoch: 1 | loss: 0.1905690\n",
      "\tspeed: 0.0477s/iter; left time: 825.0824s\n",
      "\titers: 900, epoch: 1 | loss: 0.1725994\n",
      "\tspeed: 0.0492s/iter; left time: 844.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.59s\n",
      "Steps: 904 | Train Loss: 0.2077810 Vali Loss: 0.1732043 Test Loss: 0.2144032\n",
      "Validation loss decreased (inf --> 0.173204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501734\n",
      "\tspeed: 0.1329s/iter; left time: 2268.8013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1352457\n",
      "\tspeed: 0.0497s/iter; left time: 843.4716s\n",
      "\titers: 300, epoch: 2 | loss: 0.1314882\n",
      "\tspeed: 0.0483s/iter; left time: 815.3808s\n",
      "\titers: 400, epoch: 2 | loss: 0.1208705\n",
      "\tspeed: 0.0478s/iter; left time: 801.2522s\n",
      "\titers: 500, epoch: 2 | loss: 0.1158073\n",
      "\tspeed: 0.0495s/iter; left time: 825.0634s\n",
      "\titers: 600, epoch: 2 | loss: 0.1148969\n",
      "\tspeed: 0.0457s/iter; left time: 757.8738s\n",
      "\titers: 700, epoch: 2 | loss: 0.0997682\n",
      "\tspeed: 0.0474s/iter; left time: 780.2948s\n",
      "\titers: 800, epoch: 2 | loss: 0.1034051\n",
      "\tspeed: 0.0504s/iter; left time: 824.7030s\n",
      "\titers: 900, epoch: 2 | loss: 0.0903369\n",
      "\tspeed: 0.0496s/iter; left time: 807.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.29s\n",
      "Steps: 904 | Train Loss: 0.1209288 Vali Loss: 0.0963794 Test Loss: 0.1371179\n",
      "Validation loss decreased (0.173204 --> 0.096379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0935780\n",
      "\tspeed: 0.1246s/iter; left time: 2015.7357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927026\n",
      "\tspeed: 0.0456s/iter; left time: 733.2501s\n",
      "\titers: 300, epoch: 3 | loss: 0.1050145\n",
      "\tspeed: 0.0483s/iter; left time: 771.1490s\n",
      "\titers: 400, epoch: 3 | loss: 0.0948645\n",
      "\tspeed: 0.0491s/iter; left time: 779.8359s\n",
      "\titers: 500, epoch: 3 | loss: 0.0827705\n",
      "\tspeed: 0.0498s/iter; left time: 785.2940s\n",
      "\titers: 600, epoch: 3 | loss: 0.0837813\n",
      "\tspeed: 0.0500s/iter; left time: 783.8900s\n",
      "\titers: 700, epoch: 3 | loss: 0.0890595\n",
      "\tspeed: 0.0450s/iter; left time: 700.7420s\n",
      "\titers: 800, epoch: 3 | loss: 0.0927761\n",
      "\tspeed: 0.0471s/iter; left time: 728.5241s\n",
      "\titers: 900, epoch: 3 | loss: 0.0832633\n",
      "\tspeed: 0.0483s/iter; left time: 742.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.69s\n",
      "Steps: 904 | Train Loss: 0.0918153 Vali Loss: 0.0892233 Test Loss: 0.1335807\n",
      "Validation loss decreased (0.096379 --> 0.089223).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0909086\n",
      "\tspeed: 0.1321s/iter; left time: 2016.5528s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835494\n",
      "\tspeed: 0.0475s/iter; left time: 719.9020s\n",
      "\titers: 300, epoch: 4 | loss: 0.0839262\n",
      "\tspeed: 0.0461s/iter; left time: 695.2990s\n",
      "\titers: 400, epoch: 4 | loss: 0.0796652\n",
      "\tspeed: 0.0498s/iter; left time: 744.9434s\n",
      "\titers: 500, epoch: 4 | loss: 0.0784578\n",
      "\tspeed: 0.0496s/iter; left time: 737.6688s\n",
      "\titers: 600, epoch: 4 | loss: 0.0873888\n",
      "\tspeed: 0.0484s/iter; left time: 715.3901s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838238\n",
      "\tspeed: 0.0466s/iter; left time: 683.0229s\n",
      "\titers: 800, epoch: 4 | loss: 0.0810640\n",
      "\tspeed: 0.0448s/iter; left time: 652.5258s\n",
      "\titers: 900, epoch: 4 | loss: 0.0828189\n",
      "\tspeed: 0.0458s/iter; left time: 662.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.0853449 Vali Loss: 0.0901499 Test Loss: 0.1362802\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844502\n",
      "\tspeed: 0.1213s/iter; left time: 1742.0014s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893857\n",
      "\tspeed: 0.0490s/iter; left time: 698.6678s\n",
      "\titers: 300, epoch: 5 | loss: 0.0784553\n",
      "\tspeed: 0.0453s/iter; left time: 641.0197s\n",
      "\titers: 400, epoch: 5 | loss: 0.0792715\n",
      "\tspeed: 0.0484s/iter; left time: 680.5353s\n",
      "\titers: 500, epoch: 5 | loss: 0.0742564\n",
      "\tspeed: 0.0474s/iter; left time: 662.1011s\n",
      "\titers: 600, epoch: 5 | loss: 0.0751548\n",
      "\tspeed: 0.0501s/iter; left time: 693.9776s\n",
      "\titers: 700, epoch: 5 | loss: 0.0851703\n",
      "\tspeed: 0.0410s/iter; left time: 564.2893s\n",
      "\titers: 800, epoch: 5 | loss: 0.0861519\n",
      "\tspeed: 0.0397s/iter; left time: 543.1437s\n",
      "\titers: 900, epoch: 5 | loss: 0.0877003\n",
      "\tspeed: 0.0428s/iter; left time: 580.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.0810769 Vali Loss: 0.0892295 Test Loss: 0.1417478\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809330\n",
      "\tspeed: 0.1186s/iter; left time: 1596.8832s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795789\n",
      "\tspeed: 0.0495s/iter; left time: 660.7492s\n",
      "\titers: 300, epoch: 6 | loss: 0.0735987\n",
      "\tspeed: 0.0505s/iter; left time: 669.4897s\n",
      "\titers: 400, epoch: 6 | loss: 0.0762497\n",
      "\tspeed: 0.0465s/iter; left time: 611.6702s\n",
      "\titers: 500, epoch: 6 | loss: 0.0729858\n",
      "\tspeed: 0.0456s/iter; left time: 596.0373s\n",
      "\titers: 600, epoch: 6 | loss: 0.0770677\n",
      "\tspeed: 0.0473s/iter; left time: 613.5428s\n",
      "\titers: 700, epoch: 6 | loss: 0.0758942\n",
      "\tspeed: 0.0501s/iter; left time: 644.3161s\n",
      "\titers: 800, epoch: 6 | loss: 0.0780751\n",
      "\tspeed: 0.0503s/iter; left time: 641.8302s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726726\n",
      "\tspeed: 0.0497s/iter; left time: 629.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.01s\n",
      "Steps: 904 | Train Loss: 0.0771611 Vali Loss: 0.0849141 Test Loss: 0.1407367\n",
      "Validation loss decreased (0.089223 --> 0.084914).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0729787\n",
      "\tspeed: 0.1238s/iter; left time: 1554.0443s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727771\n",
      "\tspeed: 0.0474s/iter; left time: 591.0820s\n",
      "\titers: 300, epoch: 7 | loss: 0.0745202\n",
      "\tspeed: 0.0481s/iter; left time: 594.6845s\n",
      "\titers: 400, epoch: 7 | loss: 0.0725877\n",
      "\tspeed: 0.0472s/iter; left time: 578.6928s\n",
      "\titers: 500, epoch: 7 | loss: 0.0691659\n",
      "\tspeed: 0.0467s/iter; left time: 567.4676s\n",
      "\titers: 600, epoch: 7 | loss: 0.0758437\n",
      "\tspeed: 0.0482s/iter; left time: 581.7008s\n",
      "\titers: 700, epoch: 7 | loss: 0.0709473\n",
      "\tspeed: 0.0444s/iter; left time: 531.4752s\n",
      "\titers: 800, epoch: 7 | loss: 0.0694657\n",
      "\tspeed: 0.0500s/iter; left time: 592.6362s\n",
      "\titers: 900, epoch: 7 | loss: 0.0726918\n",
      "\tspeed: 0.0505s/iter; left time: 594.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.64s\n",
      "Steps: 904 | Train Loss: 0.0737538 Vali Loss: 0.0846094 Test Loss: 0.1517563\n",
      "Validation loss decreased (0.084914 --> 0.084609).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781815\n",
      "\tspeed: 0.1233s/iter; left time: 1437.1645s\n",
      "\titers: 200, epoch: 8 | loss: 0.0669782\n",
      "\tspeed: 0.0504s/iter; left time: 582.3222s\n",
      "\titers: 300, epoch: 8 | loss: 0.0750756\n",
      "\tspeed: 0.0468s/iter; left time: 536.3345s\n",
      "\titers: 400, epoch: 8 | loss: 0.0724268\n",
      "\tspeed: 0.0439s/iter; left time: 498.6732s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750967\n",
      "\tspeed: 0.0450s/iter; left time: 505.9207s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727142\n",
      "\tspeed: 0.0468s/iter; left time: 521.5234s\n",
      "\titers: 700, epoch: 8 | loss: 0.0646042\n",
      "\tspeed: 0.0450s/iter; left time: 497.8523s\n",
      "\titers: 800, epoch: 8 | loss: 0.0693420\n",
      "\tspeed: 0.0460s/iter; left time: 503.6784s\n",
      "\titers: 900, epoch: 8 | loss: 0.0620706\n",
      "\tspeed: 0.0454s/iter; left time: 493.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.07s\n",
      "Steps: 904 | Train Loss: 0.0709016 Vali Loss: 0.0847298 Test Loss: 0.1540082\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0625846\n",
      "\tspeed: 0.1172s/iter; left time: 1259.7979s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698348\n",
      "\tspeed: 0.0455s/iter; left time: 484.1328s\n",
      "\titers: 300, epoch: 9 | loss: 0.0620178\n",
      "\tspeed: 0.0457s/iter; left time: 481.6099s\n",
      "\titers: 400, epoch: 9 | loss: 0.0690884\n",
      "\tspeed: 0.0448s/iter; left time: 467.9445s\n",
      "\titers: 500, epoch: 9 | loss: 0.0693989\n",
      "\tspeed: 0.0459s/iter; left time: 474.9093s\n",
      "\titers: 600, epoch: 9 | loss: 0.0746084\n",
      "\tspeed: 0.0454s/iter; left time: 465.4534s\n",
      "\titers: 700, epoch: 9 | loss: 0.0681551\n",
      "\tspeed: 0.0453s/iter; left time: 460.0933s\n",
      "\titers: 800, epoch: 9 | loss: 0.0686809\n",
      "\tspeed: 0.0398s/iter; left time: 399.6938s\n",
      "\titers: 900, epoch: 9 | loss: 0.0648397\n",
      "\tspeed: 0.0433s/iter; left time: 431.2835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.52s\n",
      "Steps: 904 | Train Loss: 0.0681101 Vali Loss: 0.0869950 Test Loss: 0.1493889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710971\n",
      "\tspeed: 0.1160s/iter; left time: 1142.0457s\n",
      "\titers: 200, epoch: 10 | loss: 0.0607016\n",
      "\tspeed: 0.0465s/iter; left time: 453.6124s\n",
      "\titers: 300, epoch: 10 | loss: 0.0663983\n",
      "\tspeed: 0.0467s/iter; left time: 449.9981s\n",
      "\titers: 400, epoch: 10 | loss: 0.0653817\n",
      "\tspeed: 0.0447s/iter; left time: 426.2831s\n",
      "\titers: 500, epoch: 10 | loss: 0.0647618\n",
      "\tspeed: 0.0442s/iter; left time: 417.4412s\n",
      "\titers: 600, epoch: 10 | loss: 0.0653631\n",
      "\tspeed: 0.0458s/iter; left time: 427.6832s\n",
      "\titers: 700, epoch: 10 | loss: 0.0635928\n",
      "\tspeed: 0.0459s/iter; left time: 424.1940s\n",
      "\titers: 800, epoch: 10 | loss: 0.0676852\n",
      "\tspeed: 0.0459s/iter; left time: 419.4088s\n",
      "\titers: 900, epoch: 10 | loss: 0.0719308\n",
      "\tspeed: 0.0475s/iter; left time: 429.7810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 904 | Train Loss: 0.0651464 Vali Loss: 0.0863084 Test Loss: 0.1573102\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622910\n",
      "\tspeed: 0.1207s/iter; left time: 1079.2014s\n",
      "\titers: 200, epoch: 11 | loss: 0.0615052\n",
      "\tspeed: 0.0456s/iter; left time: 403.4911s\n",
      "\titers: 300, epoch: 11 | loss: 0.0616270\n",
      "\tspeed: 0.0452s/iter; left time: 394.9188s\n",
      "\titers: 400, epoch: 11 | loss: 0.0629679\n",
      "\tspeed: 0.0413s/iter; left time: 357.0123s\n",
      "\titers: 500, epoch: 11 | loss: 0.0645794\n",
      "\tspeed: 0.0405s/iter; left time: 345.6662s\n",
      "\titers: 600, epoch: 11 | loss: 0.0598391\n",
      "\tspeed: 0.0454s/iter; left time: 383.6152s\n",
      "\titers: 700, epoch: 11 | loss: 0.0596024\n",
      "\tspeed: 0.0470s/iter; left time: 391.7359s\n",
      "\titers: 800, epoch: 11 | loss: 0.0642787\n",
      "\tspeed: 0.0483s/iter; left time: 397.8913s\n",
      "\titers: 900, epoch: 11 | loss: 0.0582848\n",
      "\tspeed: 0.0461s/iter; left time: 375.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.25s\n",
      "Steps: 904 | Train Loss: 0.0629357 Vali Loss: 0.0862783 Test Loss: 0.1557319\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594919\n",
      "\tspeed: 0.1184s/iter; left time: 951.8482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594223\n",
      "\tspeed: 0.0448s/iter; left time: 355.9143s\n",
      "\titers: 300, epoch: 12 | loss: 0.0616208\n",
      "\tspeed: 0.0469s/iter; left time: 367.9016s\n",
      "\titers: 400, epoch: 12 | loss: 0.0625487\n",
      "\tspeed: 0.0469s/iter; left time: 362.6668s\n",
      "\titers: 500, epoch: 12 | loss: 0.0591396\n",
      "\tspeed: 0.0444s/iter; left time: 339.0964s\n",
      "\titers: 600, epoch: 12 | loss: 0.0629145\n",
      "\tspeed: 0.0453s/iter; left time: 341.5741s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644609\n",
      "\tspeed: 0.0478s/iter; left time: 355.7781s\n",
      "\titers: 800, epoch: 12 | loss: 0.0662911\n",
      "\tspeed: 0.0499s/iter; left time: 366.0103s\n",
      "\titers: 900, epoch: 12 | loss: 0.0599037\n",
      "\tspeed: 0.0466s/iter; left time: 337.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 904 | Train Loss: 0.0606856 Vali Loss: 0.0858058 Test Loss: 0.1528269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05941867083311081, rmse:0.24375945329666138, mae:0.15178018808364868, rse:0.7160918712615967\n",
      "Intermediate time for ES and pred_len 96: 00h:22m:42.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2494293\n",
      "\tspeed: 0.0790s/iter; left time: 1417.6897s\n",
      "\titers: 200, epoch: 1 | loss: 0.2181168\n",
      "\tspeed: 0.0529s/iter; left time: 943.1981s\n",
      "\titers: 300, epoch: 1 | loss: 0.2107528\n",
      "\tspeed: 0.0510s/iter; left time: 904.6344s\n",
      "\titers: 400, epoch: 1 | loss: 0.2044485\n",
      "\tspeed: 0.0520s/iter; left time: 917.1043s\n",
      "\titers: 500, epoch: 1 | loss: 0.1976297\n",
      "\tspeed: 0.0502s/iter; left time: 880.4663s\n",
      "\titers: 600, epoch: 1 | loss: 0.1977707\n",
      "\tspeed: 0.0521s/iter; left time: 908.0073s\n",
      "\titers: 700, epoch: 1 | loss: 0.1934083\n",
      "\tspeed: 0.0551s/iter; left time: 955.8418s\n",
      "\titers: 800, epoch: 1 | loss: 0.1834540\n",
      "\tspeed: 0.0545s/iter; left time: 940.1561s\n",
      "\titers: 900, epoch: 1 | loss: 0.1815212\n",
      "\tspeed: 0.0531s/iter; left time: 909.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.2080731 Vali Loss: 0.1811913 Test Loss: 0.2210122\n",
      "Validation loss decreased (inf --> 0.181191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645532\n",
      "\tspeed: 0.1426s/iter; left time: 2430.1129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1557363\n",
      "\tspeed: 0.0522s/iter; left time: 883.4765s\n",
      "\titers: 300, epoch: 2 | loss: 0.1507612\n",
      "\tspeed: 0.0512s/iter; left time: 862.5728s\n",
      "\titers: 400, epoch: 2 | loss: 0.1327350\n",
      "\tspeed: 0.0512s/iter; left time: 857.6313s\n",
      "\titers: 500, epoch: 2 | loss: 0.1191086\n",
      "\tspeed: 0.0503s/iter; left time: 837.0511s\n",
      "\titers: 600, epoch: 2 | loss: 0.1147511\n",
      "\tspeed: 0.0518s/iter; left time: 856.4008s\n",
      "\titers: 700, epoch: 2 | loss: 0.1073123\n",
      "\tspeed: 0.0517s/iter; left time: 850.6455s\n",
      "\titers: 800, epoch: 2 | loss: 0.1038416\n",
      "\tspeed: 0.0514s/iter; left time: 839.6568s\n",
      "\titers: 900, epoch: 2 | loss: 0.0993121\n",
      "\tspeed: 0.0532s/iter; left time: 863.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 902 | Train Loss: 0.1322833 Vali Loss: 0.1038791 Test Loss: 0.1466250\n",
      "Validation loss decreased (0.181191 --> 0.103879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1026798\n",
      "\tspeed: 0.1504s/iter; left time: 2426.6763s\n",
      "\titers: 200, epoch: 3 | loss: 0.0970726\n",
      "\tspeed: 0.0525s/iter; left time: 841.8991s\n",
      "\titers: 300, epoch: 3 | loss: 0.0917688\n",
      "\tspeed: 0.0514s/iter; left time: 819.9162s\n",
      "\titers: 400, epoch: 3 | loss: 0.0928012\n",
      "\tspeed: 0.0531s/iter; left time: 841.5559s\n",
      "\titers: 500, epoch: 3 | loss: 0.0957348\n",
      "\tspeed: 0.0522s/iter; left time: 821.3519s\n",
      "\titers: 600, epoch: 3 | loss: 0.1012272\n",
      "\tspeed: 0.0534s/iter; left time: 834.7320s\n",
      "\titers: 700, epoch: 3 | loss: 0.0967861\n",
      "\tspeed: 0.0529s/iter; left time: 821.2245s\n",
      "\titers: 800, epoch: 3 | loss: 0.0937926\n",
      "\tspeed: 0.0534s/iter; left time: 824.6520s\n",
      "\titers: 900, epoch: 3 | loss: 0.0936729\n",
      "\tspeed: 0.0522s/iter; left time: 801.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.0974400 Vali Loss: 0.0987192 Test Loss: 0.1403093\n",
      "Validation loss decreased (0.103879 --> 0.098719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0929292\n",
      "\tspeed: 0.1488s/iter; left time: 2266.4498s\n",
      "\titers: 200, epoch: 4 | loss: 0.0965619\n",
      "\tspeed: 0.0545s/iter; left time: 825.5336s\n",
      "\titers: 300, epoch: 4 | loss: 0.0898032\n",
      "\tspeed: 0.0524s/iter; left time: 788.0433s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937172\n",
      "\tspeed: 0.0534s/iter; left time: 797.4721s\n",
      "\titers: 500, epoch: 4 | loss: 0.0906779\n",
      "\tspeed: 0.0514s/iter; left time: 762.4537s\n",
      "\titers: 600, epoch: 4 | loss: 0.0879486\n",
      "\tspeed: 0.0524s/iter; left time: 772.0911s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877434\n",
      "\tspeed: 0.0526s/iter; left time: 769.7305s\n",
      "\titers: 800, epoch: 4 | loss: 0.0960336\n",
      "\tspeed: 0.0529s/iter; left time: 768.7060s\n",
      "\titers: 900, epoch: 4 | loss: 0.0904689\n",
      "\tspeed: 0.0516s/iter; left time: 744.6675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0913474 Vali Loss: 0.0929738 Test Loss: 0.1350355\n",
      "Validation loss decreased (0.098719 --> 0.092974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862888\n",
      "\tspeed: 0.1511s/iter; left time: 2165.2130s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853113\n",
      "\tspeed: 0.0511s/iter; left time: 727.3395s\n",
      "\titers: 300, epoch: 5 | loss: 0.0885890\n",
      "\tspeed: 0.0517s/iter; left time: 731.1419s\n",
      "\titers: 400, epoch: 5 | loss: 0.0850736\n",
      "\tspeed: 0.0519s/iter; left time: 728.7964s\n",
      "\titers: 500, epoch: 5 | loss: 0.0858059\n",
      "\tspeed: 0.0524s/iter; left time: 729.9799s\n",
      "\titers: 600, epoch: 5 | loss: 0.0846744\n",
      "\tspeed: 0.0512s/iter; left time: 707.6701s\n",
      "\titers: 700, epoch: 5 | loss: 0.0864810\n",
      "\tspeed: 0.0521s/iter; left time: 715.2550s\n",
      "\titers: 800, epoch: 5 | loss: 0.0868695\n",
      "\tspeed: 0.0525s/iter; left time: 715.1709s\n",
      "\titers: 900, epoch: 5 | loss: 0.0815381\n",
      "\tspeed: 0.0511s/iter; left time: 691.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 902 | Train Loss: 0.0866137 Vali Loss: 0.0950143 Test Loss: 0.1459457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0885002\n",
      "\tspeed: 0.1449s/iter; left time: 1946.3835s\n",
      "\titers: 200, epoch: 6 | loss: 0.0887537\n",
      "\tspeed: 0.0533s/iter; left time: 710.1734s\n",
      "\titers: 300, epoch: 6 | loss: 0.0861426\n",
      "\tspeed: 0.0537s/iter; left time: 710.5378s\n",
      "\titers: 400, epoch: 6 | loss: 0.0801997\n",
      "\tspeed: 0.0547s/iter; left time: 717.9256s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807461\n",
      "\tspeed: 0.0547s/iter; left time: 712.1461s\n",
      "\titers: 600, epoch: 6 | loss: 0.0818900\n",
      "\tspeed: 0.0542s/iter; left time: 701.1401s\n",
      "\titers: 700, epoch: 6 | loss: 0.0835803\n",
      "\tspeed: 0.0537s/iter; left time: 688.4465s\n",
      "\titers: 800, epoch: 6 | loss: 0.0846795\n",
      "\tspeed: 0.0515s/iter; left time: 655.2319s\n",
      "\titers: 900, epoch: 6 | loss: 0.0825628\n",
      "\tspeed: 0.0530s/iter; left time: 668.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.0825070 Vali Loss: 0.0925536 Test Loss: 0.1536084\n",
      "Validation loss decreased (0.092974 --> 0.092554).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785005\n",
      "\tspeed: 0.1469s/iter; left time: 1840.4137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756859\n",
      "\tspeed: 0.0545s/iter; left time: 677.7375s\n",
      "\titers: 300, epoch: 7 | loss: 0.0790050\n",
      "\tspeed: 0.0526s/iter; left time: 647.9304s\n",
      "\titers: 400, epoch: 7 | loss: 0.0765400\n",
      "\tspeed: 0.0532s/iter; left time: 650.0600s\n",
      "\titers: 500, epoch: 7 | loss: 0.0782865\n",
      "\tspeed: 0.0583s/iter; left time: 707.2088s\n",
      "\titers: 600, epoch: 7 | loss: 0.0761877\n",
      "\tspeed: 0.0555s/iter; left time: 667.4252s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772740\n",
      "\tspeed: 0.0558s/iter; left time: 665.3745s\n",
      "\titers: 800, epoch: 7 | loss: 0.0769790\n",
      "\tspeed: 0.0545s/iter; left time: 644.1345s\n",
      "\titers: 900, epoch: 7 | loss: 0.0764078\n",
      "\tspeed: 0.0549s/iter; left time: 643.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.52s\n",
      "Steps: 902 | Train Loss: 0.0786847 Vali Loss: 0.0959039 Test Loss: 0.1605772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771067\n",
      "\tspeed: 0.1438s/iter; left time: 1672.5169s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762483\n",
      "\tspeed: 0.0549s/iter; left time: 633.2333s\n",
      "\titers: 300, epoch: 8 | loss: 0.0753533\n",
      "\tspeed: 0.0553s/iter; left time: 631.6388s\n",
      "\titers: 400, epoch: 8 | loss: 0.0804044\n",
      "\tspeed: 0.0548s/iter; left time: 620.5940s\n",
      "\titers: 500, epoch: 8 | loss: 0.0772283\n",
      "\tspeed: 0.0555s/iter; left time: 623.1537s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727716\n",
      "\tspeed: 0.0544s/iter; left time: 605.8202s\n",
      "\titers: 700, epoch: 8 | loss: 0.0719767\n",
      "\tspeed: 0.0533s/iter; left time: 587.3938s\n",
      "\titers: 800, epoch: 8 | loss: 0.0737946\n",
      "\tspeed: 0.0533s/iter; left time: 581.8642s\n",
      "\titers: 900, epoch: 8 | loss: 0.0697558\n",
      "\tspeed: 0.0539s/iter; left time: 583.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.34s\n",
      "Steps: 902 | Train Loss: 0.0752117 Vali Loss: 0.0952677 Test Loss: 0.1705816\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0707476\n",
      "\tspeed: 0.1490s/iter; left time: 1598.4772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711046\n",
      "\tspeed: 0.0528s/iter; left time: 560.7472s\n",
      "\titers: 300, epoch: 9 | loss: 0.0731578\n",
      "\tspeed: 0.0540s/iter; left time: 568.1655s\n",
      "\titers: 400, epoch: 9 | loss: 0.0743887\n",
      "\tspeed: 0.0551s/iter; left time: 573.9173s\n",
      "\titers: 500, epoch: 9 | loss: 0.0720469\n",
      "\tspeed: 0.0533s/iter; left time: 550.5864s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696812\n",
      "\tspeed: 0.0532s/iter; left time: 543.5740s\n",
      "\titers: 700, epoch: 9 | loss: 0.0712176\n",
      "\tspeed: 0.0526s/iter; left time: 532.9702s\n",
      "\titers: 800, epoch: 9 | loss: 0.0743244\n",
      "\tspeed: 0.0534s/iter; left time: 535.5993s\n",
      "\titers: 900, epoch: 9 | loss: 0.0718729\n",
      "\tspeed: 0.0524s/iter; left time: 519.8514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.0719530 Vali Loss: 0.0969985 Test Loss: 0.1797135\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0683066\n",
      "\tspeed: 0.1437s/iter; left time: 1412.0437s\n",
      "\titers: 200, epoch: 10 | loss: 0.0716422\n",
      "\tspeed: 0.0526s/iter; left time: 511.4677s\n",
      "\titers: 300, epoch: 10 | loss: 0.0723626\n",
      "\tspeed: 0.0526s/iter; left time: 505.9720s\n",
      "\titers: 400, epoch: 10 | loss: 0.0699641\n",
      "\tspeed: 0.0539s/iter; left time: 513.3518s\n",
      "\titers: 500, epoch: 10 | loss: 0.0695303\n",
      "\tspeed: 0.0527s/iter; left time: 496.9047s\n",
      "\titers: 600, epoch: 10 | loss: 0.0675861\n",
      "\tspeed: 0.0536s/iter; left time: 500.0521s\n",
      "\titers: 700, epoch: 10 | loss: 0.0694537\n",
      "\tspeed: 0.0525s/iter; left time: 484.4969s\n",
      "\titers: 800, epoch: 10 | loss: 0.0755490\n",
      "\tspeed: 0.0534s/iter; left time: 486.8669s\n",
      "\titers: 900, epoch: 10 | loss: 0.0642353\n",
      "\tspeed: 0.0537s/iter; left time: 484.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.0689081 Vali Loss: 0.0958964 Test Loss: 0.1808414\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0662207\n",
      "\tspeed: 0.1443s/iter; left time: 1287.4279s\n",
      "\titers: 200, epoch: 11 | loss: 0.0688213\n",
      "\tspeed: 0.0524s/iter; left time: 462.1533s\n",
      "\titers: 300, epoch: 11 | loss: 0.0666703\n",
      "\tspeed: 0.0524s/iter; left time: 456.9465s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667215\n",
      "\tspeed: 0.0536s/iter; left time: 462.2141s\n",
      "\titers: 500, epoch: 11 | loss: 0.0642328\n",
      "\tspeed: 0.0520s/iter; left time: 442.7801s\n",
      "\titers: 600, epoch: 11 | loss: 0.0628756\n",
      "\tspeed: 0.0537s/iter; left time: 451.8185s\n",
      "\titers: 700, epoch: 11 | loss: 0.0666778\n",
      "\tspeed: 0.0536s/iter; left time: 446.3034s\n",
      "\titers: 800, epoch: 11 | loss: 0.0637921\n",
      "\tspeed: 0.0533s/iter; left time: 438.4866s\n",
      "\titers: 900, epoch: 11 | loss: 0.0647936\n",
      "\tspeed: 0.0533s/iter; left time: 433.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.23s\n",
      "Steps: 902 | Train Loss: 0.0661303 Vali Loss: 0.0938816 Test Loss: 0.1753303\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.059251438826322556, rmse:0.2434161901473999, mae:0.15362679958343506, rse:0.7149913311004639\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2349210\n",
      "\tspeed: 0.0544s/iter; left time: 976.2651s\n",
      "\titers: 200, epoch: 1 | loss: 0.2279838\n",
      "\tspeed: 0.0528s/iter; left time: 942.7319s\n",
      "\titers: 300, epoch: 1 | loss: 0.2191480\n",
      "\tspeed: 0.0532s/iter; left time: 943.7385s\n",
      "\titers: 400, epoch: 1 | loss: 0.2087048\n",
      "\tspeed: 0.0523s/iter; left time: 923.2847s\n",
      "\titers: 500, epoch: 1 | loss: 0.1916923\n",
      "\tspeed: 0.0523s/iter; left time: 916.7012s\n",
      "\titers: 600, epoch: 1 | loss: 0.1907430\n",
      "\tspeed: 0.0521s/iter; left time: 908.5827s\n",
      "\titers: 700, epoch: 1 | loss: 0.1920722\n",
      "\tspeed: 0.0524s/iter; left time: 907.8864s\n",
      "\titers: 800, epoch: 1 | loss: 0.1773725\n",
      "\tspeed: 0.0521s/iter; left time: 897.7489s\n",
      "\titers: 900, epoch: 1 | loss: 0.1780178\n",
      "\tspeed: 0.0522s/iter; left time: 895.1848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.56s\n",
      "Steps: 902 | Train Loss: 0.2070508 Vali Loss: 0.1749768 Test Loss: 0.2157735\n",
      "Validation loss decreased (inf --> 0.174977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1617161\n",
      "\tspeed: 0.1497s/iter; left time: 2550.5091s\n",
      "\titers: 200, epoch: 2 | loss: 0.1568196\n",
      "\tspeed: 0.0528s/iter; left time: 895.1930s\n",
      "\titers: 300, epoch: 2 | loss: 0.1507764\n",
      "\tspeed: 0.0525s/iter; left time: 883.5483s\n",
      "\titers: 400, epoch: 2 | loss: 0.1362563\n",
      "\tspeed: 0.0526s/iter; left time: 880.5542s\n",
      "\titers: 500, epoch: 2 | loss: 0.1151469\n",
      "\tspeed: 0.0531s/iter; left time: 882.8529s\n",
      "\titers: 600, epoch: 2 | loss: 0.1056248\n",
      "\tspeed: 0.0533s/iter; left time: 881.2900s\n",
      "\titers: 700, epoch: 2 | loss: 0.1037987\n",
      "\tspeed: 0.0535s/iter; left time: 879.3878s\n",
      "\titers: 800, epoch: 2 | loss: 0.1028209\n",
      "\tspeed: 0.0516s/iter; left time: 842.9393s\n",
      "\titers: 900, epoch: 2 | loss: 0.1003323\n",
      "\tspeed: 0.0520s/iter; left time: 843.6963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.80s\n",
      "Steps: 902 | Train Loss: 0.1284606 Vali Loss: 0.1045906 Test Loss: 0.1474278\n",
      "Validation loss decreased (0.174977 --> 0.104591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1005617\n",
      "\tspeed: 0.1443s/iter; left time: 2328.3111s\n",
      "\titers: 200, epoch: 3 | loss: 0.1018791\n",
      "\tspeed: 0.0519s/iter; left time: 832.1961s\n",
      "\titers: 300, epoch: 3 | loss: 0.0966349\n",
      "\tspeed: 0.0514s/iter; left time: 819.3177s\n",
      "\titers: 400, epoch: 3 | loss: 0.0967483\n",
      "\tspeed: 0.0513s/iter; left time: 812.2297s\n",
      "\titers: 500, epoch: 3 | loss: 0.0928284\n",
      "\tspeed: 0.0504s/iter; left time: 792.6062s\n",
      "\titers: 600, epoch: 3 | loss: 0.0995029\n",
      "\tspeed: 0.0536s/iter; left time: 838.8403s\n",
      "\titers: 700, epoch: 3 | loss: 0.0985659\n",
      "\tspeed: 0.0531s/iter; left time: 825.2069s\n",
      "\titers: 800, epoch: 3 | loss: 0.0971092\n",
      "\tspeed: 0.0518s/iter; left time: 799.3335s\n",
      "\titers: 900, epoch: 3 | loss: 0.0919120\n",
      "\tspeed: 0.0525s/iter; left time: 805.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.0970943 Vali Loss: 0.0964301 Test Loss: 0.1427914\n",
      "Validation loss decreased (0.104591 --> 0.096430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0905354\n",
      "\tspeed: 0.1455s/iter; left time: 2217.4364s\n",
      "\titers: 200, epoch: 4 | loss: 0.0956672\n",
      "\tspeed: 0.0529s/iter; left time: 800.5287s\n",
      "\titers: 300, epoch: 4 | loss: 0.0939741\n",
      "\tspeed: 0.0531s/iter; left time: 798.5403s\n",
      "\titers: 400, epoch: 4 | loss: 0.0921513\n",
      "\tspeed: 0.0530s/iter; left time: 790.8765s\n",
      "\titers: 500, epoch: 4 | loss: 0.0914307\n",
      "\tspeed: 0.0515s/iter; left time: 764.4590s\n",
      "\titers: 600, epoch: 4 | loss: 0.0860426\n",
      "\tspeed: 0.0527s/iter; left time: 775.9998s\n",
      "\titers: 700, epoch: 4 | loss: 0.0933233\n",
      "\tspeed: 0.0501s/iter; left time: 732.9929s\n",
      "\titers: 800, epoch: 4 | loss: 0.0861083\n",
      "\tspeed: 0.0516s/iter; left time: 750.1494s\n",
      "\titers: 900, epoch: 4 | loss: 0.0898743\n",
      "\tspeed: 0.0515s/iter; left time: 742.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.0903123 Vali Loss: 0.0957017 Test Loss: 0.1425941\n",
      "Validation loss decreased (0.096430 --> 0.095702).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0847614\n",
      "\tspeed: 0.1452s/iter; left time: 2081.1395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937782\n",
      "\tspeed: 0.0506s/iter; left time: 720.4432s\n",
      "\titers: 300, epoch: 5 | loss: 0.0876471\n",
      "\tspeed: 0.0536s/iter; left time: 757.9856s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887670\n",
      "\tspeed: 0.0520s/iter; left time: 730.1675s\n",
      "\titers: 500, epoch: 5 | loss: 0.0893669\n",
      "\tspeed: 0.0515s/iter; left time: 717.0674s\n",
      "\titers: 600, epoch: 5 | loss: 0.0840157\n",
      "\tspeed: 0.0524s/iter; left time: 725.5151s\n",
      "\titers: 700, epoch: 5 | loss: 0.0800300\n",
      "\tspeed: 0.0516s/iter; left time: 708.5058s\n",
      "\titers: 800, epoch: 5 | loss: 0.0872025\n",
      "\tspeed: 0.0524s/iter; left time: 714.4685s\n",
      "\titers: 900, epoch: 5 | loss: 0.0851304\n",
      "\tspeed: 0.0513s/iter; left time: 694.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 902 | Train Loss: 0.0854653 Vali Loss: 0.0925818 Test Loss: 0.1454035\n",
      "Validation loss decreased (0.095702 --> 0.092582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808024\n",
      "\tspeed: 0.1489s/iter; left time: 1999.5463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0885766\n",
      "\tspeed: 0.0520s/iter; left time: 693.4472s\n",
      "\titers: 300, epoch: 6 | loss: 0.0827625\n",
      "\tspeed: 0.0521s/iter; left time: 689.2404s\n",
      "\titers: 400, epoch: 6 | loss: 0.0804902\n",
      "\tspeed: 0.0522s/iter; left time: 685.3654s\n",
      "\titers: 500, epoch: 6 | loss: 0.0835528\n",
      "\tspeed: 0.0518s/iter; left time: 675.4753s\n",
      "\titers: 600, epoch: 6 | loss: 0.0793270\n",
      "\tspeed: 0.0535s/iter; left time: 692.0030s\n",
      "\titers: 700, epoch: 6 | loss: 0.0842770\n",
      "\tspeed: 0.0524s/iter; left time: 672.9244s\n",
      "\titers: 800, epoch: 6 | loss: 0.0834730\n",
      "\tspeed: 0.0538s/iter; left time: 684.7118s\n",
      "\titers: 900, epoch: 6 | loss: 0.0774157\n",
      "\tspeed: 0.0540s/iter; left time: 682.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.81s\n",
      "Steps: 902 | Train Loss: 0.0813975 Vali Loss: 0.0921341 Test Loss: 0.1452484\n",
      "Validation loss decreased (0.092582 --> 0.092134).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779524\n",
      "\tspeed: 0.1479s/iter; left time: 1853.2045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771557\n",
      "\tspeed: 0.0518s/iter; left time: 643.8084s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816080\n",
      "\tspeed: 0.0545s/iter; left time: 671.5264s\n",
      "\titers: 400, epoch: 7 | loss: 0.0794977\n",
      "\tspeed: 0.0528s/iter; left time: 645.3208s\n",
      "\titers: 500, epoch: 7 | loss: 0.0854444\n",
      "\tspeed: 0.0541s/iter; left time: 656.7240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0777031\n",
      "\tspeed: 0.0539s/iter; left time: 647.8878s\n",
      "\titers: 700, epoch: 7 | loss: 0.0810900\n",
      "\tspeed: 0.0544s/iter; left time: 648.9561s\n",
      "\titers: 800, epoch: 7 | loss: 0.0756242\n",
      "\tspeed: 0.0522s/iter; left time: 616.9586s\n",
      "\titers: 900, epoch: 7 | loss: 0.0795688\n",
      "\tspeed: 0.0531s/iter; left time: 622.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.0777726 Vali Loss: 0.0932417 Test Loss: 0.1590466\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0717619\n",
      "\tspeed: 0.1476s/iter; left time: 1715.7293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806814\n",
      "\tspeed: 0.0541s/iter; left time: 623.4765s\n",
      "\titers: 300, epoch: 8 | loss: 0.0720096\n",
      "\tspeed: 0.0544s/iter; left time: 621.9014s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708151\n",
      "\tspeed: 0.0538s/iter; left time: 609.6725s\n",
      "\titers: 500, epoch: 8 | loss: 0.0770770\n",
      "\tspeed: 0.0540s/iter; left time: 605.8227s\n",
      "\titers: 600, epoch: 8 | loss: 0.0690221\n",
      "\tspeed: 0.0536s/iter; left time: 595.8697s\n",
      "\titers: 700, epoch: 8 | loss: 0.0720180\n",
      "\tspeed: 0.0541s/iter; left time: 596.6386s\n",
      "\titers: 800, epoch: 8 | loss: 0.0740105\n",
      "\tspeed: 0.0537s/iter; left time: 586.3305s\n",
      "\titers: 900, epoch: 8 | loss: 0.0766453\n",
      "\tspeed: 0.0540s/iter; left time: 584.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.0742275 Vali Loss: 0.0959616 Test Loss: 0.1693050\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726401\n",
      "\tspeed: 0.1448s/iter; left time: 1552.8867s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666279\n",
      "\tspeed: 0.0539s/iter; left time: 572.4371s\n",
      "\titers: 300, epoch: 9 | loss: 0.0707830\n",
      "\tspeed: 0.0531s/iter; left time: 558.9579s\n",
      "\titers: 400, epoch: 9 | loss: 0.0732539\n",
      "\tspeed: 0.0532s/iter; left time: 555.0676s\n",
      "\titers: 500, epoch: 9 | loss: 0.0725338\n",
      "\tspeed: 0.0519s/iter; left time: 536.2630s\n",
      "\titers: 600, epoch: 9 | loss: 0.0685830\n",
      "\tspeed: 0.0524s/iter; left time: 535.4196s\n",
      "\titers: 700, epoch: 9 | loss: 0.0691205\n",
      "\tspeed: 0.0513s/iter; left time: 519.7935s\n",
      "\titers: 800, epoch: 9 | loss: 0.0638777\n",
      "\tspeed: 0.0522s/iter; left time: 523.2924s\n",
      "\titers: 900, epoch: 9 | loss: 0.0657238\n",
      "\tspeed: 0.0528s/iter; left time: 523.8445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.71s\n",
      "Steps: 902 | Train Loss: 0.0708883 Vali Loss: 0.0933904 Test Loss: 0.1672392\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0691511\n",
      "\tspeed: 0.1458s/iter; left time: 1431.8984s\n",
      "\titers: 200, epoch: 10 | loss: 0.0717913\n",
      "\tspeed: 0.0517s/iter; left time: 502.4328s\n",
      "\titers: 300, epoch: 10 | loss: 0.0665604\n",
      "\tspeed: 0.0538s/iter; left time: 518.0027s\n",
      "\titers: 400, epoch: 10 | loss: 0.0681423\n",
      "\tspeed: 0.0538s/iter; left time: 512.1897s\n",
      "\titers: 500, epoch: 10 | loss: 0.0683971\n",
      "\tspeed: 0.0535s/iter; left time: 504.1959s\n",
      "\titers: 600, epoch: 10 | loss: 0.0674540\n",
      "\tspeed: 0.0518s/iter; left time: 482.7737s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714129\n",
      "\tspeed: 0.0535s/iter; left time: 493.2585s\n",
      "\titers: 800, epoch: 10 | loss: 0.0681712\n",
      "\tspeed: 0.0541s/iter; left time: 493.4230s\n",
      "\titers: 900, epoch: 10 | loss: 0.0643739\n",
      "\tspeed: 0.0521s/iter; left time: 470.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.14s\n",
      "Steps: 902 | Train Loss: 0.0681751 Vali Loss: 0.0937885 Test Loss: 0.1629257\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0640436\n",
      "\tspeed: 0.1466s/iter; left time: 1307.8026s\n",
      "\titers: 200, epoch: 11 | loss: 0.0631882\n",
      "\tspeed: 0.0529s/iter; left time: 466.7173s\n",
      "\titers: 300, epoch: 11 | loss: 0.0633764\n",
      "\tspeed: 0.0515s/iter; left time: 449.3352s\n",
      "\titers: 400, epoch: 11 | loss: 0.0611668\n",
      "\tspeed: 0.0525s/iter; left time: 452.3608s\n",
      "\titers: 500, epoch: 11 | loss: 0.0607350\n",
      "\tspeed: 0.0520s/iter; left time: 443.2550s\n",
      "\titers: 600, epoch: 11 | loss: 0.0656816\n",
      "\tspeed: 0.0530s/iter; left time: 446.6461s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642508\n",
      "\tspeed: 0.0519s/iter; left time: 431.8194s\n",
      "\titers: 800, epoch: 11 | loss: 0.0654244\n",
      "\tspeed: 0.0521s/iter; left time: 428.1195s\n",
      "\titers: 900, epoch: 11 | loss: 0.0648274\n",
      "\tspeed: 0.0529s/iter; left time: 429.7854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.79s\n",
      "Steps: 902 | Train Loss: 0.0653278 Vali Loss: 0.0973051 Test Loss: 0.1744384\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05074656754732132, rmse:0.22526998817920685, mae:0.14528633654117584, rse:0.6616901159286499\n",
      "Intermediate time for ES and pred_len 168: 00h:21m:13.79s\n",
      "Intermediate time for ES: 01h:12m:50.45s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1739433\n",
      "\tspeed: 0.0545s/iter; left time: 981.9162s\n",
      "\titers: 200, epoch: 1 | loss: 0.1698646\n",
      "\tspeed: 0.0410s/iter; left time: 734.9585s\n",
      "\titers: 300, epoch: 1 | loss: 0.1628093\n",
      "\tspeed: 0.0389s/iter; left time: 692.9846s\n",
      "\titers: 400, epoch: 1 | loss: 0.1506268\n",
      "\tspeed: 0.0381s/iter; left time: 674.8135s\n",
      "\titers: 500, epoch: 1 | loss: 0.1512203\n",
      "\tspeed: 0.0383s/iter; left time: 675.3318s\n",
      "\titers: 600, epoch: 1 | loss: 0.1498979\n",
      "\tspeed: 0.0394s/iter; left time: 690.5871s\n",
      "\titers: 700, epoch: 1 | loss: 0.1457416\n",
      "\tspeed: 0.0391s/iter; left time: 681.4140s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485578\n",
      "\tspeed: 0.0377s/iter; left time: 652.7581s\n",
      "\titers: 900, epoch: 1 | loss: 0.1391965\n",
      "\tspeed: 0.0382s/iter; left time: 657.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.00s\n",
      "Steps: 906 | Train Loss: 0.1572056 Vali Loss: 0.1463180 Test Loss: 0.1671409\n",
      "Validation loss decreased (inf --> 0.146318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182796\n",
      "\tspeed: 0.1090s/iter; left time: 1865.3764s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924962\n",
      "\tspeed: 0.0388s/iter; left time: 659.4949s\n",
      "\titers: 300, epoch: 2 | loss: 0.0810476\n",
      "\tspeed: 0.0374s/iter; left time: 632.1690s\n",
      "\titers: 400, epoch: 2 | loss: 0.0683360\n",
      "\tspeed: 0.0394s/iter; left time: 662.9679s\n",
      "\titers: 500, epoch: 2 | loss: 0.0648645\n",
      "\tspeed: 0.0387s/iter; left time: 646.9797s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752140\n",
      "\tspeed: 0.0379s/iter; left time: 629.7756s\n",
      "\titers: 700, epoch: 2 | loss: 0.0643508\n",
      "\tspeed: 0.0387s/iter; left time: 638.3899s\n",
      "\titers: 800, epoch: 2 | loss: 0.0680291\n",
      "\tspeed: 0.0389s/iter; left time: 638.2195s\n",
      "\titers: 900, epoch: 2 | loss: 0.0632531\n",
      "\tspeed: 0.0391s/iter; left time: 638.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.59s\n",
      "Steps: 906 | Train Loss: 0.0802678 Vali Loss: 0.0658131 Test Loss: 0.0756742\n",
      "Validation loss decreased (0.146318 --> 0.065813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0590658\n",
      "\tspeed: 0.1098s/iter; left time: 1779.5694s\n",
      "\titers: 200, epoch: 3 | loss: 0.0515479\n",
      "\tspeed: 0.0396s/iter; left time: 638.3218s\n",
      "\titers: 300, epoch: 3 | loss: 0.0599568\n",
      "\tspeed: 0.0365s/iter; left time: 583.9626s\n",
      "\titers: 400, epoch: 3 | loss: 0.0562826\n",
      "\tspeed: 0.0400s/iter; left time: 636.0786s\n",
      "\titers: 500, epoch: 3 | loss: 0.0613825\n",
      "\tspeed: 0.0382s/iter; left time: 603.6933s\n",
      "\titers: 600, epoch: 3 | loss: 0.0567336\n",
      "\tspeed: 0.0402s/iter; left time: 630.9852s\n",
      "\titers: 700, epoch: 3 | loss: 0.0552840\n",
      "\tspeed: 0.0390s/iter; left time: 608.4750s\n",
      "\titers: 800, epoch: 3 | loss: 0.0479929\n",
      "\tspeed: 0.0403s/iter; left time: 624.8499s\n",
      "\titers: 900, epoch: 3 | loss: 0.0459714\n",
      "\tspeed: 0.0391s/iter; left time: 601.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.68s\n",
      "Steps: 906 | Train Loss: 0.0553792 Vali Loss: 0.0635076 Test Loss: 0.0724751\n",
      "Validation loss decreased (0.065813 --> 0.063508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0503195\n",
      "\tspeed: 0.1085s/iter; left time: 1660.2666s\n",
      "\titers: 200, epoch: 4 | loss: 0.0478199\n",
      "\tspeed: 0.0394s/iter; left time: 599.5076s\n",
      "\titers: 300, epoch: 4 | loss: 0.0544001\n",
      "\tspeed: 0.0395s/iter; left time: 595.9972s\n",
      "\titers: 400, epoch: 4 | loss: 0.0519251\n",
      "\tspeed: 0.0366s/iter; left time: 549.3323s\n",
      "\titers: 500, epoch: 4 | loss: 0.0462065\n",
      "\tspeed: 0.0374s/iter; left time: 556.7468s\n",
      "\titers: 600, epoch: 4 | loss: 0.0428687\n",
      "\tspeed: 0.0396s/iter; left time: 586.4738s\n",
      "\titers: 700, epoch: 4 | loss: 0.0567114\n",
      "\tspeed: 0.0381s/iter; left time: 560.3176s\n",
      "\titers: 800, epoch: 4 | loss: 0.0539834\n",
      "\tspeed: 0.0379s/iter; left time: 553.6395s\n",
      "\titers: 900, epoch: 4 | loss: 0.0465132\n",
      "\tspeed: 0.0393s/iter; left time: 570.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.43s\n",
      "Steps: 906 | Train Loss: 0.0516731 Vali Loss: 0.0619425 Test Loss: 0.0685361\n",
      "Validation loss decreased (0.063508 --> 0.061942).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0494203\n",
      "\tspeed: 0.1117s/iter; left time: 1608.0445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0499139\n",
      "\tspeed: 0.0395s/iter; left time: 564.7785s\n",
      "\titers: 300, epoch: 5 | loss: 0.0500820\n",
      "\tspeed: 0.0391s/iter; left time: 555.3451s\n",
      "\titers: 400, epoch: 5 | loss: 0.0480923\n",
      "\tspeed: 0.0401s/iter; left time: 565.4548s\n",
      "\titers: 500, epoch: 5 | loss: 0.0483339\n",
      "\tspeed: 0.0403s/iter; left time: 563.6466s\n",
      "\titers: 600, epoch: 5 | loss: 0.0575161\n",
      "\tspeed: 0.0395s/iter; left time: 549.1202s\n",
      "\titers: 700, epoch: 5 | loss: 0.0527869\n",
      "\tspeed: 0.0402s/iter; left time: 554.5915s\n",
      "\titers: 800, epoch: 5 | loss: 0.0443416\n",
      "\tspeed: 0.0439s/iter; left time: 601.7954s\n",
      "\titers: 900, epoch: 5 | loss: 0.0465798\n",
      "\tspeed: 0.0444s/iter; left time: 604.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.49s\n",
      "Steps: 906 | Train Loss: 0.0490737 Vali Loss: 0.0608070 Test Loss: 0.0667752\n",
      "Validation loss decreased (0.061942 --> 0.060807).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0477781\n",
      "\tspeed: 0.1185s/iter; left time: 1598.3768s\n",
      "\titers: 200, epoch: 6 | loss: 0.0399382\n",
      "\tspeed: 0.0426s/iter; left time: 569.9910s\n",
      "\titers: 300, epoch: 6 | loss: 0.0452826\n",
      "\tspeed: 0.0408s/iter; left time: 541.8222s\n",
      "\titers: 400, epoch: 6 | loss: 0.0539995\n",
      "\tspeed: 0.0428s/iter; left time: 564.8477s\n",
      "\titers: 500, epoch: 6 | loss: 0.0418926\n",
      "\tspeed: 0.0406s/iter; left time: 532.1151s\n",
      "\titers: 600, epoch: 6 | loss: 0.0522295\n",
      "\tspeed: 0.0413s/iter; left time: 536.6030s\n",
      "\titers: 700, epoch: 6 | loss: 0.0463074\n",
      "\tspeed: 0.0396s/iter; left time: 510.0412s\n",
      "\titers: 800, epoch: 6 | loss: 0.0447749\n",
      "\tspeed: 0.0382s/iter; left time: 488.5759s\n",
      "\titers: 900, epoch: 6 | loss: 0.0478271\n",
      "\tspeed: 0.0404s/iter; left time: 512.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.45s\n",
      "Steps: 906 | Train Loss: 0.0473443 Vali Loss: 0.0609044 Test Loss: 0.0686819\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0404355\n",
      "\tspeed: 0.1047s/iter; left time: 1318.0163s\n",
      "\titers: 200, epoch: 7 | loss: 0.0545798\n",
      "\tspeed: 0.0433s/iter; left time: 540.6449s\n",
      "\titers: 300, epoch: 7 | loss: 0.0438270\n",
      "\tspeed: 0.0452s/iter; left time: 559.7783s\n",
      "\titers: 400, epoch: 7 | loss: 0.0470609\n",
      "\tspeed: 0.0431s/iter; left time: 529.7680s\n",
      "\titers: 500, epoch: 7 | loss: 0.0418809\n",
      "\tspeed: 0.0441s/iter; left time: 537.3889s\n",
      "\titers: 600, epoch: 7 | loss: 0.0415065\n",
      "\tspeed: 0.0410s/iter; left time: 495.7367s\n",
      "\titers: 700, epoch: 7 | loss: 0.0461207\n",
      "\tspeed: 0.0391s/iter; left time: 469.0107s\n",
      "\titers: 800, epoch: 7 | loss: 0.0440742\n",
      "\tspeed: 0.0400s/iter; left time: 475.7026s\n",
      "\titers: 900, epoch: 7 | loss: 0.0388834\n",
      "\tspeed: 0.0400s/iter; left time: 471.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.0455381 Vali Loss: 0.0588701 Test Loss: 0.0653362\n",
      "Validation loss decreased (0.060807 --> 0.058870).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0394117\n",
      "\tspeed: 0.1090s/iter; left time: 1272.7909s\n",
      "\titers: 200, epoch: 8 | loss: 0.0441284\n",
      "\tspeed: 0.0427s/iter; left time: 494.3665s\n",
      "\titers: 300, epoch: 8 | loss: 0.0406993\n",
      "\tspeed: 0.0436s/iter; left time: 500.9457s\n",
      "\titers: 400, epoch: 8 | loss: 0.0489252\n",
      "\tspeed: 0.0410s/iter; left time: 466.1972s\n",
      "\titers: 500, epoch: 8 | loss: 0.0420747\n",
      "\tspeed: 0.0411s/iter; left time: 463.9701s\n",
      "\titers: 600, epoch: 8 | loss: 0.0420048\n",
      "\tspeed: 0.0386s/iter; left time: 431.9772s\n",
      "\titers: 700, epoch: 8 | loss: 0.0441453\n",
      "\tspeed: 0.0394s/iter; left time: 436.1680s\n",
      "\titers: 800, epoch: 8 | loss: 0.0445756\n",
      "\tspeed: 0.0386s/iter; left time: 423.6749s\n",
      "\titers: 900, epoch: 8 | loss: 0.0459655\n",
      "\tspeed: 0.0396s/iter; left time: 430.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.0444504 Vali Loss: 0.0598973 Test Loss: 0.0679733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0412332\n",
      "\tspeed: 0.1013s/iter; left time: 1091.5147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0436754\n",
      "\tspeed: 0.0383s/iter; left time: 408.3242s\n",
      "\titers: 300, epoch: 9 | loss: 0.0464150\n",
      "\tspeed: 0.0384s/iter; left time: 405.9599s\n",
      "\titers: 400, epoch: 9 | loss: 0.0429204\n",
      "\tspeed: 0.0388s/iter; left time: 406.6853s\n",
      "\titers: 500, epoch: 9 | loss: 0.0452812\n",
      "\tspeed: 0.0330s/iter; left time: 342.6839s\n",
      "\titers: 600, epoch: 9 | loss: 0.0380351\n",
      "\tspeed: 0.0411s/iter; left time: 421.8096s\n",
      "\titers: 700, epoch: 9 | loss: 0.0369139\n",
      "\tspeed: 0.0403s/iter; left time: 409.7010s\n",
      "\titers: 800, epoch: 9 | loss: 0.0397433\n",
      "\tspeed: 0.0425s/iter; left time: 428.2902s\n",
      "\titers: 900, epoch: 9 | loss: 0.0355174\n",
      "\tspeed: 0.0420s/iter; left time: 418.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:35.85s\n",
      "Steps: 906 | Train Loss: 0.0431518 Vali Loss: 0.0585733 Test Loss: 0.0657527\n",
      "Validation loss decreased (0.058870 --> 0.058573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0438814\n",
      "\tspeed: 0.1108s/iter; left time: 1092.8122s\n",
      "\titers: 200, epoch: 10 | loss: 0.0401150\n",
      "\tspeed: 0.0430s/iter; left time: 420.4002s\n",
      "\titers: 300, epoch: 10 | loss: 0.0440580\n",
      "\tspeed: 0.0427s/iter; left time: 412.3520s\n",
      "\titers: 400, epoch: 10 | loss: 0.0475025\n",
      "\tspeed: 0.0434s/iter; left time: 415.6676s\n",
      "\titers: 500, epoch: 10 | loss: 0.0337716\n",
      "\tspeed: 0.0422s/iter; left time: 399.0959s\n",
      "\titers: 600, epoch: 10 | loss: 0.0398108\n",
      "\tspeed: 0.0439s/iter; left time: 410.9621s\n",
      "\titers: 700, epoch: 10 | loss: 0.0447894\n",
      "\tspeed: 0.0397s/iter; left time: 367.9111s\n",
      "\titers: 800, epoch: 10 | loss: 0.0408278\n",
      "\tspeed: 0.0393s/iter; left time: 360.0389s\n",
      "\titers: 900, epoch: 10 | loss: 0.0431183\n",
      "\tspeed: 0.0405s/iter; left time: 367.1176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.0416804 Vali Loss: 0.0569647 Test Loss: 0.0654366\n",
      "Validation loss decreased (0.058573 --> 0.056965).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0437250\n",
      "\tspeed: 0.1081s/iter; left time: 968.6066s\n",
      "\titers: 200, epoch: 11 | loss: 0.0444618\n",
      "\tspeed: 0.0423s/iter; left time: 374.4090s\n",
      "\titers: 300, epoch: 11 | loss: 0.0372252\n",
      "\tspeed: 0.0405s/iter; left time: 355.1405s\n",
      "\titers: 400, epoch: 11 | loss: 0.0400675\n",
      "\tspeed: 0.0410s/iter; left time: 354.8291s\n",
      "\titers: 500, epoch: 11 | loss: 0.0479926\n",
      "\tspeed: 0.0386s/iter; left time: 330.6914s\n",
      "\titers: 600, epoch: 11 | loss: 0.0441770\n",
      "\tspeed: 0.0396s/iter; left time: 334.8742s\n",
      "\titers: 700, epoch: 11 | loss: 0.0421550\n",
      "\tspeed: 0.0411s/iter; left time: 343.9627s\n",
      "\titers: 800, epoch: 11 | loss: 0.0402640\n",
      "\tspeed: 0.0392s/iter; left time: 323.9813s\n",
      "\titers: 900, epoch: 11 | loss: 0.0424030\n",
      "\tspeed: 0.0407s/iter; left time: 331.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.02s\n",
      "Steps: 906 | Train Loss: 0.0402147 Vali Loss: 0.0575275 Test Loss: 0.0661826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0367234\n",
      "\tspeed: 0.1064s/iter; left time: 856.9594s\n",
      "\titers: 200, epoch: 12 | loss: 0.0441120\n",
      "\tspeed: 0.0445s/iter; left time: 353.6076s\n",
      "\titers: 300, epoch: 12 | loss: 0.0377974\n",
      "\tspeed: 0.0424s/iter; left time: 332.7427s\n",
      "\titers: 400, epoch: 12 | loss: 0.0402544\n",
      "\tspeed: 0.0402s/iter; left time: 311.9148s\n",
      "\titers: 500, epoch: 12 | loss: 0.0366363\n",
      "\tspeed: 0.0444s/iter; left time: 339.6338s\n",
      "\titers: 600, epoch: 12 | loss: 0.0380469\n",
      "\tspeed: 0.0409s/iter; left time: 308.6835s\n",
      "\titers: 700, epoch: 12 | loss: 0.0380596\n",
      "\tspeed: 0.0389s/iter; left time: 289.9684s\n",
      "\titers: 800, epoch: 12 | loss: 0.0357173\n",
      "\tspeed: 0.0386s/iter; left time: 284.0102s\n",
      "\titers: 900, epoch: 12 | loss: 0.0374893\n",
      "\tspeed: 0.0377s/iter; left time: 273.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.56s\n",
      "Steps: 906 | Train Loss: 0.0390284 Vali Loss: 0.0570473 Test Loss: 0.0645510\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0410800\n",
      "\tspeed: 0.1058s/iter; left time: 756.0804s\n",
      "\titers: 200, epoch: 13 | loss: 0.0377162\n",
      "\tspeed: 0.0452s/iter; left time: 318.6452s\n",
      "\titers: 300, epoch: 13 | loss: 0.0337014\n",
      "\tspeed: 0.0417s/iter; left time: 289.5847s\n",
      "\titers: 400, epoch: 13 | loss: 0.0352647\n",
      "\tspeed: 0.0380s/iter; left time: 260.0731s\n",
      "\titers: 500, epoch: 13 | loss: 0.0410597\n",
      "\tspeed: 0.0370s/iter; left time: 249.5504s\n",
      "\titers: 600, epoch: 13 | loss: 0.0352836\n",
      "\tspeed: 0.0385s/iter; left time: 255.7908s\n",
      "\titers: 700, epoch: 13 | loss: 0.0384835\n",
      "\tspeed: 0.0382s/iter; left time: 250.3786s\n",
      "\titers: 800, epoch: 13 | loss: 0.0338243\n",
      "\tspeed: 0.0407s/iter; left time: 262.1869s\n",
      "\titers: 900, epoch: 13 | loss: 0.0383945\n",
      "\tspeed: 0.0420s/iter; left time: 266.7598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:36.87s\n",
      "Steps: 906 | Train Loss: 0.0381592 Vali Loss: 0.0571874 Test Loss: 0.0657793\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0388397\n",
      "\tspeed: 0.1030s/iter; left time: 642.9936s\n",
      "\titers: 200, epoch: 14 | loss: 0.0342924\n",
      "\tspeed: 0.0370s/iter; left time: 227.1508s\n",
      "\titers: 300, epoch: 14 | loss: 0.0353495\n",
      "\tspeed: 0.0407s/iter; left time: 245.7718s\n",
      "\titers: 400, epoch: 14 | loss: 0.0359039\n",
      "\tspeed: 0.0384s/iter; left time: 228.2510s\n",
      "\titers: 500, epoch: 14 | loss: 0.0381349\n",
      "\tspeed: 0.0396s/iter; left time: 231.1223s\n",
      "\titers: 600, epoch: 14 | loss: 0.0381662\n",
      "\tspeed: 0.0387s/iter; left time: 222.1007s\n",
      "\titers: 700, epoch: 14 | loss: 0.0357963\n",
      "\tspeed: 0.0374s/iter; left time: 210.9807s\n",
      "\titers: 800, epoch: 14 | loss: 0.0473406\n",
      "\tspeed: 0.0394s/iter; left time: 218.3380s\n",
      "\titers: 900, epoch: 14 | loss: 0.0343527\n",
      "\tspeed: 0.0386s/iter; left time: 209.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:35.37s\n",
      "Steps: 906 | Train Loss: 0.0372811 Vali Loss: 0.0566014 Test Loss: 0.0641220\n",
      "Validation loss decreased (0.056965 --> 0.056601).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0387673\n",
      "\tspeed: 0.1109s/iter; left time: 591.7178s\n",
      "\titers: 200, epoch: 15 | loss: 0.0376668\n",
      "\tspeed: 0.0431s/iter; left time: 225.5859s\n",
      "\titers: 300, epoch: 15 | loss: 0.0340129\n",
      "\tspeed: 0.0405s/iter; left time: 208.0257s\n",
      "\titers: 400, epoch: 15 | loss: 0.0356156\n",
      "\tspeed: 0.0420s/iter; left time: 211.3633s\n",
      "\titers: 500, epoch: 15 | loss: 0.0341311\n",
      "\tspeed: 0.0432s/iter; left time: 213.2384s\n",
      "\titers: 600, epoch: 15 | loss: 0.0390709\n",
      "\tspeed: 0.0416s/iter; left time: 200.9851s\n",
      "\titers: 700, epoch: 15 | loss: 0.0334687\n",
      "\tspeed: 0.0383s/iter; left time: 181.4522s\n",
      "\titers: 800, epoch: 15 | loss: 0.0408071\n",
      "\tspeed: 0.0377s/iter; left time: 174.5888s\n",
      "\titers: 900, epoch: 15 | loss: 0.0364410\n",
      "\tspeed: 0.0388s/iter; left time: 176.1881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 906 | Train Loss: 0.0367306 Vali Loss: 0.0574687 Test Loss: 0.0659029\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0368593\n",
      "\tspeed: 0.1024s/iter; left time: 453.8384s\n",
      "\titers: 200, epoch: 16 | loss: 0.0431039\n",
      "\tspeed: 0.0426s/iter; left time: 184.6693s\n",
      "\titers: 300, epoch: 16 | loss: 0.0384472\n",
      "\tspeed: 0.0413s/iter; left time: 174.8084s\n",
      "\titers: 400, epoch: 16 | loss: 0.0352341\n",
      "\tspeed: 0.0405s/iter; left time: 167.1825s\n",
      "\titers: 500, epoch: 16 | loss: 0.0311277\n",
      "\tspeed: 0.0396s/iter; left time: 159.5497s\n",
      "\titers: 600, epoch: 16 | loss: 0.0366535\n",
      "\tspeed: 0.0382s/iter; left time: 150.3405s\n",
      "\titers: 700, epoch: 16 | loss: 0.0330081\n",
      "\tspeed: 0.0388s/iter; left time: 148.7461s\n",
      "\titers: 800, epoch: 16 | loss: 0.0367885\n",
      "\tspeed: 0.0380s/iter; left time: 141.8650s\n",
      "\titers: 900, epoch: 16 | loss: 0.0353695\n",
      "\tspeed: 0.0392s/iter; left time: 142.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:36.24s\n",
      "Steps: 906 | Train Loss: 0.0359501 Vali Loss: 0.0579413 Test Loss: 0.0662559\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387607\n",
      "\tspeed: 0.1062s/iter; left time: 374.2456s\n",
      "\titers: 200, epoch: 17 | loss: 0.0358092\n",
      "\tspeed: 0.0427s/iter; left time: 146.1709s\n",
      "\titers: 300, epoch: 17 | loss: 0.0380436\n",
      "\tspeed: 0.0437s/iter; left time: 145.3790s\n",
      "\titers: 400, epoch: 17 | loss: 0.0352150\n",
      "\tspeed: 0.0388s/iter; left time: 125.1843s\n",
      "\titers: 500, epoch: 17 | loss: 0.0336286\n",
      "\tspeed: 0.0429s/iter; left time: 134.1436s\n",
      "\titers: 600, epoch: 17 | loss: 0.0328397\n",
      "\tspeed: 0.0384s/iter; left time: 116.1102s\n",
      "\titers: 700, epoch: 17 | loss: 0.0385101\n",
      "\tspeed: 0.0389s/iter; left time: 113.6682s\n",
      "\titers: 800, epoch: 17 | loss: 0.0363401\n",
      "\tspeed: 0.0403s/iter; left time: 113.7904s\n",
      "\titers: 900, epoch: 17 | loss: 0.0418978\n",
      "\tspeed: 0.0378s/iter; left time: 103.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:37.15s\n",
      "Steps: 906 | Train Loss: 0.0353823 Vali Loss: 0.0571683 Test Loss: 0.0651751\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0348546\n",
      "\tspeed: 0.1039s/iter; left time: 272.0614s\n",
      "\titers: 200, epoch: 18 | loss: 0.0355422\n",
      "\tspeed: 0.0398s/iter; left time: 100.3225s\n",
      "\titers: 300, epoch: 18 | loss: 0.0365842\n",
      "\tspeed: 0.0393s/iter; left time: 95.0118s\n",
      "\titers: 400, epoch: 18 | loss: 0.0375368\n",
      "\tspeed: 0.0382s/iter; left time: 88.6326s\n",
      "\titers: 500, epoch: 18 | loss: 0.0391709\n",
      "\tspeed: 0.0382s/iter; left time: 84.8221s\n",
      "\titers: 600, epoch: 18 | loss: 0.0359639\n",
      "\tspeed: 0.0398s/iter; left time: 84.2761s\n",
      "\titers: 700, epoch: 18 | loss: 0.0451567\n",
      "\tspeed: 0.0408s/iter; left time: 82.3707s\n",
      "\titers: 800, epoch: 18 | loss: 0.0332086\n",
      "\tspeed: 0.0404s/iter; left time: 77.5710s\n",
      "\titers: 900, epoch: 18 | loss: 0.0385903\n",
      "\tspeed: 0.0449s/iter; left time: 81.5982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.0347825 Vali Loss: 0.0575072 Test Loss: 0.0649085\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0343457\n",
      "\tspeed: 0.1052s/iter; left time: 180.1607s\n",
      "\titers: 200, epoch: 19 | loss: 0.0324227\n",
      "\tspeed: 0.0433s/iter; left time: 69.9122s\n",
      "\titers: 300, epoch: 19 | loss: 0.0352254\n",
      "\tspeed: 0.0439s/iter; left time: 66.3869s\n",
      "\titers: 400, epoch: 19 | loss: 0.0333225\n",
      "\tspeed: 0.0432s/iter; left time: 61.0403s\n",
      "\titers: 500, epoch: 19 | loss: 0.0341113\n",
      "\tspeed: 0.0421s/iter; left time: 55.3331s\n",
      "\titers: 600, epoch: 19 | loss: 0.0351807\n",
      "\tspeed: 0.0391s/iter; left time: 47.4665s\n",
      "\titers: 700, epoch: 19 | loss: 0.0348938\n",
      "\tspeed: 0.0410s/iter; left time: 45.6869s\n",
      "\titers: 800, epoch: 19 | loss: 0.0338098\n",
      "\tspeed: 0.0423s/iter; left time: 42.8148s\n",
      "\titers: 900, epoch: 19 | loss: 0.0356139\n",
      "\tspeed: 0.0420s/iter; left time: 38.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 906 | Train Loss: 0.0342754 Vali Loss: 0.0572752 Test Loss: 0.0656079\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012767552398145199, rmse:0.11299359798431396, mae:0.06396614760160446, rse:0.4360218048095703\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1801156\n",
      "\tspeed: 0.0427s/iter; left time: 768.8814s\n",
      "\titers: 200, epoch: 1 | loss: 0.1693918\n",
      "\tspeed: 0.0386s/iter; left time: 692.0285s\n",
      "\titers: 300, epoch: 1 | loss: 0.1592212\n",
      "\tspeed: 0.0393s/iter; left time: 699.5794s\n",
      "\titers: 400, epoch: 1 | loss: 0.1620753\n",
      "\tspeed: 0.0397s/iter; left time: 704.2397s\n",
      "\titers: 500, epoch: 1 | loss: 0.1458250\n",
      "\tspeed: 0.0378s/iter; left time: 665.9755s\n",
      "\titers: 600, epoch: 1 | loss: 0.1475012\n",
      "\tspeed: 0.0393s/iter; left time: 688.5811s\n",
      "\titers: 700, epoch: 1 | loss: 0.1419826\n",
      "\tspeed: 0.0395s/iter; left time: 688.5086s\n",
      "\titers: 800, epoch: 1 | loss: 0.1336648\n",
      "\tspeed: 0.0394s/iter; left time: 682.4325s\n",
      "\titers: 900, epoch: 1 | loss: 0.1408745\n",
      "\tspeed: 0.0396s/iter; left time: 681.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:35.90s\n",
      "Steps: 906 | Train Loss: 0.1612176 Vali Loss: 0.1463322 Test Loss: 0.1673547\n",
      "Validation loss decreased (inf --> 0.146332).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303828\n",
      "\tspeed: 0.1067s/iter; left time: 1826.6675s\n",
      "\titers: 200, epoch: 2 | loss: 0.1161620\n",
      "\tspeed: 0.0390s/iter; left time: 664.2655s\n",
      "\titers: 300, epoch: 2 | loss: 0.1155948\n",
      "\tspeed: 0.0401s/iter; left time: 678.8689s\n",
      "\titers: 400, epoch: 2 | loss: 0.1075312\n",
      "\tspeed: 0.0375s/iter; left time: 631.3561s\n",
      "\titers: 500, epoch: 2 | loss: 0.1108859\n",
      "\tspeed: 0.0401s/iter; left time: 670.5023s\n",
      "\titers: 600, epoch: 2 | loss: 0.1101993\n",
      "\tspeed: 0.0425s/iter; left time: 706.7913s\n",
      "\titers: 700, epoch: 2 | loss: 0.0986314\n",
      "\tspeed: 0.0412s/iter; left time: 679.6471s\n",
      "\titers: 800, epoch: 2 | loss: 0.0980658\n",
      "\tspeed: 0.0392s/iter; left time: 643.0957s\n",
      "\titers: 900, epoch: 2 | loss: 0.0954762\n",
      "\tspeed: 0.0389s/iter; left time: 634.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.24s\n",
      "Steps: 906 | Train Loss: 0.1117984 Vali Loss: 0.1216852 Test Loss: 0.1423893\n",
      "Validation loss decreased (0.146332 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071936\n",
      "\tspeed: 0.1059s/iter; left time: 1716.4609s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877124\n",
      "\tspeed: 0.0393s/iter; left time: 632.9512s\n",
      "\titers: 300, epoch: 3 | loss: 0.0951138\n",
      "\tspeed: 0.0414s/iter; left time: 662.3681s\n",
      "\titers: 400, epoch: 3 | loss: 0.1052210\n",
      "\tspeed: 0.0402s/iter; left time: 639.4561s\n",
      "\titers: 500, epoch: 3 | loss: 0.0915232\n",
      "\tspeed: 0.0403s/iter; left time: 636.4539s\n",
      "\titers: 600, epoch: 3 | loss: 0.0950945\n",
      "\tspeed: 0.0394s/iter; left time: 618.9040s\n",
      "\titers: 700, epoch: 3 | loss: 0.0965930\n",
      "\tspeed: 0.0393s/iter; left time: 613.5258s\n",
      "\titers: 800, epoch: 3 | loss: 0.0935806\n",
      "\tspeed: 0.0404s/iter; left time: 626.1080s\n",
      "\titers: 900, epoch: 3 | loss: 0.0903433\n",
      "\tspeed: 0.0395s/iter; left time: 608.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.47s\n",
      "Steps: 906 | Train Loss: 0.0975487 Vali Loss: 0.1222855 Test Loss: 0.1466359\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915177\n",
      "\tspeed: 0.1033s/iter; left time: 1581.4359s\n",
      "\titers: 200, epoch: 4 | loss: 0.0943076\n",
      "\tspeed: 0.0383s/iter; left time: 581.8604s\n",
      "\titers: 300, epoch: 4 | loss: 0.0961792\n",
      "\tspeed: 0.0373s/iter; left time: 563.5931s\n",
      "\titers: 400, epoch: 4 | loss: 0.0892987\n",
      "\tspeed: 0.0383s/iter; left time: 574.0083s\n",
      "\titers: 500, epoch: 4 | loss: 0.0983917\n",
      "\tspeed: 0.0404s/iter; left time: 601.4747s\n",
      "\titers: 600, epoch: 4 | loss: 0.0893438\n",
      "\tspeed: 0.0406s/iter; left time: 601.1224s\n",
      "\titers: 700, epoch: 4 | loss: 0.0890017\n",
      "\tspeed: 0.0380s/iter; left time: 558.9892s\n",
      "\titers: 800, epoch: 4 | loss: 0.0899160\n",
      "\tspeed: 0.0377s/iter; left time: 549.8158s\n",
      "\titers: 900, epoch: 4 | loss: 0.0873288\n",
      "\tspeed: 0.0408s/iter; left time: 591.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.59s\n",
      "Steps: 906 | Train Loss: 0.0929393 Vali Loss: 0.1178700 Test Loss: 0.1405447\n",
      "Validation loss decreased (0.121685 --> 0.117870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608060\n",
      "\tspeed: 0.1087s/iter; left time: 1564.3689s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597439\n",
      "\tspeed: 0.0412s/iter; left time: 589.1831s\n",
      "\titers: 300, epoch: 5 | loss: 0.0522412\n",
      "\tspeed: 0.0407s/iter; left time: 578.3249s\n",
      "\titers: 400, epoch: 5 | loss: 0.0543010\n",
      "\tspeed: 0.0408s/iter; left time: 575.4843s\n",
      "\titers: 500, epoch: 5 | loss: 0.0510247\n",
      "\tspeed: 0.0390s/iter; left time: 546.3922s\n",
      "\titers: 600, epoch: 5 | loss: 0.0480882\n",
      "\tspeed: 0.0422s/iter; left time: 586.7257s\n",
      "\titers: 700, epoch: 5 | loss: 0.0547104\n",
      "\tspeed: 0.0460s/iter; left time: 634.2739s\n",
      "\titers: 800, epoch: 5 | loss: 0.0395380\n",
      "\tspeed: 0.0459s/iter; left time: 628.2696s\n",
      "\titers: 900, epoch: 5 | loss: 0.0498560\n",
      "\tspeed: 0.0459s/iter; left time: 624.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 906 | Train Loss: 0.0547073 Vali Loss: 0.0645226 Test Loss: 0.0707614\n",
      "Validation loss decreased (0.117870 --> 0.064523).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568447\n",
      "\tspeed: 0.1123s/iter; left time: 1515.5677s\n",
      "\titers: 200, epoch: 6 | loss: 0.0532049\n",
      "\tspeed: 0.0458s/iter; left time: 613.4933s\n",
      "\titers: 300, epoch: 6 | loss: 0.0566209\n",
      "\tspeed: 0.0373s/iter; left time: 495.8130s\n",
      "\titers: 400, epoch: 6 | loss: 0.0460761\n",
      "\tspeed: 0.0328s/iter; left time: 433.2224s\n",
      "\titers: 500, epoch: 6 | loss: 0.0461107\n",
      "\tspeed: 0.0329s/iter; left time: 430.2425s\n",
      "\titers: 600, epoch: 6 | loss: 0.0416425\n",
      "\tspeed: 0.0329s/iter; left time: 426.8793s\n",
      "\titers: 700, epoch: 6 | loss: 0.0520144\n",
      "\tspeed: 0.0329s/iter; left time: 423.8004s\n",
      "\titers: 800, epoch: 6 | loss: 0.0474252\n",
      "\tspeed: 0.0329s/iter; left time: 420.2952s\n",
      "\titers: 900, epoch: 6 | loss: 0.0456907\n",
      "\tspeed: 0.0329s/iter; left time: 417.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 906 | Train Loss: 0.0484333 Vali Loss: 0.0617828 Test Loss: 0.0678977\n",
      "Validation loss decreased (0.064523 --> 0.061783).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0537158\n",
      "\tspeed: 0.1121s/iter; left time: 1410.6652s\n",
      "\titers: 200, epoch: 7 | loss: 0.0511137\n",
      "\tspeed: 0.0463s/iter; left time: 578.2386s\n",
      "\titers: 300, epoch: 7 | loss: 0.0435230\n",
      "\tspeed: 0.0462s/iter; left time: 571.8435s\n",
      "\titers: 400, epoch: 7 | loss: 0.0451123\n",
      "\tspeed: 0.0462s/iter; left time: 567.9675s\n",
      "\titers: 500, epoch: 7 | loss: 0.0537385\n",
      "\tspeed: 0.0460s/iter; left time: 559.9919s\n",
      "\titers: 600, epoch: 7 | loss: 0.0416286\n",
      "\tspeed: 0.0462s/iter; left time: 558.7961s\n",
      "\titers: 700, epoch: 7 | loss: 0.0466046\n",
      "\tspeed: 0.0463s/iter; left time: 555.0269s\n",
      "\titers: 800, epoch: 7 | loss: 0.0462235\n",
      "\tspeed: 0.0459s/iter; left time: 545.3901s\n",
      "\titers: 900, epoch: 7 | loss: 0.0409817\n",
      "\tspeed: 0.0463s/iter; left time: 545.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.11s\n",
      "Steps: 906 | Train Loss: 0.0464273 Vali Loss: 0.0605569 Test Loss: 0.0668078\n",
      "Validation loss decreased (0.061783 --> 0.060557).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0487131\n",
      "\tspeed: 0.1120s/iter; left time: 1308.6315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0413706\n",
      "\tspeed: 0.0460s/iter; left time: 532.4259s\n",
      "\titers: 300, epoch: 8 | loss: 0.0469885\n",
      "\tspeed: 0.0462s/iter; left time: 530.3601s\n",
      "\titers: 400, epoch: 8 | loss: 0.0439744\n",
      "\tspeed: 0.0462s/iter; left time: 525.5379s\n",
      "\titers: 500, epoch: 8 | loss: 0.0461223\n",
      "\tspeed: 0.0459s/iter; left time: 518.2190s\n",
      "\titers: 600, epoch: 8 | loss: 0.0443447\n",
      "\tspeed: 0.0462s/iter; left time: 516.8941s\n",
      "\titers: 700, epoch: 8 | loss: 0.0442688\n",
      "\tspeed: 0.0459s/iter; left time: 508.2221s\n",
      "\titers: 800, epoch: 8 | loss: 0.0440482\n",
      "\tspeed: 0.0457s/iter; left time: 501.3841s\n",
      "\titers: 900, epoch: 8 | loss: 0.0466514\n",
      "\tspeed: 0.0457s/iter; left time: 496.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.94s\n",
      "Steps: 906 | Train Loss: 0.0448513 Vali Loss: 0.0610837 Test Loss: 0.0678426\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0493816\n",
      "\tspeed: 0.1089s/iter; left time: 1173.3104s\n",
      "\titers: 200, epoch: 9 | loss: 0.0397221\n",
      "\tspeed: 0.0387s/iter; left time: 413.5162s\n",
      "\titers: 300, epoch: 9 | loss: 0.0432034\n",
      "\tspeed: 0.0329s/iter; left time: 347.3873s\n",
      "\titers: 400, epoch: 9 | loss: 0.0397232\n",
      "\tspeed: 0.0329s/iter; left time: 344.1216s\n",
      "\titers: 500, epoch: 9 | loss: 0.0407601\n",
      "\tspeed: 0.0329s/iter; left time: 341.1713s\n",
      "\titers: 600, epoch: 9 | loss: 0.0382149\n",
      "\tspeed: 0.0329s/iter; left time: 337.5988s\n",
      "\titers: 700, epoch: 9 | loss: 0.0399199\n",
      "\tspeed: 0.0329s/iter; left time: 334.2977s\n",
      "\titers: 800, epoch: 9 | loss: 0.0448039\n",
      "\tspeed: 0.0328s/iter; left time: 330.8010s\n",
      "\titers: 900, epoch: 9 | loss: 0.0397257\n",
      "\tspeed: 0.0328s/iter; left time: 327.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0435285 Vali Loss: 0.0585313 Test Loss: 0.0650581\n",
      "Validation loss decreased (0.060557 --> 0.058531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0426823\n",
      "\tspeed: 0.1114s/iter; left time: 1099.3591s\n",
      "\titers: 200, epoch: 10 | loss: 0.0409605\n",
      "\tspeed: 0.0460s/iter; left time: 449.2869s\n",
      "\titers: 300, epoch: 10 | loss: 0.0423930\n",
      "\tspeed: 0.0463s/iter; left time: 447.3325s\n",
      "\titers: 400, epoch: 10 | loss: 0.0425085\n",
      "\tspeed: 0.0463s/iter; left time: 442.4766s\n",
      "\titers: 500, epoch: 10 | loss: 0.0413204\n",
      "\tspeed: 0.0467s/iter; left time: 442.0727s\n",
      "\titers: 600, epoch: 10 | loss: 0.0463774\n",
      "\tspeed: 0.0462s/iter; left time: 432.8123s\n",
      "\titers: 700, epoch: 10 | loss: 0.0379347\n",
      "\tspeed: 0.0462s/iter; left time: 427.9731s\n",
      "\titers: 800, epoch: 10 | loss: 0.0455473\n",
      "\tspeed: 0.0463s/iter; left time: 424.0721s\n",
      "\titers: 900, epoch: 10 | loss: 0.0484285\n",
      "\tspeed: 0.0463s/iter; left time: 419.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 906 | Train Loss: 0.0419678 Vali Loss: 0.0583743 Test Loss: 0.0650106\n",
      "Validation loss decreased (0.058531 --> 0.058374).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417961\n",
      "\tspeed: 0.1136s/iter; left time: 1017.8757s\n",
      "\titers: 200, epoch: 11 | loss: 0.0406378\n",
      "\tspeed: 0.0461s/iter; left time: 408.1779s\n",
      "\titers: 300, epoch: 11 | loss: 0.0437176\n",
      "\tspeed: 0.0459s/iter; left time: 402.4304s\n",
      "\titers: 400, epoch: 11 | loss: 0.0392322\n",
      "\tspeed: 0.0458s/iter; left time: 396.2638s\n",
      "\titers: 500, epoch: 11 | loss: 0.0369425\n",
      "\tspeed: 0.0458s/iter; left time: 391.8981s\n",
      "\titers: 600, epoch: 11 | loss: 0.0395975\n",
      "\tspeed: 0.0459s/iter; left time: 388.4843s\n",
      "\titers: 700, epoch: 11 | loss: 0.0426910\n",
      "\tspeed: 0.0457s/iter; left time: 381.8703s\n",
      "\titers: 800, epoch: 11 | loss: 0.0414411\n",
      "\tspeed: 0.0458s/iter; left time: 378.4104s\n",
      "\titers: 900, epoch: 11 | loss: 0.0433159\n",
      "\tspeed: 0.0458s/iter; left time: 374.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0407944 Vali Loss: 0.0585528 Test Loss: 0.0678896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0353869\n",
      "\tspeed: 0.1093s/iter; left time: 880.0215s\n",
      "\titers: 200, epoch: 12 | loss: 0.0369177\n",
      "\tspeed: 0.0460s/iter; left time: 365.7609s\n",
      "\titers: 300, epoch: 12 | loss: 0.0402261\n",
      "\tspeed: 0.0458s/iter; left time: 360.0506s\n",
      "\titers: 400, epoch: 12 | loss: 0.0403699\n",
      "\tspeed: 0.0459s/iter; left time: 356.2830s\n",
      "\titers: 500, epoch: 12 | loss: 0.0416523\n",
      "\tspeed: 0.0457s/iter; left time: 349.8637s\n",
      "\titers: 600, epoch: 12 | loss: 0.0359642\n",
      "\tspeed: 0.0458s/iter; left time: 345.7162s\n",
      "\titers: 700, epoch: 12 | loss: 0.0365096\n",
      "\tspeed: 0.0457s/iter; left time: 340.7711s\n",
      "\titers: 800, epoch: 12 | loss: 0.0419170\n",
      "\tspeed: 0.0457s/iter; left time: 336.2889s\n",
      "\titers: 900, epoch: 12 | loss: 0.0427586\n",
      "\tspeed: 0.0458s/iter; left time: 332.6305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.0394729 Vali Loss: 0.0576715 Test Loss: 0.0654075\n",
      "Validation loss decreased (0.058374 --> 0.057672).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0382381\n",
      "\tspeed: 0.1126s/iter; left time: 805.0593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0408555\n",
      "\tspeed: 0.0460s/iter; left time: 324.3473s\n",
      "\titers: 300, epoch: 13 | loss: 0.0425836\n",
      "\tspeed: 0.0460s/iter; left time: 319.6341s\n",
      "\titers: 400, epoch: 13 | loss: 0.0404076\n",
      "\tspeed: 0.0459s/iter; left time: 314.1939s\n",
      "\titers: 500, epoch: 13 | loss: 0.0379511\n",
      "\tspeed: 0.0462s/iter; left time: 312.0545s\n",
      "\titers: 600, epoch: 13 | loss: 0.0329018\n",
      "\tspeed: 0.0461s/iter; left time: 306.8388s\n",
      "\titers: 700, epoch: 13 | loss: 0.0368670\n",
      "\tspeed: 0.0460s/iter; left time: 301.5050s\n",
      "\titers: 800, epoch: 13 | loss: 0.0375282\n",
      "\tspeed: 0.0365s/iter; left time: 235.1578s\n",
      "\titers: 900, epoch: 13 | loss: 0.0373945\n",
      "\tspeed: 0.0329s/iter; left time: 208.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.59s\n",
      "Steps: 906 | Train Loss: 0.0381429 Vali Loss: 0.0585803 Test Loss: 0.0667337\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0455244\n",
      "\tspeed: 0.1074s/iter; left time: 670.5787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0310949\n",
      "\tspeed: 0.0458s/iter; left time: 281.4525s\n",
      "\titers: 300, epoch: 14 | loss: 0.0321337\n",
      "\tspeed: 0.0454s/iter; left time: 274.2140s\n",
      "\titers: 400, epoch: 14 | loss: 0.0348212\n",
      "\tspeed: 0.0461s/iter; left time: 273.8428s\n",
      "\titers: 500, epoch: 14 | loss: 0.0381810\n",
      "\tspeed: 0.0462s/iter; left time: 269.6948s\n",
      "\titers: 600, epoch: 14 | loss: 0.0381188\n",
      "\tspeed: 0.0462s/iter; left time: 265.3836s\n",
      "\titers: 700, epoch: 14 | loss: 0.0382425\n",
      "\tspeed: 0.0460s/iter; left time: 259.7676s\n",
      "\titers: 800, epoch: 14 | loss: 0.0361690\n",
      "\tspeed: 0.0460s/iter; left time: 254.8896s\n",
      "\titers: 900, epoch: 14 | loss: 0.0385786\n",
      "\tspeed: 0.0460s/iter; left time: 250.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.0372778 Vali Loss: 0.0601808 Test Loss: 0.0676199\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0363024\n",
      "\tspeed: 0.1115s/iter; left time: 595.1988s\n",
      "\titers: 200, epoch: 15 | loss: 0.0342614\n",
      "\tspeed: 0.0470s/iter; left time: 246.1229s\n",
      "\titers: 300, epoch: 15 | loss: 0.0361045\n",
      "\tspeed: 0.0460s/iter; left time: 236.1380s\n",
      "\titers: 400, epoch: 15 | loss: 0.0331206\n",
      "\tspeed: 0.0458s/iter; left time: 230.8463s\n",
      "\titers: 500, epoch: 15 | loss: 0.0400858\n",
      "\tspeed: 0.0462s/iter; left time: 228.1404s\n",
      "\titers: 600, epoch: 15 | loss: 0.0305633\n",
      "\tspeed: 0.0461s/iter; left time: 222.8591s\n",
      "\titers: 700, epoch: 15 | loss: 0.0351738\n",
      "\tspeed: 0.0459s/iter; left time: 217.4909s\n",
      "\titers: 800, epoch: 15 | loss: 0.0380954\n",
      "\tspeed: 0.0460s/iter; left time: 213.1632s\n",
      "\titers: 900, epoch: 15 | loss: 0.0319528\n",
      "\tspeed: 0.0458s/iter; left time: 207.5697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.30s\n",
      "Steps: 906 | Train Loss: 0.0363847 Vali Loss: 0.0583235 Test Loss: 0.0649400\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0376110\n",
      "\tspeed: 0.1090s/iter; left time: 482.9346s\n",
      "\titers: 200, epoch: 16 | loss: 0.0324695\n",
      "\tspeed: 0.0459s/iter; left time: 198.8669s\n",
      "\titers: 300, epoch: 16 | loss: 0.0349067\n",
      "\tspeed: 0.0460s/iter; left time: 194.6242s\n",
      "\titers: 400, epoch: 16 | loss: 0.0405893\n",
      "\tspeed: 0.0462s/iter; left time: 190.7526s\n",
      "\titers: 500, epoch: 16 | loss: 0.0344875\n",
      "\tspeed: 0.0462s/iter; left time: 186.0671s\n",
      "\titers: 600, epoch: 16 | loss: 0.0346076\n",
      "\tspeed: 0.0459s/iter; left time: 180.3261s\n",
      "\titers: 700, epoch: 16 | loss: 0.0311003\n",
      "\tspeed: 0.0460s/iter; left time: 176.0471s\n",
      "\titers: 800, epoch: 16 | loss: 0.0379062\n",
      "\tspeed: 0.0461s/iter; left time: 171.9251s\n",
      "\titers: 900, epoch: 16 | loss: 0.0341136\n",
      "\tspeed: 0.0458s/iter; left time: 166.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:41.92s\n",
      "Steps: 906 | Train Loss: 0.0357149 Vali Loss: 0.0598772 Test Loss: 0.0668659\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0357666\n",
      "\tspeed: 0.1090s/iter; left time: 384.3938s\n",
      "\titers: 200, epoch: 17 | loss: 0.0370329\n",
      "\tspeed: 0.0464s/iter; left time: 159.0520s\n",
      "\titers: 300, epoch: 17 | loss: 0.0373027\n",
      "\tspeed: 0.0463s/iter; left time: 153.8677s\n",
      "\titers: 400, epoch: 17 | loss: 0.0400641\n",
      "\tspeed: 0.0461s/iter; left time: 148.7384s\n",
      "\titers: 500, epoch: 17 | loss: 0.0296947\n",
      "\tspeed: 0.0459s/iter; left time: 143.3042s\n",
      "\titers: 600, epoch: 17 | loss: 0.0346400\n",
      "\tspeed: 0.0463s/iter; left time: 140.0409s\n",
      "\titers: 700, epoch: 17 | loss: 0.0376296\n",
      "\tspeed: 0.0458s/iter; left time: 133.9604s\n",
      "\titers: 800, epoch: 17 | loss: 0.0341742\n",
      "\tspeed: 0.0461s/iter; left time: 130.1758s\n",
      "\titers: 900, epoch: 17 | loss: 0.0311247\n",
      "\tspeed: 0.0460s/iter; left time: 125.3007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 906 | Train Loss: 0.0350217 Vali Loss: 0.0584925 Test Loss: 0.0648316\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01316201314330101, rmse:0.11472582072019577, mae:0.06538578867912292, rse:0.4427061080932617\n",
      "Intermediate time for FR and pred_len 24: 00h:26m:36.09s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1911445\n",
      "\tspeed: 0.0803s/iter; left time: 1444.4125s\n",
      "\titers: 200, epoch: 1 | loss: 0.1656685\n",
      "\tspeed: 0.0506s/iter; left time: 903.9182s\n",
      "\titers: 300, epoch: 1 | loss: 0.1671335\n",
      "\tspeed: 0.0507s/iter; left time: 901.1391s\n",
      "\titers: 400, epoch: 1 | loss: 0.1556050\n",
      "\tspeed: 0.0507s/iter; left time: 895.5628s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509407\n",
      "\tspeed: 0.0508s/iter; left time: 892.8131s\n",
      "\titers: 600, epoch: 1 | loss: 0.1473168\n",
      "\tspeed: 0.0505s/iter; left time: 882.8836s\n",
      "\titers: 700, epoch: 1 | loss: 0.1520337\n",
      "\tspeed: 0.0505s/iter; left time: 877.1535s\n",
      "\titers: 800, epoch: 1 | loss: 0.1436543\n",
      "\tspeed: 0.0506s/iter; left time: 874.5963s\n",
      "\titers: 900, epoch: 1 | loss: 0.1419926\n",
      "\tspeed: 0.0504s/iter; left time: 865.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.54s\n",
      "Steps: 904 | Train Loss: 0.1621126 Vali Loss: 0.1570459 Test Loss: 0.1830849\n",
      "Validation loss decreased (inf --> 0.157046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1269499\n",
      "\tspeed: 0.1279s/iter; left time: 2184.4936s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186103\n",
      "\tspeed: 0.0509s/iter; left time: 863.3141s\n",
      "\titers: 300, epoch: 2 | loss: 0.1039269\n",
      "\tspeed: 0.0506s/iter; left time: 854.5644s\n",
      "\titers: 400, epoch: 2 | loss: 0.1115946\n",
      "\tspeed: 0.0506s/iter; left time: 849.1524s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037187\n",
      "\tspeed: 0.0504s/iter; left time: 840.2825s\n",
      "\titers: 600, epoch: 2 | loss: 0.1041693\n",
      "\tspeed: 0.0505s/iter; left time: 837.7539s\n",
      "\titers: 700, epoch: 2 | loss: 0.0979861\n",
      "\tspeed: 0.0507s/iter; left time: 835.9437s\n",
      "\titers: 800, epoch: 2 | loss: 0.0868282\n",
      "\tspeed: 0.0505s/iter; left time: 827.6650s\n",
      "\titers: 900, epoch: 2 | loss: 0.0910813\n",
      "\tspeed: 0.0506s/iter; left time: 822.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.1090979 Vali Loss: 0.1060935 Test Loss: 0.1198013\n",
      "Validation loss decreased (0.157046 --> 0.106094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890009\n",
      "\tspeed: 0.1259s/iter; left time: 2036.3522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865769\n",
      "\tspeed: 0.0507s/iter; left time: 814.4020s\n",
      "\titers: 300, epoch: 3 | loss: 0.0859727\n",
      "\tspeed: 0.0507s/iter; left time: 809.8494s\n",
      "\titers: 400, epoch: 3 | loss: 0.0802479\n",
      "\tspeed: 0.0506s/iter; left time: 803.6390s\n",
      "\titers: 500, epoch: 3 | loss: 0.0837094\n",
      "\tspeed: 0.0506s/iter; left time: 797.6185s\n",
      "\titers: 600, epoch: 3 | loss: 0.0759933\n",
      "\tspeed: 0.0504s/iter; left time: 790.4098s\n",
      "\titers: 700, epoch: 3 | loss: 0.0734874\n",
      "\tspeed: 0.0505s/iter; left time: 786.8602s\n",
      "\titers: 800, epoch: 3 | loss: 0.0764690\n",
      "\tspeed: 0.0507s/iter; left time: 783.9287s\n",
      "\titers: 900, epoch: 3 | loss: 0.0716284\n",
      "\tspeed: 0.0504s/iter; left time: 775.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0818074 Vali Loss: 0.0865899 Test Loss: 0.0993657\n",
      "Validation loss decreased (0.106094 --> 0.086590).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621516\n",
      "\tspeed: 0.1291s/iter; left time: 1970.8591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0672046\n",
      "\tspeed: 0.0505s/iter; left time: 765.3299s\n",
      "\titers: 300, epoch: 4 | loss: 0.0658672\n",
      "\tspeed: 0.0505s/iter; left time: 760.3700s\n",
      "\titers: 400, epoch: 4 | loss: 0.0698871\n",
      "\tspeed: 0.0505s/iter; left time: 756.4381s\n",
      "\titers: 500, epoch: 4 | loss: 0.0635847\n",
      "\tspeed: 0.0499s/iter; left time: 742.1211s\n",
      "\titers: 600, epoch: 4 | loss: 0.0619379\n",
      "\tspeed: 0.0501s/iter; left time: 739.4574s\n",
      "\titers: 700, epoch: 4 | loss: 0.0643404\n",
      "\tspeed: 0.0502s/iter; left time: 736.6118s\n",
      "\titers: 800, epoch: 4 | loss: 0.0603288\n",
      "\tspeed: 0.0505s/iter; left time: 736.1262s\n",
      "\titers: 900, epoch: 4 | loss: 0.0631917\n",
      "\tspeed: 0.0505s/iter; left time: 731.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 904 | Train Loss: 0.0672327 Vali Loss: 0.0836879 Test Loss: 0.0913545\n",
      "Validation loss decreased (0.086590 --> 0.083688).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656674\n",
      "\tspeed: 0.1275s/iter; left time: 1831.1807s\n",
      "\titers: 200, epoch: 5 | loss: 0.0633681\n",
      "\tspeed: 0.0506s/iter; left time: 721.1608s\n",
      "\titers: 300, epoch: 5 | loss: 0.0669293\n",
      "\tspeed: 0.0504s/iter; left time: 714.4979s\n",
      "\titers: 400, epoch: 5 | loss: 0.0591970\n",
      "\tspeed: 0.0506s/iter; left time: 711.3966s\n",
      "\titers: 500, epoch: 5 | loss: 0.0588198\n",
      "\tspeed: 0.0507s/iter; left time: 708.2805s\n",
      "\titers: 600, epoch: 5 | loss: 0.0630945\n",
      "\tspeed: 0.0505s/iter; left time: 700.7015s\n",
      "\titers: 700, epoch: 5 | loss: 0.0599165\n",
      "\tspeed: 0.0506s/iter; left time: 696.6852s\n",
      "\titers: 800, epoch: 5 | loss: 0.0645712\n",
      "\tspeed: 0.0505s/iter; left time: 690.1315s\n",
      "\titers: 900, epoch: 5 | loss: 0.0631721\n",
      "\tspeed: 0.0505s/iter; left time: 685.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0622755 Vali Loss: 0.0825124 Test Loss: 0.0918160\n",
      "Validation loss decreased (0.083688 --> 0.082512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566855\n",
      "\tspeed: 0.1254s/iter; left time: 1688.2624s\n",
      "\titers: 200, epoch: 6 | loss: 0.0580016\n",
      "\tspeed: 0.0506s/iter; left time: 675.6191s\n",
      "\titers: 300, epoch: 6 | loss: 0.0588441\n",
      "\tspeed: 0.0506s/iter; left time: 670.6982s\n",
      "\titers: 400, epoch: 6 | loss: 0.0573844\n",
      "\tspeed: 0.0503s/iter; left time: 661.5452s\n",
      "\titers: 500, epoch: 6 | loss: 0.0531953\n",
      "\tspeed: 0.0505s/iter; left time: 659.5892s\n",
      "\titers: 600, epoch: 6 | loss: 0.0570009\n",
      "\tspeed: 0.0505s/iter; left time: 654.6813s\n",
      "\titers: 700, epoch: 6 | loss: 0.0556639\n",
      "\tspeed: 0.0505s/iter; left time: 649.8086s\n",
      "\titers: 800, epoch: 6 | loss: 0.0532397\n",
      "\tspeed: 0.0505s/iter; left time: 644.3521s\n",
      "\titers: 900, epoch: 6 | loss: 0.0591764\n",
      "\tspeed: 0.0506s/iter; left time: 640.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0585346 Vali Loss: 0.0808577 Test Loss: 0.0923948\n",
      "Validation loss decreased (0.082512 --> 0.080858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534672\n",
      "\tspeed: 0.1284s/iter; left time: 1612.9152s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589887\n",
      "\tspeed: 0.0503s/iter; left time: 626.9591s\n",
      "\titers: 300, epoch: 7 | loss: 0.0536293\n",
      "\tspeed: 0.0506s/iter; left time: 625.8570s\n",
      "\titers: 400, epoch: 7 | loss: 0.0519964\n",
      "\tspeed: 0.0506s/iter; left time: 619.9827s\n",
      "\titers: 500, epoch: 7 | loss: 0.0530630\n",
      "\tspeed: 0.0505s/iter; left time: 614.4477s\n",
      "\titers: 600, epoch: 7 | loss: 0.0474895\n",
      "\tspeed: 0.0506s/iter; left time: 609.8932s\n",
      "\titers: 700, epoch: 7 | loss: 0.0552770\n",
      "\tspeed: 0.0507s/iter; left time: 605.8597s\n",
      "\titers: 800, epoch: 7 | loss: 0.0558303\n",
      "\tspeed: 0.0506s/iter; left time: 599.3791s\n",
      "\titers: 900, epoch: 7 | loss: 0.0549571\n",
      "\tspeed: 0.0507s/iter; left time: 595.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0557393 Vali Loss: 0.0816498 Test Loss: 0.0896462\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563578\n",
      "\tspeed: 0.1224s/iter; left time: 1426.8218s\n",
      "\titers: 200, epoch: 8 | loss: 0.0544026\n",
      "\tspeed: 0.0506s/iter; left time: 584.4998s\n",
      "\titers: 300, epoch: 8 | loss: 0.0539047\n",
      "\tspeed: 0.0505s/iter; left time: 578.1390s\n",
      "\titers: 400, epoch: 8 | loss: 0.0478208\n",
      "\tspeed: 0.0506s/iter; left time: 574.0311s\n",
      "\titers: 500, epoch: 8 | loss: 0.0498325\n",
      "\tspeed: 0.0506s/iter; left time: 569.8196s\n",
      "\titers: 600, epoch: 8 | loss: 0.0514959\n",
      "\tspeed: 0.0506s/iter; left time: 564.0083s\n",
      "\titers: 700, epoch: 8 | loss: 0.0493322\n",
      "\tspeed: 0.0506s/iter; left time: 559.2727s\n",
      "\titers: 800, epoch: 8 | loss: 0.0527163\n",
      "\tspeed: 0.0505s/iter; left time: 552.8934s\n",
      "\titers: 900, epoch: 8 | loss: 0.0476547\n",
      "\tspeed: 0.0507s/iter; left time: 550.6008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0534399 Vali Loss: 0.0823979 Test Loss: 0.0926677\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0487081\n",
      "\tspeed: 0.1220s/iter; left time: 1311.6567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0489254\n",
      "\tspeed: 0.0501s/iter; left time: 533.6282s\n",
      "\titers: 300, epoch: 9 | loss: 0.0504238\n",
      "\tspeed: 0.0503s/iter; left time: 530.8977s\n",
      "\titers: 400, epoch: 9 | loss: 0.0451382\n",
      "\tspeed: 0.0506s/iter; left time: 528.4643s\n",
      "\titers: 500, epoch: 9 | loss: 0.0497325\n",
      "\tspeed: 0.0506s/iter; left time: 524.1462s\n",
      "\titers: 600, epoch: 9 | loss: 0.0512080\n",
      "\tspeed: 0.0505s/iter; left time: 517.9714s\n",
      "\titers: 700, epoch: 9 | loss: 0.0522259\n",
      "\tspeed: 0.0505s/iter; left time: 512.7486s\n",
      "\titers: 800, epoch: 9 | loss: 0.0505538\n",
      "\tspeed: 0.0506s/iter; left time: 508.0177s\n",
      "\titers: 900, epoch: 9 | loss: 0.0517188\n",
      "\tspeed: 0.0506s/iter; left time: 502.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 904 | Train Loss: 0.0510219 Vali Loss: 0.0819406 Test Loss: 0.0904427\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0461655\n",
      "\tspeed: 0.1233s/iter; left time: 1214.0317s\n",
      "\titers: 200, epoch: 10 | loss: 0.0465046\n",
      "\tspeed: 0.0508s/iter; left time: 495.1710s\n",
      "\titers: 300, epoch: 10 | loss: 0.0463841\n",
      "\tspeed: 0.0505s/iter; left time: 487.4539s\n",
      "\titers: 400, epoch: 10 | loss: 0.0464293\n",
      "\tspeed: 0.0505s/iter; left time: 481.6041s\n",
      "\titers: 500, epoch: 10 | loss: 0.0465597\n",
      "\tspeed: 0.0507s/iter; left time: 479.1735s\n",
      "\titers: 600, epoch: 10 | loss: 0.0523428\n",
      "\tspeed: 0.0505s/iter; left time: 472.2004s\n",
      "\titers: 700, epoch: 10 | loss: 0.0491336\n",
      "\tspeed: 0.0505s/iter; left time: 466.9916s\n",
      "\titers: 800, epoch: 10 | loss: 0.0531798\n",
      "\tspeed: 0.0504s/iter; left time: 460.6456s\n",
      "\titers: 900, epoch: 10 | loss: 0.0509942\n",
      "\tspeed: 0.0503s/iter; left time: 454.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0489800 Vali Loss: 0.0816964 Test Loss: 0.0916990\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0457875\n",
      "\tspeed: 0.1222s/iter; left time: 1092.9783s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482542\n",
      "\tspeed: 0.0506s/iter; left time: 447.1186s\n",
      "\titers: 300, epoch: 11 | loss: 0.0474747\n",
      "\tspeed: 0.0505s/iter; left time: 441.6749s\n",
      "\titers: 400, epoch: 11 | loss: 0.0486984\n",
      "\tspeed: 0.0506s/iter; left time: 437.1095s\n",
      "\titers: 500, epoch: 11 | loss: 0.0492964\n",
      "\tspeed: 0.0506s/iter; left time: 431.9607s\n",
      "\titers: 600, epoch: 11 | loss: 0.0460422\n",
      "\tspeed: 0.0506s/iter; left time: 426.7474s\n",
      "\titers: 700, epoch: 11 | loss: 0.0455612\n",
      "\tspeed: 0.0505s/iter; left time: 421.1809s\n",
      "\titers: 800, epoch: 11 | loss: 0.0474474\n",
      "\tspeed: 0.0507s/iter; left time: 417.4114s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470046\n",
      "\tspeed: 0.0506s/iter; left time: 412.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0473390 Vali Loss: 0.0814191 Test Loss: 0.0897584\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023155687376856804, rmse:0.15216992795467377, mae:0.0923483744263649, rse:0.5886337161064148\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1992797\n",
      "\tspeed: 0.0530s/iter; left time: 953.8579s\n",
      "\titers: 200, epoch: 1 | loss: 0.1617417\n",
      "\tspeed: 0.0510s/iter; left time: 911.5704s\n",
      "\titers: 300, epoch: 1 | loss: 0.1604739\n",
      "\tspeed: 0.0507s/iter; left time: 900.9498s\n",
      "\titers: 400, epoch: 1 | loss: 0.1667275\n",
      "\tspeed: 0.0507s/iter; left time: 896.0491s\n",
      "\titers: 500, epoch: 1 | loss: 0.1528316\n",
      "\tspeed: 0.0506s/iter; left time: 888.8939s\n",
      "\titers: 600, epoch: 1 | loss: 0.1504665\n",
      "\tspeed: 0.0506s/iter; left time: 885.0096s\n",
      "\titers: 700, epoch: 1 | loss: 0.1398170\n",
      "\tspeed: 0.0507s/iter; left time: 881.9486s\n",
      "\titers: 800, epoch: 1 | loss: 0.1525903\n",
      "\tspeed: 0.0505s/iter; left time: 873.2741s\n",
      "\titers: 900, epoch: 1 | loss: 0.1397681\n",
      "\tspeed: 0.0508s/iter; left time: 872.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.1611014 Vali Loss: 0.1487986 Test Loss: 0.1742257\n",
      "Validation loss decreased (inf --> 0.148799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1291680\n",
      "\tspeed: 0.1317s/iter; left time: 2248.6499s\n",
      "\titers: 200, epoch: 2 | loss: 0.1218417\n",
      "\tspeed: 0.0512s/iter; left time: 868.6402s\n",
      "\titers: 300, epoch: 2 | loss: 0.1178188\n",
      "\tspeed: 0.0509s/iter; left time: 859.3650s\n",
      "\titers: 400, epoch: 2 | loss: 0.1215334\n",
      "\tspeed: 0.0508s/iter; left time: 852.6427s\n",
      "\titers: 500, epoch: 2 | loss: 0.1175609\n",
      "\tspeed: 0.0506s/iter; left time: 844.0629s\n",
      "\titers: 600, epoch: 2 | loss: 0.1084198\n",
      "\tspeed: 0.0506s/iter; left time: 838.7657s\n",
      "\titers: 700, epoch: 2 | loss: 0.1001606\n",
      "\tspeed: 0.0508s/iter; left time: 837.3330s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075935\n",
      "\tspeed: 0.0508s/iter; left time: 831.3252s\n",
      "\titers: 900, epoch: 2 | loss: 0.1030391\n",
      "\tspeed: 0.0507s/iter; left time: 825.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.24s\n",
      "Steps: 904 | Train Loss: 0.1155119 Vali Loss: 0.1259977 Test Loss: 0.1459249\n",
      "Validation loss decreased (0.148799 --> 0.125998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1066775\n",
      "\tspeed: 0.1282s/iter; left time: 2073.4635s\n",
      "\titers: 200, epoch: 3 | loss: 0.0974142\n",
      "\tspeed: 0.0505s/iter; left time: 812.1775s\n",
      "\titers: 300, epoch: 3 | loss: 0.0965906\n",
      "\tspeed: 0.0505s/iter; left time: 806.1987s\n",
      "\titers: 400, epoch: 3 | loss: 0.0946485\n",
      "\tspeed: 0.0505s/iter; left time: 801.4112s\n",
      "\titers: 500, epoch: 3 | loss: 0.0919983\n",
      "\tspeed: 0.0505s/iter; left time: 797.2381s\n",
      "\titers: 600, epoch: 3 | loss: 0.0809823\n",
      "\tspeed: 0.0502s/iter; left time: 787.2122s\n",
      "\titers: 700, epoch: 3 | loss: 0.0901392\n",
      "\tspeed: 0.0502s/iter; left time: 782.0813s\n",
      "\titers: 800, epoch: 3 | loss: 0.0719470\n",
      "\tspeed: 0.0503s/iter; left time: 777.8872s\n",
      "\titers: 900, epoch: 3 | loss: 0.0709015\n",
      "\tspeed: 0.0502s/iter; left time: 771.8865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 904 | Train Loss: 0.0926840 Vali Loss: 0.0885343 Test Loss: 0.1007292\n",
      "Validation loss decreased (0.125998 --> 0.088534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647133\n",
      "\tspeed: 0.1280s/iter; left time: 1955.1853s\n",
      "\titers: 200, epoch: 4 | loss: 0.0759917\n",
      "\tspeed: 0.0506s/iter; left time: 767.9724s\n",
      "\titers: 300, epoch: 4 | loss: 0.0750118\n",
      "\tspeed: 0.0500s/iter; left time: 753.6366s\n",
      "\titers: 400, epoch: 4 | loss: 0.0646950\n",
      "\tspeed: 0.0506s/iter; left time: 757.2492s\n",
      "\titers: 500, epoch: 4 | loss: 0.0636472\n",
      "\tspeed: 0.0506s/iter; left time: 752.4170s\n",
      "\titers: 600, epoch: 4 | loss: 0.0703337\n",
      "\tspeed: 0.0505s/iter; left time: 746.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0662696\n",
      "\tspeed: 0.0508s/iter; left time: 744.5638s\n",
      "\titers: 800, epoch: 4 | loss: 0.0660502\n",
      "\tspeed: 0.0509s/iter; left time: 741.0855s\n",
      "\titers: 900, epoch: 4 | loss: 0.0649790\n",
      "\tspeed: 0.0509s/iter; left time: 736.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 904 | Train Loss: 0.0686160 Vali Loss: 0.0839365 Test Loss: 0.0947516\n",
      "Validation loss decreased (0.088534 --> 0.083936).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616051\n",
      "\tspeed: 0.1298s/iter; left time: 1864.1785s\n",
      "\titers: 200, epoch: 5 | loss: 0.0659879\n",
      "\tspeed: 0.0505s/iter; left time: 720.6512s\n",
      "\titers: 300, epoch: 5 | loss: 0.0706296\n",
      "\tspeed: 0.0506s/iter; left time: 716.1843s\n",
      "\titers: 400, epoch: 5 | loss: 0.0663615\n",
      "\tspeed: 0.0506s/iter; left time: 712.2961s\n",
      "\titers: 500, epoch: 5 | loss: 0.0614187\n",
      "\tspeed: 0.0502s/iter; left time: 700.3798s\n",
      "\titers: 600, epoch: 5 | loss: 0.0616514\n",
      "\tspeed: 0.0506s/iter; left time: 700.9022s\n",
      "\titers: 700, epoch: 5 | loss: 0.0729438\n",
      "\tspeed: 0.0504s/iter; left time: 694.2268s\n",
      "\titers: 800, epoch: 5 | loss: 0.0523489\n",
      "\tspeed: 0.0507s/iter; left time: 692.1435s\n",
      "\titers: 900, epoch: 5 | loss: 0.0600485\n",
      "\tspeed: 0.0507s/iter; left time: 687.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0630417 Vali Loss: 0.0807501 Test Loss: 0.0890914\n",
      "Validation loss decreased (0.083936 --> 0.080750).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614960\n",
      "\tspeed: 0.1272s/iter; left time: 1711.6171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571879\n",
      "\tspeed: 0.0505s/iter; left time: 675.1414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0620920\n",
      "\tspeed: 0.0505s/iter; left time: 669.8691s\n",
      "\titers: 400, epoch: 6 | loss: 0.0574742\n",
      "\tspeed: 0.0505s/iter; left time: 664.5494s\n",
      "\titers: 500, epoch: 6 | loss: 0.0606673\n",
      "\tspeed: 0.0506s/iter; left time: 660.7471s\n",
      "\titers: 600, epoch: 6 | loss: 0.0583962\n",
      "\tspeed: 0.0506s/iter; left time: 656.2011s\n",
      "\titers: 700, epoch: 6 | loss: 0.0587346\n",
      "\tspeed: 0.0505s/iter; left time: 649.1816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0582970\n",
      "\tspeed: 0.0505s/iter; left time: 644.5022s\n",
      "\titers: 900, epoch: 6 | loss: 0.0548476\n",
      "\tspeed: 0.0506s/iter; left time: 640.1337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0592987 Vali Loss: 0.0836388 Test Loss: 0.0921502\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0547832\n",
      "\tspeed: 0.1229s/iter; left time: 1543.0266s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547374\n",
      "\tspeed: 0.0506s/iter; left time: 629.7259s\n",
      "\titers: 300, epoch: 7 | loss: 0.0591234\n",
      "\tspeed: 0.0506s/iter; left time: 625.8370s\n",
      "\titers: 400, epoch: 7 | loss: 0.0566430\n",
      "\tspeed: 0.0505s/iter; left time: 619.3298s\n",
      "\titers: 500, epoch: 7 | loss: 0.0529336\n",
      "\tspeed: 0.0505s/iter; left time: 614.5125s\n",
      "\titers: 600, epoch: 7 | loss: 0.0527418\n",
      "\tspeed: 0.0501s/iter; left time: 604.4278s\n",
      "\titers: 700, epoch: 7 | loss: 0.0545850\n",
      "\tspeed: 0.0505s/iter; left time: 604.1396s\n",
      "\titers: 800, epoch: 7 | loss: 0.0537773\n",
      "\tspeed: 0.0506s/iter; left time: 599.4206s\n",
      "\titers: 900, epoch: 7 | loss: 0.0556343\n",
      "\tspeed: 0.0507s/iter; left time: 595.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0562589 Vali Loss: 0.0830783 Test Loss: 0.0920738\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540548\n",
      "\tspeed: 0.1224s/iter; left time: 1426.2162s\n",
      "\titers: 200, epoch: 8 | loss: 0.0540662\n",
      "\tspeed: 0.0505s/iter; left time: 583.7681s\n",
      "\titers: 300, epoch: 8 | loss: 0.0517248\n",
      "\tspeed: 0.0504s/iter; left time: 577.8036s\n",
      "\titers: 400, epoch: 8 | loss: 0.0503701\n",
      "\tspeed: 0.0504s/iter; left time: 572.2432s\n",
      "\titers: 500, epoch: 8 | loss: 0.0568538\n",
      "\tspeed: 0.0505s/iter; left time: 568.1375s\n",
      "\titers: 600, epoch: 8 | loss: 0.0514664\n",
      "\tspeed: 0.0505s/iter; left time: 563.4341s\n",
      "\titers: 700, epoch: 8 | loss: 0.0525621\n",
      "\tspeed: 0.0505s/iter; left time: 558.7093s\n",
      "\titers: 800, epoch: 8 | loss: 0.0539060\n",
      "\tspeed: 0.0504s/iter; left time: 552.2348s\n",
      "\titers: 900, epoch: 8 | loss: 0.0534104\n",
      "\tspeed: 0.0505s/iter; left time: 548.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.0536997 Vali Loss: 0.0821512 Test Loss: 0.0878213\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554801\n",
      "\tspeed: 0.1224s/iter; left time: 1315.1962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525909\n",
      "\tspeed: 0.0507s/iter; left time: 539.5220s\n",
      "\titers: 300, epoch: 9 | loss: 0.0503607\n",
      "\tspeed: 0.0504s/iter; left time: 531.8914s\n",
      "\titers: 400, epoch: 9 | loss: 0.0517837\n",
      "\tspeed: 0.0505s/iter; left time: 527.7686s\n",
      "\titers: 500, epoch: 9 | loss: 0.0491131\n",
      "\tspeed: 0.0505s/iter; left time: 522.8078s\n",
      "\titers: 600, epoch: 9 | loss: 0.0495254\n",
      "\tspeed: 0.0506s/iter; left time: 518.2128s\n",
      "\titers: 700, epoch: 9 | loss: 0.0511253\n",
      "\tspeed: 0.0502s/iter; left time: 509.9266s\n",
      "\titers: 800, epoch: 9 | loss: 0.0498807\n",
      "\tspeed: 0.0506s/iter; left time: 508.3025s\n",
      "\titers: 900, epoch: 9 | loss: 0.0514518\n",
      "\tspeed: 0.0504s/iter; left time: 501.8074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.0514246 Vali Loss: 0.0811186 Test Loss: 0.0901066\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0488571\n",
      "\tspeed: 0.1219s/iter; left time: 1199.6386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0466229\n",
      "\tspeed: 0.0505s/iter; left time: 492.5093s\n",
      "\titers: 300, epoch: 10 | loss: 0.0452690\n",
      "\tspeed: 0.0505s/iter; left time: 487.0796s\n",
      "\titers: 400, epoch: 10 | loss: 0.0498474\n",
      "\tspeed: 0.0505s/iter; left time: 482.2005s\n",
      "\titers: 500, epoch: 10 | loss: 0.0495107\n",
      "\tspeed: 0.0505s/iter; left time: 477.0538s\n",
      "\titers: 600, epoch: 10 | loss: 0.0493437\n",
      "\tspeed: 0.0505s/iter; left time: 471.6458s\n",
      "\titers: 700, epoch: 10 | loss: 0.0476745\n",
      "\tspeed: 0.0506s/iter; left time: 467.4354s\n",
      "\titers: 800, epoch: 10 | loss: 0.0496488\n",
      "\tspeed: 0.0506s/iter; left time: 462.3024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0473083\n",
      "\tspeed: 0.0507s/iter; left time: 458.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0493435 Vali Loss: 0.0829276 Test Loss: 0.0909194\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02133835293352604, rmse:0.1460765302181244, mae:0.08909517526626587, rse:0.5650628209114075\n",
      "Intermediate time for FR and pred_len 96: 00h:18m:52.36s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1899857\n",
      "\tspeed: 0.0780s/iter; left time: 1399.5346s\n",
      "\titers: 200, epoch: 1 | loss: 0.1676250\n",
      "\tspeed: 0.0529s/iter; left time: 943.2363s\n",
      "\titers: 300, epoch: 1 | loss: 0.1593906\n",
      "\tspeed: 0.0521s/iter; left time: 923.6046s\n",
      "\titers: 400, epoch: 1 | loss: 0.1584194\n",
      "\tspeed: 0.0519s/iter; left time: 916.4201s\n",
      "\titers: 500, epoch: 1 | loss: 0.1616855\n",
      "\tspeed: 0.0523s/iter; left time: 917.4955s\n",
      "\titers: 600, epoch: 1 | loss: 0.1559882\n",
      "\tspeed: 0.0545s/iter; left time: 951.1120s\n",
      "\titers: 700, epoch: 1 | loss: 0.1501905\n",
      "\tspeed: 0.0538s/iter; left time: 932.6300s\n",
      "\titers: 800, epoch: 1 | loss: 0.1467984\n",
      "\tspeed: 0.0469s/iter; left time: 808.2247s\n",
      "\titers: 900, epoch: 1 | loss: 0.1486980\n",
      "\tspeed: 0.0516s/iter; left time: 883.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.1628964 Vali Loss: 0.1598981 Test Loss: 0.1863369\n",
      "Validation loss decreased (inf --> 0.159898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1357078\n",
      "\tspeed: 0.1468s/iter; left time: 2501.8069s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157170\n",
      "\tspeed: 0.0531s/iter; left time: 899.6214s\n",
      "\titers: 300, epoch: 2 | loss: 0.1116724\n",
      "\tspeed: 0.0526s/iter; left time: 885.2919s\n",
      "\titers: 400, epoch: 2 | loss: 0.1103282\n",
      "\tspeed: 0.0529s/iter; left time: 885.2732s\n",
      "\titers: 500, epoch: 2 | loss: 0.1188741\n",
      "\tspeed: 0.0530s/iter; left time: 882.0979s\n",
      "\titers: 600, epoch: 2 | loss: 0.1104626\n",
      "\tspeed: 0.0537s/iter; left time: 887.8432s\n",
      "\titers: 700, epoch: 2 | loss: 0.1123905\n",
      "\tspeed: 0.0572s/iter; left time: 939.8803s\n",
      "\titers: 800, epoch: 2 | loss: 0.1013852\n",
      "\tspeed: 0.0593s/iter; left time: 968.4194s\n",
      "\titers: 900, epoch: 2 | loss: 0.1009232\n",
      "\tspeed: 0.0561s/iter; left time: 911.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.78s\n",
      "Steps: 902 | Train Loss: 0.1158511 Vali Loss: 0.1261606 Test Loss: 0.1455380\n",
      "Validation loss decreased (0.159898 --> 0.126161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033958\n",
      "\tspeed: 0.1482s/iter; left time: 2390.7982s\n",
      "\titers: 200, epoch: 3 | loss: 0.1038508\n",
      "\tspeed: 0.0545s/iter; left time: 874.7325s\n",
      "\titers: 300, epoch: 3 | loss: 0.0945433\n",
      "\tspeed: 0.0562s/iter; left time: 896.2881s\n",
      "\titers: 400, epoch: 3 | loss: 0.0930621\n",
      "\tspeed: 0.0578s/iter; left time: 915.4324s\n",
      "\titers: 500, epoch: 3 | loss: 0.0925619\n",
      "\tspeed: 0.0578s/iter; left time: 910.2046s\n",
      "\titers: 600, epoch: 3 | loss: 0.0950229\n",
      "\tspeed: 0.0590s/iter; left time: 922.9946s\n",
      "\titers: 700, epoch: 3 | loss: 0.0878589\n",
      "\tspeed: 0.0600s/iter; left time: 932.7960s\n",
      "\titers: 800, epoch: 3 | loss: 0.0876500\n",
      "\tspeed: 0.0601s/iter; left time: 928.3239s\n",
      "\titers: 900, epoch: 3 | loss: 0.0900771\n",
      "\tspeed: 0.0597s/iter; left time: 914.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 902 | Train Loss: 0.0953644 Vali Loss: 0.1116854 Test Loss: 0.1285899\n",
      "Validation loss decreased (0.126161 --> 0.111685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870865\n",
      "\tspeed: 0.1507s/iter; left time: 2296.6213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811079\n",
      "\tspeed: 0.0583s/iter; left time: 881.7404s\n",
      "\titers: 300, epoch: 4 | loss: 0.0708244\n",
      "\tspeed: 0.0602s/iter; left time: 904.4932s\n",
      "\titers: 400, epoch: 4 | loss: 0.0783814\n",
      "\tspeed: 0.0605s/iter; left time: 903.9875s\n",
      "\titers: 500, epoch: 4 | loss: 0.0716911\n",
      "\tspeed: 0.0606s/iter; left time: 898.7375s\n",
      "\titers: 600, epoch: 4 | loss: 0.0728482\n",
      "\tspeed: 0.0607s/iter; left time: 893.9505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0684563\n",
      "\tspeed: 0.0601s/iter; left time: 880.1466s\n",
      "\titers: 800, epoch: 4 | loss: 0.0699331\n",
      "\tspeed: 0.0594s/iter; left time: 863.9287s\n",
      "\titers: 900, epoch: 4 | loss: 0.0653397\n",
      "\tspeed: 0.0548s/iter; left time: 791.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.71s\n",
      "Steps: 902 | Train Loss: 0.0746272 Vali Loss: 0.0860982 Test Loss: 0.0967193\n",
      "Validation loss decreased (0.111685 --> 0.086098).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0695566\n",
      "\tspeed: 0.1597s/iter; left time: 2288.6017s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643279\n",
      "\tspeed: 0.0595s/iter; left time: 846.8195s\n",
      "\titers: 300, epoch: 5 | loss: 0.0624109\n",
      "\tspeed: 0.0584s/iter; left time: 825.5700s\n",
      "\titers: 400, epoch: 5 | loss: 0.0653408\n",
      "\tspeed: 0.0580s/iter; left time: 813.2557s\n",
      "\titers: 500, epoch: 5 | loss: 0.0686386\n",
      "\tspeed: 0.0585s/iter; left time: 815.2293s\n",
      "\titers: 600, epoch: 5 | loss: 0.0697915\n",
      "\tspeed: 0.0608s/iter; left time: 840.9991s\n",
      "\titers: 700, epoch: 5 | loss: 0.0662466\n",
      "\tspeed: 0.0592s/iter; left time: 813.3030s\n",
      "\titers: 800, epoch: 5 | loss: 0.0670046\n",
      "\tspeed: 0.0545s/iter; left time: 742.7302s\n",
      "\titers: 900, epoch: 5 | loss: 0.0620230\n",
      "\tspeed: 0.0531s/iter; left time: 719.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:52.57s\n",
      "Steps: 902 | Train Loss: 0.0664477 Vali Loss: 0.0898873 Test Loss: 0.1025955\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616981\n",
      "\tspeed: 0.1447s/iter; left time: 1942.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742534\n",
      "\tspeed: 0.0596s/iter; left time: 794.3587s\n",
      "\titers: 300, epoch: 6 | loss: 0.0670259\n",
      "\tspeed: 0.0595s/iter; left time: 787.7372s\n",
      "\titers: 400, epoch: 6 | loss: 0.0620175\n",
      "\tspeed: 0.0595s/iter; left time: 781.8633s\n",
      "\titers: 500, epoch: 6 | loss: 0.0606017\n",
      "\tspeed: 0.0601s/iter; left time: 783.2031s\n",
      "\titers: 600, epoch: 6 | loss: 0.0605927\n",
      "\tspeed: 0.0595s/iter; left time: 769.3462s\n",
      "\titers: 700, epoch: 6 | loss: 0.0613156\n",
      "\tspeed: 0.0595s/iter; left time: 764.0355s\n",
      "\titers: 800, epoch: 6 | loss: 0.0661772\n",
      "\tspeed: 0.0558s/iter; left time: 710.9861s\n",
      "\titers: 900, epoch: 6 | loss: 0.0633410\n",
      "\tspeed: 0.0597s/iter; left time: 753.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.53s\n",
      "Steps: 902 | Train Loss: 0.0628621 Vali Loss: 0.0865787 Test Loss: 0.0994628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611387\n",
      "\tspeed: 0.1485s/iter; left time: 1861.1484s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607835\n",
      "\tspeed: 0.0579s/iter; left time: 720.1694s\n",
      "\titers: 300, epoch: 7 | loss: 0.0577639\n",
      "\tspeed: 0.0606s/iter; left time: 747.6325s\n",
      "\titers: 400, epoch: 7 | loss: 0.0605740\n",
      "\tspeed: 0.0609s/iter; left time: 744.4022s\n",
      "\titers: 500, epoch: 7 | loss: 0.0584024\n",
      "\tspeed: 0.0598s/iter; left time: 725.2008s\n",
      "\titers: 600, epoch: 7 | loss: 0.0664984\n",
      "\tspeed: 0.0587s/iter; left time: 705.6565s\n",
      "\titers: 700, epoch: 7 | loss: 0.0554081\n",
      "\tspeed: 0.0574s/iter; left time: 684.9186s\n",
      "\titers: 800, epoch: 7 | loss: 0.0564103\n",
      "\tspeed: 0.0573s/iter; left time: 677.6168s\n",
      "\titers: 900, epoch: 7 | loss: 0.0537747\n",
      "\tspeed: 0.0576s/iter; left time: 675.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:53.57s\n",
      "Steps: 902 | Train Loss: 0.0598913 Vali Loss: 0.0868521 Test Loss: 0.0966919\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0600452\n",
      "\tspeed: 0.1452s/iter; left time: 1688.2860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561281\n",
      "\tspeed: 0.0589s/iter; left time: 678.6754s\n",
      "\titers: 300, epoch: 8 | loss: 0.0555709\n",
      "\tspeed: 0.0609s/iter; left time: 696.1066s\n",
      "\titers: 400, epoch: 8 | loss: 0.0520003\n",
      "\tspeed: 0.0574s/iter; left time: 650.4371s\n",
      "\titers: 500, epoch: 8 | loss: 0.0566507\n",
      "\tspeed: 0.0581s/iter; left time: 652.5850s\n",
      "\titers: 600, epoch: 8 | loss: 0.0556884\n",
      "\tspeed: 0.0594s/iter; left time: 661.2419s\n",
      "\titers: 700, epoch: 8 | loss: 0.0591233\n",
      "\tspeed: 0.0579s/iter; left time: 638.6652s\n",
      "\titers: 800, epoch: 8 | loss: 0.0589403\n",
      "\tspeed: 0.0560s/iter; left time: 611.9083s\n",
      "\titers: 900, epoch: 8 | loss: 0.0540469\n",
      "\tspeed: 0.0530s/iter; left time: 573.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.31s\n",
      "Steps: 902 | Train Loss: 0.0569611 Vali Loss: 0.0868621 Test Loss: 0.0964759\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0561222\n",
      "\tspeed: 0.1449s/iter; left time: 1553.7256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579822\n",
      "\tspeed: 0.0588s/iter; left time: 624.8300s\n",
      "\titers: 300, epoch: 9 | loss: 0.0579146\n",
      "\tspeed: 0.0576s/iter; left time: 606.3907s\n",
      "\titers: 400, epoch: 9 | loss: 0.0504256\n",
      "\tspeed: 0.0577s/iter; left time: 601.1613s\n",
      "\titers: 500, epoch: 9 | loss: 0.0551281\n",
      "\tspeed: 0.0576s/iter; left time: 594.6160s\n",
      "\titers: 600, epoch: 9 | loss: 0.0562751\n",
      "\tspeed: 0.0585s/iter; left time: 597.6538s\n",
      "\titers: 700, epoch: 9 | loss: 0.0516972\n",
      "\tspeed: 0.0575s/iter; left time: 581.8894s\n",
      "\titers: 800, epoch: 9 | loss: 0.0570556\n",
      "\tspeed: 0.0599s/iter; left time: 600.7258s\n",
      "\titers: 900, epoch: 9 | loss: 0.0492881\n",
      "\tspeed: 0.0598s/iter; left time: 593.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:52.99s\n",
      "Steps: 902 | Train Loss: 0.0544857 Vali Loss: 0.0874148 Test Loss: 0.0987635\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024115122854709625, rmse:0.15529043972492218, mae:0.09677531570196152, rse:0.6014295220375061\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1785302\n",
      "\tspeed: 0.0635s/iter; left time: 1138.7576s\n",
      "\titers: 200, epoch: 1 | loss: 0.1742498\n",
      "\tspeed: 0.0614s/iter; left time: 1095.3331s\n",
      "\titers: 300, epoch: 1 | loss: 0.1729709\n",
      "\tspeed: 0.0599s/iter; left time: 1062.3939s\n",
      "\titers: 400, epoch: 1 | loss: 0.1655923\n",
      "\tspeed: 0.0582s/iter; left time: 1026.4602s\n",
      "\titers: 500, epoch: 1 | loss: 0.1546990\n",
      "\tspeed: 0.0577s/iter; left time: 1011.3089s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575718\n",
      "\tspeed: 0.0603s/iter; left time: 1052.4058s\n",
      "\titers: 700, epoch: 1 | loss: 0.1496958\n",
      "\tspeed: 0.0600s/iter; left time: 1041.0537s\n",
      "\titers: 800, epoch: 1 | loss: 0.1440132\n",
      "\tspeed: 0.0607s/iter; left time: 1047.0268s\n",
      "\titers: 900, epoch: 1 | loss: 0.1425814\n",
      "\tspeed: 0.0603s/iter; left time: 1033.6411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.40s\n",
      "Steps: 902 | Train Loss: 0.1641949 Vali Loss: 0.1581948 Test Loss: 0.1846315\n",
      "Validation loss decreased (inf --> 0.158195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314752\n",
      "\tspeed: 0.1529s/iter; left time: 2604.5366s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302168\n",
      "\tspeed: 0.0598s/iter; left time: 1013.7875s\n",
      "\titers: 300, epoch: 2 | loss: 0.1227156\n",
      "\tspeed: 0.0597s/iter; left time: 1006.0754s\n",
      "\titers: 400, epoch: 2 | loss: 0.1190880\n",
      "\tspeed: 0.0604s/iter; left time: 1011.0847s\n",
      "\titers: 500, epoch: 2 | loss: 0.0990525\n",
      "\tspeed: 0.0606s/iter; left time: 1008.7808s\n",
      "\titers: 600, epoch: 2 | loss: 0.1053740\n",
      "\tspeed: 0.0606s/iter; left time: 1002.4939s\n",
      "\titers: 700, epoch: 2 | loss: 0.0962143\n",
      "\tspeed: 0.0557s/iter; left time: 915.1166s\n",
      "\titers: 800, epoch: 2 | loss: 0.0986449\n",
      "\tspeed: 0.0579s/iter; left time: 946.0718s\n",
      "\titers: 900, epoch: 2 | loss: 0.1000924\n",
      "\tspeed: 0.0609s/iter; left time: 989.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.11s\n",
      "Steps: 902 | Train Loss: 0.1131171 Vali Loss: 0.1164894 Test Loss: 0.1345251\n",
      "Validation loss decreased (0.158195 --> 0.116489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1004082\n",
      "\tspeed: 0.1523s/iter; left time: 2457.6542s\n",
      "\titers: 200, epoch: 3 | loss: 0.0904731\n",
      "\tspeed: 0.0583s/iter; left time: 934.9128s\n",
      "\titers: 300, epoch: 3 | loss: 0.0904409\n",
      "\tspeed: 0.0584s/iter; left time: 930.1719s\n",
      "\titers: 400, epoch: 3 | loss: 0.0877866\n",
      "\tspeed: 0.0581s/iter; left time: 920.6820s\n",
      "\titers: 500, epoch: 3 | loss: 0.0891124\n",
      "\tspeed: 0.0598s/iter; left time: 940.5747s\n",
      "\titers: 600, epoch: 3 | loss: 0.0888252\n",
      "\tspeed: 0.0595s/iter; left time: 930.5944s\n",
      "\titers: 700, epoch: 3 | loss: 0.0889246\n",
      "\tspeed: 0.0575s/iter; left time: 893.5442s\n",
      "\titers: 800, epoch: 3 | loss: 0.0875869\n",
      "\tspeed: 0.0575s/iter; left time: 886.9235s\n",
      "\titers: 900, epoch: 3 | loss: 0.0879779\n",
      "\tspeed: 0.0579s/iter; left time: 888.4143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.95s\n",
      "Steps: 902 | Train Loss: 0.0916435 Vali Loss: 0.1094298 Test Loss: 0.1251870\n",
      "Validation loss decreased (0.116489 --> 0.109430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0813007\n",
      "\tspeed: 0.1541s/iter; left time: 2347.9719s\n",
      "\titers: 200, epoch: 4 | loss: 0.0870459\n",
      "\tspeed: 0.0603s/iter; left time: 912.5594s\n",
      "\titers: 300, epoch: 4 | loss: 0.0785663\n",
      "\tspeed: 0.0601s/iter; left time: 903.9126s\n",
      "\titers: 400, epoch: 4 | loss: 0.0740290\n",
      "\tspeed: 0.0602s/iter; left time: 899.2363s\n",
      "\titers: 500, epoch: 4 | loss: 0.0707856\n",
      "\tspeed: 0.0602s/iter; left time: 893.2220s\n",
      "\titers: 600, epoch: 4 | loss: 0.0676506\n",
      "\tspeed: 0.0554s/iter; left time: 815.7501s\n",
      "\titers: 700, epoch: 4 | loss: 0.0746882\n",
      "\tspeed: 0.0549s/iter; left time: 803.8527s\n",
      "\titers: 800, epoch: 4 | loss: 0.0669481\n",
      "\tspeed: 0.0547s/iter; left time: 794.8761s\n",
      "\titers: 900, epoch: 4 | loss: 0.0653036\n",
      "\tspeed: 0.0602s/iter; left time: 869.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.19s\n",
      "Steps: 902 | Train Loss: 0.0758402 Vali Loss: 0.0875886 Test Loss: 0.0993864\n",
      "Validation loss decreased (0.109430 --> 0.087589).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722621\n",
      "\tspeed: 0.1510s/iter; left time: 2164.7217s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759351\n",
      "\tspeed: 0.0572s/iter; left time: 814.0176s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662302\n",
      "\tspeed: 0.0551s/iter; left time: 778.5665s\n",
      "\titers: 400, epoch: 5 | loss: 0.0686782\n",
      "\tspeed: 0.0544s/iter; left time: 763.2730s\n",
      "\titers: 500, epoch: 5 | loss: 0.0718346\n",
      "\tspeed: 0.0539s/iter; left time: 751.3672s\n",
      "\titers: 600, epoch: 5 | loss: 0.0629920\n",
      "\tspeed: 0.0525s/iter; left time: 726.4640s\n",
      "\titers: 700, epoch: 5 | loss: 0.0704636\n",
      "\tspeed: 0.0539s/iter; left time: 740.5741s\n",
      "\titers: 800, epoch: 5 | loss: 0.0650801\n",
      "\tspeed: 0.0561s/iter; left time: 765.0776s\n",
      "\titers: 900, epoch: 5 | loss: 0.0662815\n",
      "\tspeed: 0.0568s/iter; left time: 768.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.39s\n",
      "Steps: 902 | Train Loss: 0.0671744 Vali Loss: 0.0864926 Test Loss: 0.0974499\n",
      "Validation loss decreased (0.087589 --> 0.086493).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0632755\n",
      "\tspeed: 0.1613s/iter; left time: 2166.8490s\n",
      "\titers: 200, epoch: 6 | loss: 0.0704076\n",
      "\tspeed: 0.0521s/iter; left time: 694.5483s\n",
      "\titers: 300, epoch: 6 | loss: 0.0638798\n",
      "\tspeed: 0.0568s/iter; left time: 751.5413s\n",
      "\titers: 400, epoch: 6 | loss: 0.0719318\n",
      "\tspeed: 0.0539s/iter; left time: 708.3267s\n",
      "\titers: 500, epoch: 6 | loss: 0.0646495\n",
      "\tspeed: 0.0537s/iter; left time: 700.1309s\n",
      "\titers: 600, epoch: 6 | loss: 0.0630737\n",
      "\tspeed: 0.0527s/iter; left time: 680.8240s\n",
      "\titers: 700, epoch: 6 | loss: 0.0621607\n",
      "\tspeed: 0.0528s/iter; left time: 676.9724s\n",
      "\titers: 800, epoch: 6 | loss: 0.0637690\n",
      "\tspeed: 0.0556s/iter; left time: 707.3471s\n",
      "\titers: 900, epoch: 6 | loss: 0.0659249\n",
      "\tspeed: 0.0570s/iter; left time: 719.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.64s\n",
      "Steps: 902 | Train Loss: 0.0638288 Vali Loss: 0.0890451 Test Loss: 0.0982523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608656\n",
      "\tspeed: 0.1494s/iter; left time: 1871.3064s\n",
      "\titers: 200, epoch: 7 | loss: 0.0660629\n",
      "\tspeed: 0.0542s/iter; left time: 673.0992s\n",
      "\titers: 300, epoch: 7 | loss: 0.0593757\n",
      "\tspeed: 0.0547s/iter; left time: 673.9836s\n",
      "\titers: 400, epoch: 7 | loss: 0.0624351\n",
      "\tspeed: 0.0580s/iter; left time: 709.3627s\n",
      "\titers: 500, epoch: 7 | loss: 0.0612352\n",
      "\tspeed: 0.0542s/iter; left time: 657.6281s\n",
      "\titers: 600, epoch: 7 | loss: 0.0603471\n",
      "\tspeed: 0.0559s/iter; left time: 672.6033s\n",
      "\titers: 700, epoch: 7 | loss: 0.0572254\n",
      "\tspeed: 0.0544s/iter; left time: 649.4253s\n",
      "\titers: 800, epoch: 7 | loss: 0.0634374\n",
      "\tspeed: 0.0559s/iter; left time: 661.4510s\n",
      "\titers: 900, epoch: 7 | loss: 0.0577613\n",
      "\tspeed: 0.0560s/iter; left time: 656.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.04s\n",
      "Steps: 902 | Train Loss: 0.0610705 Vali Loss: 0.0890353 Test Loss: 0.0984212\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568304\n",
      "\tspeed: 0.1530s/iter; left time: 1779.2663s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629917\n",
      "\tspeed: 0.0533s/iter; left time: 614.7875s\n",
      "\titers: 300, epoch: 8 | loss: 0.0604713\n",
      "\tspeed: 0.0573s/iter; left time: 654.6461s\n",
      "\titers: 400, epoch: 8 | loss: 0.0546912\n",
      "\tspeed: 0.0599s/iter; left time: 678.1914s\n",
      "\titers: 500, epoch: 8 | loss: 0.0576465\n",
      "\tspeed: 0.0536s/iter; left time: 601.8852s\n",
      "\titers: 600, epoch: 8 | loss: 0.0579468\n",
      "\tspeed: 0.0560s/iter; left time: 622.6592s\n",
      "\titers: 700, epoch: 8 | loss: 0.0640215\n",
      "\tspeed: 0.0584s/iter; left time: 644.0706s\n",
      "\titers: 800, epoch: 8 | loss: 0.0588516\n",
      "\tspeed: 0.0579s/iter; left time: 633.1668s\n",
      "\titers: 900, epoch: 8 | loss: 0.0581271\n",
      "\tspeed: 0.0597s/iter; left time: 646.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.42s\n",
      "Steps: 902 | Train Loss: 0.0581456 Vali Loss: 0.0892812 Test Loss: 0.1002643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0557753\n",
      "\tspeed: 0.1540s/iter; left time: 1651.5160s\n",
      "\titers: 200, epoch: 9 | loss: 0.0565634\n",
      "\tspeed: 0.0549s/iter; left time: 583.5711s\n",
      "\titers: 300, epoch: 9 | loss: 0.0615852\n",
      "\tspeed: 0.0533s/iter; left time: 561.2829s\n",
      "\titers: 400, epoch: 9 | loss: 0.0576182\n",
      "\tspeed: 0.0538s/iter; left time: 560.9104s\n",
      "\titers: 500, epoch: 9 | loss: 0.0538350\n",
      "\tspeed: 0.0599s/iter; left time: 618.6423s\n",
      "\titers: 600, epoch: 9 | loss: 0.0555872\n",
      "\tspeed: 0.0548s/iter; left time: 560.2040s\n",
      "\titers: 700, epoch: 9 | loss: 0.0574964\n",
      "\tspeed: 0.0563s/iter; left time: 569.7864s\n",
      "\titers: 800, epoch: 9 | loss: 0.0590935\n",
      "\tspeed: 0.0544s/iter; left time: 545.4058s\n",
      "\titers: 900, epoch: 9 | loss: 0.0515767\n",
      "\tspeed: 0.0555s/iter; left time: 551.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.18s\n",
      "Steps: 902 | Train Loss: 0.0557337 Vali Loss: 0.0892858 Test Loss: 0.1004070\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0550226\n",
      "\tspeed: 0.1545s/iter; left time: 1518.0811s\n",
      "\titers: 200, epoch: 10 | loss: 0.0531268\n",
      "\tspeed: 0.0610s/iter; left time: 593.5321s\n",
      "\titers: 300, epoch: 10 | loss: 0.0561566\n",
      "\tspeed: 0.0571s/iter; left time: 549.1860s\n",
      "\titers: 400, epoch: 10 | loss: 0.0495613\n",
      "\tspeed: 0.0566s/iter; left time: 539.3311s\n",
      "\titers: 500, epoch: 10 | loss: 0.0518721\n",
      "\tspeed: 0.0539s/iter; left time: 508.2590s\n",
      "\titers: 600, epoch: 10 | loss: 0.0532236\n",
      "\tspeed: 0.0568s/iter; left time: 529.8027s\n",
      "\titers: 700, epoch: 10 | loss: 0.0585488\n",
      "\tspeed: 0.0594s/iter; left time: 547.4720s\n",
      "\titers: 800, epoch: 10 | loss: 0.0552348\n",
      "\tspeed: 0.0569s/iter; left time: 519.3443s\n",
      "\titers: 900, epoch: 10 | loss: 0.0491405\n",
      "\tspeed: 0.0610s/iter; left time: 550.4105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:52.70s\n",
      "Steps: 902 | Train Loss: 0.0535494 Vali Loss: 0.0900601 Test Loss: 0.1045570\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02373029664158821, rmse:0.1540464162826538, mae:0.09749884158372879, rse:0.5966114401817322\n",
      "Intermediate time for FR and pred_len 168: 00h:19m:38.78s\n",
      "Intermediate time for FR: 01h:05m:07.23s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2307948\n",
      "\tspeed: 0.0721s/iter; left time: 1299.0824s\n",
      "\titers: 200, epoch: 1 | loss: 0.2170307\n",
      "\tspeed: 0.0469s/iter; left time: 840.8232s\n",
      "\titers: 300, epoch: 1 | loss: 0.1993549\n",
      "\tspeed: 0.0477s/iter; left time: 849.8236s\n",
      "\titers: 400, epoch: 1 | loss: 0.1917663\n",
      "\tspeed: 0.0475s/iter; left time: 841.9351s\n",
      "\titers: 500, epoch: 1 | loss: 0.1806835\n",
      "\tspeed: 0.0476s/iter; left time: 838.1656s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889363\n",
      "\tspeed: 0.0459s/iter; left time: 805.0661s\n",
      "\titers: 700, epoch: 1 | loss: 0.1678230\n",
      "\tspeed: 0.0464s/iter; left time: 809.0737s\n",
      "\titers: 800, epoch: 1 | loss: 0.1737418\n",
      "\tspeed: 0.0464s/iter; left time: 803.9748s\n",
      "\titers: 900, epoch: 1 | loss: 0.1780356\n",
      "\tspeed: 0.0461s/iter; left time: 794.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 906 | Train Loss: 0.1945321 Vali Loss: 0.1552572 Test Loss: 0.1695632\n",
      "Validation loss decreased (inf --> 0.155257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1274221\n",
      "\tspeed: 0.1163s/iter; left time: 1989.7082s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033664\n",
      "\tspeed: 0.0454s/iter; left time: 772.8905s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016906\n",
      "\tspeed: 0.0460s/iter; left time: 777.9083s\n",
      "\titers: 400, epoch: 2 | loss: 0.0928045\n",
      "\tspeed: 0.0405s/iter; left time: 680.1879s\n",
      "\titers: 500, epoch: 2 | loss: 0.0867835\n",
      "\tspeed: 0.0410s/iter; left time: 685.5672s\n",
      "\titers: 600, epoch: 2 | loss: 0.0947664\n",
      "\tspeed: 0.0457s/iter; left time: 759.2955s\n",
      "\titers: 700, epoch: 2 | loss: 0.0804106\n",
      "\tspeed: 0.0380s/iter; left time: 627.3463s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738746\n",
      "\tspeed: 0.0425s/iter; left time: 697.5514s\n",
      "\titers: 900, epoch: 2 | loss: 0.0749059\n",
      "\tspeed: 0.0445s/iter; left time: 726.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.47s\n",
      "Steps: 906 | Train Loss: 0.0942970 Vali Loss: 0.0736937 Test Loss: 0.0768138\n",
      "Validation loss decreased (0.155257 --> 0.073694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0687655\n",
      "\tspeed: 0.1155s/iter; left time: 1872.4141s\n",
      "\titers: 200, epoch: 3 | loss: 0.0704586\n",
      "\tspeed: 0.0445s/iter; left time: 716.1992s\n",
      "\titers: 300, epoch: 3 | loss: 0.0724156\n",
      "\tspeed: 0.0458s/iter; left time: 733.4158s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637848\n",
      "\tspeed: 0.0452s/iter; left time: 719.8114s\n",
      "\titers: 500, epoch: 3 | loss: 0.0650237\n",
      "\tspeed: 0.0462s/iter; left time: 730.1273s\n",
      "\titers: 600, epoch: 3 | loss: 0.0696827\n",
      "\tspeed: 0.0458s/iter; left time: 719.7048s\n",
      "\titers: 700, epoch: 3 | loss: 0.0704158\n",
      "\tspeed: 0.0458s/iter; left time: 715.3496s\n",
      "\titers: 800, epoch: 3 | loss: 0.0765548\n",
      "\tspeed: 0.0464s/iter; left time: 718.8555s\n",
      "\titers: 900, epoch: 3 | loss: 0.0625168\n",
      "\tspeed: 0.0461s/iter; left time: 709.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.0707018 Vali Loss: 0.0683638 Test Loss: 0.0725142\n",
      "Validation loss decreased (0.073694 --> 0.068364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0740591\n",
      "\tspeed: 0.1281s/iter; left time: 1960.5387s\n",
      "\titers: 200, epoch: 4 | loss: 0.0657040\n",
      "\tspeed: 0.0457s/iter; left time: 695.1284s\n",
      "\titers: 300, epoch: 4 | loss: 0.0651752\n",
      "\tspeed: 0.0457s/iter; left time: 689.4549s\n",
      "\titers: 400, epoch: 4 | loss: 0.0705427\n",
      "\tspeed: 0.0438s/iter; left time: 656.9906s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684307\n",
      "\tspeed: 0.0454s/iter; left time: 675.8787s\n",
      "\titers: 600, epoch: 4 | loss: 0.0605410\n",
      "\tspeed: 0.0455s/iter; left time: 673.7403s\n",
      "\titers: 700, epoch: 4 | loss: 0.0608732\n",
      "\tspeed: 0.0459s/iter; left time: 675.0490s\n",
      "\titers: 800, epoch: 4 | loss: 0.0677149\n",
      "\tspeed: 0.0463s/iter; left time: 676.7305s\n",
      "\titers: 900, epoch: 4 | loss: 0.0673072\n",
      "\tspeed: 0.0461s/iter; left time: 667.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 906 | Train Loss: 0.0663268 Vali Loss: 0.0629338 Test Loss: 0.0677571\n",
      "Validation loss decreased (0.068364 --> 0.062934).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582587\n",
      "\tspeed: 0.1164s/iter; left time: 1675.2684s\n",
      "\titers: 200, epoch: 5 | loss: 0.0729717\n",
      "\tspeed: 0.0462s/iter; left time: 660.8183s\n",
      "\titers: 300, epoch: 5 | loss: 0.0581469\n",
      "\tspeed: 0.0461s/iter; left time: 653.7912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0582043\n",
      "\tspeed: 0.0457s/iter; left time: 644.3940s\n",
      "\titers: 500, epoch: 5 | loss: 0.0630305\n",
      "\tspeed: 0.0455s/iter; left time: 636.3713s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587564\n",
      "\tspeed: 0.0440s/iter; left time: 611.6765s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723579\n",
      "\tspeed: 0.0460s/iter; left time: 635.1060s\n",
      "\titers: 800, epoch: 5 | loss: 0.0508928\n",
      "\tspeed: 0.0343s/iter; left time: 469.5837s\n",
      "\titers: 900, epoch: 5 | loss: 0.0608719\n",
      "\tspeed: 0.0384s/iter; left time: 521.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 906 | Train Loss: 0.0611652 Vali Loss: 0.0615305 Test Loss: 0.0664691\n",
      "Validation loss decreased (0.062934 --> 0.061531).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599097\n",
      "\tspeed: 0.1150s/iter; left time: 1551.8573s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599032\n",
      "\tspeed: 0.0461s/iter; left time: 617.0158s\n",
      "\titers: 300, epoch: 6 | loss: 0.0679143\n",
      "\tspeed: 0.0453s/iter; left time: 602.4755s\n",
      "\titers: 400, epoch: 6 | loss: 0.0566240\n",
      "\tspeed: 0.0458s/iter; left time: 603.7310s\n",
      "\titers: 500, epoch: 6 | loss: 0.0485979\n",
      "\tspeed: 0.0456s/iter; left time: 596.6031s\n",
      "\titers: 600, epoch: 6 | loss: 0.0569954\n",
      "\tspeed: 0.0463s/iter; left time: 601.3462s\n",
      "\titers: 700, epoch: 6 | loss: 0.0567324\n",
      "\tspeed: 0.0462s/iter; left time: 595.5850s\n",
      "\titers: 800, epoch: 6 | loss: 0.0569716\n",
      "\tspeed: 0.0456s/iter; left time: 583.1985s\n",
      "\titers: 900, epoch: 6 | loss: 0.0572487\n",
      "\tspeed: 0.0454s/iter; left time: 575.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 906 | Train Loss: 0.0585703 Vali Loss: 0.0593522 Test Loss: 0.0649830\n",
      "Validation loss decreased (0.061531 --> 0.059352).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0521329\n",
      "\tspeed: 0.1140s/iter; left time: 1434.8173s\n",
      "\titers: 200, epoch: 7 | loss: 0.0602825\n",
      "\tspeed: 0.0398s/iter; left time: 496.8121s\n",
      "\titers: 300, epoch: 7 | loss: 0.0526658\n",
      "\tspeed: 0.0403s/iter; left time: 499.5965s\n",
      "\titers: 400, epoch: 7 | loss: 0.0597318\n",
      "\tspeed: 0.0452s/iter; left time: 555.1043s\n",
      "\titers: 500, epoch: 7 | loss: 0.0559797\n",
      "\tspeed: 0.0447s/iter; left time: 545.0116s\n",
      "\titers: 600, epoch: 7 | loss: 0.0527933\n",
      "\tspeed: 0.0442s/iter; left time: 534.4707s\n",
      "\titers: 700, epoch: 7 | loss: 0.0564267\n",
      "\tspeed: 0.0450s/iter; left time: 539.3642s\n",
      "\titers: 800, epoch: 7 | loss: 0.0623623\n",
      "\tspeed: 0.0455s/iter; left time: 541.1146s\n",
      "\titers: 900, epoch: 7 | loss: 0.0521361\n",
      "\tspeed: 0.0458s/iter; left time: 539.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 906 | Train Loss: 0.0565267 Vali Loss: 0.0588676 Test Loss: 0.0644704\n",
      "Validation loss decreased (0.059352 --> 0.058868).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0495059\n",
      "\tspeed: 0.1170s/iter; left time: 1366.3918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0503293\n",
      "\tspeed: 0.0455s/iter; left time: 526.9212s\n",
      "\titers: 300, epoch: 8 | loss: 0.0528705\n",
      "\tspeed: 0.0460s/iter; left time: 527.5471s\n",
      "\titers: 400, epoch: 8 | loss: 0.0570818\n",
      "\tspeed: 0.0454s/iter; left time: 516.5250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0514506\n",
      "\tspeed: 0.0456s/iter; left time: 513.8822s\n",
      "\titers: 600, epoch: 8 | loss: 0.0580141\n",
      "\tspeed: 0.0460s/iter; left time: 513.7563s\n",
      "\titers: 700, epoch: 8 | loss: 0.0505321\n",
      "\tspeed: 0.0455s/iter; left time: 504.5194s\n",
      "\titers: 800, epoch: 8 | loss: 0.0571655\n",
      "\tspeed: 0.0459s/iter; left time: 503.8342s\n",
      "\titers: 900, epoch: 8 | loss: 0.0527277\n",
      "\tspeed: 0.0460s/iter; left time: 500.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0548148 Vali Loss: 0.0589675 Test Loss: 0.0645328\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0492653\n",
      "\tspeed: 0.1035s/iter; left time: 1115.5191s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525350\n",
      "\tspeed: 0.0405s/iter; left time: 431.7273s\n",
      "\titers: 300, epoch: 9 | loss: 0.0607874\n",
      "\tspeed: 0.0344s/iter; left time: 364.1603s\n",
      "\titers: 400, epoch: 9 | loss: 0.0506876\n",
      "\tspeed: 0.0344s/iter; left time: 360.1093s\n",
      "\titers: 500, epoch: 9 | loss: 0.0526138\n",
      "\tspeed: 0.0345s/iter; left time: 358.1490s\n",
      "\titers: 600, epoch: 9 | loss: 0.0575149\n",
      "\tspeed: 0.0347s/iter; left time: 356.8773s\n",
      "\titers: 700, epoch: 9 | loss: 0.0521966\n",
      "\tspeed: 0.0439s/iter; left time: 446.8943s\n",
      "\titers: 800, epoch: 9 | loss: 0.0507446\n",
      "\tspeed: 0.0443s/iter; left time: 446.4457s\n",
      "\titers: 900, epoch: 9 | loss: 0.0499900\n",
      "\tspeed: 0.0344s/iter; left time: 343.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:34.45s\n",
      "Steps: 906 | Train Loss: 0.0529426 Vali Loss: 0.0582318 Test Loss: 0.0637104\n",
      "Validation loss decreased (0.058868 --> 0.058232).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0533132\n",
      "\tspeed: 0.1155s/iter; left time: 1139.9241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0526193\n",
      "\tspeed: 0.0455s/iter; left time: 444.7213s\n",
      "\titers: 300, epoch: 10 | loss: 0.0531725\n",
      "\tspeed: 0.0455s/iter; left time: 440.2593s\n",
      "\titers: 400, epoch: 10 | loss: 0.0492657\n",
      "\tspeed: 0.0462s/iter; left time: 441.9885s\n",
      "\titers: 500, epoch: 10 | loss: 0.0447725\n",
      "\tspeed: 0.0461s/iter; left time: 436.0313s\n",
      "\titers: 600, epoch: 10 | loss: 0.0552568\n",
      "\tspeed: 0.0460s/iter; left time: 430.5452s\n",
      "\titers: 700, epoch: 10 | loss: 0.0507572\n",
      "\tspeed: 0.0461s/iter; left time: 427.1633s\n",
      "\titers: 800, epoch: 10 | loss: 0.0558165\n",
      "\tspeed: 0.0460s/iter; left time: 422.1070s\n",
      "\titers: 900, epoch: 10 | loss: 0.0490795\n",
      "\tspeed: 0.0461s/iter; left time: 417.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.89s\n",
      "Steps: 906 | Train Loss: 0.0516530 Vali Loss: 0.0562525 Test Loss: 0.0636979\n",
      "Validation loss decreased (0.058232 --> 0.056252).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0508998\n",
      "\tspeed: 0.1178s/iter; left time: 1055.4424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481778\n",
      "\tspeed: 0.0459s/iter; left time: 406.6955s\n",
      "\titers: 300, epoch: 11 | loss: 0.0519176\n",
      "\tspeed: 0.0461s/iter; left time: 403.6090s\n",
      "\titers: 400, epoch: 11 | loss: 0.0494691\n",
      "\tspeed: 0.0457s/iter; left time: 395.6066s\n",
      "\titers: 500, epoch: 11 | loss: 0.0515038\n",
      "\tspeed: 0.0462s/iter; left time: 395.8119s\n",
      "\titers: 600, epoch: 11 | loss: 0.0554365\n",
      "\tspeed: 0.0450s/iter; left time: 380.7408s\n",
      "\titers: 700, epoch: 11 | loss: 0.0472331\n",
      "\tspeed: 0.0455s/iter; left time: 380.6264s\n",
      "\titers: 800, epoch: 11 | loss: 0.0520767\n",
      "\tspeed: 0.0463s/iter; left time: 382.3994s\n",
      "\titers: 900, epoch: 11 | loss: 0.0424463\n",
      "\tspeed: 0.0460s/iter; left time: 375.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 906 | Train Loss: 0.0502541 Vali Loss: 0.0577327 Test Loss: 0.0642007\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454566\n",
      "\tspeed: 0.1106s/iter; left time: 891.0652s\n",
      "\titers: 200, epoch: 12 | loss: 0.0528943\n",
      "\tspeed: 0.0457s/iter; left time: 363.4229s\n",
      "\titers: 300, epoch: 12 | loss: 0.0458079\n",
      "\tspeed: 0.0461s/iter; left time: 361.9115s\n",
      "\titers: 400, epoch: 12 | loss: 0.0522390\n",
      "\tspeed: 0.0463s/iter; left time: 358.7723s\n",
      "\titers: 500, epoch: 12 | loss: 0.0539040\n",
      "\tspeed: 0.0465s/iter; left time: 356.0043s\n",
      "\titers: 600, epoch: 12 | loss: 0.0494072\n",
      "\tspeed: 0.0463s/iter; left time: 349.7081s\n",
      "\titers: 700, epoch: 12 | loss: 0.0449162\n",
      "\tspeed: 0.0426s/iter; left time: 317.6995s\n",
      "\titers: 800, epoch: 12 | loss: 0.0487760\n",
      "\tspeed: 0.0401s/iter; left time: 294.8353s\n",
      "\titers: 900, epoch: 12 | loss: 0.0489900\n",
      "\tspeed: 0.0441s/iter; left time: 319.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.84s\n",
      "Steps: 906 | Train Loss: 0.0491409 Vali Loss: 0.0570933 Test Loss: 0.0650408\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0444334\n",
      "\tspeed: 0.1098s/iter; left time: 784.7336s\n",
      "\titers: 200, epoch: 13 | loss: 0.0502308\n",
      "\tspeed: 0.0468s/iter; left time: 329.6964s\n",
      "\titers: 300, epoch: 13 | loss: 0.0439510\n",
      "\tspeed: 0.0457s/iter; left time: 317.7920s\n",
      "\titers: 400, epoch: 13 | loss: 0.0540998\n",
      "\tspeed: 0.0461s/iter; left time: 315.9764s\n",
      "\titers: 500, epoch: 13 | loss: 0.0414450\n",
      "\tspeed: 0.0450s/iter; left time: 303.5217s\n",
      "\titers: 600, epoch: 13 | loss: 0.0479760\n",
      "\tspeed: 0.0464s/iter; left time: 308.2690s\n",
      "\titers: 700, epoch: 13 | loss: 0.0474711\n",
      "\tspeed: 0.0457s/iter; left time: 299.5120s\n",
      "\titers: 800, epoch: 13 | loss: 0.0518570\n",
      "\tspeed: 0.0453s/iter; left time: 292.3641s\n",
      "\titers: 900, epoch: 13 | loss: 0.0531900\n",
      "\tspeed: 0.0459s/iter; left time: 291.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 906 | Train Loss: 0.0481198 Vali Loss: 0.0574941 Test Loss: 0.0645238\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0513889\n",
      "\tspeed: 0.1071s/iter; left time: 668.7431s\n",
      "\titers: 200, epoch: 14 | loss: 0.0478791\n",
      "\tspeed: 0.0463s/iter; left time: 284.4605s\n",
      "\titers: 300, epoch: 14 | loss: 0.0410728\n",
      "\tspeed: 0.0460s/iter; left time: 278.1191s\n",
      "\titers: 400, epoch: 14 | loss: 0.0400066\n",
      "\tspeed: 0.0461s/iter; left time: 273.6772s\n",
      "\titers: 500, epoch: 14 | loss: 0.0507554\n",
      "\tspeed: 0.0453s/iter; left time: 264.8484s\n",
      "\titers: 600, epoch: 14 | loss: 0.0465095\n",
      "\tspeed: 0.0459s/iter; left time: 263.3496s\n",
      "\titers: 700, epoch: 14 | loss: 0.0421395\n",
      "\tspeed: 0.0453s/iter; left time: 255.5417s\n",
      "\titers: 800, epoch: 14 | loss: 0.0522231\n",
      "\tspeed: 0.0462s/iter; left time: 255.9529s\n",
      "\titers: 900, epoch: 14 | loss: 0.0404586\n",
      "\tspeed: 0.0461s/iter; left time: 251.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 906 | Train Loss: 0.0469094 Vali Loss: 0.0568367 Test Loss: 0.0650876\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453801\n",
      "\tspeed: 0.1099s/iter; left time: 586.4157s\n",
      "\titers: 200, epoch: 15 | loss: 0.0439583\n",
      "\tspeed: 0.0454s/iter; left time: 237.5691s\n",
      "\titers: 300, epoch: 15 | loss: 0.0447786\n",
      "\tspeed: 0.0464s/iter; left time: 238.2008s\n",
      "\titers: 400, epoch: 15 | loss: 0.0476598\n",
      "\tspeed: 0.0463s/iter; left time: 233.0282s\n",
      "\titers: 500, epoch: 15 | loss: 0.0495078\n",
      "\tspeed: 0.0456s/iter; left time: 225.2822s\n",
      "\titers: 600, epoch: 15 | loss: 0.0445326\n",
      "\tspeed: 0.0461s/iter; left time: 223.1705s\n",
      "\titers: 700, epoch: 15 | loss: 0.0462682\n",
      "\tspeed: 0.0460s/iter; left time: 217.8345s\n",
      "\titers: 800, epoch: 15 | loss: 0.0402244\n",
      "\tspeed: 0.0458s/iter; left time: 212.4315s\n",
      "\titers: 900, epoch: 15 | loss: 0.0464951\n",
      "\tspeed: 0.0462s/iter; left time: 209.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 906 | Train Loss: 0.0460613 Vali Loss: 0.0586359 Test Loss: 0.0665492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011864868924021721, rmse:0.10892597585916519, mae:0.06381679326295853, rse:0.41163885593414307\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2109626\n",
      "\tspeed: 0.0482s/iter; left time: 868.1846s\n",
      "\titers: 200, epoch: 1 | loss: 0.2091217\n",
      "\tspeed: 0.0468s/iter; left time: 839.0923s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961004\n",
      "\tspeed: 0.0464s/iter; left time: 826.8452s\n",
      "\titers: 400, epoch: 1 | loss: 0.1901211\n",
      "\tspeed: 0.0464s/iter; left time: 821.9869s\n",
      "\titers: 500, epoch: 1 | loss: 0.1885638\n",
      "\tspeed: 0.0455s/iter; left time: 802.3692s\n",
      "\titers: 600, epoch: 1 | loss: 0.1874101\n",
      "\tspeed: 0.0462s/iter; left time: 809.0309s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783781\n",
      "\tspeed: 0.0465s/iter; left time: 810.8653s\n",
      "\titers: 800, epoch: 1 | loss: 0.1743317\n",
      "\tspeed: 0.0464s/iter; left time: 804.4761s\n",
      "\titers: 900, epoch: 1 | loss: 0.1757907\n",
      "\tspeed: 0.0462s/iter; left time: 795.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 906 | Train Loss: 0.1959116 Vali Loss: 0.1546778 Test Loss: 0.1709039\n",
      "Validation loss decreased (inf --> 0.154678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1281275\n",
      "\tspeed: 0.1177s/iter; left time: 2015.1886s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132162\n",
      "\tspeed: 0.0459s/iter; left time: 781.4092s\n",
      "\titers: 300, epoch: 2 | loss: 0.0984158\n",
      "\tspeed: 0.0462s/iter; left time: 781.5899s\n",
      "\titers: 400, epoch: 2 | loss: 0.0888975\n",
      "\tspeed: 0.0471s/iter; left time: 792.2074s\n",
      "\titers: 500, epoch: 2 | loss: 0.0904843\n",
      "\tspeed: 0.0465s/iter; left time: 777.4221s\n",
      "\titers: 600, epoch: 2 | loss: 0.0857565\n",
      "\tspeed: 0.0460s/iter; left time: 765.0775s\n",
      "\titers: 700, epoch: 2 | loss: 0.0794186\n",
      "\tspeed: 0.0461s/iter; left time: 761.2701s\n",
      "\titers: 800, epoch: 2 | loss: 0.0741243\n",
      "\tspeed: 0.0463s/iter; left time: 760.6779s\n",
      "\titers: 900, epoch: 2 | loss: 0.0768472\n",
      "\tspeed: 0.0460s/iter; left time: 750.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 906 | Train Loss: 0.0952127 Vali Loss: 0.0730349 Test Loss: 0.0759419\n",
      "Validation loss decreased (0.154678 --> 0.073035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0723839\n",
      "\tspeed: 0.1196s/iter; left time: 1939.0873s\n",
      "\titers: 200, epoch: 3 | loss: 0.0767555\n",
      "\tspeed: 0.0462s/iter; left time: 743.7280s\n",
      "\titers: 300, epoch: 3 | loss: 0.0778952\n",
      "\tspeed: 0.0461s/iter; left time: 738.3189s\n",
      "\titers: 400, epoch: 3 | loss: 0.0873912\n",
      "\tspeed: 0.0457s/iter; left time: 727.7648s\n",
      "\titers: 500, epoch: 3 | loss: 0.0722778\n",
      "\tspeed: 0.0456s/iter; left time: 720.4852s\n",
      "\titers: 600, epoch: 3 | loss: 0.0687346\n",
      "\tspeed: 0.0461s/iter; left time: 724.3926s\n",
      "\titers: 700, epoch: 3 | loss: 0.0765534\n",
      "\tspeed: 0.0459s/iter; left time: 717.2048s\n",
      "\titers: 800, epoch: 3 | loss: 0.0741475\n",
      "\tspeed: 0.0469s/iter; left time: 727.3288s\n",
      "\titers: 900, epoch: 3 | loss: 0.0682636\n",
      "\tspeed: 0.0463s/iter; left time: 712.8698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.11s\n",
      "Steps: 906 | Train Loss: 0.0705030 Vali Loss: 0.0653467 Test Loss: 0.0696557\n",
      "Validation loss decreased (0.073035 --> 0.065347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729796\n",
      "\tspeed: 0.1183s/iter; left time: 1810.1404s\n",
      "\titers: 200, epoch: 4 | loss: 0.0689848\n",
      "\tspeed: 0.0461s/iter; left time: 700.7664s\n",
      "\titers: 300, epoch: 4 | loss: 0.0671700\n",
      "\tspeed: 0.0463s/iter; left time: 699.0460s\n",
      "\titers: 400, epoch: 4 | loss: 0.0754131\n",
      "\tspeed: 0.0467s/iter; left time: 700.6095s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684203\n",
      "\tspeed: 0.0466s/iter; left time: 694.9005s\n",
      "\titers: 600, epoch: 4 | loss: 0.0608075\n",
      "\tspeed: 0.0463s/iter; left time: 685.4812s\n",
      "\titers: 700, epoch: 4 | loss: 0.0621233\n",
      "\tspeed: 0.0462s/iter; left time: 679.6706s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630564\n",
      "\tspeed: 0.0463s/iter; left time: 675.4794s\n",
      "\titers: 900, epoch: 4 | loss: 0.0627514\n",
      "\tspeed: 0.0463s/iter; left time: 671.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.30s\n",
      "Steps: 906 | Train Loss: 0.0659813 Vali Loss: 0.0651102 Test Loss: 0.0704118\n",
      "Validation loss decreased (0.065347 --> 0.065110).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0640047\n",
      "\tspeed: 0.1177s/iter; left time: 1693.9603s\n",
      "\titers: 200, epoch: 5 | loss: 0.0673053\n",
      "\tspeed: 0.0379s/iter; left time: 542.1728s\n",
      "\titers: 300, epoch: 5 | loss: 0.0616328\n",
      "\tspeed: 0.0344s/iter; left time: 488.4527s\n",
      "\titers: 400, epoch: 5 | loss: 0.0629819\n",
      "\tspeed: 0.0345s/iter; left time: 485.7056s\n",
      "\titers: 500, epoch: 5 | loss: 0.0518201\n",
      "\tspeed: 0.0379s/iter; left time: 530.8547s\n",
      "\titers: 600, epoch: 5 | loss: 0.0555115\n",
      "\tspeed: 0.0462s/iter; left time: 641.8705s\n",
      "\titers: 700, epoch: 5 | loss: 0.0688249\n",
      "\tspeed: 0.0456s/iter; left time: 629.5041s\n",
      "\titers: 800, epoch: 5 | loss: 0.0569780\n",
      "\tspeed: 0.0458s/iter; left time: 627.5672s\n",
      "\titers: 900, epoch: 5 | loss: 0.0626754\n",
      "\tspeed: 0.0466s/iter; left time: 633.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 906 | Train Loss: 0.0617045 Vali Loss: 0.0598438 Test Loss: 0.0665010\n",
      "Validation loss decreased (0.065110 --> 0.059844).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614690\n",
      "\tspeed: 0.1155s/iter; left time: 1558.7684s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638781\n",
      "\tspeed: 0.0464s/iter; left time: 620.7160s\n",
      "\titers: 300, epoch: 6 | loss: 0.0556555\n",
      "\tspeed: 0.0464s/iter; left time: 617.2711s\n",
      "\titers: 400, epoch: 6 | loss: 0.0609595\n",
      "\tspeed: 0.0457s/iter; left time: 602.3026s\n",
      "\titers: 500, epoch: 6 | loss: 0.0524145\n",
      "\tspeed: 0.0460s/iter; left time: 602.3152s\n",
      "\titers: 600, epoch: 6 | loss: 0.0607218\n",
      "\tspeed: 0.0463s/iter; left time: 600.8714s\n",
      "\titers: 700, epoch: 6 | loss: 0.0563587\n",
      "\tspeed: 0.0471s/iter; left time: 607.5614s\n",
      "\titers: 800, epoch: 6 | loss: 0.0591731\n",
      "\tspeed: 0.0460s/iter; left time: 588.7391s\n",
      "\titers: 900, epoch: 6 | loss: 0.0635162\n",
      "\tspeed: 0.0455s/iter; left time: 576.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 906 | Train Loss: 0.0581259 Vali Loss: 0.0593193 Test Loss: 0.0652329\n",
      "Validation loss decreased (0.059844 --> 0.059319).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563043\n",
      "\tspeed: 0.1158s/iter; left time: 1457.0997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620157\n",
      "\tspeed: 0.0456s/iter; left time: 569.1329s\n",
      "\titers: 300, epoch: 7 | loss: 0.0573500\n",
      "\tspeed: 0.0462s/iter; left time: 572.3171s\n",
      "\titers: 400, epoch: 7 | loss: 0.0539220\n",
      "\tspeed: 0.0458s/iter; left time: 562.7614s\n",
      "\titers: 500, epoch: 7 | loss: 0.0572008\n",
      "\tspeed: 0.0464s/iter; left time: 565.8965s\n",
      "\titers: 600, epoch: 7 | loss: 0.0531926\n",
      "\tspeed: 0.0460s/iter; left time: 555.3117s\n",
      "\titers: 700, epoch: 7 | loss: 0.0566674\n",
      "\tspeed: 0.0454s/iter; left time: 544.2876s\n",
      "\titers: 800, epoch: 7 | loss: 0.0561290\n",
      "\tspeed: 0.0461s/iter; left time: 547.9887s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559161\n",
      "\tspeed: 0.0461s/iter; left time: 543.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0564226 Vali Loss: 0.0584143 Test Loss: 0.0647861\n",
      "Validation loss decreased (0.059319 --> 0.058414).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0462566\n",
      "\tspeed: 0.1223s/iter; left time: 1428.3189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0597787\n",
      "\tspeed: 0.0460s/iter; left time: 532.2432s\n",
      "\titers: 300, epoch: 8 | loss: 0.0561780\n",
      "\tspeed: 0.0461s/iter; left time: 529.7547s\n",
      "\titers: 400, epoch: 8 | loss: 0.0555837\n",
      "\tspeed: 0.0461s/iter; left time: 524.1064s\n",
      "\titers: 500, epoch: 8 | loss: 0.0476322\n",
      "\tspeed: 0.0462s/iter; left time: 520.6140s\n",
      "\titers: 600, epoch: 8 | loss: 0.0541930\n",
      "\tspeed: 0.0461s/iter; left time: 515.4133s\n",
      "\titers: 700, epoch: 8 | loss: 0.0557520\n",
      "\tspeed: 0.0464s/iter; left time: 514.5157s\n",
      "\titers: 800, epoch: 8 | loss: 0.0503330\n",
      "\tspeed: 0.0462s/iter; left time: 507.6674s\n",
      "\titers: 900, epoch: 8 | loss: 0.0532688\n",
      "\tspeed: 0.0454s/iter; left time: 493.4389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.08s\n",
      "Steps: 906 | Train Loss: 0.0540635 Vali Loss: 0.0587974 Test Loss: 0.0668096\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0499691\n",
      "\tspeed: 0.1113s/iter; left time: 1198.5113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0512514\n",
      "\tspeed: 0.0459s/iter; left time: 490.0760s\n",
      "\titers: 300, epoch: 9 | loss: 0.0525538\n",
      "\tspeed: 0.0454s/iter; left time: 480.4917s\n",
      "\titers: 400, epoch: 9 | loss: 0.0486190\n",
      "\tspeed: 0.0460s/iter; left time: 481.8090s\n",
      "\titers: 500, epoch: 9 | loss: 0.0457945\n",
      "\tspeed: 0.0463s/iter; left time: 480.1252s\n",
      "\titers: 600, epoch: 9 | loss: 0.0426274\n",
      "\tspeed: 0.0462s/iter; left time: 474.2997s\n",
      "\titers: 700, epoch: 9 | loss: 0.0513264\n",
      "\tspeed: 0.0462s/iter; left time: 469.7447s\n",
      "\titers: 800, epoch: 9 | loss: 0.0450985\n",
      "\tspeed: 0.0462s/iter; left time: 465.8018s\n",
      "\titers: 900, epoch: 9 | loss: 0.0614643\n",
      "\tspeed: 0.0460s/iter; left time: 458.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.98s\n",
      "Steps: 906 | Train Loss: 0.0523870 Vali Loss: 0.0582359 Test Loss: 0.0673847\n",
      "Validation loss decreased (0.058414 --> 0.058236).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0525341\n",
      "\tspeed: 0.1190s/iter; left time: 1173.7879s\n",
      "\titers: 200, epoch: 10 | loss: 0.0492574\n",
      "\tspeed: 0.0469s/iter; left time: 457.6191s\n",
      "\titers: 300, epoch: 10 | loss: 0.0516225\n",
      "\tspeed: 0.0457s/iter; left time: 441.7144s\n",
      "\titers: 400, epoch: 10 | loss: 0.0542395\n",
      "\tspeed: 0.0463s/iter; left time: 442.7613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0526795\n",
      "\tspeed: 0.0462s/iter; left time: 437.0248s\n",
      "\titers: 600, epoch: 10 | loss: 0.0583520\n",
      "\tspeed: 0.0458s/iter; left time: 429.0140s\n",
      "\titers: 700, epoch: 10 | loss: 0.0519676\n",
      "\tspeed: 0.0452s/iter; left time: 418.9620s\n",
      "\titers: 800, epoch: 10 | loss: 0.0471216\n",
      "\tspeed: 0.0465s/iter; left time: 426.5380s\n",
      "\titers: 900, epoch: 10 | loss: 0.0532540\n",
      "\tspeed: 0.0443s/iter; left time: 401.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 906 | Train Loss: 0.0509804 Vali Loss: 0.0577439 Test Loss: 0.0654377\n",
      "Validation loss decreased (0.058236 --> 0.057744).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0532611\n",
      "\tspeed: 0.1141s/iter; left time: 1022.1168s\n",
      "\titers: 200, epoch: 11 | loss: 0.0440280\n",
      "\tspeed: 0.0461s/iter; left time: 408.7278s\n",
      "\titers: 300, epoch: 11 | loss: 0.0471814\n",
      "\tspeed: 0.0457s/iter; left time: 400.6578s\n",
      "\titers: 400, epoch: 11 | loss: 0.0457120\n",
      "\tspeed: 0.0455s/iter; left time: 393.8755s\n",
      "\titers: 500, epoch: 11 | loss: 0.0555467\n",
      "\tspeed: 0.0467s/iter; left time: 400.1266s\n",
      "\titers: 600, epoch: 11 | loss: 0.0511844\n",
      "\tspeed: 0.0466s/iter; left time: 394.2059s\n",
      "\titers: 700, epoch: 11 | loss: 0.0495706\n",
      "\tspeed: 0.0462s/iter; left time: 386.1215s\n",
      "\titers: 800, epoch: 11 | loss: 0.0451784\n",
      "\tspeed: 0.0461s/iter; left time: 380.7636s\n",
      "\titers: 900, epoch: 11 | loss: 0.0467793\n",
      "\tspeed: 0.0457s/iter; left time: 372.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 906 | Train Loss: 0.0497706 Vali Loss: 0.0569061 Test Loss: 0.0654467\n",
      "Validation loss decreased (0.057744 --> 0.056906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0482793\n",
      "\tspeed: 0.1185s/iter; left time: 954.5477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0434402\n",
      "\tspeed: 0.0469s/iter; left time: 373.0319s\n",
      "\titers: 300, epoch: 12 | loss: 0.0461225\n",
      "\tspeed: 0.0468s/iter; left time: 367.4067s\n",
      "\titers: 400, epoch: 12 | loss: 0.0501549\n",
      "\tspeed: 0.0464s/iter; left time: 359.7950s\n",
      "\titers: 500, epoch: 12 | loss: 0.0471101\n",
      "\tspeed: 0.0463s/iter; left time: 354.0828s\n",
      "\titers: 600, epoch: 12 | loss: 0.0460915\n",
      "\tspeed: 0.0465s/iter; left time: 351.2298s\n",
      "\titers: 700, epoch: 12 | loss: 0.0523421\n",
      "\tspeed: 0.0463s/iter; left time: 344.8894s\n",
      "\titers: 800, epoch: 12 | loss: 0.0561501\n",
      "\tspeed: 0.0463s/iter; left time: 340.8723s\n",
      "\titers: 900, epoch: 12 | loss: 0.0543579\n",
      "\tspeed: 0.0455s/iter; left time: 330.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.21s\n",
      "Steps: 906 | Train Loss: 0.0484071 Vali Loss: 0.0569519 Test Loss: 0.0658272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0523379\n",
      "\tspeed: 0.1142s/iter; left time: 816.6506s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463685\n",
      "\tspeed: 0.0469s/iter; left time: 330.3022s\n",
      "\titers: 300, epoch: 13 | loss: 0.0489728\n",
      "\tspeed: 0.0464s/iter; left time: 322.1361s\n",
      "\titers: 400, epoch: 13 | loss: 0.0463173\n",
      "\tspeed: 0.0466s/iter; left time: 319.2036s\n",
      "\titers: 500, epoch: 13 | loss: 0.0386495\n",
      "\tspeed: 0.0458s/iter; left time: 309.1874s\n",
      "\titers: 600, epoch: 13 | loss: 0.0483736\n",
      "\tspeed: 0.0458s/iter; left time: 304.3405s\n",
      "\titers: 700, epoch: 13 | loss: 0.0490400\n",
      "\tspeed: 0.0469s/iter; left time: 307.3407s\n",
      "\titers: 800, epoch: 13 | loss: 0.0517511\n",
      "\tspeed: 0.0468s/iter; left time: 302.1140s\n",
      "\titers: 900, epoch: 13 | loss: 0.0434999\n",
      "\tspeed: 0.0462s/iter; left time: 293.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.35s\n",
      "Steps: 906 | Train Loss: 0.0473505 Vali Loss: 0.0584924 Test Loss: 0.0682402\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0435317\n",
      "\tspeed: 0.1116s/iter; left time: 696.5768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0482684\n",
      "\tspeed: 0.0464s/iter; left time: 285.1611s\n",
      "\titers: 300, epoch: 14 | loss: 0.0464913\n",
      "\tspeed: 0.0466s/iter; left time: 281.6895s\n",
      "\titers: 400, epoch: 14 | loss: 0.0499952\n",
      "\tspeed: 0.0468s/iter; left time: 278.0407s\n",
      "\titers: 500, epoch: 14 | loss: 0.0423364\n",
      "\tspeed: 0.0467s/iter; left time: 272.6370s\n",
      "\titers: 600, epoch: 14 | loss: 0.0485045\n",
      "\tspeed: 0.0466s/iter; left time: 267.4313s\n",
      "\titers: 700, epoch: 14 | loss: 0.0436609\n",
      "\tspeed: 0.0464s/iter; left time: 261.8734s\n",
      "\titers: 800, epoch: 14 | loss: 0.0463641\n",
      "\tspeed: 0.0458s/iter; left time: 253.9245s\n",
      "\titers: 900, epoch: 14 | loss: 0.0399385\n",
      "\tspeed: 0.0464s/iter; left time: 252.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 906 | Train Loss: 0.0461858 Vali Loss: 0.0589781 Test Loss: 0.0686759\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0490868\n",
      "\tspeed: 0.1110s/iter; left time: 592.6486s\n",
      "\titers: 200, epoch: 15 | loss: 0.0424480\n",
      "\tspeed: 0.0471s/iter; left time: 246.8748s\n",
      "\titers: 300, epoch: 15 | loss: 0.0455182\n",
      "\tspeed: 0.0463s/iter; left time: 238.0161s\n",
      "\titers: 400, epoch: 15 | loss: 0.0462314\n",
      "\tspeed: 0.0462s/iter; left time: 232.5880s\n",
      "\titers: 500, epoch: 15 | loss: 0.0469817\n",
      "\tspeed: 0.0468s/iter; left time: 230.9556s\n",
      "\titers: 600, epoch: 15 | loss: 0.0399142\n",
      "\tspeed: 0.0461s/iter; left time: 223.0448s\n",
      "\titers: 700, epoch: 15 | loss: 0.0407262\n",
      "\tspeed: 0.0463s/iter; left time: 219.5031s\n",
      "\titers: 800, epoch: 15 | loss: 0.0469630\n",
      "\tspeed: 0.0464s/iter; left time: 215.1864s\n",
      "\titers: 900, epoch: 15 | loss: 0.0500793\n",
      "\tspeed: 0.0466s/iter; left time: 211.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.27s\n",
      "Steps: 906 | Train Loss: 0.0451721 Vali Loss: 0.0591949 Test Loss: 0.0692948\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0441049\n",
      "\tspeed: 0.1129s/iter; left time: 500.4201s\n",
      "\titers: 200, epoch: 16 | loss: 0.0419718\n",
      "\tspeed: 0.0465s/iter; left time: 201.4254s\n",
      "\titers: 300, epoch: 16 | loss: 0.0411529\n",
      "\tspeed: 0.0460s/iter; left time: 194.4386s\n",
      "\titers: 400, epoch: 16 | loss: 0.0435567\n",
      "\tspeed: 0.0456s/iter; left time: 188.5222s\n",
      "\titers: 500, epoch: 16 | loss: 0.0501134\n",
      "\tspeed: 0.0465s/iter; left time: 187.3870s\n",
      "\titers: 600, epoch: 16 | loss: 0.0526159\n",
      "\tspeed: 0.0455s/iter; left time: 178.9287s\n",
      "\titers: 700, epoch: 16 | loss: 0.0420197\n",
      "\tspeed: 0.0465s/iter; left time: 178.1328s\n",
      "\titers: 800, epoch: 16 | loss: 0.0490651\n",
      "\tspeed: 0.0466s/iter; left time: 174.0283s\n",
      "\titers: 900, epoch: 16 | loss: 0.0443328\n",
      "\tspeed: 0.0462s/iter; left time: 167.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:42.15s\n",
      "Steps: 906 | Train Loss: 0.0442571 Vali Loss: 0.0580243 Test Loss: 0.0665946\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012446870096027851, rmse:0.11156554520130157, mae:0.06534929573535919, rse:0.42161399126052856\n",
      "Intermediate time for IT and pred_len 24: 00h:24m:59.30s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2346102\n",
      "\tspeed: 0.0836s/iter; left time: 1502.8908s\n",
      "\titers: 200, epoch: 1 | loss: 0.2142702\n",
      "\tspeed: 0.0516s/iter; left time: 922.4463s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006122\n",
      "\tspeed: 0.0517s/iter; left time: 920.0968s\n",
      "\titers: 400, epoch: 1 | loss: 0.1997358\n",
      "\tspeed: 0.0522s/iter; left time: 923.4960s\n",
      "\titers: 500, epoch: 1 | loss: 0.2005629\n",
      "\tspeed: 0.0521s/iter; left time: 915.8504s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911706\n",
      "\tspeed: 0.0523s/iter; left time: 913.6639s\n",
      "\titers: 700, epoch: 1 | loss: 0.1871520\n",
      "\tspeed: 0.0516s/iter; left time: 897.4617s\n",
      "\titers: 800, epoch: 1 | loss: 0.1799988\n",
      "\tspeed: 0.0511s/iter; left time: 883.6368s\n",
      "\titers: 900, epoch: 1 | loss: 0.1866743\n",
      "\tspeed: 0.0519s/iter; left time: 891.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 904 | Train Loss: 0.2045585 Vali Loss: 0.1690600 Test Loss: 0.1870416\n",
      "Validation loss decreased (inf --> 0.169060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1703862\n",
      "\tspeed: 0.1369s/iter; left time: 2338.2148s\n",
      "\titers: 200, epoch: 2 | loss: 0.1623032\n",
      "\tspeed: 0.0521s/iter; left time: 883.7392s\n",
      "\titers: 300, epoch: 2 | loss: 0.1603419\n",
      "\tspeed: 0.0511s/iter; left time: 862.0315s\n",
      "\titers: 400, epoch: 2 | loss: 0.1485215\n",
      "\tspeed: 0.0513s/iter; left time: 860.0053s\n",
      "\titers: 500, epoch: 2 | loss: 0.1340641\n",
      "\tspeed: 0.0515s/iter; left time: 858.2297s\n",
      "\titers: 600, epoch: 2 | loss: 0.1223895\n",
      "\tspeed: 0.0516s/iter; left time: 855.4102s\n",
      "\titers: 700, epoch: 2 | loss: 0.1190573\n",
      "\tspeed: 0.0519s/iter; left time: 855.0865s\n",
      "\titers: 800, epoch: 2 | loss: 0.1006235\n",
      "\tspeed: 0.0515s/iter; left time: 844.0052s\n",
      "\titers: 900, epoch: 2 | loss: 0.0964359\n",
      "\tspeed: 0.0522s/iter; left time: 849.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.03s\n",
      "Steps: 904 | Train Loss: 0.1381357 Vali Loss: 0.0926630 Test Loss: 0.1002443\n",
      "Validation loss decreased (0.169060 --> 0.092663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0936791\n",
      "\tspeed: 0.1349s/iter; left time: 2181.6572s\n",
      "\titers: 200, epoch: 3 | loss: 0.0933003\n",
      "\tspeed: 0.0514s/iter; left time: 826.0103s\n",
      "\titers: 300, epoch: 3 | loss: 0.0929585\n",
      "\tspeed: 0.0514s/iter; left time: 820.8665s\n",
      "\titers: 400, epoch: 3 | loss: 0.0903624\n",
      "\tspeed: 0.0512s/iter; left time: 811.9754s\n",
      "\titers: 500, epoch: 3 | loss: 0.0857177\n",
      "\tspeed: 0.0508s/iter; left time: 801.2431s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911927\n",
      "\tspeed: 0.0507s/iter; left time: 793.8521s\n",
      "\titers: 700, epoch: 3 | loss: 0.0836361\n",
      "\tspeed: 0.0507s/iter; left time: 789.0365s\n",
      "\titers: 800, epoch: 3 | loss: 0.0931301\n",
      "\tspeed: 0.0506s/iter; left time: 782.9603s\n",
      "\titers: 900, epoch: 3 | loss: 0.0813277\n",
      "\tspeed: 0.0516s/iter; left time: 793.7182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.45s\n",
      "Steps: 904 | Train Loss: 0.0911522 Vali Loss: 0.0849023 Test Loss: 0.0922207\n",
      "Validation loss decreased (0.092663 --> 0.084902).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807011\n",
      "\tspeed: 0.1354s/iter; left time: 2066.9483s\n",
      "\titers: 200, epoch: 4 | loss: 0.0884485\n",
      "\tspeed: 0.0514s/iter; left time: 779.3313s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868657\n",
      "\tspeed: 0.0513s/iter; left time: 772.6133s\n",
      "\titers: 400, epoch: 4 | loss: 0.0818226\n",
      "\tspeed: 0.0513s/iter; left time: 767.3603s\n",
      "\titers: 500, epoch: 4 | loss: 0.0801383\n",
      "\tspeed: 0.0425s/iter; left time: 631.6506s\n",
      "\titers: 600, epoch: 4 | loss: 0.0800255\n",
      "\tspeed: 0.0500s/iter; left time: 737.8013s\n",
      "\titers: 700, epoch: 4 | loss: 0.0881254\n",
      "\tspeed: 0.0506s/iter; left time: 741.8925s\n",
      "\titers: 800, epoch: 4 | loss: 0.0750352\n",
      "\tspeed: 0.0520s/iter; left time: 757.3101s\n",
      "\titers: 900, epoch: 4 | loss: 0.0815959\n",
      "\tspeed: 0.0510s/iter; left time: 737.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 904 | Train Loss: 0.0842349 Vali Loss: 0.0822077 Test Loss: 0.0902671\n",
      "Validation loss decreased (0.084902 --> 0.082208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0822577\n",
      "\tspeed: 0.1347s/iter; left time: 1934.4378s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750880\n",
      "\tspeed: 0.0511s/iter; left time: 729.4213s\n",
      "\titers: 300, epoch: 5 | loss: 0.0845693\n",
      "\tspeed: 0.0509s/iter; left time: 720.7970s\n",
      "\titers: 400, epoch: 5 | loss: 0.0796774\n",
      "\tspeed: 0.0508s/iter; left time: 714.2798s\n",
      "\titers: 500, epoch: 5 | loss: 0.0784429\n",
      "\tspeed: 0.0515s/iter; left time: 718.6015s\n",
      "\titers: 600, epoch: 5 | loss: 0.0817848\n",
      "\tspeed: 0.0516s/iter; left time: 715.7869s\n",
      "\titers: 700, epoch: 5 | loss: 0.0782104\n",
      "\tspeed: 0.0507s/iter; left time: 697.8374s\n",
      "\titers: 800, epoch: 5 | loss: 0.0815488\n",
      "\tspeed: 0.0509s/iter; left time: 696.1949s\n",
      "\titers: 900, epoch: 5 | loss: 0.0798884\n",
      "\tspeed: 0.0510s/iter; left time: 691.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.53s\n",
      "Steps: 904 | Train Loss: 0.0794317 Vali Loss: 0.0809435 Test Loss: 0.0928860\n",
      "Validation loss decreased (0.082208 --> 0.080944).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0826950\n",
      "\tspeed: 0.1363s/iter; left time: 1834.1771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800711\n",
      "\tspeed: 0.0511s/iter; left time: 682.2562s\n",
      "\titers: 300, epoch: 6 | loss: 0.0783440\n",
      "\tspeed: 0.0526s/iter; left time: 697.7276s\n",
      "\titers: 400, epoch: 6 | loss: 0.0761599\n",
      "\tspeed: 0.0518s/iter; left time: 682.3269s\n",
      "\titers: 500, epoch: 6 | loss: 0.0720684\n",
      "\tspeed: 0.0513s/iter; left time: 670.1307s\n",
      "\titers: 600, epoch: 6 | loss: 0.0718406\n",
      "\tspeed: 0.0518s/iter; left time: 671.1483s\n",
      "\titers: 700, epoch: 6 | loss: 0.0753348\n",
      "\tspeed: 0.0516s/iter; left time: 663.7398s\n",
      "\titers: 800, epoch: 6 | loss: 0.0779216\n",
      "\tspeed: 0.0518s/iter; left time: 660.4063s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721837\n",
      "\tspeed: 0.0520s/iter; left time: 658.6227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.07s\n",
      "Steps: 904 | Train Loss: 0.0759032 Vali Loss: 0.0800776 Test Loss: 0.0901867\n",
      "Validation loss decreased (0.080944 --> 0.080078).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718432\n",
      "\tspeed: 0.1356s/iter; left time: 1702.2105s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773734\n",
      "\tspeed: 0.0518s/iter; left time: 645.6036s\n",
      "\titers: 300, epoch: 7 | loss: 0.0754037\n",
      "\tspeed: 0.0519s/iter; left time: 640.9338s\n",
      "\titers: 400, epoch: 7 | loss: 0.0701126\n",
      "\tspeed: 0.0514s/iter; left time: 630.1589s\n",
      "\titers: 500, epoch: 7 | loss: 0.0724805\n",
      "\tspeed: 0.0519s/iter; left time: 631.1501s\n",
      "\titers: 600, epoch: 7 | loss: 0.0637182\n",
      "\tspeed: 0.0429s/iter; left time: 517.6763s\n",
      "\titers: 700, epoch: 7 | loss: 0.0746906\n",
      "\tspeed: 0.0515s/iter; left time: 615.2225s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649625\n",
      "\tspeed: 0.0523s/iter; left time: 619.7528s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737293\n",
      "\tspeed: 0.0520s/iter; left time: 611.3888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.32s\n",
      "Steps: 904 | Train Loss: 0.0727564 Vali Loss: 0.0798132 Test Loss: 0.0905188\n",
      "Validation loss decreased (0.080078 --> 0.079813).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0764455\n",
      "\tspeed: 0.1345s/iter; left time: 1566.7566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762972\n",
      "\tspeed: 0.0518s/iter; left time: 598.1163s\n",
      "\titers: 300, epoch: 8 | loss: 0.0672638\n",
      "\tspeed: 0.0523s/iter; left time: 599.2583s\n",
      "\titers: 400, epoch: 8 | loss: 0.0701525\n",
      "\tspeed: 0.0523s/iter; left time: 593.7732s\n",
      "\titers: 500, epoch: 8 | loss: 0.0662000\n",
      "\tspeed: 0.0518s/iter; left time: 583.1192s\n",
      "\titers: 600, epoch: 8 | loss: 0.0694611\n",
      "\tspeed: 0.0517s/iter; left time: 576.2167s\n",
      "\titers: 700, epoch: 8 | loss: 0.0673127\n",
      "\tspeed: 0.0512s/iter; left time: 565.6331s\n",
      "\titers: 800, epoch: 8 | loss: 0.0704161\n",
      "\tspeed: 0.0514s/iter; left time: 562.6129s\n",
      "\titers: 900, epoch: 8 | loss: 0.0656521\n",
      "\tspeed: 0.0520s/iter; left time: 564.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 904 | Train Loss: 0.0696523 Vali Loss: 0.0797702 Test Loss: 0.0920613\n",
      "Validation loss decreased (0.079813 --> 0.079770).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0708809\n",
      "\tspeed: 0.1356s/iter; left time: 1457.7393s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683321\n",
      "\tspeed: 0.0502s/iter; left time: 534.9658s\n",
      "\titers: 300, epoch: 9 | loss: 0.0658918\n",
      "\tspeed: 0.0506s/iter; left time: 533.4506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0622855\n",
      "\tspeed: 0.0513s/iter; left time: 535.9716s\n",
      "\titers: 500, epoch: 9 | loss: 0.0712728\n",
      "\tspeed: 0.0511s/iter; left time: 529.0159s\n",
      "\titers: 600, epoch: 9 | loss: 0.0650618\n",
      "\tspeed: 0.0516s/iter; left time: 529.2829s\n",
      "\titers: 700, epoch: 9 | loss: 0.0621875\n",
      "\tspeed: 0.0516s/iter; left time: 523.5251s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671298\n",
      "\tspeed: 0.0508s/iter; left time: 510.2567s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658551\n",
      "\tspeed: 0.0521s/iter; left time: 517.8696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.56s\n",
      "Steps: 904 | Train Loss: 0.0671600 Vali Loss: 0.0818805 Test Loss: 0.0926254\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747117\n",
      "\tspeed: 0.1276s/iter; left time: 1255.7397s\n",
      "\titers: 200, epoch: 10 | loss: 0.0629282\n",
      "\tspeed: 0.0505s/iter; left time: 492.0581s\n",
      "\titers: 300, epoch: 10 | loss: 0.0615253\n",
      "\tspeed: 0.0502s/iter; left time: 484.5621s\n",
      "\titers: 400, epoch: 10 | loss: 0.0587503\n",
      "\tspeed: 0.0503s/iter; left time: 480.2918s\n",
      "\titers: 500, epoch: 10 | loss: 0.0707426\n",
      "\tspeed: 0.0507s/iter; left time: 478.8487s\n",
      "\titers: 600, epoch: 10 | loss: 0.0628930\n",
      "\tspeed: 0.0503s/iter; left time: 469.8034s\n",
      "\titers: 700, epoch: 10 | loss: 0.0636662\n",
      "\tspeed: 0.0508s/iter; left time: 469.9010s\n",
      "\titers: 800, epoch: 10 | loss: 0.0666468\n",
      "\tspeed: 0.0510s/iter; left time: 466.1574s\n",
      "\titers: 900, epoch: 10 | loss: 0.0652690\n",
      "\tspeed: 0.0506s/iter; left time: 457.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 904 | Train Loss: 0.0645158 Vali Loss: 0.0811130 Test Loss: 0.0931069\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0621498\n",
      "\tspeed: 0.1293s/iter; left time: 1156.0421s\n",
      "\titers: 200, epoch: 11 | loss: 0.0671997\n",
      "\tspeed: 0.0508s/iter; left time: 449.2967s\n",
      "\titers: 300, epoch: 11 | loss: 0.0566427\n",
      "\tspeed: 0.0511s/iter; left time: 446.7690s\n",
      "\titers: 400, epoch: 11 | loss: 0.0663417\n",
      "\tspeed: 0.0419s/iter; left time: 362.4651s\n",
      "\titers: 500, epoch: 11 | loss: 0.0570788\n",
      "\tspeed: 0.0407s/iter; left time: 347.8551s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601416\n",
      "\tspeed: 0.0515s/iter; left time: 434.6945s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623477\n",
      "\tspeed: 0.0517s/iter; left time: 430.8542s\n",
      "\titers: 800, epoch: 11 | loss: 0.0638136\n",
      "\tspeed: 0.0515s/iter; left time: 424.6432s\n",
      "\titers: 900, epoch: 11 | loss: 0.0633517\n",
      "\tspeed: 0.0515s/iter; left time: 419.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:44.77s\n",
      "Steps: 904 | Train Loss: 0.0621482 Vali Loss: 0.0833270 Test Loss: 0.0941476\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0597172\n",
      "\tspeed: 0.1209s/iter; left time: 971.7136s\n",
      "\titers: 200, epoch: 12 | loss: 0.0604670\n",
      "\tspeed: 0.0507s/iter; left time: 402.7161s\n",
      "\titers: 300, epoch: 12 | loss: 0.0571212\n",
      "\tspeed: 0.0506s/iter; left time: 396.2428s\n",
      "\titers: 400, epoch: 12 | loss: 0.0534001\n",
      "\tspeed: 0.0507s/iter; left time: 391.9751s\n",
      "\titers: 500, epoch: 12 | loss: 0.0627694\n",
      "\tspeed: 0.0508s/iter; left time: 388.0855s\n",
      "\titers: 600, epoch: 12 | loss: 0.0579445\n",
      "\tspeed: 0.0502s/iter; left time: 378.1049s\n",
      "\titers: 700, epoch: 12 | loss: 0.0641891\n",
      "\tspeed: 0.0497s/iter; left time: 369.2897s\n",
      "\titers: 800, epoch: 12 | loss: 0.0589688\n",
      "\tspeed: 0.0469s/iter; left time: 343.9118s\n",
      "\titers: 900, epoch: 12 | loss: 0.0612988\n",
      "\tspeed: 0.0417s/iter; left time: 302.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:44.01s\n",
      "Steps: 904 | Train Loss: 0.0602438 Vali Loss: 0.0849022 Test Loss: 0.0967499\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595376\n",
      "\tspeed: 0.1253s/iter; left time: 894.1169s\n",
      "\titers: 200, epoch: 13 | loss: 0.0561075\n",
      "\tspeed: 0.0405s/iter; left time: 284.5548s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545213\n",
      "\tspeed: 0.0463s/iter; left time: 320.6786s\n",
      "\titers: 400, epoch: 13 | loss: 0.0562269\n",
      "\tspeed: 0.0492s/iter; left time: 336.1617s\n",
      "\titers: 500, epoch: 13 | loss: 0.0604830\n",
      "\tspeed: 0.0500s/iter; left time: 336.9627s\n",
      "\titers: 600, epoch: 13 | loss: 0.0584102\n",
      "\tspeed: 0.0507s/iter; left time: 336.2902s\n",
      "\titers: 700, epoch: 13 | loss: 0.0524922\n",
      "\tspeed: 0.0505s/iter; left time: 330.0890s\n",
      "\titers: 800, epoch: 13 | loss: 0.0580739\n",
      "\tspeed: 0.0506s/iter; left time: 325.5880s\n",
      "\titers: 900, epoch: 13 | loss: 0.0583791\n",
      "\tspeed: 0.0494s/iter; left time: 312.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:44.18s\n",
      "Steps: 904 | Train Loss: 0.0583602 Vali Loss: 0.0844376 Test Loss: 0.0959828\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022557392716407776, rmse:0.15019118785858154, mae:0.09195020794868469, rse:0.5678890943527222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2311379\n",
      "\tspeed: 0.0546s/iter; left time: 981.7248s\n",
      "\titers: 200, epoch: 1 | loss: 0.2107387\n",
      "\tspeed: 0.0509s/iter; left time: 910.8108s\n",
      "\titers: 300, epoch: 1 | loss: 0.2088801\n",
      "\tspeed: 0.0511s/iter; left time: 908.0146s\n",
      "\titers: 400, epoch: 1 | loss: 0.2078077\n",
      "\tspeed: 0.0508s/iter; left time: 897.5353s\n",
      "\titers: 500, epoch: 1 | loss: 0.1975893\n",
      "\tspeed: 0.0509s/iter; left time: 894.0043s\n",
      "\titers: 600, epoch: 1 | loss: 0.1970696\n",
      "\tspeed: 0.0512s/iter; left time: 894.3397s\n",
      "\titers: 700, epoch: 1 | loss: 0.1888131\n",
      "\tspeed: 0.0510s/iter; left time: 887.1098s\n",
      "\titers: 800, epoch: 1 | loss: 0.1775232\n",
      "\tspeed: 0.0485s/iter; left time: 838.1275s\n",
      "\titers: 900, epoch: 1 | loss: 0.1805059\n",
      "\tspeed: 0.0495s/iter; left time: 849.6922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 904 | Train Loss: 0.2048719 Vali Loss: 0.1682425 Test Loss: 0.1862899\n",
      "Validation loss decreased (inf --> 0.168242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651758\n",
      "\tspeed: 0.1375s/iter; left time: 2347.3201s\n",
      "\titers: 200, epoch: 2 | loss: 0.1582526\n",
      "\tspeed: 0.0493s/iter; left time: 837.3827s\n",
      "\titers: 300, epoch: 2 | loss: 0.1334995\n",
      "\tspeed: 0.0504s/iter; left time: 851.4271s\n",
      "\titers: 400, epoch: 2 | loss: 0.1281435\n",
      "\tspeed: 0.0497s/iter; left time: 833.5652s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120991\n",
      "\tspeed: 0.0508s/iter; left time: 847.1016s\n",
      "\titers: 600, epoch: 2 | loss: 0.1063993\n",
      "\tspeed: 0.0502s/iter; left time: 832.0409s\n",
      "\titers: 700, epoch: 2 | loss: 0.1050140\n",
      "\tspeed: 0.0504s/iter; left time: 830.9362s\n",
      "\titers: 800, epoch: 2 | loss: 0.0939684\n",
      "\tspeed: 0.0507s/iter; left time: 829.6744s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027621\n",
      "\tspeed: 0.0506s/iter; left time: 823.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.1279720 Vali Loss: 0.0910116 Test Loss: 0.0978945\n",
      "Validation loss decreased (0.168242 --> 0.091012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874250\n",
      "\tspeed: 0.1345s/iter; left time: 2176.0240s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910681\n",
      "\tspeed: 0.0508s/iter; left time: 816.9962s\n",
      "\titers: 300, epoch: 3 | loss: 0.0960952\n",
      "\tspeed: 0.0507s/iter; left time: 810.2590s\n",
      "\titers: 400, epoch: 3 | loss: 0.1049342\n",
      "\tspeed: 0.0506s/iter; left time: 803.1317s\n",
      "\titers: 500, epoch: 3 | loss: 0.0909262\n",
      "\tspeed: 0.0509s/iter; left time: 802.7038s\n",
      "\titers: 600, epoch: 3 | loss: 0.0906060\n",
      "\tspeed: 0.0511s/iter; left time: 801.1169s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950601\n",
      "\tspeed: 0.0512s/iter; left time: 796.6056s\n",
      "\titers: 800, epoch: 3 | loss: 0.0871191\n",
      "\tspeed: 0.0504s/iter; left time: 780.2036s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931305\n",
      "\tspeed: 0.0502s/iter; left time: 772.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 904 | Train Loss: 0.0898878 Vali Loss: 0.0846631 Test Loss: 0.0933970\n",
      "Validation loss decreased (0.091012 --> 0.084663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790232\n",
      "\tspeed: 0.1300s/iter; left time: 1984.2621s\n",
      "\titers: 200, epoch: 4 | loss: 0.0902696\n",
      "\tspeed: 0.0507s/iter; left time: 768.3812s\n",
      "\titers: 300, epoch: 4 | loss: 0.0840954\n",
      "\tspeed: 0.0512s/iter; left time: 772.0275s\n",
      "\titers: 400, epoch: 4 | loss: 0.0806407\n",
      "\tspeed: 0.0505s/iter; left time: 755.6915s\n",
      "\titers: 500, epoch: 4 | loss: 0.0832484\n",
      "\tspeed: 0.0508s/iter; left time: 754.7856s\n",
      "\titers: 600, epoch: 4 | loss: 0.0873472\n",
      "\tspeed: 0.0510s/iter; left time: 753.1995s\n",
      "\titers: 700, epoch: 4 | loss: 0.0760519\n",
      "\tspeed: 0.0504s/iter; left time: 739.0469s\n",
      "\titers: 800, epoch: 4 | loss: 0.0904471\n",
      "\tspeed: 0.0505s/iter; left time: 736.2101s\n",
      "\titers: 900, epoch: 4 | loss: 0.0777563\n",
      "\tspeed: 0.0506s/iter; left time: 731.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0834705 Vali Loss: 0.0841414 Test Loss: 0.0939747\n",
      "Validation loss decreased (0.084663 --> 0.084141).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765879\n",
      "\tspeed: 0.1395s/iter; left time: 2003.2269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0705418\n",
      "\tspeed: 0.0506s/iter; left time: 722.3502s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873328\n",
      "\tspeed: 0.0507s/iter; left time: 717.7206s\n",
      "\titers: 400, epoch: 5 | loss: 0.0743462\n",
      "\tspeed: 0.0507s/iter; left time: 713.3268s\n",
      "\titers: 500, epoch: 5 | loss: 0.0757773\n",
      "\tspeed: 0.0504s/iter; left time: 703.1470s\n",
      "\titers: 600, epoch: 5 | loss: 0.0745896\n",
      "\tspeed: 0.0512s/iter; left time: 709.6763s\n",
      "\titers: 700, epoch: 5 | loss: 0.0764779\n",
      "\tspeed: 0.0507s/iter; left time: 697.4324s\n",
      "\titers: 800, epoch: 5 | loss: 0.0801189\n",
      "\tspeed: 0.0510s/iter; left time: 697.1266s\n",
      "\titers: 900, epoch: 5 | loss: 0.0745504\n",
      "\tspeed: 0.0505s/iter; left time: 684.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 904 | Train Loss: 0.0786197 Vali Loss: 0.0797811 Test Loss: 0.0875647\n",
      "Validation loss decreased (0.084141 --> 0.079781).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734403\n",
      "\tspeed: 0.1299s/iter; left time: 1748.5187s\n",
      "\titers: 200, epoch: 6 | loss: 0.0697036\n",
      "\tspeed: 0.0509s/iter; left time: 680.2679s\n",
      "\titers: 300, epoch: 6 | loss: 0.0720066\n",
      "\tspeed: 0.0509s/iter; left time: 674.8543s\n",
      "\titers: 400, epoch: 6 | loss: 0.0713798\n",
      "\tspeed: 0.0506s/iter; left time: 666.0969s\n",
      "\titers: 500, epoch: 6 | loss: 0.0751987\n",
      "\tspeed: 0.0508s/iter; left time: 663.5413s\n",
      "\titers: 600, epoch: 6 | loss: 0.0796741\n",
      "\tspeed: 0.0507s/iter; left time: 656.8715s\n",
      "\titers: 700, epoch: 6 | loss: 0.0704738\n",
      "\tspeed: 0.0505s/iter; left time: 649.4056s\n",
      "\titers: 800, epoch: 6 | loss: 0.0697082\n",
      "\tspeed: 0.0505s/iter; left time: 644.1371s\n",
      "\titers: 900, epoch: 6 | loss: 0.0710281\n",
      "\tspeed: 0.0509s/iter; left time: 644.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 904 | Train Loss: 0.0752827 Vali Loss: 0.0798891 Test Loss: 0.0936438\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0728502\n",
      "\tspeed: 0.1271s/iter; left time: 1596.0199s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820544\n",
      "\tspeed: 0.0508s/iter; left time: 633.1571s\n",
      "\titers: 300, epoch: 7 | loss: 0.0752040\n",
      "\tspeed: 0.0507s/iter; left time: 627.0224s\n",
      "\titers: 400, epoch: 7 | loss: 0.0719560\n",
      "\tspeed: 0.0508s/iter; left time: 622.9942s\n",
      "\titers: 500, epoch: 7 | loss: 0.0690600\n",
      "\tspeed: 0.0508s/iter; left time: 617.4039s\n",
      "\titers: 600, epoch: 7 | loss: 0.0686415\n",
      "\tspeed: 0.0514s/iter; left time: 620.3161s\n",
      "\titers: 700, epoch: 7 | loss: 0.0770732\n",
      "\tspeed: 0.0510s/iter; left time: 609.6197s\n",
      "\titers: 800, epoch: 7 | loss: 0.0647433\n",
      "\tspeed: 0.0510s/iter; left time: 604.5009s\n",
      "\titers: 900, epoch: 7 | loss: 0.0698012\n",
      "\tspeed: 0.0508s/iter; left time: 597.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 904 | Train Loss: 0.0721934 Vali Loss: 0.0802166 Test Loss: 0.0900334\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724484\n",
      "\tspeed: 0.1272s/iter; left time: 1482.3053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720747\n",
      "\tspeed: 0.0510s/iter; left time: 588.9821s\n",
      "\titers: 300, epoch: 8 | loss: 0.0671920\n",
      "\tspeed: 0.0514s/iter; left time: 588.5194s\n",
      "\titers: 400, epoch: 8 | loss: 0.0658102\n",
      "\tspeed: 0.0514s/iter; left time: 583.2008s\n",
      "\titers: 500, epoch: 8 | loss: 0.0691405\n",
      "\tspeed: 0.0512s/iter; left time: 576.1455s\n",
      "\titers: 600, epoch: 8 | loss: 0.0673880\n",
      "\tspeed: 0.0511s/iter; left time: 569.3840s\n",
      "\titers: 700, epoch: 8 | loss: 0.0676256\n",
      "\tspeed: 0.0508s/iter; left time: 561.2340s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773491\n",
      "\tspeed: 0.0502s/iter; left time: 549.6558s\n",
      "\titers: 900, epoch: 8 | loss: 0.0705851\n",
      "\tspeed: 0.0511s/iter; left time: 554.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.42s\n",
      "Steps: 904 | Train Loss: 0.0695177 Vali Loss: 0.0807144 Test Loss: 0.0903425\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667911\n",
      "\tspeed: 0.1272s/iter; left time: 1367.4071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0619899\n",
      "\tspeed: 0.0508s/iter; left time: 541.3632s\n",
      "\titers: 300, epoch: 9 | loss: 0.0688059\n",
      "\tspeed: 0.0508s/iter; left time: 536.2018s\n",
      "\titers: 400, epoch: 9 | loss: 0.0649368\n",
      "\tspeed: 0.0512s/iter; left time: 535.1446s\n",
      "\titers: 500, epoch: 9 | loss: 0.0658120\n",
      "\tspeed: 0.0507s/iter; left time: 525.0996s\n",
      "\titers: 600, epoch: 9 | loss: 0.0716825\n",
      "\tspeed: 0.0511s/iter; left time: 523.9275s\n",
      "\titers: 700, epoch: 9 | loss: 0.0709795\n",
      "\tspeed: 0.0506s/iter; left time: 513.7640s\n",
      "\titers: 800, epoch: 9 | loss: 0.0706118\n",
      "\tspeed: 0.0509s/iter; left time: 511.0694s\n",
      "\titers: 900, epoch: 9 | loss: 0.0659611\n",
      "\tspeed: 0.0509s/iter; left time: 506.2774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.31s\n",
      "Steps: 904 | Train Loss: 0.0666192 Vali Loss: 0.0834932 Test Loss: 0.0930626\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0744382\n",
      "\tspeed: 0.1273s/iter; left time: 1253.5433s\n",
      "\titers: 200, epoch: 10 | loss: 0.0630922\n",
      "\tspeed: 0.0510s/iter; left time: 497.1416s\n",
      "\titers: 300, epoch: 10 | loss: 0.0629388\n",
      "\tspeed: 0.0512s/iter; left time: 493.8345s\n",
      "\titers: 400, epoch: 10 | loss: 0.0620162\n",
      "\tspeed: 0.0508s/iter; left time: 484.9797s\n",
      "\titers: 500, epoch: 10 | loss: 0.0673733\n",
      "\tspeed: 0.0507s/iter; left time: 478.4284s\n",
      "\titers: 600, epoch: 10 | loss: 0.0673278\n",
      "\tspeed: 0.0502s/iter; left time: 468.7234s\n",
      "\titers: 700, epoch: 10 | loss: 0.0655921\n",
      "\tspeed: 0.0507s/iter; left time: 469.1414s\n",
      "\titers: 800, epoch: 10 | loss: 0.0597681\n",
      "\tspeed: 0.0508s/iter; left time: 464.1896s\n",
      "\titers: 900, epoch: 10 | loss: 0.0618950\n",
      "\tspeed: 0.0511s/iter; left time: 462.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 904 | Train Loss: 0.0642936 Vali Loss: 0.0834238 Test Loss: 0.0920974\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01962193101644516, rmse:0.14007830619812012, mae:0.08756327629089355, rse:0.5296511650085449\n",
      "Intermediate time for IT and pred_len 96: 00h:20m:55.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2406804\n",
      "\tspeed: 0.0817s/iter; left time: 1466.4552s\n",
      "\titers: 200, epoch: 1 | loss: 0.2127664\n",
      "\tspeed: 0.0526s/iter; left time: 938.9026s\n",
      "\titers: 300, epoch: 1 | loss: 0.2112524\n",
      "\tspeed: 0.0553s/iter; left time: 980.2543s\n",
      "\titers: 400, epoch: 1 | loss: 0.2002598\n",
      "\tspeed: 0.0530s/iter; left time: 934.7168s\n",
      "\titers: 500, epoch: 1 | loss: 0.2001060\n",
      "\tspeed: 0.0555s/iter; left time: 973.0592s\n",
      "\titers: 600, epoch: 1 | loss: 0.1987666\n",
      "\tspeed: 0.0551s/iter; left time: 961.5511s\n",
      "\titers: 700, epoch: 1 | loss: 0.1934598\n",
      "\tspeed: 0.0514s/iter; left time: 890.5093s\n",
      "\titers: 800, epoch: 1 | loss: 0.1944774\n",
      "\tspeed: 0.0507s/iter; left time: 874.6885s\n",
      "\titers: 900, epoch: 1 | loss: 0.1917253\n",
      "\tspeed: 0.0575s/iter; left time: 986.1786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.51s\n",
      "Steps: 902 | Train Loss: 0.2068505 Vali Loss: 0.1744625 Test Loss: 0.1911217\n",
      "Validation loss decreased (inf --> 0.174462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1737314\n",
      "\tspeed: 0.1531s/iter; left time: 2608.8091s\n",
      "\titers: 200, epoch: 2 | loss: 0.1589169\n",
      "\tspeed: 0.0549s/iter; left time: 930.0960s\n",
      "\titers: 300, epoch: 2 | loss: 0.1499351\n",
      "\tspeed: 0.0539s/iter; left time: 907.9172s\n",
      "\titers: 400, epoch: 2 | loss: 0.1438678\n",
      "\tspeed: 0.0514s/iter; left time: 859.6686s\n",
      "\titers: 500, epoch: 2 | loss: 0.1360246\n",
      "\tspeed: 0.0531s/iter; left time: 884.3623s\n",
      "\titers: 600, epoch: 2 | loss: 0.1343525\n",
      "\tspeed: 0.0524s/iter; left time: 866.9065s\n",
      "\titers: 700, epoch: 2 | loss: 0.1210604\n",
      "\tspeed: 0.0551s/iter; left time: 905.8356s\n",
      "\titers: 800, epoch: 2 | loss: 0.1088701\n",
      "\tspeed: 0.0542s/iter; left time: 885.7647s\n",
      "\titers: 900, epoch: 2 | loss: 0.1029986\n",
      "\tspeed: 0.0538s/iter; left time: 874.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.44s\n",
      "Steps: 902 | Train Loss: 0.1416033 Vali Loss: 0.1001055 Test Loss: 0.1089795\n",
      "Validation loss decreased (0.174462 --> 0.100105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053182\n",
      "\tspeed: 0.1566s/iter; left time: 2526.5100s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986656\n",
      "\tspeed: 0.0557s/iter; left time: 893.6372s\n",
      "\titers: 300, epoch: 3 | loss: 0.0984584\n",
      "\tspeed: 0.0541s/iter; left time: 862.0154s\n",
      "\titers: 400, epoch: 3 | loss: 0.0897405\n",
      "\tspeed: 0.0534s/iter; left time: 846.0256s\n",
      "\titers: 500, epoch: 3 | loss: 0.0952346\n",
      "\tspeed: 0.0555s/iter; left time: 873.6718s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963142\n",
      "\tspeed: 0.0544s/iter; left time: 851.3430s\n",
      "\titers: 700, epoch: 3 | loss: 0.0938548\n",
      "\tspeed: 0.0558s/iter; left time: 866.6090s\n",
      "\titers: 800, epoch: 3 | loss: 0.0881569\n",
      "\tspeed: 0.0536s/iter; left time: 827.9615s\n",
      "\titers: 900, epoch: 3 | loss: 0.0945525\n",
      "\tspeed: 0.0533s/iter; left time: 817.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.64s\n",
      "Steps: 902 | Train Loss: 0.0963866 Vali Loss: 0.0898182 Test Loss: 0.0998336\n",
      "Validation loss decreased (0.100105 --> 0.089818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0923409\n",
      "\tspeed: 0.1560s/iter; left time: 2375.9268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0874340\n",
      "\tspeed: 0.0516s/iter; left time: 781.4488s\n",
      "\titers: 300, epoch: 4 | loss: 0.0880191\n",
      "\tspeed: 0.0558s/iter; left time: 838.4748s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910763\n",
      "\tspeed: 0.0547s/iter; left time: 816.7020s\n",
      "\titers: 500, epoch: 4 | loss: 0.0871311\n",
      "\tspeed: 0.0556s/iter; left time: 825.3986s\n",
      "\titers: 600, epoch: 4 | loss: 0.0879892\n",
      "\tspeed: 0.0542s/iter; left time: 798.7329s\n",
      "\titers: 700, epoch: 4 | loss: 0.0853011\n",
      "\tspeed: 0.0548s/iter; left time: 802.0985s\n",
      "\titers: 800, epoch: 4 | loss: 0.0927186\n",
      "\tspeed: 0.0535s/iter; left time: 778.1233s\n",
      "\titers: 900, epoch: 4 | loss: 0.0857175\n",
      "\tspeed: 0.0561s/iter; left time: 810.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.63s\n",
      "Steps: 902 | Train Loss: 0.0889699 Vali Loss: 0.0872253 Test Loss: 0.0956871\n",
      "Validation loss decreased (0.089818 --> 0.087225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871143\n",
      "\tspeed: 0.1543s/iter; left time: 2211.2691s\n",
      "\titers: 200, epoch: 5 | loss: 0.0825435\n",
      "\tspeed: 0.0561s/iter; left time: 798.1456s\n",
      "\titers: 300, epoch: 5 | loss: 0.0854570\n",
      "\tspeed: 0.0548s/iter; left time: 774.9912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0884355\n",
      "\tspeed: 0.0553s/iter; left time: 776.3258s\n",
      "\titers: 500, epoch: 5 | loss: 0.0823852\n",
      "\tspeed: 0.0532s/iter; left time: 741.8953s\n",
      "\titers: 600, epoch: 5 | loss: 0.0858922\n",
      "\tspeed: 0.0570s/iter; left time: 788.3054s\n",
      "\titers: 700, epoch: 5 | loss: 0.0828293\n",
      "\tspeed: 0.0539s/iter; left time: 740.3683s\n",
      "\titers: 800, epoch: 5 | loss: 0.0816355\n",
      "\tspeed: 0.0548s/iter; left time: 746.9673s\n",
      "\titers: 900, epoch: 5 | loss: 0.0854966\n",
      "\tspeed: 0.0541s/iter; left time: 732.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.77s\n",
      "Steps: 902 | Train Loss: 0.0841458 Vali Loss: 0.0860987 Test Loss: 0.0951558\n",
      "Validation loss decreased (0.087225 --> 0.086099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0852132\n",
      "\tspeed: 0.1585s/iter; left time: 2129.1258s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888999\n",
      "\tspeed: 0.0537s/iter; left time: 715.7748s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834618\n",
      "\tspeed: 0.0535s/iter; left time: 708.3328s\n",
      "\titers: 400, epoch: 6 | loss: 0.0814066\n",
      "\tspeed: 0.0537s/iter; left time: 705.3339s\n",
      "\titers: 500, epoch: 6 | loss: 0.0789409\n",
      "\tspeed: 0.0542s/iter; left time: 706.3558s\n",
      "\titers: 600, epoch: 6 | loss: 0.0791459\n",
      "\tspeed: 0.0557s/iter; left time: 720.5780s\n",
      "\titers: 700, epoch: 6 | loss: 0.0796230\n",
      "\tspeed: 0.0511s/iter; left time: 656.2595s\n",
      "\titers: 800, epoch: 6 | loss: 0.0840694\n",
      "\tspeed: 0.0539s/iter; left time: 686.6397s\n",
      "\titers: 900, epoch: 6 | loss: 0.0776450\n",
      "\tspeed: 0.0566s/iter; left time: 714.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.47s\n",
      "Steps: 902 | Train Loss: 0.0804640 Vali Loss: 0.0859904 Test Loss: 0.0942083\n",
      "Validation loss decreased (0.086099 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0850125\n",
      "\tspeed: 0.1578s/iter; left time: 1977.6337s\n",
      "\titers: 200, epoch: 7 | loss: 0.0780817\n",
      "\tspeed: 0.0527s/iter; left time: 654.6849s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797425\n",
      "\tspeed: 0.0543s/iter; left time: 669.0924s\n",
      "\titers: 400, epoch: 7 | loss: 0.0827978\n",
      "\tspeed: 0.0556s/iter; left time: 680.1023s\n",
      "\titers: 500, epoch: 7 | loss: 0.0696051\n",
      "\tspeed: 0.0547s/iter; left time: 663.6758s\n",
      "\titers: 600, epoch: 7 | loss: 0.0784860\n",
      "\tspeed: 0.0541s/iter; left time: 650.9320s\n",
      "\titers: 700, epoch: 7 | loss: 0.0744822\n",
      "\tspeed: 0.0533s/iter; left time: 635.3568s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776769\n",
      "\tspeed: 0.0540s/iter; left time: 638.4604s\n",
      "\titers: 900, epoch: 7 | loss: 0.0753103\n",
      "\tspeed: 0.0535s/iter; left time: 627.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.11s\n",
      "Steps: 902 | Train Loss: 0.0767612 Vali Loss: 0.0869188 Test Loss: 0.0973250\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0760540\n",
      "\tspeed: 0.1513s/iter; left time: 1759.4278s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714573\n",
      "\tspeed: 0.0550s/iter; left time: 633.9818s\n",
      "\titers: 300, epoch: 8 | loss: 0.0771488\n",
      "\tspeed: 0.0542s/iter; left time: 619.4444s\n",
      "\titers: 400, epoch: 8 | loss: 0.0733557\n",
      "\tspeed: 0.0535s/iter; left time: 605.5521s\n",
      "\titers: 500, epoch: 8 | loss: 0.0753683\n",
      "\tspeed: 0.0549s/iter; left time: 616.2810s\n",
      "\titers: 600, epoch: 8 | loss: 0.0709704\n",
      "\tspeed: 0.0549s/iter; left time: 610.9294s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778525\n",
      "\tspeed: 0.0536s/iter; left time: 590.6503s\n",
      "\titers: 800, epoch: 8 | loss: 0.0728218\n",
      "\tspeed: 0.0539s/iter; left time: 589.2615s\n",
      "\titers: 900, epoch: 8 | loss: 0.0678858\n",
      "\tspeed: 0.0553s/iter; left time: 598.5270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.17s\n",
      "Steps: 902 | Train Loss: 0.0731265 Vali Loss: 0.0867562 Test Loss: 0.0984258\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0668934\n",
      "\tspeed: 0.1501s/iter; left time: 1610.2491s\n",
      "\titers: 200, epoch: 9 | loss: 0.0693415\n",
      "\tspeed: 0.0529s/iter; left time: 561.7101s\n",
      "\titers: 300, epoch: 9 | loss: 0.0720601\n",
      "\tspeed: 0.0552s/iter; left time: 581.3386s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665089\n",
      "\tspeed: 0.0568s/iter; left time: 591.7464s\n",
      "\titers: 500, epoch: 9 | loss: 0.0702857\n",
      "\tspeed: 0.0554s/iter; left time: 571.5155s\n",
      "\titers: 600, epoch: 9 | loss: 0.0722413\n",
      "\tspeed: 0.0547s/iter; left time: 558.9576s\n",
      "\titers: 700, epoch: 9 | loss: 0.0672538\n",
      "\tspeed: 0.0557s/iter; left time: 563.7864s\n",
      "\titers: 800, epoch: 9 | loss: 0.0681854\n",
      "\tspeed: 0.0561s/iter; left time: 562.3897s\n",
      "\titers: 900, epoch: 9 | loss: 0.0679674\n",
      "\tspeed: 0.0543s/iter; left time: 538.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.91s\n",
      "Steps: 902 | Train Loss: 0.0695120 Vali Loss: 0.0878431 Test Loss: 0.0970462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669751\n",
      "\tspeed: 0.1569s/iter; left time: 1541.1966s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686549\n",
      "\tspeed: 0.0549s/iter; left time: 533.9789s\n",
      "\titers: 300, epoch: 10 | loss: 0.0665885\n",
      "\tspeed: 0.0558s/iter; left time: 536.5697s\n",
      "\titers: 400, epoch: 10 | loss: 0.0687989\n",
      "\tspeed: 0.0546s/iter; left time: 519.6203s\n",
      "\titers: 500, epoch: 10 | loss: 0.0638649\n",
      "\tspeed: 0.0546s/iter; left time: 514.3068s\n",
      "\titers: 600, epoch: 10 | loss: 0.0652834\n",
      "\tspeed: 0.0588s/iter; left time: 548.0039s\n",
      "\titers: 700, epoch: 10 | loss: 0.0634052\n",
      "\tspeed: 0.0558s/iter; left time: 514.4173s\n",
      "\titers: 800, epoch: 10 | loss: 0.0706556\n",
      "\tspeed: 0.0543s/iter; left time: 495.7766s\n",
      "\titers: 900, epoch: 10 | loss: 0.0622955\n",
      "\tspeed: 0.0545s/iter; left time: 491.9339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.27s\n",
      "Steps: 902 | Train Loss: 0.0662096 Vali Loss: 0.0881258 Test Loss: 0.0997533\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642025\n",
      "\tspeed: 0.1530s/iter; left time: 1364.8534s\n",
      "\titers: 200, epoch: 11 | loss: 0.0620056\n",
      "\tspeed: 0.0575s/iter; left time: 507.0875s\n",
      "\titers: 300, epoch: 11 | loss: 0.0635489\n",
      "\tspeed: 0.0551s/iter; left time: 480.7605s\n",
      "\titers: 400, epoch: 11 | loss: 0.0652145\n",
      "\tspeed: 0.0548s/iter; left time: 472.3013s\n",
      "\titers: 500, epoch: 11 | loss: 0.0608407\n",
      "\tspeed: 0.0540s/iter; left time: 459.8280s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624363\n",
      "\tspeed: 0.0554s/iter; left time: 466.5403s\n",
      "\titers: 700, epoch: 11 | loss: 0.0605113\n",
      "\tspeed: 0.0556s/iter; left time: 462.3131s\n",
      "\titers: 800, epoch: 11 | loss: 0.0605089\n",
      "\tspeed: 0.0525s/iter; left time: 431.7932s\n",
      "\titers: 900, epoch: 11 | loss: 0.0593132\n",
      "\tspeed: 0.0587s/iter; left time: 476.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.29s\n",
      "Steps: 902 | Train Loss: 0.0631221 Vali Loss: 0.0902975 Test Loss: 0.0980740\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02240457385778427, rmse:0.14968156814575195, mae:0.09415119886398315, rse:0.5663532018661499\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2267673\n",
      "\tspeed: 0.0583s/iter; left time: 1045.9809s\n",
      "\titers: 200, epoch: 1 | loss: 0.2210553\n",
      "\tspeed: 0.0550s/iter; left time: 980.5110s\n",
      "\titers: 300, epoch: 1 | loss: 0.2116144\n",
      "\tspeed: 0.0556s/iter; left time: 986.0592s\n",
      "\titers: 400, epoch: 1 | loss: 0.2097916\n",
      "\tspeed: 0.0557s/iter; left time: 982.4223s\n",
      "\titers: 500, epoch: 1 | loss: 0.1997766\n",
      "\tspeed: 0.0551s/iter; left time: 967.0799s\n",
      "\titers: 600, epoch: 1 | loss: 0.1958111\n",
      "\tspeed: 0.0559s/iter; left time: 974.1841s\n",
      "\titers: 700, epoch: 1 | loss: 0.1964175\n",
      "\tspeed: 0.0568s/iter; left time: 984.5643s\n",
      "\titers: 800, epoch: 1 | loss: 0.1797141\n",
      "\tspeed: 0.0559s/iter; left time: 962.9982s\n",
      "\titers: 900, epoch: 1 | loss: 0.1917520\n",
      "\tspeed: 0.0550s/iter; left time: 943.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.51s\n",
      "Steps: 902 | Train Loss: 0.2058786 Vali Loss: 0.1700873 Test Loss: 0.1877915\n",
      "Validation loss decreased (inf --> 0.170087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1742273\n",
      "\tspeed: 0.1688s/iter; left time: 2876.9281s\n",
      "\titers: 200, epoch: 2 | loss: 0.1734163\n",
      "\tspeed: 0.0570s/iter; left time: 965.2957s\n",
      "\titers: 300, epoch: 2 | loss: 0.1682757\n",
      "\tspeed: 0.0567s/iter; left time: 954.7038s\n",
      "\titers: 400, epoch: 2 | loss: 0.1633339\n",
      "\tspeed: 0.0580s/iter; left time: 971.3836s\n",
      "\titers: 500, epoch: 2 | loss: 0.1598000\n",
      "\tspeed: 0.0570s/iter; left time: 948.1086s\n",
      "\titers: 600, epoch: 2 | loss: 0.1490487\n",
      "\tspeed: 0.0556s/iter; left time: 919.7467s\n",
      "\titers: 700, epoch: 2 | loss: 0.1348605\n",
      "\tspeed: 0.0615s/iter; left time: 1010.6949s\n",
      "\titers: 800, epoch: 2 | loss: 0.1170168\n",
      "\tspeed: 0.0601s/iter; left time: 982.5901s\n",
      "\titers: 900, epoch: 2 | loss: 0.1081366\n",
      "\tspeed: 0.0569s/iter; left time: 923.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:52.47s\n",
      "Steps: 902 | Train Loss: 0.1525863 Vali Loss: 0.1007635 Test Loss: 0.1088220\n",
      "Validation loss decreased (0.170087 --> 0.100763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1067860\n",
      "\tspeed: 0.1679s/iter; left time: 2709.6611s\n",
      "\titers: 200, epoch: 3 | loss: 0.1000163\n",
      "\tspeed: 0.0568s/iter; left time: 910.7521s\n",
      "\titers: 300, epoch: 3 | loss: 0.0990415\n",
      "\tspeed: 0.0554s/iter; left time: 883.6522s\n",
      "\titers: 400, epoch: 3 | loss: 0.1030617\n",
      "\tspeed: 0.0540s/iter; left time: 855.8820s\n",
      "\titers: 500, epoch: 3 | loss: 0.0993092\n",
      "\tspeed: 0.0666s/iter; left time: 1047.7999s\n",
      "\titers: 600, epoch: 3 | loss: 0.0939378\n",
      "\tspeed: 0.0559s/iter; left time: 874.0815s\n",
      "\titers: 700, epoch: 3 | loss: 0.0941445\n",
      "\tspeed: 0.0564s/iter; left time: 876.9514s\n",
      "\titers: 800, epoch: 3 | loss: 0.0921857\n",
      "\tspeed: 0.0558s/iter; left time: 860.7323s\n",
      "\titers: 900, epoch: 3 | loss: 0.0946364\n",
      "\tspeed: 0.0561s/iter; left time: 860.7192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.88s\n",
      "Steps: 902 | Train Loss: 0.0968587 Vali Loss: 0.0869811 Test Loss: 0.0956921\n",
      "Validation loss decreased (0.100763 --> 0.086981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0898372\n",
      "\tspeed: 0.1603s/iter; left time: 2442.8469s\n",
      "\titers: 200, epoch: 4 | loss: 0.0991435\n",
      "\tspeed: 0.0600s/iter; left time: 908.3866s\n",
      "\titers: 300, epoch: 4 | loss: 0.0840835\n",
      "\tspeed: 0.0570s/iter; left time: 857.6776s\n",
      "\titers: 400, epoch: 4 | loss: 0.0929531\n",
      "\tspeed: 0.0567s/iter; left time: 847.3360s\n",
      "\titers: 500, epoch: 4 | loss: 0.0892102\n",
      "\tspeed: 0.0589s/iter; left time: 873.8471s\n",
      "\titers: 600, epoch: 4 | loss: 0.0850115\n",
      "\tspeed: 0.0579s/iter; left time: 852.8185s\n",
      "\titers: 700, epoch: 4 | loss: 0.0912520\n",
      "\tspeed: 0.0579s/iter; left time: 847.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.0880117\n",
      "\tspeed: 0.0586s/iter; left time: 851.4412s\n",
      "\titers: 900, epoch: 4 | loss: 0.0846420\n",
      "\tspeed: 0.0597s/iter; left time: 862.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 902 | Train Loss: 0.0884787 Vali Loss: 0.0848812 Test Loss: 0.0973621\n",
      "Validation loss decreased (0.086981 --> 0.084881).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0810058\n",
      "\tspeed: 0.1752s/iter; left time: 2510.9140s\n",
      "\titers: 200, epoch: 5 | loss: 0.0882122\n",
      "\tspeed: 0.0558s/iter; left time: 793.5904s\n",
      "\titers: 300, epoch: 5 | loss: 0.0831145\n",
      "\tspeed: 0.0617s/iter; left time: 872.6356s\n",
      "\titers: 400, epoch: 5 | loss: 0.0829300\n",
      "\tspeed: 0.0590s/iter; left time: 827.8140s\n",
      "\titers: 500, epoch: 5 | loss: 0.0805245\n",
      "\tspeed: 0.0577s/iter; left time: 803.3644s\n",
      "\titers: 600, epoch: 5 | loss: 0.0844140\n",
      "\tspeed: 0.0566s/iter; left time: 783.0987s\n",
      "\titers: 700, epoch: 5 | loss: 0.0788835\n",
      "\tspeed: 0.0549s/iter; left time: 753.8863s\n",
      "\titers: 800, epoch: 5 | loss: 0.0826269\n",
      "\tspeed: 0.0625s/iter; left time: 851.4778s\n",
      "\titers: 900, epoch: 5 | loss: 0.0806869\n",
      "\tspeed: 0.0567s/iter; left time: 767.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:52.90s\n",
      "Steps: 902 | Train Loss: 0.0836713 Vali Loss: 0.0863794 Test Loss: 0.0963056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0811056\n",
      "\tspeed: 0.1616s/iter; left time: 2170.4834s\n",
      "\titers: 200, epoch: 6 | loss: 0.0835971\n",
      "\tspeed: 0.0552s/iter; left time: 736.3368s\n",
      "\titers: 300, epoch: 6 | loss: 0.0877080\n",
      "\tspeed: 0.0561s/iter; left time: 741.9850s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781132\n",
      "\tspeed: 0.0559s/iter; left time: 734.1611s\n",
      "\titers: 500, epoch: 6 | loss: 0.0830950\n",
      "\tspeed: 0.0504s/iter; left time: 656.7932s\n",
      "\titers: 600, epoch: 6 | loss: 0.0777409\n",
      "\tspeed: 0.0541s/iter; left time: 699.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.0786194\n",
      "\tspeed: 0.0597s/iter; left time: 766.0671s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790971\n",
      "\tspeed: 0.0533s/iter; left time: 678.1970s\n",
      "\titers: 900, epoch: 6 | loss: 0.0779720\n",
      "\tspeed: 0.0552s/iter; left time: 697.5122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.19s\n",
      "Steps: 902 | Train Loss: 0.0798447 Vali Loss: 0.0831233 Test Loss: 0.0931060\n",
      "Validation loss decreased (0.084881 --> 0.083123).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769085\n",
      "\tspeed: 0.1622s/iter; left time: 2032.7722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753283\n",
      "\tspeed: 0.0577s/iter; left time: 716.9315s\n",
      "\titers: 300, epoch: 7 | loss: 0.0888861\n",
      "\tspeed: 0.0562s/iter; left time: 692.8608s\n",
      "\titers: 400, epoch: 7 | loss: 0.0752653\n",
      "\tspeed: 0.0551s/iter; left time: 673.7293s\n",
      "\titers: 500, epoch: 7 | loss: 0.0852774\n",
      "\tspeed: 0.0562s/iter; left time: 681.6918s\n",
      "\titers: 600, epoch: 7 | loss: 0.0713650\n",
      "\tspeed: 0.0561s/iter; left time: 674.3091s\n",
      "\titers: 700, epoch: 7 | loss: 0.0733699\n",
      "\tspeed: 0.0551s/iter; left time: 657.5945s\n",
      "\titers: 800, epoch: 7 | loss: 0.0775007\n",
      "\tspeed: 0.0546s/iter; left time: 646.1685s\n",
      "\titers: 900, epoch: 7 | loss: 0.0741364\n",
      "\tspeed: 0.0596s/iter; left time: 698.5567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.28s\n",
      "Steps: 902 | Train Loss: 0.0764814 Vali Loss: 0.0855528 Test Loss: 0.0939845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789248\n",
      "\tspeed: 0.1542s/iter; left time: 1792.6305s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775377\n",
      "\tspeed: 0.0560s/iter; left time: 646.0597s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762293\n",
      "\tspeed: 0.0552s/iter; left time: 630.3400s\n",
      "\titers: 400, epoch: 8 | loss: 0.0747236\n",
      "\tspeed: 0.0546s/iter; left time: 618.3556s\n",
      "\titers: 500, epoch: 8 | loss: 0.0730445\n",
      "\tspeed: 0.0604s/iter; left time: 678.0439s\n",
      "\titers: 600, epoch: 8 | loss: 0.0738466\n",
      "\tspeed: 0.0559s/iter; left time: 621.7854s\n",
      "\titers: 700, epoch: 8 | loss: 0.0768590\n",
      "\tspeed: 0.0553s/iter; left time: 609.9158s\n",
      "\titers: 800, epoch: 8 | loss: 0.0759818\n",
      "\tspeed: 0.0561s/iter; left time: 612.5215s\n",
      "\titers: 900, epoch: 8 | loss: 0.0694436\n",
      "\tspeed: 0.0542s/iter; left time: 586.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.75s\n",
      "Steps: 902 | Train Loss: 0.0734237 Vali Loss: 0.0894040 Test Loss: 0.0991596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0683368\n",
      "\tspeed: 0.1553s/iter; left time: 1666.0632s\n",
      "\titers: 200, epoch: 9 | loss: 0.0713612\n",
      "\tspeed: 0.0561s/iter; left time: 596.3141s\n",
      "\titers: 300, epoch: 9 | loss: 0.0733693\n",
      "\tspeed: 0.0557s/iter; left time: 586.4202s\n",
      "\titers: 400, epoch: 9 | loss: 0.0686704\n",
      "\tspeed: 0.0563s/iter; left time: 586.7292s\n",
      "\titers: 500, epoch: 9 | loss: 0.0714800\n",
      "\tspeed: 0.0552s/iter; left time: 570.2415s\n",
      "\titers: 600, epoch: 9 | loss: 0.0691100\n",
      "\tspeed: 0.0573s/iter; left time: 586.2351s\n",
      "\titers: 700, epoch: 9 | loss: 0.0644889\n",
      "\tspeed: 0.0552s/iter; left time: 559.2290s\n",
      "\titers: 800, epoch: 9 | loss: 0.0633002\n",
      "\tspeed: 0.0602s/iter; left time: 603.5210s\n",
      "\titers: 900, epoch: 9 | loss: 0.0722990\n",
      "\tspeed: 0.0576s/iter; left time: 571.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:51.77s\n",
      "Steps: 902 | Train Loss: 0.0704051 Vali Loss: 0.0860073 Test Loss: 0.0975743\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682998\n",
      "\tspeed: 0.1545s/iter; left time: 1517.8492s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692387\n",
      "\tspeed: 0.0545s/iter; left time: 530.2173s\n",
      "\titers: 300, epoch: 10 | loss: 0.0657472\n",
      "\tspeed: 0.0551s/iter; left time: 529.9181s\n",
      "\titers: 400, epoch: 10 | loss: 0.0671159\n",
      "\tspeed: 0.0610s/iter; left time: 580.7138s\n",
      "\titers: 500, epoch: 10 | loss: 0.0671956\n",
      "\tspeed: 0.0555s/iter; left time: 522.5556s\n",
      "\titers: 600, epoch: 10 | loss: 0.0691979\n",
      "\tspeed: 0.0543s/iter; left time: 505.8060s\n",
      "\titers: 700, epoch: 10 | loss: 0.0719837\n",
      "\tspeed: 0.0556s/iter; left time: 512.7235s\n",
      "\titers: 800, epoch: 10 | loss: 0.0659146\n",
      "\tspeed: 0.0551s/iter; left time: 502.5871s\n",
      "\titers: 900, epoch: 10 | loss: 0.0624403\n",
      "\tspeed: 0.0553s/iter; left time: 499.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.56s\n",
      "Steps: 902 | Train Loss: 0.0673667 Vali Loss: 0.0881326 Test Loss: 0.0972519\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0659390\n",
      "\tspeed: 0.1599s/iter; left time: 1426.1146s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711790\n",
      "\tspeed: 0.0541s/iter; left time: 477.5863s\n",
      "\titers: 300, epoch: 11 | loss: 0.0636270\n",
      "\tspeed: 0.0564s/iter; left time: 491.4331s\n",
      "\titers: 400, epoch: 11 | loss: 0.0594921\n",
      "\tspeed: 0.0559s/iter; left time: 482.3355s\n",
      "\titers: 500, epoch: 11 | loss: 0.0676920\n",
      "\tspeed: 0.0546s/iter; left time: 465.1431s\n",
      "\titers: 600, epoch: 11 | loss: 0.0632904\n",
      "\tspeed: 0.0554s/iter; left time: 466.3358s\n",
      "\titers: 700, epoch: 11 | loss: 0.0643619\n",
      "\tspeed: 0.0544s/iter; left time: 452.7133s\n",
      "\titers: 800, epoch: 11 | loss: 0.0635986\n",
      "\tspeed: 0.0591s/iter; left time: 485.7729s\n",
      "\titers: 900, epoch: 11 | loss: 0.0704689\n",
      "\tspeed: 0.0558s/iter; left time: 453.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.82s\n",
      "Steps: 902 | Train Loss: 0.0645314 Vali Loss: 0.0900577 Test Loss: 0.0986329\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0215200986713171, rmse:0.1466972976922989, mae:0.09315669536590576, rse:0.5550615191459656\n",
      "Intermediate time for IT and pred_len 168: 00h:22m:28.46s\n",
      "Intermediate time for IT: 01h:08m:23.33s\n",
      "Total time: 05h:14m:11.86s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 336\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1369714\n",
      "\tspeed: 0.0541s/iter; left time: 1205.4753s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247781\n",
      "\tspeed: 0.0266s/iter; left time: 591.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.1417671 Vali Loss: 0.1297606 Test Loss: 0.1347090\n",
      "Validation loss decreased (inf --> 0.129761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869461\n",
      "\tspeed: 0.0521s/iter; left time: 1150.1137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833711\n",
      "\tspeed: 0.0267s/iter; left time: 587.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0896184 Vali Loss: 0.0936917 Test Loss: 0.0950095\n",
      "Validation loss decreased (0.129761 --> 0.093692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0781575\n",
      "\tspeed: 0.0518s/iter; left time: 1132.7286s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792153\n",
      "\tspeed: 0.0268s/iter; left time: 582.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0797606 Vali Loss: 0.0909321 Test Loss: 0.0923397\n",
      "Validation loss decreased (0.093692 --> 0.090932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807218\n",
      "\tspeed: 0.0511s/iter; left time: 1106.0893s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808649\n",
      "\tspeed: 0.0267s/iter; left time: 574.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0773325 Vali Loss: 0.0890039 Test Loss: 0.0909385\n",
      "Validation loss decreased (0.090932 --> 0.089004).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773130\n",
      "\tspeed: 0.0520s/iter; left time: 1112.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0740610\n",
      "\tspeed: 0.0267s/iter; left time: 569.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0885584 Test Loss: 0.0901798\n",
      "Validation loss decreased (0.089004 --> 0.088558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830306\n",
      "\tspeed: 0.0516s/iter; left time: 1093.4893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726725\n",
      "\tspeed: 0.0267s/iter; left time: 563.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0749306 Vali Loss: 0.0880955 Test Loss: 0.0901085\n",
      "Validation loss decreased (0.088558 --> 0.088095).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732605\n",
      "\tspeed: 0.0517s/iter; left time: 1082.8480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776332\n",
      "\tspeed: 0.0267s/iter; left time: 555.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0740759 Vali Loss: 0.0876682 Test Loss: 0.0896309\n",
      "Validation loss decreased (0.088095 --> 0.087668).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715202\n",
      "\tspeed: 0.0528s/iter; left time: 1093.9648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723670\n",
      "\tspeed: 0.0267s/iter; left time: 550.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0736438 Vali Loss: 0.0882936 Test Loss: 0.0894522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775626\n",
      "\tspeed: 0.0514s/iter; left time: 1054.5261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756080\n",
      "\tspeed: 0.0267s/iter; left time: 545.5887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0733198 Vali Loss: 0.0876187 Test Loss: 0.0892001\n",
      "Validation loss decreased (0.087668 --> 0.087619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0764146\n",
      "\tspeed: 0.0525s/iter; left time: 1064.7971s\n",
      "\titers: 200, epoch: 10 | loss: 0.0708030\n",
      "\tspeed: 0.0265s/iter; left time: 535.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0727986 Vali Loss: 0.0873704 Test Loss: 0.0889288\n",
      "Validation loss decreased (0.087619 --> 0.087370).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678855\n",
      "\tspeed: 0.0522s/iter; left time: 1048.0739s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720052\n",
      "\tspeed: 0.0268s/iter; left time: 534.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0725260 Vali Loss: 0.0871207 Test Loss: 0.0886076\n",
      "Validation loss decreased (0.087370 --> 0.087121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715223\n",
      "\tspeed: 0.0519s/iter; left time: 1030.5229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0742159\n",
      "\tspeed: 0.0266s/iter; left time: 524.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0722907 Vali Loss: 0.0866924 Test Loss: 0.0887910\n",
      "Validation loss decreased (0.087121 --> 0.086692).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0667619\n",
      "\tspeed: 0.0517s/iter; left time: 1013.0115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701735\n",
      "\tspeed: 0.0267s/iter; left time: 520.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0720069 Vali Loss: 0.0869621 Test Loss: 0.0883650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710825\n",
      "\tspeed: 0.0510s/iter; left time: 988.5146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727319\n",
      "\tspeed: 0.0266s/iter; left time: 512.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0718207 Vali Loss: 0.0862084 Test Loss: 0.0881200\n",
      "Validation loss decreased (0.086692 --> 0.086208).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721587\n",
      "\tspeed: 0.0518s/iter; left time: 993.4135s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660384\n",
      "\tspeed: 0.0267s/iter; left time: 509.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0716865 Vali Loss: 0.0862676 Test Loss: 0.0882083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0726189\n",
      "\tspeed: 0.0513s/iter; left time: 971.7333s\n",
      "\titers: 200, epoch: 16 | loss: 0.0699743\n",
      "\tspeed: 0.0266s/iter; left time: 500.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0715561 Vali Loss: 0.0862403 Test Loss: 0.0882708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734295\n",
      "\tspeed: 0.0508s/iter; left time: 950.7064s\n",
      "\titers: 200, epoch: 17 | loss: 0.0729700\n",
      "\tspeed: 0.0269s/iter; left time: 499.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0714500 Vali Loss: 0.0860131 Test Loss: 0.0878391\n",
      "Validation loss decreased (0.086208 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720860\n",
      "\tspeed: 0.0510s/iter; left time: 943.6124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807038\n",
      "\tspeed: 0.0285s/iter; left time: 524.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0712926 Vali Loss: 0.0858605 Test Loss: 0.0881299\n",
      "Validation loss decreased (0.086013 --> 0.085860).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0672827\n",
      "\tspeed: 0.0521s/iter; left time: 952.6361s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683527\n",
      "\tspeed: 0.0268s/iter; left time: 486.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0712880 Vali Loss: 0.0860396 Test Loss: 0.0881207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685089\n",
      "\tspeed: 0.0512s/iter; left time: 924.0535s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723603\n",
      "\tspeed: 0.0266s/iter; left time: 477.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0711309 Vali Loss: 0.0858991 Test Loss: 0.0879555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0669795\n",
      "\tspeed: 0.0510s/iter; left time: 908.4794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729611\n",
      "\tspeed: 0.0266s/iter; left time: 471.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0710612 Vali Loss: 0.0858557 Test Loss: 0.0878603\n",
      "Validation loss decreased (0.085860 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0644646\n",
      "\tspeed: 0.0516s/iter; left time: 908.2609s\n",
      "\titers: 200, epoch: 22 | loss: 0.0674015\n",
      "\tspeed: 0.0267s/iter; left time: 466.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0709746 Vali Loss: 0.0858742 Test Loss: 0.0879468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0715065\n",
      "\tspeed: 0.0506s/iter; left time: 878.9808s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664888\n",
      "\tspeed: 0.0266s/iter; left time: 459.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0708909 Vali Loss: 0.0858572 Test Loss: 0.0878468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697132\n",
      "\tspeed: 0.0514s/iter; left time: 881.7388s\n",
      "\titers: 200, epoch: 24 | loss: 0.0695731\n",
      "\tspeed: 0.0265s/iter; left time: 451.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0709061 Vali Loss: 0.0856822 Test Loss: 0.0878505\n",
      "Validation loss decreased (0.085856 --> 0.085682).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0698776\n",
      "\tspeed: 0.0509s/iter; left time: 862.2074s\n",
      "\titers: 200, epoch: 25 | loss: 0.0794153\n",
      "\tspeed: 0.0264s/iter; left time: 444.6524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0708391 Vali Loss: 0.0857899 Test Loss: 0.0877605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0693570\n",
      "\tspeed: 0.0507s/iter; left time: 847.0964s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686728\n",
      "\tspeed: 0.0267s/iter; left time: 442.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708132 Vali Loss: 0.0856289 Test Loss: 0.0876225\n",
      "Validation loss decreased (0.085682 --> 0.085629).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736588\n",
      "\tspeed: 0.0522s/iter; left time: 859.5258s\n",
      "\titers: 200, epoch: 27 | loss: 0.0751999\n",
      "\tspeed: 0.0266s/iter; left time: 435.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0706946 Vali Loss: 0.0857887 Test Loss: 0.0877622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681836\n",
      "\tspeed: 0.0513s/iter; left time: 834.2176s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738424\n",
      "\tspeed: 0.0267s/iter; left time: 430.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0707199 Vali Loss: 0.0856799 Test Loss: 0.0876857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0720591\n",
      "\tspeed: 0.0512s/iter; left time: 820.0638s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661264\n",
      "\tspeed: 0.0267s/iter; left time: 425.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0706302 Vali Loss: 0.0856200 Test Loss: 0.0876701\n",
      "Validation loss decreased (0.085629 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0764758\n",
      "\tspeed: 0.0525s/iter; left time: 829.9523s\n",
      "\titers: 200, epoch: 30 | loss: 0.0717371\n",
      "\tspeed: 0.0265s/iter; left time: 415.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0705703 Vali Loss: 0.0856172 Test Loss: 0.0877889\n",
      "Validation loss decreased (0.085620 --> 0.085617).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0694562\n",
      "\tspeed: 0.0528s/iter; left time: 823.0867s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669540\n",
      "\tspeed: 0.0271s/iter; left time: 420.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0705669 Vali Loss: 0.0855405 Test Loss: 0.0876212\n",
      "Validation loss decreased (0.085617 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648792\n",
      "\tspeed: 0.0519s/iter; left time: 796.4069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0739037\n",
      "\tspeed: 0.0265s/iter; left time: 403.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0705570 Vali Loss: 0.0856224 Test Loss: 0.0876501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760883\n",
      "\tspeed: 0.0509s/iter; left time: 769.5590s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659316\n",
      "\tspeed: 0.0264s/iter; left time: 397.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0705282 Vali Loss: 0.0856680 Test Loss: 0.0876398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700403\n",
      "\tspeed: 0.0509s/iter; left time: 758.6267s\n",
      "\titers: 200, epoch: 34 | loss: 0.0733599\n",
      "\tspeed: 0.0265s/iter; left time: 392.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0705505 Vali Loss: 0.0856534 Test Loss: 0.0876419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0716821\n",
      "\tspeed: 0.0509s/iter; left time: 747.2629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0660121\n",
      "\tspeed: 0.0267s/iter; left time: 389.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0704936 Vali Loss: 0.0856017 Test Loss: 0.0876743\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702281\n",
      "\tspeed: 0.0520s/iter; left time: 751.7426s\n",
      "\titers: 200, epoch: 36 | loss: 0.0758533\n",
      "\tspeed: 0.0268s/iter; left time: 385.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704848 Vali Loss: 0.0856520 Test Loss: 0.0876421\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0775575\n",
      "\tspeed: 0.0516s/iter; left time: 734.5360s\n",
      "\titers: 200, epoch: 37 | loss: 0.0730687\n",
      "\tspeed: 0.0267s/iter; left time: 377.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0705037 Vali Loss: 0.0856726 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0694183\n",
      "\tspeed: 0.0517s/iter; left time: 724.0252s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666340\n",
      "\tspeed: 0.0268s/iter; left time: 372.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704922 Vali Loss: 0.0855943 Test Loss: 0.0876738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0741279\n",
      "\tspeed: 0.0517s/iter; left time: 713.1725s\n",
      "\titers: 200, epoch: 39 | loss: 0.0680151\n",
      "\tspeed: 0.0268s/iter; left time: 366.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704478 Vali Loss: 0.0855522 Test Loss: 0.0876500\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0680514\n",
      "\tspeed: 0.0510s/iter; left time: 691.1667s\n",
      "\titers: 200, epoch: 40 | loss: 0.0764029\n",
      "\tspeed: 0.0265s/iter; left time: 356.5305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704099 Vali Loss: 0.0856432 Test Loss: 0.0876450\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0655310\n",
      "\tspeed: 0.0508s/iter; left time: 677.2596s\n",
      "\titers: 200, epoch: 41 | loss: 0.0691073\n",
      "\tspeed: 0.0268s/iter; left time: 355.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703985 Vali Loss: 0.0854845 Test Loss: 0.0875877\n",
      "Validation loss decreased (0.085541 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682409\n",
      "\tspeed: 0.0513s/iter; left time: 672.5361s\n",
      "\titers: 200, epoch: 42 | loss: 0.0763331\n",
      "\tspeed: 0.0265s/iter; left time: 345.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0704444 Vali Loss: 0.0856361 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755680\n",
      "\tspeed: 0.0513s/iter; left time: 661.0572s\n",
      "\titers: 200, epoch: 43 | loss: 0.0719940\n",
      "\tspeed: 0.0265s/iter; left time: 339.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704495 Vali Loss: 0.0855508 Test Loss: 0.0876172\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644201\n",
      "\tspeed: 0.0509s/iter; left time: 645.4822s\n",
      "\titers: 200, epoch: 44 | loss: 0.0712258\n",
      "\tspeed: 0.0265s/iter; left time: 333.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704013 Vali Loss: 0.0855588 Test Loss: 0.0876322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0704731\n",
      "\tspeed: 0.0520s/iter; left time: 647.4943s\n",
      "\titers: 200, epoch: 45 | loss: 0.0729366\n",
      "\tspeed: 0.0265s/iter; left time: 327.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703918 Vali Loss: 0.0855635 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0704228\n",
      "\tspeed: 0.0513s/iter; left time: 627.0158s\n",
      "\titers: 200, epoch: 46 | loss: 0.0755504\n",
      "\tspeed: 0.0266s/iter; left time: 323.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703368 Vali Loss: 0.0855913 Test Loss: 0.0876351\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0714861\n",
      "\tspeed: 0.0527s/iter; left time: 632.7437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0703084\n",
      "\tspeed: 0.0270s/iter; left time: 321.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0703858 Vali Loss: 0.0855839 Test Loss: 0.0876863\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0716547\n",
      "\tspeed: 0.0512s/iter; left time: 603.1520s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697001\n",
      "\tspeed: 0.0269s/iter; left time: 314.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703595 Vali Loss: 0.0855201 Test Loss: 0.0876336\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0721770\n",
      "\tspeed: 0.0514s/iter; left time: 593.2863s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752482\n",
      "\tspeed: 0.0269s/iter; left time: 308.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703970 Vali Loss: 0.0854210 Test Loss: 0.0876339\n",
      "Validation loss decreased (0.085485 --> 0.085421).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0676463\n",
      "\tspeed: 0.0513s/iter; left time: 580.5348s\n",
      "\titers: 200, epoch: 50 | loss: 0.0677730\n",
      "\tspeed: 0.0265s/iter; left time: 297.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703362 Vali Loss: 0.0856355 Test Loss: 0.0876200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0666008\n",
      "\tspeed: 0.0516s/iter; left time: 573.0979s\n",
      "\titers: 200, epoch: 51 | loss: 0.0702993\n",
      "\tspeed: 0.0268s/iter; left time: 294.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0703573 Vali Loss: 0.0855665 Test Loss: 0.0876208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0723010\n",
      "\tspeed: 0.0510s/iter; left time: 555.1316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758060\n",
      "\tspeed: 0.0265s/iter; left time: 285.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703259 Vali Loss: 0.0854868 Test Loss: 0.0876280\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0706884\n",
      "\tspeed: 0.0514s/iter; left time: 547.3564s\n",
      "\titers: 200, epoch: 53 | loss: 0.0751953\n",
      "\tspeed: 0.0265s/iter; left time: 280.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703530 Vali Loss: 0.0855637 Test Loss: 0.0876266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0702771\n",
      "\tspeed: 0.0513s/iter; left time: 535.4939s\n",
      "\titers: 200, epoch: 54 | loss: 0.0684877\n",
      "\tspeed: 0.0268s/iter; left time: 277.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703710 Vali Loss: 0.0855449 Test Loss: 0.0876197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688983\n",
      "\tspeed: 0.0514s/iter; left time: 524.3484s\n",
      "\titers: 200, epoch: 55 | loss: 0.0738532\n",
      "\tspeed: 0.0269s/iter; left time: 271.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703545 Vali Loss: 0.0854906 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0730539\n",
      "\tspeed: 0.0526s/iter; left time: 525.1879s\n",
      "\titers: 200, epoch: 56 | loss: 0.0674224\n",
      "\tspeed: 0.0266s/iter; left time: 263.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704173 Vali Loss: 0.0854536 Test Loss: 0.0876250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0707048\n",
      "\tspeed: 0.0513s/iter; left time: 500.7753s\n",
      "\titers: 200, epoch: 57 | loss: 0.0710349\n",
      "\tspeed: 0.0265s/iter; left time: 255.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703584 Vali Loss: 0.0855452 Test Loss: 0.0876381\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736169\n",
      "\tspeed: 0.0504s/iter; left time: 480.1522s\n",
      "\titers: 200, epoch: 58 | loss: 0.0741034\n",
      "\tspeed: 0.0266s/iter; left time: 250.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703132 Vali Loss: 0.0855490 Test Loss: 0.0876148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0710790\n",
      "\tspeed: 0.0514s/iter; left time: 478.3326s\n",
      "\titers: 200, epoch: 59 | loss: 0.0729701\n",
      "\tspeed: 0.0269s/iter; left time: 247.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703250 Vali Loss: 0.0855128 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020939357578754425, rmse:0.14470438659191132, mae:0.08763387054204941, rse:0.5106817483901978\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1389406\n",
      "\tspeed: 0.0286s/iter; left time: 637.3228s\n",
      "\titers: 200, epoch: 1 | loss: 0.1228134\n",
      "\tspeed: 0.0266s/iter; left time: 590.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1422911 Vali Loss: 0.1295809 Test Loss: 0.1351006\n",
      "Validation loss decreased (inf --> 0.129581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877811\n",
      "\tspeed: 0.0524s/iter; left time: 1157.5606s\n",
      "\titers: 200, epoch: 2 | loss: 0.0832211\n",
      "\tspeed: 0.0267s/iter; left time: 585.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0894358 Vali Loss: 0.0936241 Test Loss: 0.0940987\n",
      "Validation loss decreased (0.129581 --> 0.093624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775893\n",
      "\tspeed: 0.0529s/iter; left time: 1155.7753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735417\n",
      "\tspeed: 0.0268s/iter; left time: 582.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0796590 Vali Loss: 0.0902558 Test Loss: 0.0915840\n",
      "Validation loss decreased (0.093624 --> 0.090256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0772389\n",
      "\tspeed: 0.0535s/iter; left time: 1157.4906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764423\n",
      "\tspeed: 0.0267s/iter; left time: 575.2471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0774734 Vali Loss: 0.0893443 Test Loss: 0.0907840\n",
      "Validation loss decreased (0.090256 --> 0.089344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743019\n",
      "\tspeed: 0.0524s/iter; left time: 1122.3344s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750691\n",
      "\tspeed: 0.0266s/iter; left time: 566.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0761713 Vali Loss: 0.0888839 Test Loss: 0.0900800\n",
      "Validation loss decreased (0.089344 --> 0.088884).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0693859\n",
      "\tspeed: 0.0531s/iter; left time: 1125.5393s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754470\n",
      "\tspeed: 0.0268s/iter; left time: 564.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0751449 Vali Loss: 0.0878856 Test Loss: 0.0899183\n",
      "Validation loss decreased (0.088884 --> 0.087886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723351\n",
      "\tspeed: 0.0524s/iter; left time: 1098.0215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741934\n",
      "\tspeed: 0.0266s/iter; left time: 553.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0744148 Vali Loss: 0.0882161 Test Loss: 0.0896968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743478\n",
      "\tspeed: 0.0515s/iter; left time: 1067.8407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734460\n",
      "\tspeed: 0.0266s/iter; left time: 547.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0738465 Vali Loss: 0.0875170 Test Loss: 0.0890645\n",
      "Validation loss decreased (0.087886 --> 0.087517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690735\n",
      "\tspeed: 0.0529s/iter; left time: 1085.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759658\n",
      "\tspeed: 0.0267s/iter; left time: 545.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0733618 Vali Loss: 0.0870617 Test Loss: 0.0888512\n",
      "Validation loss decreased (0.087517 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763888\n",
      "\tspeed: 0.0540s/iter; left time: 1095.9059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748855\n",
      "\tspeed: 0.0267s/iter; left time: 538.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0729996 Vali Loss: 0.0868114 Test Loss: 0.0887925\n",
      "Validation loss decreased (0.087062 --> 0.086811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753090\n",
      "\tspeed: 0.0522s/iter; left time: 1047.6334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728513\n",
      "\tspeed: 0.0265s/iter; left time: 528.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0726921 Vali Loss: 0.0872061 Test Loss: 0.0885696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705457\n",
      "\tspeed: 0.0520s/iter; left time: 1031.3150s\n",
      "\titers: 200, epoch: 12 | loss: 0.0726305\n",
      "\tspeed: 0.0265s/iter; left time: 523.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723711 Vali Loss: 0.0864833 Test Loss: 0.0882598\n",
      "Validation loss decreased (0.086811 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700529\n",
      "\tspeed: 0.0524s/iter; left time: 1027.1079s\n",
      "\titers: 200, epoch: 13 | loss: 0.0684496\n",
      "\tspeed: 0.0267s/iter; left time: 520.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0721546 Vali Loss: 0.0865951 Test Loss: 0.0883359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748019\n",
      "\tspeed: 0.0529s/iter; left time: 1024.8560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713811\n",
      "\tspeed: 0.0270s/iter; left time: 520.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0719527 Vali Loss: 0.0866737 Test Loss: 0.0880236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713503\n",
      "\tspeed: 0.0521s/iter; left time: 999.2792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763744\n",
      "\tspeed: 0.0266s/iter; left time: 506.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0716899 Vali Loss: 0.0864420 Test Loss: 0.0880862\n",
      "Validation loss decreased (0.086483 --> 0.086442).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746533\n",
      "\tspeed: 0.0524s/iter; left time: 992.8871s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665798\n",
      "\tspeed: 0.0265s/iter; left time: 499.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0715671 Vali Loss: 0.0860693 Test Loss: 0.0879256\n",
      "Validation loss decreased (0.086442 --> 0.086069).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704673\n",
      "\tspeed: 0.0527s/iter; left time: 987.2801s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683351\n",
      "\tspeed: 0.0268s/iter; left time: 498.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0714092 Vali Loss: 0.0860398 Test Loss: 0.0881202\n",
      "Validation loss decreased (0.086069 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692278\n",
      "\tspeed: 0.0532s/iter; left time: 984.5075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706096\n",
      "\tspeed: 0.0265s/iter; left time: 487.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0713103 Vali Loss: 0.0860568 Test Loss: 0.0880662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711174\n",
      "\tspeed: 0.0527s/iter; left time: 963.1993s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707833\n",
      "\tspeed: 0.0265s/iter; left time: 480.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0711834 Vali Loss: 0.0858907 Test Loss: 0.0879579\n",
      "Validation loss decreased (0.086040 --> 0.085891).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700932\n",
      "\tspeed: 0.0527s/iter; left time: 951.2086s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701582\n",
      "\tspeed: 0.0268s/iter; left time: 480.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0710876 Vali Loss: 0.0862701 Test Loss: 0.0880781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699507\n",
      "\tspeed: 0.0528s/iter; left time: 940.8659s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683075\n",
      "\tspeed: 0.0267s/iter; left time: 473.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0710427 Vali Loss: 0.0861612 Test Loss: 0.0881739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0751726\n",
      "\tspeed: 0.0519s/iter; left time: 912.4235s\n",
      "\titers: 200, epoch: 22 | loss: 0.0686039\n",
      "\tspeed: 0.0265s/iter; left time: 464.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0709314 Vali Loss: 0.0859297 Test Loss: 0.0879431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740635\n",
      "\tspeed: 0.0530s/iter; left time: 920.0264s\n",
      "\titers: 200, epoch: 23 | loss: 0.0754669\n",
      "\tspeed: 0.0267s/iter; left time: 460.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0708511 Vali Loss: 0.0858247 Test Loss: 0.0877661\n",
      "Validation loss decreased (0.085891 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0669902\n",
      "\tspeed: 0.0531s/iter; left time: 911.2386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0699968\n",
      "\tspeed: 0.0264s/iter; left time: 450.4041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708038 Vali Loss: 0.0857948 Test Loss: 0.0880593\n",
      "Validation loss decreased (0.085825 --> 0.085795).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0710267\n",
      "\tspeed: 0.0519s/iter; left time: 878.6579s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701005\n",
      "\tspeed: 0.0265s/iter; left time: 445.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0707550 Vali Loss: 0.0858620 Test Loss: 0.0879302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0675721\n",
      "\tspeed: 0.0519s/iter; left time: 866.8273s\n",
      "\titers: 200, epoch: 26 | loss: 0.0723306\n",
      "\tspeed: 0.0266s/iter; left time: 441.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0707452 Vali Loss: 0.0857506 Test Loss: 0.0878565\n",
      "Validation loss decreased (0.085795 --> 0.085751).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725780\n",
      "\tspeed: 0.0528s/iter; left time: 869.7247s\n",
      "\titers: 200, epoch: 27 | loss: 0.0715543\n",
      "\tspeed: 0.0268s/iter; left time: 438.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0706913 Vali Loss: 0.0857717 Test Loss: 0.0878863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0656819\n",
      "\tspeed: 0.0536s/iter; left time: 870.6048s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728222\n",
      "\tspeed: 0.0269s/iter; left time: 434.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0706028 Vali Loss: 0.0855976 Test Loss: 0.0878353\n",
      "Validation loss decreased (0.085751 --> 0.085598).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716999\n",
      "\tspeed: 0.0531s/iter; left time: 850.3424s\n",
      "\titers: 200, epoch: 29 | loss: 0.0711410\n",
      "\tspeed: 0.0265s/iter; left time: 422.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0705973 Vali Loss: 0.0859616 Test Loss: 0.0878585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0745615\n",
      "\tspeed: 0.0523s/iter; left time: 827.2763s\n",
      "\titers: 200, epoch: 30 | loss: 0.0758140\n",
      "\tspeed: 0.0269s/iter; left time: 422.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705595 Vali Loss: 0.0856872 Test Loss: 0.0878131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0744614\n",
      "\tspeed: 0.0525s/iter; left time: 818.0931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0705624\n",
      "\tspeed: 0.0267s/iter; left time: 414.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705045 Vali Loss: 0.0857018 Test Loss: 0.0878923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0687968\n",
      "\tspeed: 0.0528s/iter; left time: 810.4927s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645319\n",
      "\tspeed: 0.0267s/iter; left time: 406.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0705371 Vali Loss: 0.0856552 Test Loss: 0.0878005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0692253\n",
      "\tspeed: 0.0522s/iter; left time: 790.4230s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719842\n",
      "\tspeed: 0.0267s/iter; left time: 401.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0704541 Vali Loss: 0.0857210 Test Loss: 0.0878580\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0711537\n",
      "\tspeed: 0.0519s/iter; left time: 773.8731s\n",
      "\titers: 200, epoch: 34 | loss: 0.0700859\n",
      "\tspeed: 0.0267s/iter; left time: 395.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704086 Vali Loss: 0.0857385 Test Loss: 0.0877898\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0727249\n",
      "\tspeed: 0.0525s/iter; left time: 771.6492s\n",
      "\titers: 200, epoch: 35 | loss: 0.0703164\n",
      "\tspeed: 0.0265s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0704289 Vali Loss: 0.0856548 Test Loss: 0.0878404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0692909\n",
      "\tspeed: 0.0518s/iter; left time: 749.3944s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745890\n",
      "\tspeed: 0.0265s/iter; left time: 380.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704170 Vali Loss: 0.0855795 Test Loss: 0.0877761\n",
      "Validation loss decreased (0.085598 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669411\n",
      "\tspeed: 0.0523s/iter; left time: 743.9817s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717780\n",
      "\tspeed: 0.0265s/iter; left time: 374.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703451 Vali Loss: 0.0857678 Test Loss: 0.0877872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0692922\n",
      "\tspeed: 0.0523s/iter; left time: 732.2128s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706012\n",
      "\tspeed: 0.0274s/iter; left time: 381.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0703509 Vali Loss: 0.0856808 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0644956\n",
      "\tspeed: 0.0523s/iter; left time: 721.3358s\n",
      "\titers: 200, epoch: 39 | loss: 0.0683517\n",
      "\tspeed: 0.0265s/iter; left time: 362.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0703036 Vali Loss: 0.0857069 Test Loss: 0.0877940\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712174\n",
      "\tspeed: 0.0528s/iter; left time: 716.0116s\n",
      "\titers: 200, epoch: 40 | loss: 0.0717972\n",
      "\tspeed: 0.0266s/iter; left time: 357.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703386 Vali Loss: 0.0855974 Test Loss: 0.0877805\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0709783\n",
      "\tspeed: 0.0521s/iter; left time: 694.8751s\n",
      "\titers: 200, epoch: 41 | loss: 0.0727384\n",
      "\tspeed: 0.0267s/iter; left time: 353.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703057 Vali Loss: 0.0855847 Test Loss: 0.0877485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0696685\n",
      "\tspeed: 0.0521s/iter; left time: 684.0514s\n",
      "\titers: 200, epoch: 42 | loss: 0.0708702\n",
      "\tspeed: 0.0266s/iter; left time: 345.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0702815 Vali Loss: 0.0856937 Test Loss: 0.0877606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755521\n",
      "\tspeed: 0.0524s/iter; left time: 675.6540s\n",
      "\titers: 200, epoch: 43 | loss: 0.0711717\n",
      "\tspeed: 0.0266s/iter; left time: 340.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0703419 Vali Loss: 0.0854786 Test Loss: 0.0877750\n",
      "Validation loss decreased (0.085579 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0711064\n",
      "\tspeed: 0.0524s/iter; left time: 664.3796s\n",
      "\titers: 200, epoch: 44 | loss: 0.0720553\n",
      "\tspeed: 0.0267s/iter; left time: 335.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703236 Vali Loss: 0.0856422 Test Loss: 0.0877193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0685135\n",
      "\tspeed: 0.0518s/iter; left time: 645.1912s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710313\n",
      "\tspeed: 0.0270s/iter; left time: 333.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703195 Vali Loss: 0.0855412 Test Loss: 0.0877509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0682689\n",
      "\tspeed: 0.0519s/iter; left time: 634.1017s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663539\n",
      "\tspeed: 0.0265s/iter; left time: 321.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702857 Vali Loss: 0.0856832 Test Loss: 0.0877343\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0781750\n",
      "\tspeed: 0.0532s/iter; left time: 637.8936s\n",
      "\titers: 200, epoch: 47 | loss: 0.0668642\n",
      "\tspeed: 0.0267s/iter; left time: 317.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0703067 Vali Loss: 0.0856037 Test Loss: 0.0877680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0757289\n",
      "\tspeed: 0.0527s/iter; left time: 620.0069s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714607\n",
      "\tspeed: 0.0265s/iter; left time: 309.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703030 Vali Loss: 0.0855959 Test Loss: 0.0877536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0738765\n",
      "\tspeed: 0.0524s/iter; left time: 605.3152s\n",
      "\titers: 200, epoch: 49 | loss: 0.0682928\n",
      "\tspeed: 0.0268s/iter; left time: 306.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703193 Vali Loss: 0.0856737 Test Loss: 0.0877642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0721883\n",
      "\tspeed: 0.0523s/iter; left time: 592.4528s\n",
      "\titers: 200, epoch: 50 | loss: 0.0696596\n",
      "\tspeed: 0.0266s/iter; left time: 298.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0702247 Vali Loss: 0.0856217 Test Loss: 0.0877349\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0724216\n",
      "\tspeed: 0.0521s/iter; left time: 578.8286s\n",
      "\titers: 200, epoch: 51 | loss: 0.0683385\n",
      "\tspeed: 0.0264s/iter; left time: 290.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0702224 Vali Loss: 0.0856550 Test Loss: 0.0877666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707191\n",
      "\tspeed: 0.0517s/iter; left time: 562.1389s\n",
      "\titers: 200, epoch: 52 | loss: 0.0697485\n",
      "\tspeed: 0.0265s/iter; left time: 285.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702648 Vali Loss: 0.0856051 Test Loss: 0.0877736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0723032\n",
      "\tspeed: 0.0528s/iter; left time: 562.8959s\n",
      "\titers: 200, epoch: 53 | loss: 0.0695717\n",
      "\tspeed: 0.0266s/iter; left time: 280.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0702753 Vali Loss: 0.0856733 Test Loss: 0.0877745\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020994756370782852, rmse:0.14489567279815674, mae:0.08777499943971634, rse:0.5113568902015686\n",
      "Intermediate time for DE and pred_len 24: 00h:14m:50.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487391\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1487s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375452\n",
      "\tspeed: 0.0269s/iter; left time: 598.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.1484455 Vali Loss: 0.1405499 Test Loss: 0.1490060\n",
      "Validation loss decreased (inf --> 0.140550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1194897\n",
      "\tspeed: 0.0533s/iter; left time: 1176.9588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064227\n",
      "\tspeed: 0.0268s/iter; left time: 588.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1145359 Vali Loss: 0.1213630 Test Loss: 0.1295630\n",
      "Validation loss decreased (0.140550 --> 0.121363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036745\n",
      "\tspeed: 0.0540s/iter; left time: 1179.6751s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068880\n",
      "\tspeed: 0.0268s/iter; left time: 583.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1064633 Vali Loss: 0.1195266 Test Loss: 0.1282235\n",
      "Validation loss decreased (0.121363 --> 0.119527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1044791\n",
      "\tspeed: 0.0537s/iter; left time: 1160.7622s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004268\n",
      "\tspeed: 0.0269s/iter; left time: 579.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1045039 Vali Loss: 0.1190653 Test Loss: 0.1280503\n",
      "Validation loss decreased (0.119527 --> 0.119065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030031\n",
      "\tspeed: 0.0531s/iter; left time: 1137.1471s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965900\n",
      "\tspeed: 0.0268s/iter; left time: 570.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1033400 Vali Loss: 0.1186632 Test Loss: 0.1276050\n",
      "Validation loss decreased (0.119065 --> 0.118663).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1102587\n",
      "\tspeed: 0.0538s/iter; left time: 1140.5733s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076527\n",
      "\tspeed: 0.0269s/iter; left time: 567.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1024590 Vali Loss: 0.1179634 Test Loss: 0.1265461\n",
      "Validation loss decreased (0.118663 --> 0.117963).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025728\n",
      "\tspeed: 0.0538s/iter; left time: 1126.7627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953970\n",
      "\tspeed: 0.0269s/iter; left time: 560.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1016823 Vali Loss: 0.1186003 Test Loss: 0.1277381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998731\n",
      "\tspeed: 0.0539s/iter; left time: 1116.5655s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977558\n",
      "\tspeed: 0.0267s/iter; left time: 551.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1010973 Vali Loss: 0.1182861 Test Loss: 0.1272469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0999197\n",
      "\tspeed: 0.0532s/iter; left time: 1090.9066s\n",
      "\titers: 200, epoch: 9 | loss: 0.1026386\n",
      "\tspeed: 0.0268s/iter; left time: 546.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1004929 Vali Loss: 0.1175796 Test Loss: 0.1266904\n",
      "Validation loss decreased (0.117963 --> 0.117580).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008377\n",
      "\tspeed: 0.0538s/iter; left time: 1091.6922s\n",
      "\titers: 200, epoch: 10 | loss: 0.0974689\n",
      "\tspeed: 0.0268s/iter; left time: 541.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1000229 Vali Loss: 0.1174014 Test Loss: 0.1273050\n",
      "Validation loss decreased (0.117580 --> 0.117401).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0975121\n",
      "\tspeed: 0.0536s/iter; left time: 1074.5040s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031677\n",
      "\tspeed: 0.0268s/iter; left time: 534.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0996410 Vali Loss: 0.1172269 Test Loss: 0.1274734\n",
      "Validation loss decreased (0.117401 --> 0.117227).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019047\n",
      "\tspeed: 0.0535s/iter; left time: 1062.0590s\n",
      "\titers: 200, epoch: 12 | loss: 0.0963887\n",
      "\tspeed: 0.0268s/iter; left time: 528.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0992125 Vali Loss: 0.1170878 Test Loss: 0.1278752\n",
      "Validation loss decreased (0.117227 --> 0.117088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961119\n",
      "\tspeed: 0.0544s/iter; left time: 1066.5978s\n",
      "\titers: 200, epoch: 13 | loss: 0.0989636\n",
      "\tspeed: 0.0268s/iter; left time: 523.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0988020 Vali Loss: 0.1168609 Test Loss: 0.1279964\n",
      "Validation loss decreased (0.117088 --> 0.116861).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0999261\n",
      "\tspeed: 0.0537s/iter; left time: 1040.9073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937633\n",
      "\tspeed: 0.0269s/iter; left time: 517.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0984957 Vali Loss: 0.1170542 Test Loss: 0.1275455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0966726\n",
      "\tspeed: 0.0539s/iter; left time: 1033.5501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981507\n",
      "\tspeed: 0.0270s/iter; left time: 515.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0981710 Vali Loss: 0.1166702 Test Loss: 0.1279635\n",
      "Validation loss decreased (0.116861 --> 0.116670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1011894\n",
      "\tspeed: 0.0547s/iter; left time: 1036.4337s\n",
      "\titers: 200, epoch: 16 | loss: 0.1026321\n",
      "\tspeed: 0.0271s/iter; left time: 510.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0978653 Vali Loss: 0.1167809 Test Loss: 0.1274564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973510\n",
      "\tspeed: 0.0535s/iter; left time: 1000.7220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0980666\n",
      "\tspeed: 0.0269s/iter; left time: 501.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0976454 Vali Loss: 0.1168894 Test Loss: 0.1274555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0964897\n",
      "\tspeed: 0.0535s/iter; left time: 989.2355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0915851\n",
      "\tspeed: 0.0269s/iter; left time: 494.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0973645 Vali Loss: 0.1169818 Test Loss: 0.1278145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0937841\n",
      "\tspeed: 0.0539s/iter; left time: 984.7285s\n",
      "\titers: 200, epoch: 19 | loss: 0.0945172\n",
      "\tspeed: 0.0268s/iter; left time: 486.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0971042 Vali Loss: 0.1170631 Test Loss: 0.1279219\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0976394\n",
      "\tspeed: 0.0532s/iter; left time: 959.2814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025702\n",
      "\tspeed: 0.0268s/iter; left time: 480.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0969481 Vali Loss: 0.1168795 Test Loss: 0.1282358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0984403\n",
      "\tspeed: 0.0539s/iter; left time: 960.3656s\n",
      "\titers: 200, epoch: 21 | loss: 0.0932305\n",
      "\tspeed: 0.0269s/iter; left time: 477.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0967456 Vali Loss: 0.1170377 Test Loss: 0.1280329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0958503\n",
      "\tspeed: 0.0537s/iter; left time: 945.1394s\n",
      "\titers: 200, epoch: 22 | loss: 0.0987119\n",
      "\tspeed: 0.0269s/iter; left time: 471.5420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0965442 Vali Loss: 0.1168456 Test Loss: 0.1277162\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0967639\n",
      "\tspeed: 0.0528s/iter; left time: 917.3884s\n",
      "\titers: 200, epoch: 23 | loss: 0.1017741\n",
      "\tspeed: 0.0268s/iter; left time: 463.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0964595 Vali Loss: 0.1169775 Test Loss: 0.1280533\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1019816\n",
      "\tspeed: 0.0538s/iter; left time: 922.2519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0947855\n",
      "\tspeed: 0.0269s/iter; left time: 458.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0962695 Vali Loss: 0.1168131 Test Loss: 0.1279567\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0958062\n",
      "\tspeed: 0.0530s/iter; left time: 897.5916s\n",
      "\titers: 200, epoch: 25 | loss: 0.0925729\n",
      "\tspeed: 0.0269s/iter; left time: 452.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961852 Vali Loss: 0.1169263 Test Loss: 0.1279396\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03738878667354584, rmse:0.1933618038892746, mae:0.12796346843242645, rse:0.6847332715988159\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1453122\n",
      "\tspeed: 0.0287s/iter; left time: 639.1908s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341071\n",
      "\tspeed: 0.0268s/iter; left time: 594.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1493950 Vali Loss: 0.1402512 Test Loss: 0.1483553\n",
      "Validation loss decreased (inf --> 0.140251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097633\n",
      "\tspeed: 0.0543s/iter; left time: 1198.2260s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095724\n",
      "\tspeed: 0.0269s/iter; left time: 591.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1142674 Vali Loss: 0.1222842 Test Loss: 0.1300744\n",
      "Validation loss decreased (0.140251 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055942\n",
      "\tspeed: 0.0555s/iter; left time: 1212.4990s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084602\n",
      "\tspeed: 0.0270s/iter; left time: 587.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1065267 Vali Loss: 0.1205910 Test Loss: 0.1294958\n",
      "Validation loss decreased (0.122284 --> 0.120591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018099\n",
      "\tspeed: 0.0542s/iter; left time: 1171.7338s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051938\n",
      "\tspeed: 0.0269s/iter; left time: 579.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1047808 Vali Loss: 0.1190739 Test Loss: 0.1283687\n",
      "Validation loss decreased (0.120591 --> 0.119074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018800\n",
      "\tspeed: 0.0539s/iter; left time: 1153.8204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956694\n",
      "\tspeed: 0.0267s/iter; left time: 569.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1035395 Vali Loss: 0.1188459 Test Loss: 0.1280372\n",
      "Validation loss decreased (0.119074 --> 0.118846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0991640\n",
      "\tspeed: 0.0546s/iter; left time: 1156.3359s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049700\n",
      "\tspeed: 0.0269s/iter; left time: 568.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1181803 Test Loss: 0.1279618\n",
      "Validation loss decreased (0.118846 --> 0.118180).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013687\n",
      "\tspeed: 0.0545s/iter; left time: 1142.8758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993038\n",
      "\tspeed: 0.0268s/iter; left time: 557.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1018238 Vali Loss: 0.1180655 Test Loss: 0.1277595\n",
      "Validation loss decreased (0.118180 --> 0.118066).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997346\n",
      "\tspeed: 0.0555s/iter; left time: 1150.8520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997878\n",
      "\tspeed: 0.0270s/iter; left time: 557.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1010508 Vali Loss: 0.1179035 Test Loss: 0.1281448\n",
      "Validation loss decreased (0.118066 --> 0.117903).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0988701\n",
      "\tspeed: 0.0563s/iter; left time: 1154.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0968515\n",
      "\tspeed: 0.0271s/iter; left time: 552.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1004422 Vali Loss: 0.1178284 Test Loss: 0.1291293\n",
      "Validation loss decreased (0.117903 --> 0.117828).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008913\n",
      "\tspeed: 0.0546s/iter; left time: 1108.5587s\n",
      "\titers: 200, epoch: 10 | loss: 0.0954883\n",
      "\tspeed: 0.0267s/iter; left time: 539.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0998062 Vali Loss: 0.1179435 Test Loss: 0.1273128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1016945\n",
      "\tspeed: 0.0525s/iter; left time: 1052.5954s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974247\n",
      "\tspeed: 0.0269s/iter; left time: 536.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0992023 Vali Loss: 0.1177902 Test Loss: 0.1276344\n",
      "Validation loss decreased (0.117828 --> 0.117790).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0978504\n",
      "\tspeed: 0.0552s/iter; left time: 1094.3827s\n",
      "\titers: 200, epoch: 12 | loss: 0.1006840\n",
      "\tspeed: 0.0270s/iter; left time: 533.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0986686 Vali Loss: 0.1178868 Test Loss: 0.1283520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029566\n",
      "\tspeed: 0.0534s/iter; left time: 1048.1343s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995638\n",
      "\tspeed: 0.0267s/iter; left time: 521.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0982064 Vali Loss: 0.1177266 Test Loss: 0.1271849\n",
      "Validation loss decreased (0.117790 --> 0.117727).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966322\n",
      "\tspeed: 0.0541s/iter; left time: 1048.6480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0939447\n",
      "\tspeed: 0.0271s/iter; left time: 521.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0977019 Vali Loss: 0.1176199 Test Loss: 0.1285766\n",
      "Validation loss decreased (0.117727 --> 0.117620).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0955380\n",
      "\tspeed: 0.0567s/iter; left time: 1086.8307s\n",
      "\titers: 200, epoch: 15 | loss: 0.0928111\n",
      "\tspeed: 0.0271s/iter; left time: 516.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0973574 Vali Loss: 0.1177496 Test Loss: 0.1279720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019763\n",
      "\tspeed: 0.0549s/iter; left time: 1039.6933s\n",
      "\titers: 200, epoch: 16 | loss: 0.1012777\n",
      "\tspeed: 0.0270s/iter; left time: 509.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0969753 Vali Loss: 0.1177540 Test Loss: 0.1296667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0968168\n",
      "\tspeed: 0.0551s/iter; left time: 1030.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0930788\n",
      "\tspeed: 0.0270s/iter; left time: 502.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0968140 Vali Loss: 0.1179194 Test Loss: 0.1291604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0877084\n",
      "\tspeed: 0.0546s/iter; left time: 1009.5318s\n",
      "\titers: 200, epoch: 18 | loss: 0.0964585\n",
      "\tspeed: 0.0271s/iter; left time: 497.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0964126 Vali Loss: 0.1179514 Test Loss: 0.1292164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978073\n",
      "\tspeed: 0.0549s/iter; left time: 1002.6800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927446\n",
      "\tspeed: 0.0270s/iter; left time: 491.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0961563 Vali Loss: 0.1180256 Test Loss: 0.1296065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997547\n",
      "\tspeed: 0.0541s/iter; left time: 976.4935s\n",
      "\titers: 200, epoch: 20 | loss: 0.0986387\n",
      "\tspeed: 0.0274s/iter; left time: 491.8739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0959443 Vali Loss: 0.1176773 Test Loss: 0.1286344\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0958655\n",
      "\tspeed: 0.0560s/iter; left time: 998.6060s\n",
      "\titers: 200, epoch: 21 | loss: 0.0964852\n",
      "\tspeed: 0.0270s/iter; left time: 478.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0957407 Vali Loss: 0.1176798 Test Loss: 0.1287229\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0942021\n",
      "\tspeed: 0.0553s/iter; left time: 972.3128s\n",
      "\titers: 200, epoch: 22 | loss: 0.0922590\n",
      "\tspeed: 0.0270s/iter; left time: 472.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0955422 Vali Loss: 0.1179530 Test Loss: 0.1288881\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0922816\n",
      "\tspeed: 0.0546s/iter; left time: 948.8017s\n",
      "\titers: 200, epoch: 23 | loss: 0.0962126\n",
      "\tspeed: 0.0273s/iter; left time: 471.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0954098 Vali Loss: 0.1179873 Test Loss: 0.1291286\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0962873\n",
      "\tspeed: 0.0545s/iter; left time: 933.8682s\n",
      "\titers: 200, epoch: 24 | loss: 0.0961054\n",
      "\tspeed: 0.0271s/iter; left time: 462.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0953075 Vali Loss: 0.1179708 Test Loss: 0.1295294\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037975143641233444, rmse:0.19487212598323822, mae:0.1285766065120697, rse:0.6900815963745117\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:50.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1511204\n",
      "\tspeed: 0.0547s/iter; left time: 1213.9765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396091\n",
      "\tspeed: 0.0271s/iter; left time: 598.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.1507847 Vali Loss: 0.1426704 Test Loss: 0.1519556\n",
      "Validation loss decreased (inf --> 0.142670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1238355\n",
      "\tspeed: 0.0542s/iter; left time: 1191.4815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123134\n",
      "\tspeed: 0.0274s/iter; left time: 599.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1200940 Vali Loss: 0.1261885 Test Loss: 0.1355995\n",
      "Validation loss decreased (0.142670 --> 0.126188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164904\n",
      "\tspeed: 0.0582s/iter; left time: 1265.1403s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123756\n",
      "\tspeed: 0.0274s/iter; left time: 593.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1126304 Vali Loss: 0.1248742 Test Loss: 0.1346599\n",
      "Validation loss decreased (0.126188 --> 0.124874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090264\n",
      "\tspeed: 0.0564s/iter; left time: 1214.2777s\n",
      "\titers: 200, epoch: 4 | loss: 0.1161850\n",
      "\tspeed: 0.0277s/iter; left time: 593.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1108241 Vali Loss: 0.1231168 Test Loss: 0.1345049\n",
      "Validation loss decreased (0.124874 --> 0.123117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1067239\n",
      "\tspeed: 0.0557s/iter; left time: 1187.0533s\n",
      "\titers: 200, epoch: 5 | loss: 0.1134487\n",
      "\tspeed: 0.0273s/iter; left time: 578.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1096404 Vali Loss: 0.1232052 Test Loss: 0.1344802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046681\n",
      "\tspeed: 0.0548s/iter; left time: 1154.7548s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130422\n",
      "\tspeed: 0.0273s/iter; left time: 573.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1086139 Vali Loss: 0.1229566 Test Loss: 0.1347695\n",
      "Validation loss decreased (0.123117 --> 0.122957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1078895\n",
      "\tspeed: 0.0562s/iter; left time: 1172.1359s\n",
      "\titers: 200, epoch: 7 | loss: 0.1087261\n",
      "\tspeed: 0.0273s/iter; left time: 566.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1077184 Vali Loss: 0.1223245 Test Loss: 0.1334847\n",
      "Validation loss decreased (0.122957 --> 0.122324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035181\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6720s\n",
      "\titers: 200, epoch: 8 | loss: 0.1118061\n",
      "\tspeed: 0.0274s/iter; left time: 562.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1069834 Vali Loss: 0.1218858 Test Loss: 0.1330454\n",
      "Validation loss decreased (0.122324 --> 0.121886).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1058632\n",
      "\tspeed: 0.0555s/iter; left time: 1132.6126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987647\n",
      "\tspeed: 0.0272s/iter; left time: 553.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1062651 Vali Loss: 0.1219982 Test Loss: 0.1338042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1030127\n",
      "\tspeed: 0.0538s/iter; left time: 1086.2314s\n",
      "\titers: 200, epoch: 10 | loss: 0.1031541\n",
      "\tspeed: 0.0273s/iter; left time: 548.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1056596 Vali Loss: 0.1220121 Test Loss: 0.1338617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1061721\n",
      "\tspeed: 0.0545s/iter; left time: 1089.1685s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000139\n",
      "\tspeed: 0.0286s/iter; left time: 568.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1051509 Vali Loss: 0.1223389 Test Loss: 0.1343730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1016918\n",
      "\tspeed: 0.0557s/iter; left time: 1099.9068s\n",
      "\titers: 200, epoch: 12 | loss: 0.1091376\n",
      "\tspeed: 0.0273s/iter; left time: 536.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.1046909 Vali Loss: 0.1220724 Test Loss: 0.1342280\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1095180\n",
      "\tspeed: 0.0545s/iter; left time: 1064.6654s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059984\n",
      "\tspeed: 0.0273s/iter; left time: 529.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1042259 Vali Loss: 0.1223401 Test Loss: 0.1342049\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0977468\n",
      "\tspeed: 0.0541s/iter; left time: 1045.0044s\n",
      "\titers: 200, epoch: 14 | loss: 0.1107927\n",
      "\tspeed: 0.0270s/iter; left time: 518.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1039162 Vali Loss: 0.1222137 Test Loss: 0.1342742\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1054508\n",
      "\tspeed: 0.0546s/iter; left time: 1042.4705s\n",
      "\titers: 200, epoch: 15 | loss: 0.1117989\n",
      "\tspeed: 0.0273s/iter; left time: 517.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035189 Vali Loss: 0.1224293 Test Loss: 0.1347673\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1062974\n",
      "\tspeed: 0.0547s/iter; left time: 1030.8627s\n",
      "\titers: 200, epoch: 16 | loss: 0.1125161\n",
      "\tspeed: 0.0272s/iter; left time: 511.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1031467 Vali Loss: 0.1224126 Test Loss: 0.1339886\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1029710\n",
      "\tspeed: 0.0545s/iter; left time: 1015.8779s\n",
      "\titers: 200, epoch: 17 | loss: 0.1050183\n",
      "\tspeed: 0.0273s/iter; left time: 505.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1029577 Vali Loss: 0.1227930 Test Loss: 0.1340047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1025430\n",
      "\tspeed: 0.0542s/iter; left time: 998.1419s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046702\n",
      "\tspeed: 0.0272s/iter; left time: 497.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1026303 Vali Loss: 0.1226197 Test Loss: 0.1343808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03874775022268295, rmse:0.19684448838233948, mae:0.13304544985294342, rse:0.6972389817237854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1546361\n",
      "\tspeed: 0.0298s/iter; left time: 662.3935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357865\n",
      "\tspeed: 0.0272s/iter; left time: 600.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1520326 Vali Loss: 0.1427907 Test Loss: 0.1520844\n",
      "Validation loss decreased (inf --> 0.142791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183958\n",
      "\tspeed: 0.0566s/iter; left time: 1243.1818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188114\n",
      "\tspeed: 0.0273s/iter; left time: 597.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1199734 Vali Loss: 0.1263667 Test Loss: 0.1363375\n",
      "Validation loss decreased (0.142791 --> 0.126367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1155362\n",
      "\tspeed: 0.0556s/iter; left time: 1208.6087s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098592\n",
      "\tspeed: 0.0272s/iter; left time: 588.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1126673 Vali Loss: 0.1251423 Test Loss: 0.1348121\n",
      "Validation loss decreased (0.126367 --> 0.125142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086826\n",
      "\tspeed: 0.0557s/iter; left time: 1199.5182s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126055\n",
      "\tspeed: 0.0274s/iter; left time: 587.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1106587 Vali Loss: 0.1242879 Test Loss: 0.1354954\n",
      "Validation loss decreased (0.125142 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1116844\n",
      "\tspeed: 0.0560s/iter; left time: 1194.1369s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103760\n",
      "\tspeed: 0.0274s/iter; left time: 580.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1092648 Vali Loss: 0.1238110 Test Loss: 0.1339414\n",
      "Validation loss decreased (0.124288 --> 0.123811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062780\n",
      "\tspeed: 0.0556s/iter; left time: 1172.0651s\n",
      "\titers: 200, epoch: 6 | loss: 0.1105472\n",
      "\tspeed: 0.0275s/iter; left time: 576.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1083813 Vali Loss: 0.1230377 Test Loss: 0.1344151\n",
      "Validation loss decreased (0.123811 --> 0.123038).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1100236\n",
      "\tspeed: 0.0563s/iter; left time: 1173.7410s\n",
      "\titers: 200, epoch: 7 | loss: 0.1094361\n",
      "\tspeed: 0.0271s/iter; left time: 563.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1075638 Vali Loss: 0.1233376 Test Loss: 0.1351425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1083931\n",
      "\tspeed: 0.0550s/iter; left time: 1135.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076261\n",
      "\tspeed: 0.0272s/iter; left time: 559.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1067569 Vali Loss: 0.1231392 Test Loss: 0.1350849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042043\n",
      "\tspeed: 0.0562s/iter; left time: 1148.2966s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087456\n",
      "\tspeed: 0.0286s/iter; left time: 580.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.1061874 Vali Loss: 0.1229115 Test Loss: 0.1347596\n",
      "Validation loss decreased (0.123038 --> 0.122912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047019\n",
      "\tspeed: 0.0569s/iter; left time: 1149.2216s\n",
      "\titers: 200, epoch: 10 | loss: 0.1098653\n",
      "\tspeed: 0.0274s/iter; left time: 551.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1054878 Vali Loss: 0.1231185 Test Loss: 0.1345507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1028828\n",
      "\tspeed: 0.0549s/iter; left time: 1096.4879s\n",
      "\titers: 200, epoch: 11 | loss: 0.1091575\n",
      "\tspeed: 0.0277s/iter; left time: 549.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1048839 Vali Loss: 0.1236878 Test Loss: 0.1354434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043799\n",
      "\tspeed: 0.0562s/iter; left time: 1109.6457s\n",
      "\titers: 200, epoch: 12 | loss: 0.1061269\n",
      "\tspeed: 0.0280s/iter; left time: 549.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.1043107 Vali Loss: 0.1239945 Test Loss: 0.1346901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1080359\n",
      "\tspeed: 0.0548s/iter; left time: 1070.4594s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058448\n",
      "\tspeed: 0.0271s/iter; left time: 527.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1037742 Vali Loss: 0.1241476 Test Loss: 0.1351113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1032596\n",
      "\tspeed: 0.0556s/iter; left time: 1073.1232s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017853\n",
      "\tspeed: 0.0273s/iter; left time: 523.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1033254 Vali Loss: 0.1241768 Test Loss: 0.1357941\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1011182\n",
      "\tspeed: 0.0548s/iter; left time: 1044.6235s\n",
      "\titers: 200, epoch: 15 | loss: 0.1017340\n",
      "\tspeed: 0.0272s/iter; left time: 516.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1029318 Vali Loss: 0.1242862 Test Loss: 0.1359198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1043327\n",
      "\tspeed: 0.0555s/iter; left time: 1046.7619s\n",
      "\titers: 200, epoch: 16 | loss: 0.1076296\n",
      "\tspeed: 0.0273s/iter; left time: 511.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1024750 Vali Loss: 0.1245145 Test Loss: 0.1355859\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003824\n",
      "\tspeed: 0.0549s/iter; left time: 1023.8289s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016187\n",
      "\tspeed: 0.0274s/iter; left time: 507.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1022286 Vali Loss: 0.1240813 Test Loss: 0.1352433\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041608\n",
      "\tspeed: 0.0561s/iter; left time: 1032.5608s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061510\n",
      "\tspeed: 0.0277s/iter; left time: 506.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1019955 Vali Loss: 0.1249169 Test Loss: 0.1354775\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1080255\n",
      "\tspeed: 0.0557s/iter; left time: 1013.8191s\n",
      "\titers: 200, epoch: 19 | loss: 0.0987023\n",
      "\tspeed: 0.0274s/iter; left time: 496.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1016865 Vali Loss: 0.1249771 Test Loss: 0.1352909\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03975802659988403, rmse:0.19939415156841278, mae:0.13475961983203888, rse:0.7062700986862183\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:20.07s\n",
      "Intermediate time for DE: 00h:27m:01.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1243801\n",
      "\tspeed: 0.0543s/iter; left time: 1211.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137652\n",
      "\tspeed: 0.0266s/iter; left time: 590.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.1302879 Vali Loss: 0.1216964 Test Loss: 0.1408504\n",
      "Validation loss decreased (inf --> 0.121696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0839070\n",
      "\tspeed: 0.0520s/iter; left time: 1147.3483s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818553\n",
      "\tspeed: 0.0265s/iter; left time: 583.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0865396 Vali Loss: 0.0920018 Test Loss: 0.1033591\n",
      "Validation loss decreased (0.121696 --> 0.092002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733085\n",
      "\tspeed: 0.0515s/iter; left time: 1125.3848s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821068\n",
      "\tspeed: 0.0267s/iter; left time: 581.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0793856 Vali Loss: 0.0900384 Test Loss: 0.1024917\n",
      "Validation loss decreased (0.092002 --> 0.090038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0750556\n",
      "\tspeed: 0.0518s/iter; left time: 1121.1212s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780856\n",
      "\tspeed: 0.0264s/iter; left time: 568.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0779691 Vali Loss: 0.0899016 Test Loss: 0.1022058\n",
      "Validation loss decreased (0.090038 --> 0.089902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758535\n",
      "\tspeed: 0.0517s/iter; left time: 1107.5445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757776\n",
      "\tspeed: 0.0267s/iter; left time: 568.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0769919 Vali Loss: 0.0893033 Test Loss: 0.1019564\n",
      "Validation loss decreased (0.089902 --> 0.089303).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798705\n",
      "\tspeed: 0.0522s/iter; left time: 1104.7398s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816744\n",
      "\tspeed: 0.0267s/iter; left time: 563.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0762630 Vali Loss: 0.0887678 Test Loss: 0.1014424\n",
      "Validation loss decreased (0.089303 --> 0.088768).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754332\n",
      "\tspeed: 0.0518s/iter; left time: 1085.2478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806607\n",
      "\tspeed: 0.0267s/iter; left time: 557.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0756519 Vali Loss: 0.0887744 Test Loss: 0.1014127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728288\n",
      "\tspeed: 0.0511s/iter; left time: 1059.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775176\n",
      "\tspeed: 0.0266s/iter; left time: 547.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0752004 Vali Loss: 0.0885392 Test Loss: 0.1006487\n",
      "Validation loss decreased (0.088768 --> 0.088539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738876\n",
      "\tspeed: 0.0528s/iter; left time: 1082.2772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792237\n",
      "\tspeed: 0.0268s/iter; left time: 546.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0748653 Vali Loss: 0.0884795 Test Loss: 0.1006068\n",
      "Validation loss decreased (0.088539 --> 0.088479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808073\n",
      "\tspeed: 0.0520s/iter; left time: 1054.3701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720843\n",
      "\tspeed: 0.0267s/iter; left time: 538.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0745151 Vali Loss: 0.0878042 Test Loss: 0.1009895\n",
      "Validation loss decreased (0.088479 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773240\n",
      "\tspeed: 0.0519s/iter; left time: 1041.0894s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738162\n",
      "\tspeed: 0.0267s/iter; left time: 531.9959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0742512 Vali Loss: 0.0880865 Test Loss: 0.1001864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778451\n",
      "\tspeed: 0.0510s/iter; left time: 1012.4607s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704564\n",
      "\tspeed: 0.0267s/iter; left time: 527.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0739914 Vali Loss: 0.0879424 Test Loss: 0.1007774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728143\n",
      "\tspeed: 0.0519s/iter; left time: 1018.4859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723630\n",
      "\tspeed: 0.0266s/iter; left time: 520.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0738506 Vali Loss: 0.0879685 Test Loss: 0.1000657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773398\n",
      "\tspeed: 0.0518s/iter; left time: 1004.9878s\n",
      "\titers: 200, epoch: 14 | loss: 0.0699778\n",
      "\tspeed: 0.0267s/iter; left time: 514.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0736961 Vali Loss: 0.0878420 Test Loss: 0.0999213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665786\n",
      "\tspeed: 0.0518s/iter; left time: 992.4915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0686087\n",
      "\tspeed: 0.0266s/iter; left time: 507.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0734943 Vali Loss: 0.0880088 Test Loss: 0.1000402\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704044\n",
      "\tspeed: 0.0525s/iter; left time: 993.4795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735029\n",
      "\tspeed: 0.0268s/iter; left time: 505.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0733230 Vali Loss: 0.0875390 Test Loss: 0.1002045\n",
      "Validation loss decreased (0.087804 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733052\n",
      "\tspeed: 0.0529s/iter; left time: 989.9356s\n",
      "\titers: 200, epoch: 17 | loss: 0.0776525\n",
      "\tspeed: 0.0267s/iter; left time: 496.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0732607 Vali Loss: 0.0874719 Test Loss: 0.0997542\n",
      "Validation loss decreased (0.087539 --> 0.087472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0733563\n",
      "\tspeed: 0.0528s/iter; left time: 976.5661s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740419\n",
      "\tspeed: 0.0269s/iter; left time: 493.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0731655 Vali Loss: 0.0875383 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0704366\n",
      "\tspeed: 0.0523s/iter; left time: 956.2087s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727878\n",
      "\tspeed: 0.0269s/iter; left time: 488.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0730607 Vali Loss: 0.0878342 Test Loss: 0.0998149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639565\n",
      "\tspeed: 0.0523s/iter; left time: 943.3723s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710644\n",
      "\tspeed: 0.0268s/iter; left time: 481.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0729284 Vali Loss: 0.0876287 Test Loss: 0.0996863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751909\n",
      "\tspeed: 0.0521s/iter; left time: 928.5994s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704616\n",
      "\tspeed: 0.0265s/iter; left time: 469.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0727867 Vali Loss: 0.0875195 Test Loss: 0.0996076\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0709846\n",
      "\tspeed: 0.0528s/iter; left time: 928.9821s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672187\n",
      "\tspeed: 0.0271s/iter; left time: 473.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0727850 Vali Loss: 0.0873734 Test Loss: 0.0995667\n",
      "Validation loss decreased (0.087472 --> 0.087373).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724984\n",
      "\tspeed: 0.0546s/iter; left time: 947.7766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0676599\n",
      "\tspeed: 0.0269s/iter; left time: 464.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0727007 Vali Loss: 0.0874452 Test Loss: 0.0995794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0710710\n",
      "\tspeed: 0.0533s/iter; left time: 914.8627s\n",
      "\titers: 200, epoch: 24 | loss: 0.0718718\n",
      "\tspeed: 0.0272s/iter; left time: 463.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0726696 Vali Loss: 0.0874877 Test Loss: 0.0994474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0733318\n",
      "\tspeed: 0.0538s/iter; left time: 909.7842s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770599\n",
      "\tspeed: 0.0271s/iter; left time: 456.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0726920 Vali Loss: 0.0873381 Test Loss: 0.0994857\n",
      "Validation loss decreased (0.087373 --> 0.087338).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0732230\n",
      "\tspeed: 0.0537s/iter; left time: 896.6000s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704290\n",
      "\tspeed: 0.0268s/iter; left time: 445.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0726002 Vali Loss: 0.0874241 Test Loss: 0.0995524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722607\n",
      "\tspeed: 0.0535s/iter; left time: 881.7593s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757692\n",
      "\tspeed: 0.0273s/iter; left time: 446.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0725308 Vali Loss: 0.0873835 Test Loss: 0.0995856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780362\n",
      "\tspeed: 0.0530s/iter; left time: 860.7019s\n",
      "\titers: 200, epoch: 28 | loss: 0.0754186\n",
      "\tspeed: 0.0269s/iter; left time: 433.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724948 Vali Loss: 0.0874800 Test Loss: 0.0996659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0755497\n",
      "\tspeed: 0.0534s/iter; left time: 856.6310s\n",
      "\titers: 200, epoch: 29 | loss: 0.0672095\n",
      "\tspeed: 0.0269s/iter; left time: 427.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724994 Vali Loss: 0.0873726 Test Loss: 0.0994512\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743681\n",
      "\tspeed: 0.0530s/iter; left time: 837.2495s\n",
      "\titers: 200, epoch: 30 | loss: 0.0714248\n",
      "\tspeed: 0.0268s/iter; left time: 421.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0724325 Vali Loss: 0.0874007 Test Loss: 0.0996015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670253\n",
      "\tspeed: 0.0540s/iter; left time: 840.9434s\n",
      "\titers: 200, epoch: 31 | loss: 0.0738778\n",
      "\tspeed: 0.0265s/iter; left time: 410.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723963 Vali Loss: 0.0873461 Test Loss: 0.0995764\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0729594\n",
      "\tspeed: 0.0534s/iter; left time: 820.6041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0743888\n",
      "\tspeed: 0.0268s/iter; left time: 409.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0724081 Vali Loss: 0.0872245 Test Loss: 0.0994373\n",
      "Validation loss decreased (0.087338 --> 0.087224).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723266\n",
      "\tspeed: 0.0541s/iter; left time: 818.1361s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713193\n",
      "\tspeed: 0.0269s/iter; left time: 404.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0723961 Vali Loss: 0.0874335 Test Loss: 0.0996177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0732763\n",
      "\tspeed: 0.0532s/iter; left time: 793.2879s\n",
      "\titers: 200, epoch: 34 | loss: 0.0748497\n",
      "\tspeed: 0.0268s/iter; left time: 396.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0723704 Vali Loss: 0.0873889 Test Loss: 0.0995195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779761\n",
      "\tspeed: 0.0529s/iter; left time: 776.7366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0753652\n",
      "\tspeed: 0.0268s/iter; left time: 390.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723036 Vali Loss: 0.0872547 Test Loss: 0.0995013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686231\n",
      "\tspeed: 0.0528s/iter; left time: 764.0125s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763031\n",
      "\tspeed: 0.0268s/iter; left time: 384.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722592 Vali Loss: 0.0874217 Test Loss: 0.0995324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755020\n",
      "\tspeed: 0.0527s/iter; left time: 750.5292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0714776\n",
      "\tspeed: 0.0268s/iter; left time: 378.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723462 Vali Loss: 0.0874196 Test Loss: 0.0995449\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0748234\n",
      "\tspeed: 0.0534s/iter; left time: 747.9698s\n",
      "\titers: 200, epoch: 38 | loss: 0.0689176\n",
      "\tspeed: 0.0268s/iter; left time: 373.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0723155 Vali Loss: 0.0872684 Test Loss: 0.0995207\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765601\n",
      "\tspeed: 0.0540s/iter; left time: 744.7602s\n",
      "\titers: 200, epoch: 39 | loss: 0.0677570\n",
      "\tspeed: 0.0268s/iter; left time: 366.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722663 Vali Loss: 0.0874316 Test Loss: 0.0995467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0654785\n",
      "\tspeed: 0.0528s/iter; left time: 716.1290s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748680\n",
      "\tspeed: 0.0265s/iter; left time: 356.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0723363 Vali Loss: 0.0873764 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700707\n",
      "\tspeed: 0.0531s/iter; left time: 708.0991s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708900\n",
      "\tspeed: 0.0270s/iter; left time: 356.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0722918 Vali Loss: 0.0873483 Test Loss: 0.0995223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721399\n",
      "\tspeed: 0.0532s/iter; left time: 697.5313s\n",
      "\titers: 200, epoch: 42 | loss: 0.0775154\n",
      "\tspeed: 0.0272s/iter; left time: 353.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0722849 Vali Loss: 0.0872172 Test Loss: 0.0995116\n",
      "Validation loss decreased (0.087224 --> 0.087217).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0751871\n",
      "\tspeed: 0.0535s/iter; left time: 689.5227s\n",
      "\titers: 200, epoch: 43 | loss: 0.0700004\n",
      "\tspeed: 0.0269s/iter; left time: 343.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722874 Vali Loss: 0.0872460 Test Loss: 0.0994964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0771745\n",
      "\tspeed: 0.0536s/iter; left time: 678.9808s\n",
      "\titers: 200, epoch: 44 | loss: 0.0732692\n",
      "\tspeed: 0.0268s/iter; left time: 336.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722729 Vali Loss: 0.0872457 Test Loss: 0.0994803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0702146\n",
      "\tspeed: 0.0527s/iter; left time: 656.2688s\n",
      "\titers: 200, epoch: 45 | loss: 0.0754088\n",
      "\tspeed: 0.0268s/iter; left time: 330.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0872447 Test Loss: 0.0994848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0695563\n",
      "\tspeed: 0.0525s/iter; left time: 641.3707s\n",
      "\titers: 200, epoch: 46 | loss: 0.0708172\n",
      "\tspeed: 0.0269s/iter; left time: 325.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722368 Vali Loss: 0.0872585 Test Loss: 0.0994719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0748870\n",
      "\tspeed: 0.0531s/iter; left time: 636.6953s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730831\n",
      "\tspeed: 0.0269s/iter; left time: 319.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722215 Vali Loss: 0.0873487 Test Loss: 0.0995225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0761661\n",
      "\tspeed: 0.0530s/iter; left time: 624.1234s\n",
      "\titers: 200, epoch: 48 | loss: 0.0745982\n",
      "\tspeed: 0.0268s/iter; left time: 312.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721901 Vali Loss: 0.0873764 Test Loss: 0.0994837\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0708556\n",
      "\tspeed: 0.0533s/iter; left time: 615.7655s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708657\n",
      "\tspeed: 0.0268s/iter; left time: 307.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722119 Vali Loss: 0.0872935 Test Loss: 0.0994825\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738270\n",
      "\tspeed: 0.0525s/iter; left time: 594.2805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0708394\n",
      "\tspeed: 0.0269s/iter; left time: 301.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721791 Vali Loss: 0.0872133 Test Loss: 0.0994824\n",
      "Validation loss decreased (0.087217 --> 0.087213).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0729056\n",
      "\tspeed: 0.0537s/iter; left time: 596.5067s\n",
      "\titers: 200, epoch: 51 | loss: 0.0680218\n",
      "\tspeed: 0.0268s/iter; left time: 294.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721853 Vali Loss: 0.0873186 Test Loss: 0.0994690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0694491\n",
      "\tspeed: 0.0528s/iter; left time: 574.4605s\n",
      "\titers: 200, epoch: 52 | loss: 0.0776386\n",
      "\tspeed: 0.0269s/iter; left time: 289.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0722179 Vali Loss: 0.0873789 Test Loss: 0.0994850\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0731650\n",
      "\tspeed: 0.0526s/iter; left time: 559.9777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0769954\n",
      "\tspeed: 0.0268s/iter; left time: 283.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721883 Vali Loss: 0.0873961 Test Loss: 0.0994792\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0745562\n",
      "\tspeed: 0.0537s/iter; left time: 559.6576s\n",
      "\titers: 200, epoch: 54 | loss: 0.0707905\n",
      "\tspeed: 0.0268s/iter; left time: 276.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722220 Vali Loss: 0.0872954 Test Loss: 0.0995034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0701514\n",
      "\tspeed: 0.0533s/iter; left time: 543.8353s\n",
      "\titers: 200, epoch: 55 | loss: 0.0714959\n",
      "\tspeed: 0.0271s/iter; left time: 274.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0873029 Test Loss: 0.0994843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0704450\n",
      "\tspeed: 0.0535s/iter; left time: 534.3546s\n",
      "\titers: 200, epoch: 56 | loss: 0.0675059\n",
      "\tspeed: 0.0269s/iter; left time: 266.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0721501 Vali Loss: 0.0873734 Test Loss: 0.0994912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0738333\n",
      "\tspeed: 0.0537s/iter; left time: 523.7482s\n",
      "\titers: 200, epoch: 57 | loss: 0.0705020\n",
      "\tspeed: 0.0269s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0722345 Vali Loss: 0.0874336 Test Loss: 0.0994758\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0767229\n",
      "\tspeed: 0.0527s/iter; left time: 502.0444s\n",
      "\titers: 200, epoch: 58 | loss: 0.0729605\n",
      "\tspeed: 0.0268s/iter; left time: 253.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722041 Vali Loss: 0.0873020 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0756847\n",
      "\tspeed: 0.0534s/iter; left time: 497.0981s\n",
      "\titers: 200, epoch: 59 | loss: 0.0757611\n",
      "\tspeed: 0.0268s/iter; left time: 247.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0721992 Vali Loss: 0.0872928 Test Loss: 0.0994752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0702965\n",
      "\tspeed: 0.0524s/iter; left time: 476.4810s\n",
      "\titers: 200, epoch: 60 | loss: 0.0741313\n",
      "\tspeed: 0.0268s/iter; left time: 240.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722097 Vali Loss: 0.0873115 Test Loss: 0.0994877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02502487227320671, rmse:0.15819251537322998, mae:0.09948243200778961, rse:0.54571932554245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1281256\n",
      "\tspeed: 0.0292s/iter; left time: 650.2233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1138560\n",
      "\tspeed: 0.0268s/iter; left time: 594.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1290584 Vali Loss: 0.1207433 Test Loss: 0.1395016\n",
      "Validation loss decreased (inf --> 0.120743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853941\n",
      "\tspeed: 0.0536s/iter; left time: 1182.5697s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847853\n",
      "\tspeed: 0.0269s/iter; left time: 590.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0861361 Vali Loss: 0.0918532 Test Loss: 0.1040095\n",
      "Validation loss decreased (0.120743 --> 0.091853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775025\n",
      "\tspeed: 0.0535s/iter; left time: 1169.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788021\n",
      "\tspeed: 0.0268s/iter; left time: 583.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0792676 Vali Loss: 0.0905056 Test Loss: 0.1025451\n",
      "Validation loss decreased (0.091853 --> 0.090506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744780\n",
      "\tspeed: 0.0530s/iter; left time: 1146.1907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797157\n",
      "\tspeed: 0.0268s/iter; left time: 576.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0780674 Vali Loss: 0.0906739 Test Loss: 0.1020297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770665\n",
      "\tspeed: 0.0537s/iter; left time: 1149.1107s\n",
      "\titers: 200, epoch: 5 | loss: 0.0766374\n",
      "\tspeed: 0.0268s/iter; left time: 571.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0769707 Vali Loss: 0.0894935 Test Loss: 0.1018222\n",
      "Validation loss decreased (0.090506 --> 0.089494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809719\n",
      "\tspeed: 0.0542s/iter; left time: 1148.6083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820128\n",
      "\tspeed: 0.0268s/iter; left time: 565.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0762634 Vali Loss: 0.0891491 Test Loss: 0.1013036\n",
      "Validation loss decreased (0.089494 --> 0.089149).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794357\n",
      "\tspeed: 0.0534s/iter; left time: 1119.2823s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746093\n",
      "\tspeed: 0.0269s/iter; left time: 560.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0757042 Vali Loss: 0.0887241 Test Loss: 0.1007391\n",
      "Validation loss decreased (0.089149 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761330\n",
      "\tspeed: 0.0535s/iter; left time: 1109.9562s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747115\n",
      "\tspeed: 0.0269s/iter; left time: 555.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0752742 Vali Loss: 0.0889610 Test Loss: 0.1005073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797194\n",
      "\tspeed: 0.0531s/iter; left time: 1089.4519s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733876\n",
      "\tspeed: 0.0269s/iter; left time: 548.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0748621 Vali Loss: 0.0881851 Test Loss: 0.1004349\n",
      "Validation loss decreased (0.088724 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750555\n",
      "\tspeed: 0.0529s/iter; left time: 1073.6207s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730892\n",
      "\tspeed: 0.0268s/iter; left time: 540.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0745724 Vali Loss: 0.0886613 Test Loss: 0.0999387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0729881\n",
      "\tspeed: 0.0534s/iter; left time: 1071.6187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750049\n",
      "\tspeed: 0.0268s/iter; left time: 534.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0742235 Vali Loss: 0.0879054 Test Loss: 0.1000553\n",
      "Validation loss decreased (0.088185 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0731180\n",
      "\tspeed: 0.0537s/iter; left time: 1065.7722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704911\n",
      "\tspeed: 0.0268s/iter; left time: 529.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0739811 Vali Loss: 0.0880940 Test Loss: 0.1000203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0734993\n",
      "\tspeed: 0.0533s/iter; left time: 1046.3170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0771078\n",
      "\tspeed: 0.0268s/iter; left time: 522.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0738054 Vali Loss: 0.0879598 Test Loss: 0.1001505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748501\n",
      "\tspeed: 0.0532s/iter; left time: 1031.9631s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740310\n",
      "\tspeed: 0.0269s/iter; left time: 518.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0736476 Vali Loss: 0.0878529 Test Loss: 0.1002746\n",
      "Validation loss decreased (0.087905 --> 0.087853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738298\n",
      "\tspeed: 0.0543s/iter; left time: 1041.4646s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762812\n",
      "\tspeed: 0.0269s/iter; left time: 513.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0735278 Vali Loss: 0.0878173 Test Loss: 0.1001467\n",
      "Validation loss decreased (0.087853 --> 0.087817).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707365\n",
      "\tspeed: 0.0534s/iter; left time: 1010.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745331\n",
      "\tspeed: 0.0269s/iter; left time: 505.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0732803 Vali Loss: 0.0877546 Test Loss: 0.0999003\n",
      "Validation loss decreased (0.087817 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0703407\n",
      "\tspeed: 0.0537s/iter; left time: 1005.2025s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806976\n",
      "\tspeed: 0.0270s/iter; left time: 501.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0732293 Vali Loss: 0.0877284 Test Loss: 0.1001207\n",
      "Validation loss decreased (0.087755 --> 0.087728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721018\n",
      "\tspeed: 0.0533s/iter; left time: 985.6505s\n",
      "\titers: 200, epoch: 18 | loss: 0.0723104\n",
      "\tspeed: 0.0268s/iter; left time: 493.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0730768 Vali Loss: 0.0877988 Test Loss: 0.0999179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0745736\n",
      "\tspeed: 0.0523s/iter; left time: 954.9691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709844\n",
      "\tspeed: 0.0268s/iter; left time: 486.2546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0729765 Vali Loss: 0.0877342 Test Loss: 0.0999373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700831\n",
      "\tspeed: 0.0528s/iter; left time: 951.9676s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720744\n",
      "\tspeed: 0.0268s/iter; left time: 480.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728975 Vali Loss: 0.0876718 Test Loss: 0.0999224\n",
      "Validation loss decreased (0.087728 --> 0.087672).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748239\n",
      "\tspeed: 0.0530s/iter; left time: 943.8389s\n",
      "\titers: 200, epoch: 21 | loss: 0.0763428\n",
      "\tspeed: 0.0268s/iter; left time: 474.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728158 Vali Loss: 0.0874219 Test Loss: 0.0997877\n",
      "Validation loss decreased (0.087672 --> 0.087422).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0726125\n",
      "\tspeed: 0.0535s/iter; left time: 941.3583s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784063\n",
      "\tspeed: 0.0267s/iter; left time: 467.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0727590 Vali Loss: 0.0874105 Test Loss: 0.0995382\n",
      "Validation loss decreased (0.087422 --> 0.087410).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0671866\n",
      "\tspeed: 0.0535s/iter; left time: 929.4445s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725489\n",
      "\tspeed: 0.0268s/iter; left time: 462.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0726649 Vali Loss: 0.0874186 Test Loss: 0.0996998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0776832\n",
      "\tspeed: 0.0533s/iter; left time: 913.3976s\n",
      "\titers: 200, epoch: 24 | loss: 0.0751887\n",
      "\tspeed: 0.0268s/iter; left time: 456.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0726117 Vali Loss: 0.0874993 Test Loss: 0.0999176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748994\n",
      "\tspeed: 0.0529s/iter; left time: 894.5695s\n",
      "\titers: 200, epoch: 25 | loss: 0.0756038\n",
      "\tspeed: 0.0265s/iter; left time: 446.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0725972 Vali Loss: 0.0874437 Test Loss: 0.0998308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704204\n",
      "\tspeed: 0.0528s/iter; left time: 881.4889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690703\n",
      "\tspeed: 0.0265s/iter; left time: 439.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0725073 Vali Loss: 0.0873915 Test Loss: 0.0997966\n",
      "Validation loss decreased (0.087410 --> 0.087391).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722938\n",
      "\tspeed: 0.0550s/iter; left time: 906.8522s\n",
      "\titers: 200, epoch: 27 | loss: 0.0707320\n",
      "\tspeed: 0.0269s/iter; left time: 440.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0724955 Vali Loss: 0.0874042 Test Loss: 0.0997572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708005\n",
      "\tspeed: 0.0524s/iter; left time: 852.1813s\n",
      "\titers: 200, epoch: 28 | loss: 0.0706717\n",
      "\tspeed: 0.0265s/iter; left time: 427.8731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0725039 Vali Loss: 0.0873560 Test Loss: 0.0996761\n",
      "Validation loss decreased (0.087391 --> 0.087356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742883\n",
      "\tspeed: 0.0536s/iter; left time: 859.0053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742773\n",
      "\tspeed: 0.0269s/iter; left time: 427.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724317 Vali Loss: 0.0874750 Test Loss: 0.0997233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733841\n",
      "\tspeed: 0.0534s/iter; left time: 844.4930s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713019\n",
      "\tspeed: 0.0268s/iter; left time: 421.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724177 Vali Loss: 0.0873239 Test Loss: 0.0995659\n",
      "Validation loss decreased (0.087356 --> 0.087324).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0728526\n",
      "\tspeed: 0.0535s/iter; left time: 834.2808s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712871\n",
      "\tspeed: 0.0268s/iter; left time: 414.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0723862 Vali Loss: 0.0873993 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745156\n",
      "\tspeed: 0.0529s/iter; left time: 811.9430s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705794\n",
      "\tspeed: 0.0267s/iter; left time: 407.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0723662 Vali Loss: 0.0874361 Test Loss: 0.0997775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0698627\n",
      "\tspeed: 0.0531s/iter; left time: 804.2879s\n",
      "\titers: 200, epoch: 33 | loss: 0.0744560\n",
      "\tspeed: 0.0267s/iter; left time: 401.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723162 Vali Loss: 0.0872565 Test Loss: 0.0996848\n",
      "Validation loss decreased (0.087324 --> 0.087256).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720458\n",
      "\tspeed: 0.0529s/iter; left time: 789.0979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0796783\n",
      "\tspeed: 0.0267s/iter; left time: 395.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722920 Vali Loss: 0.0873715 Test Loss: 0.0996110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0731819\n",
      "\tspeed: 0.0527s/iter; left time: 773.4842s\n",
      "\titers: 200, epoch: 35 | loss: 0.0786404\n",
      "\tspeed: 0.0267s/iter; left time: 389.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723127 Vali Loss: 0.0874032 Test Loss: 0.0996725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0717856\n",
      "\tspeed: 0.0527s/iter; left time: 761.5788s\n",
      "\titers: 200, epoch: 36 | loss: 0.0735888\n",
      "\tspeed: 0.0267s/iter; left time: 383.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723288 Vali Loss: 0.0872270 Test Loss: 0.0996796\n",
      "Validation loss decreased (0.087256 --> 0.087227).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752889\n",
      "\tspeed: 0.0529s/iter; left time: 753.7263s\n",
      "\titers: 200, epoch: 37 | loss: 0.0713401\n",
      "\tspeed: 0.0268s/iter; left time: 378.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723031 Vali Loss: 0.0874127 Test Loss: 0.0996993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0730377\n",
      "\tspeed: 0.0528s/iter; left time: 740.2937s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670286\n",
      "\tspeed: 0.0266s/iter; left time: 369.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0722490 Vali Loss: 0.0873063 Test Loss: 0.0996096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0739416\n",
      "\tspeed: 0.0528s/iter; left time: 727.5970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706054\n",
      "\tspeed: 0.0266s/iter; left time: 364.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0722615 Vali Loss: 0.0873521 Test Loss: 0.0996684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0689131\n",
      "\tspeed: 0.0538s/iter; left time: 729.3039s\n",
      "\titers: 200, epoch: 40 | loss: 0.0731106\n",
      "\tspeed: 0.0269s/iter; left time: 362.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722557 Vali Loss: 0.0874369 Test Loss: 0.0997051\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0715132\n",
      "\tspeed: 0.0532s/iter; left time: 710.0583s\n",
      "\titers: 200, epoch: 41 | loss: 0.0690387\n",
      "\tspeed: 0.0267s/iter; left time: 353.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722332 Vali Loss: 0.0872902 Test Loss: 0.0996747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0766864\n",
      "\tspeed: 0.0525s/iter; left time: 688.9114s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704855\n",
      "\tspeed: 0.0265s/iter; left time: 345.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0722141 Vali Loss: 0.0873723 Test Loss: 0.0996596\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0717274\n",
      "\tspeed: 0.0530s/iter; left time: 683.2456s\n",
      "\titers: 200, epoch: 43 | loss: 0.0687616\n",
      "\tspeed: 0.0274s/iter; left time: 350.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0721847 Vali Loss: 0.0872899 Test Loss: 0.0996401\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682925\n",
      "\tspeed: 0.0532s/iter; left time: 673.6730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0717148\n",
      "\tspeed: 0.0267s/iter; left time: 336.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722191 Vali Loss: 0.0873592 Test Loss: 0.0996715\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0739661\n",
      "\tspeed: 0.0526s/iter; left time: 654.3423s\n",
      "\titers: 200, epoch: 45 | loss: 0.0704421\n",
      "\tspeed: 0.0268s/iter; left time: 330.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721614 Vali Loss: 0.0873060 Test Loss: 0.0996651\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0744253\n",
      "\tspeed: 0.0525s/iter; left time: 642.1980s\n",
      "\titers: 200, epoch: 46 | loss: 0.0733730\n",
      "\tspeed: 0.0268s/iter; left time: 324.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0721902 Vali Loss: 0.0871615 Test Loss: 0.0996455\n",
      "Validation loss decreased (0.087227 --> 0.087162).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738844\n",
      "\tspeed: 0.0523s/iter; left time: 627.0182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0732504\n",
      "\tspeed: 0.0265s/iter; left time: 315.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0721966 Vali Loss: 0.0873352 Test Loss: 0.0996582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0738569\n",
      "\tspeed: 0.0522s/iter; left time: 615.0724s\n",
      "\titers: 200, epoch: 48 | loss: 0.0660235\n",
      "\tspeed: 0.0265s/iter; left time: 309.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721567 Vali Loss: 0.0874393 Test Loss: 0.0996577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700567\n",
      "\tspeed: 0.0530s/iter; left time: 611.5923s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708773\n",
      "\tspeed: 0.0268s/iter; left time: 306.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0721437 Vali Loss: 0.0873161 Test Loss: 0.0996556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0701776\n",
      "\tspeed: 0.0522s/iter; left time: 590.7105s\n",
      "\titers: 200, epoch: 50 | loss: 0.0751142\n",
      "\tspeed: 0.0267s/iter; left time: 299.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0721538 Vali Loss: 0.0873739 Test Loss: 0.0996439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0683126\n",
      "\tspeed: 0.0519s/iter; left time: 576.3710s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737489\n",
      "\tspeed: 0.0270s/iter; left time: 297.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721442 Vali Loss: 0.0874031 Test Loss: 0.0996389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0686506\n",
      "\tspeed: 0.0521s/iter; left time: 566.9737s\n",
      "\titers: 200, epoch: 52 | loss: 0.0714018\n",
      "\tspeed: 0.0266s/iter; left time: 286.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0872806 Test Loss: 0.0996446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0680443\n",
      "\tspeed: 0.0520s/iter; left time: 553.8117s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746092\n",
      "\tspeed: 0.0268s/iter; left time: 282.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0721653 Vali Loss: 0.0872594 Test Loss: 0.0996658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0697796\n",
      "\tspeed: 0.0522s/iter; left time: 544.4062s\n",
      "\titers: 200, epoch: 54 | loss: 0.0704911\n",
      "\tspeed: 0.0264s/iter; left time: 273.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721745 Vali Loss: 0.0874115 Test Loss: 0.0996338\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0660143\n",
      "\tspeed: 0.0517s/iter; left time: 527.2257s\n",
      "\titers: 200, epoch: 55 | loss: 0.0712318\n",
      "\tspeed: 0.0265s/iter; left time: 268.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721330 Vali Loss: 0.0873371 Test Loss: 0.0996511\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0705199\n",
      "\tspeed: 0.0519s/iter; left time: 518.3399s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784174\n",
      "\tspeed: 0.0265s/iter; left time: 262.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0721358 Vali Loss: 0.0872928 Test Loss: 0.0996450\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025020133703947067, rmse:0.15817753970623016, mae:0.09964548796415329, rse:0.5456676483154297\n",
      "Intermediate time for GB and pred_len 24: 00h:15m:37.54s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1362466\n",
      "\tspeed: 0.0553s/iter; left time: 1234.0899s\n",
      "\titers: 200, epoch: 1 | loss: 0.1315828\n",
      "\tspeed: 0.0268s/iter; left time: 594.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.1354785 Vali Loss: 0.1317148 Test Loss: 0.1549259\n",
      "Validation loss decreased (inf --> 0.131715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100148\n",
      "\tspeed: 0.0537s/iter; left time: 1185.5225s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011972\n",
      "\tspeed: 0.0269s/iter; left time: 590.6520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1090403 Vali Loss: 0.1182589 Test Loss: 0.1401924\n",
      "Validation loss decreased (0.131715 --> 0.118259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020023\n",
      "\tspeed: 0.0538s/iter; left time: 1174.9266s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028889\n",
      "\tspeed: 0.0270s/iter; left time: 586.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1039733 Vali Loss: 0.1175403 Test Loss: 0.1411576\n",
      "Validation loss decreased (0.118259 --> 0.117540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018276\n",
      "\tspeed: 0.0529s/iter; left time: 1143.3982s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026525\n",
      "\tspeed: 0.0270s/iter; left time: 581.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1026064 Vali Loss: 0.1166299 Test Loss: 0.1399759\n",
      "Validation loss decreased (0.117540 --> 0.116630).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026763\n",
      "\tspeed: 0.0534s/iter; left time: 1144.0695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0943075\n",
      "\tspeed: 0.0268s/iter; left time: 570.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1015074 Vali Loss: 0.1164241 Test Loss: 0.1412032\n",
      "Validation loss decreased (0.116630 --> 0.116424).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1025002\n",
      "\tspeed: 0.0531s/iter; left time: 1123.7738s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032541\n",
      "\tspeed: 0.0271s/iter; left time: 571.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1006094 Vali Loss: 0.1160348 Test Loss: 0.1397788\n",
      "Validation loss decreased (0.116424 --> 0.116035).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038390\n",
      "\tspeed: 0.0535s/iter; left time: 1121.2498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0969341\n",
      "\tspeed: 0.0268s/iter; left time: 559.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0997999 Vali Loss: 0.1159833 Test Loss: 0.1389591\n",
      "Validation loss decreased (0.116035 --> 0.115983).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006562\n",
      "\tspeed: 0.0540s/iter; left time: 1120.2872s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981172\n",
      "\tspeed: 0.0270s/iter; left time: 557.5209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0990484 Vali Loss: 0.1169135 Test Loss: 0.1407297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0989951\n",
      "\tspeed: 0.0535s/iter; left time: 1097.1081s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990440\n",
      "\tspeed: 0.0271s/iter; left time: 553.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0983205 Vali Loss: 0.1171196 Test Loss: 0.1430553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1003540\n",
      "\tspeed: 0.0529s/iter; left time: 1073.5132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0943393\n",
      "\tspeed: 0.0269s/iter; left time: 543.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0977161 Vali Loss: 0.1167704 Test Loss: 0.1415311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969625\n",
      "\tspeed: 0.0539s/iter; left time: 1081.2312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986367\n",
      "\tspeed: 0.0268s/iter; left time: 534.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0971241 Vali Loss: 0.1168764 Test Loss: 0.1429615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012906\n",
      "\tspeed: 0.0530s/iter; left time: 1051.5503s\n",
      "\titers: 200, epoch: 12 | loss: 0.0969430\n",
      "\tspeed: 0.0268s/iter; left time: 529.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0966664 Vali Loss: 0.1162381 Test Loss: 0.1405379\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961613\n",
      "\tspeed: 0.0536s/iter; left time: 1050.6042s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981514\n",
      "\tspeed: 0.0270s/iter; left time: 525.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0962394 Vali Loss: 0.1173263 Test Loss: 0.1436641\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0961513\n",
      "\tspeed: 0.0532s/iter; left time: 1031.3833s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940166\n",
      "\tspeed: 0.0269s/iter; left time: 518.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0958293 Vali Loss: 0.1172846 Test Loss: 0.1412998\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0907448\n",
      "\tspeed: 0.0530s/iter; left time: 1015.5836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0936777\n",
      "\tspeed: 0.0269s/iter; left time: 513.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0954853 Vali Loss: 0.1174681 Test Loss: 0.1431191\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0971071\n",
      "\tspeed: 0.0530s/iter; left time: 1004.5613s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991246\n",
      "\tspeed: 0.0270s/iter; left time: 508.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0951561 Vali Loss: 0.1177430 Test Loss: 0.1433660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0933138\n",
      "\tspeed: 0.0532s/iter; left time: 996.3669s\n",
      "\titers: 200, epoch: 17 | loss: 0.0953560\n",
      "\tspeed: 0.0270s/iter; left time: 502.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0948642 Vali Loss: 0.1173937 Test Loss: 0.1422419\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04156280308961868, rmse:0.20386956632137299, mae:0.138959139585495, rse:0.705009400844574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1342963\n",
      "\tspeed: 0.0294s/iter; left time: 655.5017s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212572\n",
      "\tspeed: 0.0270s/iter; left time: 598.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1354378 Vali Loss: 0.1306439 Test Loss: 0.1532763\n",
      "Validation loss decreased (inf --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1063669\n",
      "\tspeed: 0.0539s/iter; left time: 1190.0957s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015290\n",
      "\tspeed: 0.0268s/iter; left time: 588.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1090908 Vali Loss: 0.1179647 Test Loss: 0.1400083\n",
      "Validation loss decreased (0.130644 --> 0.117965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034727\n",
      "\tspeed: 0.0543s/iter; left time: 1186.3327s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050127\n",
      "\tspeed: 0.0268s/iter; left time: 582.9759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1041194 Vali Loss: 0.1176144 Test Loss: 0.1397710\n",
      "Validation loss decreased (0.117965 --> 0.117614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971245\n",
      "\tspeed: 0.0556s/iter; left time: 1202.5577s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046980\n",
      "\tspeed: 0.0271s/iter; left time: 583.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1028142 Vali Loss: 0.1171384 Test Loss: 0.1404998\n",
      "Validation loss decreased (0.117614 --> 0.117138).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977949\n",
      "\tspeed: 0.0553s/iter; left time: 1182.8713s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043665\n",
      "\tspeed: 0.0268s/iter; left time: 571.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1018217 Vali Loss: 0.1171914 Test Loss: 0.1403327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947371\n",
      "\tspeed: 0.0534s/iter; left time: 1131.0207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1068232\n",
      "\tspeed: 0.0268s/iter; left time: 564.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1010497 Vali Loss: 0.1167937 Test Loss: 0.1400926\n",
      "Validation loss decreased (0.117138 --> 0.116794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955816\n",
      "\tspeed: 0.0545s/iter; left time: 1143.1946s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973860\n",
      "\tspeed: 0.0267s/iter; left time: 557.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1002006 Vali Loss: 0.1169059 Test Loss: 0.1398973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982215\n",
      "\tspeed: 0.0550s/iter; left time: 1140.3708s\n",
      "\titers: 200, epoch: 8 | loss: 0.0986912\n",
      "\tspeed: 0.0269s/iter; left time: 555.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0995622 Vali Loss: 0.1171644 Test Loss: 0.1394792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0983291\n",
      "\tspeed: 0.0544s/iter; left time: 1115.5611s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015055\n",
      "\tspeed: 0.0267s/iter; left time: 544.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0990405 Vali Loss: 0.1170354 Test Loss: 0.1404738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0966749\n",
      "\tspeed: 0.0548s/iter; left time: 1111.2377s\n",
      "\titers: 200, epoch: 10 | loss: 0.0984571\n",
      "\tspeed: 0.0271s/iter; left time: 547.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0984118 Vali Loss: 0.1174196 Test Loss: 0.1405433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945642\n",
      "\tspeed: 0.0554s/iter; left time: 1111.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0937180\n",
      "\tspeed: 0.0268s/iter; left time: 534.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0979818 Vali Loss: 0.1171703 Test Loss: 0.1407737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0964229\n",
      "\tspeed: 0.0543s/iter; left time: 1077.2916s\n",
      "\titers: 200, epoch: 12 | loss: 0.1007808\n",
      "\tspeed: 0.0270s/iter; left time: 533.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0975590 Vali Loss: 0.1174397 Test Loss: 0.1414426\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0947333\n",
      "\tspeed: 0.0534s/iter; left time: 1048.2167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915383\n",
      "\tspeed: 0.0268s/iter; left time: 523.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0971209 Vali Loss: 0.1181216 Test Loss: 0.1418197\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0964207\n",
      "\tspeed: 0.0543s/iter; left time: 1053.2275s\n",
      "\titers: 200, epoch: 14 | loss: 0.0957182\n",
      "\tspeed: 0.0268s/iter; left time: 516.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0966924 Vali Loss: 0.1173833 Test Loss: 0.1408844\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0976923\n",
      "\tspeed: 0.0538s/iter; left time: 1031.1701s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943371\n",
      "\tspeed: 0.0268s/iter; left time: 511.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0964538 Vali Loss: 0.1180992 Test Loss: 0.1427835\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0937670\n",
      "\tspeed: 0.0538s/iter; left time: 1018.7485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0968458\n",
      "\tspeed: 0.0268s/iter; left time: 505.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961151 Vali Loss: 0.1176016 Test Loss: 0.1419638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04211575910449028, rmse:0.2052212506532669, mae:0.1400926262140274, rse:0.7096836566925049\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:39.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354124\n",
      "\tspeed: 0.0554s/iter; left time: 1229.6732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1269919\n",
      "\tspeed: 0.0271s/iter; left time: 599.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.1370751 Vali Loss: 0.1339571 Test Loss: 0.1580050\n",
      "Validation loss decreased (inf --> 0.133957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1144067\n",
      "\tspeed: 0.0538s/iter; left time: 1181.8960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070809\n",
      "\tspeed: 0.0271s/iter; left time: 593.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1134790 Vali Loss: 0.1227112 Test Loss: 0.1471968\n",
      "Validation loss decreased (0.133957 --> 0.122711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099978\n",
      "\tspeed: 0.0546s/iter; left time: 1186.9160s\n",
      "\titers: 200, epoch: 3 | loss: 0.1067006\n",
      "\tspeed: 0.0272s/iter; left time: 588.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1086630 Vali Loss: 0.1216847 Test Loss: 0.1465340\n",
      "Validation loss decreased (0.122711 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087929\n",
      "\tspeed: 0.0553s/iter; left time: 1189.7324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128875\n",
      "\tspeed: 0.0271s/iter; left time: 580.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1071564 Vali Loss: 0.1216329 Test Loss: 0.1464036\n",
      "Validation loss decreased (0.121685 --> 0.121633).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036660\n",
      "\tspeed: 0.0565s/iter; left time: 1204.0028s\n",
      "\titers: 200, epoch: 5 | loss: 0.1098936\n",
      "\tspeed: 0.0271s/iter; left time: 575.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1058232 Vali Loss: 0.1211363 Test Loss: 0.1468929\n",
      "Validation loss decreased (0.121633 --> 0.121136).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023184\n",
      "\tspeed: 0.0551s/iter; left time: 1162.4825s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047149\n",
      "\tspeed: 0.0272s/iter; left time: 570.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1045786 Vali Loss: 0.1214660 Test Loss: 0.1477442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1030283\n",
      "\tspeed: 0.0551s/iter; left time: 1148.7618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983301\n",
      "\tspeed: 0.0274s/iter; left time: 568.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035771 Vali Loss: 0.1215716 Test Loss: 0.1494350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1021642\n",
      "\tspeed: 0.0551s/iter; left time: 1137.1951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1072234\n",
      "\tspeed: 0.0274s/iter; left time: 562.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026726 Vali Loss: 0.1215428 Test Loss: 0.1478654\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027741\n",
      "\tspeed: 0.0555s/iter; left time: 1132.5589s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979295\n",
      "\tspeed: 0.0273s/iter; left time: 554.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1020552 Vali Loss: 0.1213815 Test Loss: 0.1498316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996236\n",
      "\tspeed: 0.0543s/iter; left time: 1096.0517s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013777\n",
      "\tspeed: 0.0273s/iter; left time: 548.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1013867 Vali Loss: 0.1220490 Test Loss: 0.1514326\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994694\n",
      "\tspeed: 0.0553s/iter; left time: 1104.2498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0999421\n",
      "\tspeed: 0.0274s/iter; left time: 543.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1007758 Vali Loss: 0.1213371 Test Loss: 0.1484833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966362\n",
      "\tspeed: 0.0549s/iter; left time: 1083.1968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990719\n",
      "\tspeed: 0.0273s/iter; left time: 535.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1002209 Vali Loss: 0.1218838 Test Loss: 0.1496712\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996767\n",
      "\tspeed: 0.0548s/iter; left time: 1070.0136s\n",
      "\titers: 200, epoch: 13 | loss: 0.1026959\n",
      "\tspeed: 0.0272s/iter; left time: 528.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0997564 Vali Loss: 0.1217964 Test Loss: 0.1501298\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0985504\n",
      "\tspeed: 0.0554s/iter; left time: 1068.8520s\n",
      "\titers: 200, epoch: 14 | loss: 0.0999128\n",
      "\tspeed: 0.0272s/iter; left time: 523.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0993586 Vali Loss: 0.1223004 Test Loss: 0.1509998\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021761\n",
      "\tspeed: 0.0548s/iter; left time: 1045.3280s\n",
      "\titers: 200, epoch: 15 | loss: 0.1022515\n",
      "\tspeed: 0.0273s/iter; left time: 517.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0989366 Vali Loss: 0.1226592 Test Loss: 0.1515421\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459306597709656, rmse:0.21117070317268372, mae:0.14689284563064575, rse:0.7321591973304749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343334\n",
      "\tspeed: 0.0304s/iter; left time: 675.5745s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274043\n",
      "\tspeed: 0.0273s/iter; left time: 604.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1373720 Vali Loss: 0.1342096 Test Loss: 0.1581728\n",
      "Validation loss decreased (inf --> 0.134210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1134263\n",
      "\tspeed: 0.0564s/iter; left time: 1240.0853s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105637\n",
      "\tspeed: 0.0276s/iter; left time: 603.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1132997 Vali Loss: 0.1233650 Test Loss: 0.1481477\n",
      "Validation loss decreased (0.134210 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1110428\n",
      "\tspeed: 0.0561s/iter; left time: 1219.9967s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082572\n",
      "\tspeed: 0.0271s/iter; left time: 587.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1087510 Vali Loss: 0.1223908 Test Loss: 0.1466880\n",
      "Validation loss decreased (0.123365 --> 0.122391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1091575\n",
      "\tspeed: 0.0577s/iter; left time: 1241.7612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072541\n",
      "\tspeed: 0.0274s/iter; left time: 587.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1072281 Vali Loss: 0.1221424 Test Loss: 0.1471605\n",
      "Validation loss decreased (0.122391 --> 0.122142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074684\n",
      "\tspeed: 0.0569s/iter; left time: 1212.2677s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056222\n",
      "\tspeed: 0.0274s/iter; left time: 581.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1056581 Vali Loss: 0.1219717 Test Loss: 0.1469719\n",
      "Validation loss decreased (0.122142 --> 0.121972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063322\n",
      "\tspeed: 0.0565s/iter; left time: 1192.2183s\n",
      "\titers: 200, epoch: 6 | loss: 0.1021206\n",
      "\tspeed: 0.0273s/iter; left time: 572.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1043592 Vali Loss: 0.1220159 Test Loss: 0.1479042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1007787\n",
      "\tspeed: 0.0559s/iter; left time: 1165.4247s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071176\n",
      "\tspeed: 0.0273s/iter; left time: 565.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1034426 Vali Loss: 0.1219470 Test Loss: 0.1468008\n",
      "Validation loss decreased (0.121972 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024007\n",
      "\tspeed: 0.0562s/iter; left time: 1159.3587s\n",
      "\titers: 200, epoch: 8 | loss: 0.1011106\n",
      "\tspeed: 0.0273s/iter; left time: 560.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026371 Vali Loss: 0.1226881 Test Loss: 0.1485755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010926\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1769s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037420\n",
      "\tspeed: 0.0273s/iter; left time: 555.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1018770 Vali Loss: 0.1230170 Test Loss: 0.1505015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995526\n",
      "\tspeed: 0.0558s/iter; left time: 1126.7199s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030146\n",
      "\tspeed: 0.0273s/iter; left time: 549.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1011918 Vali Loss: 0.1236346 Test Loss: 0.1512475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1019870\n",
      "\tspeed: 0.0558s/iter; left time: 1114.2898s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035597\n",
      "\tspeed: 0.0274s/iter; left time: 543.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1005595 Vali Loss: 0.1228452 Test Loss: 0.1502132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1003256\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7425s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002665\n",
      "\tspeed: 0.0273s/iter; left time: 537.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1000163 Vali Loss: 0.1234094 Test Loss: 0.1494783\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1022886\n",
      "\tspeed: 0.0564s/iter; left time: 1101.7633s\n",
      "\titers: 200, epoch: 13 | loss: 0.1002941\n",
      "\tspeed: 0.0274s/iter; left time: 531.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0994505 Vali Loss: 0.1235107 Test Loss: 0.1497943\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975255\n",
      "\tspeed: 0.0559s/iter; left time: 1078.1402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0986446\n",
      "\tspeed: 0.0274s/iter; left time: 526.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0990837 Vali Loss: 0.1231035 Test Loss: 0.1512404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982782\n",
      "\tspeed: 0.0557s/iter; left time: 1061.8515s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003537\n",
      "\tspeed: 0.0273s/iter; left time: 518.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0986666 Vali Loss: 0.1234591 Test Loss: 0.1508010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1010868\n",
      "\tspeed: 0.0562s/iter; left time: 1058.7894s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004014\n",
      "\tspeed: 0.0274s/iter; left time: 513.3969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0983119 Vali Loss: 0.1234264 Test Loss: 0.1515623\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973225\n",
      "\tspeed: 0.0560s/iter; left time: 1042.6396s\n",
      "\titers: 200, epoch: 17 | loss: 0.0972442\n",
      "\tspeed: 0.0271s/iter; left time: 502.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0979932 Vali Loss: 0.1239732 Test Loss: 0.1527091\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486566409468651, rmse:0.21181516349315643, mae:0.14680077135562897, rse:0.7343935966491699\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:39.74s\n",
      "Intermediate time for GB: 00h:24m:56.87s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1297289\n",
      "\tspeed: 0.0455s/iter; left time: 1015.3594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1126045\n",
      "\tspeed: 0.0178s/iter; left time: 395.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1356361 Vali Loss: 0.0979728 Test Loss: 0.1105253\n",
      "Validation loss decreased (inf --> 0.097973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740920\n",
      "\tspeed: 0.0365s/iter; left time: 805.5324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695283\n",
      "\tspeed: 0.0174s/iter; left time: 382.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0769994 Vali Loss: 0.0646745 Test Loss: 0.0711548\n",
      "Validation loss decreased (0.097973 --> 0.064675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641058\n",
      "\tspeed: 0.0361s/iter; left time: 789.8069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0647144\n",
      "\tspeed: 0.0174s/iter; left time: 378.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0655269 Vali Loss: 0.0602642 Test Loss: 0.0665508\n",
      "Validation loss decreased (0.064675 --> 0.060264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620353\n",
      "\tspeed: 0.0359s/iter; left time: 777.5343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641675\n",
      "\tspeed: 0.0180s/iter; left time: 386.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0622778 Vali Loss: 0.0589169 Test Loss: 0.0652260\n",
      "Validation loss decreased (0.060264 --> 0.058917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600411\n",
      "\tspeed: 0.0386s/iter; left time: 827.2866s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605951\n",
      "\tspeed: 0.0208s/iter; left time: 443.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0604136 Vali Loss: 0.0574598 Test Loss: 0.0637832\n",
      "Validation loss decreased (0.058917 --> 0.057460).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0576362\n",
      "\tspeed: 0.0362s/iter; left time: 767.1964s\n",
      "\titers: 200, epoch: 6 | loss: 0.0572372\n",
      "\tspeed: 0.0185s/iter; left time: 389.9134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0592250 Vali Loss: 0.0569232 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.057460 --> 0.056923).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0641758\n",
      "\tspeed: 0.0404s/iter; left time: 847.3156s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604304\n",
      "\tspeed: 0.0228s/iter; left time: 474.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0582727 Vali Loss: 0.0563158 Test Loss: 0.0624014\n",
      "Validation loss decreased (0.056923 --> 0.056316).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597004\n",
      "\tspeed: 0.0397s/iter; left time: 823.0412s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545038\n",
      "\tspeed: 0.0217s/iter; left time: 448.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0575341 Vali Loss: 0.0555614 Test Loss: 0.0619747\n",
      "Validation loss decreased (0.056316 --> 0.055561).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581241\n",
      "\tspeed: 0.0373s/iter; left time: 764.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0560733\n",
      "\tspeed: 0.0177s/iter; left time: 361.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0569077 Vali Loss: 0.0551520 Test Loss: 0.0613294\n",
      "Validation loss decreased (0.055561 --> 0.055152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600654\n",
      "\tspeed: 0.0369s/iter; left time: 748.1508s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543051\n",
      "\tspeed: 0.0173s/iter; left time: 349.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0564565 Vali Loss: 0.0552002 Test Loss: 0.0615373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0573782\n",
      "\tspeed: 0.0354s/iter; left time: 710.7419s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561891\n",
      "\tspeed: 0.0173s/iter; left time: 346.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0560166 Vali Loss: 0.0547021 Test Loss: 0.0608617\n",
      "Validation loss decreased (0.055152 --> 0.054702).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549166\n",
      "\tspeed: 0.0368s/iter; left time: 730.5754s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550303\n",
      "\tspeed: 0.0175s/iter; left time: 345.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0556077 Vali Loss: 0.0544642 Test Loss: 0.0607819\n",
      "Validation loss decreased (0.054702 --> 0.054464).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530001\n",
      "\tspeed: 0.0374s/iter; left time: 734.4276s\n",
      "\titers: 200, epoch: 13 | loss: 0.0505261\n",
      "\tspeed: 0.0172s/iter; left time: 336.1488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0553481 Vali Loss: 0.0544108 Test Loss: 0.0603867\n",
      "Validation loss decreased (0.054464 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576824\n",
      "\tspeed: 0.0382s/iter; left time: 741.3690s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537340\n",
      "\tspeed: 0.0180s/iter; left time: 347.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0550210 Vali Loss: 0.0542770 Test Loss: 0.0605504\n",
      "Validation loss decreased (0.054411 --> 0.054277).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0541440\n",
      "\tspeed: 0.0374s/iter; left time: 716.8168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551845\n",
      "\tspeed: 0.0176s/iter; left time: 336.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0547780 Vali Loss: 0.0540772 Test Loss: 0.0603587\n",
      "Validation loss decreased (0.054277 --> 0.054077).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509629\n",
      "\tspeed: 0.0377s/iter; left time: 714.1568s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555559\n",
      "\tspeed: 0.0201s/iter; left time: 379.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0545937 Vali Loss: 0.0540071 Test Loss: 0.0602936\n",
      "Validation loss decreased (0.054077 --> 0.054007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533449\n",
      "\tspeed: 0.0376s/iter; left time: 702.8441s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549480\n",
      "\tspeed: 0.0232s/iter; left time: 431.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543840 Vali Loss: 0.0535351 Test Loss: 0.0598909\n",
      "Validation loss decreased (0.054007 --> 0.053535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534377\n",
      "\tspeed: 0.0413s/iter; left time: 763.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519669\n",
      "\tspeed: 0.0180s/iter; left time: 330.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0541835 Vali Loss: 0.0535182 Test Loss: 0.0599301\n",
      "Validation loss decreased (0.053535 --> 0.053518).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546421\n",
      "\tspeed: 0.0365s/iter; left time: 666.7154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532574\n",
      "\tspeed: 0.0173s/iter; left time: 315.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0541097 Vali Loss: 0.0536294 Test Loss: 0.0598268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540954\n",
      "\tspeed: 0.0388s/iter; left time: 699.9337s\n",
      "\titers: 200, epoch: 20 | loss: 0.0566773\n",
      "\tspeed: 0.0218s/iter; left time: 391.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0538978 Vali Loss: 0.0535801 Test Loss: 0.0599190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0543947\n",
      "\tspeed: 0.0428s/iter; left time: 762.3693s\n",
      "\titers: 200, epoch: 21 | loss: 0.0548367\n",
      "\tspeed: 0.0209s/iter; left time: 369.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0537692 Vali Loss: 0.0534152 Test Loss: 0.0598009\n",
      "Validation loss decreased (0.053518 --> 0.053415).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549492\n",
      "\tspeed: 0.0444s/iter; left time: 780.6195s\n",
      "\titers: 200, epoch: 22 | loss: 0.0514017\n",
      "\tspeed: 0.0198s/iter; left time: 346.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0537207 Vali Loss: 0.0533374 Test Loss: 0.0596908\n",
      "Validation loss decreased (0.053415 --> 0.053337).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0534591\n",
      "\tspeed: 0.0393s/iter; left time: 682.3595s\n",
      "\titers: 200, epoch: 23 | loss: 0.0526582\n",
      "\tspeed: 0.0216s/iter; left time: 372.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0536544 Vali Loss: 0.0533163 Test Loss: 0.0596185\n",
      "Validation loss decreased (0.053337 --> 0.053316).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0538955\n",
      "\tspeed: 0.0382s/iter; left time: 655.3983s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538660\n",
      "\tspeed: 0.0208s/iter; left time: 354.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0535522 Vali Loss: 0.0532527 Test Loss: 0.0594967\n",
      "Validation loss decreased (0.053316 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573650\n",
      "\tspeed: 0.0380s/iter; left time: 643.7574s\n",
      "\titers: 200, epoch: 25 | loss: 0.0528080\n",
      "\tspeed: 0.0178s/iter; left time: 300.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0534546 Vali Loss: 0.0532459 Test Loss: 0.0595710\n",
      "Validation loss decreased (0.053253 --> 0.053246).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537234\n",
      "\tspeed: 0.0401s/iter; left time: 669.8796s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546586\n",
      "\tspeed: 0.0176s/iter; left time: 292.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0533645 Vali Loss: 0.0533376 Test Loss: 0.0595235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516834\n",
      "\tspeed: 0.0371s/iter; left time: 610.6094s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571585\n",
      "\tspeed: 0.0177s/iter; left time: 289.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0532839 Vali Loss: 0.0533172 Test Loss: 0.0594809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0494189\n",
      "\tspeed: 0.0375s/iter; left time: 610.2077s\n",
      "\titers: 200, epoch: 28 | loss: 0.0522387\n",
      "\tspeed: 0.0174s/iter; left time: 281.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0533023 Vali Loss: 0.0531314 Test Loss: 0.0593853\n",
      "Validation loss decreased (0.053246 --> 0.053131).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0519411\n",
      "\tspeed: 0.0371s/iter; left time: 594.9347s\n",
      "\titers: 200, epoch: 29 | loss: 0.0522147\n",
      "\tspeed: 0.0180s/iter; left time: 286.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0532008 Vali Loss: 0.0530601 Test Loss: 0.0593986\n",
      "Validation loss decreased (0.053131 --> 0.053060).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523858\n",
      "\tspeed: 0.0420s/iter; left time: 664.5347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0539169\n",
      "\tspeed: 0.0184s/iter; left time: 288.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0532031 Vali Loss: 0.0530461 Test Loss: 0.0593301\n",
      "Validation loss decreased (0.053060 --> 0.053046).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542132\n",
      "\tspeed: 0.0406s/iter; left time: 633.3297s\n",
      "\titers: 200, epoch: 31 | loss: 0.0558742\n",
      "\tspeed: 0.0176s/iter; left time: 272.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0531557 Vali Loss: 0.0529637 Test Loss: 0.0594197\n",
      "Validation loss decreased (0.053046 --> 0.052964).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531322\n",
      "\tspeed: 0.0409s/iter; left time: 627.4583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0507826\n",
      "\tspeed: 0.0204s/iter; left time: 310.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531287 Vali Loss: 0.0530666 Test Loss: 0.0593458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0550206\n",
      "\tspeed: 0.0367s/iter; left time: 555.3600s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542851\n",
      "\tspeed: 0.0176s/iter; left time: 264.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0531302 Vali Loss: 0.0529413 Test Loss: 0.0592580\n",
      "Validation loss decreased (0.052964 --> 0.052941).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0553355\n",
      "\tspeed: 0.0431s/iter; left time: 642.1845s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519135\n",
      "\tspeed: 0.0197s/iter; left time: 292.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0530112 Vali Loss: 0.0529859 Test Loss: 0.0593040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532875\n",
      "\tspeed: 0.0362s/iter; left time: 530.9979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0528023\n",
      "\tspeed: 0.0181s/iter; left time: 264.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0530626 Vali Loss: 0.0530781 Test Loss: 0.0593102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0557845\n",
      "\tspeed: 0.0373s/iter; left time: 539.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521810\n",
      "\tspeed: 0.0176s/iter; left time: 252.7647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529679 Vali Loss: 0.0529296 Test Loss: 0.0592321\n",
      "Validation loss decreased (0.052941 --> 0.052930).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0516731\n",
      "\tspeed: 0.0358s/iter; left time: 510.3623s\n",
      "\titers: 200, epoch: 37 | loss: 0.0540236\n",
      "\tspeed: 0.0172s/iter; left time: 243.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0529866 Vali Loss: 0.0529916 Test Loss: 0.0592840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0508000\n",
      "\tspeed: 0.0362s/iter; left time: 507.2096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547213\n",
      "\tspeed: 0.0175s/iter; left time: 244.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0529485 Vali Loss: 0.0529122 Test Loss: 0.0592196\n",
      "Validation loss decreased (0.052930 --> 0.052912).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0529043\n",
      "\tspeed: 0.0439s/iter; left time: 605.4128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516311\n",
      "\tspeed: 0.0246s/iter; left time: 337.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0528965 Test Loss: 0.0592480\n",
      "Validation loss decreased (0.052912 --> 0.052897).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0494722\n",
      "\tspeed: 0.0396s/iter; left time: 537.3741s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527704\n",
      "\tspeed: 0.0175s/iter; left time: 235.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528899 Vali Loss: 0.0529518 Test Loss: 0.0593059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0527010\n",
      "\tspeed: 0.0354s/iter; left time: 471.6542s\n",
      "\titers: 200, epoch: 41 | loss: 0.0523881\n",
      "\tspeed: 0.0176s/iter; left time: 232.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529096 Vali Loss: 0.0528782 Test Loss: 0.0592054\n",
      "Validation loss decreased (0.052897 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0550479\n",
      "\tspeed: 0.0420s/iter; left time: 550.5007s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528131\n",
      "\tspeed: 0.0175s/iter; left time: 227.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0529324 Vali Loss: 0.0529419 Test Loss: 0.0592431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511567\n",
      "\tspeed: 0.0449s/iter; left time: 578.9241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0510774\n",
      "\tspeed: 0.0215s/iter; left time: 275.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0528664 Vali Loss: 0.0529480 Test Loss: 0.0592471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547131\n",
      "\tspeed: 0.0377s/iter; left time: 478.0473s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535225\n",
      "\tspeed: 0.0176s/iter; left time: 220.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0529409 Vali Loss: 0.0529403 Test Loss: 0.0591982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0499585\n",
      "\tspeed: 0.0368s/iter; left time: 458.5532s\n",
      "\titers: 200, epoch: 45 | loss: 0.0560696\n",
      "\tspeed: 0.0211s/iter; left time: 260.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0528784 Vali Loss: 0.0529030 Test Loss: 0.0592152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0512092\n",
      "\tspeed: 0.0385s/iter; left time: 470.9820s\n",
      "\titers: 200, epoch: 46 | loss: 0.0548510\n",
      "\tspeed: 0.0178s/iter; left time: 216.1218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0528416 Vali Loss: 0.0529498 Test Loss: 0.0591846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0539514\n",
      "\tspeed: 0.0358s/iter; left time: 429.2966s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507728\n",
      "\tspeed: 0.0174s/iter; left time: 207.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0528806 Vali Loss: 0.0529439 Test Loss: 0.0591778\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547237\n",
      "\tspeed: 0.0360s/iter; left time: 423.9098s\n",
      "\titers: 200, epoch: 48 | loss: 0.0500909\n",
      "\tspeed: 0.0175s/iter; left time: 204.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0528072 Vali Loss: 0.0529146 Test Loss: 0.0592384\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0538362\n",
      "\tspeed: 0.0378s/iter; left time: 436.7830s\n",
      "\titers: 200, epoch: 49 | loss: 0.0551731\n",
      "\tspeed: 0.0176s/iter; left time: 201.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0528127 Vali Loss: 0.0528409 Test Loss: 0.0591774\n",
      "Validation loss decreased (0.052878 --> 0.052841).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547548\n",
      "\tspeed: 0.0363s/iter; left time: 410.5844s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522613\n",
      "\tspeed: 0.0175s/iter; left time: 196.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0528483 Vali Loss: 0.0529676 Test Loss: 0.0592235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0515651\n",
      "\tspeed: 0.0434s/iter; left time: 482.0306s\n",
      "\titers: 200, epoch: 51 | loss: 0.0519167\n",
      "\tspeed: 0.0205s/iter; left time: 225.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0528751 Vali Loss: 0.0528772 Test Loss: 0.0591687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0547058\n",
      "\tspeed: 0.0394s/iter; left time: 428.2818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0527426\n",
      "\tspeed: 0.0233s/iter; left time: 251.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0528348 Vali Loss: 0.0528290 Test Loss: 0.0591753\n",
      "Validation loss decreased (0.052841 --> 0.052829).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529373\n",
      "\tspeed: 0.0379s/iter; left time: 404.1027s\n",
      "\titers: 200, epoch: 53 | loss: 0.0567268\n",
      "\tspeed: 0.0182s/iter; left time: 192.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0528269 Vali Loss: 0.0528880 Test Loss: 0.0591835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0536679\n",
      "\tspeed: 0.0388s/iter; left time: 404.9540s\n",
      "\titers: 200, epoch: 54 | loss: 0.0512394\n",
      "\tspeed: 0.0189s/iter; left time: 195.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0527903 Vali Loss: 0.0528845 Test Loss: 0.0591716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0511981\n",
      "\tspeed: 0.0394s/iter; left time: 401.7271s\n",
      "\titers: 200, epoch: 55 | loss: 0.0518198\n",
      "\tspeed: 0.0175s/iter; left time: 176.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0527804 Vali Loss: 0.0528382 Test Loss: 0.0591643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0501965\n",
      "\tspeed: 0.0377s/iter; left time: 376.6580s\n",
      "\titers: 200, epoch: 56 | loss: 0.0531978\n",
      "\tspeed: 0.0177s/iter; left time: 175.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0528132 Vali Loss: 0.0529282 Test Loss: 0.0592545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0523530\n",
      "\tspeed: 0.0383s/iter; left time: 373.5001s\n",
      "\titers: 200, epoch: 57 | loss: 0.0532235\n",
      "\tspeed: 0.0188s/iter; left time: 181.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0528334 Vali Loss: 0.0528543 Test Loss: 0.0591806\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0517060\n",
      "\tspeed: 0.0385s/iter; left time: 367.0567s\n",
      "\titers: 200, epoch: 58 | loss: 0.0537203\n",
      "\tspeed: 0.0222s/iter; left time: 209.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0528633 Vali Loss: 0.0529062 Test Loss: 0.0591597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0542901\n",
      "\tspeed: 0.0444s/iter; left time: 413.4854s\n",
      "\titers: 200, epoch: 59 | loss: 0.0490207\n",
      "\tspeed: 0.0196s/iter; left time: 180.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0527814 Vali Loss: 0.0528723 Test Loss: 0.0591480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0534826\n",
      "\tspeed: 0.0398s/iter; left time: 361.2870s\n",
      "\titers: 200, epoch: 60 | loss: 0.0522820\n",
      "\tspeed: 0.0175s/iter; left time: 157.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0528065 Vali Loss: 0.0528880 Test Loss: 0.0591799\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0541162\n",
      "\tspeed: 0.0382s/iter; left time: 338.2691s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526189\n",
      "\tspeed: 0.0199s/iter; left time: 174.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0528557 Vali Loss: 0.0528851 Test Loss: 0.0591978\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0529211\n",
      "\tspeed: 0.0372s/iter; left time: 321.3345s\n",
      "\titers: 200, epoch: 62 | loss: 0.0479516\n",
      "\tspeed: 0.0172s/iter; left time: 147.0690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0527867 Vali Loss: 0.0529483 Test Loss: 0.0591934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009751381352543831, rmse:0.0987490862607956, mae:0.05917529761791229, rse:0.29060661792755127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337921\n",
      "\tspeed: 0.0206s/iter; left time: 458.7822s\n",
      "\titers: 200, epoch: 1 | loss: 0.1069674\n",
      "\tspeed: 0.0206s/iter; left time: 458.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1356587 Vali Loss: 0.0968538 Test Loss: 0.1094441\n",
      "Validation loss decreased (inf --> 0.096854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746105\n",
      "\tspeed: 0.0394s/iter; left time: 869.6349s\n",
      "\titers: 200, epoch: 2 | loss: 0.0701489\n",
      "\tspeed: 0.0175s/iter; left time: 385.2628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0639559 Test Loss: 0.0706353\n",
      "Validation loss decreased (0.096854 --> 0.063956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675678\n",
      "\tspeed: 0.0370s/iter; left time: 807.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0615702\n",
      "\tspeed: 0.0174s/iter; left time: 379.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0655629 Vali Loss: 0.0605291 Test Loss: 0.0668655\n",
      "Validation loss decreased (0.063956 --> 0.060529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629944\n",
      "\tspeed: 0.0368s/iter; left time: 795.4977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0648704\n",
      "\tspeed: 0.0183s/iter; left time: 393.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0625614 Vali Loss: 0.0589684 Test Loss: 0.0655182\n",
      "Validation loss decreased (0.060529 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588870\n",
      "\tspeed: 0.0402s/iter; left time: 860.9520s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.0176s/iter; left time: 375.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0606106 Vali Loss: 0.0578980 Test Loss: 0.0645265\n",
      "Validation loss decreased (0.058968 --> 0.057898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592575\n",
      "\tspeed: 0.0370s/iter; left time: 782.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571381\n",
      "\tspeed: 0.0175s/iter; left time: 368.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593913 Vali Loss: 0.0566761 Test Loss: 0.0631738\n",
      "Validation loss decreased (0.057898 --> 0.056676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611145\n",
      "\tspeed: 0.0367s/iter; left time: 769.3887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605097\n",
      "\tspeed: 0.0174s/iter; left time: 362.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0583720 Vali Loss: 0.0562617 Test Loss: 0.0624770\n",
      "Validation loss decreased (0.056676 --> 0.056262).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629369\n",
      "\tspeed: 0.0418s/iter; left time: 866.8303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618621\n",
      "\tspeed: 0.0217s/iter; left time: 447.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0576425 Vali Loss: 0.0556517 Test Loss: 0.0618897\n",
      "Validation loss decreased (0.056262 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606712\n",
      "\tspeed: 0.0427s/iter; left time: 875.6113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555764\n",
      "\tspeed: 0.0222s/iter; left time: 453.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0555573 Test Loss: 0.0616752\n",
      "Validation loss decreased (0.055652 --> 0.055557).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596933\n",
      "\tspeed: 0.0453s/iter; left time: 919.0482s\n",
      "\titers: 200, epoch: 10 | loss: 0.0554582\n",
      "\tspeed: 0.0227s/iter; left time: 457.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0565138 Vali Loss: 0.0551991 Test Loss: 0.0614132\n",
      "Validation loss decreased (0.055557 --> 0.055199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0616147\n",
      "\tspeed: 0.0387s/iter; left time: 776.9877s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578825\n",
      "\tspeed: 0.0174s/iter; left time: 348.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0561789 Vali Loss: 0.0549304 Test Loss: 0.0611437\n",
      "Validation loss decreased (0.055199 --> 0.054930).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0537045\n",
      "\tspeed: 0.0367s/iter; left time: 727.8192s\n",
      "\titers: 200, epoch: 12 | loss: 0.0578890\n",
      "\tspeed: 0.0176s/iter; left time: 347.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0557681 Vali Loss: 0.0547644 Test Loss: 0.0607991\n",
      "Validation loss decreased (0.054930 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570883\n",
      "\tspeed: 0.0426s/iter; left time: 835.6845s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543759\n",
      "\tspeed: 0.0178s/iter; left time: 347.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0554576 Vali Loss: 0.0546486 Test Loss: 0.0609315\n",
      "Validation loss decreased (0.054764 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559569\n",
      "\tspeed: 0.0405s/iter; left time: 784.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576939\n",
      "\tspeed: 0.0206s/iter; left time: 397.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0551173 Vali Loss: 0.0543713 Test Loss: 0.0607464\n",
      "Validation loss decreased (0.054649 --> 0.054371).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574309\n",
      "\tspeed: 0.0404s/iter; left time: 773.9555s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533791\n",
      "\tspeed: 0.0193s/iter; left time: 367.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0548902 Vali Loss: 0.0541163 Test Loss: 0.0603891\n",
      "Validation loss decreased (0.054371 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0560301\n",
      "\tspeed: 0.0400s/iter; left time: 758.5325s\n",
      "\titers: 200, epoch: 16 | loss: 0.0556359\n",
      "\tspeed: 0.0215s/iter; left time: 404.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0546661 Vali Loss: 0.0540735 Test Loss: 0.0603688\n",
      "Validation loss decreased (0.054116 --> 0.054073).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567861\n",
      "\tspeed: 0.0400s/iter; left time: 749.0467s\n",
      "\titers: 200, epoch: 17 | loss: 0.0534253\n",
      "\tspeed: 0.0173s/iter; left time: 321.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0545065 Vali Loss: 0.0539584 Test Loss: 0.0603209\n",
      "Validation loss decreased (0.054073 --> 0.053958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0544936\n",
      "\tspeed: 0.0390s/iter; left time: 721.0882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0505661\n",
      "\tspeed: 0.0215s/iter; left time: 394.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0542611 Vali Loss: 0.0537714 Test Loss: 0.0600516\n",
      "Validation loss decreased (0.053958 --> 0.053771).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572401\n",
      "\tspeed: 0.0395s/iter; left time: 720.9557s\n",
      "\titers: 200, epoch: 19 | loss: 0.0509766\n",
      "\tspeed: 0.0203s/iter; left time: 368.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541876 Vali Loss: 0.0537230 Test Loss: 0.0601269\n",
      "Validation loss decreased (0.053771 --> 0.053723).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0581672\n",
      "\tspeed: 0.0391s/iter; left time: 704.9706s\n",
      "\titers: 200, epoch: 20 | loss: 0.0560375\n",
      "\tspeed: 0.0176s/iter; left time: 316.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540584 Vali Loss: 0.0535869 Test Loss: 0.0598196\n",
      "Validation loss decreased (0.053723 --> 0.053587).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0489908\n",
      "\tspeed: 0.0382s/iter; left time: 680.8923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556523\n",
      "\tspeed: 0.0175s/iter; left time: 310.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0539873 Vali Loss: 0.0535157 Test Loss: 0.0598667\n",
      "Validation loss decreased (0.053587 --> 0.053516).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0564136\n",
      "\tspeed: 0.0368s/iter; left time: 647.5133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0507003\n",
      "\tspeed: 0.0175s/iter; left time: 305.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0538451 Vali Loss: 0.0534693 Test Loss: 0.0597156\n",
      "Validation loss decreased (0.053516 --> 0.053469).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0500772\n",
      "\tspeed: 0.0375s/iter; left time: 651.1026s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531840\n",
      "\tspeed: 0.0175s/iter; left time: 301.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0537557 Vali Loss: 0.0533803 Test Loss: 0.0598192\n",
      "Validation loss decreased (0.053469 --> 0.053380).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0520380\n",
      "\tspeed: 0.0453s/iter; left time: 776.9973s\n",
      "\titers: 200, epoch: 24 | loss: 0.0564743\n",
      "\tspeed: 0.0176s/iter; left time: 300.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0536120 Vali Loss: 0.0534145 Test Loss: 0.0596311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0510081\n",
      "\tspeed: 0.0377s/iter; left time: 638.7096s\n",
      "\titers: 200, epoch: 25 | loss: 0.0502159\n",
      "\tspeed: 0.0174s/iter; left time: 293.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0535521 Vali Loss: 0.0534059 Test Loss: 0.0596591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0510387\n",
      "\tspeed: 0.0371s/iter; left time: 620.4239s\n",
      "\titers: 200, epoch: 26 | loss: 0.0527924\n",
      "\tspeed: 0.0177s/iter; left time: 293.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0534718 Vali Loss: 0.0533074 Test Loss: 0.0596614\n",
      "Validation loss decreased (0.053380 --> 0.053307).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0546484\n",
      "\tspeed: 0.0363s/iter; left time: 597.5156s\n",
      "\titers: 200, epoch: 27 | loss: 0.0502867\n",
      "\tspeed: 0.0173s/iter; left time: 283.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0534427 Vali Loss: 0.0532914 Test Loss: 0.0595673\n",
      "Validation loss decreased (0.053307 --> 0.053291).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513472\n",
      "\tspeed: 0.0380s/iter; left time: 617.8899s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544608\n",
      "\tspeed: 0.0177s/iter; left time: 286.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0534265 Vali Loss: 0.0533097 Test Loss: 0.0595132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543246\n",
      "\tspeed: 0.0378s/iter; left time: 606.4173s\n",
      "\titers: 200, epoch: 29 | loss: 0.0545000\n",
      "\tspeed: 0.0175s/iter; left time: 278.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0533031 Vali Loss: 0.0533129 Test Loss: 0.0596252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578123\n",
      "\tspeed: 0.0384s/iter; left time: 606.5506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523473\n",
      "\tspeed: 0.0175s/iter; left time: 275.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0532915 Vali Loss: 0.0531913 Test Loss: 0.0594889\n",
      "Validation loss decreased (0.053291 --> 0.053191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544150\n",
      "\tspeed: 0.0371s/iter; left time: 578.5391s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515520\n",
      "\tspeed: 0.0175s/iter; left time: 270.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0532813 Vali Loss: 0.0531744 Test Loss: 0.0595354\n",
      "Validation loss decreased (0.053191 --> 0.053174).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559174\n",
      "\tspeed: 0.0378s/iter; left time: 580.8415s\n",
      "\titers: 200, epoch: 32 | loss: 0.0526729\n",
      "\tspeed: 0.0173s/iter; left time: 264.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0532091 Vali Loss: 0.0531425 Test Loss: 0.0594587\n",
      "Validation loss decreased (0.053174 --> 0.053143).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0532093\n",
      "\tspeed: 0.0366s/iter; left time: 553.8593s\n",
      "\titers: 200, epoch: 33 | loss: 0.0478663\n",
      "\tspeed: 0.0173s/iter; left time: 259.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0531877 Vali Loss: 0.0531788 Test Loss: 0.0594424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0499334\n",
      "\tspeed: 0.0370s/iter; left time: 551.6185s\n",
      "\titers: 200, epoch: 34 | loss: 0.0506587\n",
      "\tspeed: 0.0175s/iter; left time: 259.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0531430 Vali Loss: 0.0531837 Test Loss: 0.0594441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517330\n",
      "\tspeed: 0.0424s/iter; left time: 622.5793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0551342\n",
      "\tspeed: 0.0203s/iter; left time: 295.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0531663 Vali Loss: 0.0531581 Test Loss: 0.0594528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506947\n",
      "\tspeed: 0.0403s/iter; left time: 582.4848s\n",
      "\titers: 200, epoch: 36 | loss: 0.0583177\n",
      "\tspeed: 0.0203s/iter; left time: 291.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531392 Vali Loss: 0.0531340 Test Loss: 0.0594451\n",
      "Validation loss decreased (0.053143 --> 0.053134).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542479\n",
      "\tspeed: 0.0454s/iter; left time: 646.6699s\n",
      "\titers: 200, epoch: 37 | loss: 0.0510775\n",
      "\tspeed: 0.0217s/iter; left time: 306.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0530918 Vali Loss: 0.0530867 Test Loss: 0.0593737\n",
      "Validation loss decreased (0.053134 --> 0.053087).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556557\n",
      "\tspeed: 0.0396s/iter; left time: 554.6645s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513426\n",
      "\tspeed: 0.0202s/iter; left time: 281.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0530756 Vali Loss: 0.0531610 Test Loss: 0.0594667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526359\n",
      "\tspeed: 0.0394s/iter; left time: 543.4934s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522014\n",
      "\tspeed: 0.0172s/iter; left time: 235.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0530237 Vali Loss: 0.0530525 Test Loss: 0.0593700\n",
      "Validation loss decreased (0.053087 --> 0.053052).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0489786\n",
      "\tspeed: 0.0409s/iter; left time: 554.8960s\n",
      "\titers: 200, epoch: 40 | loss: 0.0538423\n",
      "\tspeed: 0.0191s/iter; left time: 257.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0530496 Vali Loss: 0.0531109 Test Loss: 0.0593490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0539034\n",
      "\tspeed: 0.0382s/iter; left time: 508.9971s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502612\n",
      "\tspeed: 0.0201s/iter; left time: 266.3523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0529953 Vali Loss: 0.0531376 Test Loss: 0.0593575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509308\n",
      "\tspeed: 0.0407s/iter; left time: 533.3291s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528011\n",
      "\tspeed: 0.0203s/iter; left time: 264.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0530408 Vali Loss: 0.0531074 Test Loss: 0.0593930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536508\n",
      "\tspeed: 0.0398s/iter; left time: 513.6043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0535419\n",
      "\tspeed: 0.0209s/iter; left time: 267.6998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0530064 Vali Loss: 0.0531483 Test Loss: 0.0593524\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0534231\n",
      "\tspeed: 0.0422s/iter; left time: 534.2851s\n",
      "\titers: 200, epoch: 44 | loss: 0.0485632\n",
      "\tspeed: 0.0199s/iter; left time: 250.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0529402 Vali Loss: 0.0530934 Test Loss: 0.0593843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504932\n",
      "\tspeed: 0.0404s/iter; left time: 502.4356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0521229\n",
      "\tspeed: 0.0174s/iter; left time: 214.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0530215 Vali Loss: 0.0530575 Test Loss: 0.0593451\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0538279\n",
      "\tspeed: 0.0362s/iter; left time: 442.9136s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554503\n",
      "\tspeed: 0.0174s/iter; left time: 211.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529353 Vali Loss: 0.0530863 Test Loss: 0.0592994\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0534511\n",
      "\tspeed: 0.0370s/iter; left time: 444.1844s\n",
      "\titers: 200, epoch: 47 | loss: 0.0537172\n",
      "\tspeed: 0.0176s/iter; left time: 208.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0529956 Vali Loss: 0.0529808 Test Loss: 0.0593239\n",
      "Validation loss decreased (0.053052 --> 0.052981).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0545642\n",
      "\tspeed: 0.0414s/iter; left time: 487.0466s\n",
      "\titers: 200, epoch: 48 | loss: 0.0503907\n",
      "\tspeed: 0.0176s/iter; left time: 205.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0529698 Vali Loss: 0.0530103 Test Loss: 0.0593279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0509437\n",
      "\tspeed: 0.0385s/iter; left time: 444.9423s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518087\n",
      "\tspeed: 0.0175s/iter; left time: 200.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0529407 Vali Loss: 0.0531188 Test Loss: 0.0594364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0541317\n",
      "\tspeed: 0.0405s/iter; left time: 458.9719s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539311\n",
      "\tspeed: 0.0204s/iter; left time: 228.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0529140 Vali Loss: 0.0530143 Test Loss: 0.0593071\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0535859\n",
      "\tspeed: 0.0379s/iter; left time: 421.0638s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555147\n",
      "\tspeed: 0.0172s/iter; left time: 189.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0529585 Vali Loss: 0.0530431 Test Loss: 0.0593245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0542467\n",
      "\tspeed: 0.0359s/iter; left time: 390.8151s\n",
      "\titers: 200, epoch: 52 | loss: 0.0480840\n",
      "\tspeed: 0.0176s/iter; left time: 189.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0530876 Test Loss: 0.0593659\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0522306\n",
      "\tspeed: 0.0385s/iter; left time: 410.1747s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510478\n",
      "\tspeed: 0.0195s/iter; left time: 205.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0529877 Vali Loss: 0.0530985 Test Loss: 0.0593327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0538847\n",
      "\tspeed: 0.0378s/iter; left time: 394.1452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0531133\n",
      "\tspeed: 0.0174s/iter; left time: 179.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0529167 Vali Loss: 0.0530712 Test Loss: 0.0593545\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534907\n",
      "\tspeed: 0.0399s/iter; left time: 407.1084s\n",
      "\titers: 200, epoch: 55 | loss: 0.0500412\n",
      "\tspeed: 0.0200s/iter; left time: 202.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0529414 Vali Loss: 0.0530433 Test Loss: 0.0593276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0530696\n",
      "\tspeed: 0.0400s/iter; left time: 398.8456s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546860\n",
      "\tspeed: 0.0176s/iter; left time: 173.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0529148 Vali Loss: 0.0530499 Test Loss: 0.0593268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0518850\n",
      "\tspeed: 0.0382s/iter; left time: 372.5004s\n",
      "\titers: 200, epoch: 57 | loss: 0.0534603\n",
      "\tspeed: 0.0229s/iter; left time: 221.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0529192 Vali Loss: 0.0530396 Test Loss: 0.0593469\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009775502607226372, rmse:0.0988711416721344, mae:0.05932391434907913, rse:0.29096582531929016\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:39.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1329530\n",
      "\tspeed: 0.0443s/iter; left time: 987.1059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160002\n",
      "\tspeed: 0.0176s/iter; left time: 390.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1391902 Vali Loss: 0.1071772 Test Loss: 0.1206293\n",
      "Validation loss decreased (inf --> 0.107177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0942523\n",
      "\tspeed: 0.0385s/iter; left time: 850.8737s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861847\n",
      "\tspeed: 0.0185s/iter; left time: 406.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0945715 Vali Loss: 0.0842465 Test Loss: 0.0952013\n",
      "Validation loss decreased (0.107177 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845243\n",
      "\tspeed: 0.0382s/iter; left time: 834.0629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815090\n",
      "\tspeed: 0.0181s/iter; left time: 393.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0807858 Test Loss: 0.0915264\n",
      "Validation loss decreased (0.084247 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820356\n",
      "\tspeed: 0.0378s/iter; left time: 816.7261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805881\n",
      "\tspeed: 0.0176s/iter; left time: 378.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0823000 Vali Loss: 0.0797732 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.080786 --> 0.079773).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798331\n",
      "\tspeed: 0.0379s/iter; left time: 810.5959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755010\n",
      "\tspeed: 0.0177s/iter; left time: 376.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0804131 Vali Loss: 0.0779141 Test Loss: 0.0881555\n",
      "Validation loss decreased (0.079773 --> 0.077914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0796704\n",
      "\tspeed: 0.0375s/iter; left time: 793.5661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799784\n",
      "\tspeed: 0.0176s/iter; left time: 371.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0789057 Vali Loss: 0.0770733 Test Loss: 0.0876542\n",
      "Validation loss decreased (0.077914 --> 0.077073).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788884\n",
      "\tspeed: 0.0376s/iter; left time: 788.3541s\n",
      "\titers: 200, epoch: 7 | loss: 0.0752197\n",
      "\tspeed: 0.0177s/iter; left time: 368.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777904 Vali Loss: 0.0771061 Test Loss: 0.0872416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774317\n",
      "\tspeed: 0.0376s/iter; left time: 779.7228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751686\n",
      "\tspeed: 0.0205s/iter; left time: 423.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0770810 Vali Loss: 0.0767934 Test Loss: 0.0870996\n",
      "Validation loss decreased (0.077073 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771739\n",
      "\tspeed: 0.0401s/iter; left time: 823.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746005\n",
      "\tspeed: 0.0182s/iter; left time: 372.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0765222 Vali Loss: 0.0760892 Test Loss: 0.0869368\n",
      "Validation loss decreased (0.076793 --> 0.076089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779370\n",
      "\tspeed: 0.0435s/iter; left time: 882.3856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787978\n",
      "\tspeed: 0.0186s/iter; left time: 375.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0760347 Vali Loss: 0.0766135 Test Loss: 0.0868480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761426\n",
      "\tspeed: 0.0382s/iter; left time: 765.4540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789521\n",
      "\tspeed: 0.0178s/iter; left time: 355.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0756286 Vali Loss: 0.0763626 Test Loss: 0.0866961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0761763\n",
      "\tspeed: 0.0373s/iter; left time: 740.3132s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757204\n",
      "\tspeed: 0.0178s/iter; left time: 352.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0753164 Vali Loss: 0.0763749 Test Loss: 0.0863272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718356\n",
      "\tspeed: 0.0375s/iter; left time: 735.7471s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752915\n",
      "\tspeed: 0.0178s/iter; left time: 348.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0749505 Vali Loss: 0.0764924 Test Loss: 0.0864433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712507\n",
      "\tspeed: 0.0413s/iter; left time: 800.9626s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751940\n",
      "\tspeed: 0.0204s/iter; left time: 393.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0747298 Vali Loss: 0.0763432 Test Loss: 0.0865515\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0714074\n",
      "\tspeed: 0.0389s/iter; left time: 746.0339s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769075\n",
      "\tspeed: 0.0179s/iter; left time: 340.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0744110 Vali Loss: 0.0763409 Test Loss: 0.0860551\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736857\n",
      "\tspeed: 0.0390s/iter; left time: 738.2485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0758855\n",
      "\tspeed: 0.0179s/iter; left time: 336.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0741638 Vali Loss: 0.0763573 Test Loss: 0.0862534\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732683\n",
      "\tspeed: 0.0372s/iter; left time: 696.4759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766605\n",
      "\tspeed: 0.0178s/iter; left time: 332.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0739782 Vali Loss: 0.0760687 Test Loss: 0.0860618\n",
      "Validation loss decreased (0.076089 --> 0.076069).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758949\n",
      "\tspeed: 0.0420s/iter; left time: 775.8797s\n",
      "\titers: 200, epoch: 18 | loss: 0.0741989\n",
      "\tspeed: 0.0201s/iter; left time: 369.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0738317 Vali Loss: 0.0758029 Test Loss: 0.0859767\n",
      "Validation loss decreased (0.076069 --> 0.075803).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731899\n",
      "\tspeed: 0.0400s/iter; left time: 730.6615s\n",
      "\titers: 200, epoch: 19 | loss: 0.0783558\n",
      "\tspeed: 0.0180s/iter; left time: 326.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0736161 Vali Loss: 0.0767120 Test Loss: 0.0861842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724703\n",
      "\tspeed: 0.0395s/iter; left time: 713.2295s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739780\n",
      "\tspeed: 0.0187s/iter; left time: 335.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0735227 Vali Loss: 0.0763454 Test Loss: 0.0858723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0736979\n",
      "\tspeed: 0.0383s/iter; left time: 681.9721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0692475\n",
      "\tspeed: 0.0176s/iter; left time: 312.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733244 Vali Loss: 0.0759520 Test Loss: 0.0858447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0742377\n",
      "\tspeed: 0.0378s/iter; left time: 664.7089s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738283\n",
      "\tspeed: 0.0177s/iter; left time: 309.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0732371 Vali Loss: 0.0761869 Test Loss: 0.0859049\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716027\n",
      "\tspeed: 0.0386s/iter; left time: 671.2958s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768406\n",
      "\tspeed: 0.0176s/iter; left time: 304.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0730942 Vali Loss: 0.0761952 Test Loss: 0.0858184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739905\n",
      "\tspeed: 0.0375s/iter; left time: 643.1647s\n",
      "\titers: 200, epoch: 24 | loss: 0.0714365\n",
      "\tspeed: 0.0177s/iter; left time: 300.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0729818 Vali Loss: 0.0762859 Test Loss: 0.0857470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0700301\n",
      "\tspeed: 0.0383s/iter; left time: 648.7693s\n",
      "\titers: 200, epoch: 25 | loss: 0.0753928\n",
      "\tspeed: 0.0181s/iter; left time: 303.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0729328 Vali Loss: 0.0763261 Test Loss: 0.0859215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696138\n",
      "\tspeed: 0.0382s/iter; left time: 637.6291s\n",
      "\titers: 200, epoch: 26 | loss: 0.0715025\n",
      "\tspeed: 0.0196s/iter; left time: 325.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0728175 Vali Loss: 0.0762029 Test Loss: 0.0858192\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725613\n",
      "\tspeed: 0.0370s/iter; left time: 610.2925s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719680\n",
      "\tspeed: 0.0185s/iter; left time: 302.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0727753 Vali Loss: 0.0761756 Test Loss: 0.0857254\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751431\n",
      "\tspeed: 0.0390s/iter; left time: 634.0645s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738966\n",
      "\tspeed: 0.0178s/iter; left time: 287.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0727138 Vali Loss: 0.0765646 Test Loss: 0.0857118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01854773983359337, rmse:0.13619008660316467, mae:0.08597671240568161, rse:0.4000854790210724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1367538\n",
      "\tspeed: 0.0223s/iter; left time: 496.8574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153385\n",
      "\tspeed: 0.0233s/iter; left time: 517.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1400050 Vali Loss: 0.1071248 Test Loss: 0.1205454\n",
      "Validation loss decreased (inf --> 0.107125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936913\n",
      "\tspeed: 0.0460s/iter; left time: 1015.9851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879241\n",
      "\tspeed: 0.0176s/iter; left time: 387.3446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0942411 Vali Loss: 0.0843040 Test Loss: 0.0953580\n",
      "Validation loss decreased (0.107125 --> 0.084304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803946\n",
      "\tspeed: 0.0403s/iter; left time: 880.0693s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812021\n",
      "\tspeed: 0.0178s/iter; left time: 386.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0852106 Vali Loss: 0.0801856 Test Loss: 0.0912001\n",
      "Validation loss decreased (0.084304 --> 0.080186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788692\n",
      "\tspeed: 0.0415s/iter; left time: 898.5903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0762093\n",
      "\tspeed: 0.0216s/iter; left time: 466.0767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0821201 Vali Loss: 0.0789561 Test Loss: 0.0895967\n",
      "Validation loss decreased (0.080186 --> 0.078956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793223\n",
      "\tspeed: 0.0421s/iter; left time: 900.2679s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773962\n",
      "\tspeed: 0.0193s/iter; left time: 410.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802467 Vali Loss: 0.0778591 Test Loss: 0.0884357\n",
      "Validation loss decreased (0.078956 --> 0.077859).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816932\n",
      "\tspeed: 0.0403s/iter; left time: 853.8364s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778644\n",
      "\tspeed: 0.0177s/iter; left time: 373.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0790325 Vali Loss: 0.0767959 Test Loss: 0.0875439\n",
      "Validation loss decreased (0.077859 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745961\n",
      "\tspeed: 0.0387s/iter; left time: 810.0707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834768\n",
      "\tspeed: 0.0178s/iter; left time: 371.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0781038 Vali Loss: 0.0762627 Test Loss: 0.0873462\n",
      "Validation loss decreased (0.076796 --> 0.076263).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800848\n",
      "\tspeed: 0.0400s/iter; left time: 829.6929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742644\n",
      "\tspeed: 0.0178s/iter; left time: 367.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0773239 Vali Loss: 0.0775152 Test Loss: 0.0874873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721739\n",
      "\tspeed: 0.0381s/iter; left time: 780.9902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794274\n",
      "\tspeed: 0.0209s/iter; left time: 426.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0767547 Vali Loss: 0.0763608 Test Loss: 0.0870005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758219\n",
      "\tspeed: 0.0409s/iter; left time: 828.6589s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767745\n",
      "\tspeed: 0.0189s/iter; left time: 381.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0761915 Vali Loss: 0.0771433 Test Loss: 0.0867632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747136\n",
      "\tspeed: 0.0450s/iter; left time: 903.2435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756405\n",
      "\tspeed: 0.0197s/iter; left time: 394.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0757717 Vali Loss: 0.0765610 Test Loss: 0.0865518\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0714020\n",
      "\tspeed: 0.0425s/iter; left time: 843.1375s\n",
      "\titers: 200, epoch: 12 | loss: 0.0774138\n",
      "\tspeed: 0.0219s/iter; left time: 431.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0754335 Vali Loss: 0.0767363 Test Loss: 0.0865050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722883\n",
      "\tspeed: 0.0396s/iter; left time: 775.7284s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759881\n",
      "\tspeed: 0.0175s/iter; left time: 341.8679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0751549 Vali Loss: 0.0761463 Test Loss: 0.0862424\n",
      "Validation loss decreased (0.076263 --> 0.076146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745482\n",
      "\tspeed: 0.0412s/iter; left time: 799.4890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0744093\n",
      "\tspeed: 0.0245s/iter; left time: 471.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0747696 Vali Loss: 0.0762650 Test Loss: 0.0862187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720881\n",
      "\tspeed: 0.0400s/iter; left time: 765.8024s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781316\n",
      "\tspeed: 0.0174s/iter; left time: 331.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0745868 Vali Loss: 0.0765290 Test Loss: 0.0860522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0727114\n",
      "\tspeed: 0.0412s/iter; left time: 779.4685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736387\n",
      "\tspeed: 0.0179s/iter; left time: 337.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0743449 Vali Loss: 0.0765852 Test Loss: 0.0860310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706794\n",
      "\tspeed: 0.0388s/iter; left time: 726.9777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752406\n",
      "\tspeed: 0.0205s/iter; left time: 381.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0741923 Vali Loss: 0.0764369 Test Loss: 0.0859239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0744676\n",
      "\tspeed: 0.0419s/iter; left time: 775.4276s\n",
      "\titers: 200, epoch: 18 | loss: 0.0762818\n",
      "\tspeed: 0.0202s/iter; left time: 371.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0740024 Vali Loss: 0.0767829 Test Loss: 0.0857268\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720721\n",
      "\tspeed: 0.0437s/iter; left time: 797.7713s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713664\n",
      "\tspeed: 0.0189s/iter; left time: 342.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0738495 Vali Loss: 0.0765352 Test Loss: 0.0859384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717330\n",
      "\tspeed: 0.0413s/iter; left time: 745.2349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795915\n",
      "\tspeed: 0.0205s/iter; left time: 368.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0736705 Vali Loss: 0.0764407 Test Loss: 0.0857348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724586\n",
      "\tspeed: 0.0392s/iter; left time: 697.8497s\n",
      "\titers: 200, epoch: 21 | loss: 0.0760887\n",
      "\tspeed: 0.0186s/iter; left time: 329.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0735496 Vali Loss: 0.0764364 Test Loss: 0.0857035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712291\n",
      "\tspeed: 0.0433s/iter; left time: 762.3607s\n",
      "\titers: 200, epoch: 22 | loss: 0.0771685\n",
      "\tspeed: 0.0197s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0734158 Vali Loss: 0.0766588 Test Loss: 0.0858466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0699845\n",
      "\tspeed: 0.0433s/iter; left time: 751.8209s\n",
      "\titers: 200, epoch: 23 | loss: 0.0729147\n",
      "\tspeed: 0.0220s/iter; left time: 380.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0733128 Vali Loss: 0.0762644 Test Loss: 0.0857591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018521282821893692, rmse:0.1360929161310196, mae:0.08624237030744553, rse:0.39980003237724304\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:11.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1373530\n",
      "\tspeed: 0.0465s/iter; left time: 1032.9857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231130\n",
      "\tspeed: 0.0178s/iter; left time: 392.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1409036 Vali Loss: 0.1098791 Test Loss: 0.1227950\n",
      "Validation loss decreased (inf --> 0.109879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0984424\n",
      "\tspeed: 0.0383s/iter; left time: 841.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898476\n",
      "\tspeed: 0.0182s/iter; left time: 398.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0985992 Vali Loss: 0.0892979 Test Loss: 0.1007477\n",
      "Validation loss decreased (0.109879 --> 0.089298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924045\n",
      "\tspeed: 0.0405s/iter; left time: 880.7054s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917421\n",
      "\tspeed: 0.0180s/iter; left time: 389.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0898567 Vali Loss: 0.0863748 Test Loss: 0.0964161\n",
      "Validation loss decreased (0.089298 --> 0.086375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892772\n",
      "\tspeed: 0.0398s/iter; left time: 856.7383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851799\n",
      "\tspeed: 0.0179s/iter; left time: 383.3302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0869219 Vali Loss: 0.0845703 Test Loss: 0.0945225\n",
      "Validation loss decreased (0.086375 --> 0.084570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874058\n",
      "\tspeed: 0.0391s/iter; left time: 832.4707s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828013\n",
      "\tspeed: 0.0178s/iter; left time: 377.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0849152 Vali Loss: 0.0836334 Test Loss: 0.0937513\n",
      "Validation loss decreased (0.084570 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0815478\n",
      "\tspeed: 0.0387s/iter; left time: 816.1537s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822768\n",
      "\tspeed: 0.0180s/iter; left time: 377.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0835952 Vali Loss: 0.0829994 Test Loss: 0.0932573\n",
      "Validation loss decreased (0.083633 --> 0.082999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838339\n",
      "\tspeed: 0.0395s/iter; left time: 823.9421s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832751\n",
      "\tspeed: 0.0178s/iter; left time: 370.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0826350 Vali Loss: 0.0830178 Test Loss: 0.0929825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780568\n",
      "\tspeed: 0.0390s/iter; left time: 803.9680s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825638\n",
      "\tspeed: 0.0203s/iter; left time: 417.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0819650 Vali Loss: 0.0831217 Test Loss: 0.0930658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0815612\n",
      "\tspeed: 0.0383s/iter; left time: 782.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793496\n",
      "\tspeed: 0.0184s/iter; left time: 373.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0814262 Vali Loss: 0.0825041 Test Loss: 0.0924428\n",
      "Validation loss decreased (0.082999 --> 0.082504).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0814151\n",
      "\tspeed: 0.0392s/iter; left time: 790.9053s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819548\n",
      "\tspeed: 0.0179s/iter; left time: 360.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0809147 Vali Loss: 0.0830627 Test Loss: 0.0926520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803450\n",
      "\tspeed: 0.0384s/iter; left time: 767.3787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782218\n",
      "\tspeed: 0.0181s/iter; left time: 360.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0805403 Vali Loss: 0.0824139 Test Loss: 0.0921823\n",
      "Validation loss decreased (0.082504 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775920\n",
      "\tspeed: 0.0397s/iter; left time: 784.6760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816294\n",
      "\tspeed: 0.0182s/iter; left time: 357.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0801135 Vali Loss: 0.0824283 Test Loss: 0.0917523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782452\n",
      "\tspeed: 0.0407s/iter; left time: 794.1000s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793490\n",
      "\tspeed: 0.0190s/iter; left time: 369.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0797442 Vali Loss: 0.0824807 Test Loss: 0.0922180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785616\n",
      "\tspeed: 0.0401s/iter; left time: 773.2075s\n",
      "\titers: 200, epoch: 14 | loss: 0.0811015\n",
      "\tspeed: 0.0178s/iter; left time: 342.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0794834 Vali Loss: 0.0825382 Test Loss: 0.0917946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793498\n",
      "\tspeed: 0.0381s/iter; left time: 726.5424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0845542\n",
      "\tspeed: 0.0178s/iter; left time: 337.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0791975 Vali Loss: 0.0827265 Test Loss: 0.0922221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800094\n",
      "\tspeed: 0.0381s/iter; left time: 719.1809s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803068\n",
      "\tspeed: 0.0181s/iter; left time: 340.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0789066 Vali Loss: 0.0829194 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777317\n",
      "\tspeed: 0.0381s/iter; left time: 710.2658s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769415\n",
      "\tspeed: 0.0178s/iter; left time: 329.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0787117 Vali Loss: 0.0828620 Test Loss: 0.0919372\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754707\n",
      "\tspeed: 0.0418s/iter; left time: 769.0558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807448\n",
      "\tspeed: 0.0184s/iter; left time: 336.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0784592 Vali Loss: 0.0827428 Test Loss: 0.0919137\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788248\n",
      "\tspeed: 0.0387s/iter; left time: 703.3631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779088\n",
      "\tspeed: 0.0180s/iter; left time: 325.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0783152 Vali Loss: 0.0827719 Test Loss: 0.0921597\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814836\n",
      "\tspeed: 0.0378s/iter; left time: 678.8644s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774235\n",
      "\tspeed: 0.0178s/iter; left time: 317.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0781401 Vali Loss: 0.0830398 Test Loss: 0.0921266\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0771261\n",
      "\tspeed: 0.0382s/iter; left time: 677.8467s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789094\n",
      "\tspeed: 0.0178s/iter; left time: 314.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0780248 Vali Loss: 0.0829910 Test Loss: 0.0919375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020852474495768547, rmse:0.1444038599729538, mae:0.09218230098485947, rse:0.42424553632736206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1372358\n",
      "\tspeed: 0.0202s/iter; left time: 449.2328s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189031\n",
      "\tspeed: 0.0179s/iter; left time: 395.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1425659 Vali Loss: 0.1109068 Test Loss: 0.1238196\n",
      "Validation loss decreased (inf --> 0.110907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962597\n",
      "\tspeed: 0.0425s/iter; left time: 935.0872s\n",
      "\titers: 200, epoch: 2 | loss: 0.0892632\n",
      "\tspeed: 0.0180s/iter; left time: 393.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0986520 Vali Loss: 0.0897229 Test Loss: 0.1013632\n",
      "Validation loss decreased (0.110907 --> 0.089723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895527\n",
      "\tspeed: 0.0434s/iter; left time: 943.5019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0907336\n",
      "\tspeed: 0.0201s/iter; left time: 435.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0899338 Vali Loss: 0.0860113 Test Loss: 0.0964112\n",
      "Validation loss decreased (0.089723 --> 0.086011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0877847\n",
      "\tspeed: 0.0397s/iter; left time: 854.1758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873513\n",
      "\tspeed: 0.0179s/iter; left time: 383.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0867699 Vali Loss: 0.0845652 Test Loss: 0.0945405\n",
      "Validation loss decreased (0.086011 --> 0.084565).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860343\n",
      "\tspeed: 0.0392s/iter; left time: 834.4113s\n",
      "\titers: 200, epoch: 5 | loss: 0.0856858\n",
      "\tspeed: 0.0179s/iter; left time: 380.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0848098 Vali Loss: 0.0831996 Test Loss: 0.0935732\n",
      "Validation loss decreased (0.084565 --> 0.083200).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817515\n",
      "\tspeed: 0.0383s/iter; left time: 807.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0839486\n",
      "\tspeed: 0.0178s/iter; left time: 374.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0835718 Vali Loss: 0.0824345 Test Loss: 0.0923223\n",
      "Validation loss decreased (0.083200 --> 0.082434).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821306\n",
      "\tspeed: 0.0427s/iter; left time: 891.5068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817424\n",
      "\tspeed: 0.0198s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0828282 Vali Loss: 0.0827731 Test Loss: 0.0922567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816821\n",
      "\tspeed: 0.0384s/iter; left time: 791.9485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851653\n",
      "\tspeed: 0.0178s/iter; left time: 366.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0822374 Vali Loss: 0.0825162 Test Loss: 0.0923592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792334\n",
      "\tspeed: 0.0387s/iter; left time: 789.8722s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820873\n",
      "\tspeed: 0.0177s/iter; left time: 360.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0817259 Vali Loss: 0.0824933 Test Loss: 0.0925659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0831882\n",
      "\tspeed: 0.0420s/iter; left time: 848.0628s\n",
      "\titers: 200, epoch: 10 | loss: 0.0840190\n",
      "\tspeed: 0.0204s/iter; left time: 410.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0812772 Vali Loss: 0.0824480 Test Loss: 0.0920063\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844629\n",
      "\tspeed: 0.0422s/iter; left time: 842.0142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0821361\n",
      "\tspeed: 0.0217s/iter; left time: 430.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0809295 Vali Loss: 0.0831282 Test Loss: 0.0924046\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819720\n",
      "\tspeed: 0.0393s/iter; left time: 775.8412s\n",
      "\titers: 200, epoch: 12 | loss: 0.0770248\n",
      "\tspeed: 0.0181s/iter; left time: 356.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0805377 Vali Loss: 0.0823976 Test Loss: 0.0917684\n",
      "Validation loss decreased (0.082434 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825309\n",
      "\tspeed: 0.0393s/iter; left time: 768.1248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808482\n",
      "\tspeed: 0.0178s/iter; left time: 346.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0802130 Vali Loss: 0.0822795 Test Loss: 0.0915192\n",
      "Validation loss decreased (0.082398 --> 0.082279).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787355\n",
      "\tspeed: 0.0396s/iter; left time: 764.3940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800075\n",
      "\tspeed: 0.0178s/iter; left time: 341.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0799463 Vali Loss: 0.0827081 Test Loss: 0.0917543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0808903\n",
      "\tspeed: 0.0406s/iter; left time: 775.0545s\n",
      "\titers: 200, epoch: 15 | loss: 0.0780651\n",
      "\tspeed: 0.0209s/iter; left time: 397.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0796282 Vali Loss: 0.0825399 Test Loss: 0.0913055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823017\n",
      "\tspeed: 0.0437s/iter; left time: 823.8916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0812932\n",
      "\tspeed: 0.0181s/iter; left time: 339.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0794008 Vali Loss: 0.0822595 Test Loss: 0.0912687\n",
      "Validation loss decreased (0.082279 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0768999\n",
      "\tspeed: 0.0397s/iter; left time: 740.5874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793285\n",
      "\tspeed: 0.0182s/iter; left time: 337.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0792046 Vali Loss: 0.0824286 Test Loss: 0.0913005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0811558\n",
      "\tspeed: 0.0422s/iter; left time: 776.8880s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767288\n",
      "\tspeed: 0.0186s/iter; left time: 341.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0790217 Vali Loss: 0.0826947 Test Loss: 0.0914750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766188\n",
      "\tspeed: 0.0383s/iter; left time: 696.5783s\n",
      "\titers: 200, epoch: 19 | loss: 0.0823196\n",
      "\tspeed: 0.0180s/iter; left time: 325.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0788044 Vali Loss: 0.0827591 Test Loss: 0.0914700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801984\n",
      "\tspeed: 0.0382s/iter; left time: 686.2105s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807184\n",
      "\tspeed: 0.0179s/iter; left time: 319.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0786730 Vali Loss: 0.0820548 Test Loss: 0.0909845\n",
      "Validation loss decreased (0.082259 --> 0.082055).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0805757\n",
      "\tspeed: 0.0410s/iter; left time: 726.6098s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777372\n",
      "\tspeed: 0.0185s/iter; left time: 325.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0785318 Vali Loss: 0.0824276 Test Loss: 0.0911584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793678\n",
      "\tspeed: 0.0398s/iter; left time: 697.4270s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783650\n",
      "\tspeed: 0.0185s/iter; left time: 322.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0784128 Vali Loss: 0.0825987 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0799742\n",
      "\tspeed: 0.0389s/iter; left time: 673.1967s\n",
      "\titers: 200, epoch: 23 | loss: 0.0794193\n",
      "\tspeed: 0.0180s/iter; left time: 308.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0825067 Test Loss: 0.0911256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0774844\n",
      "\tspeed: 0.0408s/iter; left time: 695.8240s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797026\n",
      "\tspeed: 0.0187s/iter; left time: 317.2155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0781464 Vali Loss: 0.0826594 Test Loss: 0.0912149\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770763\n",
      "\tspeed: 0.0453s/iter; left time: 763.6968s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791379\n",
      "\tspeed: 0.0215s/iter; left time: 359.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0780359 Vali Loss: 0.0827667 Test Loss: 0.0911917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812251\n",
      "\tspeed: 0.0463s/iter; left time: 769.7062s\n",
      "\titers: 200, epoch: 26 | loss: 0.0773855\n",
      "\tspeed: 0.0217s/iter; left time: 358.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0779974 Vali Loss: 0.0827996 Test Loss: 0.0910253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775638\n",
      "\tspeed: 0.0450s/iter; left time: 737.7617s\n",
      "\titers: 200, epoch: 27 | loss: 0.0749843\n",
      "\tspeed: 0.0213s/iter; left time: 346.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0779365 Vali Loss: 0.0824053 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0782782\n",
      "\tspeed: 0.0427s/iter; left time: 691.0858s\n",
      "\titers: 200, epoch: 28 | loss: 0.0794728\n",
      "\tspeed: 0.0213s/iter; left time: 342.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0778237 Vali Loss: 0.0824167 Test Loss: 0.0909431\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744470\n",
      "\tspeed: 0.0498s/iter; left time: 794.5243s\n",
      "\titers: 200, epoch: 29 | loss: 0.0743873\n",
      "\tspeed: 0.0229s/iter; left time: 363.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0778208 Vali Loss: 0.0826677 Test Loss: 0.0910047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778956\n",
      "\tspeed: 0.0468s/iter; left time: 736.4441s\n",
      "\titers: 200, epoch: 30 | loss: 0.0735903\n",
      "\tspeed: 0.0199s/iter; left time: 311.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0826702 Test Loss: 0.0909662\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02058718539774418, rmse:0.14348235726356506, mae:0.09098456054925919, rse:0.42153823375701904\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:15.25s\n",
      "Intermediate time for ES: 00h:22m:06.03s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0923198\n",
      "\tspeed: 0.0471s/iter; left time: 1050.7328s\n",
      "\titers: 200, epoch: 1 | loss: 0.0812700\n",
      "\tspeed: 0.0175s/iter; left time: 389.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0997137 Vali Loss: 0.0826080 Test Loss: 0.0894115\n",
      "Validation loss decreased (inf --> 0.082608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0530040\n",
      "\tspeed: 0.0374s/iter; left time: 825.2455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500890\n",
      "\tspeed: 0.0176s/iter; left time: 386.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0568332 Vali Loss: 0.0584304 Test Loss: 0.0615740\n",
      "Validation loss decreased (0.082608 --> 0.058430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0495541\n",
      "\tspeed: 0.0390s/iter; left time: 852.1089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0470994\n",
      "\tspeed: 0.0178s/iter; left time: 386.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0492891 Vali Loss: 0.0561867 Test Loss: 0.0599419\n",
      "Validation loss decreased (0.058430 --> 0.056187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472196\n",
      "\tspeed: 0.0373s/iter; left time: 805.7826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496854\n",
      "\tspeed: 0.0175s/iter; left time: 375.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0474948 Vali Loss: 0.0547214 Test Loss: 0.0583943\n",
      "Validation loss decreased (0.056187 --> 0.054721).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0445898\n",
      "\tspeed: 0.0379s/iter; left time: 811.0635s\n",
      "\titers: 200, epoch: 5 | loss: 0.0486444\n",
      "\tspeed: 0.0175s/iter; left time: 373.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462286 Vali Loss: 0.0537535 Test Loss: 0.0576479\n",
      "Validation loss decreased (0.054721 --> 0.053753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0466075\n",
      "\tspeed: 0.0384s/iter; left time: 813.6643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427133\n",
      "\tspeed: 0.0173s/iter; left time: 364.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0453936 Vali Loss: 0.0532484 Test Loss: 0.0574954\n",
      "Validation loss decreased (0.053753 --> 0.053248).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0491663\n",
      "\tspeed: 0.0406s/iter; left time: 851.6473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448862\n",
      "\tspeed: 0.0174s/iter; left time: 362.2701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0447000 Vali Loss: 0.0526119 Test Loss: 0.0567984\n",
      "Validation loss decreased (0.053248 --> 0.052612).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0448391\n",
      "\tspeed: 0.0388s/iter; left time: 803.6487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0443497\n",
      "\tspeed: 0.0175s/iter; left time: 361.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0441658 Vali Loss: 0.0528287 Test Loss: 0.0566366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0405296\n",
      "\tspeed: 0.0380s/iter; left time: 779.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0458015\n",
      "\tspeed: 0.0173s/iter; left time: 354.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0437640 Vali Loss: 0.0521360 Test Loss: 0.0564570\n",
      "Validation loss decreased (0.052612 --> 0.052136).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441886\n",
      "\tspeed: 0.0407s/iter; left time: 826.5387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0448638\n",
      "\tspeed: 0.0206s/iter; left time: 415.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0434143 Vali Loss: 0.0517792 Test Loss: 0.0561378\n",
      "Validation loss decreased (0.052136 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440236\n",
      "\tspeed: 0.0429s/iter; left time: 861.3392s\n",
      "\titers: 200, epoch: 11 | loss: 0.0420616\n",
      "\tspeed: 0.0212s/iter; left time: 423.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0431010 Vali Loss: 0.0520836 Test Loss: 0.0564000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0403346\n",
      "\tspeed: 0.0366s/iter; left time: 726.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0413291\n",
      "\tspeed: 0.0175s/iter; left time: 345.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0428325 Vali Loss: 0.0517494 Test Loss: 0.0560631\n",
      "Validation loss decreased (0.051779 --> 0.051749).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406433\n",
      "\tspeed: 0.0376s/iter; left time: 737.7125s\n",
      "\titers: 200, epoch: 13 | loss: 0.0392740\n",
      "\tspeed: 0.0175s/iter; left time: 342.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0425714 Vali Loss: 0.0517062 Test Loss: 0.0557897\n",
      "Validation loss decreased (0.051749 --> 0.051706).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0407032\n",
      "\tspeed: 0.0399s/iter; left time: 773.5516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0415839\n",
      "\tspeed: 0.0184s/iter; left time: 355.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0424152 Vali Loss: 0.0514950 Test Loss: 0.0557442\n",
      "Validation loss decreased (0.051706 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0427796\n",
      "\tspeed: 0.0377s/iter; left time: 723.2441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0386341\n",
      "\tspeed: 0.0173s/iter; left time: 330.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0422304 Vali Loss: 0.0514152 Test Loss: 0.0555388\n",
      "Validation loss decreased (0.051495 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407047\n",
      "\tspeed: 0.0367s/iter; left time: 695.1301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0395314\n",
      "\tspeed: 0.0197s/iter; left time: 370.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0421071 Vali Loss: 0.0514455 Test Loss: 0.0555331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0455639\n",
      "\tspeed: 0.0411s/iter; left time: 768.5792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0418858\n",
      "\tspeed: 0.0178s/iter; left time: 331.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0419426 Vali Loss: 0.0512198 Test Loss: 0.0553853\n",
      "Validation loss decreased (0.051415 --> 0.051220).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0401110\n",
      "\tspeed: 0.0382s/iter; left time: 706.4201s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410072\n",
      "\tspeed: 0.0177s/iter; left time: 326.4655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418059 Vali Loss: 0.0510725 Test Loss: 0.0553629\n",
      "Validation loss decreased (0.051220 --> 0.051072).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0397940\n",
      "\tspeed: 0.0400s/iter; left time: 730.7567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415944\n",
      "\tspeed: 0.0209s/iter; left time: 378.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0416938 Vali Loss: 0.0510424 Test Loss: 0.0552553\n",
      "Validation loss decreased (0.051072 --> 0.051042).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0410033\n",
      "\tspeed: 0.0427s/iter; left time: 770.8388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0419177\n",
      "\tspeed: 0.0181s/iter; left time: 324.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0416170 Vali Loss: 0.0509896 Test Loss: 0.0552562\n",
      "Validation loss decreased (0.051042 --> 0.050990).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414350\n",
      "\tspeed: 0.0380s/iter; left time: 677.0998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0406842\n",
      "\tspeed: 0.0174s/iter; left time: 307.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0415393 Vali Loss: 0.0508995 Test Loss: 0.0550967\n",
      "Validation loss decreased (0.050990 --> 0.050899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0403014\n",
      "\tspeed: 0.0401s/iter; left time: 705.8079s\n",
      "\titers: 200, epoch: 22 | loss: 0.0367226\n",
      "\tspeed: 0.0178s/iter; left time: 310.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0414575 Vali Loss: 0.0509838 Test Loss: 0.0551132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0409429\n",
      "\tspeed: 0.0398s/iter; left time: 691.6798s\n",
      "\titers: 200, epoch: 23 | loss: 0.0429620\n",
      "\tspeed: 0.0223s/iter; left time: 385.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413607 Vali Loss: 0.0509441 Test Loss: 0.0551800\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404058\n",
      "\tspeed: 0.0397s/iter; left time: 681.0152s\n",
      "\titers: 200, epoch: 24 | loss: 0.0405565\n",
      "\tspeed: 0.0222s/iter; left time: 378.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0413338 Vali Loss: 0.0509188 Test Loss: 0.0551000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423914\n",
      "\tspeed: 0.0407s/iter; left time: 688.4196s\n",
      "\titers: 200, epoch: 25 | loss: 0.0413437\n",
      "\tspeed: 0.0197s/iter; left time: 330.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0412619 Vali Loss: 0.0509029 Test Loss: 0.0551642\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0389570\n",
      "\tspeed: 0.0380s/iter; left time: 634.0786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0388686\n",
      "\tspeed: 0.0176s/iter; left time: 292.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0412201 Vali Loss: 0.0509290 Test Loss: 0.0551733\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0415587\n",
      "\tspeed: 0.0369s/iter; left time: 607.7228s\n",
      "\titers: 200, epoch: 27 | loss: 0.0423500\n",
      "\tspeed: 0.0197s/iter; left time: 322.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0411406 Vali Loss: 0.0508458 Test Loss: 0.0550130\n",
      "Validation loss decreased (0.050899 --> 0.050846).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0435844\n",
      "\tspeed: 0.0411s/iter; left time: 668.6772s\n",
      "\titers: 200, epoch: 28 | loss: 0.0385247\n",
      "\tspeed: 0.0200s/iter; left time: 322.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0411405 Vali Loss: 0.0508347 Test Loss: 0.0550222\n",
      "Validation loss decreased (0.050846 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0420762\n",
      "\tspeed: 0.0368s/iter; left time: 589.5002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0388678\n",
      "\tspeed: 0.0175s/iter; left time: 278.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0411094 Vali Loss: 0.0508880 Test Loss: 0.0549905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0427229\n",
      "\tspeed: 0.0421s/iter; left time: 665.9101s\n",
      "\titers: 200, epoch: 30 | loss: 0.0388344\n",
      "\tspeed: 0.0202s/iter; left time: 317.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0410763 Vali Loss: 0.0508937 Test Loss: 0.0550308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0407782\n",
      "\tspeed: 0.0365s/iter; left time: 568.3944s\n",
      "\titers: 200, epoch: 31 | loss: 0.0419291\n",
      "\tspeed: 0.0195s/iter; left time: 302.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0410766 Vali Loss: 0.0506749 Test Loss: 0.0550058\n",
      "Validation loss decreased (0.050835 --> 0.050675).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0414399\n",
      "\tspeed: 0.0382s/iter; left time: 586.8291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421118\n",
      "\tspeed: 0.0199s/iter; left time: 303.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0410319 Vali Loss: 0.0507480 Test Loss: 0.0549598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0422271\n",
      "\tspeed: 0.0365s/iter; left time: 552.3449s\n",
      "\titers: 200, epoch: 33 | loss: 0.0414499\n",
      "\tspeed: 0.0175s/iter; left time: 263.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0409737 Vali Loss: 0.0507774 Test Loss: 0.0549851\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0413024\n",
      "\tspeed: 0.0361s/iter; left time: 538.2906s\n",
      "\titers: 200, epoch: 34 | loss: 0.0401151\n",
      "\tspeed: 0.0174s/iter; left time: 256.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0409406 Vali Loss: 0.0506703 Test Loss: 0.0549519\n",
      "Validation loss decreased (0.050675 --> 0.050670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0408263\n",
      "\tspeed: 0.0391s/iter; left time: 574.3639s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405118\n",
      "\tspeed: 0.0176s/iter; left time: 256.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0409528 Vali Loss: 0.0507586 Test Loss: 0.0549365\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0392115\n",
      "\tspeed: 0.0370s/iter; left time: 534.8904s\n",
      "\titers: 200, epoch: 36 | loss: 0.0404948\n",
      "\tspeed: 0.0175s/iter; left time: 251.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409394 Vali Loss: 0.0507388 Test Loss: 0.0549210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0423826\n",
      "\tspeed: 0.0361s/iter; left time: 513.9982s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399949\n",
      "\tspeed: 0.0187s/iter; left time: 264.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0409280 Vali Loss: 0.0507797 Test Loss: 0.0549513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0420419\n",
      "\tspeed: 0.0364s/iter; left time: 509.5619s\n",
      "\titers: 200, epoch: 38 | loss: 0.0414468\n",
      "\tspeed: 0.0180s/iter; left time: 250.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0408825 Vali Loss: 0.0506685 Test Loss: 0.0549180\n",
      "Validation loss decreased (0.050670 --> 0.050669).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0411821\n",
      "\tspeed: 0.0397s/iter; left time: 546.7866s\n",
      "\titers: 200, epoch: 39 | loss: 0.0366663\n",
      "\tspeed: 0.0173s/iter; left time: 236.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0409059 Vali Loss: 0.0507391 Test Loss: 0.0549399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0391978\n",
      "\tspeed: 0.0413s/iter; left time: 560.1932s\n",
      "\titers: 200, epoch: 40 | loss: 0.0425756\n",
      "\tspeed: 0.0195s/iter; left time: 263.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0409207 Vali Loss: 0.0506791 Test Loss: 0.0549067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416604\n",
      "\tspeed: 0.0367s/iter; left time: 489.4409s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402725\n",
      "\tspeed: 0.0173s/iter; left time: 228.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0408218 Vali Loss: 0.0507860 Test Loss: 0.0549271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0415616\n",
      "\tspeed: 0.0356s/iter; left time: 466.7670s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426821\n",
      "\tspeed: 0.0174s/iter; left time: 226.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0408661 Vali Loss: 0.0506999 Test Loss: 0.0549061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0412373\n",
      "\tspeed: 0.0362s/iter; left time: 466.9375s\n",
      "\titers: 200, epoch: 43 | loss: 0.0388965\n",
      "\tspeed: 0.0175s/iter; left time: 224.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408737 Vali Loss: 0.0507067 Test Loss: 0.0549184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0409356\n",
      "\tspeed: 0.0366s/iter; left time: 463.4980s\n",
      "\titers: 200, epoch: 44 | loss: 0.0419919\n",
      "\tspeed: 0.0175s/iter; left time: 220.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0407900 Vali Loss: 0.0507195 Test Loss: 0.0548893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0395876\n",
      "\tspeed: 0.0357s/iter; left time: 444.3419s\n",
      "\titers: 200, epoch: 45 | loss: 0.0424386\n",
      "\tspeed: 0.0176s/iter; left time: 217.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408467 Vali Loss: 0.0507040 Test Loss: 0.0548965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400761\n",
      "\tspeed: 0.0384s/iter; left time: 468.8836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0398946\n",
      "\tspeed: 0.0200s/iter; left time: 242.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0407960 Vali Loss: 0.0507497 Test Loss: 0.0548866\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393914\n",
      "\tspeed: 0.0370s/iter; left time: 443.4982s\n",
      "\titers: 200, epoch: 47 | loss: 0.0387283\n",
      "\tspeed: 0.0223s/iter; left time: 265.7545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408184 Vali Loss: 0.0507020 Test Loss: 0.0548986\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393765\n",
      "\tspeed: 0.0409s/iter; left time: 481.1759s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420225\n",
      "\tspeed: 0.0176s/iter; left time: 205.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0408080 Vali Loss: 0.0507258 Test Loss: 0.0548816\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010047451592981815, rmse:0.10023697465658188, mae:0.05491799861192703, rse:0.3867114782333374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0935595\n",
      "\tspeed: 0.0249s/iter; left time: 554.6922s\n",
      "\titers: 200, epoch: 1 | loss: 0.0815350\n",
      "\tspeed: 0.0238s/iter; left time: 529.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0985673 Vali Loss: 0.0815828 Test Loss: 0.0878835\n",
      "Validation loss decreased (inf --> 0.081583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0546182\n",
      "\tspeed: 0.0405s/iter; left time: 894.5638s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524375\n",
      "\tspeed: 0.0177s/iter; left time: 388.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0564773 Vali Loss: 0.0585265 Test Loss: 0.0620153\n",
      "Validation loss decreased (0.081583 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0516169\n",
      "\tspeed: 0.0405s/iter; left time: 883.9750s\n",
      "\titers: 200, epoch: 3 | loss: 0.0538712\n",
      "\tspeed: 0.0176s/iter; left time: 383.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0494922 Vali Loss: 0.0564595 Test Loss: 0.0600532\n",
      "Validation loss decreased (0.058526 --> 0.056460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0500758\n",
      "\tspeed: 0.0409s/iter; left time: 884.1769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0470287\n",
      "\tspeed: 0.0173s/iter; left time: 372.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0476510 Vali Loss: 0.0550841 Test Loss: 0.0591046\n",
      "Validation loss decreased (0.056460 --> 0.055084).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476657\n",
      "\tspeed: 0.0393s/iter; left time: 840.3386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0453900\n",
      "\tspeed: 0.0175s/iter; left time: 372.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0462703 Vali Loss: 0.0539240 Test Loss: 0.0578887\n",
      "Validation loss decreased (0.055084 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0436470\n",
      "\tspeed: 0.0385s/iter; left time: 815.6399s\n",
      "\titers: 200, epoch: 6 | loss: 0.0469544\n",
      "\tspeed: 0.0179s/iter; left time: 377.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0453504 Vali Loss: 0.0534992 Test Loss: 0.0576763\n",
      "Validation loss decreased (0.053924 --> 0.053499).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0498019\n",
      "\tspeed: 0.0372s/iter; left time: 780.1501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0435070\n",
      "\tspeed: 0.0173s/iter; left time: 361.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0447041 Vali Loss: 0.0528023 Test Loss: 0.0570895\n",
      "Validation loss decreased (0.053499 --> 0.052802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433632\n",
      "\tspeed: 0.0385s/iter; left time: 797.2715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472117\n",
      "\tspeed: 0.0184s/iter; left time: 380.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0442430 Vali Loss: 0.0525080 Test Loss: 0.0565417\n",
      "Validation loss decreased (0.052802 --> 0.052508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442935\n",
      "\tspeed: 0.0381s/iter; left time: 780.5073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439991\n",
      "\tspeed: 0.0181s/iter; left time: 369.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0437869 Vali Loss: 0.0521499 Test Loss: 0.0563267\n",
      "Validation loss decreased (0.052508 --> 0.052150).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457982\n",
      "\tspeed: 0.0375s/iter; left time: 761.0894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0451140\n",
      "\tspeed: 0.0175s/iter; left time: 354.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0434726 Vali Loss: 0.0523196 Test Loss: 0.0562200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0418626\n",
      "\tspeed: 0.0373s/iter; left time: 747.8968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0411332\n",
      "\tspeed: 0.0176s/iter; left time: 350.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0431422 Vali Loss: 0.0519555 Test Loss: 0.0562363\n",
      "Validation loss decreased (0.052150 --> 0.051955).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414568\n",
      "\tspeed: 0.0397s/iter; left time: 787.3697s\n",
      "\titers: 200, epoch: 12 | loss: 0.0442729\n",
      "\tspeed: 0.0185s/iter; left time: 365.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0429151 Vali Loss: 0.0517021 Test Loss: 0.0557212\n",
      "Validation loss decreased (0.051955 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0447191\n",
      "\tspeed: 0.0423s/iter; left time: 829.6593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0452590\n",
      "\tspeed: 0.0227s/iter; left time: 443.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0426312 Vali Loss: 0.0516790 Test Loss: 0.0557699\n",
      "Validation loss decreased (0.051702 --> 0.051679).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0460300\n",
      "\tspeed: 0.0378s/iter; left time: 732.2859s\n",
      "\titers: 200, epoch: 14 | loss: 0.0424465\n",
      "\tspeed: 0.0174s/iter; left time: 335.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0424535 Vali Loss: 0.0514955 Test Loss: 0.0555738\n",
      "Validation loss decreased (0.051679 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425895\n",
      "\tspeed: 0.0379s/iter; left time: 725.9930s\n",
      "\titers: 200, epoch: 15 | loss: 0.0400014\n",
      "\tspeed: 0.0199s/iter; left time: 379.4924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0422823 Vali Loss: 0.0517129 Test Loss: 0.0555978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0436068\n",
      "\tspeed: 0.0389s/iter; left time: 736.5599s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415642\n",
      "\tspeed: 0.0175s/iter; left time: 330.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0421010 Vali Loss: 0.0514501 Test Loss: 0.0553953\n",
      "Validation loss decreased (0.051495 --> 0.051450).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0403893\n",
      "\tspeed: 0.0378s/iter; left time: 707.0198s\n",
      "\titers: 200, epoch: 17 | loss: 0.0428705\n",
      "\tspeed: 0.0175s/iter; left time: 326.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0419437 Vali Loss: 0.0512283 Test Loss: 0.0553973\n",
      "Validation loss decreased (0.051450 --> 0.051228).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435594\n",
      "\tspeed: 0.0374s/iter; left time: 691.4029s\n",
      "\titers: 200, epoch: 18 | loss: 0.0430981\n",
      "\tspeed: 0.0176s/iter; left time: 323.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418711 Vali Loss: 0.0511208 Test Loss: 0.0552354\n",
      "Validation loss decreased (0.051228 --> 0.051121).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0425317\n",
      "\tspeed: 0.0388s/iter; left time: 708.5180s\n",
      "\titers: 200, epoch: 19 | loss: 0.0425620\n",
      "\tspeed: 0.0178s/iter; left time: 322.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0417220 Vali Loss: 0.0513766 Test Loss: 0.0552269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0389410\n",
      "\tspeed: 0.0386s/iter; left time: 696.3162s\n",
      "\titers: 200, epoch: 20 | loss: 0.0418354\n",
      "\tspeed: 0.0176s/iter; left time: 316.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0416325 Vali Loss: 0.0510026 Test Loss: 0.0550833\n",
      "Validation loss decreased (0.051121 --> 0.051003).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0438422\n",
      "\tspeed: 0.0370s/iter; left time: 659.7459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0418498\n",
      "\tspeed: 0.0176s/iter; left time: 311.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0415382 Vali Loss: 0.0509244 Test Loss: 0.0550689\n",
      "Validation loss decreased (0.051003 --> 0.050924).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414739\n",
      "\tspeed: 0.0399s/iter; left time: 701.7967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0414515\n",
      "\tspeed: 0.0176s/iter; left time: 307.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0414551 Vali Loss: 0.0509189 Test Loss: 0.0550239\n",
      "Validation loss decreased (0.050924 --> 0.050919).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412667\n",
      "\tspeed: 0.0418s/iter; left time: 726.3481s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385480\n",
      "\tspeed: 0.0183s/iter; left time: 316.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0414020 Vali Loss: 0.0509293 Test Loss: 0.0549526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404608\n",
      "\tspeed: 0.0433s/iter; left time: 742.8594s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383370\n",
      "\tspeed: 0.0182s/iter; left time: 310.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0413754 Vali Loss: 0.0509873 Test Loss: 0.0550544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0416779\n",
      "\tspeed: 0.0377s/iter; left time: 638.7238s\n",
      "\titers: 200, epoch: 25 | loss: 0.0415474\n",
      "\tspeed: 0.0176s/iter; left time: 295.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0412857 Vali Loss: 0.0509787 Test Loss: 0.0549485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0422339\n",
      "\tspeed: 0.0382s/iter; left time: 638.6748s\n",
      "\titers: 200, epoch: 26 | loss: 0.0430234\n",
      "\tspeed: 0.0173s/iter; left time: 287.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0412502 Vali Loss: 0.0510159 Test Loss: 0.0549871\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0391803\n",
      "\tspeed: 0.0425s/iter; left time: 699.8363s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413634\n",
      "\tspeed: 0.0215s/iter; left time: 351.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0412082 Vali Loss: 0.0509350 Test Loss: 0.0548990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0405897\n",
      "\tspeed: 0.0418s/iter; left time: 679.4927s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397338\n",
      "\tspeed: 0.0213s/iter; left time: 344.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0411314 Vali Loss: 0.0508925 Test Loss: 0.0549294\n",
      "Validation loss decreased (0.050919 --> 0.050893).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0437130\n",
      "\tspeed: 0.0387s/iter; left time: 619.6992s\n",
      "\titers: 200, epoch: 29 | loss: 0.0453305\n",
      "\tspeed: 0.0173s/iter; left time: 276.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0410808 Vali Loss: 0.0508684 Test Loss: 0.0549480\n",
      "Validation loss decreased (0.050893 --> 0.050868).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0404034\n",
      "\tspeed: 0.0374s/iter; left time: 591.2247s\n",
      "\titers: 200, epoch: 30 | loss: 0.0408411\n",
      "\tspeed: 0.0175s/iter; left time: 274.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0410524 Vali Loss: 0.0508277 Test Loss: 0.0548504\n",
      "Validation loss decreased (0.050868 --> 0.050828).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0427010\n",
      "\tspeed: 0.0380s/iter; left time: 592.4086s\n",
      "\titers: 200, epoch: 31 | loss: 0.0425292\n",
      "\tspeed: 0.0176s/iter; left time: 271.9788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0410449 Vali Loss: 0.0508885 Test Loss: 0.0548904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403372\n",
      "\tspeed: 0.0369s/iter; left time: 566.6934s\n",
      "\titers: 200, epoch: 32 | loss: 0.0405556\n",
      "\tspeed: 0.0175s/iter; left time: 266.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0410464 Vali Loss: 0.0508567 Test Loss: 0.0548694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0431220\n",
      "\tspeed: 0.0385s/iter; left time: 582.1933s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424416\n",
      "\tspeed: 0.0190s/iter; left time: 286.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0410148 Vali Loss: 0.0507454 Test Loss: 0.0548886\n",
      "Validation loss decreased (0.050828 --> 0.050745).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425253\n",
      "\tspeed: 0.0384s/iter; left time: 572.9638s\n",
      "\titers: 200, epoch: 34 | loss: 0.0445072\n",
      "\tspeed: 0.0176s/iter; left time: 260.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409694 Vali Loss: 0.0507921 Test Loss: 0.0548382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0386003\n",
      "\tspeed: 0.0386s/iter; left time: 567.2513s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397497\n",
      "\tspeed: 0.0178s/iter; left time: 259.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0409914 Vali Loss: 0.0507661 Test Loss: 0.0548480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0463726\n",
      "\tspeed: 0.0379s/iter; left time: 547.6972s\n",
      "\titers: 200, epoch: 36 | loss: 0.0397050\n",
      "\tspeed: 0.0176s/iter; left time: 252.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0409164 Vali Loss: 0.0508233 Test Loss: 0.0548441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0409133\n",
      "\tspeed: 0.0376s/iter; left time: 534.7156s\n",
      "\titers: 200, epoch: 37 | loss: 0.0423615\n",
      "\tspeed: 0.0175s/iter; left time: 247.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409337 Vali Loss: 0.0508035 Test Loss: 0.0548229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0406316\n",
      "\tspeed: 0.0387s/iter; left time: 542.5981s\n",
      "\titers: 200, epoch: 38 | loss: 0.0397512\n",
      "\tspeed: 0.0189s/iter; left time: 263.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0409042 Vali Loss: 0.0507964 Test Loss: 0.0548444\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0381033\n",
      "\tspeed: 0.0399s/iter; left time: 550.0490s\n",
      "\titers: 200, epoch: 39 | loss: 0.0382526\n",
      "\tspeed: 0.0173s/iter; left time: 236.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409219 Vali Loss: 0.0508203 Test Loss: 0.0548079\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0409601\n",
      "\tspeed: 0.0444s/iter; left time: 602.0461s\n",
      "\titers: 200, epoch: 40 | loss: 0.0414687\n",
      "\tspeed: 0.0204s/iter; left time: 274.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0408627 Vali Loss: 0.0507907 Test Loss: 0.0547983\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0436835\n",
      "\tspeed: 0.0442s/iter; left time: 590.2730s\n",
      "\titers: 200, epoch: 41 | loss: 0.0395844\n",
      "\tspeed: 0.0205s/iter; left time: 271.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0408995 Vali Loss: 0.0507025 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050745 --> 0.050702).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0397279\n",
      "\tspeed: 0.0438s/iter; left time: 574.0071s\n",
      "\titers: 200, epoch: 42 | loss: 0.0432200\n",
      "\tspeed: 0.0203s/iter; left time: 264.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408592 Vali Loss: 0.0507363 Test Loss: 0.0547963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0390139\n",
      "\tspeed: 0.0385s/iter; left time: 496.0208s\n",
      "\titers: 200, epoch: 43 | loss: 0.0416165\n",
      "\tspeed: 0.0176s/iter; left time: 225.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0409098 Vali Loss: 0.0507644 Test Loss: 0.0547888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0394929\n",
      "\tspeed: 0.0378s/iter; left time: 478.8054s\n",
      "\titers: 200, epoch: 44 | loss: 0.0391143\n",
      "\tspeed: 0.0177s/iter; left time: 222.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0408876 Vali Loss: 0.0507556 Test Loss: 0.0547861\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0385056\n",
      "\tspeed: 0.0373s/iter; left time: 463.8164s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418280\n",
      "\tspeed: 0.0176s/iter; left time: 216.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0408062 Vali Loss: 0.0506480 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050702 --> 0.050648).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0404662\n",
      "\tspeed: 0.0407s/iter; left time: 496.9452s\n",
      "\titers: 200, epoch: 46 | loss: 0.0425981\n",
      "\tspeed: 0.0212s/iter; left time: 257.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0408597 Vali Loss: 0.0507410 Test Loss: 0.0547948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0412951\n",
      "\tspeed: 0.0371s/iter; left time: 445.5673s\n",
      "\titers: 200, epoch: 47 | loss: 0.0460205\n",
      "\tspeed: 0.0176s/iter; left time: 209.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0408051 Vali Loss: 0.0507380 Test Loss: 0.0547790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0396187\n",
      "\tspeed: 0.0385s/iter; left time: 453.1386s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420261\n",
      "\tspeed: 0.0177s/iter; left time: 206.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0408679 Vali Loss: 0.0508199 Test Loss: 0.0547630\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0402250\n",
      "\tspeed: 0.0394s/iter; left time: 455.5809s\n",
      "\titers: 200, epoch: 49 | loss: 0.0436193\n",
      "\tspeed: 0.0194s/iter; left time: 222.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0408469 Vali Loss: 0.0507091 Test Loss: 0.0547697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0362207\n",
      "\tspeed: 0.0371s/iter; left time: 420.3064s\n",
      "\titers: 200, epoch: 50 | loss: 0.0385387\n",
      "\tspeed: 0.0175s/iter; left time: 196.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408548 Vali Loss: 0.0506502 Test Loss: 0.0547767\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440735\n",
      "\tspeed: 0.0385s/iter; left time: 427.6925s\n",
      "\titers: 200, epoch: 51 | loss: 0.0387501\n",
      "\tspeed: 0.0181s/iter; left time: 199.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0408112 Vali Loss: 0.0507077 Test Loss: 0.0547609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0404372\n",
      "\tspeed: 0.0432s/iter; left time: 470.1337s\n",
      "\titers: 200, epoch: 52 | loss: 0.0423694\n",
      "\tspeed: 0.0177s/iter; left time: 190.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408257 Vali Loss: 0.0507446 Test Loss: 0.0547665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0421164\n",
      "\tspeed: 0.0409s/iter; left time: 435.6301s\n",
      "\titers: 200, epoch: 53 | loss: 0.0415824\n",
      "\tspeed: 0.0186s/iter; left time: 196.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0408422 Vali Loss: 0.0507633 Test Loss: 0.0547696\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0443786\n",
      "\tspeed: 0.0368s/iter; left time: 383.9620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0391313\n",
      "\tspeed: 0.0175s/iter; left time: 181.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408320 Vali Loss: 0.0507100 Test Loss: 0.0547600\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0417649\n",
      "\tspeed: 0.0400s/iter; left time: 408.2279s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409617\n",
      "\tspeed: 0.0212s/iter; left time: 214.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408236 Vali Loss: 0.0506238 Test Loss: 0.0547631\n",
      "Validation loss decreased (0.050648 --> 0.050624).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0360162\n",
      "\tspeed: 0.0393s/iter; left time: 392.0179s\n",
      "\titers: 200, epoch: 56 | loss: 0.0408644\n",
      "\tspeed: 0.0177s/iter; left time: 174.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0407994 Vali Loss: 0.0507128 Test Loss: 0.0547610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0406955\n",
      "\tspeed: 0.0369s/iter; left time: 359.5597s\n",
      "\titers: 200, epoch: 57 | loss: 0.0420306\n",
      "\tspeed: 0.0176s/iter; left time: 170.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408128 Vali Loss: 0.0507455 Test Loss: 0.0547706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0457876\n",
      "\tspeed: 0.0364s/iter; left time: 346.5785s\n",
      "\titers: 200, epoch: 58 | loss: 0.0406639\n",
      "\tspeed: 0.0176s/iter; left time: 166.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0408230 Vali Loss: 0.0506479 Test Loss: 0.0547651\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0408023\n",
      "\tspeed: 0.0401s/iter; left time: 373.1203s\n",
      "\titers: 200, epoch: 59 | loss: 0.0427719\n",
      "\tspeed: 0.0178s/iter; left time: 163.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0407709 Vali Loss: 0.0507367 Test Loss: 0.0547671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0425067\n",
      "\tspeed: 0.0369s/iter; left time: 335.6411s\n",
      "\titers: 200, epoch: 60 | loss: 0.0396171\n",
      "\tspeed: 0.0190s/iter; left time: 170.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0408547 Vali Loss: 0.0507473 Test Loss: 0.0547641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0417092\n",
      "\tspeed: 0.0435s/iter; left time: 385.4814s\n",
      "\titers: 200, epoch: 61 | loss: 0.0407552\n",
      "\tspeed: 0.0225s/iter; left time: 196.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0408172 Vali Loss: 0.0507417 Test Loss: 0.0547586\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394446\n",
      "\tspeed: 0.0441s/iter; left time: 380.7387s\n",
      "\titers: 200, epoch: 62 | loss: 0.0394354\n",
      "\tspeed: 0.0205s/iter; left time: 174.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408144 Vali Loss: 0.0506968 Test Loss: 0.0547682\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0409796\n",
      "\tspeed: 0.0377s/iter; left time: 316.9350s\n",
      "\titers: 200, epoch: 63 | loss: 0.0429062\n",
      "\tspeed: 0.0180s/iter; left time: 149.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408127 Vali Loss: 0.0507607 Test Loss: 0.0547640\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0448329\n",
      "\tspeed: 0.0409s/iter; left time: 334.5994s\n",
      "\titers: 200, epoch: 64 | loss: 0.0424715\n",
      "\tspeed: 0.0195s/iter; left time: 157.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408103 Vali Loss: 0.0507010 Test Loss: 0.0547563\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0428965\n",
      "\tspeed: 0.0388s/iter; left time: 309.0573s\n",
      "\titers: 200, epoch: 65 | loss: 0.0406603\n",
      "\tspeed: 0.0200s/iter; left time: 156.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0407825 Vali Loss: 0.0506624 Test Loss: 0.0547556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009938369505107403, rmse:0.09969136863946915, mae:0.05476314201951027, rse:0.3846065402030945\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:01.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0980609\n",
      "\tspeed: 0.0442s/iter; left time: 986.0843s\n",
      "\titers: 200, epoch: 1 | loss: 0.0871001\n",
      "\tspeed: 0.0176s/iter; left time: 391.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1031007 Vali Loss: 0.0901211 Test Loss: 0.0987843\n",
      "Validation loss decreased (inf --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744202\n",
      "\tspeed: 0.0399s/iter; left time: 880.2678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0627046\n",
      "\tspeed: 0.0176s/iter; left time: 387.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0707878 Vali Loss: 0.0750685 Test Loss: 0.0840957\n",
      "Validation loss decreased (0.090121 --> 0.075069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646639\n",
      "\tspeed: 0.0380s/iter; left time: 829.7925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631343\n",
      "\tspeed: 0.0185s/iter; left time: 403.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0642391 Vali Loss: 0.0723593 Test Loss: 0.0822695\n",
      "Validation loss decreased (0.075069 --> 0.072359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610678\n",
      "\tspeed: 0.0388s/iter; left time: 838.9979s\n",
      "\titers: 200, epoch: 4 | loss: 0.0642769\n",
      "\tspeed: 0.0196s/iter; left time: 421.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0623806 Vali Loss: 0.0713594 Test Loss: 0.0812874\n",
      "Validation loss decreased (0.072359 --> 0.071359).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621786\n",
      "\tspeed: 0.0390s/iter; left time: 835.2215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588774\n",
      "\tspeed: 0.0199s/iter; left time: 424.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0612256 Vali Loss: 0.0713809 Test Loss: 0.0812414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647122\n",
      "\tspeed: 0.0367s/iter; left time: 776.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587326\n",
      "\tspeed: 0.0176s/iter; left time: 371.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0604238 Vali Loss: 0.0708679 Test Loss: 0.0803343\n",
      "Validation loss decreased (0.071359 --> 0.070868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0619604\n",
      "\tspeed: 0.0379s/iter; left time: 793.8591s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573329\n",
      "\tspeed: 0.0176s/iter; left time: 367.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0597714 Vali Loss: 0.0706334 Test Loss: 0.0803544\n",
      "Validation loss decreased (0.070868 --> 0.070633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0618974\n",
      "\tspeed: 0.0390s/iter; left time: 809.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577334\n",
      "\tspeed: 0.0230s/iter; left time: 475.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0593515 Vali Loss: 0.0705784 Test Loss: 0.0799828\n",
      "Validation loss decreased (0.070633 --> 0.070578).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578773\n",
      "\tspeed: 0.0423s/iter; left time: 866.8690s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587067\n",
      "\tspeed: 0.0201s/iter; left time: 411.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0589615 Vali Loss: 0.0703924 Test Loss: 0.0804243\n",
      "Validation loss decreased (0.070578 --> 0.070392).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590116\n",
      "\tspeed: 0.0401s/iter; left time: 813.8909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0577656\n",
      "\tspeed: 0.0204s/iter; left time: 410.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0585875 Vali Loss: 0.0701964 Test Loss: 0.0800692\n",
      "Validation loss decreased (0.070392 --> 0.070196).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595273\n",
      "\tspeed: 0.0388s/iter; left time: 777.9013s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568395\n",
      "\tspeed: 0.0190s/iter; left time: 379.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0582978 Vali Loss: 0.0700665 Test Loss: 0.0801848\n",
      "Validation loss decreased (0.070196 --> 0.070066).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0578398\n",
      "\tspeed: 0.0400s/iter; left time: 792.9082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565718\n",
      "\tspeed: 0.0179s/iter; left time: 352.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0580421 Vali Loss: 0.0702680 Test Loss: 0.0803339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582126\n",
      "\tspeed: 0.0399s/iter; left time: 783.3161s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575784\n",
      "\tspeed: 0.0212s/iter; left time: 414.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0577998 Vali Loss: 0.0704259 Test Loss: 0.0806946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0567649\n",
      "\tspeed: 0.0372s/iter; left time: 721.7618s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573596\n",
      "\tspeed: 0.0178s/iter; left time: 342.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0575422 Vali Loss: 0.0701961 Test Loss: 0.0797991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537720\n",
      "\tspeed: 0.0373s/iter; left time: 714.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.0601896\n",
      "\tspeed: 0.0177s/iter; left time: 338.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0573678 Vali Loss: 0.0700427 Test Loss: 0.0800929\n",
      "Validation loss decreased (0.070066 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578917\n",
      "\tspeed: 0.0399s/iter; left time: 756.3327s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594120\n",
      "\tspeed: 0.0189s/iter; left time: 355.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0571036 Vali Loss: 0.0701092 Test Loss: 0.0802814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0561508\n",
      "\tspeed: 0.0362s/iter; left time: 677.5379s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588087\n",
      "\tspeed: 0.0178s/iter; left time: 330.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0697514 Test Loss: 0.0801798\n",
      "Validation loss decreased (0.070043 --> 0.069751).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570127\n",
      "\tspeed: 0.0401s/iter; left time: 741.0149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0550547\n",
      "\tspeed: 0.0204s/iter; left time: 374.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0568377 Vali Loss: 0.0700514 Test Loss: 0.0800432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0599390\n",
      "\tspeed: 0.0424s/iter; left time: 773.9867s\n",
      "\titers: 200, epoch: 19 | loss: 0.0592506\n",
      "\tspeed: 0.0201s/iter; left time: 365.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0566340 Vali Loss: 0.0700143 Test Loss: 0.0800947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0555497\n",
      "\tspeed: 0.0402s/iter; left time: 725.6980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594845\n",
      "\tspeed: 0.0177s/iter; left time: 317.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0565479 Vali Loss: 0.0699431 Test Loss: 0.0799722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0595895\n",
      "\tspeed: 0.0426s/iter; left time: 758.6109s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514547\n",
      "\tspeed: 0.0180s/iter; left time: 319.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0564134 Vali Loss: 0.0699077 Test Loss: 0.0799024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0577438\n",
      "\tspeed: 0.0406s/iter; left time: 713.9933s\n",
      "\titers: 200, epoch: 22 | loss: 0.0570781\n",
      "\tspeed: 0.0180s/iter; left time: 315.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0562344 Vali Loss: 0.0699412 Test Loss: 0.0799161\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543055\n",
      "\tspeed: 0.0374s/iter; left time: 650.0469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0568372\n",
      "\tspeed: 0.0178s/iter; left time: 307.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0561991 Vali Loss: 0.0698163 Test Loss: 0.0800117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0562022\n",
      "\tspeed: 0.0401s/iter; left time: 687.3905s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531656\n",
      "\tspeed: 0.0196s/iter; left time: 334.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560687 Vali Loss: 0.0699291 Test Loss: 0.0799469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552870\n",
      "\tspeed: 0.0384s/iter; left time: 650.0462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552926\n",
      "\tspeed: 0.0192s/iter; left time: 322.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0560483 Vali Loss: 0.0698628 Test Loss: 0.0803341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0539591\n",
      "\tspeed: 0.0398s/iter; left time: 663.8899s\n",
      "\titers: 200, epoch: 26 | loss: 0.0611918\n",
      "\tspeed: 0.0195s/iter; left time: 323.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0559247 Vali Loss: 0.0697493 Test Loss: 0.0802485\n",
      "Validation loss decreased (0.069751 --> 0.069749).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0552940\n",
      "\tspeed: 0.0390s/iter; left time: 643.2036s\n",
      "\titers: 200, epoch: 27 | loss: 0.0568207\n",
      "\tspeed: 0.0177s/iter; left time: 290.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0558538 Vali Loss: 0.0698645 Test Loss: 0.0802962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553827\n",
      "\tspeed: 0.0366s/iter; left time: 595.1012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0563543\n",
      "\tspeed: 0.0176s/iter; left time: 283.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0558139 Vali Loss: 0.0699737 Test Loss: 0.0799117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0549611\n",
      "\tspeed: 0.0382s/iter; left time: 612.8983s\n",
      "\titers: 200, epoch: 29 | loss: 0.0588496\n",
      "\tspeed: 0.0220s/iter; left time: 350.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0557804 Vali Loss: 0.0698076 Test Loss: 0.0803077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0569736\n",
      "\tspeed: 0.0406s/iter; left time: 642.2532s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523944\n",
      "\tspeed: 0.0191s/iter; left time: 300.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0556698 Vali Loss: 0.0699552 Test Loss: 0.0799103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0591903\n",
      "\tspeed: 0.0438s/iter; left time: 682.9421s\n",
      "\titers: 200, epoch: 31 | loss: 0.0563744\n",
      "\tspeed: 0.0195s/iter; left time: 302.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0557028 Vali Loss: 0.0698280 Test Loss: 0.0799427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0564075\n",
      "\tspeed: 0.0367s/iter; left time: 563.8824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564259\n",
      "\tspeed: 0.0178s/iter; left time: 271.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0556475 Vali Loss: 0.0699557 Test Loss: 0.0800001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0571123\n",
      "\tspeed: 0.0371s/iter; left time: 561.7987s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562876\n",
      "\tspeed: 0.0178s/iter; left time: 267.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0555754 Vali Loss: 0.0698408 Test Loss: 0.0799727\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0549147\n",
      "\tspeed: 0.0368s/iter; left time: 549.0334s\n",
      "\titers: 200, epoch: 34 | loss: 0.0569688\n",
      "\tspeed: 0.0176s/iter; left time: 260.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0555628 Vali Loss: 0.0698081 Test Loss: 0.0801774\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539672\n",
      "\tspeed: 0.0394s/iter; left time: 577.9793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0568721\n",
      "\tspeed: 0.0178s/iter; left time: 259.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0555678 Vali Loss: 0.0698511 Test Loss: 0.0800220\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0555374\n",
      "\tspeed: 0.0413s/iter; left time: 596.6173s\n",
      "\titers: 200, epoch: 36 | loss: 0.0540787\n",
      "\tspeed: 0.0202s/iter; left time: 289.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0554807 Vali Loss: 0.0698264 Test Loss: 0.0801089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019129442051053047, rmse:0.13830922544002533, mae:0.08024851232767105, rse:0.5350168347358704\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0993653\n",
      "\tspeed: 0.0221s/iter; left time: 493.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925130\n",
      "\tspeed: 0.0200s/iter; left time: 443.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1028261 Vali Loss: 0.0896393 Test Loss: 0.0984749\n",
      "Validation loss decreased (inf --> 0.089639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0716707\n",
      "\tspeed: 0.0402s/iter; left time: 888.0405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649474\n",
      "\tspeed: 0.0206s/iter; left time: 452.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0706721 Vali Loss: 0.0753703 Test Loss: 0.0839644\n",
      "Validation loss decreased (0.089639 --> 0.075370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619266\n",
      "\tspeed: 0.0440s/iter; left time: 960.5970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0610446\n",
      "\tspeed: 0.0202s/iter; left time: 438.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0645758 Vali Loss: 0.0726078 Test Loss: 0.0825484\n",
      "Validation loss decreased (0.075370 --> 0.072608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586112\n",
      "\tspeed: 0.0396s/iter; left time: 856.5662s\n",
      "\titers: 200, epoch: 4 | loss: 0.0566655\n",
      "\tspeed: 0.0199s/iter; left time: 429.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0626355 Vali Loss: 0.0717694 Test Loss: 0.0815929\n",
      "Validation loss decreased (0.072608 --> 0.071769).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629928\n",
      "\tspeed: 0.0434s/iter; left time: 928.5031s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631500\n",
      "\tspeed: 0.0198s/iter; left time: 421.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0614584 Vali Loss: 0.0710907 Test Loss: 0.0806131\n",
      "Validation loss decreased (0.071769 --> 0.071091).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608282\n",
      "\tspeed: 0.0438s/iter; left time: 928.3181s\n",
      "\titers: 200, epoch: 6 | loss: 0.0621219\n",
      "\tspeed: 0.0202s/iter; left time: 425.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0605699 Vali Loss: 0.0708390 Test Loss: 0.0803163\n",
      "Validation loss decreased (0.071091 --> 0.070839).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0545628\n",
      "\tspeed: 0.0392s/iter; left time: 820.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0180s/iter; left time: 375.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0599846 Vali Loss: 0.0707349 Test Loss: 0.0810065\n",
      "Validation loss decreased (0.070839 --> 0.070735).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596696\n",
      "\tspeed: 0.0429s/iter; left time: 889.9808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551469\n",
      "\tspeed: 0.0199s/iter; left time: 409.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0594251 Vali Loss: 0.0704187 Test Loss: 0.0808286\n",
      "Validation loss decreased (0.070735 --> 0.070419).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0601396\n",
      "\tspeed: 0.0434s/iter; left time: 889.6753s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632646\n",
      "\tspeed: 0.0244s/iter; left time: 497.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0589964 Vali Loss: 0.0704514 Test Loss: 0.0805737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0605195\n",
      "\tspeed: 0.0416s/iter; left time: 844.5786s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591787\n",
      "\tspeed: 0.0232s/iter; left time: 467.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0585768 Vali Loss: 0.0702656 Test Loss: 0.0809564\n",
      "Validation loss decreased (0.070419 --> 0.070266).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585001\n",
      "\tspeed: 0.0410s/iter; left time: 822.7208s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562668\n",
      "\tspeed: 0.0186s/iter; left time: 371.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0582614 Vali Loss: 0.0702181 Test Loss: 0.0812004\n",
      "Validation loss decreased (0.070266 --> 0.070218).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0563077\n",
      "\tspeed: 0.0414s/iter; left time: 821.1961s\n",
      "\titers: 200, epoch: 12 | loss: 0.0616315\n",
      "\tspeed: 0.0200s/iter; left time: 395.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0579842 Vali Loss: 0.0700841 Test Loss: 0.0812889\n",
      "Validation loss decreased (0.070218 --> 0.070084).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0610500\n",
      "\tspeed: 0.0430s/iter; left time: 843.5268s\n",
      "\titers: 200, epoch: 13 | loss: 0.0572273\n",
      "\tspeed: 0.0196s/iter; left time: 381.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0576614 Vali Loss: 0.0702207 Test Loss: 0.0815973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575464\n",
      "\tspeed: 0.0443s/iter; left time: 859.2950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597506\n",
      "\tspeed: 0.0186s/iter; left time: 359.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0574103 Vali Loss: 0.0701746 Test Loss: 0.0815515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0539393\n",
      "\tspeed: 0.0410s/iter; left time: 785.1048s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575244\n",
      "\tspeed: 0.0180s/iter; left time: 343.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0571507 Vali Loss: 0.0700377 Test Loss: 0.0809218\n",
      "Validation loss decreased (0.070084 --> 0.070038).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0552823\n",
      "\tspeed: 0.0431s/iter; left time: 816.5003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567672\n",
      "\tspeed: 0.0242s/iter; left time: 456.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0569635 Vali Loss: 0.0699133 Test Loss: 0.0814106\n",
      "Validation loss decreased (0.070038 --> 0.069913).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533414\n",
      "\tspeed: 0.0426s/iter; left time: 796.9191s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565612\n",
      "\tspeed: 0.0203s/iter; left time: 377.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0567306 Vali Loss: 0.0700455 Test Loss: 0.0815984\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608345\n",
      "\tspeed: 0.0403s/iter; left time: 745.6117s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592519\n",
      "\tspeed: 0.0183s/iter; left time: 335.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0566090 Vali Loss: 0.0699562 Test Loss: 0.0814214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0590397\n",
      "\tspeed: 0.0403s/iter; left time: 735.9679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541783\n",
      "\tspeed: 0.0202s/iter; left time: 367.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0564276 Vali Loss: 0.0701004 Test Loss: 0.0813950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572432\n",
      "\tspeed: 0.0412s/iter; left time: 742.9460s\n",
      "\titers: 200, epoch: 20 | loss: 0.0551385\n",
      "\tspeed: 0.0200s/iter; left time: 358.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0562702 Vali Loss: 0.0701160 Test Loss: 0.0818849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536732\n",
      "\tspeed: 0.0392s/iter; left time: 698.7143s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556528\n",
      "\tspeed: 0.0213s/iter; left time: 378.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0561357 Vali Loss: 0.0701280 Test Loss: 0.0817430\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0569166\n",
      "\tspeed: 0.0418s/iter; left time: 734.7146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534606\n",
      "\tspeed: 0.0236s/iter; left time: 413.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0559808 Vali Loss: 0.0702114 Test Loss: 0.0819262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0560534\n",
      "\tspeed: 0.0420s/iter; left time: 729.4056s\n",
      "\titers: 200, epoch: 23 | loss: 0.0574485\n",
      "\tspeed: 0.0224s/iter; left time: 386.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0559322 Vali Loss: 0.0700866 Test Loss: 0.0819694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0585243\n",
      "\tspeed: 0.0422s/iter; left time: 724.4744s\n",
      "\titers: 200, epoch: 24 | loss: 0.0549269\n",
      "\tspeed: 0.0235s/iter; left time: 400.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0557595 Vali Loss: 0.0701298 Test Loss: 0.0818227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0532516\n",
      "\tspeed: 0.0463s/iter; left time: 783.6475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0586018\n",
      "\tspeed: 0.0249s/iter; left time: 419.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0557496 Vali Loss: 0.0702347 Test Loss: 0.0820146\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552508\n",
      "\tspeed: 0.0463s/iter; left time: 772.7935s\n",
      "\titers: 200, epoch: 26 | loss: 0.0518143\n",
      "\tspeed: 0.0206s/iter; left time: 342.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0555888 Vali Loss: 0.0702477 Test Loss: 0.0821850\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019507648423314095, rmse:0.13966979086399078, mae:0.08141053467988968, rse:0.5402798652648926\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:24.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1048215\n",
      "\tspeed: 0.0448s/iter; left time: 993.6942s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905720\n",
      "\tspeed: 0.0178s/iter; left time: 393.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.1048050 Vali Loss: 0.0926501 Test Loss: 0.1004419\n",
      "Validation loss decreased (inf --> 0.092650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0787801\n",
      "\tspeed: 0.0392s/iter; left time: 860.8228s\n",
      "\titers: 200, epoch: 2 | loss: 0.0704006\n",
      "\tspeed: 0.0178s/iter; left time: 390.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0745573 Vali Loss: 0.0786099 Test Loss: 0.0878751\n",
      "Validation loss decreased (0.092650 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726460\n",
      "\tspeed: 0.0391s/iter; left time: 849.8043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645619\n",
      "\tspeed: 0.0178s/iter; left time: 386.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0679619 Vali Loss: 0.0757840 Test Loss: 0.0871083\n",
      "Validation loss decreased (0.078610 --> 0.075784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659405\n",
      "\tspeed: 0.0392s/iter; left time: 844.1832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0691877\n",
      "\tspeed: 0.0180s/iter; left time: 385.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0661932 Vali Loss: 0.0753940 Test Loss: 0.0867535\n",
      "Validation loss decreased (0.075784 --> 0.075394).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0673685\n",
      "\tspeed: 0.0386s/iter; left time: 823.0725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653306\n",
      "\tspeed: 0.0184s/iter; left time: 390.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0651771 Vali Loss: 0.0749387 Test Loss: 0.0866767\n",
      "Validation loss decreased (0.075394 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0621401\n",
      "\tspeed: 0.0391s/iter; left time: 825.2142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653071\n",
      "\tspeed: 0.0183s/iter; left time: 385.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0644035 Vali Loss: 0.0745415 Test Loss: 0.0861986\n",
      "Validation loss decreased (0.074939 --> 0.074541).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0668753\n",
      "\tspeed: 0.0396s/iter; left time: 826.2922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647811\n",
      "\tspeed: 0.0181s/iter; left time: 376.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0638201 Vali Loss: 0.0746210 Test Loss: 0.0858707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0590196\n",
      "\tspeed: 0.0405s/iter; left time: 835.0479s\n",
      "\titers: 200, epoch: 8 | loss: 0.0675284\n",
      "\tspeed: 0.0182s/iter; left time: 374.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0633939 Vali Loss: 0.0744509 Test Loss: 0.0864062\n",
      "Validation loss decreased (0.074541 --> 0.074451).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666170\n",
      "\tspeed: 0.0394s/iter; left time: 805.2458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584317\n",
      "\tspeed: 0.0178s/iter; left time: 360.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0629750 Vali Loss: 0.0741344 Test Loss: 0.0858306\n",
      "Validation loss decreased (0.074451 --> 0.074134).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615673\n",
      "\tspeed: 0.0384s/iter; left time: 775.9894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0612158\n",
      "\tspeed: 0.0178s/iter; left time: 357.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0626131 Vali Loss: 0.0743963 Test Loss: 0.0868935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669771\n",
      "\tspeed: 0.0389s/iter; left time: 776.3254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0583333\n",
      "\tspeed: 0.0182s/iter; left time: 360.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0622680 Vali Loss: 0.0740912 Test Loss: 0.0864191\n",
      "Validation loss decreased (0.074134 --> 0.074091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0600857\n",
      "\tspeed: 0.0398s/iter; left time: 785.8133s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624289\n",
      "\tspeed: 0.0182s/iter; left time: 357.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0620072 Vali Loss: 0.0738088 Test Loss: 0.0868813\n",
      "Validation loss decreased (0.074091 --> 0.073809).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0633508\n",
      "\tspeed: 0.0382s/iter; left time: 746.2036s\n",
      "\titers: 200, epoch: 13 | loss: 0.0622426\n",
      "\tspeed: 0.0177s/iter; left time: 344.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0617034 Vali Loss: 0.0738194 Test Loss: 0.0859601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0624652\n",
      "\tspeed: 0.0432s/iter; left time: 833.1308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0640134\n",
      "\tspeed: 0.0223s/iter; left time: 428.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0614224 Vali Loss: 0.0735637 Test Loss: 0.0866766\n",
      "Validation loss decreased (0.073809 --> 0.073564).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0592811\n",
      "\tspeed: 0.0412s/iter; left time: 786.3647s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659775\n",
      "\tspeed: 0.0198s/iter; left time: 375.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0612476 Vali Loss: 0.0735167 Test Loss: 0.0868006\n",
      "Validation loss decreased (0.073564 --> 0.073517).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0644561\n",
      "\tspeed: 0.0412s/iter; left time: 777.3279s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619274\n",
      "\tspeed: 0.0179s/iter; left time: 336.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0610197 Vali Loss: 0.0734734 Test Loss: 0.0862646\n",
      "Validation loss decreased (0.073517 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604587\n",
      "\tspeed: 0.0385s/iter; left time: 717.5171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619207\n",
      "\tspeed: 0.0182s/iter; left time: 337.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0608512 Vali Loss: 0.0734382 Test Loss: 0.0864064\n",
      "Validation loss decreased (0.073473 --> 0.073438).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621410\n",
      "\tspeed: 0.0444s/iter; left time: 816.7679s\n",
      "\titers: 200, epoch: 18 | loss: 0.0610293\n",
      "\tspeed: 0.0209s/iter; left time: 382.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0606406 Vali Loss: 0.0735055 Test Loss: 0.0865836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0594858\n",
      "\tspeed: 0.0395s/iter; left time: 717.9466s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603400\n",
      "\tspeed: 0.0225s/iter; left time: 407.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0604943 Vali Loss: 0.0733934 Test Loss: 0.0866218\n",
      "Validation loss decreased (0.073438 --> 0.073393).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621189\n",
      "\tspeed: 0.0405s/iter; left time: 726.9494s\n",
      "\titers: 200, epoch: 20 | loss: 0.0579614\n",
      "\tspeed: 0.0179s/iter; left time: 320.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0603450 Vali Loss: 0.0734274 Test Loss: 0.0866431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0576071\n",
      "\tspeed: 0.0397s/iter; left time: 705.1230s\n",
      "\titers: 200, epoch: 21 | loss: 0.0587716\n",
      "\tspeed: 0.0182s/iter; left time: 320.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0602134 Vali Loss: 0.0735609 Test Loss: 0.0867124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0592390\n",
      "\tspeed: 0.0411s/iter; left time: 719.6329s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672747\n",
      "\tspeed: 0.0205s/iter; left time: 357.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0601358 Vali Loss: 0.0734848 Test Loss: 0.0864877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0589457\n",
      "\tspeed: 0.0420s/iter; left time: 727.1040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600802\n",
      "\tspeed: 0.0195s/iter; left time: 334.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0600169 Vali Loss: 0.0735971 Test Loss: 0.0867336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0622105\n",
      "\tspeed: 0.0390s/iter; left time: 665.8311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0587972\n",
      "\tspeed: 0.0185s/iter; left time: 314.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0599399 Vali Loss: 0.0733272 Test Loss: 0.0868346\n",
      "Validation loss decreased (0.073393 --> 0.073327).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0618487\n",
      "\tspeed: 0.0408s/iter; left time: 686.9191s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623286\n",
      "\tspeed: 0.0199s/iter; left time: 332.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0598832 Vali Loss: 0.0733698 Test Loss: 0.0870481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628185\n",
      "\tspeed: 0.0403s/iter; left time: 669.1997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600777\n",
      "\tspeed: 0.0178s/iter; left time: 294.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0597476 Vali Loss: 0.0735480 Test Loss: 0.0870731\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584035\n",
      "\tspeed: 0.0386s/iter; left time: 633.3759s\n",
      "\titers: 200, epoch: 27 | loss: 0.0596758\n",
      "\tspeed: 0.0178s/iter; left time: 290.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0597152 Vali Loss: 0.0735673 Test Loss: 0.0869513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0575937\n",
      "\tspeed: 0.0411s/iter; left time: 664.7704s\n",
      "\titers: 200, epoch: 28 | loss: 0.0598191\n",
      "\tspeed: 0.0194s/iter; left time: 311.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0596151 Vali Loss: 0.0735890 Test Loss: 0.0869191\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602850\n",
      "\tspeed: 0.0385s/iter; left time: 614.2782s\n",
      "\titers: 200, epoch: 29 | loss: 0.0603580\n",
      "\tspeed: 0.0199s/iter; left time: 315.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0595701 Vali Loss: 0.0735271 Test Loss: 0.0868389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0609483\n",
      "\tspeed: 0.0398s/iter; left time: 625.4291s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605431\n",
      "\tspeed: 0.0178s/iter; left time: 277.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0595073 Vali Loss: 0.0735774 Test Loss: 0.0868500\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565855\n",
      "\tspeed: 0.0380s/iter; left time: 588.8619s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568368\n",
      "\tspeed: 0.0178s/iter; left time: 273.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0594662 Vali Loss: 0.0736190 Test Loss: 0.0867959\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585387\n",
      "\tspeed: 0.0384s/iter; left time: 586.9124s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621870\n",
      "\tspeed: 0.0179s/iter; left time: 271.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0594207 Vali Loss: 0.0734954 Test Loss: 0.0867695\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0560987\n",
      "\tspeed: 0.0403s/iter; left time: 607.2936s\n",
      "\titers: 200, epoch: 33 | loss: 0.0594956\n",
      "\tspeed: 0.0179s/iter; left time: 267.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0594061 Vali Loss: 0.0736040 Test Loss: 0.0867877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592257\n",
      "\tspeed: 0.0398s/iter; left time: 590.9892s\n",
      "\titers: 200, epoch: 34 | loss: 0.0612799\n",
      "\tspeed: 0.0178s/iter; left time: 262.3133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0593490 Vali Loss: 0.0734889 Test Loss: 0.0869637\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021609371528029442, rmse:0.1470012664794922, mae:0.08683455735445023, rse:0.5693498253822327\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1029223\n",
      "\tspeed: 0.0243s/iter; left time: 539.9811s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873014\n",
      "\tspeed: 0.0203s/iter; left time: 449.2947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.1060672 Vali Loss: 0.0924755 Test Loss: 0.1004355\n",
      "Validation loss decreased (inf --> 0.092476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753753\n",
      "\tspeed: 0.0444s/iter; left time: 975.9962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723152\n",
      "\tspeed: 0.0240s/iter; left time: 525.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0746971 Vali Loss: 0.0789733 Test Loss: 0.0883853\n",
      "Validation loss decreased (0.092476 --> 0.078973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749349\n",
      "\tspeed: 0.0390s/iter; left time: 849.2280s\n",
      "\titers: 200, epoch: 3 | loss: 0.0635487\n",
      "\tspeed: 0.0181s/iter; left time: 391.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0682782 Vali Loss: 0.0764451 Test Loss: 0.0874010\n",
      "Validation loss decreased (0.078973 --> 0.076445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650547\n",
      "\tspeed: 0.0431s/iter; left time: 927.6328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0675071\n",
      "\tspeed: 0.0189s/iter; left time: 404.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0665174 Vali Loss: 0.0751456 Test Loss: 0.0865133\n",
      "Validation loss decreased (0.076445 --> 0.075146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633389\n",
      "\tspeed: 0.0399s/iter; left time: 850.2645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628508\n",
      "\tspeed: 0.0180s/iter; left time: 380.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0653938 Vali Loss: 0.0750249 Test Loss: 0.0866540\n",
      "Validation loss decreased (0.075146 --> 0.075025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610570\n",
      "\tspeed: 0.0435s/iter; left time: 916.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0691948\n",
      "\tspeed: 0.0227s/iter; left time: 476.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0645714 Vali Loss: 0.0748224 Test Loss: 0.0866774\n",
      "Validation loss decreased (0.075025 --> 0.074822).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0635364\n",
      "\tspeed: 0.0438s/iter; left time: 913.4307s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676383\n",
      "\tspeed: 0.0196s/iter; left time: 405.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0640450 Vali Loss: 0.0747084 Test Loss: 0.0860682\n",
      "Validation loss decreased (0.074822 --> 0.074708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0642655\n",
      "\tspeed: 0.0433s/iter; left time: 894.1643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633054\n",
      "\tspeed: 0.0209s/iter; left time: 430.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0635069 Vali Loss: 0.0743306 Test Loss: 0.0875940\n",
      "Validation loss decreased (0.074708 --> 0.074331).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672177\n",
      "\tspeed: 0.0429s/iter; left time: 874.8904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657890\n",
      "\tspeed: 0.0209s/iter; left time: 424.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0630452 Vali Loss: 0.0741678 Test Loss: 0.0868630\n",
      "Validation loss decreased (0.074331 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632034\n",
      "\tspeed: 0.0434s/iter; left time: 876.3151s\n",
      "\titers: 200, epoch: 10 | loss: 0.0645544\n",
      "\tspeed: 0.0202s/iter; left time: 404.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0627409 Vali Loss: 0.0743513 Test Loss: 0.0880571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0636334\n",
      "\tspeed: 0.0404s/iter; left time: 806.8377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602807\n",
      "\tspeed: 0.0178s/iter; left time: 353.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0623453 Vali Loss: 0.0742074 Test Loss: 0.0878647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583318\n",
      "\tspeed: 0.0410s/iter; left time: 808.9365s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650040\n",
      "\tspeed: 0.0179s/iter; left time: 352.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0620972 Vali Loss: 0.0737038 Test Loss: 0.0867297\n",
      "Validation loss decreased (0.074168 --> 0.073704).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0613920\n",
      "\tspeed: 0.0414s/iter; left time: 808.6399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0611318\n",
      "\tspeed: 0.0182s/iter; left time: 353.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0618523 Vali Loss: 0.0738235 Test Loss: 0.0875536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0610238\n",
      "\tspeed: 0.0386s/iter; left time: 744.5537s\n",
      "\titers: 200, epoch: 14 | loss: 0.0601860\n",
      "\tspeed: 0.0179s/iter; left time: 343.8556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0615380 Vali Loss: 0.0738372 Test Loss: 0.0877525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598381\n",
      "\tspeed: 0.0387s/iter; left time: 738.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0587940\n",
      "\tspeed: 0.0178s/iter; left time: 338.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0612895 Vali Loss: 0.0739167 Test Loss: 0.0872995\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566209\n",
      "\tspeed: 0.0421s/iter; left time: 794.7425s\n",
      "\titers: 200, epoch: 16 | loss: 0.0571298\n",
      "\tspeed: 0.0183s/iter; left time: 343.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0611391 Vali Loss: 0.0740395 Test Loss: 0.0877071\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624488\n",
      "\tspeed: 0.0436s/iter; left time: 813.1598s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577584\n",
      "\tspeed: 0.0198s/iter; left time: 367.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0609111 Vali Loss: 0.0737153 Test Loss: 0.0876156\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0645408\n",
      "\tspeed: 0.0412s/iter; left time: 758.7901s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614708\n",
      "\tspeed: 0.0182s/iter; left time: 332.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0607212 Vali Loss: 0.0740565 Test Loss: 0.0879836\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0585145\n",
      "\tspeed: 0.0441s/iter; left time: 802.3411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603509\n",
      "\tspeed: 0.0209s/iter; left time: 378.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0606192 Vali Loss: 0.0737144 Test Loss: 0.0875244\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0605584\n",
      "\tspeed: 0.0389s/iter; left time: 698.6056s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584688\n",
      "\tspeed: 0.0180s/iter; left time: 321.6657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0604933 Vali Loss: 0.0737341 Test Loss: 0.0881607\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0649967\n",
      "\tspeed: 0.0399s/iter; left time: 707.6438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591727\n",
      "\tspeed: 0.0178s/iter; left time: 314.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0603355 Vali Loss: 0.0738130 Test Loss: 0.0877827\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593023\n",
      "\tspeed: 0.0445s/iter; left time: 779.7140s\n",
      "\titers: 200, epoch: 22 | loss: 0.0619041\n",
      "\tspeed: 0.0183s/iter; left time: 319.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0601923 Vali Loss: 0.0737966 Test Loss: 0.0876334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021043021231889725, rmse:0.1450621336698532, mae:0.08672972023487091, rse:0.5618393421173096\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:46.06s\n",
      "Intermediate time for FR: 00h:23m:12.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1379552\n",
      "\tspeed: 0.0457s/iter; left time: 1019.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160477\n",
      "\tspeed: 0.0178s/iter; left time: 394.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1433041 Vali Loss: 0.0977655 Test Loss: 0.1001861\n",
      "Validation loss decreased (inf --> 0.097766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780573\n",
      "\tspeed: 0.0397s/iter; left time: 877.4531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670697\n",
      "\tspeed: 0.0178s/iter; left time: 390.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0783016 Vali Loss: 0.0630192 Test Loss: 0.0662496\n",
      "Validation loss decreased (0.097766 --> 0.063019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0623454\n",
      "\tspeed: 0.0369s/iter; left time: 805.5581s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655507\n",
      "\tspeed: 0.0175s/iter; left time: 381.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0659248 Vali Loss: 0.0605475 Test Loss: 0.0632674\n",
      "Validation loss decreased (0.063019 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630882\n",
      "\tspeed: 0.0372s/iter; left time: 805.2769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0590766\n",
      "\tspeed: 0.0177s/iter; left time: 380.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628566 Vali Loss: 0.0584909 Test Loss: 0.0608319\n",
      "Validation loss decreased (0.060548 --> 0.058491).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0591956\n",
      "\tspeed: 0.0442s/iter; left time: 946.6197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0613977\n",
      "\tspeed: 0.0240s/iter; left time: 510.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0611276 Vali Loss: 0.0580106 Test Loss: 0.0599504\n",
      "Validation loss decreased (0.058491 --> 0.058011).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577363\n",
      "\tspeed: 0.0466s/iter; left time: 987.1521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0550658\n",
      "\tspeed: 0.0258s/iter; left time: 543.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0599828 Vali Loss: 0.0571707 Test Loss: 0.0595299\n",
      "Validation loss decreased (0.058011 --> 0.057171).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0601596\n",
      "\tspeed: 0.0470s/iter; left time: 985.0367s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558117\n",
      "\tspeed: 0.0244s/iter; left time: 508.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0591725 Vali Loss: 0.0566996 Test Loss: 0.0588407\n",
      "Validation loss decreased (0.057171 --> 0.056700).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567679\n",
      "\tspeed: 0.0453s/iter; left time: 938.7148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577220\n",
      "\tspeed: 0.0207s/iter; left time: 427.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0585837 Vali Loss: 0.0563851 Test Loss: 0.0587719\n",
      "Validation loss decreased (0.056700 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0536918\n",
      "\tspeed: 0.0433s/iter; left time: 888.3929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0593248\n",
      "\tspeed: 0.0202s/iter; left time: 412.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0579274 Vali Loss: 0.0560959 Test Loss: 0.0584001\n",
      "Validation loss decreased (0.056385 --> 0.056096).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576015\n",
      "\tspeed: 0.0392s/iter; left time: 795.0024s\n",
      "\titers: 200, epoch: 10 | loss: 0.0572641\n",
      "\tspeed: 0.0197s/iter; left time: 397.1217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0574487 Vali Loss: 0.0561246 Test Loss: 0.0586067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603743\n",
      "\tspeed: 0.0446s/iter; left time: 894.4247s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529461\n",
      "\tspeed: 0.0243s/iter; left time: 485.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0571570 Vali Loss: 0.0558561 Test Loss: 0.0580777\n",
      "Validation loss decreased (0.056096 --> 0.055856).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538307\n",
      "\tspeed: 0.0408s/iter; left time: 809.1254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0569894\n",
      "\tspeed: 0.0203s/iter; left time: 401.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0567255 Vali Loss: 0.0555736 Test Loss: 0.0576931\n",
      "Validation loss decreased (0.055856 --> 0.055574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559114\n",
      "\tspeed: 0.0453s/iter; left time: 888.4679s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570156\n",
      "\tspeed: 0.0183s/iter; left time: 357.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0564412 Vali Loss: 0.0555875 Test Loss: 0.0576721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608026\n",
      "\tspeed: 0.0409s/iter; left time: 793.3031s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548942\n",
      "\tspeed: 0.0202s/iter; left time: 389.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0562439 Vali Loss: 0.0556266 Test Loss: 0.0576045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0568721\n",
      "\tspeed: 0.0432s/iter; left time: 828.8342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553573\n",
      "\tspeed: 0.0237s/iter; left time: 452.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0559618 Vali Loss: 0.0554153 Test Loss: 0.0574718\n",
      "Validation loss decreased (0.055574 --> 0.055415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573713\n",
      "\tspeed: 0.0398s/iter; left time: 754.3022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561678\n",
      "\tspeed: 0.0175s/iter; left time: 329.9052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0558215 Vali Loss: 0.0551744 Test Loss: 0.0573095\n",
      "Validation loss decreased (0.055415 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589329\n",
      "\tspeed: 0.0376s/iter; left time: 703.8887s\n",
      "\titers: 200, epoch: 17 | loss: 0.0574918\n",
      "\tspeed: 0.0179s/iter; left time: 332.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0556505 Vali Loss: 0.0550482 Test Loss: 0.0572504\n",
      "Validation loss decreased (0.055174 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534935\n",
      "\tspeed: 0.0414s/iter; left time: 765.8245s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574331\n",
      "\tspeed: 0.0198s/iter; left time: 364.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0554857 Vali Loss: 0.0549875 Test Loss: 0.0572133\n",
      "Validation loss decreased (0.055048 --> 0.054988).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556992\n",
      "\tspeed: 0.0385s/iter; left time: 704.2454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604655\n",
      "\tspeed: 0.0240s/iter; left time: 435.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0553156 Vali Loss: 0.0548461 Test Loss: 0.0571244\n",
      "Validation loss decreased (0.054988 --> 0.054846).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546956\n",
      "\tspeed: 0.0414s/iter; left time: 746.4803s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543233\n",
      "\tspeed: 0.0245s/iter; left time: 440.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0551500 Vali Loss: 0.0548050 Test Loss: 0.0570001\n",
      "Validation loss decreased (0.054846 --> 0.054805).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0572998\n",
      "\tspeed: 0.0456s/iter; left time: 812.4846s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540240\n",
      "\tspeed: 0.0193s/iter; left time: 341.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0551207 Vali Loss: 0.0548231 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534088\n",
      "\tspeed: 0.0378s/iter; left time: 664.9020s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502284\n",
      "\tspeed: 0.0173s/iter; left time: 302.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0549312 Vali Loss: 0.0548708 Test Loss: 0.0570204\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0540605\n",
      "\tspeed: 0.0385s/iter; left time: 668.9097s\n",
      "\titers: 200, epoch: 23 | loss: 0.0507261\n",
      "\tspeed: 0.0178s/iter; left time: 306.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0548571 Vali Loss: 0.0547824 Test Loss: 0.0569985\n",
      "Validation loss decreased (0.054805 --> 0.054782).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583674\n",
      "\tspeed: 0.0442s/iter; left time: 758.5964s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544730\n",
      "\tspeed: 0.0176s/iter; left time: 299.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0547987 Vali Loss: 0.0546288 Test Loss: 0.0570315\n",
      "Validation loss decreased (0.054782 --> 0.054629).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508277\n",
      "\tspeed: 0.0373s/iter; left time: 631.7015s\n",
      "\titers: 200, epoch: 25 | loss: 0.0581925\n",
      "\tspeed: 0.0194s/iter; left time: 327.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0547711 Vali Loss: 0.0544805 Test Loss: 0.0568517\n",
      "Validation loss decreased (0.054629 --> 0.054480).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556801\n",
      "\tspeed: 0.0391s/iter; left time: 653.4126s\n",
      "\titers: 200, epoch: 26 | loss: 0.0554455\n",
      "\tspeed: 0.0195s/iter; left time: 323.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0546281 Vali Loss: 0.0546029 Test Loss: 0.0568632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572915\n",
      "\tspeed: 0.0379s/iter; left time: 623.7133s\n",
      "\titers: 200, epoch: 27 | loss: 0.0576790\n",
      "\tspeed: 0.0253s/iter; left time: 414.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0545952 Vali Loss: 0.0546437 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563810\n",
      "\tspeed: 0.0466s/iter; left time: 756.6862s\n",
      "\titers: 200, epoch: 28 | loss: 0.0515816\n",
      "\tspeed: 0.0244s/iter; left time: 393.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0545041 Vali Loss: 0.0544355 Test Loss: 0.0567258\n",
      "Validation loss decreased (0.054480 --> 0.054436).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0575383\n",
      "\tspeed: 0.0415s/iter; left time: 665.5287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0517639\n",
      "\tspeed: 0.0202s/iter; left time: 321.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0544492 Vali Loss: 0.0544463 Test Loss: 0.0569202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0554202\n",
      "\tspeed: 0.0422s/iter; left time: 667.1427s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573169\n",
      "\tspeed: 0.0204s/iter; left time: 320.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0544512 Vali Loss: 0.0544945 Test Loss: 0.0567682\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525765\n",
      "\tspeed: 0.0452s/iter; left time: 704.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568761\n",
      "\tspeed: 0.0243s/iter; left time: 375.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0543604 Vali Loss: 0.0544442 Test Loss: 0.0567680\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0544155\n",
      "\tspeed: 0.0463s/iter; left time: 711.2055s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564592\n",
      "\tspeed: 0.0197s/iter; left time: 301.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0543330 Vali Loss: 0.0544301 Test Loss: 0.0567419\n",
      "Validation loss decreased (0.054436 --> 0.054430).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549597\n",
      "\tspeed: 0.0429s/iter; left time: 648.7709s\n",
      "\titers: 200, epoch: 33 | loss: 0.0541910\n",
      "\tspeed: 0.0181s/iter; left time: 272.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0543469 Vali Loss: 0.0543835 Test Loss: 0.0567440\n",
      "Validation loss decreased (0.054430 --> 0.054384).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0571987\n",
      "\tspeed: 0.0416s/iter; left time: 620.5499s\n",
      "\titers: 200, epoch: 34 | loss: 0.0567482\n",
      "\tspeed: 0.0201s/iter; left time: 297.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0543108 Vali Loss: 0.0543652 Test Loss: 0.0567222\n",
      "Validation loss decreased (0.054384 --> 0.054365).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535260\n",
      "\tspeed: 0.0423s/iter; left time: 621.8226s\n",
      "\titers: 200, epoch: 35 | loss: 0.0561866\n",
      "\tspeed: 0.0193s/iter; left time: 281.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0542972 Vali Loss: 0.0544265 Test Loss: 0.0567667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0549961\n",
      "\tspeed: 0.0410s/iter; left time: 593.5670s\n",
      "\titers: 200, epoch: 36 | loss: 0.0541536\n",
      "\tspeed: 0.0192s/iter; left time: 275.6673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0542406 Vali Loss: 0.0544166 Test Loss: 0.0566596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532916\n",
      "\tspeed: 0.0400s/iter; left time: 569.6183s\n",
      "\titers: 200, epoch: 37 | loss: 0.0511241\n",
      "\tspeed: 0.0198s/iter; left time: 280.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0542641 Vali Loss: 0.0543706 Test Loss: 0.0566760\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0539109\n",
      "\tspeed: 0.0399s/iter; left time: 558.4617s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564077\n",
      "\tspeed: 0.0205s/iter; left time: 285.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0541845 Vali Loss: 0.0543355 Test Loss: 0.0566975\n",
      "Validation loss decreased (0.054365 --> 0.054336).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503076\n",
      "\tspeed: 0.0409s/iter; left time: 563.8564s\n",
      "\titers: 200, epoch: 39 | loss: 0.0562198\n",
      "\tspeed: 0.0200s/iter; left time: 273.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0541782 Vali Loss: 0.0543724 Test Loss: 0.0566402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552053\n",
      "\tspeed: 0.0407s/iter; left time: 552.2094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0516493\n",
      "\tspeed: 0.0199s/iter; left time: 267.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0543906 Test Loss: 0.0566315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0556425\n",
      "\tspeed: 0.0412s/iter; left time: 550.0056s\n",
      "\titers: 200, epoch: 41 | loss: 0.0509712\n",
      "\tspeed: 0.0201s/iter; left time: 266.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0541427 Vali Loss: 0.0543536 Test Loss: 0.0566362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523108\n",
      "\tspeed: 0.0422s/iter; left time: 553.7186s\n",
      "\titers: 200, epoch: 42 | loss: 0.0576750\n",
      "\tspeed: 0.0195s/iter; left time: 253.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0541833 Vali Loss: 0.0542894 Test Loss: 0.0566669\n",
      "Validation loss decreased (0.054336 --> 0.054289).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0529656\n",
      "\tspeed: 0.0435s/iter; left time: 561.1621s\n",
      "\titers: 200, epoch: 43 | loss: 0.0502761\n",
      "\tspeed: 0.0229s/iter; left time: 292.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0541143 Vali Loss: 0.0543694 Test Loss: 0.0566259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537367\n",
      "\tspeed: 0.0447s/iter; left time: 566.3745s\n",
      "\titers: 200, epoch: 44 | loss: 0.0559055\n",
      "\tspeed: 0.0200s/iter; left time: 251.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0541310 Vali Loss: 0.0542568 Test Loss: 0.0566117\n",
      "Validation loss decreased (0.054289 --> 0.054257).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0569029\n",
      "\tspeed: 0.0405s/iter; left time: 504.4566s\n",
      "\titers: 200, epoch: 45 | loss: 0.0579741\n",
      "\tspeed: 0.0183s/iter; left time: 225.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0541451 Vali Loss: 0.0543393 Test Loss: 0.0566353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0510111\n",
      "\tspeed: 0.0435s/iter; left time: 531.5669s\n",
      "\titers: 200, epoch: 46 | loss: 0.0570540\n",
      "\tspeed: 0.0194s/iter; left time: 235.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0543384 Test Loss: 0.0565993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0603271\n",
      "\tspeed: 0.0408s/iter; left time: 489.8614s\n",
      "\titers: 200, epoch: 47 | loss: 0.0489362\n",
      "\tspeed: 0.0221s/iter; left time: 262.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0541158 Vali Loss: 0.0542949 Test Loss: 0.0566084\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0562014\n",
      "\tspeed: 0.0430s/iter; left time: 506.5203s\n",
      "\titers: 200, epoch: 48 | loss: 0.0527634\n",
      "\tspeed: 0.0175s/iter; left time: 204.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0541052 Vali Loss: 0.0542426 Test Loss: 0.0566221\n",
      "Validation loss decreased (0.054257 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0550343\n",
      "\tspeed: 0.0405s/iter; left time: 468.1700s\n",
      "\titers: 200, epoch: 49 | loss: 0.0519099\n",
      "\tspeed: 0.0199s/iter; left time: 227.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0540786 Vali Loss: 0.0543246 Test Loss: 0.0566017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0535444\n",
      "\tspeed: 0.0454s/iter; left time: 514.6661s\n",
      "\titers: 200, epoch: 50 | loss: 0.0502683\n",
      "\tspeed: 0.0237s/iter; left time: 265.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0540946 Vali Loss: 0.0542993 Test Loss: 0.0566170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525270\n",
      "\tspeed: 0.0416s/iter; left time: 462.1014s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515277\n",
      "\tspeed: 0.0226s/iter; left time: 248.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0542633 Test Loss: 0.0566191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0528202\n",
      "\tspeed: 0.0388s/iter; left time: 422.3969s\n",
      "\titers: 200, epoch: 52 | loss: 0.0524368\n",
      "\tspeed: 0.0174s/iter; left time: 187.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0540361 Vali Loss: 0.0542905 Test Loss: 0.0565996\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548940\n",
      "\tspeed: 0.0396s/iter; left time: 421.7677s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519573\n",
      "\tspeed: 0.0204s/iter; left time: 214.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0541037 Vali Loss: 0.0542877 Test Loss: 0.0566198\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533164\n",
      "\tspeed: 0.0430s/iter; left time: 448.0185s\n",
      "\titers: 200, epoch: 54 | loss: 0.0578958\n",
      "\tspeed: 0.0241s/iter; left time: 249.1271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0540474 Vali Loss: 0.0542890 Test Loss: 0.0566051\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548727\n",
      "\tspeed: 0.0412s/iter; left time: 419.9655s\n",
      "\titers: 200, epoch: 55 | loss: 0.0566967\n",
      "\tspeed: 0.0198s/iter; left time: 200.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0540961 Vali Loss: 0.0543088 Test Loss: 0.0566188\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0531577\n",
      "\tspeed: 0.0392s/iter; left time: 391.2384s\n",
      "\titers: 200, epoch: 56 | loss: 0.0580916\n",
      "\tspeed: 0.0175s/iter; left time: 173.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0540501 Vali Loss: 0.0543088 Test Loss: 0.0566136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0559601\n",
      "\tspeed: 0.0367s/iter; left time: 358.4146s\n",
      "\titers: 200, epoch: 57 | loss: 0.0543095\n",
      "\tspeed: 0.0174s/iter; left time: 167.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0540529 Vali Loss: 0.0542350 Test Loss: 0.0566049\n",
      "Validation loss decreased (0.054243 --> 0.054235).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538715\n",
      "\tspeed: 0.0394s/iter; left time: 375.2252s\n",
      "\titers: 200, epoch: 58 | loss: 0.0555631\n",
      "\tspeed: 0.0176s/iter; left time: 165.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0540707 Vali Loss: 0.0542733 Test Loss: 0.0566099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0560754\n",
      "\tspeed: 0.0395s/iter; left time: 367.5105s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519199\n",
      "\tspeed: 0.0216s/iter; left time: 199.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0540248 Vali Loss: 0.0542616 Test Loss: 0.0566028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0571120\n",
      "\tspeed: 0.0394s/iter; left time: 358.0110s\n",
      "\titers: 200, epoch: 60 | loss: 0.0582117\n",
      "\tspeed: 0.0174s/iter; left time: 156.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0542328 Test Loss: 0.0565980\n",
      "Validation loss decreased (0.054235 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0584766\n",
      "\tspeed: 0.0408s/iter; left time: 361.3126s\n",
      "\titers: 200, epoch: 61 | loss: 0.0535091\n",
      "\tspeed: 0.0177s/iter; left time: 154.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0540387 Vali Loss: 0.0543091 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0581197\n",
      "\tspeed: 0.0361s/iter; left time: 312.1834s\n",
      "\titers: 200, epoch: 62 | loss: 0.0556779\n",
      "\tspeed: 0.0181s/iter; left time: 154.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0540725 Vali Loss: 0.0543238 Test Loss: 0.0566121\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0515098\n",
      "\tspeed: 0.0379s/iter; left time: 318.9160s\n",
      "\titers: 200, epoch: 63 | loss: 0.0547690\n",
      "\tspeed: 0.0175s/iter; left time: 145.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0539889 Vali Loss: 0.0542935 Test Loss: 0.0566016\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0558435\n",
      "\tspeed: 0.0362s/iter; left time: 296.3327s\n",
      "\titers: 200, epoch: 64 | loss: 0.0558558\n",
      "\tspeed: 0.0176s/iter; left time: 141.9768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0540476 Vali Loss: 0.0542764 Test Loss: 0.0566100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546813\n",
      "\tspeed: 0.0395s/iter; left time: 314.6030s\n",
      "\titers: 200, epoch: 65 | loss: 0.0554467\n",
      "\tspeed: 0.0175s/iter; left time: 137.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540326 Vali Loss: 0.0543010 Test Loss: 0.0565934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0568983\n",
      "\tspeed: 0.0397s/iter; left time: 306.9717s\n",
      "\titers: 200, epoch: 66 | loss: 0.0544441\n",
      "\tspeed: 0.0206s/iter; left time: 157.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0540953 Vali Loss: 0.0543162 Test Loss: 0.0565933\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0554599\n",
      "\tspeed: 0.0427s/iter; left time: 321.0730s\n",
      "\titers: 200, epoch: 67 | loss: 0.0513533\n",
      "\tspeed: 0.0207s/iter; left time: 153.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0543076 Test Loss: 0.0566009\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0543297\n",
      "\tspeed: 0.0370s/iter; left time: 269.8459s\n",
      "\titers: 200, epoch: 68 | loss: 0.0517003\n",
      "\tspeed: 0.0173s/iter; left time: 124.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0540420 Vali Loss: 0.0542774 Test Loss: 0.0566046\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0578591\n",
      "\tspeed: 0.0356s/iter; left time: 251.9135s\n",
      "\titers: 200, epoch: 69 | loss: 0.0572697\n",
      "\tspeed: 0.0175s/iter; left time: 121.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0540791 Vali Loss: 0.0542371 Test Loss: 0.0566058\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0537115\n",
      "\tspeed: 0.0371s/iter; left time: 253.6271s\n",
      "\titers: 200, epoch: 70 | loss: 0.0505972\n",
      "\tspeed: 0.0210s/iter; left time: 141.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0540482 Vali Loss: 0.0542732 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083218105137348, rmse:0.10041522979736328, mae:0.0565979890525341, rse:0.3794197142124176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1359126\n",
      "\tspeed: 0.0225s/iter; left time: 502.7281s\n",
      "\titers: 200, epoch: 1 | loss: 0.1098680\n",
      "\tspeed: 0.0213s/iter; left time: 473.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1422349 Vali Loss: 0.0974500 Test Loss: 0.0992706\n",
      "Validation loss decreased (inf --> 0.097450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754588\n",
      "\tspeed: 0.0417s/iter; left time: 921.0493s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673907\n",
      "\tspeed: 0.0174s/iter; left time: 382.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0780355 Vali Loss: 0.0627294 Test Loss: 0.0657381\n",
      "Validation loss decreased (0.097450 --> 0.062729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637678\n",
      "\tspeed: 0.0431s/iter; left time: 942.5154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663196\n",
      "\tspeed: 0.0196s/iter; left time: 425.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0660164 Vali Loss: 0.0599926 Test Loss: 0.0628002\n",
      "Validation loss decreased (0.062729 --> 0.059993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638419\n",
      "\tspeed: 0.0413s/iter; left time: 893.2220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635814\n",
      "\tspeed: 0.0202s/iter; left time: 435.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0630481 Vali Loss: 0.0586561 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.059993 --> 0.058656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630238\n",
      "\tspeed: 0.0430s/iter; left time: 921.1678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610638\n",
      "\tspeed: 0.0176s/iter; left time: 373.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0612143 Vali Loss: 0.0575957 Test Loss: 0.0601869\n",
      "Validation loss decreased (0.058656 --> 0.057596).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0648216\n",
      "\tspeed: 0.0375s/iter; left time: 794.3087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634050\n",
      "\tspeed: 0.0176s/iter; left time: 370.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0601831 Vali Loss: 0.0573942 Test Loss: 0.0597799\n",
      "Validation loss decreased (0.057596 --> 0.057394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599069\n",
      "\tspeed: 0.0371s/iter; left time: 778.1308s\n",
      "\titers: 200, epoch: 7 | loss: 0.0612065\n",
      "\tspeed: 0.0175s/iter; left time: 364.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593155 Vali Loss: 0.0566541 Test Loss: 0.0591102\n",
      "Validation loss decreased (0.057394 --> 0.056654).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542986\n",
      "\tspeed: 0.0415s/iter; left time: 859.8482s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572991\n",
      "\tspeed: 0.0223s/iter; left time: 460.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0585377 Vali Loss: 0.0566305 Test Loss: 0.0588562\n",
      "Validation loss decreased (0.056654 --> 0.056631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0640263\n",
      "\tspeed: 0.0471s/iter; left time: 966.1459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615080\n",
      "\tspeed: 0.0202s/iter; left time: 412.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0579915 Vali Loss: 0.0559572 Test Loss: 0.0582891\n",
      "Validation loss decreased (0.056631 --> 0.055957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577642\n",
      "\tspeed: 0.0505s/iter; left time: 1025.0210s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594756\n",
      "\tspeed: 0.0264s/iter; left time: 532.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0575409 Vali Loss: 0.0558674 Test Loss: 0.0583287\n",
      "Validation loss decreased (0.055957 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579124\n",
      "\tspeed: 0.0448s/iter; left time: 899.5653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581660\n",
      "\tspeed: 0.0204s/iter; left time: 406.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0571616 Vali Loss: 0.0555863 Test Loss: 0.0582007\n",
      "Validation loss decreased (0.055867 --> 0.055586).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0618948\n",
      "\tspeed: 0.0424s/iter; left time: 840.9896s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521666\n",
      "\tspeed: 0.0205s/iter; left time: 405.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0569079 Vali Loss: 0.0554603 Test Loss: 0.0577516\n",
      "Validation loss decreased (0.055586 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0548473\n",
      "\tspeed: 0.0413s/iter; left time: 809.2691s\n",
      "\titers: 200, epoch: 13 | loss: 0.0552182\n",
      "\tspeed: 0.0208s/iter; left time: 405.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0565429 Vali Loss: 0.0553249 Test Loss: 0.0574627\n",
      "Validation loss decreased (0.055460 --> 0.055325).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554208\n",
      "\tspeed: 0.0444s/iter; left time: 861.4926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0541941\n",
      "\tspeed: 0.0230s/iter; left time: 443.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0562538 Vali Loss: 0.0553683 Test Loss: 0.0575624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0557231\n",
      "\tspeed: 0.0443s/iter; left time: 848.9220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574080\n",
      "\tspeed: 0.0209s/iter; left time: 397.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0560413 Vali Loss: 0.0551291 Test Loss: 0.0575157\n",
      "Validation loss decreased (0.055325 --> 0.055129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575104\n",
      "\tspeed: 0.0396s/iter; left time: 749.1542s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551079\n",
      "\tspeed: 0.0208s/iter; left time: 392.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0557593 Vali Loss: 0.0548837 Test Loss: 0.0574590\n",
      "Validation loss decreased (0.055129 --> 0.054884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595915\n",
      "\tspeed: 0.0407s/iter; left time: 761.5210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584150\n",
      "\tspeed: 0.0174s/iter; left time: 323.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0556200 Vali Loss: 0.0549069 Test Loss: 0.0572072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0574168\n",
      "\tspeed: 0.0400s/iter; left time: 740.2444s\n",
      "\titers: 200, epoch: 18 | loss: 0.0581237\n",
      "\tspeed: 0.0177s/iter; left time: 326.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0554449 Vali Loss: 0.0550244 Test Loss: 0.0573702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542099\n",
      "\tspeed: 0.0398s/iter; left time: 726.2855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559456\n",
      "\tspeed: 0.0176s/iter; left time: 319.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0553786 Vali Loss: 0.0548329 Test Loss: 0.0571894\n",
      "Validation loss decreased (0.054884 --> 0.054833).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572355\n",
      "\tspeed: 0.0380s/iter; left time: 686.2173s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561926\n",
      "\tspeed: 0.0173s/iter; left time: 310.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0551821 Vali Loss: 0.0546544 Test Loss: 0.0570234\n",
      "Validation loss decreased (0.054833 --> 0.054654).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563121\n",
      "\tspeed: 0.0377s/iter; left time: 671.9930s\n",
      "\titers: 200, epoch: 21 | loss: 0.0511623\n",
      "\tspeed: 0.0173s/iter; left time: 307.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0551742 Vali Loss: 0.0547604 Test Loss: 0.0571249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0555600\n",
      "\tspeed: 0.0370s/iter; left time: 651.3281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0522842\n",
      "\tspeed: 0.0177s/iter; left time: 309.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0550073 Vali Loss: 0.0546179 Test Loss: 0.0571097\n",
      "Validation loss decreased (0.054654 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0549146\n",
      "\tspeed: 0.0380s/iter; left time: 660.0129s\n",
      "\titers: 200, epoch: 23 | loss: 0.0585962\n",
      "\tspeed: 0.0176s/iter; left time: 303.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0548645 Vali Loss: 0.0546012 Test Loss: 0.0568507\n",
      "Validation loss decreased (0.054618 --> 0.054601).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522619\n",
      "\tspeed: 0.0411s/iter; left time: 705.5859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523071\n",
      "\tspeed: 0.0209s/iter; left time: 356.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0547287 Vali Loss: 0.0545045 Test Loss: 0.0567771\n",
      "Validation loss decreased (0.054601 --> 0.054504).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524549\n",
      "\tspeed: 0.0374s/iter; left time: 632.9479s\n",
      "\titers: 200, epoch: 25 | loss: 0.0523958\n",
      "\tspeed: 0.0175s/iter; left time: 294.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0546907 Vali Loss: 0.0543925 Test Loss: 0.0568053\n",
      "Validation loss decreased (0.054504 --> 0.054393).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0491656\n",
      "\tspeed: 0.0375s/iter; left time: 627.0800s\n",
      "\titers: 200, epoch: 26 | loss: 0.0519010\n",
      "\tspeed: 0.0187s/iter; left time: 309.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0546669 Vali Loss: 0.0544461 Test Loss: 0.0568800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0501324\n",
      "\tspeed: 0.0378s/iter; left time: 622.8373s\n",
      "\titers: 200, epoch: 27 | loss: 0.0555143\n",
      "\tspeed: 0.0176s/iter; left time: 287.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0545846 Vali Loss: 0.0543533 Test Loss: 0.0567463\n",
      "Validation loss decreased (0.054393 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0519045\n",
      "\tspeed: 0.0415s/iter; left time: 674.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0593164\n",
      "\tspeed: 0.0198s/iter; left time: 319.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0545893 Vali Loss: 0.0543581 Test Loss: 0.0567341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0529863\n",
      "\tspeed: 0.0364s/iter; left time: 583.2380s\n",
      "\titers: 200, epoch: 29 | loss: 0.0542369\n",
      "\tspeed: 0.0178s/iter; left time: 282.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0544853 Vali Loss: 0.0542986 Test Loss: 0.0568295\n",
      "Validation loss decreased (0.054353 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555674\n",
      "\tspeed: 0.0386s/iter; left time: 609.8705s\n",
      "\titers: 200, epoch: 30 | loss: 0.0536577\n",
      "\tspeed: 0.0180s/iter; left time: 283.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0544743 Vali Loss: 0.0543639 Test Loss: 0.0568086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0559736\n",
      "\tspeed: 0.0426s/iter; left time: 664.2999s\n",
      "\titers: 200, epoch: 31 | loss: 0.0530356\n",
      "\tspeed: 0.0198s/iter; left time: 307.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0543727 Vali Loss: 0.0542804 Test Loss: 0.0567701\n",
      "Validation loss decreased (0.054299 --> 0.054280).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506607\n",
      "\tspeed: 0.0423s/iter; left time: 648.9617s\n",
      "\titers: 200, epoch: 32 | loss: 0.0552089\n",
      "\tspeed: 0.0197s/iter; left time: 301.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543940 Vali Loss: 0.0542822 Test Loss: 0.0566895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0566098\n",
      "\tspeed: 0.0416s/iter; left time: 628.8243s\n",
      "\titers: 200, epoch: 33 | loss: 0.0505462\n",
      "\tspeed: 0.0176s/iter; left time: 264.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0543382 Vali Loss: 0.0542966 Test Loss: 0.0567221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0536274\n",
      "\tspeed: 0.0372s/iter; left time: 554.7289s\n",
      "\titers: 200, epoch: 34 | loss: 0.0556459\n",
      "\tspeed: 0.0177s/iter; left time: 262.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0542882 Vali Loss: 0.0541794 Test Loss: 0.0567122\n",
      "Validation loss decreased (0.054280 --> 0.054179).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517977\n",
      "\tspeed: 0.0418s/iter; left time: 614.2475s\n",
      "\titers: 200, epoch: 35 | loss: 0.0515377\n",
      "\tspeed: 0.0187s/iter; left time: 272.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0542845 Vali Loss: 0.0542402 Test Loss: 0.0566953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0548994\n",
      "\tspeed: 0.0390s/iter; left time: 564.5106s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516339\n",
      "\tspeed: 0.0174s/iter; left time: 249.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0543297 Vali Loss: 0.0541653 Test Loss: 0.0567088\n",
      "Validation loss decreased (0.054179 --> 0.054165).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532896\n",
      "\tspeed: 0.0374s/iter; left time: 532.2474s\n",
      "\titers: 200, epoch: 37 | loss: 0.0552534\n",
      "\tspeed: 0.0173s/iter; left time: 245.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0542318 Vali Loss: 0.0542396 Test Loss: 0.0566283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0579502\n",
      "\tspeed: 0.0363s/iter; left time: 509.2660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564580\n",
      "\tspeed: 0.0174s/iter; left time: 241.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0541829 Vali Loss: 0.0542048 Test Loss: 0.0566276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0524793\n",
      "\tspeed: 0.0436s/iter; left time: 601.4429s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540179\n",
      "\tspeed: 0.0233s/iter; left time: 319.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0542241 Vali Loss: 0.0542069 Test Loss: 0.0566297\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0576975\n",
      "\tspeed: 0.0376s/iter; left time: 509.5911s\n",
      "\titers: 200, epoch: 40 | loss: 0.0566987\n",
      "\tspeed: 0.0200s/iter; left time: 269.4703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0542656 Vali Loss: 0.0541664 Test Loss: 0.0566543\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545915\n",
      "\tspeed: 0.0367s/iter; left time: 489.2609s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532811\n",
      "\tspeed: 0.0210s/iter; left time: 277.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0542114 Vali Loss: 0.0541793 Test Loss: 0.0566813\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551827\n",
      "\tspeed: 0.0411s/iter; left time: 539.2438s\n",
      "\titers: 200, epoch: 42 | loss: 0.0532943\n",
      "\tspeed: 0.0185s/iter; left time: 241.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0541279 Vali Loss: 0.0542011 Test Loss: 0.0566544\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552357\n",
      "\tspeed: 0.0401s/iter; left time: 517.6390s\n",
      "\titers: 200, epoch: 43 | loss: 0.0531659\n",
      "\tspeed: 0.0226s/iter; left time: 288.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541679 Vali Loss: 0.0542149 Test Loss: 0.0566875\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508406\n",
      "\tspeed: 0.0397s/iter; left time: 502.6425s\n",
      "\titers: 200, epoch: 44 | loss: 0.0489071\n",
      "\tspeed: 0.0176s/iter; left time: 220.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0541656 Vali Loss: 0.0542703 Test Loss: 0.0566778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571226\n",
      "\tspeed: 0.0372s/iter; left time: 463.0165s\n",
      "\titers: 200, epoch: 45 | loss: 0.0516223\n",
      "\tspeed: 0.0175s/iter; left time: 216.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0541900 Test Loss: 0.0566624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0533346\n",
      "\tspeed: 0.0367s/iter; left time: 448.1339s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554680\n",
      "\tspeed: 0.0176s/iter; left time: 213.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0541046 Vali Loss: 0.0542059 Test Loss: 0.0566667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010069291107356548, rmse:0.10034585744142532, mae:0.05670879781246185, rse:0.37915757298469543\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:52.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1438253\n",
      "\tspeed: 0.0460s/iter; left time: 1024.9099s\n",
      "\titers: 200, epoch: 1 | loss: 0.1208758\n",
      "\tspeed: 0.0179s/iter; left time: 397.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1473302 Vali Loss: 0.1059266 Test Loss: 0.1091740\n",
      "Validation loss decreased (inf --> 0.105927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936386\n",
      "\tspeed: 0.0392s/iter; left time: 865.1550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860985\n",
      "\tspeed: 0.0179s/iter; left time: 392.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0960414 Vali Loss: 0.0816183 Test Loss: 0.0868534\n",
      "Validation loss decreased (0.105927 --> 0.081618).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0869685\n",
      "\tspeed: 0.0384s/iter; left time: 839.2529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824700\n",
      "\tspeed: 0.0177s/iter; left time: 384.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0850344 Vali Loss: 0.0794767 Test Loss: 0.0840807\n",
      "Validation loss decreased (0.081618 --> 0.079477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0811073\n",
      "\tspeed: 0.0395s/iter; left time: 854.8521s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803189\n",
      "\tspeed: 0.0192s/iter; left time: 413.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823571 Vali Loss: 0.0782248 Test Loss: 0.0828857\n",
      "Validation loss decreased (0.079477 --> 0.078225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829862\n",
      "\tspeed: 0.0391s/iter; left time: 837.2694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771629\n",
      "\tspeed: 0.0180s/iter; left time: 383.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0807140 Vali Loss: 0.0776065 Test Loss: 0.0829133\n",
      "Validation loss decreased (0.078225 --> 0.077606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808049\n",
      "\tspeed: 0.0381s/iter; left time: 806.9387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791209\n",
      "\tspeed: 0.0175s/iter; left time: 369.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0796624 Vali Loss: 0.0771222 Test Loss: 0.0819657\n",
      "Validation loss decreased (0.077606 --> 0.077122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0809408\n",
      "\tspeed: 0.0381s/iter; left time: 797.8413s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773605\n",
      "\tspeed: 0.0179s/iter; left time: 373.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0788298 Vali Loss: 0.0770251 Test Loss: 0.0816225\n",
      "Validation loss decreased (0.077122 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780101\n",
      "\tspeed: 0.0386s/iter; left time: 800.1361s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734982\n",
      "\tspeed: 0.0178s/iter; left time: 366.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0781991 Vali Loss: 0.0765766 Test Loss: 0.0813183\n",
      "Validation loss decreased (0.077025 --> 0.076577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775502\n",
      "\tspeed: 0.0390s/iter; left time: 800.2133s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727340\n",
      "\tspeed: 0.0179s/iter; left time: 365.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0776098 Vali Loss: 0.0765785 Test Loss: 0.0815433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0742046\n",
      "\tspeed: 0.0384s/iter; left time: 778.6754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804574\n",
      "\tspeed: 0.0179s/iter; left time: 361.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0770741 Vali Loss: 0.0760664 Test Loss: 0.0814565\n",
      "Validation loss decreased (0.076577 --> 0.076066).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781170\n",
      "\tspeed: 0.0385s/iter; left time: 771.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763606\n",
      "\tspeed: 0.0177s/iter; left time: 354.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0766591 Vali Loss: 0.0762633 Test Loss: 0.0814268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0788421\n",
      "\tspeed: 0.0386s/iter; left time: 765.1212s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785553\n",
      "\tspeed: 0.0186s/iter; left time: 367.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0762871 Vali Loss: 0.0763303 Test Loss: 0.0807374\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767044\n",
      "\tspeed: 0.0405s/iter; left time: 794.2752s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790308\n",
      "\tspeed: 0.0190s/iter; left time: 370.3604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0760010 Vali Loss: 0.0760269 Test Loss: 0.0811383\n",
      "Validation loss decreased (0.076066 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738585\n",
      "\tspeed: 0.0382s/iter; left time: 740.1297s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735675\n",
      "\tspeed: 0.0175s/iter; left time: 337.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0756241 Vali Loss: 0.0759628 Test Loss: 0.0812599\n",
      "Validation loss decreased (0.076027 --> 0.075963).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746233\n",
      "\tspeed: 0.0403s/iter; left time: 773.2452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766651\n",
      "\tspeed: 0.0178s/iter; left time: 340.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0754588 Vali Loss: 0.0756437 Test Loss: 0.0810107\n",
      "Validation loss decreased (0.075963 --> 0.075644).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0798216\n",
      "\tspeed: 0.0379s/iter; left time: 718.3975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763530\n",
      "\tspeed: 0.0177s/iter; left time: 333.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0750988 Vali Loss: 0.0756608 Test Loss: 0.0809585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749412\n",
      "\tspeed: 0.0400s/iter; left time: 748.7746s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748506\n",
      "\tspeed: 0.0177s/iter; left time: 329.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0748632 Vali Loss: 0.0757296 Test Loss: 0.0809511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732470\n",
      "\tspeed: 0.0383s/iter; left time: 708.6400s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771152\n",
      "\tspeed: 0.0177s/iter; left time: 325.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0746712 Vali Loss: 0.0759519 Test Loss: 0.0808242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716322\n",
      "\tspeed: 0.0374s/iter; left time: 682.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0734277\n",
      "\tspeed: 0.0175s/iter; left time: 318.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0744779 Vali Loss: 0.0757884 Test Loss: 0.0807449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720630\n",
      "\tspeed: 0.0396s/iter; left time: 714.6965s\n",
      "\titers: 200, epoch: 20 | loss: 0.0764352\n",
      "\tspeed: 0.0176s/iter; left time: 315.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0742645 Vali Loss: 0.0756426 Test Loss: 0.0808228\n",
      "Validation loss decreased (0.075644 --> 0.075643).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752152\n",
      "\tspeed: 0.0425s/iter; left time: 757.8532s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683738\n",
      "\tspeed: 0.0190s/iter; left time: 336.3019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0741271 Vali Loss: 0.0756992 Test Loss: 0.0806643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747552\n",
      "\tspeed: 0.0387s/iter; left time: 680.3511s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740042\n",
      "\tspeed: 0.0178s/iter; left time: 311.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0740510 Vali Loss: 0.0756657 Test Loss: 0.0808825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729785\n",
      "\tspeed: 0.0379s/iter; left time: 658.7155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724722\n",
      "\tspeed: 0.0175s/iter; left time: 302.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0738833 Vali Loss: 0.0756935 Test Loss: 0.0808874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741584\n",
      "\tspeed: 0.0379s/iter; left time: 650.3920s\n",
      "\titers: 200, epoch: 24 | loss: 0.0702976\n",
      "\tspeed: 0.0176s/iter; left time: 299.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0737572 Vali Loss: 0.0755926 Test Loss: 0.0806114\n",
      "Validation loss decreased (0.075643 --> 0.075593).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0726041\n",
      "\tspeed: 0.0387s/iter; left time: 654.9765s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721414\n",
      "\tspeed: 0.0177s/iter; left time: 297.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0735935 Vali Loss: 0.0755621 Test Loss: 0.0806927\n",
      "Validation loss decreased (0.075593 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0734444\n",
      "\tspeed: 0.0385s/iter; left time: 643.0189s\n",
      "\titers: 200, epoch: 26 | loss: 0.0754302\n",
      "\tspeed: 0.0175s/iter; left time: 291.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0735225 Vali Loss: 0.0756676 Test Loss: 0.0805907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747007\n",
      "\tspeed: 0.0378s/iter; left time: 623.2643s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694138\n",
      "\tspeed: 0.0177s/iter; left time: 290.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0734549 Vali Loss: 0.0755092 Test Loss: 0.0805312\n",
      "Validation loss decreased (0.075562 --> 0.075509).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0760770\n",
      "\tspeed: 0.0391s/iter; left time: 635.0650s\n",
      "\titers: 200, epoch: 28 | loss: 0.0724863\n",
      "\tspeed: 0.0178s/iter; left time: 287.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0733856 Vali Loss: 0.0755548 Test Loss: 0.0805923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0735273\n",
      "\tspeed: 0.0381s/iter; left time: 610.0264s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731055\n",
      "\tspeed: 0.0177s/iter; left time: 281.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0733169 Vali Loss: 0.0754803 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.075509 --> 0.075480).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0725225\n",
      "\tspeed: 0.0388s/iter; left time: 613.0244s\n",
      "\titers: 200, epoch: 30 | loss: 0.0722679\n",
      "\tspeed: 0.0177s/iter; left time: 278.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0732621 Vali Loss: 0.0754730 Test Loss: 0.0806382\n",
      "Validation loss decreased (0.075480 --> 0.075473).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0735552\n",
      "\tspeed: 0.0406s/iter; left time: 632.5392s\n",
      "\titers: 200, epoch: 31 | loss: 0.0696184\n",
      "\tspeed: 0.0177s/iter; left time: 273.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0732522 Vali Loss: 0.0753299 Test Loss: 0.0805189\n",
      "Validation loss decreased (0.075473 --> 0.075330).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0748394\n",
      "\tspeed: 0.0394s/iter; left time: 605.2338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749177\n",
      "\tspeed: 0.0178s/iter; left time: 271.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0731558 Vali Loss: 0.0754113 Test Loss: 0.0805488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731158\n",
      "\tspeed: 0.0415s/iter; left time: 628.1651s\n",
      "\titers: 200, epoch: 33 | loss: 0.0764134\n",
      "\tspeed: 0.0190s/iter; left time: 285.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0731354 Vali Loss: 0.0754464 Test Loss: 0.0805663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720409\n",
      "\tspeed: 0.0380s/iter; left time: 566.4270s\n",
      "\titers: 200, epoch: 34 | loss: 0.0738428\n",
      "\tspeed: 0.0178s/iter; left time: 262.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0730683 Vali Loss: 0.0754058 Test Loss: 0.0804376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0698061\n",
      "\tspeed: 0.0400s/iter; left time: 587.5626s\n",
      "\titers: 200, epoch: 35 | loss: 0.0759599\n",
      "\tspeed: 0.0194s/iter; left time: 283.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0730275 Vali Loss: 0.0754564 Test Loss: 0.0805740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716557\n",
      "\tspeed: 0.0385s/iter; left time: 557.2221s\n",
      "\titers: 200, epoch: 36 | loss: 0.0711207\n",
      "\tspeed: 0.0175s/iter; left time: 251.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0730016 Vali Loss: 0.0754517 Test Loss: 0.0805066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755870\n",
      "\tspeed: 0.0383s/iter; left time: 545.3388s\n",
      "\titers: 200, epoch: 37 | loss: 0.0734674\n",
      "\tspeed: 0.0181s/iter; left time: 255.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0729387 Vali Loss: 0.0754124 Test Loss: 0.0805279\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0684947\n",
      "\tspeed: 0.0376s/iter; left time: 526.9358s\n",
      "\titers: 200, epoch: 38 | loss: 0.0758405\n",
      "\tspeed: 0.0177s/iter; left time: 245.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0729181 Vali Loss: 0.0754555 Test Loss: 0.0805209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0743821\n",
      "\tspeed: 0.0375s/iter; left time: 517.0128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711856\n",
      "\tspeed: 0.0175s/iter; left time: 239.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0728928 Vali Loss: 0.0753763 Test Loss: 0.0805926\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0773584\n",
      "\tspeed: 0.0425s/iter; left time: 576.3701s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719035\n",
      "\tspeed: 0.0231s/iter; left time: 311.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0729117 Vali Loss: 0.0754172 Test Loss: 0.0805385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0723396\n",
      "\tspeed: 0.0413s/iter; left time: 551.6058s\n",
      "\titers: 200, epoch: 41 | loss: 0.0712304\n",
      "\tspeed: 0.0176s/iter; left time: 232.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0729427 Vali Loss: 0.0753424 Test Loss: 0.0805553\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678918480873108, rmse:0.13667084276676178, mae:0.08051890879869461, rse:0.5167672038078308\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446110\n",
      "\tspeed: 0.0221s/iter; left time: 493.8308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1253999\n",
      "\tspeed: 0.0199s/iter; left time: 441.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1496909 Vali Loss: 0.1045320 Test Loss: 0.1075368\n",
      "Validation loss decreased (inf --> 0.104532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924727\n",
      "\tspeed: 0.0412s/iter; left time: 910.6740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894741\n",
      "\tspeed: 0.0178s/iter; left time: 390.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0954484 Vali Loss: 0.0817993 Test Loss: 0.0867445\n",
      "Validation loss decreased (0.104532 --> 0.081799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0847295\n",
      "\tspeed: 0.0402s/iter; left time: 878.0263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0820517\n",
      "\tspeed: 0.0180s/iter; left time: 391.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0846861 Vali Loss: 0.0795831 Test Loss: 0.0841799\n",
      "Validation loss decreased (0.081799 --> 0.079583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826818\n",
      "\tspeed: 0.0404s/iter; left time: 873.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826001\n",
      "\tspeed: 0.0179s/iter; left time: 386.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823463 Vali Loss: 0.0784222 Test Loss: 0.0830313\n",
      "Validation loss decreased (0.079583 --> 0.078422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0834706\n",
      "\tspeed: 0.0389s/iter; left time: 833.0787s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793772\n",
      "\tspeed: 0.0177s/iter; left time: 376.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0808059 Vali Loss: 0.0778977 Test Loss: 0.0820265\n",
      "Validation loss decreased (0.078422 --> 0.077898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793130\n",
      "\tspeed: 0.0408s/iter; left time: 863.3459s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798471\n",
      "\tspeed: 0.0182s/iter; left time: 382.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0797353 Vali Loss: 0.0771687 Test Loss: 0.0820218\n",
      "Validation loss decreased (0.077898 --> 0.077169).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792806\n",
      "\tspeed: 0.0394s/iter; left time: 825.4901s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804888\n",
      "\tspeed: 0.0179s/iter; left time: 373.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0788949 Vali Loss: 0.0769688 Test Loss: 0.0814737\n",
      "Validation loss decreased (0.077169 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805822\n",
      "\tspeed: 0.0417s/iter; left time: 865.1671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799717\n",
      "\tspeed: 0.0187s/iter; left time: 385.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0782915 Vali Loss: 0.0768342 Test Loss: 0.0813357\n",
      "Validation loss decreased (0.076969 --> 0.076834).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787869\n",
      "\tspeed: 0.0384s/iter; left time: 787.5092s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796126\n",
      "\tspeed: 0.0176s/iter; left time: 358.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777337 Vali Loss: 0.0765885 Test Loss: 0.0811092\n",
      "Validation loss decreased (0.076834 --> 0.076589).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0715174\n",
      "\tspeed: 0.0388s/iter; left time: 786.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0793800\n",
      "\tspeed: 0.0177s/iter; left time: 358.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0773026 Vali Loss: 0.0766290 Test Loss: 0.0812185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754477\n",
      "\tspeed: 0.0381s/iter; left time: 764.6416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789837\n",
      "\tspeed: 0.0178s/iter; left time: 354.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0767757 Vali Loss: 0.0764785 Test Loss: 0.0808268\n",
      "Validation loss decreased (0.076589 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715470\n",
      "\tspeed: 0.0443s/iter; left time: 879.6698s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762711\n",
      "\tspeed: 0.0199s/iter; left time: 392.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0764457 Vali Loss: 0.0764530 Test Loss: 0.0807678\n",
      "Validation loss decreased (0.076479 --> 0.076453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757492\n",
      "\tspeed: 0.0450s/iter; left time: 883.5416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821893\n",
      "\tspeed: 0.0204s/iter; left time: 397.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0761522 Vali Loss: 0.0763963 Test Loss: 0.0806580\n",
      "Validation loss decreased (0.076453 --> 0.076396).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764003\n",
      "\tspeed: 0.0461s/iter; left time: 894.1181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738080\n",
      "\tspeed: 0.0196s/iter; left time: 378.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0758944 Vali Loss: 0.0761132 Test Loss: 0.0809184\n",
      "Validation loss decreased (0.076396 --> 0.076113).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746748\n",
      "\tspeed: 0.0406s/iter; left time: 778.9004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0724435\n",
      "\tspeed: 0.0194s/iter; left time: 370.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0755759 Vali Loss: 0.0764618 Test Loss: 0.0805427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719663\n",
      "\tspeed: 0.0390s/iter; left time: 737.9347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0697170\n",
      "\tspeed: 0.0178s/iter; left time: 335.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0753819 Vali Loss: 0.0761848 Test Loss: 0.0806028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727296\n",
      "\tspeed: 0.0406s/iter; left time: 760.1802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727161\n",
      "\tspeed: 0.0177s/iter; left time: 330.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0750679 Vali Loss: 0.0762574 Test Loss: 0.0805783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725658\n",
      "\tspeed: 0.0381s/iter; left time: 703.8773s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764599\n",
      "\tspeed: 0.0178s/iter; left time: 327.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0748732 Vali Loss: 0.0761443 Test Loss: 0.0805745\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0747242\n",
      "\tspeed: 0.0466s/iter; left time: 851.3817s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744604\n",
      "\tspeed: 0.0214s/iter; left time: 388.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0746945 Vali Loss: 0.0761027 Test Loss: 0.0805595\n",
      "Validation loss decreased (0.076113 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739140\n",
      "\tspeed: 0.0443s/iter; left time: 798.5066s\n",
      "\titers: 200, epoch: 20 | loss: 0.0799948\n",
      "\tspeed: 0.0225s/iter; left time: 403.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0745287 Vali Loss: 0.0761509 Test Loss: 0.0804114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0718822\n",
      "\tspeed: 0.0403s/iter; left time: 719.0455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0686560\n",
      "\tspeed: 0.0197s/iter; left time: 348.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0743691 Vali Loss: 0.0761282 Test Loss: 0.0804886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756082\n",
      "\tspeed: 0.0382s/iter; left time: 671.8549s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743395\n",
      "\tspeed: 0.0176s/iter; left time: 307.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0742769 Vali Loss: 0.0762186 Test Loss: 0.0808756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802817\n",
      "\tspeed: 0.0395s/iter; left time: 686.2851s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747382\n",
      "\tspeed: 0.0194s/iter; left time: 334.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0740906 Vali Loss: 0.0761006 Test Loss: 0.0809374\n",
      "Validation loss decreased (0.076103 --> 0.076101).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0721726\n",
      "\tspeed: 0.0388s/iter; left time: 665.4127s\n",
      "\titers: 200, epoch: 24 | loss: 0.0764399\n",
      "\tspeed: 0.0179s/iter; left time: 305.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0739739 Vali Loss: 0.0763183 Test Loss: 0.0805535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0713016\n",
      "\tspeed: 0.0377s/iter; left time: 638.2618s\n",
      "\titers: 200, epoch: 25 | loss: 0.0763350\n",
      "\tspeed: 0.0177s/iter; left time: 297.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0739049 Vali Loss: 0.0761669 Test Loss: 0.0804498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704296\n",
      "\tspeed: 0.0396s/iter; left time: 661.2235s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738422\n",
      "\tspeed: 0.0211s/iter; left time: 350.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0737833 Vali Loss: 0.0761739 Test Loss: 0.0806323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736066\n",
      "\tspeed: 0.0397s/iter; left time: 654.4782s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724954\n",
      "\tspeed: 0.0181s/iter; left time: 295.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0737053 Vali Loss: 0.0761146 Test Loss: 0.0805858\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708030\n",
      "\tspeed: 0.0417s/iter; left time: 678.2211s\n",
      "\titers: 200, epoch: 28 | loss: 0.0726346\n",
      "\tspeed: 0.0224s/iter; left time: 361.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0736342 Vali Loss: 0.0761730 Test Loss: 0.0805067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0736985\n",
      "\tspeed: 0.0394s/iter; left time: 631.5932s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757324\n",
      "\tspeed: 0.0175s/iter; left time: 279.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0736515 Vali Loss: 0.0762277 Test Loss: 0.0805709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0738680\n",
      "\tspeed: 0.0382s/iter; left time: 604.3951s\n",
      "\titers: 200, epoch: 30 | loss: 0.0754899\n",
      "\tspeed: 0.0175s/iter; left time: 275.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0735729 Vali Loss: 0.0761100 Test Loss: 0.0804291\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0771352\n",
      "\tspeed: 0.0394s/iter; left time: 614.2084s\n",
      "\titers: 200, epoch: 31 | loss: 0.0740414\n",
      "\tspeed: 0.0175s/iter; left time: 271.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0734717 Vali Loss: 0.0763483 Test Loss: 0.0805765\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0702331\n",
      "\tspeed: 0.0375s/iter; left time: 576.6210s\n",
      "\titers: 200, epoch: 32 | loss: 0.0758914\n",
      "\tspeed: 0.0181s/iter; left time: 276.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0734446 Vali Loss: 0.0761305 Test Loss: 0.0804661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723481\n",
      "\tspeed: 0.0372s/iter; left time: 563.5045s\n",
      "\titers: 200, epoch: 33 | loss: 0.0725820\n",
      "\tspeed: 0.0176s/iter; left time: 264.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0733762 Vali Loss: 0.0761667 Test Loss: 0.0805655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018912920728325844, rmse:0.13752426207065582, mae:0.08093737810850143, rse:0.5199940204620361\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:21.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423216\n",
      "\tspeed: 0.0461s/iter; left time: 1023.0411s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238418\n",
      "\tspeed: 0.0180s/iter; left time: 397.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1487374 Vali Loss: 0.1077961 Test Loss: 0.1103803\n",
      "Validation loss decreased (inf --> 0.107796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939423\n",
      "\tspeed: 0.0391s/iter; left time: 860.2094s\n",
      "\titers: 200, epoch: 2 | loss: 0.0893055\n",
      "\tspeed: 0.0179s/iter; left time: 392.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0994013 Vali Loss: 0.0860546 Test Loss: 0.0906314\n",
      "Validation loss decreased (0.107796 --> 0.086055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925718\n",
      "\tspeed: 0.0395s/iter; left time: 859.8668s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874189\n",
      "\tspeed: 0.0179s/iter; left time: 387.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0890840 Vali Loss: 0.0842465 Test Loss: 0.0879599\n",
      "Validation loss decreased (0.086055 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881069\n",
      "\tspeed: 0.0411s/iter; left time: 885.5673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0894828\n",
      "\tspeed: 0.0193s/iter; left time: 413.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0864151 Vali Loss: 0.0837157 Test Loss: 0.0879383\n",
      "Validation loss decreased (0.084247 --> 0.083716).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829716\n",
      "\tspeed: 0.0404s/iter; left time: 860.1269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826994\n",
      "\tspeed: 0.0179s/iter; left time: 379.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0848429 Vali Loss: 0.0827259 Test Loss: 0.0875212\n",
      "Validation loss decreased (0.083716 --> 0.082726).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817767\n",
      "\tspeed: 0.0409s/iter; left time: 861.8152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862948\n",
      "\tspeed: 0.0193s/iter; left time: 404.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0836924 Vali Loss: 0.0822996 Test Loss: 0.0872402\n",
      "Validation loss decreased (0.082726 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838116\n",
      "\tspeed: 0.0392s/iter; left time: 818.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848943\n",
      "\tspeed: 0.0179s/iter; left time: 370.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0827538 Vali Loss: 0.0820797 Test Loss: 0.0871094\n",
      "Validation loss decreased (0.082300 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825785\n",
      "\tspeed: 0.0387s/iter; left time: 799.7960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793753\n",
      "\tspeed: 0.0179s/iter; left time: 366.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0820263 Vali Loss: 0.0822556 Test Loss: 0.0876831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795462\n",
      "\tspeed: 0.0425s/iter; left time: 868.7222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789129\n",
      "\tspeed: 0.0228s/iter; left time: 464.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0815050 Vali Loss: 0.0815729 Test Loss: 0.0867696\n",
      "Validation loss decreased (0.082080 --> 0.081573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811481\n",
      "\tspeed: 0.0412s/iter; left time: 831.2948s\n",
      "\titers: 200, epoch: 10 | loss: 0.0825071\n",
      "\tspeed: 0.0183s/iter; left time: 368.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0810133 Vali Loss: 0.0817944 Test Loss: 0.0868367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0821963\n",
      "\tspeed: 0.0398s/iter; left time: 794.0686s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761625\n",
      "\tspeed: 0.0208s/iter; left time: 413.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0805028 Vali Loss: 0.0818734 Test Loss: 0.0874601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0790672\n",
      "\tspeed: 0.0383s/iter; left time: 756.6160s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799741\n",
      "\tspeed: 0.0178s/iter; left time: 350.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0801906 Vali Loss: 0.0817134 Test Loss: 0.0878104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782696\n",
      "\tspeed: 0.0420s/iter; left time: 820.3538s\n",
      "\titers: 200, epoch: 13 | loss: 0.0798471\n",
      "\tspeed: 0.0206s/iter; left time: 400.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0798508 Vali Loss: 0.0815302 Test Loss: 0.0871841\n",
      "Validation loss decreased (0.081573 --> 0.081530).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773299\n",
      "\tspeed: 0.0454s/iter; left time: 876.7918s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797019\n",
      "\tspeed: 0.0185s/iter; left time: 354.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0794928 Vali Loss: 0.0817144 Test Loss: 0.0871146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0791878\n",
      "\tspeed: 0.0386s/iter; left time: 736.6542s\n",
      "\titers: 200, epoch: 15 | loss: 0.0850011\n",
      "\tspeed: 0.0180s/iter; left time: 341.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0791677 Vali Loss: 0.0815923 Test Loss: 0.0870508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0806760\n",
      "\tspeed: 0.0414s/iter; left time: 779.9618s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801392\n",
      "\tspeed: 0.0179s/iter; left time: 336.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0789298 Vali Loss: 0.0816933 Test Loss: 0.0873272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782162\n",
      "\tspeed: 0.0394s/iter; left time: 734.2989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770024\n",
      "\tspeed: 0.0182s/iter; left time: 337.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0786994 Vali Loss: 0.0814644 Test Loss: 0.0871423\n",
      "Validation loss decreased (0.081530 --> 0.081464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750689\n",
      "\tspeed: 0.0393s/iter; left time: 723.2489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0791912\n",
      "\tspeed: 0.0179s/iter; left time: 326.9713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0784913 Vali Loss: 0.0817581 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772508\n",
      "\tspeed: 0.0385s/iter; left time: 700.3244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0785425\n",
      "\tspeed: 0.0179s/iter; left time: 323.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0782302 Vali Loss: 0.0813190 Test Loss: 0.0870724\n",
      "Validation loss decreased (0.081464 --> 0.081319).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0796085\n",
      "\tspeed: 0.0418s/iter; left time: 750.8243s\n",
      "\titers: 200, epoch: 20 | loss: 0.0747003\n",
      "\tspeed: 0.0179s/iter; left time: 319.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0780742 Vali Loss: 0.0815029 Test Loss: 0.0872391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0798976\n",
      "\tspeed: 0.0385s/iter; left time: 682.9507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783784\n",
      "\tspeed: 0.0205s/iter; left time: 360.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0778642 Vali Loss: 0.0814129 Test Loss: 0.0872288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798767\n",
      "\tspeed: 0.0401s/iter; left time: 701.9505s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798330\n",
      "\tspeed: 0.0185s/iter; left time: 323.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0777549 Vali Loss: 0.0814658 Test Loss: 0.0875085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0734261\n",
      "\tspeed: 0.0395s/iter; left time: 683.3050s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779886\n",
      "\tspeed: 0.0181s/iter; left time: 311.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0775775 Vali Loss: 0.0814620 Test Loss: 0.0873106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789265\n",
      "\tspeed: 0.0384s/iter; left time: 655.8847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768867\n",
      "\tspeed: 0.0181s/iter; left time: 306.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0774439 Vali Loss: 0.0814374 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0773396\n",
      "\tspeed: 0.0389s/iter; left time: 655.6546s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760351\n",
      "\tspeed: 0.0185s/iter; left time: 310.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0773691 Vali Loss: 0.0813845 Test Loss: 0.0871841\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796533\n",
      "\tspeed: 0.0399s/iter; left time: 662.7052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0774103\n",
      "\tspeed: 0.0180s/iter; left time: 297.4635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0771835 Vali Loss: 0.0814663 Test Loss: 0.0871791\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742327\n",
      "\tspeed: 0.0372s/iter; left time: 610.6163s\n",
      "\titers: 200, epoch: 27 | loss: 0.0805335\n",
      "\tspeed: 0.0178s/iter; left time: 289.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0771259 Vali Loss: 0.0814744 Test Loss: 0.0872126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0766790\n",
      "\tspeed: 0.0381s/iter; left time: 616.6928s\n",
      "\titers: 200, epoch: 28 | loss: 0.0775495\n",
      "\tspeed: 0.0179s/iter; left time: 288.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0770471 Vali Loss: 0.0813009 Test Loss: 0.0870816\n",
      "Validation loss decreased (0.081319 --> 0.081301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0757094\n",
      "\tspeed: 0.0408s/iter; left time: 650.4701s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760654\n",
      "\tspeed: 0.0180s/iter; left time: 285.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0769555 Vali Loss: 0.0812396 Test Loss: 0.0871117\n",
      "Validation loss decreased (0.081301 --> 0.081240).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0767229\n",
      "\tspeed: 0.0404s/iter; left time: 635.6768s\n",
      "\titers: 200, epoch: 30 | loss: 0.0786787\n",
      "\tspeed: 0.0180s/iter; left time: 282.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0768584 Vali Loss: 0.0815030 Test Loss: 0.0869776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778194\n",
      "\tspeed: 0.0383s/iter; left time: 594.6005s\n",
      "\titers: 200, epoch: 31 | loss: 0.0778298\n",
      "\tspeed: 0.0178s/iter; left time: 274.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0767776 Vali Loss: 0.0813545 Test Loss: 0.0871082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0754501\n",
      "\tspeed: 0.0407s/iter; left time: 622.4346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764830\n",
      "\tspeed: 0.0179s/iter; left time: 272.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0767559 Vali Loss: 0.0812562 Test Loss: 0.0870397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0755639\n",
      "\tspeed: 0.0414s/iter; left time: 624.0858s\n",
      "\titers: 200, epoch: 33 | loss: 0.0777980\n",
      "\tspeed: 0.0204s/iter; left time: 305.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0767118 Vali Loss: 0.0814427 Test Loss: 0.0868835\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754135\n",
      "\tspeed: 0.0393s/iter; left time: 583.4103s\n",
      "\titers: 200, epoch: 34 | loss: 0.0785940\n",
      "\tspeed: 0.0180s/iter; left time: 264.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0766594 Vali Loss: 0.0814381 Test Loss: 0.0870054\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776752\n",
      "\tspeed: 0.0433s/iter; left time: 633.2336s\n",
      "\titers: 200, epoch: 35 | loss: 0.0752889\n",
      "\tspeed: 0.0219s/iter; left time: 318.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0766568 Vali Loss: 0.0813767 Test Loss: 0.0870404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0754985\n",
      "\tspeed: 0.0434s/iter; left time: 624.6602s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774933\n",
      "\tspeed: 0.0183s/iter; left time: 261.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0765844 Vali Loss: 0.0814429 Test Loss: 0.0870331\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0767131\n",
      "\tspeed: 0.0404s/iter; left time: 572.0861s\n",
      "\titers: 200, epoch: 37 | loss: 0.0771547\n",
      "\tspeed: 0.0180s/iter; left time: 253.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0765541 Vali Loss: 0.0814060 Test Loss: 0.0868510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0774624\n",
      "\tspeed: 0.0379s/iter; left time: 528.8624s\n",
      "\titers: 200, epoch: 38 | loss: 0.0765092\n",
      "\tspeed: 0.0180s/iter; left time: 249.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0765164 Vali Loss: 0.0814066 Test Loss: 0.0870728\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0766422\n",
      "\tspeed: 0.0387s/iter; left time: 531.8544s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785535\n",
      "\tspeed: 0.0204s/iter; left time: 278.2109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0765010 Vali Loss: 0.0812689 Test Loss: 0.0869280\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02109212428331375, rmse:0.14523127675056458, mae:0.08711174875497818, rse:0.5496454238891602\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1449288\n",
      "\tspeed: 0.0237s/iter; left time: 527.1092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275386\n",
      "\tspeed: 0.0189s/iter; left time: 416.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1514120 Vali Loss: 0.1083481 Test Loss: 0.1111070\n",
      "Validation loss decreased (inf --> 0.108348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964038\n",
      "\tspeed: 0.0406s/iter; left time: 891.5062s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950081\n",
      "\tspeed: 0.0182s/iter; left time: 397.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0995364 Vali Loss: 0.0861125 Test Loss: 0.0903715\n",
      "Validation loss decreased (0.108348 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903619\n",
      "\tspeed: 0.0439s/iter; left time: 955.2516s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892618\n",
      "\tspeed: 0.0180s/iter; left time: 388.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0891035 Vali Loss: 0.0844135 Test Loss: 0.0887872\n",
      "Validation loss decreased (0.086113 --> 0.084413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915347\n",
      "\tspeed: 0.0401s/iter; left time: 863.5181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848709\n",
      "\tspeed: 0.0179s/iter; left time: 384.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0866611 Vali Loss: 0.0836004 Test Loss: 0.0878691\n",
      "Validation loss decreased (0.084413 --> 0.083600).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874841\n",
      "\tspeed: 0.0425s/iter; left time: 906.4325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0879956\n",
      "\tspeed: 0.0203s/iter; left time: 430.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0851195 Vali Loss: 0.0828480 Test Loss: 0.0873044\n",
      "Validation loss decreased (0.083600 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839838\n",
      "\tspeed: 0.0420s/iter; left time: 885.0919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821068\n",
      "\tspeed: 0.0179s/iter; left time: 375.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0839008 Vali Loss: 0.0822585 Test Loss: 0.0870409\n",
      "Validation loss decreased (0.082848 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821517\n",
      "\tspeed: 0.0422s/iter; left time: 879.5556s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844231\n",
      "\tspeed: 0.0184s/iter; left time: 381.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0830070 Vali Loss: 0.0822771 Test Loss: 0.0872937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803021\n",
      "\tspeed: 0.0392s/iter; left time: 809.3280s\n",
      "\titers: 200, epoch: 8 | loss: 0.0812417\n",
      "\tspeed: 0.0180s/iter; left time: 368.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0822285 Vali Loss: 0.0821905 Test Loss: 0.0874587\n",
      "Validation loss decreased (0.082259 --> 0.082190).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808798\n",
      "\tspeed: 0.0417s/iter; left time: 851.4096s\n",
      "\titers: 200, epoch: 9 | loss: 0.0797862\n",
      "\tspeed: 0.0180s/iter; left time: 364.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0815818 Vali Loss: 0.0818749 Test Loss: 0.0877508\n",
      "Validation loss decreased (0.082190 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799902\n",
      "\tspeed: 0.0440s/iter; left time: 888.7792s\n",
      "\titers: 200, epoch: 10 | loss: 0.0788336\n",
      "\tspeed: 0.0186s/iter; left time: 372.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0810375 Vali Loss: 0.0815037 Test Loss: 0.0872590\n",
      "Validation loss decreased (0.081875 --> 0.081504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795319\n",
      "\tspeed: 0.0391s/iter; left time: 780.5435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794025\n",
      "\tspeed: 0.0180s/iter; left time: 357.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0806232 Vali Loss: 0.0819767 Test Loss: 0.0874538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821759\n",
      "\tspeed: 0.0420s/iter; left time: 829.3506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778371\n",
      "\tspeed: 0.0198s/iter; left time: 388.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0801564 Vali Loss: 0.0814462 Test Loss: 0.0873747\n",
      "Validation loss decreased (0.081504 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842263\n",
      "\tspeed: 0.0417s/iter; left time: 814.4622s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809889\n",
      "\tspeed: 0.0182s/iter; left time: 352.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0797804 Vali Loss: 0.0816962 Test Loss: 0.0877320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0751703\n",
      "\tspeed: 0.0421s/iter; left time: 811.9402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763598\n",
      "\tspeed: 0.0207s/iter; left time: 397.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0794535 Vali Loss: 0.0814359 Test Loss: 0.0876379\n",
      "Validation loss decreased (0.081446 --> 0.081436).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0789681\n",
      "\tspeed: 0.0400s/iter; left time: 763.7075s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766760\n",
      "\tspeed: 0.0180s/iter; left time: 342.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0791543 Vali Loss: 0.0809303 Test Loss: 0.0873543\n",
      "Validation loss decreased (0.081436 --> 0.080930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803362\n",
      "\tspeed: 0.0399s/iter; left time: 753.0844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774697\n",
      "\tspeed: 0.0182s/iter; left time: 341.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0788688 Vali Loss: 0.0816369 Test Loss: 0.0876021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0793249\n",
      "\tspeed: 0.0407s/iter; left time: 757.9852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790591\n",
      "\tspeed: 0.0200s/iter; left time: 370.2881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0786432 Vali Loss: 0.0810094 Test Loss: 0.0877025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760391\n",
      "\tspeed: 0.0409s/iter; left time: 753.7718s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795988\n",
      "\tspeed: 0.0204s/iter; left time: 374.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0784823 Vali Loss: 0.0814446 Test Loss: 0.0877750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0790216\n",
      "\tspeed: 0.0412s/iter; left time: 749.6815s\n",
      "\titers: 200, epoch: 19 | loss: 0.0839612\n",
      "\tspeed: 0.0182s/iter; left time: 328.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0782333 Vali Loss: 0.0810218 Test Loss: 0.0872108\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764522\n",
      "\tspeed: 0.0399s/iter; left time: 716.8600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756822\n",
      "\tspeed: 0.0180s/iter; left time: 321.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0780890 Vali Loss: 0.0807879 Test Loss: 0.0873520\n",
      "Validation loss decreased (0.080930 --> 0.080788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766985\n",
      "\tspeed: 0.0389s/iter; left time: 689.3043s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789640\n",
      "\tspeed: 0.0181s/iter; left time: 319.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0778664 Vali Loss: 0.0809161 Test Loss: 0.0873467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0807523\n",
      "\tspeed: 0.0377s/iter; left time: 660.2344s\n",
      "\titers: 200, epoch: 22 | loss: 0.0760726\n",
      "\tspeed: 0.0180s/iter; left time: 313.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0777179 Vali Loss: 0.0807275 Test Loss: 0.0872172\n",
      "Validation loss decreased (0.080788 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772732\n",
      "\tspeed: 0.0393s/iter; left time: 680.4143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791408\n",
      "\tspeed: 0.0183s/iter; left time: 314.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0775855 Vali Loss: 0.0809376 Test Loss: 0.0875355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0792675\n",
      "\tspeed: 0.0397s/iter; left time: 677.4338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0806082\n",
      "\tspeed: 0.0195s/iter; left time: 331.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0774288 Vali Loss: 0.0809761 Test Loss: 0.0873712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786049\n",
      "\tspeed: 0.0395s/iter; left time: 665.1974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782466\n",
      "\tspeed: 0.0180s/iter; left time: 301.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0773741 Vali Loss: 0.0809126 Test Loss: 0.0873566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797315\n",
      "\tspeed: 0.0417s/iter; left time: 694.0438s\n",
      "\titers: 200, epoch: 26 | loss: 0.0777119\n",
      "\tspeed: 0.0210s/iter; left time: 347.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0772352 Vali Loss: 0.0808808 Test Loss: 0.0872862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776568\n",
      "\tspeed: 0.0410s/iter; left time: 671.8824s\n",
      "\titers: 200, epoch: 27 | loss: 0.0756376\n",
      "\tspeed: 0.0179s/iter; left time: 291.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0771665 Vali Loss: 0.0809822 Test Loss: 0.0873216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762978\n",
      "\tspeed: 0.0376s/iter; left time: 608.6421s\n",
      "\titers: 200, epoch: 28 | loss: 0.0765274\n",
      "\tspeed: 0.0178s/iter; left time: 286.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0770732 Vali Loss: 0.0810418 Test Loss: 0.0872446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0719681\n",
      "\tspeed: 0.0379s/iter; left time: 605.4086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788069\n",
      "\tspeed: 0.0182s/iter; left time: 288.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0769719 Vali Loss: 0.0809646 Test Loss: 0.0873285\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789183\n",
      "\tspeed: 0.0404s/iter; left time: 635.3260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782066\n",
      "\tspeed: 0.0180s/iter; left time: 281.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0769468 Vali Loss: 0.0807314 Test Loss: 0.0870685\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808447\n",
      "\tspeed: 0.0380s/iter; left time: 589.4340s\n",
      "\titers: 200, epoch: 31 | loss: 0.0765283\n",
      "\tspeed: 0.0181s/iter; left time: 278.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0768495 Vali Loss: 0.0806943 Test Loss: 0.0872749\n",
      "Validation loss decreased (0.080727 --> 0.080694).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761573\n",
      "\tspeed: 0.0438s/iter; left time: 668.9799s\n",
      "\titers: 200, epoch: 32 | loss: 0.0757153\n",
      "\tspeed: 0.0182s/iter; left time: 276.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0768053 Vali Loss: 0.0808349 Test Loss: 0.0872295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775786\n",
      "\tspeed: 0.0419s/iter; left time: 631.6551s\n",
      "\titers: 200, epoch: 33 | loss: 0.0767409\n",
      "\tspeed: 0.0190s/iter; left time: 283.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0767355 Vali Loss: 0.0808667 Test Loss: 0.0871681\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757100\n",
      "\tspeed: 0.0388s/iter; left time: 576.0192s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774558\n",
      "\tspeed: 0.0180s/iter; left time: 265.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0767543 Vali Loss: 0.0808929 Test Loss: 0.0871076\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778735\n",
      "\tspeed: 0.0407s/iter; left time: 594.7343s\n",
      "\titers: 200, epoch: 35 | loss: 0.0775153\n",
      "\tspeed: 0.0189s/iter; left time: 274.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0766747 Vali Loss: 0.0807420 Test Loss: 0.0872145\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0747025\n",
      "\tspeed: 0.0386s/iter; left time: 555.6579s\n",
      "\titers: 200, epoch: 36 | loss: 0.0751638\n",
      "\tspeed: 0.0182s/iter; left time: 260.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766659 Vali Loss: 0.0808573 Test Loss: 0.0873167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0759581\n",
      "\tspeed: 0.0399s/iter; left time: 565.5094s\n",
      "\titers: 200, epoch: 37 | loss: 0.0804632\n",
      "\tspeed: 0.0189s/iter; left time: 265.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0766658 Vali Loss: 0.0808365 Test Loss: 0.0872206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0759550\n",
      "\tspeed: 0.0397s/iter; left time: 554.0831s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777812\n",
      "\tspeed: 0.0181s/iter; left time: 251.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766106 Vali Loss: 0.0808862 Test Loss: 0.0872444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806029\n",
      "\tspeed: 0.0399s/iter; left time: 548.0181s\n",
      "\titers: 200, epoch: 39 | loss: 0.0741781\n",
      "\tspeed: 0.0183s/iter; left time: 248.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0765723 Vali Loss: 0.0807692 Test Loss: 0.0871365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0759363\n",
      "\tspeed: 0.0406s/iter; left time: 548.8343s\n",
      "\titers: 200, epoch: 40 | loss: 0.0809224\n",
      "\tspeed: 0.0184s/iter; left time: 246.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0764995 Vali Loss: 0.0808269 Test Loss: 0.0872263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0751095\n",
      "\tspeed: 0.0400s/iter; left time: 531.8427s\n",
      "\titers: 200, epoch: 41 | loss: 0.0726962\n",
      "\tspeed: 0.0206s/iter; left time: 271.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0764408 Vali Loss: 0.0807421 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020868754014372826, rmse:0.14446021616458893, mae:0.08727487176656723, rse:0.5467272400856018\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:06.28s\n",
      "Intermediate time for IT: 00h:27m:20.07s\n",
      "Total time: 02h:04m:37.46s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1448  0.0877\n",
       "        96            0.0377  0.1941  0.1283\n",
       "        168           0.0393  0.1981  0.1339\n",
       "ES      24            0.0098  0.0988  0.0592\n",
       "        96            0.0185  0.1361  0.0861\n",
       "        168           0.0207  0.1439  0.0916\n",
       "FR      24            0.0100  0.1000  0.0548\n",
       "        96            0.0193  0.1390  0.0808\n",
       "        168           0.0213  0.1460  0.0868\n",
       "GB      24            0.0250  0.1582  0.0996\n",
       "        96            0.0418  0.2045  0.1395\n",
       "        168           0.0447  0.2115  0.1468\n",
       "IT      24            0.0101  0.1004  0.0567\n",
       "        96            0.0188  0.1371  0.0807\n",
       "        168           0.0210  0.1448  0.0872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_512.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1332144\n",
      "\tspeed: 0.0739s/iter; left time: 1641.4667s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229960\n",
      "\tspeed: 0.0557s/iter; left time: 1231.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 223 | Train Loss: 0.1358273 Vali Loss: 0.1260563 Test Loss: 0.1311544\n",
      "Validation loss decreased (inf --> 0.126056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0868122\n",
      "\tspeed: 0.0981s/iter; left time: 2155.1823s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820302\n",
      "\tspeed: 0.0557s/iter; left time: 1218.1033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0882056 Vali Loss: 0.0927888 Test Loss: 0.0949692\n",
      "Validation loss decreased (0.126056 --> 0.092789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0753110\n",
      "\tspeed: 0.0970s/iter; left time: 2110.9623s\n",
      "\titers: 200, epoch: 3 | loss: 0.0757236\n",
      "\tspeed: 0.0557s/iter; left time: 1205.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0788444 Vali Loss: 0.0894453 Test Loss: 0.0920496\n",
      "Validation loss decreased (0.092789 --> 0.089445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0791433\n",
      "\tspeed: 0.0980s/iter; left time: 2109.3909s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825152\n",
      "\tspeed: 0.0560s/iter; left time: 1199.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0767609 Vali Loss: 0.0887320 Test Loss: 0.0910566\n",
      "Validation loss decreased (0.089445 --> 0.088732).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760196\n",
      "\tspeed: 0.1003s/iter; left time: 2136.6525s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715352\n",
      "\tspeed: 0.0557s/iter; left time: 1180.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0754450 Vali Loss: 0.0889264 Test Loss: 0.0909010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798182\n",
      "\tspeed: 0.0978s/iter; left time: 2061.9008s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760352\n",
      "\tspeed: 0.0559s/iter; left time: 1172.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0743708 Vali Loss: 0.0882881 Test Loss: 0.0898762\n",
      "Validation loss decreased (0.088732 --> 0.088288).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732908\n",
      "\tspeed: 0.0976s/iter; left time: 2036.5197s\n",
      "\titers: 200, epoch: 7 | loss: 0.0716462\n",
      "\tspeed: 0.0558s/iter; left time: 1157.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0736464 Vali Loss: 0.0883676 Test Loss: 0.0901687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711929\n",
      "\tspeed: 0.0975s/iter; left time: 2012.4290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738796\n",
      "\tspeed: 0.0557s/iter; left time: 1144.0460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0730284 Vali Loss: 0.0872638 Test Loss: 0.0893016\n",
      "Validation loss decreased (0.088288 --> 0.087264).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718604\n",
      "\tspeed: 0.0974s/iter; left time: 1989.0109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724918\n",
      "\tspeed: 0.0557s/iter; left time: 1131.3802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0724477 Vali Loss: 0.0873610 Test Loss: 0.0892784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735393\n",
      "\tspeed: 0.0977s/iter; left time: 1973.5957s\n",
      "\titers: 200, epoch: 10 | loss: 0.0687648\n",
      "\tspeed: 0.0557s/iter; left time: 1119.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0722126 Vali Loss: 0.0868895 Test Loss: 0.0890840\n",
      "Validation loss decreased (0.087264 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0741503\n",
      "\tspeed: 0.0977s/iter; left time: 1950.5542s\n",
      "\titers: 200, epoch: 11 | loss: 0.0751265\n",
      "\tspeed: 0.0556s/iter; left time: 1105.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0719460 Vali Loss: 0.0867828 Test Loss: 0.0886687\n",
      "Validation loss decreased (0.086889 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0688678\n",
      "\tspeed: 0.0969s/iter; left time: 1913.2028s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754033\n",
      "\tspeed: 0.0558s/iter; left time: 1095.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0716845 Vali Loss: 0.0863442 Test Loss: 0.0887282\n",
      "Validation loss decreased (0.086783 --> 0.086344).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0660991\n",
      "\tspeed: 0.0971s/iter; left time: 1896.2582s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696966\n",
      "\tspeed: 0.0557s/iter; left time: 1082.7238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0713887 Vali Loss: 0.0863370 Test Loss: 0.0882716\n",
      "Validation loss decreased (0.086344 --> 0.086337).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0725164\n",
      "\tspeed: 0.0976s/iter; left time: 1884.3073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0659105\n",
      "\tspeed: 0.0556s/iter; left time: 1068.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0712591 Vali Loss: 0.0863522 Test Loss: 0.0883677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713117\n",
      "\tspeed: 0.0970s/iter; left time: 1851.5268s\n",
      "\titers: 200, epoch: 15 | loss: 0.0666008\n",
      "\tspeed: 0.0558s/iter; left time: 1058.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0710470 Vali Loss: 0.0864777 Test Loss: 0.0887146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0738203\n",
      "\tspeed: 0.0974s/iter; left time: 1836.1377s\n",
      "\titers: 200, epoch: 16 | loss: 0.0769220\n",
      "\tspeed: 0.0557s/iter; left time: 1045.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0708745 Vali Loss: 0.0861809 Test Loss: 0.0884529\n",
      "Validation loss decreased (0.086337 --> 0.086181).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0708035\n",
      "\tspeed: 0.0988s/iter; left time: 1841.3885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0764474\n",
      "\tspeed: 0.0557s/iter; left time: 1032.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0707748 Vali Loss: 0.0861680 Test Loss: 0.0882925\n",
      "Validation loss decreased (0.086181 --> 0.086168).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0686066\n",
      "\tspeed: 0.0977s/iter; left time: 1797.7864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0637440\n",
      "\tspeed: 0.0557s/iter; left time: 1019.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0705734 Vali Loss: 0.0859288 Test Loss: 0.0882091\n",
      "Validation loss decreased (0.086168 --> 0.085929).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716321\n",
      "\tspeed: 0.0975s/iter; left time: 1773.7313s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779866\n",
      "\tspeed: 0.0557s/iter; left time: 1007.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.59s\n",
      "Steps: 223 | Train Loss: 0.0705458 Vali Loss: 0.0859715 Test Loss: 0.0881990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0711506\n",
      "\tspeed: 0.1971s/iter; left time: 3541.5114s\n",
      "\titers: 200, epoch: 20 | loss: 0.0688243\n",
      "\tspeed: 0.0586s/iter; left time: 1046.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 223 | Train Loss: 0.0704459 Vali Loss: 0.0860364 Test Loss: 0.0881711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0696923\n",
      "\tspeed: 0.1037s/iter; left time: 1839.7463s\n",
      "\titers: 200, epoch: 21 | loss: 0.0741142\n",
      "\tspeed: 0.1406s/iter; left time: 2479.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:23.64s\n",
      "Steps: 223 | Train Loss: 0.0703798 Vali Loss: 0.0858786 Test Loss: 0.0881454\n",
      "Validation loss decreased (0.085929 --> 0.085879).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712104\n",
      "\tspeed: 0.2403s/iter; left time: 4209.2540s\n",
      "\titers: 200, epoch: 22 | loss: 0.0711397\n",
      "\tspeed: 0.0558s/iter; left time: 971.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 223 | Train Loss: 0.0702365 Vali Loss: 0.0858019 Test Loss: 0.0882561\n",
      "Validation loss decreased (0.085879 --> 0.085802).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0722965\n",
      "\tspeed: 0.0973s/iter; left time: 1682.5152s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714301\n",
      "\tspeed: 0.0556s/iter; left time: 956.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0702496 Vali Loss: 0.0856940 Test Loss: 0.0880869\n",
      "Validation loss decreased (0.085802 --> 0.085694).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0729966\n",
      "\tspeed: 0.0972s/iter; left time: 1659.1227s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680063\n",
      "\tspeed: 0.0557s/iter; left time: 945.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0700992 Vali Loss: 0.0857747 Test Loss: 0.0881663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0697086\n",
      "\tspeed: 0.0964s/iter; left time: 1623.6354s\n",
      "\titers: 200, epoch: 25 | loss: 0.0660151\n",
      "\tspeed: 0.0556s/iter; left time: 932.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0700257 Vali Loss: 0.0856531 Test Loss: 0.0879749\n",
      "Validation loss decreased (0.085694 --> 0.085653).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0688517\n",
      "\tspeed: 0.0974s/iter; left time: 1619.7967s\n",
      "\titers: 200, epoch: 26 | loss: 0.0606614\n",
      "\tspeed: 0.0557s/iter; left time: 920.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0699975 Vali Loss: 0.0857388 Test Loss: 0.0880380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0686153\n",
      "\tspeed: 0.0961s/iter; left time: 1576.8762s\n",
      "\titers: 200, epoch: 27 | loss: 0.0720461\n",
      "\tspeed: 0.0557s/iter; left time: 907.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0699892 Vali Loss: 0.0856320 Test Loss: 0.0880470\n",
      "Validation loss decreased (0.085653 --> 0.085632).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0720013\n",
      "\tspeed: 0.0964s/iter; left time: 1560.2263s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707490\n",
      "\tspeed: 0.0557s/iter; left time: 895.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0699229 Vali Loss: 0.0855001 Test Loss: 0.0879894\n",
      "Validation loss decreased (0.085632 --> 0.085500).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0708807\n",
      "\tspeed: 0.0973s/iter; left time: 1552.7180s\n",
      "\titers: 200, epoch: 29 | loss: 0.0707058\n",
      "\tspeed: 0.0557s/iter; left time: 882.5779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0699270 Vali Loss: 0.0854612 Test Loss: 0.0880216\n",
      "Validation loss decreased (0.085500 --> 0.085461).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0710514\n",
      "\tspeed: 0.0971s/iter; left time: 1528.0552s\n",
      "\titers: 200, epoch: 30 | loss: 0.0662546\n",
      "\tspeed: 0.0557s/iter; left time: 870.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0698292 Vali Loss: 0.0856229 Test Loss: 0.0880136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0734654\n",
      "\tspeed: 0.0966s/iter; left time: 1497.6724s\n",
      "\titers: 200, epoch: 31 | loss: 0.0677515\n",
      "\tspeed: 0.0598s/iter; left time: 921.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.98s\n",
      "Steps: 223 | Train Loss: 0.0698069 Vali Loss: 0.0854874 Test Loss: 0.0878906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712474\n",
      "\tspeed: 0.1011s/iter; left time: 1545.5408s\n",
      "\titers: 200, epoch: 32 | loss: 0.0654372\n",
      "\tspeed: 0.0557s/iter; left time: 846.0904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0697557 Vali Loss: 0.0854843 Test Loss: 0.0879423\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0690423\n",
      "\tspeed: 0.0965s/iter; left time: 1453.1797s\n",
      "\titers: 200, epoch: 33 | loss: 0.0679753\n",
      "\tspeed: 0.0557s/iter; left time: 833.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0696973 Vali Loss: 0.0855460 Test Loss: 0.0879180\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0715394\n",
      "\tspeed: 0.0974s/iter; left time: 1445.0831s\n",
      "\titers: 200, epoch: 34 | loss: 0.0750787\n",
      "\tspeed: 0.0557s/iter; left time: 820.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0697239 Vali Loss: 0.0854108 Test Loss: 0.0879490\n",
      "Validation loss decreased (0.085461 --> 0.085411).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0690634\n",
      "\tspeed: 0.0970s/iter; left time: 1417.6459s\n",
      "\titers: 200, epoch: 35 | loss: 0.0721469\n",
      "\tspeed: 0.0556s/iter; left time: 807.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0696829 Vali Loss: 0.0855239 Test Loss: 0.0879045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0645434\n",
      "\tspeed: 0.0963s/iter; left time: 1386.0281s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615992\n",
      "\tspeed: 0.0557s/iter; left time: 795.6057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0697068 Vali Loss: 0.0854764 Test Loss: 0.0879015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0672771\n",
      "\tspeed: 0.0961s/iter; left time: 1361.8382s\n",
      "\titers: 200, epoch: 37 | loss: 0.0621125\n",
      "\tspeed: 0.0557s/iter; left time: 783.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0696620 Vali Loss: 0.0854599 Test Loss: 0.0879198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677729\n",
      "\tspeed: 0.0970s/iter; left time: 1353.8420s\n",
      "\titers: 200, epoch: 38 | loss: 0.0694276\n",
      "\tspeed: 0.0557s/iter; left time: 770.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0696719 Vali Loss: 0.0854918 Test Loss: 0.0879481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0696932\n",
      "\tspeed: 0.0971s/iter; left time: 1333.2887s\n",
      "\titers: 200, epoch: 39 | loss: 0.0687645\n",
      "\tspeed: 0.0557s/iter; left time: 758.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0696647 Vali Loss: 0.0855289 Test Loss: 0.0879689\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0642762\n",
      "\tspeed: 0.0973s/iter; left time: 1314.1102s\n",
      "\titers: 200, epoch: 40 | loss: 0.0678461\n",
      "\tspeed: 0.0557s/iter; left time: 746.1651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0696252 Vali Loss: 0.0854736 Test Loss: 0.0878735\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0698427\n",
      "\tspeed: 0.0987s/iter; left time: 1311.2121s\n",
      "\titers: 200, epoch: 41 | loss: 0.0653338\n",
      "\tspeed: 0.0557s/iter; left time: 734.1025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 223 | Train Loss: 0.0696694 Vali Loss: 0.0853362 Test Loss: 0.0879158\n",
      "Validation loss decreased (0.085411 --> 0.085336).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0717271\n",
      "\tspeed: 0.1739s/iter; left time: 2271.2466s\n",
      "\titers: 200, epoch: 42 | loss: 0.0678519\n",
      "\tspeed: 0.0590s/iter; left time: 764.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:20.30s\n",
      "Steps: 223 | Train Loss: 0.0696300 Vali Loss: 0.0855636 Test Loss: 0.0878947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0661314\n",
      "\tspeed: 0.0969s/iter; left time: 1243.8776s\n",
      "\titers: 200, epoch: 43 | loss: 0.0704750\n",
      "\tspeed: 0.0556s/iter; left time: 708.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0695907 Vali Loss: 0.0854893 Test Loss: 0.0878903\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0704460\n",
      "\tspeed: 0.0958s/iter; left time: 1208.1613s\n",
      "\titers: 200, epoch: 44 | loss: 0.0706366\n",
      "\tspeed: 0.0556s/iter; left time: 695.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0696234 Vali Loss: 0.0853781 Test Loss: 0.0879172\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0717367\n",
      "\tspeed: 0.0991s/iter; left time: 1227.6265s\n",
      "\titers: 200, epoch: 45 | loss: 0.0698064\n",
      "\tspeed: 0.0566s/iter; left time: 695.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 223 | Train Loss: 0.0695847 Vali Loss: 0.0853864 Test Loss: 0.0879186\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0661803\n",
      "\tspeed: 0.3822s/iter; left time: 4649.6345s\n",
      "\titers: 200, epoch: 46 | loss: 0.0637130\n",
      "\tspeed: 0.1979s/iter; left time: 2387.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 223 | Train Loss: 0.0695895 Vali Loss: 0.0854397 Test Loss: 0.0879578\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0707999\n",
      "\tspeed: 0.4448s/iter; left time: 5312.2584s\n",
      "\titers: 200, epoch: 47 | loss: 0.0674502\n",
      "\tspeed: 0.2049s/iter; left time: 2426.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:44.92s\n",
      "Steps: 223 | Train Loss: 0.0695607 Vali Loss: 0.0854818 Test Loss: 0.0879332\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0653478\n",
      "\tspeed: 0.4403s/iter; left time: 5159.8858s\n",
      "\titers: 200, epoch: 48 | loss: 0.0760485\n",
      "\tspeed: 0.1901s/iter; left time: 2208.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 223 | Train Loss: 0.0695990 Vali Loss: 0.0855168 Test Loss: 0.0878915\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0666074\n",
      "\tspeed: 0.4195s/iter; left time: 4822.5781s\n",
      "\titers: 200, epoch: 49 | loss: 0.0666795\n",
      "\tspeed: 0.0937s/iter; left time: 1068.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:30.52s\n",
      "Steps: 223 | Train Loss: 0.0695911 Vali Loss: 0.0854137 Test Loss: 0.0878726\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0674558\n",
      "\tspeed: 0.1339s/iter; left time: 1509.6432s\n",
      "\titers: 200, epoch: 50 | loss: 0.0675304\n",
      "\tspeed: 0.0566s/iter; left time: 632.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 223 | Train Loss: 0.0695212 Vali Loss: 0.0853814 Test Loss: 0.0879392\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0730881\n",
      "\tspeed: 0.1021s/iter; left time: 1128.5975s\n",
      "\titers: 200, epoch: 51 | loss: 0.0706381\n",
      "\tspeed: 0.0564s/iter; left time: 617.7231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:12.85s\n",
      "Steps: 223 | Train Loss: 0.0695619 Vali Loss: 0.0853749 Test Loss: 0.0879278\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02084571123123169, rmse:0.14438043534755707, mae:0.08791576325893402, rse:0.5095385909080505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1321949\n",
      "\tspeed: 0.0585s/iter; left time: 1297.8655s\n",
      "\titers: 200, epoch: 1 | loss: 0.1195247\n",
      "\tspeed: 0.0563s/iter; left time: 1244.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 223 | Train Loss: 0.1355204 Vali Loss: 0.1248920 Test Loss: 0.1302046\n",
      "Validation loss decreased (inf --> 0.124892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869159\n",
      "\tspeed: 0.1001s/iter; left time: 2200.7431s\n",
      "\titers: 200, epoch: 2 | loss: 0.0792214\n",
      "\tspeed: 0.0562s/iter; left time: 1230.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 223 | Train Loss: 0.0882127 Vali Loss: 0.0918631 Test Loss: 0.0943182\n",
      "Validation loss decreased (0.124892 --> 0.091863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820515\n",
      "\tspeed: 0.1003s/iter; left time: 2181.7006s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794274\n",
      "\tspeed: 0.0562s/iter; left time: 1216.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 223 | Train Loss: 0.0791551 Vali Loss: 0.0898517 Test Loss: 0.0931835\n",
      "Validation loss decreased (0.091863 --> 0.089852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0748319\n",
      "\tspeed: 0.1004s/iter; left time: 2161.6282s\n",
      "\titers: 200, epoch: 4 | loss: 0.0758545\n",
      "\tspeed: 0.0562s/iter; left time: 1203.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 223 | Train Loss: 0.0770344 Vali Loss: 0.0888502 Test Loss: 0.0912462\n",
      "Validation loss decreased (0.089852 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0794775\n",
      "\tspeed: 0.0996s/iter; left time: 2121.9133s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783038\n",
      "\tspeed: 0.0561s/iter; left time: 1189.6976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 223 | Train Loss: 0.0755707 Vali Loss: 0.0883333 Test Loss: 0.0905530\n",
      "Validation loss decreased (0.088850 --> 0.088333).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737492\n",
      "\tspeed: 0.0998s/iter; left time: 2104.7996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699851\n",
      "\tspeed: 0.0560s/iter; left time: 1175.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 223 | Train Loss: 0.0745040 Vali Loss: 0.0882450 Test Loss: 0.0902655\n",
      "Validation loss decreased (0.088333 --> 0.088245).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0761966\n",
      "\tspeed: 0.0986s/iter; left time: 2056.8633s\n",
      "\titers: 200, epoch: 7 | loss: 0.0732298\n",
      "\tspeed: 0.0559s/iter; left time: 1161.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0737765 Vali Loss: 0.0872415 Test Loss: 0.0893371\n",
      "Validation loss decreased (0.088245 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0738960\n",
      "\tspeed: 0.0981s/iter; left time: 2025.0048s\n",
      "\titers: 200, epoch: 8 | loss: 0.0792185\n",
      "\tspeed: 0.0559s/iter; left time: 1148.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0730418 Vali Loss: 0.0870644 Test Loss: 0.0889776\n",
      "Validation loss decreased (0.087241 --> 0.087064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0699037\n",
      "\tspeed: 0.0981s/iter; left time: 2003.0031s\n",
      "\titers: 200, epoch: 9 | loss: 0.0689672\n",
      "\tspeed: 0.0560s/iter; left time: 1137.1824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 223 | Train Loss: 0.0725071 Vali Loss: 0.0869053 Test Loss: 0.0892861\n",
      "Validation loss decreased (0.087064 --> 0.086905).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692783\n",
      "\tspeed: 0.0987s/iter; left time: 1993.4443s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771821\n",
      "\tspeed: 0.0560s/iter; left time: 1125.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0722507 Vali Loss: 0.0868102 Test Loss: 0.0888723\n",
      "Validation loss decreased (0.086905 --> 0.086810).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0732150\n",
      "\tspeed: 0.0988s/iter; left time: 1973.0183s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711397\n",
      "\tspeed: 0.0560s/iter; left time: 1112.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0718777 Vali Loss: 0.0862361 Test Loss: 0.0886134\n",
      "Validation loss decreased (0.086810 --> 0.086236).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752613\n",
      "\tspeed: 0.0996s/iter; left time: 1965.9867s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696609\n",
      "\tspeed: 0.0560s/iter; left time: 1099.6293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.0715555 Vali Loss: 0.0862368 Test Loss: 0.0885744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0696154\n",
      "\tspeed: 0.0978s/iter; left time: 1910.4225s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712538\n",
      "\tspeed: 0.0559s/iter; left time: 1086.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0713454 Vali Loss: 0.0865776 Test Loss: 0.0886776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710302\n",
      "\tspeed: 0.0976s/iter; left time: 1883.5708s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697807\n",
      "\tspeed: 0.0560s/iter; left time: 1075.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0710154 Vali Loss: 0.0861612 Test Loss: 0.0887227\n",
      "Validation loss decreased (0.086236 --> 0.086161).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721809\n",
      "\tspeed: 0.0984s/iter; left time: 1876.4410s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740700\n",
      "\tspeed: 0.0560s/iter; left time: 1062.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0708765 Vali Loss: 0.0859608 Test Loss: 0.0887293\n",
      "Validation loss decreased (0.086161 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704648\n",
      "\tspeed: 0.0982s/iter; left time: 1852.1776s\n",
      "\titers: 200, epoch: 16 | loss: 0.0707092\n",
      "\tspeed: 0.0560s/iter; left time: 1050.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0707461 Vali Loss: 0.0859768 Test Loss: 0.0884334\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0682754\n",
      "\tspeed: 0.0983s/iter; left time: 1831.9460s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726420\n",
      "\tspeed: 0.0558s/iter; left time: 1033.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 223 | Train Loss: 0.0705416 Vali Loss: 0.0860883 Test Loss: 0.0883619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0666464\n",
      "\tspeed: 0.0985s/iter; left time: 1814.0579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0721241\n",
      "\tspeed: 0.0560s/iter; left time: 1024.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0704308 Vali Loss: 0.0858410 Test Loss: 0.0884350\n",
      "Validation loss decreased (0.085961 --> 0.085841).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720225\n",
      "\tspeed: 0.0998s/iter; left time: 1814.5629s\n",
      "\titers: 200, epoch: 19 | loss: 0.0684079\n",
      "\tspeed: 0.0559s/iter; left time: 1011.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0703177 Vali Loss: 0.0862782 Test Loss: 0.0886609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747698\n",
      "\tspeed: 0.0981s/iter; left time: 1762.9499s\n",
      "\titers: 200, epoch: 20 | loss: 0.0740259\n",
      "\tspeed: 0.0557s/iter; left time: 995.5033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0702077 Vali Loss: 0.0857407 Test Loss: 0.0881165\n",
      "Validation loss decreased (0.085841 --> 0.085741).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0676428\n",
      "\tspeed: 0.0986s/iter; left time: 1749.5794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731598\n",
      "\tspeed: 0.0557s/iter; left time: 982.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0700955 Vali Loss: 0.0856354 Test Loss: 0.0884902\n",
      "Validation loss decreased (0.085741 --> 0.085635).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0673825\n",
      "\tspeed: 0.0981s/iter; left time: 1718.5668s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733292\n",
      "\tspeed: 0.0559s/iter; left time: 972.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0700543 Vali Loss: 0.0858868 Test Loss: 0.0882234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0761369\n",
      "\tspeed: 0.0983s/iter; left time: 1699.9604s\n",
      "\titers: 200, epoch: 23 | loss: 0.0708756\n",
      "\tspeed: 0.0558s/iter; left time: 959.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.0699498 Vali Loss: 0.0855788 Test Loss: 0.0882074\n",
      "Validation loss decreased (0.085635 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0689597\n",
      "\tspeed: 0.0981s/iter; left time: 1674.3440s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710519\n",
      "\tspeed: 0.0556s/iter; left time: 944.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0698366 Vali Loss: 0.0856740 Test Loss: 0.0882654\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673283\n",
      "\tspeed: 0.0978s/iter; left time: 1647.4443s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701892\n",
      "\tspeed: 0.0556s/iter; left time: 930.9707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0698020 Vali Loss: 0.0855684 Test Loss: 0.0883306\n",
      "Validation loss decreased (0.085579 --> 0.085568).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654884\n",
      "\tspeed: 0.0986s/iter; left time: 1639.9428s\n",
      "\titers: 200, epoch: 26 | loss: 0.0740729\n",
      "\tspeed: 0.0556s/iter; left time: 918.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0697329 Vali Loss: 0.0856214 Test Loss: 0.0882084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697414\n",
      "\tspeed: 0.0977s/iter; left time: 1603.2724s\n",
      "\titers: 200, epoch: 27 | loss: 0.0663603\n",
      "\tspeed: 0.0556s/iter; left time: 906.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0697158 Vali Loss: 0.0856465 Test Loss: 0.0883860\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0733333\n",
      "\tspeed: 0.0978s/iter; left time: 1581.8238s\n",
      "\titers: 200, epoch: 28 | loss: 0.0680581\n",
      "\tspeed: 0.0557s/iter; left time: 894.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0696312 Vali Loss: 0.0855474 Test Loss: 0.0882996\n",
      "Validation loss decreased (0.085568 --> 0.085547).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0695887\n",
      "\tspeed: 0.0984s/iter; left time: 1570.6086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0727355\n",
      "\tspeed: 0.0556s/iter; left time: 881.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0695944 Vali Loss: 0.0855103 Test Loss: 0.0882742\n",
      "Validation loss decreased (0.085547 --> 0.085510).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0654744\n",
      "\tspeed: 0.0980s/iter; left time: 1541.6680s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713100\n",
      "\tspeed: 0.0556s/iter; left time: 869.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0695733 Vali Loss: 0.0854913 Test Loss: 0.0881864\n",
      "Validation loss decreased (0.085510 --> 0.085491).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699294\n",
      "\tspeed: 0.0995s/iter; left time: 1543.0130s\n",
      "\titers: 200, epoch: 31 | loss: 0.0719529\n",
      "\tspeed: 0.0556s/iter; left time: 856.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694808 Vali Loss: 0.0855194 Test Loss: 0.0882467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0717089\n",
      "\tspeed: 0.0982s/iter; left time: 1501.4923s\n",
      "\titers: 200, epoch: 32 | loss: 0.0716076\n",
      "\tspeed: 0.0556s/iter; left time: 843.8282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0695085 Vali Loss: 0.0855041 Test Loss: 0.0881491\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0678412\n",
      "\tspeed: 0.0976s/iter; left time: 1469.7178s\n",
      "\titers: 200, epoch: 33 | loss: 0.0721972\n",
      "\tspeed: 0.0558s/iter; left time: 834.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694701 Vali Loss: 0.0854765 Test Loss: 0.0881829\n",
      "Validation loss decreased (0.085491 --> 0.085477).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687791\n",
      "\tspeed: 0.0981s/iter; left time: 1455.8451s\n",
      "\titers: 200, epoch: 34 | loss: 0.0698830\n",
      "\tspeed: 0.0557s/iter; left time: 820.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0694615 Vali Loss: 0.0854668 Test Loss: 0.0881900\n",
      "Validation loss decreased (0.085477 --> 0.085467).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0780406\n",
      "\tspeed: 0.0988s/iter; left time: 1444.6798s\n",
      "\titers: 200, epoch: 35 | loss: 0.0692534\n",
      "\tspeed: 0.0557s/iter; left time: 808.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0694168 Vali Loss: 0.0854433 Test Loss: 0.0881925\n",
      "Validation loss decreased (0.085467 --> 0.085443).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702760\n",
      "\tspeed: 0.0983s/iter; left time: 1414.6276s\n",
      "\titers: 200, epoch: 36 | loss: 0.0728263\n",
      "\tspeed: 0.0558s/iter; left time: 797.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694150 Vali Loss: 0.0854202 Test Loss: 0.0882087\n",
      "Validation loss decreased (0.085443 --> 0.085420).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0724953\n",
      "\tspeed: 0.0993s/iter; left time: 1406.7536s\n",
      "\titers: 200, epoch: 37 | loss: 0.0703829\n",
      "\tspeed: 0.0557s/iter; left time: 783.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0694151 Vali Loss: 0.0854038 Test Loss: 0.0881835\n",
      "Validation loss decreased (0.085420 --> 0.085404).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0660174\n",
      "\tspeed: 0.0988s/iter; left time: 1378.2318s\n",
      "\titers: 200, epoch: 38 | loss: 0.0667294\n",
      "\tspeed: 0.0557s/iter; left time: 771.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0693594 Vali Loss: 0.0854219 Test Loss: 0.0882360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0672446\n",
      "\tspeed: 0.0980s/iter; left time: 1344.5821s\n",
      "\titers: 200, epoch: 39 | loss: 0.0719632\n",
      "\tspeed: 0.0556s/iter; left time: 757.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0694173 Vali Loss: 0.0854895 Test Loss: 0.0882136\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0677967\n",
      "\tspeed: 0.0974s/iter; left time: 1315.8969s\n",
      "\titers: 200, epoch: 40 | loss: 0.0689068\n",
      "\tspeed: 0.0556s/iter; left time: 744.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0693307 Vali Loss: 0.0854681 Test Loss: 0.0881989\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0681659\n",
      "\tspeed: 0.0972s/iter; left time: 1291.0549s\n",
      "\titers: 200, epoch: 41 | loss: 0.0671629\n",
      "\tspeed: 0.0555s/iter; left time: 731.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0692700 Vali Loss: 0.0854146 Test Loss: 0.0881918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682741\n",
      "\tspeed: 0.0978s/iter; left time: 1277.6139s\n",
      "\titers: 200, epoch: 42 | loss: 0.0739376\n",
      "\tspeed: 0.0556s/iter; left time: 719.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0692600 Vali Loss: 0.0854725 Test Loss: 0.0882275\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0713579\n",
      "\tspeed: 0.0973s/iter; left time: 1249.4545s\n",
      "\titers: 200, epoch: 43 | loss: 0.0718290\n",
      "\tspeed: 0.0556s/iter; left time: 708.1053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0693000 Vali Loss: 0.0854612 Test Loss: 0.0882292\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0687260\n",
      "\tspeed: 0.0981s/iter; left time: 1237.7862s\n",
      "\titers: 200, epoch: 44 | loss: 0.0746944\n",
      "\tspeed: 0.0555s/iter; left time: 695.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0693090 Vali Loss: 0.0854083 Test Loss: 0.0882302\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0692354\n",
      "\tspeed: 0.0980s/iter; left time: 1214.4327s\n",
      "\titers: 200, epoch: 45 | loss: 0.0661913\n",
      "\tspeed: 0.0557s/iter; left time: 684.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0692688 Vali Loss: 0.0854105 Test Loss: 0.0882326\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0687669\n",
      "\tspeed: 0.0977s/iter; left time: 1188.5401s\n",
      "\titers: 200, epoch: 46 | loss: 0.0675251\n",
      "\tspeed: 0.0557s/iter; left time: 672.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0692543 Vali Loss: 0.0854415 Test Loss: 0.0882191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0708708\n",
      "\tspeed: 0.0972s/iter; left time: 1160.2913s\n",
      "\titers: 200, epoch: 47 | loss: 0.0699173\n",
      "\tspeed: 0.0556s/iter; left time: 658.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0692846 Vali Loss: 0.0854284 Test Loss: 0.0882030\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02115781232714653, rmse:0.14545725286006927, mae:0.08818355202674866, rse:0.5133388042449951\n",
      "Intermediate time for DE and pred_len 24: 00h:29m:00.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1386770\n",
      "\tspeed: 0.0732s/iter; left time: 1617.9581s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275029\n",
      "\tspeed: 0.0561s/iter; left time: 1234.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 222 | Train Loss: 0.1436589 Vali Loss: 0.1367227 Test Loss: 0.1443707\n",
      "Validation loss decreased (inf --> 0.136723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1119815\n",
      "\tspeed: 0.0975s/iter; left time: 2133.7373s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102261\n",
      "\tspeed: 0.0560s/iter; left time: 1219.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.1122268 Vali Loss: 0.1208071 Test Loss: 0.1275149\n",
      "Validation loss decreased (0.136723 --> 0.120807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020786\n",
      "\tspeed: 0.1001s/iter; left time: 2168.2093s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071238\n",
      "\tspeed: 0.0560s/iter; left time: 1207.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.1050913 Vali Loss: 0.1187858 Test Loss: 0.1260760\n",
      "Validation loss decreased (0.120807 --> 0.118786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993240\n",
      "\tspeed: 0.0982s/iter; left time: 2104.2546s\n",
      "\titers: 200, epoch: 4 | loss: 0.1062713\n",
      "\tspeed: 0.0559s/iter; left time: 1192.9190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 222 | Train Loss: 0.1032697 Vali Loss: 0.1184309 Test Loss: 0.1263589\n",
      "Validation loss decreased (0.118786 --> 0.118431).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1071941\n",
      "\tspeed: 0.0989s/iter; left time: 2097.1131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1011960\n",
      "\tspeed: 0.0561s/iter; left time: 1183.5208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1018686 Vali Loss: 0.1174367 Test Loss: 0.1259556\n",
      "Validation loss decreased (0.118431 --> 0.117437).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0985333\n",
      "\tspeed: 0.0983s/iter; left time: 2062.7188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0995864\n",
      "\tspeed: 0.0561s/iter; left time: 1171.1833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1008020 Vali Loss: 0.1173732 Test Loss: 0.1252204\n",
      "Validation loss decreased (0.117437 --> 0.117373).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983450\n",
      "\tspeed: 0.0993s/iter; left time: 2062.8763s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028825\n",
      "\tspeed: 0.0561s/iter; left time: 1158.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0997352 Vali Loss: 0.1163223 Test Loss: 0.1250026\n",
      "Validation loss decreased (0.117373 --> 0.116322).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0966778\n",
      "\tspeed: 0.1006s/iter; left time: 2067.5907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981909\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0990780 Vali Loss: 0.1164870 Test Loss: 0.1249006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0970541\n",
      "\tspeed: 0.0981s/iter; left time: 1994.2145s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927569\n",
      "\tspeed: 0.0562s/iter; left time: 1136.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0982853 Vali Loss: 0.1163101 Test Loss: 0.1247123\n",
      "Validation loss decreased (0.116322 --> 0.116310).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004419\n",
      "\tspeed: 0.0987s/iter; left time: 1984.2426s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027958\n",
      "\tspeed: 0.0561s/iter; left time: 1122.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0977100 Vali Loss: 0.1168362 Test Loss: 0.1261414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0973103\n",
      "\tspeed: 0.0985s/iter; left time: 1957.3190s\n",
      "\titers: 200, epoch: 11 | loss: 0.0973775\n",
      "\tspeed: 0.0561s/iter; left time: 1109.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0972067 Vali Loss: 0.1165401 Test Loss: 0.1248463\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0943016\n",
      "\tspeed: 0.0979s/iter; left time: 1925.0397s\n",
      "\titers: 200, epoch: 12 | loss: 0.0890948\n",
      "\tspeed: 0.0559s/iter; left time: 1094.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 222 | Train Loss: 0.0967826 Vali Loss: 0.1167771 Test Loss: 0.1255921\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0919507\n",
      "\tspeed: 0.0975s/iter; left time: 1894.2783s\n",
      "\titers: 200, epoch: 13 | loss: 0.0924439\n",
      "\tspeed: 0.0561s/iter; left time: 1084.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0964317 Vali Loss: 0.1169391 Test Loss: 0.1255141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920366\n",
      "\tspeed: 0.0979s/iter; left time: 1881.9140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965247\n",
      "\tspeed: 0.0560s/iter; left time: 1071.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0958845 Vali Loss: 0.1169356 Test Loss: 0.1257542\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0993237\n",
      "\tspeed: 0.0979s/iter; left time: 1858.6467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0994493\n",
      "\tspeed: 0.0560s/iter; left time: 1058.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0956289 Vali Loss: 0.1167035 Test Loss: 0.1253432\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000477\n",
      "\tspeed: 0.0982s/iter; left time: 1843.9902s\n",
      "\titers: 200, epoch: 16 | loss: 0.0847670\n",
      "\tspeed: 0.0560s/iter; left time: 1046.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0952643 Vali Loss: 0.1171782 Test Loss: 0.1261246\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0950092\n",
      "\tspeed: 0.0981s/iter; left time: 1818.7499s\n",
      "\titers: 200, epoch: 17 | loss: 0.0940945\n",
      "\tspeed: 0.0561s/iter; left time: 1034.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0950014 Vali Loss: 0.1169843 Test Loss: 0.1258609\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0952450\n",
      "\tspeed: 0.0970s/iter; left time: 1776.8518s\n",
      "\titers: 200, epoch: 18 | loss: 0.0911217\n",
      "\tspeed: 0.0561s/iter; left time: 1022.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.0946936 Vali Loss: 0.1172174 Test Loss: 0.1259473\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0924156\n",
      "\tspeed: 0.0960s/iter; left time: 1737.5872s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927952\n",
      "\tspeed: 0.0560s/iter; left time: 1008.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 222 | Train Loss: 0.0944330 Vali Loss: 0.1170902 Test Loss: 0.1258976\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0357123464345932, rmse:0.18897710740566254, mae:0.12471231073141098, rse:0.6692061424255371\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1400153\n",
      "\tspeed: 0.0607s/iter; left time: 1340.4608s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283204\n",
      "\tspeed: 0.0560s/iter; left time: 1231.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1451430 Vali Loss: 0.1368039 Test Loss: 0.1443701\n",
      "Validation loss decreased (inf --> 0.136804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1105237\n",
      "\tspeed: 0.0977s/iter; left time: 2136.7989s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087797\n",
      "\tspeed: 0.0560s/iter; left time: 1219.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1123487 Vali Loss: 0.1206258 Test Loss: 0.1276149\n",
      "Validation loss decreased (0.136804 --> 0.120626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1059384\n",
      "\tspeed: 0.0978s/iter; left time: 2118.7439s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022027\n",
      "\tspeed: 0.0562s/iter; left time: 1211.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.1053810 Vali Loss: 0.1195757 Test Loss: 0.1275250\n",
      "Validation loss decreased (0.120626 --> 0.119576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1005405\n",
      "\tspeed: 0.1000s/iter; left time: 2143.8992s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009716\n",
      "\tspeed: 0.0560s/iter; left time: 1194.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1036713 Vali Loss: 0.1178414 Test Loss: 0.1258538\n",
      "Validation loss decreased (0.119576 --> 0.117841).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1006262\n",
      "\tspeed: 0.0984s/iter; left time: 2086.4697s\n",
      "\titers: 200, epoch: 5 | loss: 0.1009720\n",
      "\tspeed: 0.0560s/iter; left time: 1182.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1022844 Vali Loss: 0.1183373 Test Loss: 0.1259439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044686\n",
      "\tspeed: 0.0985s/iter; left time: 2066.9535s\n",
      "\titers: 200, epoch: 6 | loss: 0.1039320\n",
      "\tspeed: 0.0561s/iter; left time: 1172.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1011754 Vali Loss: 0.1172123 Test Loss: 0.1262177\n",
      "Validation loss decreased (0.117841 --> 0.117212).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983822\n",
      "\tspeed: 0.0985s/iter; left time: 2046.7621s\n",
      "\titers: 200, epoch: 7 | loss: 0.0999982\n",
      "\tspeed: 0.0560s/iter; left time: 1156.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1001580 Vali Loss: 0.1167087 Test Loss: 0.1267239\n",
      "Validation loss decreased (0.117212 --> 0.116709).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0978371\n",
      "\tspeed: 0.0986s/iter; left time: 2026.7079s\n",
      "\titers: 200, epoch: 8 | loss: 0.0960991\n",
      "\tspeed: 0.0560s/iter; left time: 1144.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0993198 Vali Loss: 0.1167437 Test Loss: 0.1256996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030914\n",
      "\tspeed: 0.0971s/iter; left time: 1972.8331s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060393\n",
      "\tspeed: 0.0562s/iter; left time: 1136.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0985208 Vali Loss: 0.1168993 Test Loss: 0.1262533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0944255\n",
      "\tspeed: 0.0968s/iter; left time: 1945.8575s\n",
      "\titers: 200, epoch: 10 | loss: 0.1005896\n",
      "\tspeed: 0.0560s/iter; left time: 1120.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.0978726 Vali Loss: 0.1164778 Test Loss: 0.1254682\n",
      "Validation loss decreased (0.116709 --> 0.116478).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0977786\n",
      "\tspeed: 0.0978s/iter; left time: 1944.9826s\n",
      "\titers: 200, epoch: 11 | loss: 0.1001371\n",
      "\tspeed: 0.0560s/iter; left time: 1107.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0972471 Vali Loss: 0.1168976 Test Loss: 0.1259428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0953204\n",
      "\tspeed: 0.0989s/iter; left time: 1944.8913s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940205\n",
      "\tspeed: 0.0561s/iter; left time: 1096.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0966455 Vali Loss: 0.1169655 Test Loss: 0.1269953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961258\n",
      "\tspeed: 0.0975s/iter; left time: 1895.6554s\n",
      "\titers: 200, epoch: 13 | loss: 0.0972280\n",
      "\tspeed: 0.0560s/iter; left time: 1083.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 222 | Train Loss: 0.0962103 Vali Loss: 0.1170050 Test Loss: 0.1266064\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0952882\n",
      "\tspeed: 0.0973s/iter; left time: 1870.4021s\n",
      "\titers: 200, epoch: 14 | loss: 0.0944683\n",
      "\tspeed: 0.0560s/iter; left time: 1070.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0957853 Vali Loss: 0.1175132 Test Loss: 0.1264056\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0908371\n",
      "\tspeed: 0.0974s/iter; left time: 1849.2390s\n",
      "\titers: 200, epoch: 15 | loss: 0.0950360\n",
      "\tspeed: 0.0560s/iter; left time: 1058.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0954513 Vali Loss: 0.1173833 Test Loss: 0.1263880\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0962350\n",
      "\tspeed: 0.0972s/iter; left time: 1824.7716s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930480\n",
      "\tspeed: 0.0560s/iter; left time: 1045.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.0950452 Vali Loss: 0.1174323 Test Loss: 0.1273650\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0914153\n",
      "\tspeed: 0.0971s/iter; left time: 1801.1286s\n",
      "\titers: 200, epoch: 17 | loss: 0.0968439\n",
      "\tspeed: 0.0560s/iter; left time: 1033.5842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0946228 Vali Loss: 0.1173784 Test Loss: 0.1264199\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0973026\n",
      "\tspeed: 0.0983s/iter; left time: 1801.6330s\n",
      "\titers: 200, epoch: 18 | loss: 0.0956572\n",
      "\tspeed: 0.0560s/iter; left time: 1020.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0943172 Vali Loss: 0.1177413 Test Loss: 0.1269055\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978792\n",
      "\tspeed: 0.0969s/iter; left time: 1754.5040s\n",
      "\titers: 200, epoch: 19 | loss: 0.0975742\n",
      "\tspeed: 0.0560s/iter; left time: 1008.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0940416 Vali Loss: 0.1174546 Test Loss: 0.1267941\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0935509\n",
      "\tspeed: 0.0974s/iter; left time: 1741.2340s\n",
      "\titers: 200, epoch: 20 | loss: 0.0917177\n",
      "\tspeed: 0.0560s/iter; left time: 996.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0937595 Vali Loss: 0.1178303 Test Loss: 0.1271784\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03607788681983948, rmse:0.18994179368019104, mae:0.1254681944847107, rse:0.6726222634315491\n",
      "Intermediate time for DE and pred_len 96: 00h:10m:12.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1399002\n",
      "\tspeed: 0.0736s/iter; left time: 1627.4941s\n",
      "\titers: 200, epoch: 1 | loss: 0.1310720\n",
      "\tspeed: 0.0563s/iter; left time: 1239.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1455335 Vali Loss: 0.1382271 Test Loss: 0.1469403\n",
      "Validation loss decreased (inf --> 0.138227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1117309\n",
      "\tspeed: 0.1001s/iter; left time: 2189.3365s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123937\n",
      "\tspeed: 0.0562s/iter; left time: 1224.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1173331 Vali Loss: 0.1245262 Test Loss: 0.1328125\n",
      "Validation loss decreased (0.138227 --> 0.124526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142129\n",
      "\tspeed: 0.0987s/iter; left time: 2136.9183s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112960\n",
      "\tspeed: 0.0562s/iter; left time: 1212.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.1107632 Vali Loss: 0.1232793 Test Loss: 0.1330868\n",
      "Validation loss decreased (0.124526 --> 0.123279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1128851\n",
      "\tspeed: 0.0990s/iter; left time: 2121.5691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1049208\n",
      "\tspeed: 0.0564s/iter; left time: 1202.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1088794 Vali Loss: 0.1225181 Test Loss: 0.1325915\n",
      "Validation loss decreased (0.123279 --> 0.122518).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1046247\n",
      "\tspeed: 0.0995s/iter; left time: 2111.0974s\n",
      "\titers: 200, epoch: 5 | loss: 0.1109414\n",
      "\tspeed: 0.0563s/iter; left time: 1187.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1072736 Vali Loss: 0.1221427 Test Loss: 0.1330497\n",
      "Validation loss decreased (0.122518 --> 0.122143).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1038896\n",
      "\tspeed: 0.1006s/iter; left time: 2112.5653s\n",
      "\titers: 200, epoch: 6 | loss: 0.1055614\n",
      "\tspeed: 0.0562s/iter; left time: 1174.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1058474 Vali Loss: 0.1215778 Test Loss: 0.1318558\n",
      "Validation loss decreased (0.122143 --> 0.121578).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041685\n",
      "\tspeed: 0.0989s/iter; left time: 2054.7160s\n",
      "\titers: 200, epoch: 7 | loss: 0.1039714\n",
      "\tspeed: 0.0564s/iter; left time: 1165.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1048099 Vali Loss: 0.1214240 Test Loss: 0.1309484\n",
      "Validation loss decreased (0.121578 --> 0.121424).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1028266\n",
      "\tspeed: 0.1006s/iter; left time: 2067.7900s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051091\n",
      "\tspeed: 0.0563s/iter; left time: 1150.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.1038182 Vali Loss: 0.1214119 Test Loss: 0.1320169\n",
      "Validation loss decreased (0.121424 --> 0.121412).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042578\n",
      "\tspeed: 0.0996s/iter; left time: 2025.2615s\n",
      "\titers: 200, epoch: 9 | loss: 0.1050219\n",
      "\tspeed: 0.0565s/iter; left time: 1143.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1030263 Vali Loss: 0.1220749 Test Loss: 0.1315216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0999491\n",
      "\tspeed: 0.0985s/iter; left time: 1980.2510s\n",
      "\titers: 200, epoch: 10 | loss: 0.1035637\n",
      "\tspeed: 0.0565s/iter; left time: 1131.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1022463 Vali Loss: 0.1222583 Test Loss: 0.1317445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1062949\n",
      "\tspeed: 0.0994s/iter; left time: 1976.7728s\n",
      "\titers: 200, epoch: 11 | loss: 0.1018711\n",
      "\tspeed: 0.0564s/iter; left time: 1116.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1015389 Vali Loss: 0.1223068 Test Loss: 0.1325487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043713\n",
      "\tspeed: 0.0972s/iter; left time: 1910.6977s\n",
      "\titers: 200, epoch: 12 | loss: 0.1038010\n",
      "\tspeed: 0.0563s/iter; left time: 1100.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1009183 Vali Loss: 0.1225692 Test Loss: 0.1322718\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0969497\n",
      "\tspeed: 0.0987s/iter; left time: 1919.2575s\n",
      "\titers: 200, epoch: 13 | loss: 0.1017084\n",
      "\tspeed: 0.0565s/iter; left time: 1093.1834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1002693 Vali Loss: 0.1229654 Test Loss: 0.1329298\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0960272\n",
      "\tspeed: 0.0974s/iter; left time: 1871.2541s\n",
      "\titers: 200, epoch: 14 | loss: 0.0956312\n",
      "\tspeed: 0.0563s/iter; left time: 1075.4648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0997279 Vali Loss: 0.1232132 Test Loss: 0.1330129\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0969483\n",
      "\tspeed: 0.0976s/iter; left time: 1854.4657s\n",
      "\titers: 200, epoch: 15 | loss: 0.0989557\n",
      "\tspeed: 0.0563s/iter; left time: 1063.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0992188 Vali Loss: 0.1234317 Test Loss: 0.1328251\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0992143\n",
      "\tspeed: 0.0978s/iter; left time: 1836.5780s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004101\n",
      "\tspeed: 0.0562s/iter; left time: 1050.1986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0986988 Vali Loss: 0.1237274 Test Loss: 0.1332834\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0983965\n",
      "\tspeed: 0.0975s/iter; left time: 1809.4157s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016725\n",
      "\tspeed: 0.0563s/iter; left time: 1039.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0982776 Vali Loss: 0.1234311 Test Loss: 0.1342439\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1021305\n",
      "\tspeed: 0.0978s/iter; left time: 1791.5198s\n",
      "\titers: 200, epoch: 18 | loss: 0.1000237\n",
      "\tspeed: 0.0563s/iter; left time: 1026.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0979285 Vali Loss: 0.1238799 Test Loss: 0.1341607\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038425009697675705, rmse:0.19602298736572266, mae:0.13201698660850525, rse:0.6943292021751404\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1515820\n",
      "\tspeed: 0.0581s/iter; left time: 1284.1425s\n",
      "\titers: 200, epoch: 1 | loss: 0.1351595\n",
      "\tspeed: 0.0562s/iter; left time: 1236.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 222 | Train Loss: 0.1459106 Vali Loss: 0.1384471 Test Loss: 0.1474545\n",
      "Validation loss decreased (inf --> 0.138447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1206223\n",
      "\tspeed: 0.1032s/iter; left time: 2258.6045s\n",
      "\titers: 200, epoch: 2 | loss: 0.1142049\n",
      "\tspeed: 0.0564s/iter; left time: 1227.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 222 | Train Loss: 0.1174732 Vali Loss: 0.1245720 Test Loss: 0.1331472\n",
      "Validation loss decreased (0.138447 --> 0.124572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1117440\n",
      "\tspeed: 0.1027s/iter; left time: 2223.2753s\n",
      "\titers: 200, epoch: 3 | loss: 0.1069415\n",
      "\tspeed: 0.0563s/iter; left time: 1213.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1109596 Vali Loss: 0.1228000 Test Loss: 0.1327924\n",
      "Validation loss decreased (0.124572 --> 0.122800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1147476\n",
      "\tspeed: 0.1018s/iter; left time: 2182.9928s\n",
      "\titers: 200, epoch: 4 | loss: 0.1086724\n",
      "\tspeed: 0.0565s/iter; left time: 1205.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1091430 Vali Loss: 0.1222963 Test Loss: 0.1323178\n",
      "Validation loss decreased (0.122800 --> 0.122296).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032344\n",
      "\tspeed: 0.0997s/iter; left time: 2114.5639s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114992\n",
      "\tspeed: 0.0565s/iter; left time: 1192.8346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1075674 Vali Loss: 0.1216319 Test Loss: 0.1328520\n",
      "Validation loss decreased (0.122296 --> 0.121632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1055237\n",
      "\tspeed: 0.1015s/iter; left time: 2130.5685s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056632\n",
      "\tspeed: 0.0565s/iter; left time: 1180.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1062136 Vali Loss: 0.1215922 Test Loss: 0.1327853\n",
      "Validation loss decreased (0.121632 --> 0.121592).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061727\n",
      "\tspeed: 0.1000s/iter; left time: 2076.2507s\n",
      "\titers: 200, epoch: 7 | loss: 0.1068689\n",
      "\tspeed: 0.0566s/iter; left time: 1169.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 222 | Train Loss: 0.1049340 Vali Loss: 0.1212201 Test Loss: 0.1333899\n",
      "Validation loss decreased (0.121592 --> 0.121220).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1025914\n",
      "\tspeed: 0.1011s/iter; left time: 2077.9060s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054732\n",
      "\tspeed: 0.0566s/iter; left time: 1157.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 222 | Train Loss: 0.1037226 Vali Loss: 0.1214384 Test Loss: 0.1324994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1038579\n",
      "\tspeed: 0.0990s/iter; left time: 2011.6868s\n",
      "\titers: 200, epoch: 9 | loss: 0.0974196\n",
      "\tspeed: 0.0563s/iter; left time: 1139.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1026216 Vali Loss: 0.1224918 Test Loss: 0.1345142\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996268\n",
      "\tspeed: 0.0987s/iter; left time: 1984.3095s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027106\n",
      "\tspeed: 0.0564s/iter; left time: 1128.9756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 222 | Train Loss: 0.1015664 Vali Loss: 0.1220061 Test Loss: 0.1339394\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0993154\n",
      "\tspeed: 0.0985s/iter; left time: 1958.2135s\n",
      "\titers: 200, epoch: 11 | loss: 0.1040305\n",
      "\tspeed: 0.0564s/iter; left time: 1114.9837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1006644 Vali Loss: 0.1220355 Test Loss: 0.1343870\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1000718\n",
      "\tspeed: 0.0978s/iter; left time: 1923.4137s\n",
      "\titers: 200, epoch: 12 | loss: 0.1012884\n",
      "\tspeed: 0.0562s/iter; left time: 1099.4035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0998381 Vali Loss: 0.1228722 Test Loss: 0.1341205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016827\n",
      "\tspeed: 0.0980s/iter; left time: 1904.5476s\n",
      "\titers: 200, epoch: 13 | loss: 0.0976272\n",
      "\tspeed: 0.0562s/iter; left time: 1086.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0991605 Vali Loss: 0.1230029 Test Loss: 0.1345378\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1022788\n",
      "\tspeed: 0.0974s/iter; left time: 1870.8376s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998285\n",
      "\tspeed: 0.0562s/iter; left time: 1074.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.0985090 Vali Loss: 0.1234400 Test Loss: 0.1346146\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0985817\n",
      "\tspeed: 0.0994s/iter; left time: 1888.7617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0989988\n",
      "\tspeed: 0.0564s/iter; left time: 1065.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 222 | Train Loss: 0.0979335 Vali Loss: 0.1231191 Test Loss: 0.1347603\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990492\n",
      "\tspeed: 0.0994s/iter; left time: 1866.4312s\n",
      "\titers: 200, epoch: 16 | loss: 0.0982786\n",
      "\tspeed: 0.0566s/iter; left time: 1057.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 222 | Train Loss: 0.0974306 Vali Loss: 0.1235838 Test Loss: 0.1353326\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0952108\n",
      "\tspeed: 0.0994s/iter; left time: 1844.3263s\n",
      "\titers: 200, epoch: 17 | loss: 0.0949799\n",
      "\tspeed: 0.0562s/iter; left time: 1037.2817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 222 | Train Loss: 0.0968703 Vali Loss: 0.1237597 Test Loss: 0.1353569\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03871931508183479, rmse:0.1967722475528717, mae:0.1333899199962616, rse:0.6969830989837646\n",
      "Intermediate time for DE and pred_len 168: 00h:09m:17.71s\n",
      "Intermediate time for DE: 00h:48m:30.61s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1190656\n",
      "\tspeed: 0.0736s/iter; left time: 1634.9689s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161422\n",
      "\tspeed: 0.0558s/iter; left time: 1233.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.91s\n",
      "Steps: 223 | Train Loss: 0.1253484 Vali Loss: 0.1194087 Test Loss: 0.1384515\n",
      "Validation loss decreased (inf --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870098\n",
      "\tspeed: 0.0978s/iter; left time: 2148.4085s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820863\n",
      "\tspeed: 0.0558s/iter; left time: 1220.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0858498 Vali Loss: 0.0922656 Test Loss: 0.1037217\n",
      "Validation loss decreased (0.119409 --> 0.092266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0805822\n",
      "\tspeed: 0.0972s/iter; left time: 2115.0916s\n",
      "\titers: 200, epoch: 3 | loss: 0.0783289\n",
      "\tspeed: 0.0558s/iter; left time: 1207.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0789233 Vali Loss: 0.0894624 Test Loss: 0.1028290\n",
      "Validation loss decreased (0.092266 --> 0.089462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815623\n",
      "\tspeed: 0.0970s/iter; left time: 2089.5757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827173\n",
      "\tspeed: 0.0558s/iter; left time: 1196.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0773275 Vali Loss: 0.0896265 Test Loss: 0.1026914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726509\n",
      "\tspeed: 0.0965s/iter; left time: 2056.0343s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737885\n",
      "\tspeed: 0.0557s/iter; left time: 1182.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0762504 Vali Loss: 0.0890852 Test Loss: 0.1016043\n",
      "Validation loss decreased (0.089462 --> 0.089085).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734069\n",
      "\tspeed: 0.0971s/iter; left time: 2046.4637s\n",
      "\titers: 200, epoch: 6 | loss: 0.0775540\n",
      "\tspeed: 0.0558s/iter; left time: 1170.8743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0755329 Vali Loss: 0.0884747 Test Loss: 0.1004770\n",
      "Validation loss decreased (0.089085 --> 0.088475).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754288\n",
      "\tspeed: 0.0979s/iter; left time: 2043.1717s\n",
      "\titers: 200, epoch: 7 | loss: 0.0744961\n",
      "\tspeed: 0.0558s/iter; left time: 1157.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0749985 Vali Loss: 0.0885333 Test Loss: 0.1013064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774653\n",
      "\tspeed: 0.0970s/iter; left time: 2001.8117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739258\n",
      "\tspeed: 0.0557s/iter; left time: 1144.0606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0745286 Vali Loss: 0.0878436 Test Loss: 0.1005928\n",
      "Validation loss decreased (0.088475 --> 0.087844).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736594\n",
      "\tspeed: 0.0970s/iter; left time: 1980.6955s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707307\n",
      "\tspeed: 0.0558s/iter; left time: 1133.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0740644 Vali Loss: 0.0879482 Test Loss: 0.0996325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0720190\n",
      "\tspeed: 0.0973s/iter; left time: 1964.6439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767412\n",
      "\tspeed: 0.0558s/iter; left time: 1121.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0736389 Vali Loss: 0.0878936 Test Loss: 0.1004490\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0787126\n",
      "\tspeed: 0.0964s/iter; left time: 1925.3029s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735841\n",
      "\tspeed: 0.0557s/iter; left time: 1107.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0733615 Vali Loss: 0.0875434 Test Loss: 0.1004866\n",
      "Validation loss decreased (0.087844 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650659\n",
      "\tspeed: 0.0968s/iter; left time: 1910.8100s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782444\n",
      "\tspeed: 0.0556s/iter; left time: 1092.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0731628 Vali Loss: 0.0876492 Test Loss: 0.0996653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0720514\n",
      "\tspeed: 0.0967s/iter; left time: 1887.9786s\n",
      "\titers: 200, epoch: 13 | loss: 0.0745456\n",
      "\tspeed: 0.0558s/iter; left time: 1084.3613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0729101 Vali Loss: 0.0874964 Test Loss: 0.0996864\n",
      "Validation loss decreased (0.087543 --> 0.087496).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719180\n",
      "\tspeed: 0.0982s/iter; left time: 1895.3045s\n",
      "\titers: 200, epoch: 14 | loss: 0.0725956\n",
      "\tspeed: 0.0558s/iter; left time: 1071.4137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0727339 Vali Loss: 0.0876334 Test Loss: 0.0996331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718653\n",
      "\tspeed: 0.0971s/iter; left time: 1852.5220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711401\n",
      "\tspeed: 0.0556s/iter; left time: 1054.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0725731 Vali Loss: 0.0873525 Test Loss: 0.0995370\n",
      "Validation loss decreased (0.087496 --> 0.087353).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709502\n",
      "\tspeed: 0.0977s/iter; left time: 1843.0721s\n",
      "\titers: 200, epoch: 16 | loss: 0.0688956\n",
      "\tspeed: 0.0556s/iter; left time: 1042.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0724521 Vali Loss: 0.0873687 Test Loss: 0.0992573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0763475\n",
      "\tspeed: 0.0968s/iter; left time: 1803.3515s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740564\n",
      "\tspeed: 0.0556s/iter; left time: 1031.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0722744 Vali Loss: 0.0872078 Test Loss: 0.0993596\n",
      "Validation loss decreased (0.087353 --> 0.087208).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710246\n",
      "\tspeed: 0.0976s/iter; left time: 1797.2363s\n",
      "\titers: 200, epoch: 18 | loss: 0.0711855\n",
      "\tspeed: 0.0558s/iter; left time: 1020.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0721521 Vali Loss: 0.0872633 Test Loss: 0.0994425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733631\n",
      "\tspeed: 0.0969s/iter; left time: 1761.6434s\n",
      "\titers: 200, epoch: 19 | loss: 0.0770690\n",
      "\tspeed: 0.0558s/iter; left time: 1008.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0720333 Vali Loss: 0.0873004 Test Loss: 0.0993044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0704630\n",
      "\tspeed: 0.0972s/iter; left time: 1746.3209s\n",
      "\titers: 200, epoch: 20 | loss: 0.0651565\n",
      "\tspeed: 0.0558s/iter; left time: 996.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0719302 Vali Loss: 0.0872917 Test Loss: 0.0991583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0689208\n",
      "\tspeed: 0.0968s/iter; left time: 1717.5031s\n",
      "\titers: 200, epoch: 21 | loss: 0.0757201\n",
      "\tspeed: 0.0557s/iter; left time: 983.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0718589 Vali Loss: 0.0872711 Test Loss: 0.0992796\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0733921\n",
      "\tspeed: 0.0967s/iter; left time: 1694.3010s\n",
      "\titers: 200, epoch: 22 | loss: 0.0708673\n",
      "\tspeed: 0.0558s/iter; left time: 972.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0717552 Vali Loss: 0.0871347 Test Loss: 0.0991715\n",
      "Validation loss decreased (0.087208 --> 0.087135).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0760645\n",
      "\tspeed: 0.0974s/iter; left time: 1684.4248s\n",
      "\titers: 200, epoch: 23 | loss: 0.0667015\n",
      "\tspeed: 0.0557s/iter; left time: 958.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0717327 Vali Loss: 0.0870459 Test Loss: 0.0991245\n",
      "Validation loss decreased (0.087135 --> 0.087046).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0735871\n",
      "\tspeed: 0.0970s/iter; left time: 1655.6581s\n",
      "\titers: 200, epoch: 24 | loss: 0.0728756\n",
      "\tspeed: 0.0558s/iter; left time: 946.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0716163 Vali Loss: 0.0871637 Test Loss: 0.0992907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0732243\n",
      "\tspeed: 0.0970s/iter; left time: 1633.7305s\n",
      "\titers: 200, epoch: 25 | loss: 0.0709287\n",
      "\tspeed: 0.0558s/iter; left time: 934.9185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0716102 Vali Loss: 0.0873323 Test Loss: 0.0991644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0683563\n",
      "\tspeed: 0.0967s/iter; left time: 1608.1505s\n",
      "\titers: 200, epoch: 26 | loss: 0.0677319\n",
      "\tspeed: 0.0558s/iter; left time: 921.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0715926 Vali Loss: 0.0872675 Test Loss: 0.0991061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0738787\n",
      "\tspeed: 0.0969s/iter; left time: 1589.7199s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742473\n",
      "\tspeed: 0.0558s/iter; left time: 910.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0714851 Vali Loss: 0.0870536 Test Loss: 0.0990238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0666653\n",
      "\tspeed: 0.1012s/iter; left time: 1637.0762s\n",
      "\titers: 200, epoch: 28 | loss: 0.0767145\n",
      "\tspeed: 0.0584s/iter; left time: 938.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 223 | Train Loss: 0.0714313 Vali Loss: 0.0872936 Test Loss: 0.0991399\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0739312\n",
      "\tspeed: 0.2538s/iter; left time: 4050.4375s\n",
      "\titers: 200, epoch: 29 | loss: 0.0702690\n",
      "\tspeed: 0.1388s/iter; left time: 2201.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:31.52s\n",
      "Steps: 223 | Train Loss: 0.0714035 Vali Loss: 0.0871968 Test Loss: 0.0991477\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0746630\n",
      "\tspeed: 0.2824s/iter; left time: 4442.6480s\n",
      "\titers: 200, epoch: 30 | loss: 0.0762597\n",
      "\tspeed: 0.1269s/iter; left time: 1984.1953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 223 | Train Loss: 0.0713885 Vali Loss: 0.0873346 Test Loss: 0.0991395\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0695903\n",
      "\tspeed: 0.2994s/iter; left time: 4644.7499s\n",
      "\titers: 200, epoch: 31 | loss: 0.0737659\n",
      "\tspeed: 0.1662s/iter; left time: 2561.6537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:31.84s\n",
      "Steps: 223 | Train Loss: 0.0713434 Vali Loss: 0.0871035 Test Loss: 0.0991213\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0750624\n",
      "\tspeed: 0.2879s/iter; left time: 4401.4034s\n",
      "\titers: 200, epoch: 32 | loss: 0.0747816\n",
      "\tspeed: 0.0944s/iter; left time: 1433.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 223 | Train Loss: 0.0713147 Vali Loss: 0.0871615 Test Loss: 0.0991062\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0709687\n",
      "\tspeed: 0.3957s/iter; left time: 5960.8588s\n",
      "\titers: 200, epoch: 33 | loss: 0.0697152\n",
      "\tspeed: 0.1926s/iter; left time: 2882.6352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 223 | Train Loss: 0.0712944 Vali Loss: 0.0871505 Test Loss: 0.0990493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024570560082793236, rmse:0.15674999356269836, mae:0.09912451356649399, rse:0.5407430529594421\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1245341\n",
      "\tspeed: 0.2228s/iter; left time: 4946.5063s\n",
      "\titers: 200, epoch: 1 | loss: 0.1095097\n",
      "\tspeed: 0.2037s/iter; left time: 4501.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 223 | Train Loss: 0.1254445 Vali Loss: 0.1200309 Test Loss: 0.1391877\n",
      "Validation loss decreased (inf --> 0.120031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0840376\n",
      "\tspeed: 0.3435s/iter; left time: 7550.2616s\n",
      "\titers: 200, epoch: 2 | loss: 0.0810726\n",
      "\tspeed: 0.0788s/iter; left time: 1723.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.44s\n",
      "Steps: 223 | Train Loss: 0.0858071 Vali Loss: 0.0911559 Test Loss: 0.1027333\n",
      "Validation loss decreased (0.120031 --> 0.091156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0800171\n",
      "\tspeed: 0.1037s/iter; left time: 2255.2973s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812158\n",
      "\tspeed: 0.0565s/iter; left time: 1222.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 223 | Train Loss: 0.0790698 Vali Loss: 0.0896118 Test Loss: 0.1031010\n",
      "Validation loss decreased (0.091156 --> 0.089612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818189\n",
      "\tspeed: 0.1006s/iter; left time: 2165.9190s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696711\n",
      "\tspeed: 0.0557s/iter; left time: 1193.7008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0774647 Vali Loss: 0.0894184 Test Loss: 0.1019324\n",
      "Validation loss decreased (0.089612 --> 0.089418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0843827\n",
      "\tspeed: 0.0983s/iter; left time: 2094.6637s\n",
      "\titers: 200, epoch: 5 | loss: 0.0805781\n",
      "\tspeed: 0.0557s/iter; left time: 1180.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0764215 Vali Loss: 0.0892403 Test Loss: 0.1013356\n",
      "Validation loss decreased (0.089418 --> 0.089240).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0738009\n",
      "\tspeed: 0.0976s/iter; left time: 2057.9585s\n",
      "\titers: 200, epoch: 6 | loss: 0.0750279\n",
      "\tspeed: 0.0555s/iter; left time: 1165.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0756854 Vali Loss: 0.0886191 Test Loss: 0.1014508\n",
      "Validation loss decreased (0.089240 --> 0.088619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0818800\n",
      "\tspeed: 0.0975s/iter; left time: 2034.9174s\n",
      "\titers: 200, epoch: 7 | loss: 0.0787578\n",
      "\tspeed: 0.0556s/iter; left time: 1154.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0751229 Vali Loss: 0.0883886 Test Loss: 0.1005039\n",
      "Validation loss decreased (0.088619 --> 0.088389).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0751207\n",
      "\tspeed: 0.0968s/iter; left time: 1998.4805s\n",
      "\titers: 200, epoch: 8 | loss: 0.0725476\n",
      "\tspeed: 0.0556s/iter; left time: 1141.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0746188 Vali Loss: 0.0880025 Test Loss: 0.1003955\n",
      "Validation loss decreased (0.088389 --> 0.088002).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0723632\n",
      "\tspeed: 0.0971s/iter; left time: 1982.6216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748586\n",
      "\tspeed: 0.0556s/iter; left time: 1130.1861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0741620 Vali Loss: 0.0884281 Test Loss: 0.1003440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684523\n",
      "\tspeed: 0.0966s/iter; left time: 1950.1821s\n",
      "\titers: 200, epoch: 10 | loss: 0.0759455\n",
      "\tspeed: 0.0556s/iter; left time: 1117.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0738323 Vali Loss: 0.0877718 Test Loss: 0.0998402\n",
      "Validation loss decreased (0.088002 --> 0.087772).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773028\n",
      "\tspeed: 0.0974s/iter; left time: 1945.8627s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717021\n",
      "\tspeed: 0.0557s/iter; left time: 1106.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0735408 Vali Loss: 0.0878956 Test Loss: 0.0997441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0727853\n",
      "\tspeed: 0.0970s/iter; left time: 1914.7258s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768436\n",
      "\tspeed: 0.0556s/iter; left time: 1092.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0732213 Vali Loss: 0.0874504 Test Loss: 0.0993545\n",
      "Validation loss decreased (0.087772 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0748568\n",
      "\tspeed: 0.0980s/iter; left time: 1914.2375s\n",
      "\titers: 200, epoch: 13 | loss: 0.0693408\n",
      "\tspeed: 0.0556s/iter; left time: 1080.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0729368 Vali Loss: 0.0872005 Test Loss: 0.0996057\n",
      "Validation loss decreased (0.087450 --> 0.087201).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0723982\n",
      "\tspeed: 0.0974s/iter; left time: 1880.8414s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762133\n",
      "\tspeed: 0.0556s/iter; left time: 1067.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0728184 Vali Loss: 0.0872517 Test Loss: 0.0992832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731171\n",
      "\tspeed: 0.0971s/iter; left time: 1853.1380s\n",
      "\titers: 200, epoch: 15 | loss: 0.0741022\n",
      "\tspeed: 0.0555s/iter; left time: 1053.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0726241 Vali Loss: 0.0870855 Test Loss: 0.0991462\n",
      "Validation loss decreased (0.087201 --> 0.087085).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0750456\n",
      "\tspeed: 0.0963s/iter; left time: 1816.6623s\n",
      "\titers: 200, epoch: 16 | loss: 0.0713072\n",
      "\tspeed: 0.0555s/iter; left time: 1040.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0724411 Vali Loss: 0.0871672 Test Loss: 0.0994019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0668869\n",
      "\tspeed: 0.0966s/iter; left time: 1800.4650s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713389\n",
      "\tspeed: 0.0555s/iter; left time: 1029.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0723312 Vali Loss: 0.0871781 Test Loss: 0.0993513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706983\n",
      "\tspeed: 0.0959s/iter; left time: 1766.2521s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748784\n",
      "\tspeed: 0.0555s/iter; left time: 1016.2035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0721220 Vali Loss: 0.0872997 Test Loss: 0.0990167\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0700274\n",
      "\tspeed: 0.0962s/iter; left time: 1750.2997s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744739\n",
      "\tspeed: 0.0554s/iter; left time: 1002.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0720195 Vali Loss: 0.0869263 Test Loss: 0.0991538\n",
      "Validation loss decreased (0.087085 --> 0.086926).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791809\n",
      "\tspeed: 0.0968s/iter; left time: 1739.6417s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694202\n",
      "\tspeed: 0.0555s/iter; left time: 991.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0719323 Vali Loss: 0.0870747 Test Loss: 0.0990399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0741944\n",
      "\tspeed: 0.0967s/iter; left time: 1715.2873s\n",
      "\titers: 200, epoch: 21 | loss: 0.0745496\n",
      "\tspeed: 0.0555s/iter; left time: 979.4937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0719164 Vali Loss: 0.0870800 Test Loss: 0.0990365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0724013\n",
      "\tspeed: 0.0970s/iter; left time: 1699.3488s\n",
      "\titers: 200, epoch: 22 | loss: 0.0665953\n",
      "\tspeed: 0.0555s/iter; left time: 967.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0718348 Vali Loss: 0.0870564 Test Loss: 0.0989102\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0713616\n",
      "\tspeed: 0.0960s/iter; left time: 1660.6828s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664531\n",
      "\tspeed: 0.0555s/iter; left time: 954.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0717544 Vali Loss: 0.0869851 Test Loss: 0.0988903\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0733751\n",
      "\tspeed: 0.0972s/iter; left time: 1659.7551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768953\n",
      "\tspeed: 0.0555s/iter; left time: 942.4096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0716118 Vali Loss: 0.0870040 Test Loss: 0.0988361\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0696853\n",
      "\tspeed: 0.0961s/iter; left time: 1618.8960s\n",
      "\titers: 200, epoch: 25 | loss: 0.0754574\n",
      "\tspeed: 0.0556s/iter; left time: 930.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0715513 Vali Loss: 0.0869943 Test Loss: 0.0989808\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0709983\n",
      "\tspeed: 0.0962s/iter; left time: 1599.8028s\n",
      "\titers: 200, epoch: 26 | loss: 0.0676465\n",
      "\tspeed: 0.0555s/iter; left time: 917.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0714881 Vali Loss: 0.0869537 Test Loss: 0.0987807\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0693488\n",
      "\tspeed: 0.0959s/iter; left time: 1573.5555s\n",
      "\titers: 200, epoch: 27 | loss: 0.0711039\n",
      "\tspeed: 0.0555s/iter; left time: 904.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 223 | Train Loss: 0.0713989 Vali Loss: 0.0868826 Test Loss: 0.0987545\n",
      "Validation loss decreased (0.086926 --> 0.086883).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0756186\n",
      "\tspeed: 0.0977s/iter; left time: 1580.8555s\n",
      "\titers: 200, epoch: 28 | loss: 0.0743463\n",
      "\tspeed: 0.0557s/iter; left time: 895.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0714247 Vali Loss: 0.0867862 Test Loss: 0.0988359\n",
      "Validation loss decreased (0.086883 --> 0.086786).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0710060\n",
      "\tspeed: 0.0968s/iter; left time: 1544.3542s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695662\n",
      "\tspeed: 0.0556s/iter; left time: 882.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0714264 Vali Loss: 0.0868562 Test Loss: 0.0987503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701287\n",
      "\tspeed: 0.0963s/iter; left time: 1515.0535s\n",
      "\titers: 200, epoch: 30 | loss: 0.0757296\n",
      "\tspeed: 0.0555s/iter; left time: 867.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0713372 Vali Loss: 0.0867431 Test Loss: 0.0987461\n",
      "Validation loss decreased (0.086786 --> 0.086743).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0701553\n",
      "\tspeed: 0.0968s/iter; left time: 1502.2116s\n",
      "\titers: 200, epoch: 31 | loss: 0.0727991\n",
      "\tspeed: 0.0557s/iter; left time: 858.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0712994 Vali Loss: 0.0868837 Test Loss: 0.0987813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0733458\n",
      "\tspeed: 0.0965s/iter; left time: 1474.7947s\n",
      "\titers: 200, epoch: 32 | loss: 0.0694019\n",
      "\tspeed: 0.0556s/iter; left time: 844.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0713098 Vali Loss: 0.0868881 Test Loss: 0.0988373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0712834\n",
      "\tspeed: 0.0961s/iter; left time: 1448.3921s\n",
      "\titers: 200, epoch: 33 | loss: 0.0688486\n",
      "\tspeed: 0.0555s/iter; left time: 830.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0712188 Vali Loss: 0.0868297 Test Loss: 0.0987804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0690468\n",
      "\tspeed: 0.0959s/iter; left time: 1422.8061s\n",
      "\titers: 200, epoch: 34 | loss: 0.0661724\n",
      "\tspeed: 0.0555s/iter; left time: 818.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0712138 Vali Loss: 0.0868261 Test Loss: 0.0987904\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0734023\n",
      "\tspeed: 0.0965s/iter; left time: 1410.8276s\n",
      "\titers: 200, epoch: 35 | loss: 0.0691267\n",
      "\tspeed: 0.0554s/iter; left time: 805.0715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711909 Vali Loss: 0.0868607 Test Loss: 0.0987801\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0676273\n",
      "\tspeed: 0.0962s/iter; left time: 1384.2812s\n",
      "\titers: 200, epoch: 36 | loss: 0.0762189\n",
      "\tspeed: 0.0555s/iter; left time: 794.1158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0712222 Vali Loss: 0.0868300 Test Loss: 0.0987861\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0705356\n",
      "\tspeed: 0.0967s/iter; left time: 1370.1689s\n",
      "\titers: 200, epoch: 37 | loss: 0.0708427\n",
      "\tspeed: 0.0555s/iter; left time: 781.1515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711363 Vali Loss: 0.0867921 Test Loss: 0.0988260\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0765347\n",
      "\tspeed: 0.0962s/iter; left time: 1341.3558s\n",
      "\titers: 200, epoch: 38 | loss: 0.0721635\n",
      "\tspeed: 0.0555s/iter; left time: 768.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711380 Vali Loss: 0.0868325 Test Loss: 0.0988323\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0716699\n",
      "\tspeed: 0.0969s/iter; left time: 1330.4072s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682490\n",
      "\tspeed: 0.0556s/iter; left time: 757.6486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0710949 Vali Loss: 0.0868223 Test Loss: 0.0987682\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0706478\n",
      "\tspeed: 0.0961s/iter; left time: 1298.0829s\n",
      "\titers: 200, epoch: 40 | loss: 0.0696950\n",
      "\tspeed: 0.0555s/iter; left time: 743.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 223 | Train Loss: 0.0711050 Vali Loss: 0.0869668 Test Loss: 0.0987652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02454490214586258, rmse:0.15666812658309937, mae:0.09874614328145981, rse:0.5404606461524963\n",
      "Intermediate time for GB and pred_len 24: 00h:22m:41.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1306827\n",
      "\tspeed: 0.0737s/iter; left time: 1627.9731s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177318\n",
      "\tspeed: 0.0562s/iter; left time: 1236.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1310412 Vali Loss: 0.1288174 Test Loss: 0.1522436\n",
      "Validation loss decreased (inf --> 0.128817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1066177\n",
      "\tspeed: 0.0998s/iter; left time: 2183.2131s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095714\n",
      "\tspeed: 0.0562s/iter; left time: 1224.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1078968 Vali Loss: 0.1167912 Test Loss: 0.1385723\n",
      "Validation loss decreased (0.128817 --> 0.116791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1022676\n",
      "\tspeed: 0.0989s/iter; left time: 2141.9155s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059308\n",
      "\tspeed: 0.0562s/iter; left time: 1211.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1029695 Vali Loss: 0.1158236 Test Loss: 0.1393959\n",
      "Validation loss decreased (0.116791 --> 0.115824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0960328\n",
      "\tspeed: 0.0999s/iter; left time: 2141.3581s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025381\n",
      "\tspeed: 0.0560s/iter; left time: 1194.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1014715 Vali Loss: 0.1154466 Test Loss: 0.1393613\n",
      "Validation loss decreased (0.115824 --> 0.115447).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026418\n",
      "\tspeed: 0.0990s/iter; left time: 2099.4794s\n",
      "\titers: 200, epoch: 5 | loss: 0.1024776\n",
      "\tspeed: 0.0560s/iter; left time: 1181.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1004793 Vali Loss: 0.1146312 Test Loss: 0.1378396\n",
      "Validation loss decreased (0.115447 --> 0.114631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0979286\n",
      "\tspeed: 0.0992s/iter; left time: 2081.7530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994375\n",
      "\tspeed: 0.0561s/iter; left time: 1172.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0995605 Vali Loss: 0.1148999 Test Loss: 0.1380830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0970419\n",
      "\tspeed: 0.0987s/iter; left time: 2049.6012s\n",
      "\titers: 200, epoch: 7 | loss: 0.0962363\n",
      "\tspeed: 0.0560s/iter; left time: 1157.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0987005 Vali Loss: 0.1152062 Test Loss: 0.1379218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0996104\n",
      "\tspeed: 0.0982s/iter; left time: 2017.8896s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979448\n",
      "\tspeed: 0.0559s/iter; left time: 1142.7453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.0980342 Vali Loss: 0.1154223 Test Loss: 0.1376054\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0958485\n",
      "\tspeed: 0.0991s/iter; left time: 2014.7033s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965145\n",
      "\tspeed: 0.0615s/iter; left time: 1244.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.21s\n",
      "Steps: 222 | Train Loss: 0.0972717 Vali Loss: 0.1154799 Test Loss: 0.1370620\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954895\n",
      "\tspeed: 0.6275s/iter; left time: 12615.0912s\n",
      "\titers: 200, epoch: 10 | loss: 0.0944765\n",
      "\tspeed: 0.1997s/iter; left time: 3994.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.62s\n",
      "Steps: 222 | Train Loss: 0.0966941 Vali Loss: 0.1156659 Test Loss: 0.1384369\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0955338\n",
      "\tspeed: 0.1835s/iter; left time: 3648.6977s\n",
      "\titers: 200, epoch: 11 | loss: 0.0942479\n",
      "\tspeed: 0.0563s/iter; left time: 1112.7131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 222 | Train Loss: 0.0960870 Vali Loss: 0.1158695 Test Loss: 0.1388598\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0913796\n",
      "\tspeed: 0.0982s/iter; left time: 1930.1414s\n",
      "\titers: 200, epoch: 12 | loss: 0.0934490\n",
      "\tspeed: 0.0567s/iter; left time: 1109.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0955488 Vali Loss: 0.1158540 Test Loss: 0.1386886\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0921230\n",
      "\tspeed: 0.0977s/iter; left time: 1899.7747s\n",
      "\titers: 200, epoch: 13 | loss: 0.0977281\n",
      "\tspeed: 0.0560s/iter; left time: 1083.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0950370 Vali Loss: 0.1160690 Test Loss: 0.1403026\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0938734\n",
      "\tspeed: 0.0981s/iter; left time: 1885.5387s\n",
      "\titers: 200, epoch: 14 | loss: 0.0945882\n",
      "\tspeed: 0.0561s/iter; left time: 1071.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0945816 Vali Loss: 0.1165808 Test Loss: 0.1402343\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0991733\n",
      "\tspeed: 0.0988s/iter; left time: 1877.2304s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967700\n",
      "\tspeed: 0.0561s/iter; left time: 1059.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0940588 Vali Loss: 0.1163656 Test Loss: 0.1410571\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04015038162469864, rmse:0.20037560164928436, mae:0.13783958554267883, rse:0.6929267048835754\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1303071\n",
      "\tspeed: 0.0615s/iter; left time: 1358.7608s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283034\n",
      "\tspeed: 0.0562s/iter; left time: 1236.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 222 | Train Loss: 0.1310060 Vali Loss: 0.1287630 Test Loss: 0.1517619\n",
      "Validation loss decreased (inf --> 0.128763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1048923\n",
      "\tspeed: 0.0999s/iter; left time: 2185.0535s\n",
      "\titers: 200, epoch: 2 | loss: 0.1013105\n",
      "\tspeed: 0.0560s/iter; left time: 1220.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1080856 Vali Loss: 0.1171368 Test Loss: 0.1385304\n",
      "Validation loss decreased (0.128763 --> 0.117137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1040064\n",
      "\tspeed: 0.0983s/iter; left time: 2128.0664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0998071\n",
      "\tspeed: 0.0560s/iter; left time: 1208.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 222 | Train Loss: 0.1030684 Vali Loss: 0.1154471 Test Loss: 0.1375951\n",
      "Validation loss decreased (0.117137 --> 0.115447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053156\n",
      "\tspeed: 0.3820s/iter; left time: 8187.8691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008415\n",
      "\tspeed: 0.0589s/iter; left time: 1257.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.1016380 Vali Loss: 0.1151421 Test Loss: 0.1379311\n",
      "Validation loss decreased (0.115447 --> 0.115142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0987126\n",
      "\tspeed: 0.0994s/iter; left time: 2107.6234s\n",
      "\titers: 200, epoch: 5 | loss: 0.0972618\n",
      "\tspeed: 0.0691s/iter; left time: 1458.8311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.43s\n",
      "Steps: 222 | Train Loss: 0.1004928 Vali Loss: 0.1147536 Test Loss: 0.1380800\n",
      "Validation loss decreased (0.115142 --> 0.114754).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1012318\n",
      "\tspeed: 0.6444s/iter; left time: 13526.0305s\n",
      "\titers: 200, epoch: 6 | loss: 0.0969684\n",
      "\tspeed: 0.1934s/iter; left time: 4040.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.55s\n",
      "Steps: 222 | Train Loss: 0.0993943 Vali Loss: 0.1148224 Test Loss: 0.1386869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0970156\n",
      "\tspeed: 0.1453s/iter; left time: 3018.6714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0988887\n",
      "\tspeed: 0.0560s/iter; left time: 1158.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 222 | Train Loss: 0.0985187 Vali Loss: 0.1149543 Test Loss: 0.1399635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0929216\n",
      "\tspeed: 0.0985s/iter; left time: 2023.5995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0935230\n",
      "\tspeed: 0.0568s/iter; left time: 1162.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 222 | Train Loss: 0.0974779 Vali Loss: 0.1147359 Test Loss: 0.1398059\n",
      "Validation loss decreased (0.114754 --> 0.114736).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0948713\n",
      "\tspeed: 0.1010s/iter; left time: 2053.3036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0958109\n",
      "\tspeed: 0.0566s/iter; left time: 1144.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 222 | Train Loss: 0.0966486 Vali Loss: 0.1154781 Test Loss: 0.1414918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0992346\n",
      "\tspeed: 0.0998s/iter; left time: 2005.2822s\n",
      "\titers: 200, epoch: 10 | loss: 0.0941390\n",
      "\tspeed: 0.0561s/iter; left time: 1121.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.0958207 Vali Loss: 0.1155172 Test Loss: 0.1409567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0913739\n",
      "\tspeed: 0.0985s/iter; left time: 1958.4105s\n",
      "\titers: 200, epoch: 11 | loss: 0.0964964\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0951955 Vali Loss: 0.1160658 Test Loss: 0.1419416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966781\n",
      "\tspeed: 0.0999s/iter; left time: 1963.4582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0935920\n",
      "\tspeed: 0.0560s/iter; left time: 1095.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 222 | Train Loss: 0.0943973 Vali Loss: 0.1160687 Test Loss: 0.1421239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0959323\n",
      "\tspeed: 0.0984s/iter; left time: 1912.5597s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973188\n",
      "\tspeed: 0.0562s/iter; left time: 1086.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 222 | Train Loss: 0.0938334 Vali Loss: 0.1156196 Test Loss: 0.1408184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0913993\n",
      "\tspeed: 0.1000s/iter; left time: 1921.0940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937971\n",
      "\tspeed: 0.0560s/iter; left time: 1070.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 222 | Train Loss: 0.0932455 Vali Loss: 0.1158227 Test Loss: 0.1420476\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0968988\n",
      "\tspeed: 0.3754s/iter; left time: 7129.8569s\n",
      "\titers: 200, epoch: 15 | loss: 0.0916217\n",
      "\tspeed: 0.0633s/iter; left time: 1195.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 222 | Train Loss: 0.0927197 Vali Loss: 0.1161066 Test Loss: 0.1418097\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0897948\n",
      "\tspeed: 0.1000s/iter; left time: 1876.2781s\n",
      "\titers: 200, epoch: 16 | loss: 0.0920113\n",
      "\tspeed: 0.0822s/iter; left time: 1534.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.04s\n",
      "Steps: 222 | Train Loss: 0.0922969 Vali Loss: 0.1167289 Test Loss: 0.1427078\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0914260\n",
      "\tspeed: 0.6881s/iter; left time: 12762.8375s\n",
      "\titers: 200, epoch: 17 | loss: 0.0921046\n",
      "\tspeed: 0.1896s/iter; left time: 3498.6136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:44.62s\n",
      "Steps: 222 | Train Loss: 0.0918778 Vali Loss: 0.1167830 Test Loss: 0.1428674\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878626\n",
      "\tspeed: 0.5708s/iter; left time: 10461.8958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0943621\n",
      "\tspeed: 0.0735s/iter; left time: 1339.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:23.58s\n",
      "Steps: 222 | Train Loss: 0.0915997 Vali Loss: 0.1168165 Test Loss: 0.1414241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041960179805755615, rmse:0.20484183728694916, mae:0.1398058831691742, rse:0.708371639251709\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:16.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1260773\n",
      "\tspeed: 0.0773s/iter; left time: 1709.3037s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229722\n",
      "\tspeed: 0.0571s/iter; left time: 1255.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.22s\n",
      "Steps: 222 | Train Loss: 0.1327026 Vali Loss: 0.1309201 Test Loss: 0.1548616\n",
      "Validation loss decreased (inf --> 0.130920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093555\n",
      "\tspeed: 0.1009s/iter; left time: 2206.9556s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087653\n",
      "\tspeed: 0.0565s/iter; left time: 1230.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1121223 Vali Loss: 0.1213975 Test Loss: 0.1448217\n",
      "Validation loss decreased (0.130920 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089418\n",
      "\tspeed: 0.1006s/iter; left time: 2179.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108851\n",
      "\tspeed: 0.0563s/iter; left time: 1214.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1075883 Vali Loss: 0.1200373 Test Loss: 0.1443896\n",
      "Validation loss decreased (0.121397 --> 0.120037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1100808\n",
      "\tspeed: 0.0998s/iter; left time: 2139.3352s\n",
      "\titers: 200, epoch: 4 | loss: 0.1029688\n",
      "\tspeed: 0.0567s/iter; left time: 1208.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1060422 Vali Loss: 0.1198486 Test Loss: 0.1441484\n",
      "Validation loss decreased (0.120037 --> 0.119849).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044006\n",
      "\tspeed: 0.0993s/iter; left time: 2105.7861s\n",
      "\titers: 200, epoch: 5 | loss: 0.1066292\n",
      "\tspeed: 0.0564s/iter; left time: 1190.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1046534 Vali Loss: 0.1206437 Test Loss: 0.1449600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0995353\n",
      "\tspeed: 0.0979s/iter; left time: 2054.9923s\n",
      "\titers: 200, epoch: 6 | loss: 0.1040475\n",
      "\tspeed: 0.0563s/iter; left time: 1176.3104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1034120 Vali Loss: 0.1211787 Test Loss: 0.1452242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1019453\n",
      "\tspeed: 0.0970s/iter; left time: 2014.0747s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026548\n",
      "\tspeed: 0.0563s/iter; left time: 1162.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.1023776 Vali Loss: 0.1218576 Test Loss: 0.1468516\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994126\n",
      "\tspeed: 0.0974s/iter; left time: 2000.8456s\n",
      "\titers: 200, epoch: 8 | loss: 0.0971872\n",
      "\tspeed: 0.0562s/iter; left time: 1148.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1013684 Vali Loss: 0.1218202 Test Loss: 0.1467308\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008324\n",
      "\tspeed: 0.0978s/iter; left time: 1987.1658s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001003\n",
      "\tspeed: 0.0561s/iter; left time: 1135.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1004547 Vali Loss: 0.1227126 Test Loss: 0.1460044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0981952\n",
      "\tspeed: 0.0970s/iter; left time: 1950.1614s\n",
      "\titers: 200, epoch: 10 | loss: 0.1011151\n",
      "\tspeed: 0.0562s/iter; left time: 1124.2371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0996076 Vali Loss: 0.1219485 Test Loss: 0.1458998\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022985\n",
      "\tspeed: 0.0968s/iter; left time: 1924.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0971800\n",
      "\tspeed: 0.0562s/iter; left time: 1112.3330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0987144 Vali Loss: 0.1226570 Test Loss: 0.1463754\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019033\n",
      "\tspeed: 0.0973s/iter; left time: 1912.4186s\n",
      "\titers: 200, epoch: 12 | loss: 0.0964095\n",
      "\tspeed: 0.0562s/iter; left time: 1100.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0978685 Vali Loss: 0.1225567 Test Loss: 0.1457474\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0953344\n",
      "\tspeed: 0.0966s/iter; left time: 1878.4410s\n",
      "\titers: 200, epoch: 13 | loss: 0.0992721\n",
      "\tspeed: 0.0562s/iter; left time: 1087.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0971082 Vali Loss: 0.1227023 Test Loss: 0.1472565\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0926120\n",
      "\tspeed: 0.0967s/iter; left time: 1858.5787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0951313\n",
      "\tspeed: 0.0562s/iter; left time: 1074.8672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0964137 Vali Loss: 0.1233526 Test Loss: 0.1470043\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042849574238061905, rmse:0.20700138807296753, mae:0.14414843916893005, rse:0.7177035808563232\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354991\n",
      "\tspeed: 0.0578s/iter; left time: 1278.1000s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270298\n",
      "\tspeed: 0.0562s/iter; left time: 1235.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1335611 Vali Loss: 0.1309445 Test Loss: 0.1545844\n",
      "Validation loss decreased (inf --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1133388\n",
      "\tspeed: 0.0999s/iter; left time: 2186.3013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1125569\n",
      "\tspeed: 0.0562s/iter; left time: 1224.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1122486 Vali Loss: 0.1214251 Test Loss: 0.1446685\n",
      "Validation loss decreased (0.130944 --> 0.121425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1068718\n",
      "\tspeed: 0.0986s/iter; left time: 2135.8821s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110569\n",
      "\tspeed: 0.0562s/iter; left time: 1211.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1077239 Vali Loss: 0.1201799 Test Loss: 0.1456124\n",
      "Validation loss decreased (0.121425 --> 0.120180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068212\n",
      "\tspeed: 0.0992s/iter; left time: 2126.1356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1060848\n",
      "\tspeed: 0.0562s/iter; left time: 1199.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1062277 Vali Loss: 0.1203073 Test Loss: 0.1457645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1072107\n",
      "\tspeed: 0.0976s/iter; left time: 2071.3545s\n",
      "\titers: 200, epoch: 5 | loss: 0.1050748\n",
      "\tspeed: 0.0562s/iter; left time: 1187.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1048063 Vali Loss: 0.1204287 Test Loss: 0.1452082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1055551\n",
      "\tspeed: 0.0977s/iter; left time: 2050.0902s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049092\n",
      "\tspeed: 0.0562s/iter; left time: 1174.0853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1034492 Vali Loss: 0.1209216 Test Loss: 0.1464381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1012986\n",
      "\tspeed: 0.0978s/iter; left time: 2031.0061s\n",
      "\titers: 200, epoch: 7 | loss: 0.0988212\n",
      "\tspeed: 0.0562s/iter; left time: 1161.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1020838 Vali Loss: 0.1218336 Test Loss: 0.1478448\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1025517\n",
      "\tspeed: 0.0974s/iter; left time: 2001.2240s\n",
      "\titers: 200, epoch: 8 | loss: 0.1005487\n",
      "\tspeed: 0.0562s/iter; left time: 1148.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1008029 Vali Loss: 0.1223594 Test Loss: 0.1472702\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0975043\n",
      "\tspeed: 0.0974s/iter; left time: 1979.6024s\n",
      "\titers: 200, epoch: 9 | loss: 0.0961284\n",
      "\tspeed: 0.0562s/iter; left time: 1137.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0996357 Vali Loss: 0.1229091 Test Loss: 0.1470626\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0974637\n",
      "\tspeed: 0.0974s/iter; left time: 1957.4357s\n",
      "\titers: 200, epoch: 10 | loss: 0.0978937\n",
      "\tspeed: 0.0562s/iter; left time: 1124.2371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0983070 Vali Loss: 0.1235878 Test Loss: 0.1470104\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0942716\n",
      "\tspeed: 0.0973s/iter; left time: 1935.1333s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986272\n",
      "\tspeed: 0.0562s/iter; left time: 1112.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0972591 Vali Loss: 0.1241986 Test Loss: 0.1483821\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0955178\n",
      "\tspeed: 0.0972s/iter; left time: 1911.0378s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003032\n",
      "\tspeed: 0.0562s/iter; left time: 1100.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0963243 Vali Loss: 0.1242227 Test Loss: 0.1486393\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0958638\n",
      "\tspeed: 0.0974s/iter; left time: 1894.0650s\n",
      "\titers: 200, epoch: 13 | loss: 0.0918685\n",
      "\tspeed: 0.0563s/iter; left time: 1087.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0954410 Vali Loss: 0.1246279 Test Loss: 0.1481834\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04403311014175415, rmse:0.20984068512916565, mae:0.145612433552742, rse:0.7275477647781372\n",
      "Intermediate time for GB and pred_len 168: 00h:07m:10.11s\n",
      "Intermediate time for GB: 00h:44m:08.61s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1175637\n",
      "\tspeed: 0.0539s/iter; left time: 1197.6987s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060088\n",
      "\tspeed: 0.0349s/iter; left time: 770.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 223 | Train Loss: 0.1258741 Vali Loss: 0.0934121 Test Loss: 0.1067465\n",
      "Validation loss decreased (inf --> 0.093412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0715940\n",
      "\tspeed: 0.0640s/iter; left time: 1405.7288s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685092\n",
      "\tspeed: 0.0349s/iter; left time: 762.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0747378 Vali Loss: 0.0624876 Test Loss: 0.0695573\n",
      "Validation loss decreased (0.093412 --> 0.062488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635684\n",
      "\tspeed: 0.0649s/iter; left time: 1412.1529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0621238\n",
      "\tspeed: 0.0349s/iter; left time: 754.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0643560 Vali Loss: 0.0598924 Test Loss: 0.0667066\n",
      "Validation loss decreased (0.062488 --> 0.059892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0643697\n",
      "\tspeed: 0.0639s/iter; left time: 1376.3862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0598484\n",
      "\tspeed: 0.0349s/iter; left time: 747.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0616906 Vali Loss: 0.0581373 Test Loss: 0.0651106\n",
      "Validation loss decreased (0.059892 --> 0.058137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0595916\n",
      "\tspeed: 0.0639s/iter; left time: 1361.1248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612903\n",
      "\tspeed: 0.0349s/iter; left time: 740.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0598992 Vali Loss: 0.0570621 Test Loss: 0.0634679\n",
      "Validation loss decreased (0.058137 --> 0.057062).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566540\n",
      "\tspeed: 0.0640s/iter; left time: 1350.0472s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576317\n",
      "\tspeed: 0.0348s/iter; left time: 730.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0587601 Vali Loss: 0.0561196 Test Loss: 0.0627356\n",
      "Validation loss decreased (0.057062 --> 0.056120).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0537630\n",
      "\tspeed: 0.0642s/iter; left time: 1338.9650s\n",
      "\titers: 200, epoch: 7 | loss: 0.0569170\n",
      "\tspeed: 0.0348s/iter; left time: 722.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0579201 Vali Loss: 0.0557699 Test Loss: 0.0623582\n",
      "Validation loss decreased (0.056120 --> 0.055770).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542791\n",
      "\tspeed: 0.0642s/iter; left time: 1325.0179s\n",
      "\titers: 200, epoch: 8 | loss: 0.0535772\n",
      "\tspeed: 0.0348s/iter; left time: 715.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0571417 Vali Loss: 0.0554661 Test Loss: 0.0623493\n",
      "Validation loss decreased (0.055770 --> 0.055466).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552964\n",
      "\tspeed: 0.0636s/iter; left time: 1297.8393s\n",
      "\titers: 200, epoch: 9 | loss: 0.0563664\n",
      "\tspeed: 0.0348s/iter; left time: 707.5805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0565837 Vali Loss: 0.0556016 Test Loss: 0.0629203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570711\n",
      "\tspeed: 0.0634s/iter; left time: 1280.1725s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551535\n",
      "\tspeed: 0.0348s/iter; left time: 699.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0560324 Vali Loss: 0.0548921 Test Loss: 0.0620095\n",
      "Validation loss decreased (0.055466 --> 0.054892).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0551980\n",
      "\tspeed: 0.0639s/iter; left time: 1276.4136s\n",
      "\titers: 200, epoch: 11 | loss: 0.0572951\n",
      "\tspeed: 0.0348s/iter; left time: 692.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0556399 Vali Loss: 0.0546968 Test Loss: 0.0617010\n",
      "Validation loss decreased (0.054892 --> 0.054697).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0568327\n",
      "\tspeed: 0.0644s/iter; left time: 1270.9269s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558428\n",
      "\tspeed: 0.0349s/iter; left time: 685.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0552164 Vali Loss: 0.0544590 Test Loss: 0.0614751\n",
      "Validation loss decreased (0.054697 --> 0.054459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0542535\n",
      "\tspeed: 0.0641s/iter; left time: 1251.9684s\n",
      "\titers: 200, epoch: 13 | loss: 0.0545616\n",
      "\tspeed: 0.0348s/iter; left time: 676.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0549488 Vali Loss: 0.0545881 Test Loss: 0.0614434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523805\n",
      "\tspeed: 0.0629s/iter; left time: 1213.4130s\n",
      "\titers: 200, epoch: 14 | loss: 0.0542101\n",
      "\tspeed: 0.0349s/iter; left time: 669.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0546171 Vali Loss: 0.0541874 Test Loss: 0.0611198\n",
      "Validation loss decreased (0.054459 --> 0.054187).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0497755\n",
      "\tspeed: 0.0640s/iter; left time: 1220.7282s\n",
      "\titers: 200, epoch: 15 | loss: 0.0600670\n",
      "\tspeed: 0.0349s/iter; left time: 662.4437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0543438 Vali Loss: 0.0538917 Test Loss: 0.0610247\n",
      "Validation loss decreased (0.054187 --> 0.053892).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0559755\n",
      "\tspeed: 0.0640s/iter; left time: 1206.6236s\n",
      "\titers: 200, epoch: 16 | loss: 0.0507899\n",
      "\tspeed: 0.0348s/iter; left time: 653.3455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0541344 Vali Loss: 0.0536988 Test Loss: 0.0605547\n",
      "Validation loss decreased (0.053892 --> 0.053699).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0569965\n",
      "\tspeed: 0.0658s/iter; left time: 1226.5335s\n",
      "\titers: 200, epoch: 17 | loss: 0.0506428\n",
      "\tspeed: 0.0348s/iter; left time: 644.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0539298 Vali Loss: 0.0534636 Test Loss: 0.0604280\n",
      "Validation loss decreased (0.053699 --> 0.053464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0565841\n",
      "\tspeed: 0.0639s/iter; left time: 1176.2585s\n",
      "\titers: 200, epoch: 18 | loss: 0.0540568\n",
      "\tspeed: 0.0348s/iter; left time: 636.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0537874 Vali Loss: 0.0535432 Test Loss: 0.0605775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0548989\n",
      "\tspeed: 0.0634s/iter; left time: 1153.7619s\n",
      "\titers: 200, epoch: 19 | loss: 0.0527071\n",
      "\tspeed: 0.0347s/iter; left time: 628.4186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0535218 Vali Loss: 0.0535281 Test Loss: 0.0603313\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0550305\n",
      "\tspeed: 0.0634s/iter; left time: 1138.6081s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543642\n",
      "\tspeed: 0.0347s/iter; left time: 620.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0534504 Vali Loss: 0.0532689 Test Loss: 0.0604245\n",
      "Validation loss decreased (0.053464 --> 0.053269).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0523972\n",
      "\tspeed: 0.0642s/iter; left time: 1139.5554s\n",
      "\titers: 200, epoch: 21 | loss: 0.0529216\n",
      "\tspeed: 0.0348s/iter; left time: 614.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0532740 Vali Loss: 0.0531319 Test Loss: 0.0601385\n",
      "Validation loss decreased (0.053269 --> 0.053132).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0521433\n",
      "\tspeed: 0.0634s/iter; left time: 1110.0221s\n",
      "\titers: 200, epoch: 22 | loss: 0.0547027\n",
      "\tspeed: 0.0348s/iter; left time: 605.8963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0532038 Vali Loss: 0.0531704 Test Loss: 0.0603939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0536981\n",
      "\tspeed: 0.0627s/iter; left time: 1084.6706s\n",
      "\titers: 200, epoch: 23 | loss: 0.0563880\n",
      "\tspeed: 0.0348s/iter; left time: 598.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0531312 Vali Loss: 0.0531458 Test Loss: 0.0602351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0546271\n",
      "\tspeed: 0.0633s/iter; left time: 1080.1650s\n",
      "\titers: 200, epoch: 24 | loss: 0.0504135\n",
      "\tspeed: 0.0348s/iter; left time: 590.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0529921 Vali Loss: 0.0530581 Test Loss: 0.0600498\n",
      "Validation loss decreased (0.053132 --> 0.053058).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0553383\n",
      "\tspeed: 0.0641s/iter; left time: 1080.2681s\n",
      "\titers: 200, epoch: 25 | loss: 0.0518673\n",
      "\tspeed: 0.0348s/iter; left time: 582.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0528590 Vali Loss: 0.0530624 Test Loss: 0.0601539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0514446\n",
      "\tspeed: 0.0636s/iter; left time: 1057.3343s\n",
      "\titers: 200, epoch: 26 | loss: 0.0503461\n",
      "\tspeed: 0.0348s/iter; left time: 574.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0528106 Vali Loss: 0.0528923 Test Loss: 0.0600861\n",
      "Validation loss decreased (0.053058 --> 0.052892).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517057\n",
      "\tspeed: 0.0634s/iter; left time: 1039.4872s\n",
      "\titers: 200, epoch: 27 | loss: 0.0537945\n",
      "\tspeed: 0.0348s/iter; left time: 566.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0528068 Vali Loss: 0.0531387 Test Loss: 0.0601630\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0525555\n",
      "\tspeed: 0.0632s/iter; left time: 1022.5375s\n",
      "\titers: 200, epoch: 28 | loss: 0.0549811\n",
      "\tspeed: 0.0348s/iter; left time: 559.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0526904 Vali Loss: 0.0528783 Test Loss: 0.0598450\n",
      "Validation loss decreased (0.052892 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0500230\n",
      "\tspeed: 0.0638s/iter; left time: 1018.3266s\n",
      "\titers: 200, epoch: 29 | loss: 0.0551892\n",
      "\tspeed: 0.0348s/iter; left time: 552.4548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0526697 Vali Loss: 0.0527954 Test Loss: 0.0598333\n",
      "Validation loss decreased (0.052878 --> 0.052795).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0544261\n",
      "\tspeed: 0.0637s/iter; left time: 1001.4913s\n",
      "\titers: 200, epoch: 30 | loss: 0.0517382\n",
      "\tspeed: 0.0348s/iter; left time: 543.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0526079 Vali Loss: 0.0527942 Test Loss: 0.0599940\n",
      "Validation loss decreased (0.052795 --> 0.052794).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509290\n",
      "\tspeed: 0.0648s/iter; left time: 1005.2482s\n",
      "\titers: 200, epoch: 31 | loss: 0.0522115\n",
      "\tspeed: 0.0347s/iter; left time: 535.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0525354 Vali Loss: 0.0528468 Test Loss: 0.0600238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0518514\n",
      "\tspeed: 0.0632s/iter; left time: 966.6202s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561669\n",
      "\tspeed: 0.0348s/iter; left time: 528.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0525267 Vali Loss: 0.0528122 Test Loss: 0.0600026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549385\n",
      "\tspeed: 0.0635s/iter; left time: 956.5434s\n",
      "\titers: 200, epoch: 33 | loss: 0.0550187\n",
      "\tspeed: 0.0347s/iter; left time: 519.9973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0524861 Vali Loss: 0.0527625 Test Loss: 0.0598903\n",
      "Validation loss decreased (0.052794 --> 0.052763).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0545956\n",
      "\tspeed: 0.0640s/iter; left time: 950.3746s\n",
      "\titers: 200, epoch: 34 | loss: 0.0507859\n",
      "\tspeed: 0.0347s/iter; left time: 512.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0524479 Vali Loss: 0.0527562 Test Loss: 0.0599022\n",
      "Validation loss decreased (0.052763 --> 0.052756).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0541387\n",
      "\tspeed: 0.0636s/iter; left time: 929.6086s\n",
      "\titers: 200, epoch: 35 | loss: 0.0549738\n",
      "\tspeed: 0.0348s/iter; left time: 505.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0524044 Vali Loss: 0.0526615 Test Loss: 0.0598362\n",
      "Validation loss decreased (0.052756 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545615\n",
      "\tspeed: 0.0638s/iter; left time: 917.7742s\n",
      "\titers: 200, epoch: 36 | loss: 0.0542032\n",
      "\tspeed: 0.0348s/iter; left time: 497.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0523493 Vali Loss: 0.0526948 Test Loss: 0.0597999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0499858\n",
      "\tspeed: 0.0633s/iter; left time: 897.6538s\n",
      "\titers: 200, epoch: 37 | loss: 0.0523338\n",
      "\tspeed: 0.0348s/iter; left time: 489.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0523323 Vali Loss: 0.0526763 Test Loss: 0.0599144\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0525568\n",
      "\tspeed: 0.0631s/iter; left time: 879.5964s\n",
      "\titers: 200, epoch: 38 | loss: 0.0531557\n",
      "\tspeed: 0.0348s/iter; left time: 481.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523191 Vali Loss: 0.0528053 Test Loss: 0.0598900\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0517309\n",
      "\tspeed: 0.0632s/iter; left time: 867.8943s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516564\n",
      "\tspeed: 0.0348s/iter; left time: 474.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522917 Vali Loss: 0.0527077 Test Loss: 0.0598312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0536129\n",
      "\tspeed: 0.0633s/iter; left time: 855.3285s\n",
      "\titers: 200, epoch: 40 | loss: 0.0507274\n",
      "\tspeed: 0.0347s/iter; left time: 465.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0523048 Vali Loss: 0.0527075 Test Loss: 0.0598177\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530339\n",
      "\tspeed: 0.0636s/iter; left time: 844.5963s\n",
      "\titers: 200, epoch: 41 | loss: 0.0536149\n",
      "\tspeed: 0.0347s/iter; left time: 457.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0523129 Vali Loss: 0.0526658 Test Loss: 0.0599047\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0494002\n",
      "\tspeed: 0.0631s/iter; left time: 824.4909s\n",
      "\titers: 200, epoch: 42 | loss: 0.0515069\n",
      "\tspeed: 0.0347s/iter; left time: 449.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0522722 Vali Loss: 0.0526509 Test Loss: 0.0598522\n",
      "Validation loss decreased (0.052662 --> 0.052651).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0539627\n",
      "\tspeed: 0.0652s/iter; left time: 837.1283s\n",
      "\titers: 200, epoch: 43 | loss: 0.0533281\n",
      "\tspeed: 0.0348s/iter; left time: 442.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0523110 Vali Loss: 0.0525890 Test Loss: 0.0597770\n",
      "Validation loss decreased (0.052651 --> 0.052589).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0521373\n",
      "\tspeed: 0.0636s/iter; left time: 802.5087s\n",
      "\titers: 200, epoch: 44 | loss: 0.0501604\n",
      "\tspeed: 0.0348s/iter; left time: 435.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522199 Vali Loss: 0.0526631 Test Loss: 0.0598244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0566270\n",
      "\tspeed: 0.0637s/iter; left time: 789.3379s\n",
      "\titers: 200, epoch: 45 | loss: 0.0523463\n",
      "\tspeed: 0.0348s/iter; left time: 427.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522631 Vali Loss: 0.0527159 Test Loss: 0.0598033\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0528714\n",
      "\tspeed: 0.0631s/iter; left time: 767.5373s\n",
      "\titers: 200, epoch: 46 | loss: 0.0532004\n",
      "\tspeed: 0.0348s/iter; left time: 419.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522354 Vali Loss: 0.0526221 Test Loss: 0.0598067\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528335\n",
      "\tspeed: 0.0632s/iter; left time: 755.1653s\n",
      "\titers: 200, epoch: 47 | loss: 0.0564661\n",
      "\tspeed: 0.0347s/iter; left time: 411.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523151 Vali Loss: 0.0526697 Test Loss: 0.0597932\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0519690\n",
      "\tspeed: 0.0634s/iter; left time: 743.0612s\n",
      "\titers: 200, epoch: 48 | loss: 0.0549003\n",
      "\tspeed: 0.0348s/iter; left time: 404.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522235 Vali Loss: 0.0526347 Test Loss: 0.0597990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543164\n",
      "\tspeed: 0.0631s/iter; left time: 725.7057s\n",
      "\titers: 200, epoch: 49 | loss: 0.0473209\n",
      "\tspeed: 0.0347s/iter; left time: 395.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522493 Vali Loss: 0.0526192 Test Loss: 0.0598093\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0499371\n",
      "\tspeed: 0.0632s/iter; left time: 712.6842s\n",
      "\titers: 200, epoch: 50 | loss: 0.0519783\n",
      "\tspeed: 0.0348s/iter; left time: 388.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522329 Vali Loss: 0.0526891 Test Loss: 0.0598834\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0568660\n",
      "\tspeed: 0.0631s/iter; left time: 696.8242s\n",
      "\titers: 200, epoch: 51 | loss: 0.0513868\n",
      "\tspeed: 0.0347s/iter; left time: 380.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522060 Vali Loss: 0.0526809 Test Loss: 0.0598164\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0506357\n",
      "\tspeed: 0.0632s/iter; left time: 684.8435s\n",
      "\titers: 200, epoch: 52 | loss: 0.0513345\n",
      "\tspeed: 0.0348s/iter; left time: 373.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0521876 Vali Loss: 0.0526349 Test Loss: 0.0598106\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0541688\n",
      "\tspeed: 0.0632s/iter; left time: 669.7787s\n",
      "\titers: 200, epoch: 53 | loss: 0.0502305\n",
      "\tspeed: 0.0348s/iter; left time: 365.2347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521811 Vali Loss: 0.0526638 Test Loss: 0.0598178\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009866542182862759, rmse:0.09933046996593475, mae:0.05977698788046837, rse:0.29231756925582886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1220326\n",
      "\tspeed: 0.0364s/iter; left time: 808.0457s\n",
      "\titers: 200, epoch: 1 | loss: 0.1029346\n",
      "\tspeed: 0.0348s/iter; left time: 769.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.1259346 Vali Loss: 0.0930124 Test Loss: 0.1065052\n",
      "Validation loss decreased (inf --> 0.093012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0726846\n",
      "\tspeed: 0.0640s/iter; left time: 1406.5569s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688826\n",
      "\tspeed: 0.0348s/iter; left time: 760.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0747757 Vali Loss: 0.0630129 Test Loss: 0.0701470\n",
      "Validation loss decreased (0.093012 --> 0.063013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0630229\n",
      "\tspeed: 0.0638s/iter; left time: 1388.3226s\n",
      "\titers: 200, epoch: 3 | loss: 0.0606441\n",
      "\tspeed: 0.0348s/iter; left time: 752.8131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0643692 Vali Loss: 0.0595219 Test Loss: 0.0660069\n",
      "Validation loss decreased (0.063013 --> 0.059522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0577680\n",
      "\tspeed: 0.0636s/iter; left time: 1369.1470s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634644\n",
      "\tspeed: 0.0348s/iter; left time: 746.0911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0615642 Vali Loss: 0.0584180 Test Loss: 0.0651230\n",
      "Validation loss decreased (0.059522 --> 0.058418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608671\n",
      "\tspeed: 0.0634s/iter; left time: 1350.4796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0647859\n",
      "\tspeed: 0.0348s/iter; left time: 738.8029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0598110 Vali Loss: 0.0573382 Test Loss: 0.0638470\n",
      "Validation loss decreased (0.058418 --> 0.057338).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577245\n",
      "\tspeed: 0.0637s/iter; left time: 1343.0667s\n",
      "\titers: 200, epoch: 6 | loss: 0.0596926\n",
      "\tspeed: 0.0348s/iter; left time: 730.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0586960 Vali Loss: 0.0561589 Test Loss: 0.0628494\n",
      "Validation loss decreased (0.057338 --> 0.056159).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0554998\n",
      "\tspeed: 0.0630s/iter; left time: 1315.0874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0615113\n",
      "\tspeed: 0.0347s/iter; left time: 721.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0577603 Vali Loss: 0.0560129 Test Loss: 0.0629468\n",
      "Validation loss decreased (0.056159 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0617084\n",
      "\tspeed: 0.0634s/iter; left time: 1308.8752s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562230\n",
      "\tspeed: 0.0348s/iter; left time: 715.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0571237 Vali Loss: 0.0552313 Test Loss: 0.0622659\n",
      "Validation loss decreased (0.056013 --> 0.055231).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549473\n",
      "\tspeed: 0.0634s/iter; left time: 1294.6717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0565709\n",
      "\tspeed: 0.0348s/iter; left time: 706.5157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0564831 Vali Loss: 0.0553474 Test Loss: 0.0621103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554801\n",
      "\tspeed: 0.0627s/iter; left time: 1266.8730s\n",
      "\titers: 200, epoch: 10 | loss: 0.0555981\n",
      "\tspeed: 0.0348s/iter; left time: 698.7287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0559145 Vali Loss: 0.0549688 Test Loss: 0.0617780\n",
      "Validation loss decreased (0.055231 --> 0.054969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0557911\n",
      "\tspeed: 0.0641s/iter; left time: 1279.4897s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561363\n",
      "\tspeed: 0.0348s/iter; left time: 691.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0555488 Vali Loss: 0.0545749 Test Loss: 0.0615567\n",
      "Validation loss decreased (0.054969 --> 0.054575).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0546582\n",
      "\tspeed: 0.0646s/iter; left time: 1276.6914s\n",
      "\titers: 200, epoch: 12 | loss: 0.0536586\n",
      "\tspeed: 0.0348s/iter; left time: 683.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0551339 Vali Loss: 0.0539980 Test Loss: 0.0610293\n",
      "Validation loss decreased (0.054575 --> 0.053998).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0567421\n",
      "\tspeed: 0.0655s/iter; left time: 1279.7422s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555143\n",
      "\tspeed: 0.0348s/iter; left time: 675.8562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0547809 Vali Loss: 0.0539634 Test Loss: 0.0609647\n",
      "Validation loss decreased (0.053998 --> 0.053963).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559703\n",
      "\tspeed: 0.0635s/iter; left time: 1226.2728s\n",
      "\titers: 200, epoch: 14 | loss: 0.0540294\n",
      "\tspeed: 0.0348s/iter; left time: 667.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0545201 Vali Loss: 0.0537920 Test Loss: 0.0607807\n",
      "Validation loss decreased (0.053963 --> 0.053792).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571534\n",
      "\tspeed: 0.0633s/iter; left time: 1206.8337s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574851\n",
      "\tspeed: 0.0348s/iter; left time: 659.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0542520 Vali Loss: 0.0537604 Test Loss: 0.0608433\n",
      "Validation loss decreased (0.053792 --> 0.053760).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0579594\n",
      "\tspeed: 0.0634s/iter; left time: 1195.8435s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538236\n",
      "\tspeed: 0.0348s/iter; left time: 652.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0540514 Vali Loss: 0.0534855 Test Loss: 0.0605299\n",
      "Validation loss decreased (0.053760 --> 0.053486).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0563427\n",
      "\tspeed: 0.0634s/iter; left time: 1182.1512s\n",
      "\titers: 200, epoch: 17 | loss: 0.0530981\n",
      "\tspeed: 0.0348s/iter; left time: 644.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0538100 Vali Loss: 0.0537486 Test Loss: 0.0609309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0554305\n",
      "\tspeed: 0.0628s/iter; left time: 1156.8952s\n",
      "\titers: 200, epoch: 18 | loss: 0.0560160\n",
      "\tspeed: 0.0348s/iter; left time: 636.5147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0536474 Vali Loss: 0.0534000 Test Loss: 0.0606266\n",
      "Validation loss decreased (0.053486 --> 0.053400).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525237\n",
      "\tspeed: 0.0636s/iter; left time: 1155.9690s\n",
      "\titers: 200, epoch: 19 | loss: 0.0536887\n",
      "\tspeed: 0.0348s/iter; left time: 629.7454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0534839 Vali Loss: 0.0532571 Test Loss: 0.0605488\n",
      "Validation loss decreased (0.053400 --> 0.053257).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549485\n",
      "\tspeed: 0.0635s/iter; left time: 1141.0508s\n",
      "\titers: 200, epoch: 20 | loss: 0.0514710\n",
      "\tspeed: 0.0348s/iter; left time: 621.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0533952 Vali Loss: 0.0533304 Test Loss: 0.0602945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0535472\n",
      "\tspeed: 0.0630s/iter; left time: 1117.8355s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519489\n",
      "\tspeed: 0.0348s/iter; left time: 613.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0532001 Vali Loss: 0.0531706 Test Loss: 0.0604976\n",
      "Validation loss decreased (0.053257 --> 0.053171).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0557677\n",
      "\tspeed: 0.0635s/iter; left time: 1112.5365s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539617\n",
      "\tspeed: 0.0348s/iter; left time: 605.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0531452 Vali Loss: 0.0529666 Test Loss: 0.0602932\n",
      "Validation loss decreased (0.053171 --> 0.052967).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0514711\n",
      "\tspeed: 0.0632s/iter; left time: 1093.1251s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566470\n",
      "\tspeed: 0.0348s/iter; left time: 599.1830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0530440 Vali Loss: 0.0530361 Test Loss: 0.0602941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492075\n",
      "\tspeed: 0.0631s/iter; left time: 1077.1810s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510157\n",
      "\tspeed: 0.0348s/iter; left time: 590.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0529677 Vali Loss: 0.0528758 Test Loss: 0.0600719\n",
      "Validation loss decreased (0.052967 --> 0.052876).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0576330\n",
      "\tspeed: 0.0633s/iter; left time: 1067.3515s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552283\n",
      "\tspeed: 0.0348s/iter; left time: 582.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0528415 Vali Loss: 0.0529786 Test Loss: 0.0600655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0512867\n",
      "\tspeed: 0.0628s/iter; left time: 1044.1945s\n",
      "\titers: 200, epoch: 26 | loss: 0.0496288\n",
      "\tspeed: 0.0348s/iter; left time: 574.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0527987 Vali Loss: 0.0530332 Test Loss: 0.0601122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0509674\n",
      "\tspeed: 0.0627s/iter; left time: 1028.3703s\n",
      "\titers: 200, epoch: 27 | loss: 0.0484194\n",
      "\tspeed: 0.0348s/iter; left time: 566.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0527392 Vali Loss: 0.0528903 Test Loss: 0.0600539\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0530106\n",
      "\tspeed: 0.0628s/iter; left time: 1016.4508s\n",
      "\titers: 200, epoch: 28 | loss: 0.0531000\n",
      "\tspeed: 0.0348s/iter; left time: 558.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0527272 Vali Loss: 0.0529470 Test Loss: 0.0600106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0491770\n",
      "\tspeed: 0.0630s/iter; left time: 1005.7877s\n",
      "\titers: 200, epoch: 29 | loss: 0.0452469\n",
      "\tspeed: 0.0348s/iter; left time: 552.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0526793 Vali Loss: 0.0528311 Test Loss: 0.0599793\n",
      "Validation loss decreased (0.052876 --> 0.052831).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0550407\n",
      "\tspeed: 0.0633s/iter; left time: 996.5060s\n",
      "\titers: 200, epoch: 30 | loss: 0.0518973\n",
      "\tspeed: 0.0348s/iter; left time: 543.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0526110 Vali Loss: 0.0528266 Test Loss: 0.0600462\n",
      "Validation loss decreased (0.052831 --> 0.052827).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542863\n",
      "\tspeed: 0.0635s/iter; left time: 985.3027s\n",
      "\titers: 200, epoch: 31 | loss: 0.0546150\n",
      "\tspeed: 0.0348s/iter; left time: 535.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0525636 Vali Loss: 0.0527613 Test Loss: 0.0599322\n",
      "Validation loss decreased (0.052827 --> 0.052761).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0539835\n",
      "\tspeed: 0.0635s/iter; left time: 970.0583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0490118\n",
      "\tspeed: 0.0348s/iter; left time: 528.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0524810 Vali Loss: 0.0527825 Test Loss: 0.0599976\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549474\n",
      "\tspeed: 0.0631s/iter; left time: 950.4359s\n",
      "\titers: 200, epoch: 33 | loss: 0.0535856\n",
      "\tspeed: 0.0348s/iter; left time: 520.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0525075 Vali Loss: 0.0527115 Test Loss: 0.0599608\n",
      "Validation loss decreased (0.052761 --> 0.052712).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0556550\n",
      "\tspeed: 0.0647s/iter; left time: 960.1710s\n",
      "\titers: 200, epoch: 34 | loss: 0.0515874\n",
      "\tspeed: 0.0348s/iter; left time: 513.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0524111 Vali Loss: 0.0526704 Test Loss: 0.0598688\n",
      "Validation loss decreased (0.052712 --> 0.052670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0557314\n",
      "\tspeed: 0.0633s/iter; left time: 926.0640s\n",
      "\titers: 200, epoch: 35 | loss: 0.0507834\n",
      "\tspeed: 0.0348s/iter; left time: 505.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0523630 Vali Loss: 0.0527240 Test Loss: 0.0598827\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0512614\n",
      "\tspeed: 0.0629s/iter; left time: 905.4383s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518102\n",
      "\tspeed: 0.0348s/iter; left time: 497.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0524054 Vali Loss: 0.0526994 Test Loss: 0.0598760\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0523046\n",
      "\tspeed: 0.0630s/iter; left time: 893.0770s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508446\n",
      "\tspeed: 0.0348s/iter; left time: 489.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523582 Vali Loss: 0.0527033 Test Loss: 0.0599662\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0494673\n",
      "\tspeed: 0.0630s/iter; left time: 878.4601s\n",
      "\titers: 200, epoch: 38 | loss: 0.0530426\n",
      "\tspeed: 0.0348s/iter; left time: 481.6451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0523731 Vali Loss: 0.0527296 Test Loss: 0.0598084\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0518862\n",
      "\tspeed: 0.0631s/iter; left time: 866.3405s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517699\n",
      "\tspeed: 0.0348s/iter; left time: 474.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0523550 Vali Loss: 0.0526709 Test Loss: 0.0597897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0523804\n",
      "\tspeed: 0.0629s/iter; left time: 849.3857s\n",
      "\titers: 200, epoch: 40 | loss: 0.0547245\n",
      "\tspeed: 0.0348s/iter; left time: 466.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522779 Vali Loss: 0.0526520 Test Loss: 0.0598167\n",
      "Validation loss decreased (0.052670 --> 0.052652).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0520796\n",
      "\tspeed: 0.0645s/iter; left time: 857.0303s\n",
      "\titers: 200, epoch: 41 | loss: 0.0510751\n",
      "\tspeed: 0.0363s/iter; left time: 477.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0522868 Vali Loss: 0.0526246 Test Loss: 0.0597722\n",
      "Validation loss decreased (0.052652 --> 0.052625).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0512310\n",
      "\tspeed: 0.0635s/iter; left time: 829.0423s\n",
      "\titers: 200, epoch: 42 | loss: 0.0529866\n",
      "\tspeed: 0.0348s/iter; left time: 451.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522490 Vali Loss: 0.0525609 Test Loss: 0.0597641\n",
      "Validation loss decreased (0.052625 --> 0.052561).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0510413\n",
      "\tspeed: 0.0632s/iter; left time: 811.6630s\n",
      "\titers: 200, epoch: 43 | loss: 0.0491077\n",
      "\tspeed: 0.0348s/iter; left time: 443.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522282 Vali Loss: 0.0525843 Test Loss: 0.0597606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0520502\n",
      "\tspeed: 0.0629s/iter; left time: 793.6619s\n",
      "\titers: 200, epoch: 44 | loss: 0.0531535\n",
      "\tspeed: 0.0349s/iter; left time: 436.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0522566 Vali Loss: 0.0526180 Test Loss: 0.0597909\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0503224\n",
      "\tspeed: 0.0635s/iter; left time: 786.1438s\n",
      "\titers: 200, epoch: 45 | loss: 0.0540412\n",
      "\tspeed: 0.0349s/iter; left time: 429.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522631 Vali Loss: 0.0525658 Test Loss: 0.0597489\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0557683\n",
      "\tspeed: 0.0634s/iter; left time: 771.0397s\n",
      "\titers: 200, epoch: 46 | loss: 0.0500644\n",
      "\tspeed: 0.0349s/iter; left time: 420.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0522589 Vali Loss: 0.0525750 Test Loss: 0.0597478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0505572\n",
      "\tspeed: 0.0631s/iter; left time: 753.5801s\n",
      "\titers: 200, epoch: 47 | loss: 0.0517297\n",
      "\tspeed: 0.0348s/iter; left time: 412.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522229 Vali Loss: 0.0525794 Test Loss: 0.0597371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0519887\n",
      "\tspeed: 0.0631s/iter; left time: 740.0177s\n",
      "\titers: 200, epoch: 48 | loss: 0.0505121\n",
      "\tspeed: 0.0348s/iter; left time: 404.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522587 Vali Loss: 0.0525739 Test Loss: 0.0597563\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0551468\n",
      "\tspeed: 0.0633s/iter; left time: 727.5549s\n",
      "\titers: 200, epoch: 49 | loss: 0.0543535\n",
      "\tspeed: 0.0349s/iter; left time: 397.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0522053 Vali Loss: 0.0526640 Test Loss: 0.0597686\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0530866\n",
      "\tspeed: 0.0860s/iter; left time: 969.2238s\n",
      "\titers: 200, epoch: 50 | loss: 0.0546758\n",
      "\tspeed: 0.1936s/iter; left time: 2162.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:29.79s\n",
      "Steps: 223 | Train Loss: 0.0521773 Vali Loss: 0.0525721 Test Loss: 0.0597589\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0559117\n",
      "\tspeed: 0.2853s/iter; left time: 3152.6291s\n",
      "\titers: 200, epoch: 51 | loss: 0.0528672\n",
      "\tspeed: 0.0355s/iter; left time: 389.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 223 | Train Loss: 0.0521526 Vali Loss: 0.0525845 Test Loss: 0.0597217\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0560968\n",
      "\tspeed: 0.0648s/iter; left time: 701.4242s\n",
      "\titers: 200, epoch: 52 | loss: 0.0540408\n",
      "\tspeed: 0.0347s/iter; left time: 371.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0521717 Vali Loss: 0.0525350 Test Loss: 0.0597281\n",
      "Validation loss decreased (0.052561 --> 0.052535).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529655\n",
      "\tspeed: 0.0641s/iter; left time: 679.3497s\n",
      "\titers: 200, epoch: 53 | loss: 0.0516334\n",
      "\tspeed: 0.0347s/iter; left time: 364.5613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0522050 Vali Loss: 0.0525881 Test Loss: 0.0597237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0511335\n",
      "\tspeed: 0.0633s/iter; left time: 657.0816s\n",
      "\titers: 200, epoch: 54 | loss: 0.0495469\n",
      "\tspeed: 0.0347s/iter; left time: 356.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522098 Vali Loss: 0.0525827 Test Loss: 0.0597430\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0499042\n",
      "\tspeed: 0.0638s/iter; left time: 647.9299s\n",
      "\titers: 200, epoch: 55 | loss: 0.0543089\n",
      "\tspeed: 0.0347s/iter; left time: 348.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0521472 Vali Loss: 0.0525706 Test Loss: 0.0597533\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0549883\n",
      "\tspeed: 0.0634s/iter; left time: 629.8835s\n",
      "\titers: 200, epoch: 56 | loss: 0.0486927\n",
      "\tspeed: 0.0347s/iter; left time: 341.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0521627 Vali Loss: 0.0525882 Test Loss: 0.0597260\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0517346\n",
      "\tspeed: 0.0640s/iter; left time: 621.6329s\n",
      "\titers: 200, epoch: 57 | loss: 0.0517503\n",
      "\tspeed: 0.0349s/iter; left time: 335.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0521682 Vali Loss: 0.0525590 Test Loss: 0.0597397\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0523834\n",
      "\tspeed: 0.0632s/iter; left time: 600.0961s\n",
      "\titers: 200, epoch: 58 | loss: 0.0494293\n",
      "\tspeed: 0.0346s/iter; left time: 325.1599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521432 Vali Loss: 0.0524969 Test Loss: 0.0597336\n",
      "Validation loss decreased (0.052535 --> 0.052497).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0492647\n",
      "\tspeed: 0.0634s/iter; left time: 587.0846s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519503\n",
      "\tspeed: 0.0346s/iter; left time: 317.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522087 Vali Loss: 0.0525812 Test Loss: 0.0597525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0497367\n",
      "\tspeed: 0.0630s/iter; left time: 570.0427s\n",
      "\titers: 200, epoch: 60 | loss: 0.0495885\n",
      "\tspeed: 0.0347s/iter; left time: 310.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521029 Vali Loss: 0.0525469 Test Loss: 0.0597159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0560998\n",
      "\tspeed: 0.0628s/iter; left time: 553.6345s\n",
      "\titers: 200, epoch: 61 | loss: 0.0487670\n",
      "\tspeed: 0.0346s/iter; left time: 301.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521652 Vali Loss: 0.0525439 Test Loss: 0.0597304\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0514731\n",
      "\tspeed: 0.0631s/iter; left time: 542.5550s\n",
      "\titers: 200, epoch: 62 | loss: 0.0511709\n",
      "\tspeed: 0.0347s/iter; left time: 294.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521105 Vali Loss: 0.0525647 Test Loss: 0.0597182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0521433\n",
      "\tspeed: 0.0628s/iter; left time: 526.2233s\n",
      "\titers: 200, epoch: 63 | loss: 0.0503324\n",
      "\tspeed: 0.0346s/iter; left time: 286.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0521071 Vali Loss: 0.0525776 Test Loss: 0.0597103\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0540591\n",
      "\tspeed: 0.0628s/iter; left time: 512.1828s\n",
      "\titers: 200, epoch: 64 | loss: 0.0516116\n",
      "\tspeed: 0.0346s/iter; left time: 278.9412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0522032 Vali Loss: 0.0525546 Test Loss: 0.0596993\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0474531\n",
      "\tspeed: 0.0630s/iter; left time: 499.7513s\n",
      "\titers: 200, epoch: 65 | loss: 0.0538364\n",
      "\tspeed: 0.0346s/iter; left time: 270.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521677 Vali Loss: 0.0525728 Test Loss: 0.0597150\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0497643\n",
      "\tspeed: 0.0629s/iter; left time: 484.6543s\n",
      "\titers: 200, epoch: 66 | loss: 0.0538237\n",
      "\tspeed: 0.0347s/iter; left time: 263.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521412 Vali Loss: 0.0525373 Test Loss: 0.0597279\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499914\n",
      "\tspeed: 0.0629s/iter; left time: 470.8134s\n",
      "\titers: 200, epoch: 67 | loss: 0.0554513\n",
      "\tspeed: 0.0346s/iter; left time: 255.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521308 Vali Loss: 0.0525533 Test Loss: 0.0597116\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0493037\n",
      "\tspeed: 0.0634s/iter; left time: 460.3703s\n",
      "\titers: 200, epoch: 68 | loss: 0.0565311\n",
      "\tspeed: 0.0347s/iter; left time: 248.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521564 Vali Loss: 0.0525395 Test Loss: 0.0596687\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009866722859442234, rmse:0.09933137893676758, mae:0.05973363667726517, rse:0.29232025146484375\n",
      "Intermediate time for ES and pred_len 24: 00h:20m:40.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1260398\n",
      "\tspeed: 0.0530s/iter; left time: 1172.3117s\n",
      "\titers: 200, epoch: 1 | loss: 0.1094058\n",
      "\tspeed: 0.0350s/iter; left time: 770.4190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 222 | Train Loss: 0.1312395 Vali Loss: 0.1025643 Test Loss: 0.1179704\n",
      "Validation loss decreased (inf --> 0.102564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0910940\n",
      "\tspeed: 0.0670s/iter; left time: 1466.3118s\n",
      "\titers: 200, epoch: 2 | loss: 0.0862823\n",
      "\tspeed: 0.0351s/iter; left time: 764.1153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0916984 Vali Loss: 0.0828621 Test Loss: 0.0948578\n",
      "Validation loss decreased (0.102564 --> 0.082862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0830963\n",
      "\tspeed: 0.0658s/iter; left time: 1425.5313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800575\n",
      "\tspeed: 0.0351s/iter; left time: 757.2695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0835440 Vali Loss: 0.0801127 Test Loss: 0.0918577\n",
      "Validation loss decreased (0.082862 --> 0.080113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827469\n",
      "\tspeed: 0.0655s/iter; left time: 1402.9393s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801315\n",
      "\tspeed: 0.0351s/iter; left time: 749.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0810485 Vali Loss: 0.0794556 Test Loss: 0.0912822\n",
      "Validation loss decreased (0.080113 --> 0.079456).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791584\n",
      "\tspeed: 0.0670s/iter; left time: 1421.3492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771858\n",
      "\tspeed: 0.0352s/iter; left time: 743.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0794836 Vali Loss: 0.0775880 Test Loss: 0.0889750\n",
      "Validation loss decreased (0.079456 --> 0.077588).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0784760\n",
      "\tspeed: 0.0650s/iter; left time: 1364.3395s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783841\n",
      "\tspeed: 0.0350s/iter; left time: 732.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0781405 Vali Loss: 0.0771143 Test Loss: 0.0890088\n",
      "Validation loss decreased (0.077588 --> 0.077114).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748558\n",
      "\tspeed: 0.0646s/iter; left time: 1340.6576s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760703\n",
      "\tspeed: 0.0351s/iter; left time: 725.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0771091 Vali Loss: 0.0769558 Test Loss: 0.0889577\n",
      "Validation loss decreased (0.077114 --> 0.076956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0765331\n",
      "\tspeed: 0.0650s/iter; left time: 1335.3036s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739735\n",
      "\tspeed: 0.0351s/iter; left time: 717.8247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0762211 Vali Loss: 0.0766279 Test Loss: 0.0881195\n",
      "Validation loss decreased (0.076956 --> 0.076628).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0740731\n",
      "\tspeed: 0.0655s/iter; left time: 1331.3336s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760542\n",
      "\tspeed: 0.0351s/iter; left time: 710.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0754744 Vali Loss: 0.0768604 Test Loss: 0.0877999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748701\n",
      "\tspeed: 0.0639s/iter; left time: 1284.6550s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732583\n",
      "\tspeed: 0.0351s/iter; left time: 701.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0747732 Vali Loss: 0.0759283 Test Loss: 0.0877505\n",
      "Validation loss decreased (0.076628 --> 0.075928).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744002\n",
      "\tspeed: 0.0644s/iter; left time: 1280.6382s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738547\n",
      "\tspeed: 0.0351s/iter; left time: 695.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0742015 Vali Loss: 0.0763542 Test Loss: 0.0879077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0763251\n",
      "\tspeed: 0.0638s/iter; left time: 1253.8331s\n",
      "\titers: 200, epoch: 12 | loss: 0.0744755\n",
      "\tspeed: 0.0350s/iter; left time: 685.4543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0737041 Vali Loss: 0.0765918 Test Loss: 0.0877662\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757539\n",
      "\tspeed: 0.0648s/iter; left time: 1258.6087s\n",
      "\titers: 200, epoch: 13 | loss: 0.0730051\n",
      "\tspeed: 0.0352s/iter; left time: 680.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0732794 Vali Loss: 0.0768405 Test Loss: 0.0879112\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0759228\n",
      "\tspeed: 0.0649s/iter; left time: 1246.7385s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697216\n",
      "\tspeed: 0.0351s/iter; left time: 670.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0729788 Vali Loss: 0.0768946 Test Loss: 0.0879021\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0712653\n",
      "\tspeed: 0.0642s/iter; left time: 1218.9842s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766184\n",
      "\tspeed: 0.0350s/iter; left time: 661.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 222 | Train Loss: 0.0726127 Vali Loss: 0.0770157 Test Loss: 0.0880994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0742202\n",
      "\tspeed: 0.0650s/iter; left time: 1220.9232s\n",
      "\titers: 200, epoch: 16 | loss: 0.0683738\n",
      "\tspeed: 0.0352s/iter; left time: 657.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0722651 Vali Loss: 0.0772379 Test Loss: 0.0881794\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0698431\n",
      "\tspeed: 0.0646s/iter; left time: 1198.5947s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702294\n",
      "\tspeed: 0.0352s/iter; left time: 650.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0719513 Vali Loss: 0.0765780 Test Loss: 0.0879023\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0715836\n",
      "\tspeed: 0.0643s/iter; left time: 1178.7720s\n",
      "\titers: 200, epoch: 18 | loss: 0.0724372\n",
      "\tspeed: 0.0353s/iter; left time: 643.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0717396 Vali Loss: 0.0768387 Test Loss: 0.0879140\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737238\n",
      "\tspeed: 0.0642s/iter; left time: 1163.0566s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690236\n",
      "\tspeed: 0.0351s/iter; left time: 631.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 222 | Train Loss: 0.0714695 Vali Loss: 0.0772368 Test Loss: 0.0880769\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733092\n",
      "\tspeed: 0.0641s/iter; left time: 1146.9008s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739523\n",
      "\tspeed: 0.0351s/iter; left time: 623.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0713218 Vali Loss: 0.0768432 Test Loss: 0.0879300\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018871869891881943, rmse:0.13737492263317108, mae:0.08775053173303604, rse:0.4035661816596985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1251608\n",
      "\tspeed: 0.0369s/iter; left time: 815.6401s\n",
      "\titers: 200, epoch: 1 | loss: 0.1145597\n",
      "\tspeed: 0.0351s/iter; left time: 772.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.1341426 Vali Loss: 0.1022528 Test Loss: 0.1178219\n",
      "Validation loss decreased (inf --> 0.102253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918480\n",
      "\tspeed: 0.0673s/iter; left time: 1471.8311s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841864\n",
      "\tspeed: 0.0351s/iter; left time: 765.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0917143 Vali Loss: 0.0827933 Test Loss: 0.0951420\n",
      "Validation loss decreased (0.102253 --> 0.082793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802328\n",
      "\tspeed: 0.0659s/iter; left time: 1427.4664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0848325\n",
      "\tspeed: 0.0351s/iter; left time: 756.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0834263 Vali Loss: 0.0801661 Test Loss: 0.0913073\n",
      "Validation loss decreased (0.082793 --> 0.080166).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818230\n",
      "\tspeed: 0.0643s/iter; left time: 1379.0318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802361\n",
      "\tspeed: 0.0351s/iter; left time: 748.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0809871 Vali Loss: 0.0786778 Test Loss: 0.0897193\n",
      "Validation loss decreased (0.080166 --> 0.078678).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772564\n",
      "\tspeed: 0.0652s/iter; left time: 1383.8049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0814229\n",
      "\tspeed: 0.0359s/iter; left time: 757.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0792988 Vali Loss: 0.0778066 Test Loss: 0.0885959\n",
      "Validation loss decreased (0.078678 --> 0.077807).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764081\n",
      "\tspeed: 0.2176s/iter; left time: 4566.7076s\n",
      "\titers: 200, epoch: 6 | loss: 0.0773624\n",
      "\tspeed: 0.1878s/iter; left time: 3923.8099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.55s\n",
      "Steps: 222 | Train Loss: 0.0779447 Vali Loss: 0.0773780 Test Loss: 0.0886872\n",
      "Validation loss decreased (0.077807 --> 0.077378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811512\n",
      "\tspeed: 0.1895s/iter; left time: 3936.2038s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761342\n",
      "\tspeed: 0.0351s/iter; left time: 724.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0769921 Vali Loss: 0.0766341 Test Loss: 0.0885049\n",
      "Validation loss decreased (0.077378 --> 0.076634).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770397\n",
      "\tspeed: 0.0646s/iter; left time: 1328.0639s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767725\n",
      "\tspeed: 0.0351s/iter; left time: 717.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0761878 Vali Loss: 0.0762908 Test Loss: 0.0881954\n",
      "Validation loss decreased (0.076634 --> 0.076291).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769685\n",
      "\tspeed: 0.0649s/iter; left time: 1319.4390s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753919\n",
      "\tspeed: 0.0356s/iter; left time: 720.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0754454 Vali Loss: 0.0759398 Test Loss: 0.0880421\n",
      "Validation loss decreased (0.076291 --> 0.075940).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743246\n",
      "\tspeed: 0.0665s/iter; left time: 1337.4520s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720993\n",
      "\tspeed: 0.0353s/iter; left time: 705.4292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0748660 Vali Loss: 0.0759301 Test Loss: 0.0884588\n",
      "Validation loss decreased (0.075940 --> 0.075930).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720741\n",
      "\tspeed: 0.0656s/iter; left time: 1304.3697s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748360\n",
      "\tspeed: 0.0351s/iter; left time: 695.1580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0743284 Vali Loss: 0.0763421 Test Loss: 0.0880268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726227\n",
      "\tspeed: 0.0646s/iter; left time: 1269.5504s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748167\n",
      "\tspeed: 0.0352s/iter; left time: 688.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0738782 Vali Loss: 0.0759847 Test Loss: 0.0881390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721753\n",
      "\tspeed: 0.0648s/iter; left time: 1258.6577s\n",
      "\titers: 200, epoch: 13 | loss: 0.0772060\n",
      "\tspeed: 0.0352s/iter; left time: 679.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0734766 Vali Loss: 0.0758512 Test Loss: 0.0878312\n",
      "Validation loss decreased (0.075930 --> 0.075851).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715857\n",
      "\tspeed: 0.0655s/iter; left time: 1258.5466s\n",
      "\titers: 200, epoch: 14 | loss: 0.0760631\n",
      "\tspeed: 0.0356s/iter; left time: 680.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0731019 Vali Loss: 0.0763125 Test Loss: 0.0881449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0728902\n",
      "\tspeed: 0.0664s/iter; left time: 1261.9057s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735835\n",
      "\tspeed: 0.0351s/iter; left time: 662.6150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0727445 Vali Loss: 0.0761350 Test Loss: 0.0879413\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0705711\n",
      "\tspeed: 0.0645s/iter; left time: 1210.8984s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673693\n",
      "\tspeed: 0.0351s/iter; left time: 656.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0725134 Vali Loss: 0.0764219 Test Loss: 0.0875670\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732625\n",
      "\tspeed: 0.0653s/iter; left time: 1210.4970s\n",
      "\titers: 200, epoch: 17 | loss: 0.0735754\n",
      "\tspeed: 0.0352s/iter; left time: 649.9066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0722842 Vali Loss: 0.0762213 Test Loss: 0.0875859\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754683\n",
      "\tspeed: 0.0651s/iter; left time: 1193.8060s\n",
      "\titers: 200, epoch: 18 | loss: 0.0736159\n",
      "\tspeed: 0.0352s/iter; left time: 642.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0720724 Vali Loss: 0.0760946 Test Loss: 0.0880375\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718110\n",
      "\tspeed: 0.0659s/iter; left time: 1192.2314s\n",
      "\titers: 200, epoch: 19 | loss: 0.0741730\n",
      "\tspeed: 0.0352s/iter; left time: 633.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0717672 Vali Loss: 0.0764167 Test Loss: 0.0877499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0699607\n",
      "\tspeed: 0.0677s/iter; left time: 1211.3845s\n",
      "\titers: 200, epoch: 20 | loss: 0.0741154\n",
      "\tspeed: 0.1638s/iter; left time: 2913.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 222 | Train Loss: 0.0715612 Vali Loss: 0.0762464 Test Loss: 0.0878026\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0707614\n",
      "\tspeed: 0.0929s/iter; left time: 1639.8626s\n",
      "\titers: 200, epoch: 21 | loss: 0.0679704\n",
      "\tspeed: 0.0365s/iter; left time: 640.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0714182 Vali Loss: 0.0766377 Test Loss: 0.0876773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0744809\n",
      "\tspeed: 0.3808s/iter; left time: 6639.9250s\n",
      "\titers: 200, epoch: 22 | loss: 0.0662124\n",
      "\tspeed: 0.0354s/iter; left time: 614.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 222 | Train Loss: 0.0713353 Vali Loss: 0.0763942 Test Loss: 0.0876612\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0721484\n",
      "\tspeed: 0.0647s/iter; left time: 1113.8564s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740722\n",
      "\tspeed: 0.0352s/iter; left time: 601.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0712046 Vali Loss: 0.0763761 Test Loss: 0.0877781\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019007287919521332, rmse:0.13786691427230835, mae:0.08783120661973953, rse:0.40501153469085693\n",
      "Intermediate time for ES and pred_len 96: 00h:08m:51.89s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1248044\n",
      "\tspeed: 0.0530s/iter; left time: 1170.7224s\n",
      "\titers: 200, epoch: 1 | loss: 0.1121375\n",
      "\tspeed: 0.0354s/iter; left time: 777.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 222 | Train Loss: 0.1329905 Vali Loss: 0.1052874 Test Loss: 0.1202584\n",
      "Validation loss decreased (inf --> 0.105287).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913955\n",
      "\tspeed: 0.0676s/iter; left time: 1479.3802s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897939\n",
      "\tspeed: 0.0354s/iter; left time: 770.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0956577 Vali Loss: 0.0880194 Test Loss: 0.1003802\n",
      "Validation loss decreased (0.105287 --> 0.088019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0912098\n",
      "\tspeed: 0.0658s/iter; left time: 1424.0831s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903715\n",
      "\tspeed: 0.0354s/iter; left time: 762.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0882833 Vali Loss: 0.0853559 Test Loss: 0.0969999\n",
      "Validation loss decreased (0.088019 --> 0.085356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0885219\n",
      "\tspeed: 0.0659s/iter; left time: 1412.1189s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829042\n",
      "\tspeed: 0.0354s/iter; left time: 754.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0855933 Vali Loss: 0.0840832 Test Loss: 0.0959689\n",
      "Validation loss decreased (0.085356 --> 0.084083).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806795\n",
      "\tspeed: 0.0687s/iter; left time: 1457.9011s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851555\n",
      "\tspeed: 0.0354s/iter; left time: 747.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0837458 Vali Loss: 0.0834666 Test Loss: 0.0952264\n",
      "Validation loss decreased (0.084083 --> 0.083467).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0795757\n",
      "\tspeed: 0.0661s/iter; left time: 1386.5759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0825070\n",
      "\tspeed: 0.0354s/iter; left time: 738.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0821476 Vali Loss: 0.0832355 Test Loss: 0.0942999\n",
      "Validation loss decreased (0.083467 --> 0.083235).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832260\n",
      "\tspeed: 0.0666s/iter; left time: 1383.7755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0815057\n",
      "\tspeed: 0.0353s/iter; left time: 730.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0809988 Vali Loss: 0.0836252 Test Loss: 0.0949094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0845280\n",
      "\tspeed: 0.0648s/iter; left time: 1330.4769s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820176\n",
      "\tspeed: 0.0354s/iter; left time: 723.4412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0800716 Vali Loss: 0.0830692 Test Loss: 0.0949128\n",
      "Validation loss decreased (0.083235 --> 0.083069).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779482\n",
      "\tspeed: 0.0692s/iter; left time: 1407.4368s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817634\n",
      "\tspeed: 0.1056s/iter; left time: 2136.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 222 | Train Loss: 0.0792837 Vali Loss: 0.0832909 Test Loss: 0.0947785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0796368\n",
      "\tspeed: 0.0675s/iter; left time: 1356.3240s\n",
      "\titers: 200, epoch: 10 | loss: 0.0779853\n",
      "\tspeed: 0.0526s/iter; left time: 1052.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 222 | Train Loss: 0.0786656 Vali Loss: 0.0832510 Test Loss: 0.0946252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785343\n",
      "\tspeed: 0.6281s/iter; left time: 12486.9896s\n",
      "\titers: 200, epoch: 11 | loss: 0.0724108\n",
      "\tspeed: 0.1509s/iter; left time: 2984.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:36.38s\n",
      "Steps: 222 | Train Loss: 0.0780590 Vali Loss: 0.0837434 Test Loss: 0.0947317\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778789\n",
      "\tspeed: 0.0767s/iter; left time: 1508.4605s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793115\n",
      "\tspeed: 0.0354s/iter; left time: 692.7958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 222 | Train Loss: 0.0776558 Vali Loss: 0.0835496 Test Loss: 0.0946513\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0768540\n",
      "\tspeed: 0.0645s/iter; left time: 1253.1599s\n",
      "\titers: 200, epoch: 13 | loss: 0.0758939\n",
      "\tspeed: 0.0353s/iter; left time: 683.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0771729 Vali Loss: 0.0840376 Test Loss: 0.0947968\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770758\n",
      "\tspeed: 0.0646s/iter; left time: 1240.6503s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722814\n",
      "\tspeed: 0.0353s/iter; left time: 674.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0767453 Vali Loss: 0.0838487 Test Loss: 0.0948405\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0768786\n",
      "\tspeed: 0.0642s/iter; left time: 1220.2160s\n",
      "\titers: 200, epoch: 15 | loss: 0.0742398\n",
      "\tspeed: 0.0353s/iter; left time: 667.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0764734 Vali Loss: 0.0840944 Test Loss: 0.0948674\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0763122\n",
      "\tspeed: 0.0648s/iter; left time: 1216.8669s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735435\n",
      "\tspeed: 0.0354s/iter; left time: 660.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0761429 Vali Loss: 0.0840424 Test Loss: 0.0947928\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0758866\n",
      "\tspeed: 0.0647s/iter; left time: 1199.2048s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786234\n",
      "\tspeed: 0.0354s/iter; left time: 652.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0758693 Vali Loss: 0.0847151 Test Loss: 0.0951496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750566\n",
      "\tspeed: 0.0647s/iter; left time: 1186.6675s\n",
      "\titers: 200, epoch: 18 | loss: 0.0735079\n",
      "\tspeed: 0.0354s/iter; left time: 645.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0756012 Vali Loss: 0.0840558 Test Loss: 0.0955794\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021398372948169708, rmse:0.14628182351589203, mae:0.0949128046631813, rse:0.4297628402709961\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262133\n",
      "\tspeed: 0.0370s/iter; left time: 818.7084s\n",
      "\titers: 200, epoch: 1 | loss: 0.1155465\n",
      "\tspeed: 0.0354s/iter; left time: 778.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.1330362 Vali Loss: 0.1057256 Test Loss: 0.1209119\n",
      "Validation loss decreased (inf --> 0.105726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0969276\n",
      "\tspeed: 0.0782s/iter; left time: 1711.8345s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930786\n",
      "\tspeed: 0.0354s/iter; left time: 769.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0959136 Vali Loss: 0.0881749 Test Loss: 0.1012242\n",
      "Validation loss decreased (0.105726 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903248\n",
      "\tspeed: 0.0657s/iter; left time: 1422.9299s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888213\n",
      "\tspeed: 0.0353s/iter; left time: 761.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0886226 Vali Loss: 0.0859347 Test Loss: 0.0981556\n",
      "Validation loss decreased (0.088175 --> 0.085935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0835429\n",
      "\tspeed: 0.0693s/iter; left time: 1484.7536s\n",
      "\titers: 200, epoch: 4 | loss: 0.0864875\n",
      "\tspeed: 0.0354s/iter; left time: 754.2379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0859898 Vali Loss: 0.0845382 Test Loss: 0.0961444\n",
      "Validation loss decreased (0.085935 --> 0.084538).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793198\n",
      "\tspeed: 0.0675s/iter; left time: 1432.3049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0833651\n",
      "\tspeed: 0.0390s/iter; left time: 824.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 222 | Train Loss: 0.0841185 Vali Loss: 0.0830565 Test Loss: 0.0956405\n",
      "Validation loss decreased (0.084538 --> 0.083056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843879\n",
      "\tspeed: 0.2041s/iter; left time: 4283.3636s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821313\n",
      "\tspeed: 0.0360s/iter; left time: 751.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0827344 Vali Loss: 0.0830209 Test Loss: 0.0961275\n",
      "Validation loss decreased (0.083056 --> 0.083021).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815268\n",
      "\tspeed: 0.4162s/iter; left time: 8645.0667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820298\n",
      "\tspeed: 0.1791s/iter; left time: 3701.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 222 | Train Loss: 0.0815136 Vali Loss: 0.0829712 Test Loss: 0.0942766\n",
      "Validation loss decreased (0.083021 --> 0.082971).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826096\n",
      "\tspeed: 0.2969s/iter; left time: 6100.9579s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799328\n",
      "\tspeed: 0.0360s/iter; left time: 736.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 222 | Train Loss: 0.0804369 Vali Loss: 0.0834113 Test Loss: 0.0943891\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0811863\n",
      "\tspeed: 0.0661s/iter; left time: 1343.7931s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789521\n",
      "\tspeed: 0.0355s/iter; left time: 718.8979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0796194 Vali Loss: 0.0833020 Test Loss: 0.0946176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0792897\n",
      "\tspeed: 0.0654s/iter; left time: 1314.4616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0795097\n",
      "\tspeed: 0.0354s/iter; left time: 708.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0788510 Vali Loss: 0.0848339 Test Loss: 0.0951783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800021\n",
      "\tspeed: 0.0655s/iter; left time: 1302.6337s\n",
      "\titers: 200, epoch: 11 | loss: 0.0780762\n",
      "\tspeed: 0.0354s/iter; left time: 700.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0782232 Vali Loss: 0.0836270 Test Loss: 0.0940536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0789887\n",
      "\tspeed: 0.0661s/iter; left time: 1300.0125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775751\n",
      "\tspeed: 0.0357s/iter; left time: 698.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 222 | Train Loss: 0.0777460 Vali Loss: 0.0836621 Test Loss: 0.0943825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776807\n",
      "\tspeed: 0.0648s/iter; left time: 1260.3107s\n",
      "\titers: 200, epoch: 13 | loss: 0.0753892\n",
      "\tspeed: 0.0354s/iter; left time: 684.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0772821 Vali Loss: 0.0838019 Test Loss: 0.0949747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766929\n",
      "\tspeed: 0.0649s/iter; left time: 1246.8134s\n",
      "\titers: 200, epoch: 14 | loss: 0.0776243\n",
      "\tspeed: 0.0354s/iter; left time: 677.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0768859 Vali Loss: 0.0844462 Test Loss: 0.0948179\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0752913\n",
      "\tspeed: 0.0650s/iter; left time: 1233.6634s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740202\n",
      "\tspeed: 0.0354s/iter; left time: 668.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0764546 Vali Loss: 0.0840741 Test Loss: 0.0945859\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780877\n",
      "\tspeed: 0.0654s/iter; left time: 1226.7383s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740172\n",
      "\tspeed: 0.0354s/iter; left time: 660.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0760855 Vali Loss: 0.0843399 Test Loss: 0.0947543\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0761232\n",
      "\tspeed: 0.0647s/iter; left time: 1200.3612s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759137\n",
      "\tspeed: 0.0354s/iter; left time: 652.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0757693 Vali Loss: 0.0838592 Test Loss: 0.0947815\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02121954783797264, rmse:0.14566931128501892, mae:0.09427657723426819, rse:0.4279633164405823\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:50.20s\n",
      "Intermediate time for ES: 00h:38m:22.14s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0836576\n",
      "\tspeed: 0.0553s/iter; left time: 1228.5774s\n",
      "\titers: 200, epoch: 1 | loss: 0.0827788\n",
      "\tspeed: 0.0347s/iter; left time: 767.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0929252 Vali Loss: 0.0809843 Test Loss: 0.0874676\n",
      "Validation loss decreased (inf --> 0.080984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0541820\n",
      "\tspeed: 0.0640s/iter; left time: 1405.6421s\n",
      "\titers: 200, epoch: 2 | loss: 0.0536694\n",
      "\tspeed: 0.0755s/iter; left time: 1651.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.29s\n",
      "Steps: 223 | Train Loss: 0.0554993 Vali Loss: 0.0584362 Test Loss: 0.0612443\n",
      "Validation loss decreased (0.080984 --> 0.058436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0479808\n",
      "\tspeed: 0.1419s/iter; left time: 3086.3528s\n",
      "\titers: 200, epoch: 3 | loss: 0.0469247\n",
      "\tspeed: 0.0348s/iter; left time: 754.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0488807 Vali Loss: 0.0559211 Test Loss: 0.0599450\n",
      "Validation loss decreased (0.058436 --> 0.055921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495132\n",
      "\tspeed: 0.1465s/iter; left time: 3155.4757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0486777\n",
      "\tspeed: 0.1460s/iter; left time: 3128.0486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.75s\n",
      "Steps: 223 | Train Loss: 0.0471245 Vali Loss: 0.0549650 Test Loss: 0.0586658\n",
      "Validation loss decreased (0.055921 --> 0.054965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461087\n",
      "\tspeed: 0.3328s/iter; left time: 7091.7118s\n",
      "\titers: 200, epoch: 5 | loss: 0.0431552\n",
      "\tspeed: 0.1444s/iter; left time: 3063.2244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.69s\n",
      "Steps: 223 | Train Loss: 0.0459224 Vali Loss: 0.0544292 Test Loss: 0.0579801\n",
      "Validation loss decreased (0.054965 --> 0.054429).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0429516\n",
      "\tspeed: 0.1242s/iter; left time: 2619.4910s\n",
      "\titers: 200, epoch: 6 | loss: 0.0450441\n",
      "\tspeed: 0.0351s/iter; left time: 737.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 223 | Train Loss: 0.0450753 Vali Loss: 0.0534364 Test Loss: 0.0574893\n",
      "Validation loss decreased (0.054429 --> 0.053436).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0427252\n",
      "\tspeed: 0.0642s/iter; left time: 1340.3451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0438986\n",
      "\tspeed: 0.0348s/iter; left time: 722.7895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0443351 Vali Loss: 0.0531485 Test Loss: 0.0569254\n",
      "Validation loss decreased (0.053436 --> 0.053148).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460687\n",
      "\tspeed: 0.0638s/iter; left time: 1316.1113s\n",
      "\titers: 200, epoch: 8 | loss: 0.0425774\n",
      "\tspeed: 0.0348s/iter; left time: 714.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0439071 Vali Loss: 0.0528703 Test Loss: 0.0569165\n",
      "Validation loss decreased (0.053148 --> 0.052870).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0421830\n",
      "\tspeed: 0.0641s/iter; left time: 1308.4582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0437702\n",
      "\tspeed: 0.0348s/iter; left time: 706.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0434690 Vali Loss: 0.0526643 Test Loss: 0.0562686\n",
      "Validation loss decreased (0.052870 --> 0.052664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0450998\n",
      "\tspeed: 0.0646s/iter; left time: 1304.3270s\n",
      "\titers: 200, epoch: 10 | loss: 0.0410023\n",
      "\tspeed: 0.0349s/iter; left time: 700.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0431665 Vali Loss: 0.0526991 Test Loss: 0.0567075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0446551\n",
      "\tspeed: 0.0643s/iter; left time: 1283.4945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0440647\n",
      "\tspeed: 0.0348s/iter; left time: 690.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0428013 Vali Loss: 0.0522881 Test Loss: 0.0562465\n",
      "Validation loss decreased (0.052664 --> 0.052288).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0446330\n",
      "\tspeed: 0.0638s/iter; left time: 1260.3358s\n",
      "\titers: 200, epoch: 12 | loss: 0.0441936\n",
      "\tspeed: 0.0347s/iter; left time: 682.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0425423 Vali Loss: 0.0518824 Test Loss: 0.0558948\n",
      "Validation loss decreased (0.052288 --> 0.051882).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0426764\n",
      "\tspeed: 0.0636s/iter; left time: 1241.3250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0411832\n",
      "\tspeed: 0.0347s/iter; left time: 674.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0423290 Vali Loss: 0.0518348 Test Loss: 0.0561304\n",
      "Validation loss decreased (0.051882 --> 0.051835).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0393404\n",
      "\tspeed: 0.0663s/iter; left time: 1280.1072s\n",
      "\titers: 200, epoch: 14 | loss: 0.0417510\n",
      "\tspeed: 0.0347s/iter; left time: 666.4404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0421292 Vali Loss: 0.0518482 Test Loss: 0.0560844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0428903\n",
      "\tspeed: 0.0640s/iter; left time: 1220.6665s\n",
      "\titers: 200, epoch: 15 | loss: 0.0426096\n",
      "\tspeed: 0.0348s/iter; left time: 659.6620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0419744 Vali Loss: 0.0517020 Test Loss: 0.0557122\n",
      "Validation loss decreased (0.051835 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0406196\n",
      "\tspeed: 0.0650s/iter; left time: 1224.7883s\n",
      "\titers: 200, epoch: 16 | loss: 0.0429875\n",
      "\tspeed: 0.0348s/iter; left time: 652.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0418102 Vali Loss: 0.0516462 Test Loss: 0.0557060\n",
      "Validation loss decreased (0.051702 --> 0.051646).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0435691\n",
      "\tspeed: 0.0640s/iter; left time: 1192.3540s\n",
      "\titers: 200, epoch: 17 | loss: 0.0413735\n",
      "\tspeed: 0.0349s/iter; left time: 647.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0416812 Vali Loss: 0.0513440 Test Loss: 0.0555808\n",
      "Validation loss decreased (0.051646 --> 0.051344).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0442521\n",
      "\tspeed: 0.0658s/iter; left time: 1210.8082s\n",
      "\titers: 200, epoch: 18 | loss: 0.0423577\n",
      "\tspeed: 0.0642s/iter; left time: 1175.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 223 | Train Loss: 0.0415006 Vali Loss: 0.0514995 Test Loss: 0.0556802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0410317\n",
      "\tspeed: 0.1585s/iter; left time: 2882.1213s\n",
      "\titers: 200, epoch: 19 | loss: 0.0432977\n",
      "\tspeed: 0.0363s/iter; left time: 656.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0414593 Vali Loss: 0.0512872 Test Loss: 0.0555878\n",
      "Validation loss decreased (0.051344 --> 0.051287).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0433293\n",
      "\tspeed: 0.0672s/iter; left time: 1207.6452s\n",
      "\titers: 200, epoch: 20 | loss: 0.0413895\n",
      "\tspeed: 0.0352s/iter; left time: 629.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0413562 Vali Loss: 0.0513565 Test Loss: 0.0554658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414682\n",
      "\tspeed: 0.0639s/iter; left time: 1134.4744s\n",
      "\titers: 200, epoch: 21 | loss: 0.0405680\n",
      "\tspeed: 0.0352s/iter; left time: 620.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0412301 Vali Loss: 0.0511387 Test Loss: 0.0554350\n",
      "Validation loss decreased (0.051287 --> 0.051139).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410880\n",
      "\tspeed: 0.0652s/iter; left time: 1141.9281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0437249\n",
      "\tspeed: 0.0351s/iter; left time: 611.8609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0411701 Vali Loss: 0.0511831 Test Loss: 0.0554506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0435361\n",
      "\tspeed: 0.0643s/iter; left time: 1112.1037s\n",
      "\titers: 200, epoch: 23 | loss: 0.0397593\n",
      "\tspeed: 0.0349s/iter; left time: 599.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0410498 Vali Loss: 0.0511003 Test Loss: 0.0554148\n",
      "Validation loss decreased (0.051139 --> 0.051100).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0421156\n",
      "\tspeed: 0.0640s/iter; left time: 1093.1930s\n",
      "\titers: 200, epoch: 24 | loss: 0.0424190\n",
      "\tspeed: 0.0351s/iter; left time: 596.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0409924 Vali Loss: 0.0511058 Test Loss: 0.0553837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0414506\n",
      "\tspeed: 0.0634s/iter; left time: 1068.7081s\n",
      "\titers: 200, epoch: 25 | loss: 0.0393909\n",
      "\tspeed: 0.0352s/iter; left time: 589.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0409429 Vali Loss: 0.0511639 Test Loss: 0.0554420\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0408931\n",
      "\tspeed: 0.0639s/iter; left time: 1062.6643s\n",
      "\titers: 200, epoch: 26 | loss: 0.0393896\n",
      "\tspeed: 0.0353s/iter; left time: 583.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0409068 Vali Loss: 0.0509211 Test Loss: 0.0554087\n",
      "Validation loss decreased (0.051100 --> 0.050921).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0420896\n",
      "\tspeed: 0.0656s/iter; left time: 1075.2783s\n",
      "\titers: 200, epoch: 27 | loss: 0.0398492\n",
      "\tspeed: 0.0352s/iter; left time: 574.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0408039 Vali Loss: 0.0509325 Test Loss: 0.0554289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0403437\n",
      "\tspeed: 0.0642s/iter; left time: 1038.8252s\n",
      "\titers: 200, epoch: 28 | loss: 0.0404508\n",
      "\tspeed: 0.0353s/iter; left time: 567.0769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0407987 Vali Loss: 0.0510672 Test Loss: 0.0553461\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0401933\n",
      "\tspeed: 0.0633s/iter; left time: 1010.2558s\n",
      "\titers: 200, epoch: 29 | loss: 0.0441964\n",
      "\tspeed: 0.0352s/iter; left time: 558.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0407347 Vali Loss: 0.0510270 Test Loss: 0.0553932\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0433453\n",
      "\tspeed: 0.0641s/iter; left time: 1008.9971s\n",
      "\titers: 200, epoch: 30 | loss: 0.0377617\n",
      "\tspeed: 0.0353s/iter; left time: 552.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0407489 Vali Loss: 0.0510796 Test Loss: 0.0552628\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0389959\n",
      "\tspeed: 0.0642s/iter; left time: 995.9266s\n",
      "\titers: 200, epoch: 31 | loss: 0.0391954\n",
      "\tspeed: 0.0351s/iter; left time: 541.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0406471 Vali Loss: 0.0509092 Test Loss: 0.0552722\n",
      "Validation loss decreased (0.050921 --> 0.050909).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0397254\n",
      "\tspeed: 0.0641s/iter; left time: 980.3520s\n",
      "\titers: 200, epoch: 32 | loss: 0.0423798\n",
      "\tspeed: 0.0352s/iter; left time: 535.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0406437 Vali Loss: 0.0510015 Test Loss: 0.0552981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0381529\n",
      "\tspeed: 0.0641s/iter; left time: 965.1537s\n",
      "\titers: 200, epoch: 33 | loss: 0.0393681\n",
      "\tspeed: 0.0351s/iter; left time: 525.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0405906 Vali Loss: 0.0508919 Test Loss: 0.0552640\n",
      "Validation loss decreased (0.050909 --> 0.050892).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0391373\n",
      "\tspeed: 0.0637s/iter; left time: 944.8045s\n",
      "\titers: 200, epoch: 34 | loss: 0.0429796\n",
      "\tspeed: 0.0351s/iter; left time: 517.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0406271 Vali Loss: 0.0509401 Test Loss: 0.0552789\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0393175\n",
      "\tspeed: 0.0638s/iter; left time: 932.6291s\n",
      "\titers: 200, epoch: 35 | loss: 0.0452444\n",
      "\tspeed: 0.0351s/iter; left time: 509.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0405727 Vali Loss: 0.0509840 Test Loss: 0.0553096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0396500\n",
      "\tspeed: 0.0640s/iter; left time: 921.9813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0374432\n",
      "\tspeed: 0.0347s/iter; left time: 496.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0405686 Vali Loss: 0.0508993 Test Loss: 0.0552813\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0382940\n",
      "\tspeed: 0.0635s/iter; left time: 899.3899s\n",
      "\titers: 200, epoch: 37 | loss: 0.0385352\n",
      "\tspeed: 0.0351s/iter; left time: 494.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0405605 Vali Loss: 0.0508825 Test Loss: 0.0552457\n",
      "Validation loss decreased (0.050892 --> 0.050883).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0443772\n",
      "\tspeed: 0.0645s/iter; left time: 900.2980s\n",
      "\titers: 200, epoch: 38 | loss: 0.0408431\n",
      "\tspeed: 0.0351s/iter; left time: 486.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405323 Vali Loss: 0.0508869 Test Loss: 0.0552040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0415697\n",
      "\tspeed: 0.0640s/iter; left time: 878.8649s\n",
      "\titers: 200, epoch: 39 | loss: 0.0401583\n",
      "\tspeed: 0.0352s/iter; left time: 479.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405325 Vali Loss: 0.0508903 Test Loss: 0.0552433\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0401176\n",
      "\tspeed: 0.0641s/iter; left time: 865.6091s\n",
      "\titers: 200, epoch: 40 | loss: 0.0379751\n",
      "\tspeed: 0.0351s/iter; left time: 471.0771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405105 Vali Loss: 0.0509022 Test Loss: 0.0552413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416584\n",
      "\tspeed: 0.0644s/iter; left time: 855.7865s\n",
      "\titers: 200, epoch: 41 | loss: 0.0421260\n",
      "\tspeed: 0.0351s/iter; left time: 463.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0404700 Vali Loss: 0.0508691 Test Loss: 0.0552322\n",
      "Validation loss decreased (0.050883 --> 0.050869).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0404644\n",
      "\tspeed: 0.0649s/iter; left time: 847.9688s\n",
      "\titers: 200, epoch: 42 | loss: 0.0408125\n",
      "\tspeed: 0.0352s/iter; left time: 456.5434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0404701 Vali Loss: 0.0508088 Test Loss: 0.0552237\n",
      "Validation loss decreased (0.050869 --> 0.050809).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0419943\n",
      "\tspeed: 0.0644s/iter; left time: 826.1812s\n",
      "\titers: 200, epoch: 43 | loss: 0.0436137\n",
      "\tspeed: 0.0352s/iter; left time: 448.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0404592 Vali Loss: 0.0509347 Test Loss: 0.0552353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0376701\n",
      "\tspeed: 0.0633s/iter; left time: 798.2065s\n",
      "\titers: 200, epoch: 44 | loss: 0.0406414\n",
      "\tspeed: 0.0351s/iter; left time: 439.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404487 Vali Loss: 0.0508428 Test Loss: 0.0552090\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0393764\n",
      "\tspeed: 0.0640s/iter; left time: 792.5910s\n",
      "\titers: 200, epoch: 45 | loss: 0.0365028\n",
      "\tspeed: 0.0352s/iter; left time: 432.4115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0404632 Vali Loss: 0.0508255 Test Loss: 0.0552031\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0385800\n",
      "\tspeed: 0.0635s/iter; left time: 772.3172s\n",
      "\titers: 200, epoch: 46 | loss: 0.0384708\n",
      "\tspeed: 0.0351s/iter; left time: 423.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0404808 Vali Loss: 0.0508547 Test Loss: 0.0552096\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0380203\n",
      "\tspeed: 0.0649s/iter; left time: 775.6657s\n",
      "\titers: 200, epoch: 47 | loss: 0.0389383\n",
      "\tspeed: 0.0352s/iter; left time: 417.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0404394 Vali Loss: 0.0508684 Test Loss: 0.0552029\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0392998\n",
      "\tspeed: 0.0636s/iter; left time: 745.6993s\n",
      "\titers: 200, epoch: 48 | loss: 0.0419598\n",
      "\tspeed: 0.0352s/iter; left time: 408.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0404412 Vali Loss: 0.0508178 Test Loss: 0.0552285\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0428239\n",
      "\tspeed: 0.0651s/iter; left time: 748.3714s\n",
      "\titers: 200, epoch: 49 | loss: 0.0397411\n",
      "\tspeed: 0.0352s/iter; left time: 401.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0404602 Vali Loss: 0.0508335 Test Loss: 0.0552242\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0395791\n",
      "\tspeed: 0.0641s/iter; left time: 723.0227s\n",
      "\titers: 200, epoch: 50 | loss: 0.0381157\n",
      "\tspeed: 0.0351s/iter; left time: 392.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0404383 Vali Loss: 0.0508597 Test Loss: 0.0552245\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440048\n",
      "\tspeed: 0.0636s/iter; left time: 703.3596s\n",
      "\titers: 200, epoch: 51 | loss: 0.0397665\n",
      "\tspeed: 0.0352s/iter; left time: 385.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404183 Vali Loss: 0.0508182 Test Loss: 0.0552197\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0443854\n",
      "\tspeed: 0.0631s/iter; left time: 683.4818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0379273\n",
      "\tspeed: 0.0352s/iter; left time: 377.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404342 Vali Loss: 0.0508417 Test Loss: 0.0552029\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010042295791208744, rmse:0.1002112552523613, mae:0.0552237294614315, rse:0.38661226630210876\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0905331\n",
      "\tspeed: 0.0367s/iter; left time: 815.7851s\n",
      "\titers: 200, epoch: 1 | loss: 0.0790937\n",
      "\tspeed: 0.0351s/iter; left time: 776.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0933416 Vali Loss: 0.0811227 Test Loss: 0.0884504\n",
      "Validation loss decreased (inf --> 0.081123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0556278\n",
      "\tspeed: 0.0653s/iter; left time: 1435.0369s\n",
      "\titers: 200, epoch: 2 | loss: 0.0504415\n",
      "\tspeed: 0.0352s/iter; left time: 769.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0557345 Vali Loss: 0.0583004 Test Loss: 0.0612372\n",
      "Validation loss decreased (0.081123 --> 0.058300).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0461911\n",
      "\tspeed: 0.0646s/iter; left time: 1404.6647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0472828\n",
      "\tspeed: 0.0347s/iter; left time: 752.4354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0487746 Vali Loss: 0.0558743 Test Loss: 0.0592142\n",
      "Validation loss decreased (0.058300 --> 0.055874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0482211\n",
      "\tspeed: 0.0657s/iter; left time: 1414.7441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0449718\n",
      "\tspeed: 0.0351s/iter; left time: 751.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0470474 Vali Loss: 0.0544716 Test Loss: 0.0583089\n",
      "Validation loss decreased (0.055874 --> 0.054472).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449317\n",
      "\tspeed: 0.0647s/iter; left time: 1379.2122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0439852\n",
      "\tspeed: 0.0351s/iter; left time: 744.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0458716 Vali Loss: 0.0539440 Test Loss: 0.0576853\n",
      "Validation loss decreased (0.054472 --> 0.053944).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0437656\n",
      "\tspeed: 0.0671s/iter; left time: 1415.3703s\n",
      "\titers: 200, epoch: 6 | loss: 0.0466216\n",
      "\tspeed: 0.0351s/iter; left time: 736.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0449662 Vali Loss: 0.0534553 Test Loss: 0.0572674\n",
      "Validation loss decreased (0.053944 --> 0.053455).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0432135\n",
      "\tspeed: 0.0636s/iter; left time: 1326.0862s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448062\n",
      "\tspeed: 0.0349s/iter; left time: 725.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0443374 Vali Loss: 0.0534272 Test Loss: 0.0571053\n",
      "Validation loss decreased (0.053455 --> 0.053427).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409291\n",
      "\tspeed: 0.0637s/iter; left time: 1315.3355s\n",
      "\titers: 200, epoch: 8 | loss: 0.0430096\n",
      "\tspeed: 0.0351s/iter; left time: 720.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0437858 Vali Loss: 0.0525818 Test Loss: 0.0564486\n",
      "Validation loss decreased (0.053427 --> 0.052582).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0434833\n",
      "\tspeed: 0.0640s/iter; left time: 1307.3049s\n",
      "\titers: 200, epoch: 9 | loss: 0.0431426\n",
      "\tspeed: 0.0347s/iter; left time: 705.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0433379 Vali Loss: 0.0527517 Test Loss: 0.0565157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0436005\n",
      "\tspeed: 0.0650s/iter; left time: 1312.1588s\n",
      "\titers: 200, epoch: 10 | loss: 0.0441317\n",
      "\tspeed: 0.0351s/iter; left time: 704.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0429824 Vali Loss: 0.0525102 Test Loss: 0.0561908\n",
      "Validation loss decreased (0.052582 --> 0.052510).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441469\n",
      "\tspeed: 0.0643s/iter; left time: 1283.2634s\n",
      "\titers: 200, epoch: 11 | loss: 0.0429173\n",
      "\tspeed: 0.0351s/iter; left time: 697.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0427291 Vali Loss: 0.0522521 Test Loss: 0.0560558\n",
      "Validation loss decreased (0.052510 --> 0.052252).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414824\n",
      "\tspeed: 0.0648s/iter; left time: 1280.0183s\n",
      "\titers: 200, epoch: 12 | loss: 0.0416152\n",
      "\tspeed: 0.0351s/iter; left time: 689.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0424671 Vali Loss: 0.0520982 Test Loss: 0.0563322\n",
      "Validation loss decreased (0.052252 --> 0.052098).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0391976\n",
      "\tspeed: 0.0643s/iter; left time: 1256.3365s\n",
      "\titers: 200, epoch: 13 | loss: 0.0431828\n",
      "\tspeed: 0.0351s/iter; left time: 682.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0422042 Vali Loss: 0.0521203 Test Loss: 0.0560514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0414172\n",
      "\tspeed: 0.0635s/iter; left time: 1226.3180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0436923\n",
      "\tspeed: 0.0351s/iter; left time: 674.5539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0420351 Vali Loss: 0.0519225 Test Loss: 0.0560759\n",
      "Validation loss decreased (0.052098 --> 0.051923).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0435061\n",
      "\tspeed: 0.0638s/iter; left time: 1216.5322s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421386\n",
      "\tspeed: 0.0351s/iter; left time: 665.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0418336 Vali Loss: 0.0516601 Test Loss: 0.0557258\n",
      "Validation loss decreased (0.051923 --> 0.051660).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0417260\n",
      "\tspeed: 0.0641s/iter; left time: 1208.7892s\n",
      "\titers: 200, epoch: 16 | loss: 0.0413655\n",
      "\tspeed: 0.0350s/iter; left time: 656.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0416313 Vali Loss: 0.0515719 Test Loss: 0.0557763\n",
      "Validation loss decreased (0.051660 --> 0.051572).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0441681\n",
      "\tspeed: 0.0641s/iter; left time: 1195.2433s\n",
      "\titers: 200, epoch: 17 | loss: 0.0442261\n",
      "\tspeed: 0.0348s/iter; left time: 644.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0415218 Vali Loss: 0.0514898 Test Loss: 0.0556714\n",
      "Validation loss decreased (0.051572 --> 0.051490).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0444827\n",
      "\tspeed: 0.0640s/iter; left time: 1178.9398s\n",
      "\titers: 200, epoch: 18 | loss: 0.0387237\n",
      "\tspeed: 0.0352s/iter; left time: 643.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0414431 Vali Loss: 0.0514083 Test Loss: 0.0557639\n",
      "Validation loss decreased (0.051490 --> 0.051408).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0441746\n",
      "\tspeed: 0.0645s/iter; left time: 1173.3143s\n",
      "\titers: 200, epoch: 19 | loss: 0.0418730\n",
      "\tspeed: 0.0352s/iter; left time: 637.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0412976 Vali Loss: 0.0512842 Test Loss: 0.0555965\n",
      "Validation loss decreased (0.051408 --> 0.051284).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0414115\n",
      "\tspeed: 0.0639s/iter; left time: 1147.5876s\n",
      "\titers: 200, epoch: 20 | loss: 0.0421314\n",
      "\tspeed: 0.0351s/iter; left time: 626.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0411188 Vali Loss: 0.0511608 Test Loss: 0.0555696\n",
      "Validation loss decreased (0.051284 --> 0.051161).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0425900\n",
      "\tspeed: 0.0650s/iter; left time: 1153.4993s\n",
      "\titers: 200, epoch: 21 | loss: 0.0420930\n",
      "\tspeed: 0.0351s/iter; left time: 619.1400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0410380 Vali Loss: 0.0512272 Test Loss: 0.0553351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0425151\n",
      "\tspeed: 0.0645s/iter; left time: 1130.6564s\n",
      "\titers: 200, epoch: 22 | loss: 0.0404247\n",
      "\tspeed: 0.0348s/iter; left time: 607.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0409953 Vali Loss: 0.0513290 Test Loss: 0.0555016\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0388141\n",
      "\tspeed: 0.0642s/iter; left time: 1111.1592s\n",
      "\titers: 200, epoch: 23 | loss: 0.0456665\n",
      "\tspeed: 0.0351s/iter; left time: 603.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0409120 Vali Loss: 0.0512186 Test Loss: 0.0554686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0415782\n",
      "\tspeed: 0.0635s/iter; left time: 1084.5977s\n",
      "\titers: 200, epoch: 24 | loss: 0.0400148\n",
      "\tspeed: 0.0351s/iter; left time: 595.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0408801 Vali Loss: 0.0510632 Test Loss: 0.0552173\n",
      "Validation loss decreased (0.051161 --> 0.051063).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0390060\n",
      "\tspeed: 0.0642s/iter; left time: 1081.8480s\n",
      "\titers: 200, epoch: 25 | loss: 0.0404676\n",
      "\tspeed: 0.0351s/iter; left time: 587.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0407820 Vali Loss: 0.0510935 Test Loss: 0.0554337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0458288\n",
      "\tspeed: 0.0646s/iter; left time: 1074.6319s\n",
      "\titers: 200, epoch: 26 | loss: 0.0387769\n",
      "\tspeed: 0.0348s/iter; left time: 574.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0407251 Vali Loss: 0.0509819 Test Loss: 0.0554200\n",
      "Validation loss decreased (0.051063 --> 0.050982).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0404320\n",
      "\tspeed: 0.0658s/iter; left time: 1078.9898s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413531\n",
      "\tspeed: 0.0350s/iter; left time: 569.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0407241 Vali Loss: 0.0510599 Test Loss: 0.0553351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0404339\n",
      "\tspeed: 0.0638s/iter; left time: 1032.9770s\n",
      "\titers: 200, epoch: 28 | loss: 0.0420386\n",
      "\tspeed: 0.0351s/iter; left time: 564.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0406286 Vali Loss: 0.0510436 Test Loss: 0.0554185\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0406484\n",
      "\tspeed: 0.0636s/iter; left time: 1015.1565s\n",
      "\titers: 200, epoch: 29 | loss: 0.0422703\n",
      "\tspeed: 0.0351s/iter; left time: 557.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0405925 Vali Loss: 0.0509693 Test Loss: 0.0553177\n",
      "Validation loss decreased (0.050982 --> 0.050969).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0401751\n",
      "\tspeed: 0.0644s/iter; left time: 1013.3650s\n",
      "\titers: 200, epoch: 30 | loss: 0.0380990\n",
      "\tspeed: 0.0351s/iter; left time: 548.6465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0405841 Vali Loss: 0.0510028 Test Loss: 0.0553068\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0398719\n",
      "\tspeed: 0.0637s/iter; left time: 988.3468s\n",
      "\titers: 200, epoch: 31 | loss: 0.0389703\n",
      "\tspeed: 0.0351s/iter; left time: 540.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0405483 Vali Loss: 0.0509729 Test Loss: 0.0552955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0416216\n",
      "\tspeed: 0.0632s/iter; left time: 965.4634s\n",
      "\titers: 200, epoch: 32 | loss: 0.0408665\n",
      "\tspeed: 0.0351s/iter; left time: 532.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0404781 Vali Loss: 0.0509606 Test Loss: 0.0552734\n",
      "Validation loss decreased (0.050969 --> 0.050961).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0401581\n",
      "\tspeed: 0.0639s/iter; left time: 963.0300s\n",
      "\titers: 200, epoch: 33 | loss: 0.0444146\n",
      "\tspeed: 0.0351s/iter; left time: 524.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0405358 Vali Loss: 0.0509348 Test Loss: 0.0552480\n",
      "Validation loss decreased (0.050961 --> 0.050935).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0434580\n",
      "\tspeed: 0.0652s/iter; left time: 967.3864s\n",
      "\titers: 200, epoch: 34 | loss: 0.0450271\n",
      "\tspeed: 0.0351s/iter; left time: 517.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404639 Vali Loss: 0.0508491 Test Loss: 0.0552922\n",
      "Validation loss decreased (0.050935 --> 0.050849).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0404810\n",
      "\tspeed: 0.0640s/iter; left time: 935.7007s\n",
      "\titers: 200, epoch: 35 | loss: 0.0394439\n",
      "\tspeed: 0.0351s/iter; left time: 509.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404808 Vali Loss: 0.0508755 Test Loss: 0.0551853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0409779\n",
      "\tspeed: 0.0635s/iter; left time: 914.0628s\n",
      "\titers: 200, epoch: 36 | loss: 0.0380761\n",
      "\tspeed: 0.0351s/iter; left time: 501.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404602 Vali Loss: 0.0508840 Test Loss: 0.0552284\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0408223\n",
      "\tspeed: 0.0637s/iter; left time: 903.0386s\n",
      "\titers: 200, epoch: 37 | loss: 0.0389406\n",
      "\tspeed: 0.0351s/iter; left time: 494.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0403593 Vali Loss: 0.0509414 Test Loss: 0.0552473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0373138\n",
      "\tspeed: 0.0636s/iter; left time: 886.9634s\n",
      "\titers: 200, epoch: 38 | loss: 0.0389028\n",
      "\tspeed: 0.0351s/iter; left time: 485.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0403862 Vali Loss: 0.0509620 Test Loss: 0.0551982\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0404616\n",
      "\tspeed: 0.0632s/iter; left time: 867.3303s\n",
      "\titers: 200, epoch: 39 | loss: 0.0412011\n",
      "\tspeed: 0.0351s/iter; left time: 478.4572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0403805 Vali Loss: 0.0509299 Test Loss: 0.0552320\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0420976\n",
      "\tspeed: 0.0632s/iter; left time: 853.8060s\n",
      "\titers: 200, epoch: 40 | loss: 0.0417795\n",
      "\tspeed: 0.0351s/iter; left time: 470.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0403735 Vali Loss: 0.0509674 Test Loss: 0.0552053\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0420395\n",
      "\tspeed: 0.0635s/iter; left time: 843.0458s\n",
      "\titers: 200, epoch: 41 | loss: 0.0419803\n",
      "\tspeed: 0.0351s/iter; left time: 462.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0403411 Vali Loss: 0.0508990 Test Loss: 0.0551867\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0386650\n",
      "\tspeed: 0.0631s/iter; left time: 823.5859s\n",
      "\titers: 200, epoch: 42 | loss: 0.0394861\n",
      "\tspeed: 0.0351s/iter; left time: 454.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0403213 Vali Loss: 0.0509176 Test Loss: 0.0551957\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0385314\n",
      "\tspeed: 0.0635s/iter; left time: 814.5643s\n",
      "\titers: 200, epoch: 43 | loss: 0.0429035\n",
      "\tspeed: 0.0351s/iter; left time: 447.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0403033 Vali Loss: 0.0508787 Test Loss: 0.0552006\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0395700\n",
      "\tspeed: 0.0635s/iter; left time: 800.6240s\n",
      "\titers: 200, epoch: 44 | loss: 0.0420449\n",
      "\tspeed: 0.0351s/iter; left time: 438.9876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0403666 Vali Loss: 0.0508539 Test Loss: 0.0551681\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010036074556410313, rmse:0.10018020868301392, mae:0.05529222637414932, rse:0.38649246096611023\n",
      "Intermediate time for FR and pred_len 24: 00h:17m:30.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0945510\n",
      "\tspeed: 0.0573s/iter; left time: 1265.8507s\n",
      "\titers: 200, epoch: 1 | loss: 0.0804860\n",
      "\tspeed: 0.0351s/iter; left time: 772.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 222 | Train Loss: 0.0976736 Vali Loss: 0.0885169 Test Loss: 0.0971670\n",
      "Validation loss decreased (inf --> 0.088517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0725761\n",
      "\tspeed: 0.0659s/iter; left time: 1440.8780s\n",
      "\titers: 200, epoch: 2 | loss: 0.0638014\n",
      "\tspeed: 0.0349s/iter; left time: 760.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0691180 Vali Loss: 0.0740624 Test Loss: 0.0824161\n",
      "Validation loss decreased (0.088517 --> 0.074062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0630231\n",
      "\tspeed: 0.0673s/iter; left time: 1457.6326s\n",
      "\titers: 200, epoch: 3 | loss: 0.0608463\n",
      "\tspeed: 0.0349s/iter; left time: 753.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0631260 Vali Loss: 0.0725156 Test Loss: 0.0812358\n",
      "Validation loss decreased (0.074062 --> 0.072516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0594296\n",
      "\tspeed: 0.0667s/iter; left time: 1428.9581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622745\n",
      "\tspeed: 0.0355s/iter; left time: 757.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0616088 Vali Loss: 0.0718310 Test Loss: 0.0810862\n",
      "Validation loss decreased (0.072516 --> 0.071831).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637568\n",
      "\tspeed: 0.0682s/iter; left time: 1446.7270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0579425\n",
      "\tspeed: 0.0355s/iter; left time: 748.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0605200 Vali Loss: 0.0706862 Test Loss: 0.0809231\n",
      "Validation loss decreased (0.071831 --> 0.070686).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610347\n",
      "\tspeed: 0.0665s/iter; left time: 1395.1944s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598491\n",
      "\tspeed: 0.0354s/iter; left time: 740.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0597658 Vali Loss: 0.0708580 Test Loss: 0.0803957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572771\n",
      "\tspeed: 0.0661s/iter; left time: 1372.9512s\n",
      "\titers: 200, epoch: 7 | loss: 0.0592725\n",
      "\tspeed: 0.0355s/iter; left time: 733.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0592040 Vali Loss: 0.0703460 Test Loss: 0.0810018\n",
      "Validation loss decreased (0.070686 --> 0.070346).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603465\n",
      "\tspeed: 0.0671s/iter; left time: 1378.0604s\n",
      "\titers: 200, epoch: 8 | loss: 0.0571824\n",
      "\tspeed: 0.0354s/iter; left time: 723.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0587333 Vali Loss: 0.0699967 Test Loss: 0.0808316\n",
      "Validation loss decreased (0.070346 --> 0.069997).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0587291\n",
      "\tspeed: 0.0694s/iter; left time: 1411.4907s\n",
      "\titers: 200, epoch: 9 | loss: 0.0578059\n",
      "\tspeed: 0.0355s/iter; left time: 717.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0582413 Vali Loss: 0.0700071 Test Loss: 0.0808572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0635774\n",
      "\tspeed: 0.0658s/iter; left time: 1322.8441s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593283\n",
      "\tspeed: 0.0354s/iter; left time: 708.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0578581 Vali Loss: 0.0697521 Test Loss: 0.0807573\n",
      "Validation loss decreased (0.069997 --> 0.069752).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0564659\n",
      "\tspeed: 0.0678s/iter; left time: 1348.2090s\n",
      "\titers: 200, epoch: 11 | loss: 0.0573542\n",
      "\tspeed: 0.0354s/iter; left time: 699.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0575417 Vali Loss: 0.0696464 Test Loss: 0.0805303\n",
      "Validation loss decreased (0.069752 --> 0.069646).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0535343\n",
      "\tspeed: 0.0672s/iter; left time: 1321.5389s\n",
      "\titers: 200, epoch: 12 | loss: 0.0554652\n",
      "\tspeed: 0.0353s/iter; left time: 690.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0572956 Vali Loss: 0.0695640 Test Loss: 0.0808186\n",
      "Validation loss decreased (0.069646 --> 0.069564).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570938\n",
      "\tspeed: 0.0678s/iter; left time: 1317.5560s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562633\n",
      "\tspeed: 0.0355s/iter; left time: 686.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0569312 Vali Loss: 0.0693360 Test Loss: 0.0807541\n",
      "Validation loss decreased (0.069564 --> 0.069336).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0537705\n",
      "\tspeed: 0.0687s/iter; left time: 1320.1573s\n",
      "\titers: 200, epoch: 14 | loss: 0.0578052\n",
      "\tspeed: 0.0354s/iter; left time: 676.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0566256 Vali Loss: 0.0694911 Test Loss: 0.0805661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587510\n",
      "\tspeed: 0.0652s/iter; left time: 1237.5370s\n",
      "\titers: 200, epoch: 15 | loss: 0.0568240\n",
      "\tspeed: 0.0354s/iter; left time: 668.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0564097 Vali Loss: 0.0691684 Test Loss: 0.0807191\n",
      "Validation loss decreased (0.069336 --> 0.069168).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0599924\n",
      "\tspeed: 0.0680s/iter; left time: 1275.8116s\n",
      "\titers: 200, epoch: 16 | loss: 0.0536479\n",
      "\tspeed: 0.0354s/iter; left time: 660.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0561433 Vali Loss: 0.0693624 Test Loss: 0.0812679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0548374\n",
      "\tspeed: 0.0655s/iter; left time: 1214.5475s\n",
      "\titers: 200, epoch: 17 | loss: 0.0567769\n",
      "\tspeed: 0.0354s/iter; left time: 653.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0559172 Vali Loss: 0.0695743 Test Loss: 0.0812910\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608710\n",
      "\tspeed: 0.0658s/iter; left time: 1205.4118s\n",
      "\titers: 200, epoch: 18 | loss: 0.0556681\n",
      "\tspeed: 0.0354s/iter; left time: 645.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0557394 Vali Loss: 0.0695313 Test Loss: 0.0813298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0558614\n",
      "\tspeed: 0.0657s/iter; left time: 1189.2892s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570341\n",
      "\tspeed: 0.0354s/iter; left time: 637.6695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0555549 Vali Loss: 0.0694608 Test Loss: 0.0812635\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582343\n",
      "\tspeed: 0.0663s/iter; left time: 1186.0984s\n",
      "\titers: 200, epoch: 20 | loss: 0.0527344\n",
      "\tspeed: 0.0354s/iter; left time: 630.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0553880 Vali Loss: 0.0695730 Test Loss: 0.0817058\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0549253\n",
      "\tspeed: 0.0655s/iter; left time: 1156.4616s\n",
      "\titers: 200, epoch: 21 | loss: 0.0572006\n",
      "\tspeed: 0.0355s/iter; left time: 623.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0552723 Vali Loss: 0.0695640 Test Loss: 0.0813932\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0524042\n",
      "\tspeed: 0.0661s/iter; left time: 1152.6042s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539139\n",
      "\tspeed: 0.0355s/iter; left time: 615.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0551118 Vali Loss: 0.0697175 Test Loss: 0.0816214\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0565736\n",
      "\tspeed: 0.0654s/iter; left time: 1125.5020s\n",
      "\titers: 200, epoch: 23 | loss: 0.0502564\n",
      "\tspeed: 0.0355s/iter; left time: 607.7470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0549755 Vali Loss: 0.0695328 Test Loss: 0.0816044\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0571896\n",
      "\tspeed: 0.0655s/iter; left time: 1113.1195s\n",
      "\titers: 200, epoch: 24 | loss: 0.0563414\n",
      "\tspeed: 0.0355s/iter; left time: 599.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0548804 Vali Loss: 0.0693878 Test Loss: 0.0821570\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0534910\n",
      "\tspeed: 0.0660s/iter; left time: 1106.5047s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567336\n",
      "\tspeed: 0.0354s/iter; left time: 590.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0548006 Vali Loss: 0.0694751 Test Loss: 0.0820147\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01948266476392746, rmse:0.13958030939102173, mae:0.08071916550397873, rse:0.5399338006973267\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0952632\n",
      "\tspeed: 0.0373s/iter; left time: 824.5705s\n",
      "\titers: 200, epoch: 1 | loss: 0.0882251\n",
      "\tspeed: 0.0354s/iter; left time: 778.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0984777 Vali Loss: 0.0887115 Test Loss: 0.0972712\n",
      "Validation loss decreased (inf --> 0.088711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0684055\n",
      "\tspeed: 0.0682s/iter; left time: 1491.7078s\n",
      "\titers: 200, epoch: 2 | loss: 0.0648619\n",
      "\tspeed: 0.0353s/iter; left time: 769.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0695240 Vali Loss: 0.0743351 Test Loss: 0.0826704\n",
      "Validation loss decreased (0.088711 --> 0.074335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636595\n",
      "\tspeed: 0.0668s/iter; left time: 1447.5879s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675047\n",
      "\tspeed: 0.0354s/iter; left time: 762.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0633260 Vali Loss: 0.0723846 Test Loss: 0.0817243\n",
      "Validation loss decreased (0.074335 --> 0.072385).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609815\n",
      "\tspeed: 0.0665s/iter; left time: 1426.3549s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616805\n",
      "\tspeed: 0.0351s/iter; left time: 748.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0616337 Vali Loss: 0.0714362 Test Loss: 0.0802713\n",
      "Validation loss decreased (0.072385 --> 0.071436).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0625119\n",
      "\tspeed: 0.0682s/iter; left time: 1447.5042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612546\n",
      "\tspeed: 0.0354s/iter; left time: 746.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0605159 Vali Loss: 0.0711307 Test Loss: 0.0806584\n",
      "Validation loss decreased (0.071436 --> 0.071131).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579954\n",
      "\tspeed: 0.0666s/iter; left time: 1397.2714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0607083\n",
      "\tspeed: 0.0354s/iter; left time: 739.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0598531 Vali Loss: 0.0707090 Test Loss: 0.0807273\n",
      "Validation loss decreased (0.071131 --> 0.070709).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563586\n",
      "\tspeed: 0.0660s/iter; left time: 1371.2620s\n",
      "\titers: 200, epoch: 7 | loss: 0.0581983\n",
      "\tspeed: 0.0354s/iter; left time: 730.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0591799 Vali Loss: 0.0702574 Test Loss: 0.0805652\n",
      "Validation loss decreased (0.070709 --> 0.070257).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0548895\n",
      "\tspeed: 0.0676s/iter; left time: 1389.8110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0588075\n",
      "\tspeed: 0.0354s/iter; left time: 723.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0587707 Vali Loss: 0.0706747 Test Loss: 0.0802811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0568464\n",
      "\tspeed: 0.0654s/iter; left time: 1329.5698s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626500\n",
      "\tspeed: 0.0351s/iter; left time: 709.1836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0583234 Vali Loss: 0.0702878 Test Loss: 0.0808060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0558727\n",
      "\tspeed: 0.0660s/iter; left time: 1325.8540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0567011\n",
      "\tspeed: 0.0350s/iter; left time: 700.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0579293 Vali Loss: 0.0699047 Test Loss: 0.0802349\n",
      "Validation loss decreased (0.070257 --> 0.069905).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0550953\n",
      "\tspeed: 0.0667s/iter; left time: 1325.3956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0569662\n",
      "\tspeed: 0.0354s/iter; left time: 699.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0576132 Vali Loss: 0.0698486 Test Loss: 0.0809873\n",
      "Validation loss decreased (0.069905 --> 0.069849).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0587837\n",
      "\tspeed: 0.0693s/iter; left time: 1362.3569s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571281\n",
      "\tspeed: 0.0354s/iter; left time: 692.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0572527 Vali Loss: 0.0696938 Test Loss: 0.0804241\n",
      "Validation loss decreased (0.069849 --> 0.069694).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0594783\n",
      "\tspeed: 0.0664s/iter; left time: 1290.7610s\n",
      "\titers: 200, epoch: 13 | loss: 0.0590962\n",
      "\tspeed: 0.0354s/iter; left time: 684.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0569948 Vali Loss: 0.0695417 Test Loss: 0.0802769\n",
      "Validation loss decreased (0.069694 --> 0.069542).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0586970\n",
      "\tspeed: 0.0691s/iter; left time: 1328.1501s\n",
      "\titers: 200, epoch: 14 | loss: 0.0570726\n",
      "\tspeed: 0.0353s/iter; left time: 674.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0567403 Vali Loss: 0.0694959 Test Loss: 0.0799488\n",
      "Validation loss decreased (0.069542 --> 0.069496).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0508721\n",
      "\tspeed: 0.0674s/iter; left time: 1279.5230s\n",
      "\titers: 200, epoch: 15 | loss: 0.0571368\n",
      "\tspeed: 0.0354s/iter; left time: 669.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0564738 Vali Loss: 0.0696391 Test Loss: 0.0806447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578979\n",
      "\tspeed: 0.0655s/iter; left time: 1229.7151s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557072\n",
      "\tspeed: 0.0354s/iter; left time: 661.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0562549 Vali Loss: 0.0693150 Test Loss: 0.0804174\n",
      "Validation loss decreased (0.069496 --> 0.069315).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562159\n",
      "\tspeed: 0.0687s/iter; left time: 1274.4518s\n",
      "\titers: 200, epoch: 17 | loss: 0.0547446\n",
      "\tspeed: 0.0354s/iter; left time: 653.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0560603 Vali Loss: 0.0694241 Test Loss: 0.0808445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0540287\n",
      "\tspeed: 0.0656s/iter; left time: 1202.6489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0579191\n",
      "\tspeed: 0.0354s/iter; left time: 644.7447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0558207 Vali Loss: 0.0693042 Test Loss: 0.0811839\n",
      "Validation loss decreased (0.069315 --> 0.069304).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564311\n",
      "\tspeed: 0.0667s/iter; left time: 1207.6176s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542815\n",
      "\tspeed: 0.0354s/iter; left time: 637.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0556295 Vali Loss: 0.0692249 Test Loss: 0.0809378\n",
      "Validation loss decreased (0.069304 --> 0.069225).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543697\n",
      "\tspeed: 0.0662s/iter; left time: 1184.5198s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536799\n",
      "\tspeed: 0.0355s/iter; left time: 630.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0554733 Vali Loss: 0.0693348 Test Loss: 0.0810664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560020\n",
      "\tspeed: 0.0663s/iter; left time: 1170.3878s\n",
      "\titers: 200, epoch: 21 | loss: 0.0537978\n",
      "\tspeed: 0.0355s/iter; left time: 624.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0553447 Vali Loss: 0.0692935 Test Loss: 0.0814518\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0574112\n",
      "\tspeed: 0.0664s/iter; left time: 1157.2201s\n",
      "\titers: 200, epoch: 22 | loss: 0.0532606\n",
      "\tspeed: 0.0354s/iter; left time: 613.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0551855 Vali Loss: 0.0692805 Test Loss: 0.0813622\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513187\n",
      "\tspeed: 0.0653s/iter; left time: 1124.6813s\n",
      "\titers: 200, epoch: 23 | loss: 0.0571556\n",
      "\tspeed: 0.0354s/iter; left time: 605.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0550499 Vali Loss: 0.0693083 Test Loss: 0.0811403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0542284\n",
      "\tspeed: 0.0653s/iter; left time: 1109.8194s\n",
      "\titers: 200, epoch: 24 | loss: 0.0524075\n",
      "\tspeed: 0.0354s/iter; left time: 597.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0549588 Vali Loss: 0.0693526 Test Loss: 0.0811186\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0529980\n",
      "\tspeed: 0.0654s/iter; left time: 1096.4720s\n",
      "\titers: 200, epoch: 25 | loss: 0.0608104\n",
      "\tspeed: 0.0352s/iter; left time: 587.1956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0548511 Vali Loss: 0.0693528 Test Loss: 0.0813975\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0549603\n",
      "\tspeed: 0.0659s/iter; left time: 1090.3294s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546359\n",
      "\tspeed: 0.0350s/iter; left time: 575.4963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0547515 Vali Loss: 0.0693082 Test Loss: 0.0813971\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0566669\n",
      "\tspeed: 0.0657s/iter; left time: 1072.5640s\n",
      "\titers: 200, epoch: 27 | loss: 0.0536185\n",
      "\tspeed: 0.0354s/iter; left time: 574.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0546388 Vali Loss: 0.0692286 Test Loss: 0.0812176\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0581224\n",
      "\tspeed: 0.0652s/iter; left time: 1050.6461s\n",
      "\titers: 200, epoch: 28 | loss: 0.0531175\n",
      "\tspeed: 0.0354s/iter; left time: 566.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0545494 Vali Loss: 0.0692481 Test Loss: 0.0811681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0550669\n",
      "\tspeed: 0.0660s/iter; left time: 1048.3709s\n",
      "\titers: 200, epoch: 29 | loss: 0.0559058\n",
      "\tspeed: 0.0353s/iter; left time: 557.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0545274 Vali Loss: 0.0692898 Test Loss: 0.0814695\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019968293607234955, rmse:0.1413092166185379, mae:0.08093781024217606, rse:0.546621561050415\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:21.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0937559\n",
      "\tspeed: 0.0561s/iter; left time: 1239.1318s\n",
      "\titers: 200, epoch: 1 | loss: 0.0854991\n",
      "\tspeed: 0.0355s/iter; left time: 779.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 222 | Train Loss: 0.0996557 Vali Loss: 0.0909250 Test Loss: 0.0982337\n",
      "Validation loss decreased (inf --> 0.090925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0671461\n",
      "\tspeed: 0.0656s/iter; left time: 1434.8695s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668403\n",
      "\tspeed: 0.0355s/iter; left time: 772.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0727891 Vali Loss: 0.0776555 Test Loss: 0.0865498\n",
      "Validation loss decreased (0.090925 --> 0.077656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0663325\n",
      "\tspeed: 0.0668s/iter; left time: 1446.0545s\n",
      "\titers: 200, epoch: 3 | loss: 0.0676556\n",
      "\tspeed: 0.0356s/iter; left time: 766.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0669277 Vali Loss: 0.0760982 Test Loss: 0.0855469\n",
      "Validation loss decreased (0.077656 --> 0.076098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676006\n",
      "\tspeed: 0.0666s/iter; left time: 1428.5333s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629337\n",
      "\tspeed: 0.0357s/iter; left time: 760.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0653958 Vali Loss: 0.0748803 Test Loss: 0.0857829\n",
      "Validation loss decreased (0.076098 --> 0.074880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0611826\n",
      "\tspeed: 0.0730s/iter; left time: 1548.7207s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664870\n",
      "\tspeed: 0.0356s/iter; left time: 751.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0643448 Vali Loss: 0.0745668 Test Loss: 0.0858744\n",
      "Validation loss decreased (0.074880 --> 0.074567).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614737\n",
      "\tspeed: 0.0655s/iter; left time: 1375.5068s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662357\n",
      "\tspeed: 0.0356s/iter; left time: 743.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0634906 Vali Loss: 0.0741564 Test Loss: 0.0861201\n",
      "Validation loss decreased (0.074567 --> 0.074156).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0638003\n",
      "\tspeed: 0.0705s/iter; left time: 1464.1748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668866\n",
      "\tspeed: 0.0356s/iter; left time: 735.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0628535 Vali Loss: 0.0738947 Test Loss: 0.0862584\n",
      "Validation loss decreased (0.074156 --> 0.073895).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640526\n",
      "\tspeed: 0.0671s/iter; left time: 1378.5933s\n",
      "\titers: 200, epoch: 8 | loss: 0.0602180\n",
      "\tspeed: 0.0356s/iter; left time: 727.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0623205 Vali Loss: 0.0736341 Test Loss: 0.0873836\n",
      "Validation loss decreased (0.073895 --> 0.073634).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0597319\n",
      "\tspeed: 0.0677s/iter; left time: 1375.0568s\n",
      "\titers: 200, epoch: 9 | loss: 0.0623516\n",
      "\tspeed: 0.0356s/iter; left time: 719.8003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0617649 Vali Loss: 0.0733476 Test Loss: 0.0872618\n",
      "Validation loss decreased (0.073634 --> 0.073348).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0592745\n",
      "\tspeed: 0.0667s/iter; left time: 1340.9773s\n",
      "\titers: 200, epoch: 10 | loss: 0.0611175\n",
      "\tspeed: 0.0356s/iter; left time: 711.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0613298 Vali Loss: 0.0734085 Test Loss: 0.0880000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628366\n",
      "\tspeed: 0.0668s/iter; left time: 1327.6390s\n",
      "\titers: 200, epoch: 11 | loss: 0.0590079\n",
      "\tspeed: 0.0357s/iter; left time: 705.2565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0608626 Vali Loss: 0.0732229 Test Loss: 0.0884979\n",
      "Validation loss decreased (0.073348 --> 0.073223).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0631045\n",
      "\tspeed: 0.0685s/iter; left time: 1346.3562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0598766\n",
      "\tspeed: 0.0356s/iter; left time: 696.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0604511 Vali Loss: 0.0730404 Test Loss: 0.0892168\n",
      "Validation loss decreased (0.073223 --> 0.073040).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0589007\n",
      "\tspeed: 0.0709s/iter; left time: 1377.8861s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626884\n",
      "\tspeed: 0.0356s/iter; left time: 688.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0600724 Vali Loss: 0.0733249 Test Loss: 0.0880689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554329\n",
      "\tspeed: 0.0646s/iter; left time: 1241.6465s\n",
      "\titers: 200, epoch: 14 | loss: 0.0609844\n",
      "\tspeed: 0.0356s/iter; left time: 680.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0597418 Vali Loss: 0.0732096 Test Loss: 0.0892474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584123\n",
      "\tspeed: 0.0669s/iter; left time: 1270.9218s\n",
      "\titers: 200, epoch: 15 | loss: 0.0562647\n",
      "\tspeed: 0.0356s/iter; left time: 672.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0594256 Vali Loss: 0.0731097 Test Loss: 0.0883574\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0595126\n",
      "\tspeed: 0.0652s/iter; left time: 1223.3511s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591843\n",
      "\tspeed: 0.0356s/iter; left time: 664.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0590443 Vali Loss: 0.0733004 Test Loss: 0.0884439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0588591\n",
      "\tspeed: 0.0654s/iter; left time: 1213.0199s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619928\n",
      "\tspeed: 0.0356s/iter; left time: 656.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0588040 Vali Loss: 0.0732601 Test Loss: 0.0887275\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0623288\n",
      "\tspeed: 0.0658s/iter; left time: 1206.2240s\n",
      "\titers: 200, epoch: 18 | loss: 0.0596518\n",
      "\tspeed: 0.0356s/iter; left time: 647.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0585427 Vali Loss: 0.0734186 Test Loss: 0.0887857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578743\n",
      "\tspeed: 0.0652s/iter; left time: 1180.0319s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603924\n",
      "\tspeed: 0.0356s/iter; left time: 640.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0582407 Vali Loss: 0.0731707 Test Loss: 0.0886741\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0583632\n",
      "\tspeed: 0.0652s/iter; left time: 1166.5112s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561615\n",
      "\tspeed: 0.0356s/iter; left time: 632.5779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0580611 Vali Loss: 0.0733136 Test Loss: 0.0878214\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0573657\n",
      "\tspeed: 0.0665s/iter; left time: 1174.8416s\n",
      "\titers: 200, epoch: 21 | loss: 0.0576622\n",
      "\tspeed: 0.0356s/iter; left time: 625.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0579166 Vali Loss: 0.0733115 Test Loss: 0.0880976\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0600090\n",
      "\tspeed: 0.0652s/iter; left time: 1137.6887s\n",
      "\titers: 200, epoch: 22 | loss: 0.0580474\n",
      "\tspeed: 0.0356s/iter; left time: 617.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0577131 Vali Loss: 0.0735373 Test Loss: 0.0889308\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022798532620072365, rmse:0.15099182724952698, mae:0.08921678364276886, rse:0.5848056674003601\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0909746\n",
      "\tspeed: 0.0377s/iter; left time: 833.2248s\n",
      "\titers: 200, epoch: 1 | loss: 0.0863153\n",
      "\tspeed: 0.0356s/iter; left time: 783.0251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.1003204 Vali Loss: 0.0907418 Test Loss: 0.0980454\n",
      "Validation loss decreased (inf --> 0.090742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0734469\n",
      "\tspeed: 0.0719s/iter; left time: 1572.7107s\n",
      "\titers: 200, epoch: 2 | loss: 0.0706323\n",
      "\tspeed: 0.0356s/iter; left time: 775.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0730947 Vali Loss: 0.0781138 Test Loss: 0.0861697\n",
      "Validation loss decreased (0.090742 --> 0.078114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670260\n",
      "\tspeed: 0.0673s/iter; left time: 1457.4871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0672487\n",
      "\tspeed: 0.0356s/iter; left time: 768.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0671942 Vali Loss: 0.0764739 Test Loss: 0.0861640\n",
      "Validation loss decreased (0.078114 --> 0.076474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0642420\n",
      "\tspeed: 0.0680s/iter; left time: 1458.2017s\n",
      "\titers: 200, epoch: 4 | loss: 0.0681193\n",
      "\tspeed: 0.0356s/iter; left time: 760.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0656319 Vali Loss: 0.0756089 Test Loss: 0.0862310\n",
      "Validation loss decreased (0.076474 --> 0.075609).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0662459\n",
      "\tspeed: 0.0670s/iter; left time: 1420.6034s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619034\n",
      "\tspeed: 0.0356s/iter; left time: 751.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0644669 Vali Loss: 0.0750021 Test Loss: 0.0863676\n",
      "Validation loss decreased (0.075609 --> 0.075002).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0615688\n",
      "\tspeed: 0.0688s/iter; left time: 1443.4137s\n",
      "\titers: 200, epoch: 6 | loss: 0.0642635\n",
      "\tspeed: 0.0356s/iter; left time: 743.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0636490 Vali Loss: 0.0744124 Test Loss: 0.0862947\n",
      "Validation loss decreased (0.075002 --> 0.074412).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0634491\n",
      "\tspeed: 0.0675s/iter; left time: 1401.9660s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646780\n",
      "\tspeed: 0.0356s/iter; left time: 736.2142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0630115 Vali Loss: 0.0743968 Test Loss: 0.0861245\n",
      "Validation loss decreased (0.074412 --> 0.074397).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0609125\n",
      "\tspeed: 0.0680s/iter; left time: 1396.7771s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609732\n",
      "\tspeed: 0.0356s/iter; left time: 728.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0624589 Vali Loss: 0.0742223 Test Loss: 0.0872146\n",
      "Validation loss decreased (0.074397 --> 0.074222).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0626477\n",
      "\tspeed: 0.0745s/iter; left time: 1515.2203s\n",
      "\titers: 200, epoch: 9 | loss: 0.0611828\n",
      "\tspeed: 0.0355s/iter; left time: 718.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0619476 Vali Loss: 0.0739779 Test Loss: 0.0874620\n",
      "Validation loss decreased (0.074222 --> 0.073978).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0587265\n",
      "\tspeed: 0.0668s/iter; left time: 1342.0950s\n",
      "\titers: 200, epoch: 10 | loss: 0.0634449\n",
      "\tspeed: 0.0357s/iter; left time: 714.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0615030 Vali Loss: 0.0735479 Test Loss: 0.0874568\n",
      "Validation loss decreased (0.073978 --> 0.073548).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0611382\n",
      "\tspeed: 0.0682s/iter; left time: 1356.1429s\n",
      "\titers: 200, epoch: 11 | loss: 0.0599037\n",
      "\tspeed: 0.0356s/iter; left time: 704.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0609948 Vali Loss: 0.0734347 Test Loss: 0.0872699\n",
      "Validation loss decreased (0.073548 --> 0.073435).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0662991\n",
      "\tspeed: 0.0685s/iter; left time: 1346.9227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608686\n",
      "\tspeed: 0.0357s/iter; left time: 699.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0606455 Vali Loss: 0.0734493 Test Loss: 0.0879909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596966\n",
      "\tspeed: 0.0657s/iter; left time: 1276.2439s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599534\n",
      "\tspeed: 0.0355s/iter; left time: 686.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0601907 Vali Loss: 0.0735516 Test Loss: 0.0877190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608951\n",
      "\tspeed: 0.0657s/iter; left time: 1262.0944s\n",
      "\titers: 200, epoch: 14 | loss: 0.0583582\n",
      "\tspeed: 0.0355s/iter; left time: 678.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0598597 Vali Loss: 0.0735693 Test Loss: 0.0877809\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0589544\n",
      "\tspeed: 0.0659s/iter; left time: 1251.5029s\n",
      "\titers: 200, epoch: 15 | loss: 0.0602499\n",
      "\tspeed: 0.0356s/iter; left time: 672.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0595246 Vali Loss: 0.0736768 Test Loss: 0.0872724\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0602101\n",
      "\tspeed: 0.0656s/iter; left time: 1230.9355s\n",
      "\titers: 200, epoch: 16 | loss: 0.0599441\n",
      "\tspeed: 0.0356s/iter; left time: 664.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0592592 Vali Loss: 0.0735794 Test Loss: 0.0879726\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604870\n",
      "\tspeed: 0.0660s/iter; left time: 1223.9008s\n",
      "\titers: 200, epoch: 17 | loss: 0.0608909\n",
      "\tspeed: 0.0356s/iter; left time: 656.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0590200 Vali Loss: 0.0737601 Test Loss: 0.0877102\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599590\n",
      "\tspeed: 0.0662s/iter; left time: 1212.8331s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562896\n",
      "\tspeed: 0.0356s/iter; left time: 648.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0587453 Vali Loss: 0.0735990 Test Loss: 0.0877120\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0577539\n",
      "\tspeed: 0.0667s/iter; left time: 1207.1130s\n",
      "\titers: 200, epoch: 19 | loss: 0.0615933\n",
      "\tspeed: 0.0358s/iter; left time: 644.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0585088 Vali Loss: 0.0736174 Test Loss: 0.0875808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0613166\n",
      "\tspeed: 0.0662s/iter; left time: 1184.7246s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565838\n",
      "\tspeed: 0.0358s/iter; left time: 636.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0583672 Vali Loss: 0.0737815 Test Loss: 0.0879796\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569845\n",
      "\tspeed: 0.0658s/iter; left time: 1161.7737s\n",
      "\titers: 200, epoch: 21 | loss: 0.0580906\n",
      "\tspeed: 0.0356s/iter; left time: 625.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0581812 Vali Loss: 0.0738442 Test Loss: 0.0877143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02144342102110386, rmse:0.1464357227087021, mae:0.08726988732814789, rse:0.5671594142913818\n",
      "Intermediate time for FR and pred_len 168: 00h:07m:33.54s\n",
      "Intermediate time for FR: 00h:34m:26.29s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1215151\n",
      "\tspeed: 0.0584s/iter; left time: 1295.5311s\n",
      "\titers: 200, epoch: 1 | loss: 0.1118875\n",
      "\tspeed: 0.0348s/iter; left time: 769.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 223 | Train Loss: 0.1326542 Vali Loss: 0.0942807 Test Loss: 0.0955525\n",
      "Validation loss decreased (inf --> 0.094281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692392\n",
      "\tspeed: 0.0640s/iter; left time: 1406.0753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668463\n",
      "\tspeed: 0.0348s/iter; left time: 762.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0759663 Vali Loss: 0.0627304 Test Loss: 0.0655534\n",
      "Validation loss decreased (0.094281 --> 0.062730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0653248\n",
      "\tspeed: 0.0646s/iter; left time: 1406.0183s\n",
      "\titers: 200, epoch: 3 | loss: 0.0658268\n",
      "\tspeed: 0.0348s/iter; left time: 753.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0649989 Vali Loss: 0.0598344 Test Loss: 0.0623941\n",
      "Validation loss decreased (0.062730 --> 0.059834).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612408\n",
      "\tspeed: 0.0640s/iter; left time: 1378.4370s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641704\n",
      "\tspeed: 0.0348s/iter; left time: 745.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0622214 Vali Loss: 0.0590931 Test Loss: 0.0612764\n",
      "Validation loss decreased (0.059834 --> 0.059093).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0578229\n",
      "\tspeed: 0.0643s/iter; left time: 1371.0302s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619481\n",
      "\tspeed: 0.0348s/iter; left time: 737.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0607123 Vali Loss: 0.0585121 Test Loss: 0.0608895\n",
      "Validation loss decreased (0.059093 --> 0.058512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601596\n",
      "\tspeed: 0.0650s/iter; left time: 1370.2385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582513\n",
      "\tspeed: 0.0348s/iter; left time: 729.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0596344 Vali Loss: 0.0577123 Test Loss: 0.0601836\n",
      "Validation loss decreased (0.058512 --> 0.057712).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607782\n",
      "\tspeed: 0.0649s/iter; left time: 1354.3299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582576\n",
      "\tspeed: 0.0348s/iter; left time: 721.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0587942 Vali Loss: 0.0578430 Test Loss: 0.0603699\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568957\n",
      "\tspeed: 0.0643s/iter; left time: 1327.7018s\n",
      "\titers: 200, epoch: 8 | loss: 0.0612838\n",
      "\tspeed: 0.0352s/iter; left time: 723.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0581849 Vali Loss: 0.0571036 Test Loss: 0.0594110\n",
      "Validation loss decreased (0.057712 --> 0.057104).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551574\n",
      "\tspeed: 0.0660s/iter; left time: 1348.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544234\n",
      "\tspeed: 0.0351s/iter; left time: 713.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0575606 Vali Loss: 0.0566828 Test Loss: 0.0591373\n",
      "Validation loss decreased (0.057104 --> 0.056683).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0561724\n",
      "\tspeed: 0.0651s/iter; left time: 1315.1278s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550264\n",
      "\tspeed: 0.0348s/iter; left time: 698.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0571180 Vali Loss: 0.0566658 Test Loss: 0.0590203\n",
      "Validation loss decreased (0.056683 --> 0.056666).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0558567\n",
      "\tspeed: 0.0644s/iter; left time: 1286.5022s\n",
      "\titers: 200, epoch: 11 | loss: 0.0551412\n",
      "\tspeed: 0.0348s/iter; left time: 691.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0566924 Vali Loss: 0.0562612 Test Loss: 0.0588131\n",
      "Validation loss decreased (0.056666 --> 0.056261).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0582320\n",
      "\tspeed: 0.0649s/iter; left time: 1281.9793s\n",
      "\titers: 200, epoch: 12 | loss: 0.0552496\n",
      "\tspeed: 0.0348s/iter; left time: 683.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0563733 Vali Loss: 0.0559708 Test Loss: 0.0585530\n",
      "Validation loss decreased (0.056261 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0537563\n",
      "\tspeed: 0.0642s/iter; left time: 1253.5717s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591910\n",
      "\tspeed: 0.0351s/iter; left time: 681.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0560258 Vali Loss: 0.0559113 Test Loss: 0.0584941\n",
      "Validation loss decreased (0.055971 --> 0.055911).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0578019\n",
      "\tspeed: 0.0661s/iter; left time: 1276.2238s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537843\n",
      "\tspeed: 0.0352s/iter; left time: 675.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0557317 Vali Loss: 0.0559744 Test Loss: 0.0587135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582544\n",
      "\tspeed: 0.0650s/iter; left time: 1239.8983s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575671\n",
      "\tspeed: 0.0351s/iter; left time: 666.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0555913 Vali Loss: 0.0556698 Test Loss: 0.0585108\n",
      "Validation loss decreased (0.055911 --> 0.055670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573789\n",
      "\tspeed: 0.0660s/iter; left time: 1244.6433s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597599\n",
      "\tspeed: 0.0350s/iter; left time: 656.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0553490 Vali Loss: 0.0555906 Test Loss: 0.0583118\n",
      "Validation loss decreased (0.055670 --> 0.055591).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0530117\n",
      "\tspeed: 0.0641s/iter; left time: 1193.9584s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540745\n",
      "\tspeed: 0.0348s/iter; left time: 645.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0551468 Vali Loss: 0.0554781 Test Loss: 0.0580857\n",
      "Validation loss decreased (0.055591 --> 0.055478).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0579623\n",
      "\tspeed: 0.0633s/iter; left time: 1164.9885s\n",
      "\titers: 200, epoch: 18 | loss: 0.0557412\n",
      "\tspeed: 0.0348s/iter; left time: 636.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0549865 Vali Loss: 0.0554452 Test Loss: 0.0580464\n",
      "Validation loss decreased (0.055478 --> 0.055445).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0522057\n",
      "\tspeed: 0.0661s/iter; left time: 1202.7089s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545580\n",
      "\tspeed: 0.0351s/iter; left time: 635.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0548027 Vali Loss: 0.0552358 Test Loss: 0.0578113\n",
      "Validation loss decreased (0.055445 --> 0.055236).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0529114\n",
      "\tspeed: 0.0657s/iter; left time: 1179.4980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0570487\n",
      "\tspeed: 0.0351s/iter; left time: 626.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0545887 Vali Loss: 0.0552181 Test Loss: 0.0577855\n",
      "Validation loss decreased (0.055236 --> 0.055218).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0552240\n",
      "\tspeed: 0.0650s/iter; left time: 1153.0202s\n",
      "\titers: 200, epoch: 21 | loss: 0.0546114\n",
      "\tspeed: 0.0348s/iter; left time: 613.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0544541 Vali Loss: 0.0550816 Test Loss: 0.0578460\n",
      "Validation loss decreased (0.055218 --> 0.055082).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533617\n",
      "\tspeed: 0.0654s/iter; left time: 1144.9189s\n",
      "\titers: 200, epoch: 22 | loss: 0.0563828\n",
      "\tspeed: 0.0351s/iter; left time: 611.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0543534 Vali Loss: 0.0550777 Test Loss: 0.0576476\n",
      "Validation loss decreased (0.055082 --> 0.055078).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511991\n",
      "\tspeed: 0.0668s/iter; left time: 1155.7207s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566833\n",
      "\tspeed: 0.0349s/iter; left time: 600.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0543686 Vali Loss: 0.0550093 Test Loss: 0.0577616\n",
      "Validation loss decreased (0.055078 --> 0.055009).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0561067\n",
      "\tspeed: 0.0661s/iter; left time: 1127.7561s\n",
      "\titers: 200, epoch: 24 | loss: 0.0524344\n",
      "\tspeed: 0.0349s/iter; left time: 592.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0541953 Vali Loss: 0.0550054 Test Loss: 0.0576725\n",
      "Validation loss decreased (0.055009 --> 0.055005).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0548554\n",
      "\tspeed: 0.0659s/iter; left time: 1110.4297s\n",
      "\titers: 200, epoch: 25 | loss: 0.0545839\n",
      "\tspeed: 0.0352s/iter; left time: 589.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0541028 Vali Loss: 0.0548294 Test Loss: 0.0576062\n",
      "Validation loss decreased (0.055005 --> 0.054829).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537943\n",
      "\tspeed: 0.0659s/iter; left time: 1095.5692s\n",
      "\titers: 200, epoch: 26 | loss: 0.0544039\n",
      "\tspeed: 0.0352s/iter; left time: 580.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0540807 Vali Loss: 0.0549287 Test Loss: 0.0575237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516824\n",
      "\tspeed: 0.0648s/iter; left time: 1062.6808s\n",
      "\titers: 200, epoch: 27 | loss: 0.0538087\n",
      "\tspeed: 0.0350s/iter; left time: 571.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0540239 Vali Loss: 0.0549428 Test Loss: 0.0576405\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0550418\n",
      "\tspeed: 0.0649s/iter; left time: 1049.2804s\n",
      "\titers: 200, epoch: 28 | loss: 0.0557069\n",
      "\tspeed: 0.0352s/iter; left time: 565.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0539656 Vali Loss: 0.0549259 Test Loss: 0.0575492\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525850\n",
      "\tspeed: 0.0658s/iter; left time: 1050.3386s\n",
      "\titers: 200, epoch: 29 | loss: 0.0557783\n",
      "\tspeed: 0.0351s/iter; left time: 556.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0538052 Vali Loss: 0.0548689 Test Loss: 0.0575678\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0511998\n",
      "\tspeed: 0.0653s/iter; left time: 1027.5420s\n",
      "\titers: 200, epoch: 30 | loss: 0.0484094\n",
      "\tspeed: 0.0351s/iter; left time: 548.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0538262 Vali Loss: 0.0548523 Test Loss: 0.0574607\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0547087\n",
      "\tspeed: 0.0654s/iter; left time: 1014.9761s\n",
      "\titers: 200, epoch: 31 | loss: 0.0517584\n",
      "\tspeed: 0.0351s/iter; left time: 541.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0537514 Vali Loss: 0.0547773 Test Loss: 0.0574989\n",
      "Validation loss decreased (0.054829 --> 0.054777).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0566123\n",
      "\tspeed: 0.0666s/iter; left time: 1018.2078s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561727\n",
      "\tspeed: 0.0351s/iter; left time: 532.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0537302 Vali Loss: 0.0546972 Test Loss: 0.0574458\n",
      "Validation loss decreased (0.054777 --> 0.054697).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0504116\n",
      "\tspeed: 0.0664s/iter; left time: 999.7059s\n",
      "\titers: 200, epoch: 33 | loss: 0.0543427\n",
      "\tspeed: 0.0351s/iter; left time: 524.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0537074 Vali Loss: 0.0547021 Test Loss: 0.0574178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0528668\n",
      "\tspeed: 0.0650s/iter; left time: 965.4444s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530927\n",
      "\tspeed: 0.0352s/iter; left time: 518.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0536574 Vali Loss: 0.0547484 Test Loss: 0.0575011\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0500943\n",
      "\tspeed: 0.0648s/iter; left time: 947.6750s\n",
      "\titers: 200, epoch: 35 | loss: 0.0544246\n",
      "\tspeed: 0.0351s/iter; left time: 509.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0536428 Vali Loss: 0.0547106 Test Loss: 0.0574473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0533398\n",
      "\tspeed: 0.0647s/iter; left time: 930.9460s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516305\n",
      "\tspeed: 0.0351s/iter; left time: 502.2065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0535983 Vali Loss: 0.0547135 Test Loss: 0.0573656\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0511870\n",
      "\tspeed: 0.0644s/iter; left time: 912.4765s\n",
      "\titers: 200, epoch: 37 | loss: 0.0523624\n",
      "\tspeed: 0.0352s/iter; left time: 494.9946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0535729 Vali Loss: 0.0547284 Test Loss: 0.0574137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0543733\n",
      "\tspeed: 0.0647s/iter; left time: 902.9269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0522128\n",
      "\tspeed: 0.0351s/iter; left time: 486.0404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0535330 Vali Loss: 0.0547177 Test Loss: 0.0574156\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0500885\n",
      "\tspeed: 0.0655s/iter; left time: 899.1704s\n",
      "\titers: 200, epoch: 39 | loss: 0.0544045\n",
      "\tspeed: 0.0351s/iter; left time: 478.4573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0535079 Vali Loss: 0.0546792 Test Loss: 0.0574100\n",
      "Validation loss decreased (0.054697 --> 0.054679).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0556632\n",
      "\tspeed: 0.0670s/iter; left time: 905.3214s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608936\n",
      "\tspeed: 0.0350s/iter; left time: 468.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0534729 Vali Loss: 0.0546630 Test Loss: 0.0573546\n",
      "Validation loss decreased (0.054679 --> 0.054663).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530188\n",
      "\tspeed: 0.0659s/iter; left time: 875.4849s\n",
      "\titers: 200, epoch: 41 | loss: 0.0543008\n",
      "\tspeed: 0.0348s/iter; left time: 458.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0534663 Vali Loss: 0.0546640 Test Loss: 0.0574067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0527376\n",
      "\tspeed: 0.0639s/iter; left time: 834.7783s\n",
      "\titers: 200, epoch: 42 | loss: 0.0504257\n",
      "\tspeed: 0.0349s/iter; left time: 452.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0535045 Vali Loss: 0.0546867 Test Loss: 0.0574020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0528321\n",
      "\tspeed: 0.0641s/iter; left time: 823.0251s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554217\n",
      "\tspeed: 0.0348s/iter; left time: 442.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0534852 Vali Loss: 0.0545953 Test Loss: 0.0573738\n",
      "Validation loss decreased (0.054663 --> 0.054595).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0516735\n",
      "\tspeed: 0.0659s/iter; left time: 830.8775s\n",
      "\titers: 200, epoch: 44 | loss: 0.0480767\n",
      "\tspeed: 0.0353s/iter; left time: 442.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0534319 Vali Loss: 0.0546308 Test Loss: 0.0573753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0563546\n",
      "\tspeed: 0.0649s/iter; left time: 803.6160s\n",
      "\titers: 200, epoch: 45 | loss: 0.0553964\n",
      "\tspeed: 0.0351s/iter; left time: 431.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0534774 Vali Loss: 0.0546294 Test Loss: 0.0573575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0543456\n",
      "\tspeed: 0.0647s/iter; left time: 787.1173s\n",
      "\titers: 200, epoch: 46 | loss: 0.0519089\n",
      "\tspeed: 0.0351s/iter; left time: 423.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0534381 Vali Loss: 0.0546489 Test Loss: 0.0573632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0561337\n",
      "\tspeed: 0.0652s/iter; left time: 778.7757s\n",
      "\titers: 200, epoch: 47 | loss: 0.0566098\n",
      "\tspeed: 0.0351s/iter; left time: 415.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0534364 Vali Loss: 0.0546397 Test Loss: 0.0573571\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0528050\n",
      "\tspeed: 0.0650s/iter; left time: 762.2341s\n",
      "\titers: 200, epoch: 48 | loss: 0.0533476\n",
      "\tspeed: 0.0351s/iter; left time: 408.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533972 Vali Loss: 0.0546512 Test Loss: 0.0573457\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0541846\n",
      "\tspeed: 0.0641s/iter; left time: 737.5301s\n",
      "\titers: 200, epoch: 49 | loss: 0.0543380\n",
      "\tspeed: 0.0352s/iter; left time: 401.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0534589 Vali Loss: 0.0546227 Test Loss: 0.0573440\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0543175\n",
      "\tspeed: 0.0655s/iter; left time: 738.5563s\n",
      "\titers: 200, epoch: 50 | loss: 0.0555421\n",
      "\tspeed: 0.0351s/iter; left time: 392.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533554 Vali Loss: 0.0546184 Test Loss: 0.0573636\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0542763\n",
      "\tspeed: 0.0648s/iter; left time: 716.4132s\n",
      "\titers: 200, epoch: 51 | loss: 0.0507013\n",
      "\tspeed: 0.0352s/iter; left time: 385.6910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0534446 Vali Loss: 0.0546714 Test Loss: 0.0573693\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0516548\n",
      "\tspeed: 0.0655s/iter; left time: 709.0504s\n",
      "\titers: 200, epoch: 52 | loss: 0.0511236\n",
      "\tspeed: 0.0347s/iter; left time: 372.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0534571 Vali Loss: 0.0545920 Test Loss: 0.0573518\n",
      "Validation loss decreased (0.054595 --> 0.054592).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531069\n",
      "\tspeed: 0.0663s/iter; left time: 703.3966s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519074\n",
      "\tspeed: 0.0352s/iter; left time: 369.6296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533825 Vali Loss: 0.0546071 Test Loss: 0.0573369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0534862\n",
      "\tspeed: 0.0651s/iter; left time: 676.2541s\n",
      "\titers: 200, epoch: 54 | loss: 0.0492625\n",
      "\tspeed: 0.0351s/iter; left time: 361.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533829 Vali Loss: 0.0546410 Test Loss: 0.0573390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0580978\n",
      "\tspeed: 0.0652s/iter; left time: 661.9629s\n",
      "\titers: 200, epoch: 55 | loss: 0.0531033\n",
      "\tspeed: 0.0351s/iter; left time: 353.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533624 Vali Loss: 0.0546159 Test Loss: 0.0573383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0576224\n",
      "\tspeed: 0.0651s/iter; left time: 647.1622s\n",
      "\titers: 200, epoch: 56 | loss: 0.0542574\n",
      "\tspeed: 0.0352s/iter; left time: 346.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0534060 Vali Loss: 0.0545954 Test Loss: 0.0573395\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0483128\n",
      "\tspeed: 0.0654s/iter; left time: 635.4040s\n",
      "\titers: 200, epoch: 57 | loss: 0.0510019\n",
      "\tspeed: 0.0352s/iter; left time: 338.4549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0534189 Vali Loss: 0.0545630 Test Loss: 0.0573416\n",
      "Validation loss decreased (0.054592 --> 0.054563).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0566853\n",
      "\tspeed: 0.0660s/iter; left time: 626.3256s\n",
      "\titers: 200, epoch: 58 | loss: 0.0580699\n",
      "\tspeed: 0.0351s/iter; left time: 329.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533494 Vali Loss: 0.0546348 Test Loss: 0.0573394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0527851\n",
      "\tspeed: 0.0652s/iter; left time: 604.6087s\n",
      "\titers: 200, epoch: 59 | loss: 0.0541783\n",
      "\tspeed: 0.0352s/iter; left time: 322.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533600 Vali Loss: 0.0546001 Test Loss: 0.0573527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0554900\n",
      "\tspeed: 0.0650s/iter; left time: 587.4264s\n",
      "\titers: 200, epoch: 60 | loss: 0.0530581\n",
      "\tspeed: 0.0353s/iter; left time: 315.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0533252 Vali Loss: 0.0545773 Test Loss: 0.0573337\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0569755\n",
      "\tspeed: 0.0648s/iter; left time: 571.7519s\n",
      "\titers: 200, epoch: 61 | loss: 0.0525112\n",
      "\tspeed: 0.0351s/iter; left time: 306.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533005 Vali Loss: 0.0545922 Test Loss: 0.0573551\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0562148\n",
      "\tspeed: 0.0655s/iter; left time: 563.0432s\n",
      "\titers: 200, epoch: 62 | loss: 0.0510816\n",
      "\tspeed: 0.0353s/iter; left time: 299.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0533370 Vali Loss: 0.0546487 Test Loss: 0.0573723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0574854\n",
      "\tspeed: 0.0650s/iter; left time: 544.0078s\n",
      "\titers: 200, epoch: 63 | loss: 0.0529368\n",
      "\tspeed: 0.0351s/iter; left time: 290.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533335 Vali Loss: 0.0545922 Test Loss: 0.0573501\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0557035\n",
      "\tspeed: 0.0655s/iter; left time: 534.1520s\n",
      "\titers: 200, epoch: 64 | loss: 0.0525432\n",
      "\tspeed: 0.0351s/iter; left time: 282.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533528 Vali Loss: 0.0545735 Test Loss: 0.0573364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546455\n",
      "\tspeed: 0.0654s/iter; left time: 518.4721s\n",
      "\titers: 200, epoch: 65 | loss: 0.0553183\n",
      "\tspeed: 0.0353s/iter; left time: 276.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533852 Vali Loss: 0.0546433 Test Loss: 0.0573452\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0561917\n",
      "\tspeed: 0.0655s/iter; left time: 504.8543s\n",
      "\titers: 200, epoch: 66 | loss: 0.0568168\n",
      "\tspeed: 0.0352s/iter; left time: 268.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0533577 Vali Loss: 0.0545441 Test Loss: 0.0573378\n",
      "Validation loss decreased (0.054563 --> 0.054544).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0525508\n",
      "\tspeed: 0.0675s/iter; left time: 505.2784s\n",
      "\titers: 200, epoch: 67 | loss: 0.0557896\n",
      "\tspeed: 0.0351s/iter; left time: 259.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533420 Vali Loss: 0.0545776 Test Loss: 0.0573440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0541739\n",
      "\tspeed: 0.0664s/iter; left time: 481.9078s\n",
      "\titers: 200, epoch: 68 | loss: 0.0537945\n",
      "\tspeed: 0.0351s/iter; left time: 251.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0534072 Vali Loss: 0.0545726 Test Loss: 0.0573432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0530109\n",
      "\tspeed: 0.0647s/iter; left time: 455.3412s\n",
      "\titers: 200, epoch: 69 | loss: 0.0540929\n",
      "\tspeed: 0.0351s/iter; left time: 243.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0533449 Vali Loss: 0.0545826 Test Loss: 0.0573481\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0518707\n",
      "\tspeed: 0.0642s/iter; left time: 437.7741s\n",
      "\titers: 200, epoch: 70 | loss: 0.0542034\n",
      "\tspeed: 0.0351s/iter; left time: 235.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0533946 Vali Loss: 0.0546405 Test Loss: 0.0573622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0554011\n",
      "\tspeed: 0.0645s/iter; left time: 425.0080s\n",
      "\titers: 200, epoch: 71 | loss: 0.0511646\n",
      "\tspeed: 0.0348s/iter; left time: 225.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0533162 Vali Loss: 0.0545336 Test Loss: 0.0573344\n",
      "Validation loss decreased (0.054544 --> 0.054534).  Saving model ...\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0530440\n",
      "\tspeed: 0.0666s/iter; left time: 423.8380s\n",
      "\titers: 200, epoch: 72 | loss: 0.0569498\n",
      "\tspeed: 0.0352s/iter; left time: 220.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533984 Vali Loss: 0.0546323 Test Loss: 0.0573371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0569372\n",
      "\tspeed: 0.0652s/iter; left time: 400.6707s\n",
      "\titers: 200, epoch: 73 | loss: 0.0584623\n",
      "\tspeed: 0.0353s/iter; left time: 213.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533600 Vali Loss: 0.0546291 Test Loss: 0.0573471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0547817\n",
      "\tspeed: 0.0651s/iter; left time: 385.7203s\n",
      "\titers: 200, epoch: 74 | loss: 0.0493505\n",
      "\tspeed: 0.0351s/iter; left time: 204.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533033 Vali Loss: 0.0546224 Test Loss: 0.0573429\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0493547\n",
      "\tspeed: 0.0652s/iter; left time: 371.6734s\n",
      "\titers: 200, epoch: 75 | loss: 0.0555176\n",
      "\tspeed: 0.0351s/iter; left time: 196.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533029 Vali Loss: 0.0546485 Test Loss: 0.0573412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0529091\n",
      "\tspeed: 0.0652s/iter; left time: 356.8269s\n",
      "\titers: 200, epoch: 76 | loss: 0.0509300\n",
      "\tspeed: 0.0351s/iter; left time: 188.5033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0533624 Vali Loss: 0.0545650 Test Loss: 0.0573443\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0607637\n",
      "\tspeed: 0.0649s/iter; left time: 340.9881s\n",
      "\titers: 200, epoch: 77 | loss: 0.0514726\n",
      "\tspeed: 0.0348s/iter; left time: 179.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0534102 Vali Loss: 0.0546305 Test Loss: 0.0573268\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0570907\n",
      "\tspeed: 0.0650s/iter; left time: 327.1195s\n",
      "\titers: 200, epoch: 78 | loss: 0.0551430\n",
      "\tspeed: 0.0348s/iter; left time: 171.3208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0533672 Vali Loss: 0.0546221 Test Loss: 0.0573372\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0489359\n",
      "\tspeed: 0.0640s/iter; left time: 307.8709s\n",
      "\titers: 200, epoch: 79 | loss: 0.0488577\n",
      "\tspeed: 0.0351s/iter; left time: 165.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0533639 Vali Loss: 0.0546596 Test Loss: 0.0573285\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0496042\n",
      "\tspeed: 0.0650s/iter; left time: 298.0569s\n",
      "\titers: 200, epoch: 80 | loss: 0.0566325\n",
      "\tspeed: 0.0352s/iter; left time: 157.9521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533528 Vali Loss: 0.0546019 Test Loss: 0.0573275\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0518748\n",
      "\tspeed: 0.0649s/iter; left time: 282.9662s\n",
      "\titers: 200, epoch: 81 | loss: 0.0521037\n",
      "\tspeed: 0.0351s/iter; left time: 149.5322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0533605 Vali Loss: 0.0546087 Test Loss: 0.0573167\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010125267319381237, rmse:0.10062438994646072, mae:0.05733437091112137, rse:0.3802099823951721\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1236653\n",
      "\tspeed: 0.0376s/iter; left time: 834.0754s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085836\n",
      "\tspeed: 0.0351s/iter; left time: 775.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1340056 Vali Loss: 0.0942551 Test Loss: 0.0959092\n",
      "Validation loss decreased (inf --> 0.094255).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0773130\n",
      "\tspeed: 0.0653s/iter; left time: 1434.5734s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673379\n",
      "\tspeed: 0.0353s/iter; left time: 771.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0760516 Vali Loss: 0.0626796 Test Loss: 0.0656753\n",
      "Validation loss decreased (0.094255 --> 0.062680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0674818\n",
      "\tspeed: 0.0682s/iter; left time: 1484.1721s\n",
      "\titers: 200, epoch: 3 | loss: 0.0624525\n",
      "\tspeed: 0.0353s/iter; left time: 764.3250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0652883 Vali Loss: 0.0601960 Test Loss: 0.0628172\n",
      "Validation loss decreased (0.062680 --> 0.060196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614427\n",
      "\tspeed: 0.0671s/iter; left time: 1445.3883s\n",
      "\titers: 200, epoch: 4 | loss: 0.0611415\n",
      "\tspeed: 0.0350s/iter; left time: 749.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0625278 Vali Loss: 0.0590170 Test Loss: 0.0610467\n",
      "Validation loss decreased (0.060196 --> 0.059017).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621039\n",
      "\tspeed: 0.0661s/iter; left time: 1409.5724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0640478\n",
      "\tspeed: 0.0352s/iter; left time: 746.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0608943 Vali Loss: 0.0580759 Test Loss: 0.0605287\n",
      "Validation loss decreased (0.059017 --> 0.058076).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599137\n",
      "\tspeed: 0.0658s/iter; left time: 1387.6109s\n",
      "\titers: 200, epoch: 6 | loss: 0.0580266\n",
      "\tspeed: 0.0351s/iter; left time: 735.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0598067 Vali Loss: 0.0580089 Test Loss: 0.0606433\n",
      "Validation loss decreased (0.058076 --> 0.058009).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0658s/iter; left time: 1372.6480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0552828\n",
      "\tspeed: 0.0347s/iter; left time: 719.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0587435 Vali Loss: 0.0578174 Test Loss: 0.0599102\n",
      "Validation loss decreased (0.058009 --> 0.057817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599756\n",
      "\tspeed: 0.0685s/iter; left time: 1414.0659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0566922\n",
      "\tspeed: 0.0351s/iter; left time: 720.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0582020 Vali Loss: 0.0570890 Test Loss: 0.0592180\n",
      "Validation loss decreased (0.057817 --> 0.057089).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0565534\n",
      "\tspeed: 0.0684s/iter; left time: 1397.4800s\n",
      "\titers: 200, epoch: 9 | loss: 0.0553257\n",
      "\tspeed: 0.0513s/iter; left time: 1041.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 223 | Train Loss: 0.0576028 Vali Loss: 0.0568853 Test Loss: 0.0593272\n",
      "Validation loss decreased (0.057089 --> 0.056885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0572889\n",
      "\tspeed: 0.1087s/iter; left time: 2194.5938s\n",
      "\titers: 200, epoch: 10 | loss: 0.0606292\n",
      "\tspeed: 0.0475s/iter; left time: 954.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.99s\n",
      "Steps: 223 | Train Loss: 0.0571892 Vali Loss: 0.0565961 Test Loss: 0.0590728\n",
      "Validation loss decreased (0.056885 --> 0.056596).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582079\n",
      "\tspeed: 0.0726s/iter; left time: 1450.6256s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550425\n",
      "\tspeed: 0.0347s/iter; left time: 689.4622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0567719 Vali Loss: 0.0565161 Test Loss: 0.0591691\n",
      "Validation loss decreased (0.056596 --> 0.056516).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0565605\n",
      "\tspeed: 0.0672s/iter; left time: 1326.7966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558233\n",
      "\tspeed: 0.0427s/iter; left time: 838.2186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 223 | Train Loss: 0.0563979 Vali Loss: 0.0561776 Test Loss: 0.0585629\n",
      "Validation loss decreased (0.056516 --> 0.056178).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540284\n",
      "\tspeed: 0.0687s/iter; left time: 1341.6880s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555557\n",
      "\tspeed: 0.0356s/iter; left time: 691.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0560746 Vali Loss: 0.0561454 Test Loss: 0.0584856\n",
      "Validation loss decreased (0.056178 --> 0.056145).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542161\n",
      "\tspeed: 0.0706s/iter; left time: 1363.3169s\n",
      "\titers: 200, epoch: 14 | loss: 0.0567283\n",
      "\tspeed: 0.0349s/iter; left time: 670.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0558765 Vali Loss: 0.0556245 Test Loss: 0.0582671\n",
      "Validation loss decreased (0.056145 --> 0.055624).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0516504\n",
      "\tspeed: 0.0770s/iter; left time: 1468.6501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539961\n",
      "\tspeed: 0.0351s/iter; left time: 665.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0555634 Vali Loss: 0.0556393 Test Loss: 0.0580658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541912\n",
      "\tspeed: 0.0656s/iter; left time: 1236.3415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0579656\n",
      "\tspeed: 0.0348s/iter; left time: 651.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0554230 Vali Loss: 0.0556770 Test Loss: 0.0582363\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0512342\n",
      "\tspeed: 0.0647s/iter; left time: 1206.3463s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564994\n",
      "\tspeed: 0.0347s/iter; left time: 642.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0551551 Vali Loss: 0.0556197 Test Loss: 0.0580029\n",
      "Validation loss decreased (0.055624 --> 0.055620).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0525832\n",
      "\tspeed: 0.0646s/iter; left time: 1188.7275s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526098\n",
      "\tspeed: 0.0347s/iter; left time: 634.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0549796 Vali Loss: 0.0554065 Test Loss: 0.0579263\n",
      "Validation loss decreased (0.055620 --> 0.055407).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0523012\n",
      "\tspeed: 0.0648s/iter; left time: 1178.7482s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539355\n",
      "\tspeed: 0.0347s/iter; left time: 627.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0548759 Vali Loss: 0.0553395 Test Loss: 0.0578735\n",
      "Validation loss decreased (0.055407 --> 0.055340).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545199\n",
      "\tspeed: 0.0663s/iter; left time: 1191.7170s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550749\n",
      "\tspeed: 0.0347s/iter; left time: 620.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0546577 Vali Loss: 0.0552465 Test Loss: 0.0578412\n",
      "Validation loss decreased (0.055340 --> 0.055246).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0550329\n",
      "\tspeed: 0.0666s/iter; left time: 1181.2350s\n",
      "\titers: 200, epoch: 21 | loss: 0.0578060\n",
      "\tspeed: 0.0353s/iter; left time: 622.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0545746 Vali Loss: 0.0553627 Test Loss: 0.0578596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0537746\n",
      "\tspeed: 0.0686s/iter; left time: 1202.3220s\n",
      "\titers: 200, epoch: 22 | loss: 0.0538387\n",
      "\tspeed: 0.0360s/iter; left time: 627.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0545020 Vali Loss: 0.0551188 Test Loss: 0.0577297\n",
      "Validation loss decreased (0.055246 --> 0.055119).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0544303\n",
      "\tspeed: 0.1279s/iter; left time: 2211.8278s\n",
      "\titers: 200, epoch: 23 | loss: 0.0528518\n",
      "\tspeed: 0.0740s/iter; left time: 1271.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.95s\n",
      "Steps: 223 | Train Loss: 0.0543437 Vali Loss: 0.0548906 Test Loss: 0.0576726\n",
      "Validation loss decreased (0.055119 --> 0.054891).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0523297\n",
      "\tspeed: 0.1661s/iter; left time: 2835.7849s\n",
      "\titers: 200, epoch: 24 | loss: 0.0491816\n",
      "\tspeed: 0.0741s/iter; left time: 1257.3326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:16.93s\n",
      "Steps: 223 | Train Loss: 0.0542616 Vali Loss: 0.0550434 Test Loss: 0.0577392\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573380\n",
      "\tspeed: 0.1635s/iter; left time: 2755.0971s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550361\n",
      "\tspeed: 0.0731s/iter; left time: 1224.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:16.70s\n",
      "Steps: 223 | Train Loss: 0.0541424 Vali Loss: 0.0550252 Test Loss: 0.0575210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0571581\n",
      "\tspeed: 0.1663s/iter; left time: 2765.1225s\n",
      "\titers: 200, epoch: 26 | loss: 0.0503851\n",
      "\tspeed: 0.0724s/iter; left time: 1196.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 223 | Train Loss: 0.0541551 Vali Loss: 0.0548709 Test Loss: 0.0574785\n",
      "Validation loss decreased (0.054891 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0507494\n",
      "\tspeed: 0.1703s/iter; left time: 2793.6248s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532626\n",
      "\tspeed: 0.0744s/iter; left time: 1212.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 223 | Train Loss: 0.0539924 Vali Loss: 0.0549234 Test Loss: 0.0575042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0542392\n",
      "\tspeed: 0.1879s/iter; left time: 3039.4868s\n",
      "\titers: 200, epoch: 28 | loss: 0.0539691\n",
      "\tspeed: 0.0783s/iter; left time: 1258.3340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.64s\n",
      "Steps: 223 | Train Loss: 0.0539487 Vali Loss: 0.0548774 Test Loss: 0.0575267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0521044\n",
      "\tspeed: 0.3136s/iter; left time: 5004.0189s\n",
      "\titers: 200, epoch: 29 | loss: 0.0509934\n",
      "\tspeed: 0.1754s/iter; left time: 2781.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:42.57s\n",
      "Steps: 223 | Train Loss: 0.0539058 Vali Loss: 0.0548742 Test Loss: 0.0573750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0580714\n",
      "\tspeed: 0.2264s/iter; left time: 3561.8815s\n",
      "\titers: 200, epoch: 30 | loss: 0.0515862\n",
      "\tspeed: 0.0814s/iter; left time: 1273.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.93s\n",
      "Steps: 223 | Train Loss: 0.0539120 Vali Loss: 0.0547454 Test Loss: 0.0574369\n",
      "Validation loss decreased (0.054871 --> 0.054745).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0573174\n",
      "\tspeed: 0.1904s/iter; left time: 2953.3819s\n",
      "\titers: 200, epoch: 31 | loss: 0.0589227\n",
      "\tspeed: 0.0822s/iter; left time: 1266.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.89s\n",
      "Steps: 223 | Train Loss: 0.0538397 Vali Loss: 0.0547085 Test Loss: 0.0573836\n",
      "Validation loss decreased (0.054745 --> 0.054708).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0572007\n",
      "\tspeed: 0.1876s/iter; left time: 2867.8048s\n",
      "\titers: 200, epoch: 32 | loss: 0.0529349\n",
      "\tspeed: 0.0807s/iter; left time: 1225.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.60s\n",
      "Steps: 223 | Train Loss: 0.0537666 Vali Loss: 0.0548522 Test Loss: 0.0574574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0535290\n",
      "\tspeed: 0.2115s/iter; left time: 3185.5163s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521026\n",
      "\tspeed: 0.1249s/iter; left time: 1869.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.58s\n",
      "Steps: 223 | Train Loss: 0.0538062 Vali Loss: 0.0548358 Test Loss: 0.0574031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0542147\n",
      "\tspeed: 0.2777s/iter; left time: 4121.8149s\n",
      "\titers: 200, epoch: 34 | loss: 0.0529351\n",
      "\tspeed: 0.1283s/iter; left time: 1891.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:28.99s\n",
      "Steps: 223 | Train Loss: 0.0536756 Vali Loss: 0.0547746 Test Loss: 0.0574166\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0524224\n",
      "\tspeed: 0.3269s/iter; left time: 4779.3293s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521868\n",
      "\tspeed: 0.1556s/iter; left time: 2258.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:34.61s\n",
      "Steps: 223 | Train Loss: 0.0537168 Vali Loss: 0.0546867 Test Loss: 0.0573712\n",
      "Validation loss decreased (0.054708 --> 0.054687).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0547390\n",
      "\tspeed: 0.3498s/iter; left time: 5035.1722s\n",
      "\titers: 200, epoch: 36 | loss: 0.0513252\n",
      "\tspeed: 0.1773s/iter; left time: 2534.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 223 | Train Loss: 0.0536649 Vali Loss: 0.0548329 Test Loss: 0.0573338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0526233\n",
      "\tspeed: 0.4131s/iter; left time: 5855.0527s\n",
      "\titers: 200, epoch: 37 | loss: 0.0532994\n",
      "\tspeed: 0.1768s/iter; left time: 2488.2374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 223 | Train Loss: 0.0536699 Vali Loss: 0.0547430 Test Loss: 0.0573483\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0552216\n",
      "\tspeed: 0.4277s/iter; left time: 5966.7552s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542184\n",
      "\tspeed: 0.1920s/iter; left time: 2659.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:42.05s\n",
      "Steps: 223 | Train Loss: 0.0536600 Vali Loss: 0.0546434 Test Loss: 0.0573275\n",
      "Validation loss decreased (0.054687 --> 0.054643).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0544269\n",
      "\tspeed: 0.4247s/iter; left time: 5829.1753s\n",
      "\titers: 200, epoch: 39 | loss: 0.0550644\n",
      "\tspeed: 0.2114s/iter; left time: 2880.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 223 | Train Loss: 0.0536410 Vali Loss: 0.0547653 Test Loss: 0.0573865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0523039\n",
      "\tspeed: 0.4798s/iter; left time: 6478.7783s\n",
      "\titers: 200, epoch: 40 | loss: 0.0555325\n",
      "\tspeed: 0.2019s/iter; left time: 2706.1862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 223 | Train Loss: 0.0535535 Vali Loss: 0.0547170 Test Loss: 0.0573768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0485696\n",
      "\tspeed: 0.4853s/iter; left time: 6445.8641s\n",
      "\titers: 200, epoch: 41 | loss: 0.0521793\n",
      "\tspeed: 0.1909s/iter; left time: 2515.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:47.15s\n",
      "Steps: 223 | Train Loss: 0.0535917 Vali Loss: 0.0547144 Test Loss: 0.0573494\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0557823\n",
      "\tspeed: 0.4580s/iter; left time: 5981.1233s\n",
      "\titers: 200, epoch: 42 | loss: 0.0514218\n",
      "\tspeed: 0.2059s/iter; left time: 2667.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:45.00s\n",
      "Steps: 223 | Train Loss: 0.0535651 Vali Loss: 0.0547100 Test Loss: 0.0573217\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536297\n",
      "\tspeed: 0.4410s/iter; left time: 5660.0517s\n",
      "\titers: 200, epoch: 43 | loss: 0.0508653\n",
      "\tspeed: 0.1746s/iter; left time: 2223.6951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 223 | Train Loss: 0.0535408 Vali Loss: 0.0545471 Test Loss: 0.0573033\n",
      "Validation loss decreased (0.054643 --> 0.054547).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537778\n",
      "\tspeed: 0.4515s/iter; left time: 5693.6991s\n",
      "\titers: 200, epoch: 44 | loss: 0.0539068\n",
      "\tspeed: 0.1859s/iter; left time: 2325.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 223 | Train Loss: 0.0535216 Vali Loss: 0.0546545 Test Loss: 0.0572622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0526309\n",
      "\tspeed: 0.4266s/iter; left time: 5285.0607s\n",
      "\titers: 200, epoch: 45 | loss: 0.0578126\n",
      "\tspeed: 0.1870s/iter; left time: 2298.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:44.35s\n",
      "Steps: 223 | Train Loss: 0.0534860 Vali Loss: 0.0545956 Test Loss: 0.0573146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0516833\n",
      "\tspeed: 0.4951s/iter; left time: 6023.1268s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523372\n",
      "\tspeed: 0.2050s/iter; left time: 2473.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:47.70s\n",
      "Steps: 223 | Train Loss: 0.0535217 Vali Loss: 0.0546559 Test Loss: 0.0573144\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530197\n",
      "\tspeed: 0.4584s/iter; left time: 5474.1490s\n",
      "\titers: 200, epoch: 47 | loss: 0.0499367\n",
      "\tspeed: 0.2057s/iter; left time: 2436.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 223 | Train Loss: 0.0534722 Vali Loss: 0.0547245 Test Loss: 0.0573141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0524021\n",
      "\tspeed: 0.4370s/iter; left time: 5121.5473s\n",
      "\titers: 200, epoch: 48 | loss: 0.0547925\n",
      "\tspeed: 0.2086s/iter; left time: 2423.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:45.47s\n",
      "Steps: 223 | Train Loss: 0.0535118 Vali Loss: 0.0547139 Test Loss: 0.0573085\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0580956\n",
      "\tspeed: 0.4509s/iter; left time: 5184.5046s\n",
      "\titers: 200, epoch: 49 | loss: 0.0481888\n",
      "\tspeed: 0.2091s/iter; left time: 2382.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 223 | Train Loss: 0.0534437 Vali Loss: 0.0546712 Test Loss: 0.0573046\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0534444\n",
      "\tspeed: 0.3882s/iter; left time: 4376.7753s\n",
      "\titers: 200, epoch: 50 | loss: 0.0551254\n",
      "\tspeed: 0.1342s/iter; left time: 1499.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:32.72s\n",
      "Steps: 223 | Train Loss: 0.0535029 Vali Loss: 0.0545804 Test Loss: 0.0572849\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0532080\n",
      "\tspeed: 0.2621s/iter; left time: 2896.1256s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547003\n",
      "\tspeed: 0.0959s/iter; left time: 1050.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:23.39s\n",
      "Steps: 223 | Train Loss: 0.0535040 Vali Loss: 0.0546792 Test Loss: 0.0572739\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0539353\n",
      "\tspeed: 0.2211s/iter; left time: 2394.0653s\n",
      "\titers: 200, epoch: 52 | loss: 0.0537760\n",
      "\tspeed: 0.0919s/iter; left time: 986.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:21.63s\n",
      "Steps: 223 | Train Loss: 0.0534933 Vali Loss: 0.0546623 Test Loss: 0.0572583\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0524189\n",
      "\tspeed: 0.2059s/iter; left time: 2183.1426s\n",
      "\titers: 200, epoch: 53 | loss: 0.0573189\n",
      "\tspeed: 0.0870s/iter; left time: 913.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:19.95s\n",
      "Steps: 223 | Train Loss: 0.0534749 Vali Loss: 0.0546200 Test Loss: 0.0572883\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010080976411700249, rmse:0.10040406882762909, mae:0.057303305715322495, rse:0.3793775141239166\n",
      "Intermediate time for IT and pred_len 24: 00h:41m:49.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1311399\n",
      "\tspeed: 0.1691s/iter; left time: 3738.3040s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141715\n",
      "\tspeed: 0.1285s/iter; left time: 2827.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 222 | Train Loss: 0.1386955 Vali Loss: 0.1032611 Test Loss: 0.1052448\n",
      "Validation loss decreased (inf --> 0.103261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0856372\n",
      "\tspeed: 0.3564s/iter; left time: 7798.5274s\n",
      "\titers: 200, epoch: 2 | loss: 0.0825728\n",
      "\tspeed: 0.1042s/iter; left time: 2269.2966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.83s\n",
      "Steps: 222 | Train Loss: 0.0933017 Vali Loss: 0.0821070 Test Loss: 0.0853990\n",
      "Validation loss decreased (0.103261 --> 0.082107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840829\n",
      "\tspeed: 0.3542s/iter; left time: 7671.4029s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774338\n",
      "\tspeed: 0.0991s/iter; left time: 2136.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.08s\n",
      "Steps: 222 | Train Loss: 0.0836652 Vali Loss: 0.0801823 Test Loss: 0.0839848\n",
      "Validation loss decreased (0.082107 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0777906\n",
      "\tspeed: 0.3823s/iter; left time: 8194.1118s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808969\n",
      "\tspeed: 0.1163s/iter; left time: 2482.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.82s\n",
      "Steps: 222 | Train Loss: 0.0810691 Vali Loss: 0.0786099 Test Loss: 0.0832172\n",
      "Validation loss decreased (0.080182 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0820504\n",
      "\tspeed: 0.3402s/iter; left time: 7217.5537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0778563\n",
      "\tspeed: 0.1159s/iter; left time: 2446.4149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.97s\n",
      "Steps: 222 | Train Loss: 0.0794057 Vali Loss: 0.0787720 Test Loss: 0.0831368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778250\n",
      "\tspeed: 0.3327s/iter; left time: 6983.2994s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792012\n",
      "\tspeed: 0.1144s/iter; left time: 2390.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.02s\n",
      "Steps: 222 | Train Loss: 0.0783560 Vali Loss: 0.0787365 Test Loss: 0.0827528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0766344\n",
      "\tspeed: 0.3451s/iter; left time: 7168.1667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771671\n",
      "\tspeed: 0.1036s/iter; left time: 2140.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.0773313 Vali Loss: 0.0777745 Test Loss: 0.0821120\n",
      "Validation loss decreased (0.078610 --> 0.077775).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767398\n",
      "\tspeed: 0.3375s/iter; left time: 6935.1741s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759662\n",
      "\tspeed: 0.1116s/iter; left time: 2281.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 222 | Train Loss: 0.0764446 Vali Loss: 0.0786228 Test Loss: 0.0820677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730551\n",
      "\tspeed: 0.3426s/iter; left time: 6963.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0752378\n",
      "\tspeed: 0.1105s/iter; left time: 2234.0419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.50s\n",
      "Steps: 222 | Train Loss: 0.0758786 Vali Loss: 0.0777612 Test Loss: 0.0823828\n",
      "Validation loss decreased (0.077775 --> 0.077761).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0798666\n",
      "\tspeed: 0.3382s/iter; left time: 6799.1711s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749843\n",
      "\tspeed: 0.1098s/iter; left time: 2195.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.35s\n",
      "Steps: 222 | Train Loss: 0.0752808 Vali Loss: 0.0778954 Test Loss: 0.0823552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764299\n",
      "\tspeed: 0.3560s/iter; left time: 7076.8356s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740857\n",
      "\tspeed: 0.1054s/iter; left time: 2084.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:24.96s\n",
      "Steps: 222 | Train Loss: 0.0748124 Vali Loss: 0.0778898 Test Loss: 0.0825079\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0724045\n",
      "\tspeed: 0.3405s/iter; left time: 6694.3039s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746246\n",
      "\tspeed: 0.1063s/iter; left time: 2078.9870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.41s\n",
      "Steps: 222 | Train Loss: 0.0744042 Vali Loss: 0.0778334 Test Loss: 0.0823106\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0746598\n",
      "\tspeed: 0.3462s/iter; left time: 6729.1110s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782185\n",
      "\tspeed: 0.1074s/iter; left time: 2076.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 222 | Train Loss: 0.0740403 Vali Loss: 0.0775864 Test Loss: 0.0823642\n",
      "Validation loss decreased (0.077761 --> 0.077586).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0693135\n",
      "\tspeed: 0.3455s/iter; left time: 6638.4685s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716517\n",
      "\tspeed: 0.1053s/iter; left time: 2012.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 222 | Train Loss: 0.0736158 Vali Loss: 0.0778610 Test Loss: 0.0827634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719399\n",
      "\tspeed: 0.3487s/iter; left time: 6622.2708s\n",
      "\titers: 200, epoch: 15 | loss: 0.0678389\n",
      "\tspeed: 0.1075s/iter; left time: 2030.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 222 | Train Loss: 0.0732489 Vali Loss: 0.0777737 Test Loss: 0.0830149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0743510\n",
      "\tspeed: 0.3548s/iter; left time: 6659.0880s\n",
      "\titers: 200, epoch: 16 | loss: 0.0752960\n",
      "\tspeed: 0.1010s/iter; left time: 1886.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 222 | Train Loss: 0.0729326 Vali Loss: 0.0778201 Test Loss: 0.0826653\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0726962\n",
      "\tspeed: 0.3047s/iter; left time: 5651.1722s\n",
      "\titers: 200, epoch: 17 | loss: 0.0722981\n",
      "\tspeed: 0.0992s/iter; left time: 1830.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 222 | Train Loss: 0.0726651 Vali Loss: 0.0779380 Test Loss: 0.0830403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729924\n",
      "\tspeed: 0.3398s/iter; left time: 6227.3028s\n",
      "\titers: 200, epoch: 18 | loss: 0.0750807\n",
      "\tspeed: 0.1095s/iter; left time: 1996.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:26.56s\n",
      "Steps: 222 | Train Loss: 0.0725138 Vali Loss: 0.0775092 Test Loss: 0.0824644\n",
      "Validation loss decreased (0.077586 --> 0.077509).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725602\n",
      "\tspeed: 0.3671s/iter; left time: 6646.6417s\n",
      "\titers: 200, epoch: 19 | loss: 0.0742136\n",
      "\tspeed: 0.1126s/iter; left time: 2026.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.90s\n",
      "Steps: 222 | Train Loss: 0.0722610 Vali Loss: 0.0777993 Test Loss: 0.0827277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709395\n",
      "\tspeed: 0.3372s/iter; left time: 6029.4661s\n",
      "\titers: 200, epoch: 20 | loss: 0.0712768\n",
      "\tspeed: 0.1099s/iter; left time: 1954.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 222 | Train Loss: 0.0720304 Vali Loss: 0.0776217 Test Loss: 0.0830709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749833\n",
      "\tspeed: 0.3386s/iter; left time: 5979.6552s\n",
      "\titers: 200, epoch: 21 | loss: 0.0723694\n",
      "\tspeed: 0.1125s/iter; left time: 1975.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:25.08s\n",
      "Steps: 222 | Train Loss: 0.0718289 Vali Loss: 0.0777689 Test Loss: 0.0829489\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0728807\n",
      "\tspeed: 0.3430s/iter; left time: 5981.2282s\n",
      "\titers: 200, epoch: 22 | loss: 0.0715724\n",
      "\tspeed: 0.1138s/iter; left time: 1972.5922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 222 | Train Loss: 0.0716578 Vali Loss: 0.0775245 Test Loss: 0.0829920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0736327\n",
      "\tspeed: 0.3422s/iter; left time: 5891.1664s\n",
      "\titers: 200, epoch: 23 | loss: 0.0700886\n",
      "\tspeed: 0.1078s/iter; left time: 1845.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:25.05s\n",
      "Steps: 222 | Train Loss: 0.0715372 Vali Loss: 0.0774438 Test Loss: 0.0829975\n",
      "Validation loss decreased (0.077509 --> 0.077444).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0732769\n",
      "\tspeed: 0.3416s/iter; left time: 5806.1703s\n",
      "\titers: 200, epoch: 24 | loss: 0.0709394\n",
      "\tspeed: 0.1102s/iter; left time: 1861.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 222 | Train Loss: 0.0713622 Vali Loss: 0.0777394 Test Loss: 0.0830288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0692430\n",
      "\tspeed: 0.3341s/iter; left time: 5604.0832s\n",
      "\titers: 200, epoch: 25 | loss: 0.0746632\n",
      "\tspeed: 0.1088s/iter; left time: 1813.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 222 | Train Loss: 0.0712769 Vali Loss: 0.0775630 Test Loss: 0.0829923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0727863\n",
      "\tspeed: 0.3352s/iter; left time: 5547.7592s\n",
      "\titers: 200, epoch: 26 | loss: 0.0689155\n",
      "\tspeed: 0.1044s/iter; left time: 1718.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 222 | Train Loss: 0.0711172 Vali Loss: 0.0776434 Test Loss: 0.0832030\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0752033\n",
      "\tspeed: 0.3557s/iter; left time: 5808.5386s\n",
      "\titers: 200, epoch: 27 | loss: 0.0673548\n",
      "\tspeed: 0.1038s/iter; left time: 1683.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:24.32s\n",
      "Steps: 222 | Train Loss: 0.0710334 Vali Loss: 0.0776247 Test Loss: 0.0831966\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734832\n",
      "\tspeed: 0.3505s/iter; left time: 5644.7200s\n",
      "\titers: 200, epoch: 28 | loss: 0.0692218\n",
      "\tspeed: 0.1076s/iter; left time: 1723.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:24.30s\n",
      "Steps: 222 | Train Loss: 0.0709934 Vali Loss: 0.0776521 Test Loss: 0.0830424\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0723570\n",
      "\tspeed: 0.3472s/iter; left time: 5515.3677s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728116\n",
      "\tspeed: 0.1085s/iter; left time: 1712.1444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 222 | Train Loss: 0.0708610 Vali Loss: 0.0775053 Test Loss: 0.0831043\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0713507\n",
      "\tspeed: 0.3366s/iter; left time: 5271.5541s\n",
      "\titers: 200, epoch: 30 | loss: 0.0729116\n",
      "\tspeed: 0.1111s/iter; left time: 1728.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 222 | Train Loss: 0.0708525 Vali Loss: 0.0777053 Test Loss: 0.0831629\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0749389\n",
      "\tspeed: 0.3201s/iter; left time: 4942.7000s\n",
      "\titers: 200, epoch: 31 | loss: 0.0724649\n",
      "\tspeed: 0.0976s/iter; left time: 1496.7263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 222 | Train Loss: 0.0707049 Vali Loss: 0.0778409 Test Loss: 0.0833423\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0705555\n",
      "\tspeed: 0.2971s/iter; left time: 4521.7761s\n",
      "\titers: 200, epoch: 32 | loss: 0.0722894\n",
      "\tspeed: 0.1003s/iter; left time: 1515.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 222 | Train Loss: 0.0705979 Vali Loss: 0.0777341 Test Loss: 0.0832765\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0708174\n",
      "\tspeed: 0.3026s/iter; left time: 4537.4618s\n",
      "\titers: 200, epoch: 33 | loss: 0.0716869\n",
      "\tspeed: 0.0999s/iter; left time: 1487.6257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.27s\n",
      "Steps: 222 | Train Loss: 0.0705853 Vali Loss: 0.0774142 Test Loss: 0.0832275\n",
      "Validation loss decreased (0.077444 --> 0.077414).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687195\n",
      "\tspeed: 0.3042s/iter; left time: 4495.0039s\n",
      "\titers: 200, epoch: 34 | loss: 0.0715097\n",
      "\tspeed: 0.0980s/iter; left time: 1437.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 222 | Train Loss: 0.0705578 Vali Loss: 0.0776007 Test Loss: 0.0832708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0726959\n",
      "\tspeed: 0.2997s/iter; left time: 4361.7562s\n",
      "\titers: 200, epoch: 35 | loss: 0.0734263\n",
      "\tspeed: 0.0991s/iter; left time: 1432.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 222 | Train Loss: 0.0705173 Vali Loss: 0.0776994 Test Loss: 0.0832131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0730397\n",
      "\tspeed: 0.3074s/iter; left time: 4404.8692s\n",
      "\titers: 200, epoch: 36 | loss: 0.0701893\n",
      "\tspeed: 0.0976s/iter; left time: 1389.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 222 | Train Loss: 0.0704305 Vali Loss: 0.0776818 Test Loss: 0.0833117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0684488\n",
      "\tspeed: 0.2998s/iter; left time: 4230.0076s\n",
      "\titers: 200, epoch: 37 | loss: 0.0706373\n",
      "\tspeed: 0.0987s/iter; left time: 1382.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 222 | Train Loss: 0.0704381 Vali Loss: 0.0776246 Test Loss: 0.0833702\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0681006\n",
      "\tspeed: 0.2962s/iter; left time: 4112.8413s\n",
      "\titers: 200, epoch: 38 | loss: 0.0723561\n",
      "\tspeed: 0.0998s/iter; left time: 1376.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 222 | Train Loss: 0.0703652 Vali Loss: 0.0777585 Test Loss: 0.0832768\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0716680\n",
      "\tspeed: 0.2981s/iter; left time: 4073.8396s\n",
      "\titers: 200, epoch: 39 | loss: 0.0727969\n",
      "\tspeed: 0.0982s/iter; left time: 1332.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 222 | Train Loss: 0.0703907 Vali Loss: 0.0776063 Test Loss: 0.0832168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0663224\n",
      "\tspeed: 0.3013s/iter; left time: 4050.4021s\n",
      "\titers: 200, epoch: 40 | loss: 0.0692386\n",
      "\tspeed: 0.0990s/iter; left time: 1320.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:22.61s\n",
      "Steps: 222 | Train Loss: 0.0703427 Vali Loss: 0.0775947 Test Loss: 0.0833248\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0682518\n",
      "\tspeed: 0.2965s/iter; left time: 3919.5222s\n",
      "\titers: 200, epoch: 41 | loss: 0.0704335\n",
      "\tspeed: 0.0948s/iter; left time: 1243.2475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:21.63s\n",
      "Steps: 222 | Train Loss: 0.0702792 Vali Loss: 0.0776268 Test Loss: 0.0833209\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765378\n",
      "\tspeed: 0.2978s/iter; left time: 3871.5576s\n",
      "\titers: 200, epoch: 42 | loss: 0.0654985\n",
      "\tspeed: 0.0942s/iter; left time: 1214.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:21.71s\n",
      "Steps: 222 | Train Loss: 0.0702523 Vali Loss: 0.0776762 Test Loss: 0.0832865\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0718094\n",
      "\tspeed: 0.2963s/iter; left time: 3785.2200s\n",
      "\titers: 200, epoch: 43 | loss: 0.0723811\n",
      "\tspeed: 0.0982s/iter; left time: 1244.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 222 | Train Loss: 0.0702900 Vali Loss: 0.0777120 Test Loss: 0.0833350\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019661061465740204, rmse:0.14021790027618408, mae:0.08322744071483612, rse:0.5301790237426758\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1307814\n",
      "\tspeed: 0.1003s/iter; left time: 2217.2914s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171321\n",
      "\tspeed: 0.0956s/iter; left time: 2103.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.85s\n",
      "Steps: 222 | Train Loss: 0.1395332 Vali Loss: 0.1032470 Test Loss: 0.1049860\n",
      "Validation loss decreased (inf --> 0.103247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916372\n",
      "\tspeed: 0.2953s/iter; left time: 6461.9022s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823959\n",
      "\tspeed: 0.0953s/iter; left time: 2075.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.83s\n",
      "Steps: 222 | Train Loss: 0.0933076 Vali Loss: 0.0824281 Test Loss: 0.0858068\n",
      "Validation loss decreased (0.103247 --> 0.082428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872041\n",
      "\tspeed: 0.2911s/iter; left time: 6304.3783s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788812\n",
      "\tspeed: 0.0976s/iter; left time: 2102.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.08s\n",
      "Steps: 222 | Train Loss: 0.0836500 Vali Loss: 0.0802880 Test Loss: 0.0839654\n",
      "Validation loss decreased (0.082428 --> 0.080288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820672\n",
      "\tspeed: 0.2980s/iter; left time: 6386.7419s\n",
      "\titers: 200, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.0960s/iter; left time: 2047.8672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.85s\n",
      "Steps: 222 | Train Loss: 0.0810862 Vali Loss: 0.0789895 Test Loss: 0.0830211\n",
      "Validation loss decreased (0.080288 --> 0.078989).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760076\n",
      "\tspeed: 0.2990s/iter; left time: 6343.6648s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797620\n",
      "\tspeed: 0.0976s/iter; left time: 2060.0964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 222 | Train Loss: 0.0795027 Vali Loss: 0.0782971 Test Loss: 0.0827075\n",
      "Validation loss decreased (0.078989 --> 0.078297).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0779532\n",
      "\tspeed: 0.2913s/iter; left time: 6114.8252s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816109\n",
      "\tspeed: 0.0953s/iter; left time: 1991.4572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.93s\n",
      "Steps: 222 | Train Loss: 0.0784048 Vali Loss: 0.0775458 Test Loss: 0.0820731\n",
      "Validation loss decreased (0.078297 --> 0.077546).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748276\n",
      "\tspeed: 0.2925s/iter; left time: 6075.6091s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819100\n",
      "\tspeed: 0.0936s/iter; left time: 1934.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.68s\n",
      "Steps: 222 | Train Loss: 0.0774822 Vali Loss: 0.0781644 Test Loss: 0.0823445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749587\n",
      "\tspeed: 0.2956s/iter; left time: 6073.0907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749932\n",
      "\tspeed: 0.0982s/iter; left time: 2007.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 222 | Train Loss: 0.0766891 Vali Loss: 0.0772725 Test Loss: 0.0819850\n",
      "Validation loss decreased (0.077546 --> 0.077272).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0743355\n",
      "\tspeed: 0.2922s/iter; left time: 5938.0465s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758577\n",
      "\tspeed: 0.0967s/iter; left time: 1955.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.03s\n",
      "Steps: 222 | Train Loss: 0.0760432 Vali Loss: 0.0781481 Test Loss: 0.0822719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0754635\n",
      "\tspeed: 0.2888s/iter; left time: 5805.8640s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753185\n",
      "\tspeed: 0.0995s/iter; left time: 1990.9896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 222 | Train Loss: 0.0755703 Vali Loss: 0.0779481 Test Loss: 0.0822187\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784725\n",
      "\tspeed: 0.2976s/iter; left time: 5915.8656s\n",
      "\titers: 200, epoch: 11 | loss: 0.0744855\n",
      "\tspeed: 0.0964s/iter; left time: 1907.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.03s\n",
      "Steps: 222 | Train Loss: 0.0750095 Vali Loss: 0.0778305 Test Loss: 0.0819077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705007\n",
      "\tspeed: 0.2777s/iter; left time: 5459.0270s\n",
      "\titers: 200, epoch: 12 | loss: 0.0720747\n",
      "\tspeed: 0.0974s/iter; left time: 1904.9933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.06s\n",
      "Steps: 222 | Train Loss: 0.0745374 Vali Loss: 0.0780981 Test Loss: 0.0819330\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698386\n",
      "\tspeed: 0.2974s/iter; left time: 5780.9542s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727388\n",
      "\tspeed: 0.0962s/iter; left time: 1860.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 222 | Train Loss: 0.0741739 Vali Loss: 0.0778864 Test Loss: 0.0820878\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0789689\n",
      "\tspeed: 0.2803s/iter; left time: 5386.2076s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682087\n",
      "\tspeed: 0.0977s/iter; left time: 1867.6835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 222 | Train Loss: 0.0737458 Vali Loss: 0.0776178 Test Loss: 0.0820219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734283\n",
      "\tspeed: 0.2920s/iter; left time: 5545.9914s\n",
      "\titers: 200, epoch: 15 | loss: 0.0718359\n",
      "\tspeed: 0.0999s/iter; left time: 1887.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 222 | Train Loss: 0.0733381 Vali Loss: 0.0776815 Test Loss: 0.0821751\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0711537\n",
      "\tspeed: 0.2979s/iter; left time: 5592.2039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0715080\n",
      "\tspeed: 0.1002s/iter; left time: 1870.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 222 | Train Loss: 0.0731208 Vali Loss: 0.0775902 Test Loss: 0.0822790\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744190\n",
      "\tspeed: 0.2809s/iter; left time: 5210.4807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702729\n",
      "\tspeed: 0.0994s/iter; left time: 1834.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 222 | Train Loss: 0.0727643 Vali Loss: 0.0776203 Test Loss: 0.0821167\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710593\n",
      "\tspeed: 0.2910s/iter; left time: 5332.4292s\n",
      "\titers: 200, epoch: 18 | loss: 0.0704435\n",
      "\tspeed: 0.0999s/iter; left time: 1820.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 222 | Train Loss: 0.0725734 Vali Loss: 0.0780306 Test Loss: 0.0821137\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01830422878265381, rmse:0.1352931261062622, mae:0.08198496699333191, rse:0.5115578770637512\n",
      "Intermediate time for IT and pred_len 96: 00h:43m:23.82s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1295985\n",
      "\tspeed: 0.1465s/iter; left time: 3237.6315s\n",
      "\titers: 200, epoch: 1 | loss: 0.1180896\n",
      "\tspeed: 0.0983s/iter; left time: 2162.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 222 | Train Loss: 0.1401323 Vali Loss: 0.1051054 Test Loss: 0.1060525\n",
      "Validation loss decreased (inf --> 0.105105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924811\n",
      "\tspeed: 0.3124s/iter; left time: 6835.2263s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879458\n",
      "\tspeed: 0.1004s/iter; left time: 2186.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 222 | Train Loss: 0.0966438 Vali Loss: 0.0867667 Test Loss: 0.0893334\n",
      "Validation loss decreased (0.105105 --> 0.086767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903072\n",
      "\tspeed: 0.3075s/iter; left time: 6659.6450s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883525\n",
      "\tspeed: 0.1024s/iter; left time: 2206.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 222 | Train Loss: 0.0874388 Vali Loss: 0.0843132 Test Loss: 0.0879837\n",
      "Validation loss decreased (0.086767 --> 0.084313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0860730\n",
      "\tspeed: 0.3110s/iter; left time: 6666.9633s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831108\n",
      "\tspeed: 0.1014s/iter; left time: 2162.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 222 | Train Loss: 0.0847376 Vali Loss: 0.0837539 Test Loss: 0.0880465\n",
      "Validation loss decreased (0.084313 --> 0.083754).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0837407\n",
      "\tspeed: 0.3030s/iter; left time: 6427.6945s\n",
      "\titers: 200, epoch: 5 | loss: 0.0845941\n",
      "\tspeed: 0.0998s/iter; left time: 2106.0811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 222 | Train Loss: 0.0829249 Vali Loss: 0.0836297 Test Loss: 0.0880610\n",
      "Validation loss decreased (0.083754 --> 0.083630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783244\n",
      "\tspeed: 0.3130s/iter; left time: 6569.6838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0828781\n",
      "\tspeed: 0.1010s/iter; left time: 2109.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:23.23s\n",
      "Steps: 222 | Train Loss: 0.0816438 Vali Loss: 0.0839534 Test Loss: 0.0884101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834960\n",
      "\tspeed: 0.3080s/iter; left time: 6397.0898s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834978\n",
      "\tspeed: 0.1022s/iter; left time: 2113.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 222 | Train Loss: 0.0806016 Vali Loss: 0.0844958 Test Loss: 0.0885445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0818839\n",
      "\tspeed: 0.3093s/iter; left time: 6354.7046s\n",
      "\titers: 200, epoch: 8 | loss: 0.0781465\n",
      "\tspeed: 0.1028s/iter; left time: 2101.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:23.02s\n",
      "Steps: 222 | Train Loss: 0.0798453 Vali Loss: 0.0841923 Test Loss: 0.0884497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763105\n",
      "\tspeed: 0.3110s/iter; left time: 6320.6427s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815194\n",
      "\tspeed: 0.1017s/iter; left time: 2057.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.26s\n",
      "Steps: 222 | Train Loss: 0.0790506 Vali Loss: 0.0838278 Test Loss: 0.0882513\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0768552\n",
      "\tspeed: 0.3190s/iter; left time: 6412.4627s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751613\n",
      "\tspeed: 0.1010s/iter; left time: 2020.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:23.15s\n",
      "Steps: 222 | Train Loss: 0.0785731 Vali Loss: 0.0852505 Test Loss: 0.0894450\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779051\n",
      "\tspeed: 0.3096s/iter; left time: 6156.0761s\n",
      "\titers: 200, epoch: 11 | loss: 0.0783429\n",
      "\tspeed: 0.1012s/iter; left time: 2002.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 222 | Train Loss: 0.0779830 Vali Loss: 0.0841723 Test Loss: 0.0893404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0793392\n",
      "\tspeed: 0.3183s/iter; left time: 6256.6462s\n",
      "\titers: 200, epoch: 12 | loss: 0.0783407\n",
      "\tspeed: 0.1063s/iter; left time: 2079.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:23.95s\n",
      "Steps: 222 | Train Loss: 0.0775615 Vali Loss: 0.0845753 Test Loss: 0.0896497\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0717627\n",
      "\tspeed: 0.3200s/iter; left time: 6220.8047s\n",
      "\titers: 200, epoch: 13 | loss: 0.0760427\n",
      "\tspeed: 0.1052s/iter; left time: 2035.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.00s\n",
      "Steps: 222 | Train Loss: 0.0771428 Vali Loss: 0.0849008 Test Loss: 0.0896374\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738550\n",
      "\tspeed: 0.3131s/iter; left time: 6015.4938s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723396\n",
      "\tspeed: 0.1023s/iter; left time: 1955.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.37s\n",
      "Steps: 222 | Train Loss: 0.0767282 Vali Loss: 0.0847574 Test Loss: 0.0897097\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0740597\n",
      "\tspeed: 0.3176s/iter; left time: 6031.7120s\n",
      "\titers: 200, epoch: 15 | loss: 0.0726431\n",
      "\tspeed: 0.1038s/iter; left time: 1960.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.49s\n",
      "Steps: 222 | Train Loss: 0.0763989 Vali Loss: 0.0849585 Test Loss: 0.0900345\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01999608241021633, rmse:0.14140750467777252, mae:0.08806101232767105, rse:0.5351738333702087\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1304552\n",
      "\tspeed: 0.1111s/iter; left time: 2456.3137s\n",
      "\titers: 200, epoch: 1 | loss: 0.1230357\n",
      "\tspeed: 0.1008s/iter; left time: 2216.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.68s\n",
      "Steps: 222 | Train Loss: 0.1400045 Vali Loss: 0.1050060 Test Loss: 0.1058844\n",
      "Validation loss decreased (inf --> 0.105006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0944798\n",
      "\tspeed: 0.3307s/iter; left time: 7234.8804s\n",
      "\titers: 200, epoch: 2 | loss: 0.0940326\n",
      "\tspeed: 0.1042s/iter; left time: 2269.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.80s\n",
      "Steps: 222 | Train Loss: 0.0967777 Vali Loss: 0.0866084 Test Loss: 0.0891818\n",
      "Validation loss decreased (0.105006 --> 0.086608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894913\n",
      "\tspeed: 0.3224s/iter; left time: 6982.8506s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858088\n",
      "\tspeed: 0.1092s/iter; left time: 2353.6217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.36s\n",
      "Steps: 222 | Train Loss: 0.0879031 Vali Loss: 0.0848397 Test Loss: 0.0882691\n",
      "Validation loss decreased (0.086608 --> 0.084840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866619\n",
      "\tspeed: 0.3221s/iter; left time: 6903.3660s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828001\n",
      "\tspeed: 0.1054s/iter; left time: 2248.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.07s\n",
      "Steps: 222 | Train Loss: 0.0851090 Vali Loss: 0.0837484 Test Loss: 0.0878012\n",
      "Validation loss decreased (0.084840 --> 0.083748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861621\n",
      "\tspeed: 0.3200s/iter; left time: 6788.4171s\n",
      "\titers: 200, epoch: 5 | loss: 0.0821062\n",
      "\tspeed: 0.1052s/iter; left time: 2220.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.0834075 Vali Loss: 0.0829306 Test Loss: 0.0874454\n",
      "Validation loss decreased (0.083748 --> 0.082931).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808549\n",
      "\tspeed: 0.3190s/iter; left time: 6697.1051s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820382\n",
      "\tspeed: 0.1059s/iter; left time: 2213.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:23.85s\n",
      "Steps: 222 | Train Loss: 0.0819533 Vali Loss: 0.0829529 Test Loss: 0.0878453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0796450\n",
      "\tspeed: 0.3250s/iter; left time: 6749.3430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832715\n",
      "\tspeed: 0.1009s/iter; left time: 2085.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.29s\n",
      "Steps: 222 | Train Loss: 0.0809442 Vali Loss: 0.0825301 Test Loss: 0.0880153\n",
      "Validation loss decreased (0.082931 --> 0.082530).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775254\n",
      "\tspeed: 0.3193s/iter; left time: 6560.8919s\n",
      "\titers: 200, epoch: 8 | loss: 0.0788324\n",
      "\tspeed: 0.1018s/iter; left time: 2081.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:23.35s\n",
      "Steps: 222 | Train Loss: 0.0800502 Vali Loss: 0.0832425 Test Loss: 0.0887176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806981\n",
      "\tspeed: 0.3034s/iter; left time: 6167.0507s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805786\n",
      "\tspeed: 0.1017s/iter; left time: 2056.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.17s\n",
      "Steps: 222 | Train Loss: 0.0792796 Vali Loss: 0.0830872 Test Loss: 0.0887377\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775588\n",
      "\tspeed: 0.3140s/iter; left time: 6313.2120s\n",
      "\titers: 200, epoch: 10 | loss: 0.0809518\n",
      "\tspeed: 0.1087s/iter; left time: 2174.7747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.03s\n",
      "Steps: 222 | Train Loss: 0.0786215 Vali Loss: 0.0832103 Test Loss: 0.0886014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0769939\n",
      "\tspeed: 0.3092s/iter; left time: 6147.3395s\n",
      "\titers: 200, epoch: 11 | loss: 0.0785858\n",
      "\tspeed: 0.1026s/iter; left time: 2029.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.44s\n",
      "Steps: 222 | Train Loss: 0.0780797 Vali Loss: 0.0831849 Test Loss: 0.0888413\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0780162\n",
      "\tspeed: 0.3202s/iter; left time: 6294.6527s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788598\n",
      "\tspeed: 0.1017s/iter; left time: 1989.9683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:23.42s\n",
      "Steps: 222 | Train Loss: 0.0775825 Vali Loss: 0.0833615 Test Loss: 0.0889409\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782921\n",
      "\tspeed: 0.3117s/iter; left time: 6058.5961s\n",
      "\titers: 200, epoch: 13 | loss: 0.0769778\n",
      "\tspeed: 0.1051s/iter; left time: 2033.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:23.88s\n",
      "Steps: 222 | Train Loss: 0.0772040 Vali Loss: 0.0830693 Test Loss: 0.0891442\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791389\n",
      "\tspeed: 0.3194s/iter; left time: 6136.8757s\n",
      "\titers: 200, epoch: 14 | loss: 0.0789384\n",
      "\tspeed: 0.1032s/iter; left time: 1973.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.63s\n",
      "Steps: 222 | Train Loss: 0.0767473 Vali Loss: 0.0832471 Test Loss: 0.0888520\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770241\n",
      "\tspeed: 0.3009s/iter; left time: 5715.4488s\n",
      "\titers: 200, epoch: 15 | loss: 0.0787771\n",
      "\tspeed: 0.1036s/iter; left time: 1957.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.66s\n",
      "Steps: 222 | Train Loss: 0.0764810 Vali Loss: 0.0833797 Test Loss: 0.0892758\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0778514\n",
      "\tspeed: 0.3028s/iter; left time: 5684.6335s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740805\n",
      "\tspeed: 0.1048s/iter; left time: 1955.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:23.80s\n",
      "Steps: 222 | Train Loss: 0.0761760 Vali Loss: 0.0830844 Test Loss: 0.0889327\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792995\n",
      "\tspeed: 0.3109s/iter; left time: 5765.9951s\n",
      "\titers: 200, epoch: 17 | loss: 0.0781442\n",
      "\tspeed: 0.1039s/iter; left time: 1917.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:23.78s\n",
      "Steps: 222 | Train Loss: 0.0758439 Vali Loss: 0.0834271 Test Loss: 0.0892882\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02077891305088997, rmse:0.14414893090724945, mae:0.08801530301570892, rse:0.5455491542816162\n",
      "Intermediate time for IT and pred_len 168: 00h:22m:46.48s\n",
      "Intermediate time for IT: 01h:47m:59.37s\n",
      "Total time: 04h:33m:27.02s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.0989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1449  0.0880\n",
       "        96            0.0359  0.1895  0.1251\n",
       "        168           0.0386  0.1964  0.1327\n",
       "ES      24            0.0099  0.0993  0.0598\n",
       "        96            0.0189  0.1376  0.0878\n",
       "        168           0.0213  0.1460  0.0946\n",
       "FR      24            0.0100  0.1002  0.0553\n",
       "        96            0.0197  0.1404  0.0808\n",
       "        168           0.0221  0.1487  0.0882\n",
       "GB      24            0.0246  0.1567  0.0989\n",
       "        96            0.0411  0.2026  0.1388\n",
       "        168           0.0434  0.2084  0.1449\n",
       "IT      24            0.0101  0.1005  0.0573\n",
       "        96            0.0190  0.1378  0.0826\n",
       "        168           0.0204  0.1428  0.0880"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
