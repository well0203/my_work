{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 336](#3-patchtst-336)\n",
    "- [4. PatchTST 512](#4-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with seq_len = 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2157750\n",
      "\tspeed: 0.0573s/iter; left time: 1032.1750s\n",
      "\titers: 200, epoch: 1 | loss: 0.1963026\n",
      "\tspeed: 0.0345s/iter; left time: 618.3465s\n",
      "\titers: 300, epoch: 1 | loss: 0.1900428\n",
      "\tspeed: 0.0346s/iter; left time: 616.3469s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759242\n",
      "\tspeed: 0.0346s/iter; left time: 612.6584s\n",
      "\titers: 500, epoch: 1 | loss: 0.1711153\n",
      "\tspeed: 0.0346s/iter; left time: 609.0709s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630517\n",
      "\tspeed: 0.0346s/iter; left time: 605.7895s\n",
      "\titers: 700, epoch: 1 | loss: 0.1811213\n",
      "\tspeed: 0.0346s/iter; left time: 602.2036s\n",
      "\titers: 800, epoch: 1 | loss: 0.1556394\n",
      "\tspeed: 0.0346s/iter; left time: 598.6039s\n",
      "\titers: 900, epoch: 1 | loss: 0.1458707\n",
      "\tspeed: 0.0346s/iter; left time: 595.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.96s\n",
      "Steps: 906 | Train Loss: 0.1844934 Vali Loss: 0.1649067 Test Loss: 0.1739943\n",
      "Validation loss decreased (inf --> 0.164907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1358088\n",
      "\tspeed: 0.1027s/iter; left time: 1757.8565s\n",
      "\titers: 200, epoch: 2 | loss: 0.1412189\n",
      "\tspeed: 0.0345s/iter; left time: 586.6060s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239359\n",
      "\tspeed: 0.0345s/iter; left time: 582.8982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1101899\n",
      "\tspeed: 0.0345s/iter; left time: 579.3501s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120785\n",
      "\tspeed: 0.0344s/iter; left time: 575.1125s\n",
      "\titers: 600, epoch: 2 | loss: 0.1019989\n",
      "\tspeed: 0.0344s/iter; left time: 571.9308s\n",
      "\titers: 700, epoch: 2 | loss: 0.1072432\n",
      "\tspeed: 0.0339s/iter; left time: 559.6339s\n",
      "\titers: 800, epoch: 2 | loss: 0.1118224\n",
      "\tspeed: 0.0338s/iter; left time: 555.2880s\n",
      "\titers: 900, epoch: 2 | loss: 0.1012448\n",
      "\tspeed: 0.0338s/iter; left time: 551.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.1192783 Vali Loss: 0.1259812 Test Loss: 0.1363558\n",
      "Validation loss decreased (0.164907 --> 0.125981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092039\n",
      "\tspeed: 0.0994s/iter; left time: 1611.1556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914676\n",
      "\tspeed: 0.0344s/iter; left time: 554.0304s\n",
      "\titers: 300, epoch: 3 | loss: 0.0905245\n",
      "\tspeed: 0.0344s/iter; left time: 550.6343s\n",
      "\titers: 400, epoch: 3 | loss: 0.0860451\n",
      "\tspeed: 0.0344s/iter; left time: 547.1417s\n",
      "\titers: 500, epoch: 3 | loss: 0.0840570\n",
      "\tspeed: 0.0344s/iter; left time: 544.1619s\n",
      "\titers: 600, epoch: 3 | loss: 0.0864475\n",
      "\tspeed: 0.0345s/iter; left time: 541.2266s\n",
      "\titers: 700, epoch: 3 | loss: 0.0776535\n",
      "\tspeed: 0.0344s/iter; left time: 537.5386s\n",
      "\titers: 800, epoch: 3 | loss: 0.0880026\n",
      "\tspeed: 0.0339s/iter; left time: 525.2373s\n",
      "\titers: 900, epoch: 3 | loss: 0.0833839\n",
      "\tspeed: 0.0339s/iter; left time: 522.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.37s\n",
      "Steps: 906 | Train Loss: 0.0881952 Vali Loss: 0.1017724 Test Loss: 0.1044518\n",
      "Validation loss decreased (0.125981 --> 0.101772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744945\n",
      "\tspeed: 0.0997s/iter; left time: 1525.1724s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867104\n",
      "\tspeed: 0.0346s/iter; left time: 526.1904s\n",
      "\titers: 300, epoch: 4 | loss: 0.0777602\n",
      "\tspeed: 0.0346s/iter; left time: 522.0265s\n",
      "\titers: 400, epoch: 4 | loss: 0.0799538\n",
      "\tspeed: 0.0345s/iter; left time: 518.2007s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863173\n",
      "\tspeed: 0.0345s/iter; left time: 514.7978s\n",
      "\titers: 600, epoch: 4 | loss: 0.0789659\n",
      "\tspeed: 0.0345s/iter; left time: 510.7476s\n",
      "\titers: 700, epoch: 4 | loss: 0.0863506\n",
      "\tspeed: 0.0346s/iter; left time: 508.8477s\n",
      "\titers: 800, epoch: 4 | loss: 0.0809430\n",
      "\tspeed: 0.0346s/iter; left time: 504.7647s\n",
      "\titers: 900, epoch: 4 | loss: 0.0644707\n",
      "\tspeed: 0.0345s/iter; left time: 500.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0795589 Vali Loss: 0.0984519 Test Loss: 0.0999526\n",
      "Validation loss decreased (0.101772 --> 0.098452).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0721323\n",
      "\tspeed: 0.0989s/iter; left time: 1423.9969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783579\n",
      "\tspeed: 0.0345s/iter; left time: 493.9352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0719792\n",
      "\tspeed: 0.0346s/iter; left time: 490.6305s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887703\n",
      "\tspeed: 0.0346s/iter; left time: 487.6967s\n",
      "\titers: 500, epoch: 5 | loss: 0.0698399\n",
      "\tspeed: 0.0345s/iter; left time: 483.3961s\n",
      "\titers: 600, epoch: 5 | loss: 0.0868544\n",
      "\tspeed: 0.0346s/iter; left time: 480.1936s\n",
      "\titers: 700, epoch: 5 | loss: 0.0848192\n",
      "\tspeed: 0.0346s/iter; left time: 477.6474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0792127\n",
      "\tspeed: 0.0345s/iter; left time: 472.9793s\n",
      "\titers: 900, epoch: 5 | loss: 0.0864622\n",
      "\tspeed: 0.0345s/iter; left time: 469.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0759394 Vali Loss: 0.0958418 Test Loss: 0.1013505\n",
      "Validation loss decreased (0.098452 --> 0.095842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0766028\n",
      "\tspeed: 0.1005s/iter; left time: 1355.8127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0649590\n",
      "\tspeed: 0.0340s/iter; left time: 454.6845s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727186\n",
      "\tspeed: 0.0340s/iter; left time: 451.7025s\n",
      "\titers: 400, epoch: 6 | loss: 0.0766119\n",
      "\tspeed: 0.0340s/iter; left time: 448.5078s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743469\n",
      "\tspeed: 0.0339s/iter; left time: 444.3921s\n",
      "\titers: 600, epoch: 6 | loss: 0.0666672\n",
      "\tspeed: 0.0342s/iter; left time: 444.0445s\n",
      "\titers: 700, epoch: 6 | loss: 0.0702888\n",
      "\tspeed: 0.0346s/iter; left time: 445.4402s\n",
      "\titers: 800, epoch: 6 | loss: 0.0753023\n",
      "\tspeed: 0.0345s/iter; left time: 441.7408s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721991\n",
      "\tspeed: 0.0345s/iter; left time: 438.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 906 | Train Loss: 0.0725840 Vali Loss: 0.0960399 Test Loss: 0.1029606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0633076\n",
      "\tspeed: 0.0959s/iter; left time: 1207.1412s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646344\n",
      "\tspeed: 0.0341s/iter; left time: 425.4750s\n",
      "\titers: 300, epoch: 7 | loss: 0.0732895\n",
      "\tspeed: 0.0341s/iter; left time: 421.7839s\n",
      "\titers: 400, epoch: 7 | loss: 0.0704056\n",
      "\tspeed: 0.0341s/iter; left time: 418.9666s\n",
      "\titers: 500, epoch: 7 | loss: 0.0750957\n",
      "\tspeed: 0.0340s/iter; left time: 414.5119s\n",
      "\titers: 600, epoch: 7 | loss: 0.0560974\n",
      "\tspeed: 0.0340s/iter; left time: 411.1310s\n",
      "\titers: 700, epoch: 7 | loss: 0.0703704\n",
      "\tspeed: 0.0339s/iter; left time: 406.7731s\n",
      "\titers: 800, epoch: 7 | loss: 0.0585428\n",
      "\tspeed: 0.0340s/iter; left time: 404.0264s\n",
      "\titers: 900, epoch: 7 | loss: 0.0656901\n",
      "\tspeed: 0.0340s/iter; left time: 400.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0696662 Vali Loss: 0.0953170 Test Loss: 0.1043832\n",
      "Validation loss decreased (0.095842 --> 0.095317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597942\n",
      "\tspeed: 0.0999s/iter; left time: 1166.6990s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753576\n",
      "\tspeed: 0.0340s/iter; left time: 394.0254s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652202\n",
      "\tspeed: 0.0340s/iter; left time: 389.8927s\n",
      "\titers: 400, epoch: 8 | loss: 0.0703675\n",
      "\tspeed: 0.0340s/iter; left time: 386.8097s\n",
      "\titers: 500, epoch: 8 | loss: 0.0684308\n",
      "\tspeed: 0.0340s/iter; left time: 383.7727s\n",
      "\titers: 600, epoch: 8 | loss: 0.0796844\n",
      "\tspeed: 0.0340s/iter; left time: 379.9436s\n",
      "\titers: 700, epoch: 8 | loss: 0.0586823\n",
      "\tspeed: 0.0340s/iter; left time: 376.6601s\n",
      "\titers: 800, epoch: 8 | loss: 0.0628379\n",
      "\tspeed: 0.0340s/iter; left time: 373.1167s\n",
      "\titers: 900, epoch: 8 | loss: 0.0772258\n",
      "\tspeed: 0.0340s/iter; left time: 369.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0667833 Vali Loss: 0.0989558 Test Loss: 0.1058859\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731515\n",
      "\tspeed: 0.0953s/iter; left time: 1026.8488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666756\n",
      "\tspeed: 0.0339s/iter; left time: 362.1014s\n",
      "\titers: 300, epoch: 9 | loss: 0.0595185\n",
      "\tspeed: 0.0340s/iter; left time: 358.9964s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703624\n",
      "\tspeed: 0.0339s/iter; left time: 354.9658s\n",
      "\titers: 500, epoch: 9 | loss: 0.0656522\n",
      "\tspeed: 0.0339s/iter; left time: 351.8254s\n",
      "\titers: 600, epoch: 9 | loss: 0.0701082\n",
      "\tspeed: 0.0340s/iter; left time: 348.9358s\n",
      "\titers: 700, epoch: 9 | loss: 0.0658102\n",
      "\tspeed: 0.0340s/iter; left time: 345.7134s\n",
      "\titers: 800, epoch: 9 | loss: 0.0694849\n",
      "\tspeed: 0.0340s/iter; left time: 342.2395s\n",
      "\titers: 900, epoch: 9 | loss: 0.0585585\n",
      "\tspeed: 0.0340s/iter; left time: 338.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0644456 Vali Loss: 0.0969864 Test Loss: 0.1054834\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0660802\n",
      "\tspeed: 0.0965s/iter; left time: 952.2213s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685927\n",
      "\tspeed: 0.0346s/iter; left time: 337.5984s\n",
      "\titers: 300, epoch: 10 | loss: 0.0581311\n",
      "\tspeed: 0.0346s/iter; left time: 334.6282s\n",
      "\titers: 400, epoch: 10 | loss: 0.0709546\n",
      "\tspeed: 0.0346s/iter; left time: 330.5468s\n",
      "\titers: 500, epoch: 10 | loss: 0.0617054\n",
      "\tspeed: 0.0345s/iter; left time: 326.9514s\n",
      "\titers: 600, epoch: 10 | loss: 0.0566655\n",
      "\tspeed: 0.0344s/iter; left time: 322.5654s\n",
      "\titers: 700, epoch: 10 | loss: 0.0555644\n",
      "\tspeed: 0.0344s/iter; left time: 318.7316s\n",
      "\titers: 800, epoch: 10 | loss: 0.0605263\n",
      "\tspeed: 0.0342s/iter; left time: 313.3976s\n",
      "\titers: 900, epoch: 10 | loss: 0.0554270\n",
      "\tspeed: 0.0346s/iter; left time: 313.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.0618099 Vali Loss: 0.0958811 Test Loss: 0.1058694\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619151\n",
      "\tspeed: 0.0963s/iter; left time: 863.0085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597805\n",
      "\tspeed: 0.0344s/iter; left time: 304.8721s\n",
      "\titers: 300, epoch: 11 | loss: 0.0536805\n",
      "\tspeed: 0.0343s/iter; left time: 300.7942s\n",
      "\titers: 400, epoch: 11 | loss: 0.0513019\n",
      "\tspeed: 0.0342s/iter; left time: 296.3691s\n",
      "\titers: 500, epoch: 11 | loss: 0.0637296\n",
      "\tspeed: 0.0340s/iter; left time: 291.1695s\n",
      "\titers: 600, epoch: 11 | loss: 0.0655506\n",
      "\tspeed: 0.0345s/iter; left time: 291.5188s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623056\n",
      "\tspeed: 0.0346s/iter; left time: 289.1530s\n",
      "\titers: 800, epoch: 11 | loss: 0.0541347\n",
      "\tspeed: 0.0345s/iter; left time: 285.3061s\n",
      "\titers: 900, epoch: 11 | loss: 0.0503099\n",
      "\tspeed: 0.0346s/iter; left time: 282.1885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0593142 Vali Loss: 0.0960872 Test Loss: 0.1093873\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611448\n",
      "\tspeed: 0.0971s/iter; left time: 782.3115s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560043\n",
      "\tspeed: 0.0345s/iter; left time: 274.5392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0558763\n",
      "\tspeed: 0.0346s/iter; left time: 271.4691s\n",
      "\titers: 400, epoch: 12 | loss: 0.0633862\n",
      "\tspeed: 0.0345s/iter; left time: 267.7986s\n",
      "\titers: 500, epoch: 12 | loss: 0.0537031\n",
      "\tspeed: 0.0345s/iter; left time: 263.8130s\n",
      "\titers: 600, epoch: 12 | loss: 0.0556691\n",
      "\tspeed: 0.0345s/iter; left time: 260.6213s\n",
      "\titers: 700, epoch: 12 | loss: 0.0593802\n",
      "\tspeed: 0.0345s/iter; left time: 257.2170s\n",
      "\titers: 800, epoch: 12 | loss: 0.0507883\n",
      "\tspeed: 0.0341s/iter; left time: 251.0438s\n",
      "\titers: 900, epoch: 12 | loss: 0.0559344\n",
      "\tspeed: 0.0341s/iter; left time: 247.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.50s\n",
      "Steps: 906 | Train Loss: 0.0574293 Vali Loss: 0.0990894 Test Loss: 0.1103720\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025507517158985138, rmse:0.15971073508262634, mae:0.1042659804224968, rse:0.5640227794647217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2230141\n",
      "\tspeed: 0.0367s/iter; left time: 661.5227s\n",
      "\titers: 200, epoch: 1 | loss: 0.1912384\n",
      "\tspeed: 0.0340s/iter; left time: 608.9154s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890538\n",
      "\tspeed: 0.0340s/iter; left time: 606.1844s\n",
      "\titers: 400, epoch: 1 | loss: 0.1821308\n",
      "\tspeed: 0.0340s/iter; left time: 602.3591s\n",
      "\titers: 500, epoch: 1 | loss: 0.1777495\n",
      "\tspeed: 0.0340s/iter; left time: 598.7651s\n",
      "\titers: 600, epoch: 1 | loss: 0.1753001\n",
      "\tspeed: 0.0340s/iter; left time: 594.9457s\n",
      "\titers: 700, epoch: 1 | loss: 0.1703886\n",
      "\tspeed: 0.0339s/iter; left time: 591.3277s\n",
      "\titers: 800, epoch: 1 | loss: 0.1719142\n",
      "\tspeed: 0.0340s/iter; left time: 589.2019s\n",
      "\titers: 900, epoch: 1 | loss: 0.1525570\n",
      "\tspeed: 0.0343s/iter; left time: 590.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.1884397 Vali Loss: 0.1670010 Test Loss: 0.1773647\n",
      "Validation loss decreased (inf --> 0.167001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437568\n",
      "\tspeed: 0.0981s/iter; left time: 1678.7434s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364804\n",
      "\tspeed: 0.0340s/iter; left time: 578.6627s\n",
      "\titers: 300, epoch: 2 | loss: 0.1206845\n",
      "\tspeed: 0.0339s/iter; left time: 574.1556s\n",
      "\titers: 400, epoch: 2 | loss: 0.1204325\n",
      "\tspeed: 0.0339s/iter; left time: 570.6358s\n",
      "\titers: 500, epoch: 2 | loss: 0.1200934\n",
      "\tspeed: 0.0339s/iter; left time: 567.3894s\n",
      "\titers: 600, epoch: 2 | loss: 0.1026905\n",
      "\tspeed: 0.0340s/iter; left time: 565.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.1184056\n",
      "\tspeed: 0.0342s/iter; left time: 564.1581s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938529\n",
      "\tspeed: 0.0340s/iter; left time: 557.4805s\n",
      "\titers: 900, epoch: 2 | loss: 0.1178905\n",
      "\tspeed: 0.0340s/iter; left time: 554.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.1221062 Vali Loss: 0.1266311 Test Loss: 0.1376089\n",
      "Validation loss decreased (0.167001 --> 0.126631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071769\n",
      "\tspeed: 0.0964s/iter; left time: 1562.9527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011983\n",
      "\tspeed: 0.0340s/iter; left time: 547.1883s\n",
      "\titers: 300, epoch: 3 | loss: 0.0976297\n",
      "\tspeed: 0.0339s/iter; left time: 543.1893s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108132\n",
      "\tspeed: 0.0340s/iter; left time: 541.4452s\n",
      "\titers: 500, epoch: 3 | loss: 0.1018856\n",
      "\tspeed: 0.0340s/iter; left time: 537.0724s\n",
      "\titers: 600, epoch: 3 | loss: 0.0973330\n",
      "\tspeed: 0.0339s/iter; left time: 533.1113s\n",
      "\titers: 700, epoch: 3 | loss: 0.1023080\n",
      "\tspeed: 0.0340s/iter; left time: 530.2765s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062835\n",
      "\tspeed: 0.0340s/iter; left time: 527.0927s\n",
      "\titers: 900, epoch: 3 | loss: 0.1069887\n",
      "\tspeed: 0.0340s/iter; left time: 523.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.1036100 Vali Loss: 0.1243204 Test Loss: 0.1360400\n",
      "Validation loss decreased (0.126631 --> 0.124320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992623\n",
      "\tspeed: 0.0962s/iter; left time: 1472.6358s\n",
      "\titers: 200, epoch: 4 | loss: 0.1065900\n",
      "\tspeed: 0.0341s/iter; left time: 518.2205s\n",
      "\titers: 300, epoch: 4 | loss: 0.0931358\n",
      "\tspeed: 0.0339s/iter; left time: 512.1561s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058308\n",
      "\tspeed: 0.0339s/iter; left time: 509.0334s\n",
      "\titers: 500, epoch: 4 | loss: 0.0744899\n",
      "\tspeed: 0.0339s/iter; left time: 505.7343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0765016\n",
      "\tspeed: 0.0340s/iter; left time: 502.9699s\n",
      "\titers: 700, epoch: 4 | loss: 0.0799936\n",
      "\tspeed: 0.0340s/iter; left time: 500.2816s\n",
      "\titers: 800, epoch: 4 | loss: 0.0827769\n",
      "\tspeed: 0.0340s/iter; left time: 496.7079s\n",
      "\titers: 900, epoch: 4 | loss: 0.0796529\n",
      "\tspeed: 0.0340s/iter; left time: 493.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0907794 Vali Loss: 0.0990055 Test Loss: 0.1009647\n",
      "Validation loss decreased (0.124320 --> 0.099006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691942\n",
      "\tspeed: 0.0981s/iter; left time: 1411.9831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784808\n",
      "\tspeed: 0.0342s/iter; left time: 489.5829s\n",
      "\titers: 300, epoch: 5 | loss: 0.0777235\n",
      "\tspeed: 0.0340s/iter; left time: 482.8251s\n",
      "\titers: 400, epoch: 5 | loss: 0.0742996\n",
      "\tspeed: 0.0340s/iter; left time: 478.9214s\n",
      "\titers: 500, epoch: 5 | loss: 0.0769375\n",
      "\tspeed: 0.0340s/iter; left time: 476.0276s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693606\n",
      "\tspeed: 0.0340s/iter; left time: 472.2992s\n",
      "\titers: 700, epoch: 5 | loss: 0.0777253\n",
      "\tspeed: 0.0341s/iter; left time: 469.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0345s/iter; left time: 472.8234s\n",
      "\titers: 900, epoch: 5 | loss: 0.0693382\n",
      "\tspeed: 0.0345s/iter; left time: 469.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0772579 Vali Loss: 0.0970609 Test Loss: 0.1022710\n",
      "Validation loss decreased (0.099006 --> 0.097061).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816712\n",
      "\tspeed: 0.0976s/iter; left time: 1317.1927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686115\n",
      "\tspeed: 0.0340s/iter; left time: 455.8893s\n",
      "\titers: 300, epoch: 6 | loss: 0.0724844\n",
      "\tspeed: 0.0340s/iter; left time: 451.8054s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776625\n",
      "\tspeed: 0.0340s/iter; left time: 448.8444s\n",
      "\titers: 500, epoch: 6 | loss: 0.0742506\n",
      "\tspeed: 0.0340s/iter; left time: 445.3133s\n",
      "\titers: 600, epoch: 6 | loss: 0.0692068\n",
      "\tspeed: 0.0340s/iter; left time: 441.3233s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700073\n",
      "\tspeed: 0.0341s/iter; left time: 438.9639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0682788\n",
      "\tspeed: 0.0340s/iter; left time: 434.4684s\n",
      "\titers: 900, epoch: 6 | loss: 0.0709434\n",
      "\tspeed: 0.0340s/iter; left time: 431.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0735981 Vali Loss: 0.0985253 Test Loss: 0.1054766\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695847\n",
      "\tspeed: 0.0942s/iter; left time: 1185.8467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0663946\n",
      "\tspeed: 0.0347s/iter; left time: 432.8294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0748294\n",
      "\tspeed: 0.0347s/iter; left time: 429.4195s\n",
      "\titers: 400, epoch: 7 | loss: 0.0655389\n",
      "\tspeed: 0.0347s/iter; left time: 426.0399s\n",
      "\titers: 500, epoch: 7 | loss: 0.0710848\n",
      "\tspeed: 0.0347s/iter; left time: 422.4656s\n",
      "\titers: 600, epoch: 7 | loss: 0.0750432\n",
      "\tspeed: 0.0347s/iter; left time: 418.9342s\n",
      "\titers: 700, epoch: 7 | loss: 0.0589826\n",
      "\tspeed: 0.0347s/iter; left time: 415.5421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0753183\n",
      "\tspeed: 0.0345s/iter; left time: 410.4611s\n",
      "\titers: 900, epoch: 7 | loss: 0.0640458\n",
      "\tspeed: 0.0345s/iter; left time: 406.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0701836 Vali Loss: 0.0988405 Test Loss: 0.1049409\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640777\n",
      "\tspeed: 0.0967s/iter; left time: 1129.8765s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628060\n",
      "\tspeed: 0.0340s/iter; left time: 393.7841s\n",
      "\titers: 300, epoch: 8 | loss: 0.0658005\n",
      "\tspeed: 0.0340s/iter; left time: 390.8261s\n",
      "\titers: 400, epoch: 8 | loss: 0.0692687\n",
      "\tspeed: 0.0340s/iter; left time: 386.9866s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804830\n",
      "\tspeed: 0.0340s/iter; left time: 383.3645s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704948\n",
      "\tspeed: 0.0340s/iter; left time: 380.1543s\n",
      "\titers: 700, epoch: 8 | loss: 0.0721590\n",
      "\tspeed: 0.0340s/iter; left time: 376.3733s\n",
      "\titers: 800, epoch: 8 | loss: 0.0717574\n",
      "\tspeed: 0.0340s/iter; left time: 373.2058s\n",
      "\titers: 900, epoch: 8 | loss: 0.0600496\n",
      "\tspeed: 0.0340s/iter; left time: 369.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0675137 Vali Loss: 0.0970914 Test Loss: 0.1058643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0610077\n",
      "\tspeed: 0.0939s/iter; left time: 1012.0603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536139\n",
      "\tspeed: 0.0340s/iter; left time: 363.0301s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636304\n",
      "\tspeed: 0.0340s/iter; left time: 359.2915s\n",
      "\titers: 400, epoch: 9 | loss: 0.0654796\n",
      "\tspeed: 0.0339s/iter; left time: 355.4828s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599042\n",
      "\tspeed: 0.0340s/iter; left time: 352.4805s\n",
      "\titers: 600, epoch: 9 | loss: 0.0565385\n",
      "\tspeed: 0.0340s/iter; left time: 348.7747s\n",
      "\titers: 700, epoch: 9 | loss: 0.0668385\n",
      "\tspeed: 0.0340s/iter; left time: 345.7664s\n",
      "\titers: 800, epoch: 9 | loss: 0.0648912\n",
      "\tspeed: 0.0340s/iter; left time: 342.2205s\n",
      "\titers: 900, epoch: 9 | loss: 0.0582753\n",
      "\tspeed: 0.0340s/iter; left time: 339.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0648913 Vali Loss: 0.0960822 Test Loss: 0.1028538\n",
      "Validation loss decreased (0.097061 --> 0.096082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571060\n",
      "\tspeed: 0.0974s/iter; left time: 961.0195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593772\n",
      "\tspeed: 0.0340s/iter; left time: 332.1973s\n",
      "\titers: 300, epoch: 10 | loss: 0.0612443\n",
      "\tspeed: 0.0340s/iter; left time: 328.9119s\n",
      "\titers: 400, epoch: 10 | loss: 0.0655431\n",
      "\tspeed: 0.0340s/iter; left time: 325.6748s\n",
      "\titers: 500, epoch: 10 | loss: 0.0650016\n",
      "\tspeed: 0.0340s/iter; left time: 322.1937s\n",
      "\titers: 600, epoch: 10 | loss: 0.0638729\n",
      "\tspeed: 0.0341s/iter; left time: 319.2505s\n",
      "\titers: 700, epoch: 10 | loss: 0.0595213\n",
      "\tspeed: 0.0340s/iter; left time: 315.3304s\n",
      "\titers: 800, epoch: 10 | loss: 0.0569092\n",
      "\tspeed: 0.0340s/iter; left time: 311.9479s\n",
      "\titers: 900, epoch: 10 | loss: 0.0640525\n",
      "\tspeed: 0.0340s/iter; left time: 308.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0622086 Vali Loss: 0.0958591 Test Loss: 0.1072349\n",
      "Validation loss decreased (0.096082 --> 0.095859).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0614833\n",
      "\tspeed: 0.0974s/iter; left time: 872.4934s\n",
      "\titers: 200, epoch: 11 | loss: 0.0575255\n",
      "\tspeed: 0.0339s/iter; left time: 300.4564s\n",
      "\titers: 300, epoch: 11 | loss: 0.0580176\n",
      "\tspeed: 0.0339s/iter; left time: 297.3484s\n",
      "\titers: 400, epoch: 11 | loss: 0.0558818\n",
      "\tspeed: 0.0339s/iter; left time: 293.5805s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552967\n",
      "\tspeed: 0.0339s/iter; left time: 290.2811s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624112\n",
      "\tspeed: 0.0340s/iter; left time: 287.2546s\n",
      "\titers: 700, epoch: 11 | loss: 0.0603113\n",
      "\tspeed: 0.0339s/iter; left time: 283.7670s\n",
      "\titers: 800, epoch: 11 | loss: 0.0681967\n",
      "\tspeed: 0.0339s/iter; left time: 280.0891s\n",
      "\titers: 900, epoch: 11 | loss: 0.0524940\n",
      "\tspeed: 0.0339s/iter; left time: 276.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0599555 Vali Loss: 0.0940875 Test Loss: 0.1040663\n",
      "Validation loss decreased (0.095859 --> 0.094087).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0657773\n",
      "\tspeed: 0.0984s/iter; left time: 792.4305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594814\n",
      "\tspeed: 0.0340s/iter; left time: 270.1358s\n",
      "\titers: 300, epoch: 12 | loss: 0.0568700\n",
      "\tspeed: 0.0340s/iter; left time: 267.2081s\n",
      "\titers: 400, epoch: 12 | loss: 0.0558004\n",
      "\tspeed: 0.0341s/iter; left time: 264.1364s\n",
      "\titers: 500, epoch: 12 | loss: 0.0566751\n",
      "\tspeed: 0.0340s/iter; left time: 260.4906s\n",
      "\titers: 600, epoch: 12 | loss: 0.0581444\n",
      "\tspeed: 0.0340s/iter; left time: 257.1118s\n",
      "\titers: 700, epoch: 12 | loss: 0.0557531\n",
      "\tspeed: 0.0340s/iter; left time: 253.6974s\n",
      "\titers: 800, epoch: 12 | loss: 0.0620691\n",
      "\tspeed: 0.0340s/iter; left time: 250.2706s\n",
      "\titers: 900, epoch: 12 | loss: 0.0582283\n",
      "\tspeed: 0.0340s/iter; left time: 246.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0577892 Vali Loss: 0.0964437 Test Loss: 0.1105988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533582\n",
      "\tspeed: 0.0941s/iter; left time: 672.9972s\n",
      "\titers: 200, epoch: 13 | loss: 0.0481930\n",
      "\tspeed: 0.0347s/iter; left time: 244.4470s\n",
      "\titers: 300, epoch: 13 | loss: 0.0606546\n",
      "\tspeed: 0.0347s/iter; left time: 241.1487s\n",
      "\titers: 400, epoch: 13 | loss: 0.0518627\n",
      "\tspeed: 0.0347s/iter; left time: 237.4272s\n",
      "\titers: 500, epoch: 13 | loss: 0.0569521\n",
      "\tspeed: 0.0347s/iter; left time: 233.9909s\n",
      "\titers: 600, epoch: 13 | loss: 0.0532617\n",
      "\tspeed: 0.0347s/iter; left time: 230.4939s\n",
      "\titers: 700, epoch: 13 | loss: 0.0609730\n",
      "\tspeed: 0.0347s/iter; left time: 227.0485s\n",
      "\titers: 800, epoch: 13 | loss: 0.0557893\n",
      "\tspeed: 0.0347s/iter; left time: 223.6601s\n",
      "\titers: 900, epoch: 13 | loss: 0.0557036\n",
      "\tspeed: 0.0347s/iter; left time: 220.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.66s\n",
      "Steps: 906 | Train Loss: 0.0560332 Vali Loss: 0.0970379 Test Loss: 0.1079533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0597315\n",
      "\tspeed: 0.0939s/iter; left time: 586.2774s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535129\n",
      "\tspeed: 0.0345s/iter; left time: 212.0048s\n",
      "\titers: 300, epoch: 14 | loss: 0.0514123\n",
      "\tspeed: 0.0344s/iter; left time: 208.1608s\n",
      "\titers: 400, epoch: 14 | loss: 0.0533041\n",
      "\tspeed: 0.0339s/iter; left time: 201.7241s\n",
      "\titers: 500, epoch: 14 | loss: 0.0519378\n",
      "\tspeed: 0.0339s/iter; left time: 198.1319s\n",
      "\titers: 600, epoch: 14 | loss: 0.0486918\n",
      "\tspeed: 0.0339s/iter; left time: 194.8968s\n",
      "\titers: 700, epoch: 14 | loss: 0.0514592\n",
      "\tspeed: 0.0339s/iter; left time: 191.3317s\n",
      "\titers: 800, epoch: 14 | loss: 0.0511779\n",
      "\tspeed: 0.0340s/iter; left time: 188.2007s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592240\n",
      "\tspeed: 0.0340s/iter; left time: 184.8092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0542619 Vali Loss: 0.1007048 Test Loss: 0.1137719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533272\n",
      "\tspeed: 0.0937s/iter; left time: 500.2540s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540463\n",
      "\tspeed: 0.0340s/iter; left time: 178.0053s\n",
      "\titers: 300, epoch: 15 | loss: 0.0475888\n",
      "\tspeed: 0.0340s/iter; left time: 174.6277s\n",
      "\titers: 400, epoch: 15 | loss: 0.0573437\n",
      "\tspeed: 0.0340s/iter; left time: 171.1498s\n",
      "\titers: 500, epoch: 15 | loss: 0.0579779\n",
      "\tspeed: 0.0340s/iter; left time: 167.7634s\n",
      "\titers: 600, epoch: 15 | loss: 0.0538819\n",
      "\tspeed: 0.0340s/iter; left time: 164.3892s\n",
      "\titers: 700, epoch: 15 | loss: 0.0519059\n",
      "\tspeed: 0.0340s/iter; left time: 161.0040s\n",
      "\titers: 800, epoch: 15 | loss: 0.0557711\n",
      "\tspeed: 0.0341s/iter; left time: 157.8956s\n",
      "\titers: 900, epoch: 15 | loss: 0.0465270\n",
      "\tspeed: 0.0340s/iter; left time: 154.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0528399 Vali Loss: 0.0974168 Test Loss: 0.1095551\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476120\n",
      "\tspeed: 0.0947s/iter; left time: 419.5489s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560914\n",
      "\tspeed: 0.0340s/iter; left time: 147.1741s\n",
      "\titers: 300, epoch: 16 | loss: 0.0469050\n",
      "\tspeed: 0.0340s/iter; left time: 143.6711s\n",
      "\titers: 400, epoch: 16 | loss: 0.0462344\n",
      "\tspeed: 0.0340s/iter; left time: 140.2631s\n",
      "\titers: 500, epoch: 16 | loss: 0.0579376\n",
      "\tspeed: 0.0340s/iter; left time: 136.8792s\n",
      "\titers: 600, epoch: 16 | loss: 0.0472905\n",
      "\tspeed: 0.0340s/iter; left time: 133.6086s\n",
      "\titers: 700, epoch: 16 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 129.8898s\n",
      "\titers: 800, epoch: 16 | loss: 0.0483521\n",
      "\tspeed: 0.0340s/iter; left time: 126.7298s\n",
      "\titers: 900, epoch: 16 | loss: 0.0505118\n",
      "\tspeed: 0.0340s/iter; left time: 123.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0516243 Vali Loss: 0.0969801 Test Loss: 0.1082252\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027125487104058266, rmse:0.16469816863536835, mae:0.10410299152135849, rse:0.5816360116004944\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:33.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2236743\n",
      "\tspeed: 0.0659s/iter; left time: 1184.4053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113647\n",
      "\tspeed: 0.0418s/iter; left time: 747.1035s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026322\n",
      "\tspeed: 0.0415s/iter; left time: 737.3678s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935861\n",
      "\tspeed: 0.0415s/iter; left time: 733.9055s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860587\n",
      "\tspeed: 0.0420s/iter; left time: 738.5568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1778900\n",
      "\tspeed: 0.0416s/iter; left time: 727.0239s\n",
      "\titers: 700, epoch: 1 | loss: 0.1723806\n",
      "\tspeed: 0.0418s/iter; left time: 725.8630s\n",
      "\titers: 800, epoch: 1 | loss: 0.1740834\n",
      "\tspeed: 0.0421s/iter; left time: 727.4376s\n",
      "\titers: 900, epoch: 1 | loss: 0.1730634\n",
      "\tspeed: 0.0421s/iter; left time: 723.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 904 | Train Loss: 0.1950106 Vali Loss: 0.1828621 Test Loss: 0.2036057\n",
      "Validation loss decreased (inf --> 0.182862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645211\n",
      "\tspeed: 0.1168s/iter; left time: 1994.4889s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429543\n",
      "\tspeed: 0.0416s/iter; left time: 705.5633s\n",
      "\titers: 300, epoch: 2 | loss: 0.1374299\n",
      "\tspeed: 0.0416s/iter; left time: 701.5841s\n",
      "\titers: 400, epoch: 2 | loss: 0.1448636\n",
      "\tspeed: 0.0416s/iter; left time: 697.7827s\n",
      "\titers: 500, epoch: 2 | loss: 0.1413144\n",
      "\tspeed: 0.0416s/iter; left time: 693.9163s\n",
      "\titers: 600, epoch: 2 | loss: 0.1236145\n",
      "\tspeed: 0.0416s/iter; left time: 689.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.1246188\n",
      "\tspeed: 0.0416s/iter; left time: 685.3335s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242174\n",
      "\tspeed: 0.0416s/iter; left time: 681.5506s\n",
      "\titers: 900, epoch: 2 | loss: 0.1292692\n",
      "\tspeed: 0.0416s/iter; left time: 677.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1378524 Vali Loss: 0.1397373 Test Loss: 0.1576225\n",
      "Validation loss decreased (0.182862 --> 0.139737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1165264\n",
      "\tspeed: 0.1172s/iter; left time: 1894.8829s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007225\n",
      "\tspeed: 0.0417s/iter; left time: 670.0918s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167652\n",
      "\tspeed: 0.0416s/iter; left time: 665.2381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1072120\n",
      "\tspeed: 0.0416s/iter; left time: 659.8419s\n",
      "\titers: 500, epoch: 3 | loss: 0.1060360\n",
      "\tspeed: 0.0416s/iter; left time: 656.2613s\n",
      "\titers: 600, epoch: 3 | loss: 0.1059219\n",
      "\tspeed: 0.0416s/iter; left time: 651.9737s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176727\n",
      "\tspeed: 0.0416s/iter; left time: 647.9141s\n",
      "\titers: 800, epoch: 3 | loss: 0.0983266\n",
      "\tspeed: 0.0416s/iter; left time: 643.8895s\n",
      "\titers: 900, epoch: 3 | loss: 0.1117628\n",
      "\tspeed: 0.0417s/iter; left time: 640.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.1093381 Vali Loss: 0.1260393 Test Loss: 0.1418328\n",
      "Validation loss decreased (0.139737 --> 0.126039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144765\n",
      "\tspeed: 0.1182s/iter; left time: 1805.4575s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020382\n",
      "\tspeed: 0.0416s/iter; left time: 631.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.1153255\n",
      "\tspeed: 0.0416s/iter; left time: 627.1646s\n",
      "\titers: 400, epoch: 4 | loss: 0.1025088\n",
      "\tspeed: 0.0416s/iter; left time: 622.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.1027884\n",
      "\tspeed: 0.0416s/iter; left time: 618.4806s\n",
      "\titers: 600, epoch: 4 | loss: 0.1016667\n",
      "\tspeed: 0.0416s/iter; left time: 614.3470s\n",
      "\titers: 700, epoch: 4 | loss: 0.1033425\n",
      "\tspeed: 0.0416s/iter; left time: 610.2125s\n",
      "\titers: 800, epoch: 4 | loss: 0.0933737\n",
      "\tspeed: 0.0416s/iter; left time: 606.3138s\n",
      "\titers: 900, epoch: 4 | loss: 0.0934185\n",
      "\tspeed: 0.0416s/iter; left time: 601.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1001598 Vali Loss: 0.1275451 Test Loss: 0.1407701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895917\n",
      "\tspeed: 0.1148s/iter; left time: 1649.6186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927757\n",
      "\tspeed: 0.0416s/iter; left time: 593.4980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965540\n",
      "\tspeed: 0.0416s/iter; left time: 588.6807s\n",
      "\titers: 400, epoch: 5 | loss: 0.0999158\n",
      "\tspeed: 0.0416s/iter; left time: 585.5770s\n",
      "\titers: 500, epoch: 5 | loss: 0.0884686\n",
      "\tspeed: 0.0416s/iter; left time: 581.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.0966759\n",
      "\tspeed: 0.0417s/iter; left time: 578.2581s\n",
      "\titers: 700, epoch: 5 | loss: 0.0977219\n",
      "\tspeed: 0.0416s/iter; left time: 573.0901s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846407\n",
      "\tspeed: 0.0416s/iter; left time: 568.7870s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849928\n",
      "\tspeed: 0.0416s/iter; left time: 564.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 904 | Train Loss: 0.0935273 Vali Loss: 0.1276608 Test Loss: 0.1445250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835068\n",
      "\tspeed: 0.1146s/iter; left time: 1542.3072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837331\n",
      "\tspeed: 0.0416s/iter; left time: 555.9648s\n",
      "\titers: 300, epoch: 6 | loss: 0.0913434\n",
      "\tspeed: 0.0416s/iter; left time: 551.4175s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903796\n",
      "\tspeed: 0.0416s/iter; left time: 547.4075s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856775\n",
      "\tspeed: 0.0416s/iter; left time: 543.5327s\n",
      "\titers: 600, epoch: 6 | loss: 0.0846278\n",
      "\tspeed: 0.0416s/iter; left time: 539.4484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0778856\n",
      "\tspeed: 0.0416s/iter; left time: 535.0167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0858639\n",
      "\tspeed: 0.0416s/iter; left time: 530.9052s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903355\n",
      "\tspeed: 0.0416s/iter; left time: 527.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0873677 Vali Loss: 0.1281512 Test Loss: 0.1463322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829671\n",
      "\tspeed: 0.1144s/iter; left time: 1436.1222s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799333\n",
      "\tspeed: 0.0416s/iter; left time: 518.3830s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816214\n",
      "\tspeed: 0.0416s/iter; left time: 514.4665s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803851\n",
      "\tspeed: 0.0416s/iter; left time: 510.3534s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766140\n",
      "\tspeed: 0.0417s/iter; left time: 506.3998s\n",
      "\titers: 600, epoch: 7 | loss: 0.0814182\n",
      "\tspeed: 0.0416s/iter; left time: 502.0855s\n",
      "\titers: 700, epoch: 7 | loss: 0.0843650\n",
      "\tspeed: 0.0417s/iter; left time: 498.0307s\n",
      "\titers: 800, epoch: 7 | loss: 0.0786219\n",
      "\tspeed: 0.0416s/iter; left time: 493.6940s\n",
      "\titers: 900, epoch: 7 | loss: 0.0786166\n",
      "\tspeed: 0.0416s/iter; left time: 489.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0820126 Vali Loss: 0.1301628 Test Loss: 0.1494684\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744809\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1676s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740958\n",
      "\tspeed: 0.0416s/iter; left time: 480.6162s\n",
      "\titers: 300, epoch: 8 | loss: 0.0821366\n",
      "\tspeed: 0.0416s/iter; left time: 476.9035s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776912\n",
      "\tspeed: 0.0416s/iter; left time: 472.4502s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823452\n",
      "\tspeed: 0.0417s/iter; left time: 468.7491s\n",
      "\titers: 600, epoch: 8 | loss: 0.0832772\n",
      "\tspeed: 0.0416s/iter; left time: 464.2049s\n",
      "\titers: 700, epoch: 8 | loss: 0.0772706\n",
      "\tspeed: 0.0416s/iter; left time: 460.0779s\n",
      "\titers: 800, epoch: 8 | loss: 0.0733887\n",
      "\tspeed: 0.0416s/iter; left time: 455.9084s\n",
      "\titers: 900, epoch: 8 | loss: 0.0711432\n",
      "\tspeed: 0.0417s/iter; left time: 452.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0772220 Vali Loss: 0.1286450 Test Loss: 0.1474413\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111143946647644, rmse:0.20275956392288208, mae:0.14186589419841766, rse:0.7180125713348389\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2234415\n",
      "\tspeed: 0.0448s/iter; left time: 804.8949s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966856\n",
      "\tspeed: 0.0422s/iter; left time: 754.5125s\n",
      "\titers: 300, epoch: 1 | loss: 0.1985690\n",
      "\tspeed: 0.0422s/iter; left time: 750.9129s\n",
      "\titers: 400, epoch: 1 | loss: 0.1968302\n",
      "\tspeed: 0.0422s/iter; left time: 746.5394s\n",
      "\titers: 500, epoch: 1 | loss: 0.2051390\n",
      "\tspeed: 0.0422s/iter; left time: 742.6659s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833022\n",
      "\tspeed: 0.0422s/iter; left time: 737.9051s\n",
      "\titers: 700, epoch: 1 | loss: 0.1789588\n",
      "\tspeed: 0.0422s/iter; left time: 733.3599s\n",
      "\titers: 800, epoch: 1 | loss: 0.1781165\n",
      "\tspeed: 0.0422s/iter; left time: 730.0477s\n",
      "\titers: 900, epoch: 1 | loss: 0.1753210\n",
      "\tspeed: 0.0422s/iter; left time: 725.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 904 | Train Loss: 0.1983297 Vali Loss: 0.1792039 Test Loss: 0.1982639\n",
      "Validation loss decreased (inf --> 0.179204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652503\n",
      "\tspeed: 0.1185s/iter; left time: 2023.6443s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410911\n",
      "\tspeed: 0.0422s/iter; left time: 716.3351s\n",
      "\titers: 300, epoch: 2 | loss: 0.1531194\n",
      "\tspeed: 0.0422s/iter; left time: 712.5301s\n",
      "\titers: 400, epoch: 2 | loss: 0.1385903\n",
      "\tspeed: 0.0422s/iter; left time: 707.9972s\n",
      "\titers: 500, epoch: 2 | loss: 0.1392631\n",
      "\tspeed: 0.0422s/iter; left time: 703.6733s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265477\n",
      "\tspeed: 0.0419s/iter; left time: 694.9356s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320228\n",
      "\tspeed: 0.0417s/iter; left time: 686.5249s\n",
      "\titers: 800, epoch: 2 | loss: 0.1308168\n",
      "\tspeed: 0.0417s/iter; left time: 682.6446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1204412\n",
      "\tspeed: 0.0417s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 904 | Train Loss: 0.1407695 Vali Loss: 0.1408073 Test Loss: 0.1547505\n",
      "Validation loss decreased (0.179204 --> 0.140807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168671\n",
      "\tspeed: 0.1192s/iter; left time: 1927.4650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049146\n",
      "\tspeed: 0.0417s/iter; left time: 670.7429s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167228\n",
      "\tspeed: 0.0417s/iter; left time: 666.5092s\n",
      "\titers: 400, epoch: 3 | loss: 0.1142903\n",
      "\tspeed: 0.0417s/iter; left time: 662.3797s\n",
      "\titers: 500, epoch: 3 | loss: 0.1116785\n",
      "\tspeed: 0.0417s/iter; left time: 657.1454s\n",
      "\titers: 600, epoch: 3 | loss: 0.1235701\n",
      "\tspeed: 0.0417s/iter; left time: 653.4055s\n",
      "\titers: 700, epoch: 3 | loss: 0.1162522\n",
      "\tspeed: 0.0417s/iter; left time: 649.3268s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972967\n",
      "\tspeed: 0.0417s/iter; left time: 644.6283s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052426\n",
      "\tspeed: 0.0417s/iter; left time: 641.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.1110472 Vali Loss: 0.1264536 Test Loss: 0.1413004\n",
      "Validation loss decreased (0.140807 --> 0.126454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090948\n",
      "\tspeed: 0.1191s/iter; left time: 1818.1072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982538\n",
      "\tspeed: 0.0416s/iter; left time: 631.4894s\n",
      "\titers: 300, epoch: 4 | loss: 0.1019681\n",
      "\tspeed: 0.0416s/iter; left time: 627.4270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011304\n",
      "\tspeed: 0.0417s/iter; left time: 623.9304s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932572\n",
      "\tspeed: 0.0417s/iter; left time: 619.6904s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023407\n",
      "\tspeed: 0.0417s/iter; left time: 615.6053s\n",
      "\titers: 700, epoch: 4 | loss: 0.1069069\n",
      "\tspeed: 0.0417s/iter; left time: 611.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006559\n",
      "\tspeed: 0.0417s/iter; left time: 607.7450s\n",
      "\titers: 900, epoch: 4 | loss: 0.0924000\n",
      "\tspeed: 0.0417s/iter; left time: 603.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.1005647 Vali Loss: 0.1294573 Test Loss: 0.1431555\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859475\n",
      "\tspeed: 0.1151s/iter; left time: 1653.0452s\n",
      "\titers: 200, epoch: 5 | loss: 0.0939509\n",
      "\tspeed: 0.0417s/iter; left time: 594.5175s\n",
      "\titers: 300, epoch: 5 | loss: 0.1010361\n",
      "\tspeed: 0.0417s/iter; left time: 590.4591s\n",
      "\titers: 400, epoch: 5 | loss: 0.0910976\n",
      "\tspeed: 0.0417s/iter; left time: 586.6165s\n",
      "\titers: 500, epoch: 5 | loss: 0.0985042\n",
      "\tspeed: 0.0417s/iter; left time: 582.4643s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925515\n",
      "\tspeed: 0.0417s/iter; left time: 578.1049s\n",
      "\titers: 700, epoch: 5 | loss: 0.0912867\n",
      "\tspeed: 0.0417s/iter; left time: 574.5983s\n",
      "\titers: 800, epoch: 5 | loss: 0.0828394\n",
      "\tspeed: 0.0417s/iter; left time: 570.0924s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920023\n",
      "\tspeed: 0.0417s/iter; left time: 565.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.0930013 Vali Loss: 0.1250305 Test Loss: 0.1447869\n",
      "Validation loss decreased (0.126454 --> 0.125030).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0978971\n",
      "\tspeed: 0.1175s/iter; left time: 1581.6357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836452\n",
      "\tspeed: 0.0423s/iter; left time: 564.7488s\n",
      "\titers: 300, epoch: 6 | loss: 0.0813788\n",
      "\tspeed: 0.0423s/iter; left time: 560.4317s\n",
      "\titers: 400, epoch: 6 | loss: 0.0883501\n",
      "\tspeed: 0.0423s/iter; left time: 556.4378s\n",
      "\titers: 500, epoch: 6 | loss: 0.0908173\n",
      "\tspeed: 0.0419s/iter; left time: 547.4124s\n",
      "\titers: 600, epoch: 6 | loss: 0.0855428\n",
      "\tspeed: 0.0417s/iter; left time: 540.3965s\n",
      "\titers: 700, epoch: 6 | loss: 0.0813997\n",
      "\tspeed: 0.0418s/iter; left time: 538.0849s\n",
      "\titers: 800, epoch: 6 | loss: 0.0851901\n",
      "\tspeed: 0.0422s/iter; left time: 538.7857s\n",
      "\titers: 900, epoch: 6 | loss: 0.0928024\n",
      "\tspeed: 0.0422s/iter; left time: 534.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0864959 Vali Loss: 0.1274113 Test Loss: 0.1429392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860452\n",
      "\tspeed: 0.1152s/iter; left time: 1445.9693s\n",
      "\titers: 200, epoch: 7 | loss: 0.0802008\n",
      "\tspeed: 0.0417s/iter; left time: 520.0418s\n",
      "\titers: 300, epoch: 7 | loss: 0.0844645\n",
      "\tspeed: 0.0417s/iter; left time: 515.7681s\n",
      "\titers: 400, epoch: 7 | loss: 0.0800768\n",
      "\tspeed: 0.0417s/iter; left time: 511.2027s\n",
      "\titers: 500, epoch: 7 | loss: 0.0742883\n",
      "\tspeed: 0.0417s/iter; left time: 507.2303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0797856\n",
      "\tspeed: 0.0417s/iter; left time: 502.8343s\n",
      "\titers: 700, epoch: 7 | loss: 0.0820259\n",
      "\tspeed: 0.0417s/iter; left time: 498.4365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776940\n",
      "\tspeed: 0.0417s/iter; left time: 494.1525s\n",
      "\titers: 900, epoch: 7 | loss: 0.0846543\n",
      "\tspeed: 0.0417s/iter; left time: 490.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0810965 Vali Loss: 0.1287853 Test Loss: 0.1496999\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749170\n",
      "\tspeed: 0.1138s/iter; left time: 1326.4466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0768698\n",
      "\tspeed: 0.0416s/iter; left time: 481.0175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0775572\n",
      "\tspeed: 0.0416s/iter; left time: 476.9494s\n",
      "\titers: 400, epoch: 8 | loss: 0.0874197\n",
      "\tspeed: 0.0417s/iter; left time: 473.0103s\n",
      "\titers: 500, epoch: 8 | loss: 0.0777074\n",
      "\tspeed: 0.0417s/iter; left time: 468.9067s\n",
      "\titers: 600, epoch: 8 | loss: 0.0779779\n",
      "\tspeed: 0.0417s/iter; left time: 464.8537s\n",
      "\titers: 700, epoch: 8 | loss: 0.0688209\n",
      "\tspeed: 0.0416s/iter; left time: 460.1467s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773090\n",
      "\tspeed: 0.0416s/iter; left time: 455.8680s\n",
      "\titers: 900, epoch: 8 | loss: 0.0762522\n",
      "\tspeed: 0.0416s/iter; left time: 452.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0761603 Vali Loss: 0.1303706 Test Loss: 0.1481057\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745463\n",
      "\tspeed: 0.1140s/iter; left time: 1225.3924s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718982\n",
      "\tspeed: 0.0417s/iter; left time: 444.2716s\n",
      "\titers: 300, epoch: 9 | loss: 0.0661809\n",
      "\tspeed: 0.0417s/iter; left time: 439.7693s\n",
      "\titers: 400, epoch: 9 | loss: 0.0663692\n",
      "\tspeed: 0.0417s/iter; left time: 435.6156s\n",
      "\titers: 500, epoch: 9 | loss: 0.0759411\n",
      "\tspeed: 0.0417s/iter; left time: 431.6843s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733939\n",
      "\tspeed: 0.0417s/iter; left time: 427.4183s\n",
      "\titers: 700, epoch: 9 | loss: 0.0685498\n",
      "\tspeed: 0.0417s/iter; left time: 423.4725s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660150\n",
      "\tspeed: 0.0417s/iter; left time: 418.9598s\n",
      "\titers: 900, epoch: 9 | loss: 0.0665430\n",
      "\tspeed: 0.0417s/iter; left time: 414.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0720239 Vali Loss: 0.1313181 Test Loss: 0.1486595\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688543\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9525s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704562\n",
      "\tspeed: 0.0416s/iter; left time: 405.8092s\n",
      "\titers: 300, epoch: 10 | loss: 0.0691381\n",
      "\tspeed: 0.0416s/iter; left time: 401.6987s\n",
      "\titers: 400, epoch: 10 | loss: 0.0685972\n",
      "\tspeed: 0.0417s/iter; left time: 397.8337s\n",
      "\titers: 500, epoch: 10 | loss: 0.0678505\n",
      "\tspeed: 0.0417s/iter; left time: 393.6512s\n",
      "\titers: 600, epoch: 10 | loss: 0.0690019\n",
      "\tspeed: 0.0417s/iter; left time: 389.3610s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663853\n",
      "\tspeed: 0.0417s/iter; left time: 385.2586s\n",
      "\titers: 800, epoch: 10 | loss: 0.0663898\n",
      "\tspeed: 0.0417s/iter; left time: 381.0024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0707798\n",
      "\tspeed: 0.0417s/iter; left time: 376.8207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0684217 Vali Loss: 0.1309250 Test Loss: 0.1480408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04497264325618744, rmse:0.21206754446029663, mae:0.14488229155540466, rse:0.7509739995002747\n",
      "Intermediate time for DE and pred_len 96: 00h:13m:48.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2135790\n",
      "\tspeed: 0.0737s/iter; left time: 1322.8469s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131124\n",
      "\tspeed: 0.0512s/iter; left time: 912.6013s\n",
      "\titers: 300, epoch: 1 | loss: 0.1944744\n",
      "\tspeed: 0.0511s/iter; left time: 906.5395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934913\n",
      "\tspeed: 0.0511s/iter; left time: 901.8570s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860318\n",
      "\tspeed: 0.0512s/iter; left time: 898.2652s\n",
      "\titers: 600, epoch: 1 | loss: 0.1891531\n",
      "\tspeed: 0.0507s/iter; left time: 884.7699s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774250\n",
      "\tspeed: 0.0505s/iter; left time: 875.0270s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730052\n",
      "\tspeed: 0.0510s/iter; left time: 878.7949s\n",
      "\titers: 900, epoch: 1 | loss: 0.1795384\n",
      "\tspeed: 0.0510s/iter; left time: 874.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 902 | Train Loss: 0.1965859 Vali Loss: 0.1832028 Test Loss: 0.2074134\n",
      "Validation loss decreased (inf --> 0.183203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704737\n",
      "\tspeed: 0.1414s/iter; left time: 2408.5213s\n",
      "\titers: 200, epoch: 2 | loss: 0.1490840\n",
      "\tspeed: 0.0512s/iter; left time: 866.9052s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521463\n",
      "\tspeed: 0.0511s/iter; left time: 861.3000s\n",
      "\titers: 400, epoch: 2 | loss: 0.1506241\n",
      "\tspeed: 0.0512s/iter; left time: 856.7931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1406512\n",
      "\tspeed: 0.0512s/iter; left time: 851.7499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1345950\n",
      "\tspeed: 0.0512s/iter; left time: 846.4364s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337818\n",
      "\tspeed: 0.0512s/iter; left time: 841.2830s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407173\n",
      "\tspeed: 0.0512s/iter; left time: 835.9682s\n",
      "\titers: 900, epoch: 2 | loss: 0.1290744\n",
      "\tspeed: 0.0512s/iter; left time: 831.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1488273 Vali Loss: 0.1596573 Test Loss: 0.1774935\n",
      "Validation loss decreased (0.183203 --> 0.159657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323122\n",
      "\tspeed: 0.1454s/iter; left time: 2346.2832s\n",
      "\titers: 200, epoch: 3 | loss: 0.1293032\n",
      "\tspeed: 0.0512s/iter; left time: 820.8534s\n",
      "\titers: 300, epoch: 3 | loss: 0.1290850\n",
      "\tspeed: 0.0512s/iter; left time: 815.8447s\n",
      "\titers: 400, epoch: 3 | loss: 0.1349285\n",
      "\tspeed: 0.0512s/iter; left time: 811.2225s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263371\n",
      "\tspeed: 0.0511s/iter; left time: 803.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1262871\n",
      "\tspeed: 0.0510s/iter; left time: 797.6849s\n",
      "\titers: 700, epoch: 3 | loss: 0.1187956\n",
      "\tspeed: 0.0507s/iter; left time: 787.9002s\n",
      "\titers: 800, epoch: 3 | loss: 0.1199932\n",
      "\tspeed: 0.0508s/iter; left time: 784.8815s\n",
      "\titers: 900, epoch: 3 | loss: 0.1152969\n",
      "\tspeed: 0.0510s/iter; left time: 782.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 902 | Train Loss: 0.1267166 Vali Loss: 0.1417985 Test Loss: 0.1600939\n",
      "Validation loss decreased (0.159657 --> 0.141799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117888\n",
      "\tspeed: 0.1424s/iter; left time: 2169.7528s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026877\n",
      "\tspeed: 0.0505s/iter; left time: 763.6327s\n",
      "\titers: 300, epoch: 4 | loss: 0.1014980\n",
      "\tspeed: 0.0506s/iter; left time: 760.6549s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038646\n",
      "\tspeed: 0.0505s/iter; left time: 754.2511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0989735\n",
      "\tspeed: 0.0504s/iter; left time: 747.5785s\n",
      "\titers: 600, epoch: 4 | loss: 0.1064414\n",
      "\tspeed: 0.0504s/iter; left time: 742.2079s\n",
      "\titers: 700, epoch: 4 | loss: 0.0987112\n",
      "\tspeed: 0.0504s/iter; left time: 737.3631s\n",
      "\titers: 800, epoch: 4 | loss: 0.1000495\n",
      "\tspeed: 0.0504s/iter; left time: 732.4440s\n",
      "\titers: 900, epoch: 4 | loss: 0.0978920\n",
      "\tspeed: 0.0504s/iter; left time: 727.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1061221 Vali Loss: 0.1528979 Test Loss: 0.1627806\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918928\n",
      "\tspeed: 0.1384s/iter; left time: 1983.2864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0960290\n",
      "\tspeed: 0.0511s/iter; left time: 727.3949s\n",
      "\titers: 300, epoch: 5 | loss: 0.0931458\n",
      "\tspeed: 0.0512s/iter; left time: 724.2957s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993961\n",
      "\tspeed: 0.0511s/iter; left time: 716.4612s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912344\n",
      "\tspeed: 0.0506s/iter; left time: 704.4801s\n",
      "\titers: 600, epoch: 5 | loss: 0.0892607\n",
      "\tspeed: 0.0505s/iter; left time: 698.8492s\n",
      "\titers: 700, epoch: 5 | loss: 0.0910661\n",
      "\tspeed: 0.0504s/iter; left time: 692.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1011088\n",
      "\tspeed: 0.0505s/iter; left time: 688.4830s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920976\n",
      "\tspeed: 0.0504s/iter; left time: 682.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.0971309 Vali Loss: 0.1423063 Test Loss: 0.1565221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920235\n",
      "\tspeed: 0.1408s/iter; left time: 1890.4647s\n",
      "\titers: 200, epoch: 6 | loss: 0.0922436\n",
      "\tspeed: 0.0511s/iter; left time: 681.2781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902070\n",
      "\tspeed: 0.0511s/iter; left time: 676.7292s\n",
      "\titers: 400, epoch: 6 | loss: 0.0975088\n",
      "\tspeed: 0.0512s/iter; left time: 671.7489s\n",
      "\titers: 500, epoch: 6 | loss: 0.0972495\n",
      "\tspeed: 0.0511s/iter; left time: 666.4803s\n",
      "\titers: 600, epoch: 6 | loss: 0.0895226\n",
      "\tspeed: 0.0511s/iter; left time: 661.3073s\n",
      "\titers: 700, epoch: 6 | loss: 0.0809252\n",
      "\tspeed: 0.0511s/iter; left time: 655.7049s\n",
      "\titers: 800, epoch: 6 | loss: 0.0889638\n",
      "\tspeed: 0.0511s/iter; left time: 651.0962s\n",
      "\titers: 900, epoch: 6 | loss: 0.0874771\n",
      "\tspeed: 0.0511s/iter; left time: 645.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0901457 Vali Loss: 0.1472353 Test Loss: 0.1613897\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832280\n",
      "\tspeed: 0.1385s/iter; left time: 1735.5467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830341\n",
      "\tspeed: 0.0505s/iter; left time: 628.0122s\n",
      "\titers: 300, epoch: 7 | loss: 0.0871024\n",
      "\tspeed: 0.0505s/iter; left time: 622.9652s\n",
      "\titers: 400, epoch: 7 | loss: 0.0823863\n",
      "\tspeed: 0.0505s/iter; left time: 617.8123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869082\n",
      "\tspeed: 0.0506s/iter; left time: 613.9551s\n",
      "\titers: 600, epoch: 7 | loss: 0.0787628\n",
      "\tspeed: 0.0505s/iter; left time: 607.5038s\n",
      "\titers: 700, epoch: 7 | loss: 0.0807302\n",
      "\tspeed: 0.0504s/iter; left time: 601.6845s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859715\n",
      "\tspeed: 0.0505s/iter; left time: 596.9224s\n",
      "\titers: 900, epoch: 7 | loss: 0.0893550\n",
      "\tspeed: 0.0505s/iter; left time: 591.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0839997 Vali Loss: 0.1402461 Test Loss: 0.1580236\n",
      "Validation loss decreased (0.141799 --> 0.140246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807353\n",
      "\tspeed: 0.1480s/iter; left time: 1721.0885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845029\n",
      "\tspeed: 0.0505s/iter; left time: 582.2940s\n",
      "\titers: 300, epoch: 8 | loss: 0.0833175\n",
      "\tspeed: 0.0505s/iter; left time: 577.5719s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774543\n",
      "\tspeed: 0.0504s/iter; left time: 570.9776s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767989\n",
      "\tspeed: 0.0506s/iter; left time: 568.2994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0740711\n",
      "\tspeed: 0.0506s/iter; left time: 562.4822s\n",
      "\titers: 700, epoch: 8 | loss: 0.0755660\n",
      "\tspeed: 0.0506s/iter; left time: 557.9460s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745798\n",
      "\tspeed: 0.0506s/iter; left time: 553.4293s\n",
      "\titers: 900, epoch: 8 | loss: 0.0752394\n",
      "\tspeed: 0.0505s/iter; left time: 546.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.0790876 Vali Loss: 0.1432174 Test Loss: 0.1611511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703514\n",
      "\tspeed: 0.1390s/iter; left time: 1490.3299s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778098\n",
      "\tspeed: 0.0509s/iter; left time: 540.7775s\n",
      "\titers: 300, epoch: 9 | loss: 0.0785731\n",
      "\tspeed: 0.0505s/iter; left time: 531.7624s\n",
      "\titers: 400, epoch: 9 | loss: 0.0750980\n",
      "\tspeed: 0.0506s/iter; left time: 527.9468s\n",
      "\titers: 500, epoch: 9 | loss: 0.0785402\n",
      "\tspeed: 0.0512s/iter; left time: 528.2391s\n",
      "\titers: 600, epoch: 9 | loss: 0.0711287\n",
      "\tspeed: 0.0512s/iter; left time: 523.7596s\n",
      "\titers: 700, epoch: 9 | loss: 0.0769884\n",
      "\tspeed: 0.0513s/iter; left time: 518.9390s\n",
      "\titers: 800, epoch: 9 | loss: 0.0754216\n",
      "\tspeed: 0.0512s/iter; left time: 513.7073s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719022\n",
      "\tspeed: 0.0512s/iter; left time: 508.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.23s\n",
      "Steps: 902 | Train Loss: 0.0748285 Vali Loss: 0.1403084 Test Loss: 0.1591520\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676495\n",
      "\tspeed: 0.1400s/iter; left time: 1375.3179s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732440\n",
      "\tspeed: 0.0512s/iter; left time: 498.0206s\n",
      "\titers: 300, epoch: 10 | loss: 0.0741318\n",
      "\tspeed: 0.0512s/iter; left time: 492.5140s\n",
      "\titers: 400, epoch: 10 | loss: 0.0708465\n",
      "\tspeed: 0.0511s/iter; left time: 486.7042s\n",
      "\titers: 500, epoch: 10 | loss: 0.0714293\n",
      "\tspeed: 0.0512s/iter; left time: 482.4216s\n",
      "\titers: 600, epoch: 10 | loss: 0.0729542\n",
      "\tspeed: 0.0511s/iter; left time: 476.5732s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714578\n",
      "\tspeed: 0.0511s/iter; left time: 471.3907s\n",
      "\titers: 800, epoch: 10 | loss: 0.0682916\n",
      "\tspeed: 0.0511s/iter; left time: 466.2845s\n",
      "\titers: 900, epoch: 10 | loss: 0.0718856\n",
      "\tspeed: 0.0506s/iter; left time: 456.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.0712225 Vali Loss: 0.1423417 Test Loss: 0.1615068\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672577\n",
      "\tspeed: 0.1397s/iter; left time: 1246.3109s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695483\n",
      "\tspeed: 0.0512s/iter; left time: 451.4285s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647759\n",
      "\tspeed: 0.0510s/iter; left time: 445.1117s\n",
      "\titers: 400, epoch: 11 | loss: 0.0645632\n",
      "\tspeed: 0.0510s/iter; left time: 439.9699s\n",
      "\titers: 500, epoch: 11 | loss: 0.0772103\n",
      "\tspeed: 0.0510s/iter; left time: 434.5106s\n",
      "\titers: 600, epoch: 11 | loss: 0.0657790\n",
      "\tspeed: 0.0510s/iter; left time: 429.5179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0685922\n",
      "\tspeed: 0.0507s/iter; left time: 422.0749s\n",
      "\titers: 800, epoch: 11 | loss: 0.0658226\n",
      "\tspeed: 0.0510s/iter; left time: 419.3127s\n",
      "\titers: 900, epoch: 11 | loss: 0.0667105\n",
      "\tspeed: 0.0510s/iter; left time: 414.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.34s\n",
      "Steps: 902 | Train Loss: 0.0681893 Vali Loss: 0.1411986 Test Loss: 0.1595801\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650528\n",
      "\tspeed: 0.1383s/iter; left time: 1108.7168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708718\n",
      "\tspeed: 0.0511s/iter; left time: 404.2901s\n",
      "\titers: 300, epoch: 12 | loss: 0.0652237\n",
      "\tspeed: 0.0506s/iter; left time: 395.8605s\n",
      "\titers: 400, epoch: 12 | loss: 0.0649883\n",
      "\tspeed: 0.0507s/iter; left time: 391.5492s\n",
      "\titers: 500, epoch: 12 | loss: 0.0644263\n",
      "\tspeed: 0.0506s/iter; left time: 385.6037s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660991\n",
      "\tspeed: 0.0506s/iter; left time: 380.4517s\n",
      "\titers: 700, epoch: 12 | loss: 0.0694268\n",
      "\tspeed: 0.0506s/iter; left time: 375.5242s\n",
      "\titers: 800, epoch: 12 | loss: 0.0674071\n",
      "\tspeed: 0.0506s/iter; left time: 370.2007s\n",
      "\titers: 900, epoch: 12 | loss: 0.0676546\n",
      "\tspeed: 0.0506s/iter; left time: 365.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0656815 Vali Loss: 0.1400202 Test Loss: 0.1601845\n",
      "Validation loss decreased (0.140246 --> 0.140020).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625419\n",
      "\tspeed: 0.1435s/iter; left time: 1021.4043s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636671\n",
      "\tspeed: 0.0510s/iter; left time: 357.9900s\n",
      "\titers: 300, epoch: 13 | loss: 0.0667756\n",
      "\tspeed: 0.0510s/iter; left time: 353.0616s\n",
      "\titers: 400, epoch: 13 | loss: 0.0637611\n",
      "\tspeed: 0.0512s/iter; left time: 349.0311s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616729\n",
      "\tspeed: 0.0512s/iter; left time: 344.0386s\n",
      "\titers: 600, epoch: 13 | loss: 0.0642316\n",
      "\tspeed: 0.0509s/iter; left time: 336.7321s\n",
      "\titers: 700, epoch: 13 | loss: 0.0620666\n",
      "\tspeed: 0.0510s/iter; left time: 332.5125s\n",
      "\titers: 800, epoch: 13 | loss: 0.0658408\n",
      "\tspeed: 0.0513s/iter; left time: 328.8980s\n",
      "\titers: 900, epoch: 13 | loss: 0.0617386\n",
      "\tspeed: 0.0513s/iter; left time: 323.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 902 | Train Loss: 0.0634137 Vali Loss: 0.1419839 Test Loss: 0.1631894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0585671\n",
      "\tspeed: 0.1396s/iter; left time: 867.4336s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664492\n",
      "\tspeed: 0.0506s/iter; left time: 309.6088s\n",
      "\titers: 300, epoch: 14 | loss: 0.0629691\n",
      "\tspeed: 0.0507s/iter; left time: 304.6759s\n",
      "\titers: 400, epoch: 14 | loss: 0.0620267\n",
      "\tspeed: 0.0507s/iter; left time: 299.7290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0623624\n",
      "\tspeed: 0.0507s/iter; left time: 294.8488s\n",
      "\titers: 600, epoch: 14 | loss: 0.0619973\n",
      "\tspeed: 0.0506s/iter; left time: 289.3720s\n",
      "\titers: 700, epoch: 14 | loss: 0.0618283\n",
      "\tspeed: 0.0508s/iter; left time: 285.1200s\n",
      "\titers: 800, epoch: 14 | loss: 0.0577629\n",
      "\tspeed: 0.0511s/iter; left time: 281.8709s\n",
      "\titers: 900, epoch: 14 | loss: 0.0643250\n",
      "\tspeed: 0.0512s/iter; left time: 277.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.10s\n",
      "Steps: 902 | Train Loss: 0.0616388 Vali Loss: 0.1407283 Test Loss: 0.1611458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597400\n",
      "\tspeed: 0.1409s/iter; left time: 748.5759s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610378\n",
      "\tspeed: 0.0513s/iter; left time: 267.3372s\n",
      "\titers: 300, epoch: 15 | loss: 0.0592156\n",
      "\tspeed: 0.0513s/iter; left time: 262.3524s\n",
      "\titers: 400, epoch: 15 | loss: 0.0588845\n",
      "\tspeed: 0.0513s/iter; left time: 257.2757s\n",
      "\titers: 500, epoch: 15 | loss: 0.0618582\n",
      "\tspeed: 0.0513s/iter; left time: 251.8946s\n",
      "\titers: 600, epoch: 15 | loss: 0.0604138\n",
      "\tspeed: 0.0513s/iter; left time: 246.7312s\n",
      "\titers: 700, epoch: 15 | loss: 0.0605271\n",
      "\tspeed: 0.0513s/iter; left time: 241.7580s\n",
      "\titers: 800, epoch: 15 | loss: 0.0604768\n",
      "\tspeed: 0.0513s/iter; left time: 236.5873s\n",
      "\titers: 900, epoch: 15 | loss: 0.0590711\n",
      "\tspeed: 0.0513s/iter; left time: 231.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.0600248 Vali Loss: 0.1428889 Test Loss: 0.1618677\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0612130\n",
      "\tspeed: 0.1387s/iter; left time: 611.8801s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578973\n",
      "\tspeed: 0.0506s/iter; left time: 218.1125s\n",
      "\titers: 300, epoch: 16 | loss: 0.0590760\n",
      "\tspeed: 0.0507s/iter; left time: 213.3454s\n",
      "\titers: 400, epoch: 16 | loss: 0.0539181\n",
      "\tspeed: 0.0506s/iter; left time: 208.1322s\n",
      "\titers: 500, epoch: 16 | loss: 0.0605631\n",
      "\tspeed: 0.0507s/iter; left time: 203.3086s\n",
      "\titers: 600, epoch: 16 | loss: 0.0602342\n",
      "\tspeed: 0.0506s/iter; left time: 197.8721s\n",
      "\titers: 700, epoch: 16 | loss: 0.0567739\n",
      "\tspeed: 0.0506s/iter; left time: 192.9792s\n",
      "\titers: 800, epoch: 16 | loss: 0.0596344\n",
      "\tspeed: 0.0506s/iter; left time: 187.9486s\n",
      "\titers: 900, epoch: 16 | loss: 0.0615203\n",
      "\tspeed: 0.0506s/iter; left time: 182.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 902 | Train Loss: 0.0586482 Vali Loss: 0.1421482 Test Loss: 0.1612585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595209\n",
      "\tspeed: 0.1391s/iter; left time: 488.1010s\n",
      "\titers: 200, epoch: 17 | loss: 0.0596009\n",
      "\tspeed: 0.0504s/iter; left time: 171.6961s\n",
      "\titers: 300, epoch: 17 | loss: 0.0585621\n",
      "\tspeed: 0.0504s/iter; left time: 166.7300s\n",
      "\titers: 400, epoch: 17 | loss: 0.0652123\n",
      "\tspeed: 0.0504s/iter; left time: 161.8197s\n",
      "\titers: 500, epoch: 17 | loss: 0.0540461\n",
      "\tspeed: 0.0505s/iter; left time: 157.0520s\n",
      "\titers: 600, epoch: 17 | loss: 0.0559000\n",
      "\tspeed: 0.0506s/iter; left time: 152.3226s\n",
      "\titers: 700, epoch: 17 | loss: 0.0554206\n",
      "\tspeed: 0.0506s/iter; left time: 147.2073s\n",
      "\titers: 800, epoch: 17 | loss: 0.0559492\n",
      "\tspeed: 0.0506s/iter; left time: 142.2411s\n",
      "\titers: 900, epoch: 17 | loss: 0.0555495\n",
      "\tspeed: 0.0507s/iter; left time: 137.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 902 | Train Loss: 0.0575157 Vali Loss: 0.1406434 Test Loss: 0.1615269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05564524605870247, rmse:0.23589244484901428, mae:0.16008244454860687, rse:0.8356959223747253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2329182\n",
      "\tspeed: 0.0528s/iter; left time: 947.6494s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172202\n",
      "\tspeed: 0.0507s/iter; left time: 904.7054s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961658\n",
      "\tspeed: 0.0507s/iter; left time: 899.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1850062\n",
      "\tspeed: 0.0507s/iter; left time: 895.1299s\n",
      "\titers: 500, epoch: 1 | loss: 0.1870918\n",
      "\tspeed: 0.0508s/iter; left time: 890.3390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1944518\n",
      "\tspeed: 0.0506s/iter; left time: 882.1736s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783303\n",
      "\tspeed: 0.0506s/iter; left time: 876.9964s\n",
      "\titers: 800, epoch: 1 | loss: 0.1759333\n",
      "\tspeed: 0.0505s/iter; left time: 871.0565s\n",
      "\titers: 900, epoch: 1 | loss: 0.1763727\n",
      "\tspeed: 0.0506s/iter; left time: 867.0226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.1973616 Vali Loss: 0.1830743 Test Loss: 0.2059395\n",
      "Validation loss decreased (inf --> 0.183074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503127\n",
      "\tspeed: 0.1421s/iter; left time: 2420.4738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512766\n",
      "\tspeed: 0.0506s/iter; left time: 857.6590s\n",
      "\titers: 300, epoch: 2 | loss: 0.1382957\n",
      "\tspeed: 0.0506s/iter; left time: 852.5279s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341342\n",
      "\tspeed: 0.0506s/iter; left time: 847.7158s\n",
      "\titers: 500, epoch: 2 | loss: 0.1374097\n",
      "\tspeed: 0.0506s/iter; left time: 842.4117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1432593\n",
      "\tspeed: 0.0505s/iter; left time: 834.9621s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279730\n",
      "\tspeed: 0.0504s/iter; left time: 828.2137s\n",
      "\titers: 800, epoch: 2 | loss: 0.1409557\n",
      "\tspeed: 0.0504s/iter; left time: 823.0514s\n",
      "\titers: 900, epoch: 2 | loss: 0.1172102\n",
      "\tspeed: 0.0504s/iter; left time: 818.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 902 | Train Loss: 0.1439408 Vali Loss: 0.1546091 Test Loss: 0.1715550\n",
      "Validation loss decreased (0.183074 --> 0.154609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1301890\n",
      "\tspeed: 0.1410s/iter; left time: 2275.0167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247176\n",
      "\tspeed: 0.0505s/iter; left time: 809.6763s\n",
      "\titers: 300, epoch: 3 | loss: 0.1338786\n",
      "\tspeed: 0.0507s/iter; left time: 807.7225s\n",
      "\titers: 400, epoch: 3 | loss: 0.1215102\n",
      "\tspeed: 0.0507s/iter; left time: 802.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1196253\n",
      "\tspeed: 0.0507s/iter; left time: 797.5365s\n",
      "\titers: 600, epoch: 3 | loss: 0.1286701\n",
      "\tspeed: 0.0504s/iter; left time: 787.8341s\n",
      "\titers: 700, epoch: 3 | loss: 0.1157779\n",
      "\tspeed: 0.0504s/iter; left time: 782.7377s\n",
      "\titers: 800, epoch: 3 | loss: 0.1232034\n",
      "\tspeed: 0.0504s/iter; left time: 778.3771s\n",
      "\titers: 900, epoch: 3 | loss: 0.1138987\n",
      "\tspeed: 0.0504s/iter; left time: 773.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.1216343 Vali Loss: 0.1383445 Test Loss: 0.1558911\n",
      "Validation loss decreased (0.154609 --> 0.138345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097272\n",
      "\tspeed: 0.1400s/iter; left time: 2132.6516s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003548\n",
      "\tspeed: 0.0504s/iter; left time: 763.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034977\n",
      "\tspeed: 0.0504s/iter; left time: 757.4019s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083793\n",
      "\tspeed: 0.0504s/iter; left time: 752.3880s\n",
      "\titers: 500, epoch: 4 | loss: 0.1005158\n",
      "\tspeed: 0.0504s/iter; left time: 747.7124s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054492\n",
      "\tspeed: 0.0504s/iter; left time: 742.8598s\n",
      "\titers: 700, epoch: 4 | loss: 0.1030866\n",
      "\tspeed: 0.0504s/iter; left time: 737.7559s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006965\n",
      "\tspeed: 0.0504s/iter; left time: 732.9385s\n",
      "\titers: 900, epoch: 4 | loss: 0.1023383\n",
      "\tspeed: 0.0505s/iter; left time: 728.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.1054264 Vali Loss: 0.1426753 Test Loss: 0.1533596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043797\n",
      "\tspeed: 0.1380s/iter; left time: 1978.4526s\n",
      "\titers: 200, epoch: 5 | loss: 0.1015226\n",
      "\tspeed: 0.0506s/iter; left time: 719.8159s\n",
      "\titers: 300, epoch: 5 | loss: 0.1025427\n",
      "\tspeed: 0.0506s/iter; left time: 715.4537s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976157\n",
      "\tspeed: 0.0505s/iter; left time: 708.6062s\n",
      "\titers: 500, epoch: 5 | loss: 0.0992124\n",
      "\tspeed: 0.0506s/iter; left time: 704.4007s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925273\n",
      "\tspeed: 0.0505s/iter; left time: 698.1557s\n",
      "\titers: 700, epoch: 5 | loss: 0.0902019\n",
      "\tspeed: 0.0506s/iter; left time: 694.8242s\n",
      "\titers: 800, epoch: 5 | loss: 0.0899991\n",
      "\tspeed: 0.0505s/iter; left time: 688.3376s\n",
      "\titers: 900, epoch: 5 | loss: 0.0957246\n",
      "\tspeed: 0.0505s/iter; left time: 683.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0968106 Vali Loss: 0.1373353 Test Loss: 0.1569665\n",
      "Validation loss decreased (0.138345 --> 0.137335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0971396\n",
      "\tspeed: 0.1410s/iter; left time: 1893.4415s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877258\n",
      "\tspeed: 0.0505s/iter; left time: 673.6076s\n",
      "\titers: 300, epoch: 6 | loss: 0.0944563\n",
      "\tspeed: 0.0505s/iter; left time: 668.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0953016\n",
      "\tspeed: 0.0505s/iter; left time: 663.6332s\n",
      "\titers: 500, epoch: 6 | loss: 0.0904507\n",
      "\tspeed: 0.0506s/iter; left time: 658.7336s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920923\n",
      "\tspeed: 0.0507s/iter; left time: 655.0894s\n",
      "\titers: 700, epoch: 6 | loss: 0.0855336\n",
      "\tspeed: 0.0506s/iter; left time: 649.2819s\n",
      "\titers: 800, epoch: 6 | loss: 0.0849263\n",
      "\tspeed: 0.0507s/iter; left time: 645.0929s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849293\n",
      "\tspeed: 0.0505s/iter; left time: 638.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 902 | Train Loss: 0.0900812 Vali Loss: 0.1398693 Test Loss: 0.1587747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829473\n",
      "\tspeed: 0.1391s/iter; left time: 1742.6588s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794557\n",
      "\tspeed: 0.0507s/iter; left time: 630.6465s\n",
      "\titers: 300, epoch: 7 | loss: 0.0834720\n",
      "\tspeed: 0.0507s/iter; left time: 625.3873s\n",
      "\titers: 400, epoch: 7 | loss: 0.0812156\n",
      "\tspeed: 0.0507s/iter; left time: 620.2857s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828412\n",
      "\tspeed: 0.0507s/iter; left time: 614.8473s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856180\n",
      "\tspeed: 0.0506s/iter; left time: 609.1617s\n",
      "\titers: 700, epoch: 7 | loss: 0.0841857\n",
      "\tspeed: 0.0507s/iter; left time: 604.2357s\n",
      "\titers: 800, epoch: 7 | loss: 0.0855514\n",
      "\tspeed: 0.0506s/iter; left time: 598.9587s\n",
      "\titers: 900, epoch: 7 | loss: 0.0821454\n",
      "\tspeed: 0.0507s/iter; left time: 594.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0844364 Vali Loss: 0.1380800 Test Loss: 0.1562963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792243\n",
      "\tspeed: 0.1383s/iter; left time: 1607.5268s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758932\n",
      "\tspeed: 0.0506s/iter; left time: 583.1025s\n",
      "\titers: 300, epoch: 8 | loss: 0.0826427\n",
      "\tspeed: 0.0506s/iter; left time: 578.4702s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799903\n",
      "\tspeed: 0.0506s/iter; left time: 573.5689s\n",
      "\titers: 500, epoch: 8 | loss: 0.0791600\n",
      "\tspeed: 0.0504s/iter; left time: 565.6440s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825389\n",
      "\tspeed: 0.0505s/iter; left time: 562.1391s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792387\n",
      "\tspeed: 0.0506s/iter; left time: 557.6783s\n",
      "\titers: 800, epoch: 8 | loss: 0.0800074\n",
      "\tspeed: 0.0504s/iter; left time: 551.0006s\n",
      "\titers: 900, epoch: 8 | loss: 0.0764232\n",
      "\tspeed: 0.0504s/iter; left time: 545.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0794340 Vali Loss: 0.1406030 Test Loss: 0.1605993\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766746\n",
      "\tspeed: 0.1381s/iter; left time: 1481.6013s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807511\n",
      "\tspeed: 0.0505s/iter; left time: 536.5790s\n",
      "\titers: 300, epoch: 9 | loss: 0.0721841\n",
      "\tspeed: 0.0507s/iter; left time: 533.2897s\n",
      "\titers: 400, epoch: 9 | loss: 0.0782305\n",
      "\tspeed: 0.0507s/iter; left time: 528.4923s\n",
      "\titers: 500, epoch: 9 | loss: 0.0747176\n",
      "\tspeed: 0.0507s/iter; left time: 523.3335s\n",
      "\titers: 600, epoch: 9 | loss: 0.0727979\n",
      "\tspeed: 0.0507s/iter; left time: 518.3577s\n",
      "\titers: 700, epoch: 9 | loss: 0.0737757\n",
      "\tspeed: 0.0507s/iter; left time: 513.0490s\n",
      "\titers: 800, epoch: 9 | loss: 0.0740445\n",
      "\tspeed: 0.0506s/iter; left time: 506.9854s\n",
      "\titers: 900, epoch: 9 | loss: 0.0758738\n",
      "\tspeed: 0.0506s/iter; left time: 501.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 902 | Train Loss: 0.0753867 Vali Loss: 0.1409122 Test Loss: 0.1620111\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738081\n",
      "\tspeed: 0.1402s/iter; left time: 1377.4754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753992\n",
      "\tspeed: 0.0515s/iter; left time: 500.3210s\n",
      "\titers: 300, epoch: 10 | loss: 0.0722770\n",
      "\tspeed: 0.0515s/iter; left time: 495.7508s\n",
      "\titers: 400, epoch: 10 | loss: 0.0743530\n",
      "\tspeed: 0.0511s/iter; left time: 486.2793s\n",
      "\titers: 500, epoch: 10 | loss: 0.0718583\n",
      "\tspeed: 0.0510s/iter; left time: 481.0144s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755678\n",
      "\tspeed: 0.0511s/iter; left time: 476.3854s\n",
      "\titers: 700, epoch: 10 | loss: 0.0725444\n",
      "\tspeed: 0.0510s/iter; left time: 470.1557s\n",
      "\titers: 800, epoch: 10 | loss: 0.0725415\n",
      "\tspeed: 0.0507s/iter; left time: 462.4133s\n",
      "\titers: 900, epoch: 10 | loss: 0.0698420\n",
      "\tspeed: 0.0507s/iter; left time: 457.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0718391 Vali Loss: 0.1405233 Test Loss: 0.1635022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.051229722797870636, rmse:0.22633983194828033, mae:0.1569782793521881, rse:0.8018538951873779\n",
      "Intermediate time for DE and pred_len 168: 00h:24m:56.06s\n",
      "Intermediate time for DE: 00h:56m:17.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2065667\n",
      "\tspeed: 0.0585s/iter; left time: 1055.0276s\n",
      "\titers: 200, epoch: 1 | loss: 0.1898771\n",
      "\tspeed: 0.0340s/iter; left time: 608.9094s\n",
      "\titers: 300, epoch: 1 | loss: 0.1781441\n",
      "\tspeed: 0.0339s/iter; left time: 604.1571s\n",
      "\titers: 400, epoch: 1 | loss: 0.1769260\n",
      "\tspeed: 0.0339s/iter; left time: 601.0270s\n",
      "\titers: 500, epoch: 1 | loss: 0.1623933\n",
      "\tspeed: 0.0340s/iter; left time: 598.4446s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630156\n",
      "\tspeed: 0.0340s/iter; left time: 594.9816s\n",
      "\titers: 700, epoch: 1 | loss: 0.1549021\n",
      "\tspeed: 0.0339s/iter; left time: 591.3637s\n",
      "\titers: 800, epoch: 1 | loss: 0.1450832\n",
      "\tspeed: 0.0340s/iter; left time: 588.7659s\n",
      "\titers: 900, epoch: 1 | loss: 0.1431629\n",
      "\tspeed: 0.0340s/iter; left time: 585.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.1802093 Vali Loss: 0.1521474 Test Loss: 0.1806995\n",
      "Validation loss decreased (inf --> 0.152147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1379461\n",
      "\tspeed: 0.1024s/iter; left time: 1752.2041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1183134\n",
      "\tspeed: 0.0340s/iter; left time: 578.6834s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016329\n",
      "\tspeed: 0.0340s/iter; left time: 575.0825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1114180\n",
      "\tspeed: 0.0340s/iter; left time: 571.9411s\n",
      "\titers: 500, epoch: 2 | loss: 0.1128901\n",
      "\tspeed: 0.0340s/iter; left time: 568.0567s\n",
      "\titers: 600, epoch: 2 | loss: 0.0933868\n",
      "\tspeed: 0.0340s/iter; left time: 565.0899s\n",
      "\titers: 700, epoch: 2 | loss: 0.1148216\n",
      "\tspeed: 0.0340s/iter; left time: 562.1364s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128488\n",
      "\tspeed: 0.0340s/iter; left time: 558.8138s\n",
      "\titers: 900, epoch: 2 | loss: 0.0961874\n",
      "\tspeed: 0.0340s/iter; left time: 555.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.1125205 Vali Loss: 0.1164644 Test Loss: 0.1396194\n",
      "Validation loss decreased (0.152147 --> 0.116464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1032601\n",
      "\tspeed: 0.0965s/iter; left time: 1563.8764s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003233\n",
      "\tspeed: 0.0340s/iter; left time: 548.0625s\n",
      "\titers: 300, epoch: 3 | loss: 0.1062481\n",
      "\tspeed: 0.0340s/iter; left time: 544.6023s\n",
      "\titers: 400, epoch: 3 | loss: 0.0953404\n",
      "\tspeed: 0.0340s/iter; left time: 541.1076s\n",
      "\titers: 500, epoch: 3 | loss: 0.0999686\n",
      "\tspeed: 0.0340s/iter; left time: 538.0603s\n",
      "\titers: 600, epoch: 3 | loss: 0.0992506\n",
      "\tspeed: 0.0340s/iter; left time: 534.1618s\n",
      "\titers: 700, epoch: 3 | loss: 0.0999163\n",
      "\tspeed: 0.0340s/iter; left time: 531.0028s\n",
      "\titers: 800, epoch: 3 | loss: 0.0913728\n",
      "\tspeed: 0.0340s/iter; left time: 527.7707s\n",
      "\titers: 900, epoch: 3 | loss: 0.1034245\n",
      "\tspeed: 0.0340s/iter; left time: 524.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0998791 Vali Loss: 0.1129812 Test Loss: 0.1356770\n",
      "Validation loss decreased (0.116464 --> 0.112981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897522\n",
      "\tspeed: 0.0980s/iter; left time: 1499.8458s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064864\n",
      "\tspeed: 0.0346s/iter; left time: 526.4130s\n",
      "\titers: 300, epoch: 4 | loss: 0.0940685\n",
      "\tspeed: 0.0343s/iter; left time: 518.5255s\n",
      "\titers: 400, epoch: 4 | loss: 0.1048222\n",
      "\tspeed: 0.0341s/iter; left time: 511.0756s\n",
      "\titers: 500, epoch: 4 | loss: 0.1119908\n",
      "\tspeed: 0.0341s/iter; left time: 508.0281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1028988\n",
      "\tspeed: 0.0341s/iter; left time: 504.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.0919001\n",
      "\tspeed: 0.0341s/iter; left time: 501.7008s\n",
      "\titers: 800, epoch: 4 | loss: 0.0971707\n",
      "\tspeed: 0.0341s/iter; left time: 497.9438s\n",
      "\titers: 900, epoch: 4 | loss: 0.0936811\n",
      "\tspeed: 0.0341s/iter; left time: 494.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 906 | Train Loss: 0.0970638 Vali Loss: 0.1139413 Test Loss: 0.1345681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1065073\n",
      "\tspeed: 0.0945s/iter; left time: 1360.9809s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901787\n",
      "\tspeed: 0.0340s/iter; left time: 486.4075s\n",
      "\titers: 300, epoch: 5 | loss: 0.0899963\n",
      "\tspeed: 0.0340s/iter; left time: 483.3176s\n",
      "\titers: 400, epoch: 5 | loss: 0.1047166\n",
      "\tspeed: 0.0340s/iter; left time: 479.6122s\n",
      "\titers: 500, epoch: 5 | loss: 0.0848665\n",
      "\tspeed: 0.0340s/iter; left time: 476.0220s\n",
      "\titers: 600, epoch: 5 | loss: 0.0877800\n",
      "\tspeed: 0.0341s/iter; left time: 473.3804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0995184\n",
      "\tspeed: 0.0340s/iter; left time: 469.2897s\n",
      "\titers: 800, epoch: 5 | loss: 0.1012287\n",
      "\tspeed: 0.0340s/iter; left time: 466.3292s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855802\n",
      "\tspeed: 0.0341s/iter; left time: 463.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0934970 Vali Loss: 0.1173672 Test Loss: 0.1402675\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0928552\n",
      "\tspeed: 0.0936s/iter; left time: 1262.0840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0989584\n",
      "\tspeed: 0.0341s/iter; left time: 456.0414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907293\n",
      "\tspeed: 0.0341s/iter; left time: 453.4878s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939442\n",
      "\tspeed: 0.0341s/iter; left time: 449.2852s\n",
      "\titers: 500, epoch: 6 | loss: 0.0951724\n",
      "\tspeed: 0.0341s/iter; left time: 446.5104s\n",
      "\titers: 600, epoch: 6 | loss: 0.0863666\n",
      "\tspeed: 0.0341s/iter; left time: 442.9592s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910364\n",
      "\tspeed: 0.0341s/iter; left time: 439.9638s\n",
      "\titers: 800, epoch: 6 | loss: 0.0822814\n",
      "\tspeed: 0.0341s/iter; left time: 436.3053s\n",
      "\titers: 900, epoch: 6 | loss: 0.0938590\n",
      "\tspeed: 0.0341s/iter; left time: 433.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0908272 Vali Loss: 0.1192106 Test Loss: 0.1453762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746693\n",
      "\tspeed: 0.0942s/iter; left time: 1185.1489s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773950\n",
      "\tspeed: 0.0341s/iter; left time: 426.2154s\n",
      "\titers: 300, epoch: 7 | loss: 0.0814477\n",
      "\tspeed: 0.0341s/iter; left time: 421.8661s\n",
      "\titers: 400, epoch: 7 | loss: 0.0867475\n",
      "\tspeed: 0.0341s/iter; left time: 418.9123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766155\n",
      "\tspeed: 0.0341s/iter; left time: 415.1243s\n",
      "\titers: 600, epoch: 7 | loss: 0.0661413\n",
      "\tspeed: 0.0341s/iter; left time: 411.8718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0771113\n",
      "\tspeed: 0.0340s/iter; left time: 408.0494s\n",
      "\titers: 800, epoch: 7 | loss: 0.0708948\n",
      "\tspeed: 0.0341s/iter; left time: 404.7029s\n",
      "\titers: 900, epoch: 7 | loss: 0.0775627\n",
      "\tspeed: 0.0341s/iter; left time: 401.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0792233 Vali Loss: 0.1053339 Test Loss: 0.1323265\n",
      "Validation loss decreased (0.112981 --> 0.105334).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742684\n",
      "\tspeed: 0.0994s/iter; left time: 1160.8595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691775\n",
      "\tspeed: 0.0342s/iter; left time: 395.4680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0811470\n",
      "\tspeed: 0.0342s/iter; left time: 392.3738s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708296\n",
      "\tspeed: 0.0341s/iter; left time: 387.5259s\n",
      "\titers: 500, epoch: 8 | loss: 0.0749293\n",
      "\tspeed: 0.0341s/iter; left time: 384.5004s\n",
      "\titers: 600, epoch: 8 | loss: 0.0783654\n",
      "\tspeed: 0.0341s/iter; left time: 381.4007s\n",
      "\titers: 700, epoch: 8 | loss: 0.0806148\n",
      "\tspeed: 0.0341s/iter; left time: 378.3309s\n",
      "\titers: 800, epoch: 8 | loss: 0.0710718\n",
      "\tspeed: 0.0341s/iter; left time: 374.6150s\n",
      "\titers: 900, epoch: 8 | loss: 0.0672735\n",
      "\tspeed: 0.0341s/iter; left time: 371.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0752110 Vali Loss: 0.1059797 Test Loss: 0.1272185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0764559\n",
      "\tspeed: 0.0936s/iter; left time: 1008.6992s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805175\n",
      "\tspeed: 0.0341s/iter; left time: 364.3434s\n",
      "\titers: 300, epoch: 9 | loss: 0.0701884\n",
      "\tspeed: 0.0341s/iter; left time: 360.6060s\n",
      "\titers: 400, epoch: 9 | loss: 0.0753982\n",
      "\tspeed: 0.0341s/iter; left time: 357.3582s\n",
      "\titers: 500, epoch: 9 | loss: 0.0740065\n",
      "\tspeed: 0.0341s/iter; left time: 353.8814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0621589\n",
      "\tspeed: 0.0341s/iter; left time: 350.4821s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747598\n",
      "\tspeed: 0.0341s/iter; left time: 347.1544s\n",
      "\titers: 800, epoch: 9 | loss: 0.0816423\n",
      "\tspeed: 0.0342s/iter; left time: 344.0571s\n",
      "\titers: 900, epoch: 9 | loss: 0.0695066\n",
      "\tspeed: 0.0341s/iter; left time: 339.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0726019 Vali Loss: 0.1069399 Test Loss: 0.1331095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704984\n",
      "\tspeed: 0.0937s/iter; left time: 924.1009s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701090\n",
      "\tspeed: 0.0341s/iter; left time: 332.8216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0659057\n",
      "\tspeed: 0.0341s/iter; left time: 329.1772s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728105\n",
      "\tspeed: 0.0340s/iter; left time: 325.6335s\n",
      "\titers: 500, epoch: 10 | loss: 0.0748692\n",
      "\tspeed: 0.0341s/iter; left time: 322.9291s\n",
      "\titers: 600, epoch: 10 | loss: 0.0678749\n",
      "\tspeed: 0.0341s/iter; left time: 319.4862s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699628\n",
      "\tspeed: 0.0341s/iter; left time: 315.9728s\n",
      "\titers: 800, epoch: 10 | loss: 0.0634394\n",
      "\tspeed: 0.0341s/iter; left time: 312.2789s\n",
      "\titers: 900, epoch: 10 | loss: 0.0716516\n",
      "\tspeed: 0.0341s/iter; left time: 309.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0698472 Vali Loss: 0.0994613 Test Loss: 0.1233056\n",
      "Validation loss decreased (0.105334 --> 0.099461).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0626306\n",
      "\tspeed: 0.0962s/iter; left time: 861.7134s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640720\n",
      "\tspeed: 0.0340s/iter; left time: 301.5909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0588703\n",
      "\tspeed: 0.0341s/iter; left time: 298.7134s\n",
      "\titers: 400, epoch: 11 | loss: 0.0595044\n",
      "\tspeed: 0.0340s/iter; left time: 294.7817s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624516\n",
      "\tspeed: 0.0341s/iter; left time: 291.5805s\n",
      "\titers: 600, epoch: 11 | loss: 0.0580348\n",
      "\tspeed: 0.0340s/iter; left time: 287.6216s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642682\n",
      "\tspeed: 0.0341s/iter; left time: 285.1872s\n",
      "\titers: 800, epoch: 11 | loss: 0.0618705\n",
      "\tspeed: 0.0341s/iter; left time: 281.5465s\n",
      "\titers: 900, epoch: 11 | loss: 0.0543362\n",
      "\tspeed: 0.0340s/iter; left time: 277.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0620900 Vali Loss: 0.1001814 Test Loss: 0.1275305\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608115\n",
      "\tspeed: 0.0933s/iter; left time: 751.3224s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623593\n",
      "\tspeed: 0.0341s/iter; left time: 270.8942s\n",
      "\titers: 300, epoch: 12 | loss: 0.0562274\n",
      "\tspeed: 0.0341s/iter; left time: 268.0192s\n",
      "\titers: 400, epoch: 12 | loss: 0.0648748\n",
      "\tspeed: 0.0341s/iter; left time: 264.4116s\n",
      "\titers: 500, epoch: 12 | loss: 0.0535899\n",
      "\tspeed: 0.0341s/iter; left time: 260.6790s\n",
      "\titers: 600, epoch: 12 | loss: 0.0538404\n",
      "\tspeed: 0.0341s/iter; left time: 257.2894s\n",
      "\titers: 700, epoch: 12 | loss: 0.0548301\n",
      "\tspeed: 0.0341s/iter; left time: 254.1875s\n",
      "\titers: 800, epoch: 12 | loss: 0.0514138\n",
      "\tspeed: 0.0340s/iter; left time: 250.2762s\n",
      "\titers: 900, epoch: 12 | loss: 0.0655189\n",
      "\tspeed: 0.0341s/iter; left time: 247.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0597273 Vali Loss: 0.1036253 Test Loss: 0.1352557\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0566351\n",
      "\tspeed: 0.0941s/iter; left time: 673.0170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536230\n",
      "\tspeed: 0.0341s/iter; left time: 240.1297s\n",
      "\titers: 300, epoch: 13 | loss: 0.0634737\n",
      "\tspeed: 0.0341s/iter; left time: 237.0724s\n",
      "\titers: 400, epoch: 13 | loss: 0.0572632\n",
      "\tspeed: 0.0340s/iter; left time: 233.1244s\n",
      "\titers: 500, epoch: 13 | loss: 0.0540060\n",
      "\tspeed: 0.0341s/iter; left time: 229.8116s\n",
      "\titers: 600, epoch: 13 | loss: 0.0529787\n",
      "\tspeed: 0.0341s/iter; left time: 226.9394s\n",
      "\titers: 700, epoch: 13 | loss: 0.0610991\n",
      "\tspeed: 0.0341s/iter; left time: 223.1880s\n",
      "\titers: 800, epoch: 13 | loss: 0.0578308\n",
      "\tspeed: 0.0341s/iter; left time: 219.6118s\n",
      "\titers: 900, epoch: 13 | loss: 0.0553324\n",
      "\tspeed: 0.0341s/iter; left time: 216.2252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0578906 Vali Loss: 0.1017295 Test Loss: 0.1305108\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0616051\n",
      "\tspeed: 0.0943s/iter; left time: 588.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553820\n",
      "\tspeed: 0.0342s/iter; left time: 209.7892s\n",
      "\titers: 300, epoch: 14 | loss: 0.0544165\n",
      "\tspeed: 0.0342s/iter; left time: 206.4339s\n",
      "\titers: 400, epoch: 14 | loss: 0.0571011\n",
      "\tspeed: 0.0341s/iter; left time: 202.7012s\n",
      "\titers: 500, epoch: 14 | loss: 0.0607028\n",
      "\tspeed: 0.0341s/iter; left time: 199.2424s\n",
      "\titers: 600, epoch: 14 | loss: 0.0542016\n",
      "\tspeed: 0.0341s/iter; left time: 195.8150s\n",
      "\titers: 700, epoch: 14 | loss: 0.0561629\n",
      "\tspeed: 0.0342s/iter; left time: 192.8704s\n",
      "\titers: 800, epoch: 14 | loss: 0.0597202\n",
      "\tspeed: 0.0341s/iter; left time: 189.0456s\n",
      "\titers: 900, epoch: 14 | loss: 0.0638149\n",
      "\tspeed: 0.0342s/iter; left time: 186.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.25s\n",
      "Steps: 906 | Train Loss: 0.0560134 Vali Loss: 0.1008903 Test Loss: 0.1284106\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531591\n",
      "\tspeed: 0.0942s/iter; left time: 502.6085s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574485\n",
      "\tspeed: 0.0341s/iter; left time: 178.4678s\n",
      "\titers: 300, epoch: 15 | loss: 0.0499670\n",
      "\tspeed: 0.0341s/iter; left time: 175.3850s\n",
      "\titers: 400, epoch: 15 | loss: 0.0561084\n",
      "\tspeed: 0.0342s/iter; left time: 172.0325s\n",
      "\titers: 500, epoch: 15 | loss: 0.0534714\n",
      "\tspeed: 0.0342s/iter; left time: 168.7018s\n",
      "\titers: 600, epoch: 15 | loss: 0.0518036\n",
      "\tspeed: 0.0341s/iter; left time: 165.0023s\n",
      "\titers: 700, epoch: 15 | loss: 0.0593414\n",
      "\tspeed: 0.0341s/iter; left time: 161.5421s\n",
      "\titers: 800, epoch: 15 | loss: 0.0531404\n",
      "\tspeed: 0.0341s/iter; left time: 158.3529s\n",
      "\titers: 900, epoch: 15 | loss: 0.0592867\n",
      "\tspeed: 0.0341s/iter; left time: 154.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0546766 Vali Loss: 0.1010287 Test Loss: 0.1288189\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03368111699819565, rmse:0.18352416157722473, mae:0.12335905432701111, rse:0.6327870488166809\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2087424\n",
      "\tspeed: 0.0362s/iter; left time: 652.4385s\n",
      "\titers: 200, epoch: 1 | loss: 0.1828572\n",
      "\tspeed: 0.0342s/iter; left time: 612.3118s\n",
      "\titers: 300, epoch: 1 | loss: 0.1897422\n",
      "\tspeed: 0.0341s/iter; left time: 608.0596s\n",
      "\titers: 400, epoch: 1 | loss: 0.1720902\n",
      "\tspeed: 0.0342s/iter; left time: 605.3768s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669981\n",
      "\tspeed: 0.0341s/iter; left time: 600.9832s\n",
      "\titers: 600, epoch: 1 | loss: 0.1590210\n",
      "\tspeed: 0.0341s/iter; left time: 598.1668s\n",
      "\titers: 700, epoch: 1 | loss: 0.1618395\n",
      "\tspeed: 0.0341s/iter; left time: 594.8208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1537406\n",
      "\tspeed: 0.0342s/iter; left time: 591.7778s\n",
      "\titers: 900, epoch: 1 | loss: 0.1561620\n",
      "\tspeed: 0.0341s/iter; left time: 588.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1811837 Vali Loss: 0.1443907 Test Loss: 0.1706055\n",
      "Validation loss decreased (inf --> 0.144391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1264048\n",
      "\tspeed: 0.0961s/iter; left time: 1644.2747s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242911\n",
      "\tspeed: 0.0342s/iter; left time: 581.1043s\n",
      "\titers: 300, epoch: 2 | loss: 0.1100120\n",
      "\tspeed: 0.0342s/iter; left time: 577.6774s\n",
      "\titers: 400, epoch: 2 | loss: 0.0976940\n",
      "\tspeed: 0.0342s/iter; left time: 574.5811s\n",
      "\titers: 500, epoch: 2 | loss: 0.0993426\n",
      "\tspeed: 0.0341s/iter; left time: 570.3608s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993942\n",
      "\tspeed: 0.0342s/iter; left time: 567.6991s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957400\n",
      "\tspeed: 0.0342s/iter; left time: 564.1766s\n",
      "\titers: 800, epoch: 2 | loss: 0.0965493\n",
      "\tspeed: 0.0342s/iter; left time: 560.8260s\n",
      "\titers: 900, epoch: 2 | loss: 0.1025189\n",
      "\tspeed: 0.0341s/iter; left time: 556.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1120638 Vali Loss: 0.1135424 Test Loss: 0.1331562\n",
      "Validation loss decreased (0.144391 --> 0.113542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881129\n",
      "\tspeed: 0.0991s/iter; left time: 1606.9283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0977456\n",
      "\tspeed: 0.0347s/iter; left time: 559.4386s\n",
      "\titers: 300, epoch: 3 | loss: 0.1086163\n",
      "\tspeed: 0.0343s/iter; left time: 549.2724s\n",
      "\titers: 400, epoch: 3 | loss: 0.1002908\n",
      "\tspeed: 0.0341s/iter; left time: 542.8495s\n",
      "\titers: 500, epoch: 3 | loss: 0.0826901\n",
      "\tspeed: 0.0341s/iter; left time: 539.5337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893644\n",
      "\tspeed: 0.0342s/iter; left time: 536.9598s\n",
      "\titers: 700, epoch: 3 | loss: 0.0908650\n",
      "\tspeed: 0.0341s/iter; left time: 532.7367s\n",
      "\titers: 800, epoch: 3 | loss: 0.0975903\n",
      "\tspeed: 0.0346s/iter; left time: 536.0341s\n",
      "\titers: 900, epoch: 3 | loss: 0.0928147\n",
      "\tspeed: 0.0347s/iter; left time: 534.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.41s\n",
      "Steps: 906 | Train Loss: 0.0944582 Vali Loss: 0.1077265 Test Loss: 0.1298520\n",
      "Validation loss decreased (0.113542 --> 0.107726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863190\n",
      "\tspeed: 0.0970s/iter; left time: 1483.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907177\n",
      "\tspeed: 0.0341s/iter; left time: 518.1031s\n",
      "\titers: 300, epoch: 4 | loss: 0.0833950\n",
      "\tspeed: 0.0341s/iter; left time: 514.8418s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885096\n",
      "\tspeed: 0.0341s/iter; left time: 510.8771s\n",
      "\titers: 500, epoch: 4 | loss: 0.1024313\n",
      "\tspeed: 0.0341s/iter; left time: 508.6603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902057\n",
      "\tspeed: 0.0341s/iter; left time: 504.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877432\n",
      "\tspeed: 0.0341s/iter; left time: 501.8142s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994082\n",
      "\tspeed: 0.0342s/iter; left time: 499.0221s\n",
      "\titers: 900, epoch: 4 | loss: 0.0841573\n",
      "\tspeed: 0.0341s/iter; left time: 494.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0908629 Vali Loss: 0.1066669 Test Loss: 0.1268926\n",
      "Validation loss decreased (0.107726 --> 0.106667).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901364\n",
      "\tspeed: 0.0965s/iter; left time: 1388.7668s\n",
      "\titers: 200, epoch: 5 | loss: 0.0883172\n",
      "\tspeed: 0.0341s/iter; left time: 488.0627s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873815\n",
      "\tspeed: 0.0341s/iter; left time: 484.5753s\n",
      "\titers: 400, epoch: 5 | loss: 0.0802048\n",
      "\tspeed: 0.0342s/iter; left time: 481.8464s\n",
      "\titers: 500, epoch: 5 | loss: 0.0834858\n",
      "\tspeed: 0.0342s/iter; left time: 478.1296s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920321\n",
      "\tspeed: 0.0341s/iter; left time: 474.1742s\n",
      "\titers: 700, epoch: 5 | loss: 0.1012928\n",
      "\tspeed: 0.0341s/iter; left time: 470.7579s\n",
      "\titers: 800, epoch: 5 | loss: 0.0949160\n",
      "\tspeed: 0.0342s/iter; left time: 467.9884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0833733\n",
      "\tspeed: 0.0341s/iter; left time: 464.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0878463 Vali Loss: 0.1098253 Test Loss: 0.1307452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0875461\n",
      "\tspeed: 0.0945s/iter; left time: 1274.8394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793280\n",
      "\tspeed: 0.0347s/iter; left time: 464.6410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0823781\n",
      "\tspeed: 0.0347s/iter; left time: 461.2001s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781062\n",
      "\tspeed: 0.0347s/iter; left time: 458.1822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0726712\n",
      "\tspeed: 0.0347s/iter; left time: 453.9454s\n",
      "\titers: 600, epoch: 6 | loss: 0.0621493\n",
      "\tspeed: 0.0344s/iter; left time: 446.9567s\n",
      "\titers: 700, epoch: 6 | loss: 0.0807547\n",
      "\tspeed: 0.0341s/iter; left time: 439.7816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0704086\n",
      "\tspeed: 0.0341s/iter; left time: 436.5041s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726400\n",
      "\tspeed: 0.0341s/iter; left time: 432.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0782342 Vali Loss: 0.0994923 Test Loss: 0.1179419\n",
      "Validation loss decreased (0.106667 --> 0.099492).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712830\n",
      "\tspeed: 0.0978s/iter; left time: 1231.4343s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739732\n",
      "\tspeed: 0.0347s/iter; left time: 433.0052s\n",
      "\titers: 300, epoch: 7 | loss: 0.0753709\n",
      "\tspeed: 0.0347s/iter; left time: 429.3025s\n",
      "\titers: 400, epoch: 7 | loss: 0.0684797\n",
      "\tspeed: 0.0341s/iter; left time: 419.4674s\n",
      "\titers: 500, epoch: 7 | loss: 0.0776076\n",
      "\tspeed: 0.0342s/iter; left time: 416.5956s\n",
      "\titers: 600, epoch: 7 | loss: 0.0703165\n",
      "\tspeed: 0.0341s/iter; left time: 412.4213s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794782\n",
      "\tspeed: 0.0341s/iter; left time: 409.1995s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693715\n",
      "\tspeed: 0.0341s/iter; left time: 405.5195s\n",
      "\titers: 900, epoch: 7 | loss: 0.0780969\n",
      "\tspeed: 0.0342s/iter; left time: 402.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0721806 Vali Loss: 0.0970641 Test Loss: 0.1169970\n",
      "Validation loss decreased (0.099492 --> 0.097064).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0636127\n",
      "\tspeed: 0.0981s/iter; left time: 1145.4293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0630548\n",
      "\tspeed: 0.0342s/iter; left time: 395.8652s\n",
      "\titers: 300, epoch: 8 | loss: 0.0730316\n",
      "\tspeed: 0.0342s/iter; left time: 392.2474s\n",
      "\titers: 400, epoch: 8 | loss: 0.0669587\n",
      "\tspeed: 0.0341s/iter; left time: 388.5562s\n",
      "\titers: 500, epoch: 8 | loss: 0.0619939\n",
      "\tspeed: 0.0342s/iter; left time: 385.2777s\n",
      "\titers: 600, epoch: 8 | loss: 0.0640725\n",
      "\tspeed: 0.0342s/iter; left time: 382.2546s\n",
      "\titers: 700, epoch: 8 | loss: 0.0613099\n",
      "\tspeed: 0.0341s/iter; left time: 378.3109s\n",
      "\titers: 800, epoch: 8 | loss: 0.0650655\n",
      "\tspeed: 0.0342s/iter; left time: 375.4917s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699186\n",
      "\tspeed: 0.0342s/iter; left time: 371.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.21s\n",
      "Steps: 906 | Train Loss: 0.0689264 Vali Loss: 0.0993467 Test Loss: 0.1192917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681697\n",
      "\tspeed: 0.0938s/iter; left time: 1010.6405s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609449\n",
      "\tspeed: 0.0341s/iter; left time: 364.2415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0758209\n",
      "\tspeed: 0.0341s/iter; left time: 360.3506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0647182\n",
      "\tspeed: 0.0341s/iter; left time: 357.5211s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599880\n",
      "\tspeed: 0.0341s/iter; left time: 353.8521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696192\n",
      "\tspeed: 0.0342s/iter; left time: 351.0960s\n",
      "\titers: 700, epoch: 9 | loss: 0.0631149\n",
      "\tspeed: 0.0342s/iter; left time: 347.4902s\n",
      "\titers: 800, epoch: 9 | loss: 0.0657809\n",
      "\tspeed: 0.0342s/iter; left time: 344.1916s\n",
      "\titers: 900, epoch: 9 | loss: 0.0715103\n",
      "\tspeed: 0.0341s/iter; left time: 340.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.17s\n",
      "Steps: 906 | Train Loss: 0.0663550 Vali Loss: 0.0995142 Test Loss: 0.1232103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0680644\n",
      "\tspeed: 0.0938s/iter; left time: 925.4896s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559841\n",
      "\tspeed: 0.0342s/iter; left time: 333.7656s\n",
      "\titers: 300, epoch: 10 | loss: 0.0640021\n",
      "\tspeed: 0.0342s/iter; left time: 330.1482s\n",
      "\titers: 400, epoch: 10 | loss: 0.0558519\n",
      "\tspeed: 0.0342s/iter; left time: 327.0613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0592567\n",
      "\tspeed: 0.0341s/iter; left time: 323.1783s\n",
      "\titers: 600, epoch: 10 | loss: 0.0703132\n",
      "\tspeed: 0.0342s/iter; left time: 320.2512s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663644\n",
      "\tspeed: 0.0342s/iter; left time: 316.9101s\n",
      "\titers: 800, epoch: 10 | loss: 0.0713700\n",
      "\tspeed: 0.0342s/iter; left time: 313.5720s\n",
      "\titers: 900, epoch: 10 | loss: 0.0612881\n",
      "\tspeed: 0.0342s/iter; left time: 309.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0636049 Vali Loss: 0.1003592 Test Loss: 0.1226154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0635687\n",
      "\tspeed: 0.0959s/iter; left time: 858.9658s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579782\n",
      "\tspeed: 0.0341s/iter; left time: 302.2018s\n",
      "\titers: 300, epoch: 11 | loss: 0.0577329\n",
      "\tspeed: 0.0341s/iter; left time: 298.8250s\n",
      "\titers: 400, epoch: 11 | loss: 0.0584427\n",
      "\tspeed: 0.0341s/iter; left time: 295.6880s\n",
      "\titers: 500, epoch: 11 | loss: 0.0652117\n",
      "\tspeed: 0.0341s/iter; left time: 292.0533s\n",
      "\titers: 600, epoch: 11 | loss: 0.0556371\n",
      "\tspeed: 0.0341s/iter; left time: 288.8224s\n",
      "\titers: 700, epoch: 11 | loss: 0.0617914\n",
      "\tspeed: 0.0341s/iter; left time: 285.2151s\n",
      "\titers: 800, epoch: 11 | loss: 0.0650759\n",
      "\tspeed: 0.0341s/iter; left time: 281.8704s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628121\n",
      "\tspeed: 0.0341s/iter; left time: 278.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0608432 Vali Loss: 0.1019767 Test Loss: 0.1295339\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601404\n",
      "\tspeed: 0.0934s/iter; left time: 752.6225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608226\n",
      "\tspeed: 0.0342s/iter; left time: 271.9253s\n",
      "\titers: 300, epoch: 12 | loss: 0.0585720\n",
      "\tspeed: 0.0342s/iter; left time: 268.3737s\n",
      "\titers: 400, epoch: 12 | loss: 0.0671864\n",
      "\tspeed: 0.0342s/iter; left time: 264.9392s\n",
      "\titers: 500, epoch: 12 | loss: 0.0586702\n",
      "\tspeed: 0.0342s/iter; left time: 261.5608s\n",
      "\titers: 600, epoch: 12 | loss: 0.0578963\n",
      "\tspeed: 0.0342s/iter; left time: 258.2738s\n",
      "\titers: 700, epoch: 12 | loss: 0.0511237\n",
      "\tspeed: 0.0342s/iter; left time: 254.6666s\n",
      "\titers: 800, epoch: 12 | loss: 0.0598192\n",
      "\tspeed: 0.0342s/iter; left time: 251.4330s\n",
      "\titers: 900, epoch: 12 | loss: 0.0562920\n",
      "\tspeed: 0.0342s/iter; left time: 247.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0588874 Vali Loss: 0.1025693 Test Loss: 0.1268519\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03127928450703621, rmse:0.17685949802398682, mae:0.11696060001850128, rse:0.6098074316978455\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:51.71s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2268764\n",
      "\tspeed: 0.0655s/iter; left time: 1178.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.1978672\n",
      "\tspeed: 0.0413s/iter; left time: 739.0064s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943929\n",
      "\tspeed: 0.0420s/iter; left time: 747.6673s\n",
      "\titers: 400, epoch: 1 | loss: 0.1920299\n",
      "\tspeed: 0.0420s/iter; left time: 743.2215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1802773\n",
      "\tspeed: 0.0421s/iter; left time: 739.5867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717280\n",
      "\tspeed: 0.0421s/iter; left time: 735.5826s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656476\n",
      "\tspeed: 0.0420s/iter; left time: 730.7696s\n",
      "\titers: 800, epoch: 1 | loss: 0.1696963\n",
      "\tspeed: 0.0420s/iter; left time: 726.1528s\n",
      "\titers: 900, epoch: 1 | loss: 0.1643242\n",
      "\tspeed: 0.0421s/iter; left time: 723.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 904 | Train Loss: 0.1897053 Vali Loss: 0.1728368 Test Loss: 0.2124270\n",
      "Validation loss decreased (inf --> 0.172837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1457785\n",
      "\tspeed: 0.1164s/iter; left time: 1987.5548s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392656\n",
      "\tspeed: 0.0415s/iter; left time: 705.1681s\n",
      "\titers: 300, epoch: 2 | loss: 0.1343261\n",
      "\tspeed: 0.0415s/iter; left time: 699.7559s\n",
      "\titers: 400, epoch: 2 | loss: 0.1345560\n",
      "\tspeed: 0.0421s/iter; left time: 705.8104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1346623\n",
      "\tspeed: 0.0421s/iter; left time: 702.6320s\n",
      "\titers: 600, epoch: 2 | loss: 0.1332583\n",
      "\tspeed: 0.0419s/iter; left time: 694.3021s\n",
      "\titers: 700, epoch: 2 | loss: 0.1261364\n",
      "\tspeed: 0.0421s/iter; left time: 693.9271s\n",
      "\titers: 800, epoch: 2 | loss: 0.1254614\n",
      "\tspeed: 0.0421s/iter; left time: 689.2999s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305606\n",
      "\tspeed: 0.0421s/iter; left time: 684.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 904 | Train Loss: 0.1357239 Vali Loss: 0.1446885 Test Loss: 0.1781681\n",
      "Validation loss decreased (0.172837 --> 0.144689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1175372\n",
      "\tspeed: 0.1192s/iter; left time: 1927.9999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1188484\n",
      "\tspeed: 0.0421s/iter; left time: 676.6233s\n",
      "\titers: 300, epoch: 3 | loss: 0.1154065\n",
      "\tspeed: 0.0421s/iter; left time: 672.0777s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113715\n",
      "\tspeed: 0.0420s/iter; left time: 667.4296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1078852\n",
      "\tspeed: 0.0421s/iter; left time: 663.4356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1149738\n",
      "\tspeed: 0.0421s/iter; left time: 659.3680s\n",
      "\titers: 700, epoch: 3 | loss: 0.1066848\n",
      "\tspeed: 0.0421s/iter; left time: 655.3036s\n",
      "\titers: 800, epoch: 3 | loss: 0.1042039\n",
      "\tspeed: 0.0420s/iter; left time: 649.6626s\n",
      "\titers: 900, epoch: 3 | loss: 0.1103720\n",
      "\tspeed: 0.0420s/iter; left time: 645.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.1113842 Vali Loss: 0.1260925 Test Loss: 0.1568912\n",
      "Validation loss decreased (0.144689 --> 0.126093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1156684\n",
      "\tspeed: 0.1176s/iter; left time: 1795.7961s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072669\n",
      "\tspeed: 0.0415s/iter; left time: 629.9717s\n",
      "\titers: 300, epoch: 4 | loss: 0.1097675\n",
      "\tspeed: 0.0415s/iter; left time: 626.0487s\n",
      "\titers: 400, epoch: 4 | loss: 0.0987495\n",
      "\tspeed: 0.0416s/iter; left time: 622.0291s\n",
      "\titers: 500, epoch: 4 | loss: 0.0966180\n",
      "\tspeed: 0.0416s/iter; left time: 618.0380s\n",
      "\titers: 600, epoch: 4 | loss: 0.1013041\n",
      "\tspeed: 0.0416s/iter; left time: 613.6836s\n",
      "\titers: 700, epoch: 4 | loss: 0.0967172\n",
      "\tspeed: 0.0416s/iter; left time: 609.5065s\n",
      "\titers: 800, epoch: 4 | loss: 0.1014885\n",
      "\tspeed: 0.0415s/iter; left time: 605.2582s\n",
      "\titers: 900, epoch: 4 | loss: 0.1030009\n",
      "\tspeed: 0.0415s/iter; left time: 601.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1018708 Vali Loss: 0.1277115 Test Loss: 0.1587207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942518\n",
      "\tspeed: 0.1139s/iter; left time: 1636.5789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950471\n",
      "\tspeed: 0.0415s/iter; left time: 592.5768s\n",
      "\titers: 300, epoch: 5 | loss: 0.0928046\n",
      "\tspeed: 0.0415s/iter; left time: 588.2587s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033714\n",
      "\tspeed: 0.0415s/iter; left time: 583.5658s\n",
      "\titers: 500, epoch: 5 | loss: 0.0941585\n",
      "\tspeed: 0.0415s/iter; left time: 579.3170s\n",
      "\titers: 600, epoch: 5 | loss: 0.0995664\n",
      "\tspeed: 0.0415s/iter; left time: 575.1951s\n",
      "\titers: 700, epoch: 5 | loss: 0.1031185\n",
      "\tspeed: 0.0415s/iter; left time: 571.0616s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025636\n",
      "\tspeed: 0.0415s/iter; left time: 567.0282s\n",
      "\titers: 900, epoch: 5 | loss: 0.1002272\n",
      "\tspeed: 0.0415s/iter; left time: 562.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0953789 Vali Loss: 0.1268768 Test Loss: 0.1636338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910520\n",
      "\tspeed: 0.1140s/iter; left time: 1534.1408s\n",
      "\titers: 200, epoch: 6 | loss: 0.0860340\n",
      "\tspeed: 0.0415s/iter; left time: 554.6341s\n",
      "\titers: 300, epoch: 6 | loss: 0.0880820\n",
      "\tspeed: 0.0415s/iter; left time: 550.1306s\n",
      "\titers: 400, epoch: 6 | loss: 0.0941288\n",
      "\tspeed: 0.0415s/iter; left time: 546.4273s\n",
      "\titers: 500, epoch: 6 | loss: 0.0841647\n",
      "\tspeed: 0.0415s/iter; left time: 542.0510s\n",
      "\titers: 600, epoch: 6 | loss: 0.0876083\n",
      "\tspeed: 0.0415s/iter; left time: 537.7534s\n",
      "\titers: 700, epoch: 6 | loss: 0.0830211\n",
      "\tspeed: 0.0415s/iter; left time: 534.1377s\n",
      "\titers: 800, epoch: 6 | loss: 0.0914322\n",
      "\tspeed: 0.0415s/iter; left time: 529.4035s\n",
      "\titers: 900, epoch: 6 | loss: 0.0899133\n",
      "\tspeed: 0.0415s/iter; left time: 525.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0895236 Vali Loss: 0.1278808 Test Loss: 0.1652189\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0836434\n",
      "\tspeed: 0.1132s/iter; left time: 1421.1546s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844925\n",
      "\tspeed: 0.0415s/iter; left time: 517.5073s\n",
      "\titers: 300, epoch: 7 | loss: 0.0794558\n",
      "\tspeed: 0.0415s/iter; left time: 513.3383s\n",
      "\titers: 400, epoch: 7 | loss: 0.0855794\n",
      "\tspeed: 0.0415s/iter; left time: 508.9053s\n",
      "\titers: 500, epoch: 7 | loss: 0.0898345\n",
      "\tspeed: 0.0415s/iter; left time: 504.9240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0911049\n",
      "\tspeed: 0.0415s/iter; left time: 500.8588s\n",
      "\titers: 700, epoch: 7 | loss: 0.0897632\n",
      "\tspeed: 0.0415s/iter; left time: 496.6991s\n",
      "\titers: 800, epoch: 7 | loss: 0.0752865\n",
      "\tspeed: 0.0415s/iter; left time: 492.4032s\n",
      "\titers: 900, epoch: 7 | loss: 0.0809941\n",
      "\tspeed: 0.0415s/iter; left time: 488.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0841153 Vali Loss: 0.1298804 Test Loss: 0.1732888\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823286\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1804s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805886\n",
      "\tspeed: 0.0416s/iter; left time: 480.0498s\n",
      "\titers: 300, epoch: 8 | loss: 0.0787768\n",
      "\tspeed: 0.0415s/iter; left time: 475.3546s\n",
      "\titers: 400, epoch: 8 | loss: 0.0750168\n",
      "\tspeed: 0.0415s/iter; left time: 471.2326s\n",
      "\titers: 500, epoch: 8 | loss: 0.0819786\n",
      "\tspeed: 0.0415s/iter; left time: 466.9707s\n",
      "\titers: 600, epoch: 8 | loss: 0.0769879\n",
      "\tspeed: 0.0416s/iter; left time: 463.5953s\n",
      "\titers: 700, epoch: 8 | loss: 0.0801579\n",
      "\tspeed: 0.0415s/iter; left time: 458.9882s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806662\n",
      "\tspeed: 0.0415s/iter; left time: 454.6568s\n",
      "\titers: 900, epoch: 8 | loss: 0.0836962\n",
      "\tspeed: 0.0415s/iter; left time: 450.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0791007 Vali Loss: 0.1308822 Test Loss: 0.1750989\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049356184899806976, rmse:0.22216251492500305, mae:0.15691299736499786, rse:0.7682689428329468\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2278353\n",
      "\tspeed: 0.0436s/iter; left time: 783.7662s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020534\n",
      "\tspeed: 0.0415s/iter; left time: 742.9428s\n",
      "\titers: 300, epoch: 1 | loss: 0.1878239\n",
      "\tspeed: 0.0416s/iter; left time: 739.1002s\n",
      "\titers: 400, epoch: 1 | loss: 0.1944844\n",
      "\tspeed: 0.0416s/iter; left time: 734.9105s\n",
      "\titers: 500, epoch: 1 | loss: 0.1941353\n",
      "\tspeed: 0.0416s/iter; left time: 731.1568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1729999\n",
      "\tspeed: 0.0416s/iter; left time: 726.9874s\n",
      "\titers: 700, epoch: 1 | loss: 0.1679289\n",
      "\tspeed: 0.0416s/iter; left time: 722.5073s\n",
      "\titers: 800, epoch: 1 | loss: 0.1699705\n",
      "\tspeed: 0.0416s/iter; left time: 719.0877s\n",
      "\titers: 900, epoch: 1 | loss: 0.1647512\n",
      "\tspeed: 0.0416s/iter; left time: 715.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.1937501 Vali Loss: 0.1664132 Test Loss: 0.2047869\n",
      "Validation loss decreased (inf --> 0.166413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1548872\n",
      "\tspeed: 0.1165s/iter; left time: 1990.3129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364976\n",
      "\tspeed: 0.0416s/iter; left time: 706.8648s\n",
      "\titers: 300, epoch: 2 | loss: 0.1455883\n",
      "\tspeed: 0.0417s/iter; left time: 703.0128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1231301\n",
      "\tspeed: 0.0416s/iter; left time: 697.4636s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362744\n",
      "\tspeed: 0.0416s/iter; left time: 693.1189s\n",
      "\titers: 600, epoch: 2 | loss: 0.1244080\n",
      "\tspeed: 0.0416s/iter; left time: 689.3567s\n",
      "\titers: 700, epoch: 2 | loss: 0.1334690\n",
      "\tspeed: 0.0416s/iter; left time: 685.3067s\n",
      "\titers: 800, epoch: 2 | loss: 0.1270750\n",
      "\tspeed: 0.0416s/iter; left time: 680.8819s\n",
      "\titers: 900, epoch: 2 | loss: 0.1180649\n",
      "\tspeed: 0.0416s/iter; left time: 677.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1352863 Vali Loss: 0.1410898 Test Loss: 0.1708414\n",
      "Validation loss decreased (0.166413 --> 0.141090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147558\n",
      "\tspeed: 0.1170s/iter; left time: 1891.8432s\n",
      "\titers: 200, epoch: 3 | loss: 0.1144703\n",
      "\tspeed: 0.0417s/iter; left time: 669.6380s\n",
      "\titers: 300, epoch: 3 | loss: 0.1129461\n",
      "\tspeed: 0.0416s/iter; left time: 665.2663s\n",
      "\titers: 400, epoch: 3 | loss: 0.1159053\n",
      "\tspeed: 0.0417s/iter; left time: 661.1881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1037145\n",
      "\tspeed: 0.0416s/iter; left time: 656.4345s\n",
      "\titers: 600, epoch: 3 | loss: 0.1191663\n",
      "\tspeed: 0.0416s/iter; left time: 652.6964s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158241\n",
      "\tspeed: 0.0416s/iter; left time: 648.3619s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989802\n",
      "\tspeed: 0.0417s/iter; left time: 644.6881s\n",
      "\titers: 900, epoch: 3 | loss: 0.1078756\n",
      "\tspeed: 0.0416s/iter; left time: 639.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.1118837 Vali Loss: 0.1274420 Test Loss: 0.1581856\n",
      "Validation loss decreased (0.141090 --> 0.127442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1074443\n",
      "\tspeed: 0.1171s/iter; left time: 1788.3894s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052178\n",
      "\tspeed: 0.0416s/iter; left time: 630.7722s\n",
      "\titers: 300, epoch: 4 | loss: 0.1018802\n",
      "\tspeed: 0.0416s/iter; left time: 626.5580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1033611\n",
      "\tspeed: 0.0416s/iter; left time: 622.8882s\n",
      "\titers: 500, epoch: 4 | loss: 0.1052628\n",
      "\tspeed: 0.0416s/iter; left time: 618.2769s\n",
      "\titers: 600, epoch: 4 | loss: 0.1043086\n",
      "\tspeed: 0.0416s/iter; left time: 614.4294s\n",
      "\titers: 700, epoch: 4 | loss: 0.1040385\n",
      "\tspeed: 0.0416s/iter; left time: 610.2642s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061757\n",
      "\tspeed: 0.0416s/iter; left time: 606.3039s\n",
      "\titers: 900, epoch: 4 | loss: 0.1004524\n",
      "\tspeed: 0.0416s/iter; left time: 601.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.1023712 Vali Loss: 0.1312658 Test Loss: 0.1651838\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0989314\n",
      "\tspeed: 0.1142s/iter; left time: 1640.3943s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047119\n",
      "\tspeed: 0.0417s/iter; left time: 594.2167s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982214\n",
      "\tspeed: 0.0417s/iter; left time: 590.0576s\n",
      "\titers: 400, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0417s/iter; left time: 585.9079s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974938\n",
      "\tspeed: 0.0416s/iter; left time: 581.2475s\n",
      "\titers: 600, epoch: 5 | loss: 0.0970161\n",
      "\tspeed: 0.0416s/iter; left time: 576.9025s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918606\n",
      "\tspeed: 0.0416s/iter; left time: 572.8600s\n",
      "\titers: 800, epoch: 5 | loss: 0.0898132\n",
      "\tspeed: 0.0417s/iter; left time: 569.1998s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893147\n",
      "\tspeed: 0.0416s/iter; left time: 564.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0967186 Vali Loss: 0.1319823 Test Loss: 0.1671596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0955259\n",
      "\tspeed: 0.1140s/iter; left time: 1534.6863s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896132\n",
      "\tspeed: 0.0416s/iter; left time: 556.4829s\n",
      "\titers: 300, epoch: 6 | loss: 0.0947796\n",
      "\tspeed: 0.0417s/iter; left time: 552.5246s\n",
      "\titers: 400, epoch: 6 | loss: 0.0908911\n",
      "\tspeed: 0.0416s/iter; left time: 548.1117s\n",
      "\titers: 500, epoch: 6 | loss: 0.0873807\n",
      "\tspeed: 0.0417s/iter; left time: 544.2589s\n",
      "\titers: 600, epoch: 6 | loss: 0.0879827\n",
      "\tspeed: 0.0417s/iter; left time: 540.0754s\n",
      "\titers: 700, epoch: 6 | loss: 0.0896935\n",
      "\tspeed: 0.0417s/iter; left time: 536.0600s\n",
      "\titers: 800, epoch: 6 | loss: 0.0941269\n",
      "\tspeed: 0.0416s/iter; left time: 531.3673s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933578\n",
      "\tspeed: 0.0417s/iter; left time: 527.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0908674 Vali Loss: 0.1343007 Test Loss: 0.1725691\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869733\n",
      "\tspeed: 0.1148s/iter; left time: 1441.3462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865798\n",
      "\tspeed: 0.0417s/iter; left time: 519.1138s\n",
      "\titers: 300, epoch: 7 | loss: 0.0872979\n",
      "\tspeed: 0.0417s/iter; left time: 515.1221s\n",
      "\titers: 400, epoch: 7 | loss: 0.0808157\n",
      "\tspeed: 0.0417s/iter; left time: 510.9330s\n",
      "\titers: 500, epoch: 7 | loss: 0.0819069\n",
      "\tspeed: 0.0417s/iter; left time: 506.6866s\n",
      "\titers: 600, epoch: 7 | loss: 0.0884176\n",
      "\tspeed: 0.0417s/iter; left time: 502.3795s\n",
      "\titers: 700, epoch: 7 | loss: 0.0929823\n",
      "\tspeed: 0.0417s/iter; left time: 498.2833s\n",
      "\titers: 800, epoch: 7 | loss: 0.0822935\n",
      "\tspeed: 0.0417s/iter; left time: 494.2249s\n",
      "\titers: 900, epoch: 7 | loss: 0.0851985\n",
      "\tspeed: 0.0417s/iter; left time: 490.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0852665 Vali Loss: 0.1313283 Test Loss: 0.1676679\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839205\n",
      "\tspeed: 0.1140s/iter; left time: 1328.2757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803091\n",
      "\tspeed: 0.0416s/iter; left time: 481.1273s\n",
      "\titers: 300, epoch: 8 | loss: 0.0736933\n",
      "\tspeed: 0.0416s/iter; left time: 476.6921s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799875\n",
      "\tspeed: 0.0416s/iter; left time: 472.7424s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814201\n",
      "\tspeed: 0.0416s/iter; left time: 468.2029s\n",
      "\titers: 600, epoch: 8 | loss: 0.0776833\n",
      "\tspeed: 0.0416s/iter; left time: 464.3979s\n",
      "\titers: 700, epoch: 8 | loss: 0.0707026\n",
      "\tspeed: 0.0417s/iter; left time: 460.3869s\n",
      "\titers: 800, epoch: 8 | loss: 0.0765746\n",
      "\tspeed: 0.0417s/iter; left time: 456.2890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0856424\n",
      "\tspeed: 0.0416s/iter; left time: 451.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0801459 Vali Loss: 0.1328648 Test Loss: 0.1732243\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051835522055625916, rmse:0.22767415642738342, mae:0.158115953207016, rse:0.7873289585113525\n",
      "Intermediate time for GB and pred_len 96: 00h:12m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2144550\n",
      "\tspeed: 0.0736s/iter; left time: 1320.3347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2042320\n",
      "\tspeed: 0.0505s/iter; left time: 901.4268s\n",
      "\titers: 300, epoch: 1 | loss: 0.1855985\n",
      "\tspeed: 0.0507s/iter; left time: 899.5263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1828096\n",
      "\tspeed: 0.0508s/iter; left time: 896.1169s\n",
      "\titers: 500, epoch: 1 | loss: 0.1863522\n",
      "\tspeed: 0.0508s/iter; left time: 890.4390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1806218\n",
      "\tspeed: 0.0507s/iter; left time: 885.0513s\n",
      "\titers: 700, epoch: 1 | loss: 0.1707170\n",
      "\tspeed: 0.0508s/iter; left time: 880.8659s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668490\n",
      "\tspeed: 0.0507s/iter; left time: 874.7028s\n",
      "\titers: 900, epoch: 1 | loss: 0.1642738\n",
      "\tspeed: 0.0508s/iter; left time: 870.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 902 | Train Loss: 0.1902878 Vali Loss: 0.1756261 Test Loss: 0.2136206\n",
      "Validation loss decreased (inf --> 0.175626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546461\n",
      "\tspeed: 0.1416s/iter; left time: 2412.0118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1453713\n",
      "\tspeed: 0.0507s/iter; left time: 858.6454s\n",
      "\titers: 300, epoch: 2 | loss: 0.1408072\n",
      "\tspeed: 0.0507s/iter; left time: 853.8900s\n",
      "\titers: 400, epoch: 2 | loss: 0.1328956\n",
      "\tspeed: 0.0507s/iter; left time: 848.6835s\n",
      "\titers: 500, epoch: 2 | loss: 0.1344081\n",
      "\tspeed: 0.0507s/iter; left time: 844.3704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1351472\n",
      "\tspeed: 0.0507s/iter; left time: 838.7043s\n",
      "\titers: 700, epoch: 2 | loss: 0.1377063\n",
      "\tspeed: 0.0507s/iter; left time: 834.0462s\n",
      "\titers: 800, epoch: 2 | loss: 0.1352134\n",
      "\tspeed: 0.0508s/iter; left time: 829.4362s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376040\n",
      "\tspeed: 0.0507s/iter; left time: 823.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1412551 Vali Loss: 0.1557616 Test Loss: 0.1941232\n",
      "Validation loss decreased (0.175626 --> 0.155762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1322913\n",
      "\tspeed: 0.1434s/iter; left time: 2314.1137s\n",
      "\titers: 200, epoch: 3 | loss: 0.1251840\n",
      "\tspeed: 0.0507s/iter; left time: 812.6631s\n",
      "\titers: 300, epoch: 3 | loss: 0.1327689\n",
      "\tspeed: 0.0507s/iter; left time: 807.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.1270881\n",
      "\tspeed: 0.0507s/iter; left time: 802.8697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1229750\n",
      "\tspeed: 0.0506s/iter; left time: 797.0577s\n",
      "\titers: 600, epoch: 3 | loss: 0.1328987\n",
      "\tspeed: 0.0507s/iter; left time: 793.3704s\n",
      "\titers: 700, epoch: 3 | loss: 0.1204278\n",
      "\tspeed: 0.0506s/iter; left time: 785.9965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1188312\n",
      "\tspeed: 0.0508s/iter; left time: 784.4461s\n",
      "\titers: 900, epoch: 3 | loss: 0.1182145\n",
      "\tspeed: 0.0508s/iter; left time: 779.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.1258696 Vali Loss: 0.1498645 Test Loss: 0.1913567\n",
      "Validation loss decreased (0.155762 --> 0.149865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1236095\n",
      "\tspeed: 0.1429s/iter; left time: 2177.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127460\n",
      "\tspeed: 0.0517s/iter; left time: 783.0264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1189013\n",
      "\tspeed: 0.0511s/iter; left time: 768.8154s\n",
      "\titers: 400, epoch: 4 | loss: 0.1107328\n",
      "\tspeed: 0.0506s/iter; left time: 756.4537s\n",
      "\titers: 500, epoch: 4 | loss: 0.1057849\n",
      "\tspeed: 0.0507s/iter; left time: 751.7938s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077283\n",
      "\tspeed: 0.0506s/iter; left time: 745.7883s\n",
      "\titers: 700, epoch: 4 | loss: 0.1090573\n",
      "\tspeed: 0.0507s/iter; left time: 742.5099s\n",
      "\titers: 800, epoch: 4 | loss: 0.1042960\n",
      "\tspeed: 0.0508s/iter; left time: 737.7649s\n",
      "\titers: 900, epoch: 4 | loss: 0.0960267\n",
      "\tspeed: 0.0508s/iter; left time: 733.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1102404 Vali Loss: 0.1309775 Test Loss: 0.1653814\n",
      "Validation loss decreased (0.149865 --> 0.130978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0952837\n",
      "\tspeed: 0.1428s/iter; left time: 2046.0842s\n",
      "\titers: 200, epoch: 5 | loss: 0.1016937\n",
      "\tspeed: 0.0508s/iter; left time: 722.8595s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965871\n",
      "\tspeed: 0.0509s/iter; left time: 718.7543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0990509\n",
      "\tspeed: 0.0507s/iter; left time: 711.1350s\n",
      "\titers: 500, epoch: 5 | loss: 0.0965394\n",
      "\tspeed: 0.0507s/iter; left time: 706.1450s\n",
      "\titers: 600, epoch: 5 | loss: 0.0947464\n",
      "\tspeed: 0.0508s/iter; left time: 702.9266s\n",
      "\titers: 700, epoch: 5 | loss: 0.0906473\n",
      "\tspeed: 0.0507s/iter; left time: 696.2827s\n",
      "\titers: 800, epoch: 5 | loss: 0.1027681\n",
      "\tspeed: 0.0507s/iter; left time: 691.5529s\n",
      "\titers: 900, epoch: 5 | loss: 0.0998390\n",
      "\tspeed: 0.0507s/iter; left time: 686.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0975682 Vali Loss: 0.1345402 Test Loss: 0.1749502\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0953098\n",
      "\tspeed: 0.1394s/iter; left time: 1871.6152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0979535\n",
      "\tspeed: 0.0509s/iter; left time: 678.3546s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898484\n",
      "\tspeed: 0.0508s/iter; left time: 671.7667s\n",
      "\titers: 400, epoch: 6 | loss: 0.0891806\n",
      "\tspeed: 0.0508s/iter; left time: 666.6549s\n",
      "\titers: 500, epoch: 6 | loss: 0.1021477\n",
      "\tspeed: 0.0507s/iter; left time: 660.9795s\n",
      "\titers: 600, epoch: 6 | loss: 0.0873509\n",
      "\tspeed: 0.0507s/iter; left time: 656.0776s\n",
      "\titers: 700, epoch: 6 | loss: 0.0811544\n",
      "\tspeed: 0.0508s/iter; left time: 651.4109s\n",
      "\titers: 800, epoch: 6 | loss: 0.0884078\n",
      "\tspeed: 0.0510s/iter; left time: 649.1018s\n",
      "\titers: 900, epoch: 6 | loss: 0.0890452\n",
      "\tspeed: 0.0508s/iter; left time: 641.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0908929 Vali Loss: 0.1383472 Test Loss: 0.1792563\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0930536\n",
      "\tspeed: 0.1397s/iter; left time: 1750.8723s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848575\n",
      "\tspeed: 0.0508s/iter; left time: 630.9018s\n",
      "\titers: 300, epoch: 7 | loss: 0.0895651\n",
      "\tspeed: 0.0507s/iter; left time: 625.6852s\n",
      "\titers: 400, epoch: 7 | loss: 0.0846024\n",
      "\tspeed: 0.0508s/iter; left time: 620.9344s\n",
      "\titers: 500, epoch: 7 | loss: 0.0824052\n",
      "\tspeed: 0.0508s/iter; left time: 616.3262s\n",
      "\titers: 600, epoch: 7 | loss: 0.0801848\n",
      "\tspeed: 0.0507s/iter; left time: 610.1180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0878324\n",
      "\tspeed: 0.0507s/iter; left time: 605.1832s\n",
      "\titers: 800, epoch: 7 | loss: 0.0794692\n",
      "\tspeed: 0.0508s/iter; left time: 600.5393s\n",
      "\titers: 900, epoch: 7 | loss: 0.0923864\n",
      "\tspeed: 0.0508s/iter; left time: 595.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 902 | Train Loss: 0.0853172 Vali Loss: 0.1356244 Test Loss: 0.1794397\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0795482\n",
      "\tspeed: 0.1391s/iter; left time: 1616.8590s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793333\n",
      "\tspeed: 0.0509s/iter; left time: 586.2408s\n",
      "\titers: 300, epoch: 8 | loss: 0.0832426\n",
      "\tspeed: 0.0508s/iter; left time: 579.9564s\n",
      "\titers: 400, epoch: 8 | loss: 0.0788528\n",
      "\tspeed: 0.0507s/iter; left time: 574.7891s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814730\n",
      "\tspeed: 0.0508s/iter; left time: 569.9731s\n",
      "\titers: 600, epoch: 8 | loss: 0.0817954\n",
      "\tspeed: 0.0507s/iter; left time: 564.5199s\n",
      "\titers: 700, epoch: 8 | loss: 0.0758450\n",
      "\tspeed: 0.0507s/iter; left time: 559.4593s\n",
      "\titers: 800, epoch: 8 | loss: 0.0744339\n",
      "\tspeed: 0.0507s/iter; left time: 553.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0780436\n",
      "\tspeed: 0.0507s/iter; left time: 549.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0805622 Vali Loss: 0.1370406 Test Loss: 0.1795973\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742666\n",
      "\tspeed: 0.1390s/iter; left time: 1490.7365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785919\n",
      "\tspeed: 0.0507s/iter; left time: 539.1281s\n",
      "\titers: 300, epoch: 9 | loss: 0.0799072\n",
      "\tspeed: 0.0508s/iter; left time: 534.4281s\n",
      "\titers: 400, epoch: 9 | loss: 0.0714043\n",
      "\tspeed: 0.0508s/iter; left time: 529.4868s\n",
      "\titers: 500, epoch: 9 | loss: 0.0772576\n",
      "\tspeed: 0.0507s/iter; left time: 523.5973s\n",
      "\titers: 600, epoch: 9 | loss: 0.0725148\n",
      "\tspeed: 0.0507s/iter; left time: 518.2077s\n",
      "\titers: 700, epoch: 9 | loss: 0.0799865\n",
      "\tspeed: 0.0506s/iter; left time: 512.3497s\n",
      "\titers: 800, epoch: 9 | loss: 0.0802605\n",
      "\tspeed: 0.0507s/iter; left time: 508.6986s\n",
      "\titers: 900, epoch: 9 | loss: 0.0742895\n",
      "\tspeed: 0.0506s/iter; left time: 502.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.0766087 Vali Loss: 0.1366436 Test Loss: 0.1790668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05534675344824791, rmse:0.23525890707969666, mae:0.1653159260749817, rse:0.815612256526947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2155263\n",
      "\tspeed: 0.0535s/iter; left time: 959.0820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1987825\n",
      "\tspeed: 0.0508s/iter; left time: 906.4877s\n",
      "\titers: 300, epoch: 1 | loss: 0.1921764\n",
      "\tspeed: 0.0509s/iter; left time: 902.4375s\n",
      "\titers: 400, epoch: 1 | loss: 0.1906046\n",
      "\tspeed: 0.0508s/iter; left time: 895.3965s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840005\n",
      "\tspeed: 0.0507s/iter; left time: 888.9264s\n",
      "\titers: 600, epoch: 1 | loss: 0.1789132\n",
      "\tspeed: 0.0506s/iter; left time: 883.3171s\n",
      "\titers: 700, epoch: 1 | loss: 0.1818265\n",
      "\tspeed: 0.0507s/iter; left time: 878.3863s\n",
      "\titers: 800, epoch: 1 | loss: 0.1734744\n",
      "\tspeed: 0.0507s/iter; left time: 873.2800s\n",
      "\titers: 900, epoch: 1 | loss: 0.1659183\n",
      "\tspeed: 0.0507s/iter; left time: 868.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1887618 Vali Loss: 0.1742335 Test Loss: 0.2129559\n",
      "Validation loss decreased (inf --> 0.174234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1481940\n",
      "\tspeed: 0.1416s/iter; left time: 2412.2036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1454901\n",
      "\tspeed: 0.0507s/iter; left time: 859.2595s\n",
      "\titers: 300, epoch: 2 | loss: 0.1338724\n",
      "\tspeed: 0.0507s/iter; left time: 853.2802s\n",
      "\titers: 400, epoch: 2 | loss: 0.1323974\n",
      "\tspeed: 0.0507s/iter; left time: 849.0272s\n",
      "\titers: 500, epoch: 2 | loss: 0.1412918\n",
      "\tspeed: 0.0506s/iter; left time: 842.7404s\n",
      "\titers: 600, epoch: 2 | loss: 0.1327669\n",
      "\tspeed: 0.0507s/iter; left time: 837.7773s\n",
      "\titers: 700, epoch: 2 | loss: 0.1384447\n",
      "\tspeed: 0.0506s/iter; left time: 832.4445s\n",
      "\titers: 800, epoch: 2 | loss: 0.1426750\n",
      "\tspeed: 0.0507s/iter; left time: 828.2160s\n",
      "\titers: 900, epoch: 2 | loss: 0.1431397\n",
      "\tspeed: 0.0506s/iter; left time: 821.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1400927 Vali Loss: 0.1554372 Test Loss: 0.1979454\n",
      "Validation loss decreased (0.174234 --> 0.155437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1327099\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1331211\n",
      "\tspeed: 0.0508s/iter; left time: 814.9257s\n",
      "\titers: 300, epoch: 3 | loss: 0.1262807\n",
      "\tspeed: 0.0507s/iter; left time: 808.6486s\n",
      "\titers: 400, epoch: 3 | loss: 0.1330259\n",
      "\tspeed: 0.0507s/iter; left time: 803.5242s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233167\n",
      "\tspeed: 0.0508s/iter; left time: 798.7087s\n",
      "\titers: 600, epoch: 3 | loss: 0.1312564\n",
      "\tspeed: 0.0508s/iter; left time: 794.0562s\n",
      "\titers: 700, epoch: 3 | loss: 0.1340061\n",
      "\tspeed: 0.0508s/iter; left time: 788.8538s\n",
      "\titers: 800, epoch: 3 | loss: 0.1299911\n",
      "\tspeed: 0.0508s/iter; left time: 783.7229s\n",
      "\titers: 900, epoch: 3 | loss: 0.1227380\n",
      "\tspeed: 0.0508s/iter; left time: 778.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1299872 Vali Loss: 0.1563615 Test Loss: 0.1916026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1271074\n",
      "\tspeed: 0.1384s/iter; left time: 2107.9744s\n",
      "\titers: 200, epoch: 4 | loss: 0.1254569\n",
      "\tspeed: 0.0508s/iter; left time: 768.8118s\n",
      "\titers: 300, epoch: 4 | loss: 0.1280436\n",
      "\tspeed: 0.0508s/iter; left time: 763.2334s\n",
      "\titers: 400, epoch: 4 | loss: 0.1153991\n",
      "\tspeed: 0.0508s/iter; left time: 758.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.1159150\n",
      "\tspeed: 0.0508s/iter; left time: 753.6041s\n",
      "\titers: 600, epoch: 4 | loss: 0.1088557\n",
      "\tspeed: 0.0508s/iter; left time: 748.8954s\n",
      "\titers: 700, epoch: 4 | loss: 0.1164074\n",
      "\tspeed: 0.0508s/iter; left time: 743.0256s\n",
      "\titers: 800, epoch: 4 | loss: 0.1089536\n",
      "\tspeed: 0.0508s/iter; left time: 738.1433s\n",
      "\titers: 900, epoch: 4 | loss: 0.1018279\n",
      "\tspeed: 0.0508s/iter; left time: 733.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 902 | Train Loss: 0.1170789 Vali Loss: 0.1380812 Test Loss: 0.1758089\n",
      "Validation loss decreased (0.155437 --> 0.138081).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0984079\n",
      "\tspeed: 0.1416s/iter; left time: 2029.5328s\n",
      "\titers: 200, epoch: 5 | loss: 0.1044581\n",
      "\tspeed: 0.0508s/iter; left time: 722.8784s\n",
      "\titers: 300, epoch: 5 | loss: 0.1054922\n",
      "\tspeed: 0.0508s/iter; left time: 717.7790s\n",
      "\titers: 400, epoch: 5 | loss: 0.1023428\n",
      "\tspeed: 0.0507s/iter; left time: 711.4377s\n",
      "\titers: 500, epoch: 5 | loss: 0.0925209\n",
      "\tspeed: 0.0507s/iter; left time: 706.7249s\n",
      "\titers: 600, epoch: 5 | loss: 0.1032169\n",
      "\tspeed: 0.0506s/iter; left time: 700.3312s\n",
      "\titers: 700, epoch: 5 | loss: 0.0928220\n",
      "\tspeed: 0.0507s/iter; left time: 696.7048s\n",
      "\titers: 800, epoch: 5 | loss: 0.0937007\n",
      "\tspeed: 0.0507s/iter; left time: 691.8461s\n",
      "\titers: 900, epoch: 5 | loss: 0.0924801\n",
      "\tspeed: 0.0508s/iter; left time: 687.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0993847 Vali Loss: 0.1335634 Test Loss: 0.1753410\n",
      "Validation loss decreased (0.138081 --> 0.133563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0887428\n",
      "\tspeed: 0.1454s/iter; left time: 1952.7363s\n",
      "\titers: 200, epoch: 6 | loss: 0.0971114\n",
      "\tspeed: 0.0520s/iter; left time: 692.8835s\n",
      "\titers: 300, epoch: 6 | loss: 0.0936855\n",
      "\tspeed: 0.0519s/iter; left time: 687.2491s\n",
      "\titers: 400, epoch: 6 | loss: 0.0994137\n",
      "\tspeed: 0.0518s/iter; left time: 680.3947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0940784\n",
      "\tspeed: 0.0512s/iter; left time: 666.7375s\n",
      "\titers: 600, epoch: 6 | loss: 0.0946007\n",
      "\tspeed: 0.0512s/iter; left time: 662.5407s\n",
      "\titers: 700, epoch: 6 | loss: 0.0885791\n",
      "\tspeed: 0.0515s/iter; left time: 660.2895s\n",
      "\titers: 800, epoch: 6 | loss: 0.0929599\n",
      "\tspeed: 0.0519s/iter; left time: 661.1869s\n",
      "\titers: 900, epoch: 6 | loss: 0.0841106\n",
      "\tspeed: 0.0519s/iter; left time: 655.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 902 | Train Loss: 0.0917087 Vali Loss: 0.1354960 Test Loss: 0.1834424\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0964288\n",
      "\tspeed: 0.1416s/iter; left time: 1773.7211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0859183\n",
      "\tspeed: 0.0512s/iter; left time: 636.0309s\n",
      "\titers: 300, epoch: 7 | loss: 0.0867437\n",
      "\tspeed: 0.0512s/iter; left time: 630.7155s\n",
      "\titers: 400, epoch: 7 | loss: 0.0866471\n",
      "\tspeed: 0.0512s/iter; left time: 625.6057s\n",
      "\titers: 500, epoch: 7 | loss: 0.0843690\n",
      "\tspeed: 0.0512s/iter; left time: 621.0936s\n",
      "\titers: 600, epoch: 7 | loss: 0.0867086\n",
      "\tspeed: 0.0511s/iter; left time: 615.2524s\n",
      "\titers: 700, epoch: 7 | loss: 0.0789776\n",
      "\tspeed: 0.0512s/iter; left time: 610.4739s\n",
      "\titers: 800, epoch: 7 | loss: 0.0838990\n",
      "\tspeed: 0.0513s/iter; left time: 606.5523s\n",
      "\titers: 900, epoch: 7 | loss: 0.0761397\n",
      "\tspeed: 0.0512s/iter; left time: 600.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 902 | Train Loss: 0.0856256 Vali Loss: 0.1398314 Test Loss: 0.1858543\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0796307\n",
      "\tspeed: 0.1429s/iter; left time: 1661.3558s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775476\n",
      "\tspeed: 0.0512s/iter; left time: 589.7926s\n",
      "\titers: 300, epoch: 8 | loss: 0.0838974\n",
      "\tspeed: 0.0522s/iter; left time: 596.2414s\n",
      "\titers: 400, epoch: 8 | loss: 0.0857031\n",
      "\tspeed: 0.0522s/iter; left time: 590.7387s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767407\n",
      "\tspeed: 0.0521s/iter; left time: 585.4244s\n",
      "\titers: 600, epoch: 8 | loss: 0.0837792\n",
      "\tspeed: 0.0519s/iter; left time: 577.5250s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778488\n",
      "\tspeed: 0.0513s/iter; left time: 565.8063s\n",
      "\titers: 800, epoch: 8 | loss: 0.0795030\n",
      "\tspeed: 0.0516s/iter; left time: 563.3232s\n",
      "\titers: 900, epoch: 8 | loss: 0.0821027\n",
      "\tspeed: 0.0516s/iter; left time: 558.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 902 | Train Loss: 0.0805042 Vali Loss: 0.1397548 Test Loss: 0.1822339\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0796983\n",
      "\tspeed: 0.1412s/iter; left time: 1514.5020s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759311\n",
      "\tspeed: 0.0512s/iter; left time: 544.0384s\n",
      "\titers: 300, epoch: 9 | loss: 0.0725377\n",
      "\tspeed: 0.0512s/iter; left time: 538.8407s\n",
      "\titers: 400, epoch: 9 | loss: 0.0776962\n",
      "\tspeed: 0.0512s/iter; left time: 533.6721s\n",
      "\titers: 500, epoch: 9 | loss: 0.0771654\n",
      "\tspeed: 0.0512s/iter; left time: 528.1837s\n",
      "\titers: 600, epoch: 9 | loss: 0.0781724\n",
      "\tspeed: 0.0511s/iter; left time: 522.8375s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747964\n",
      "\tspeed: 0.0512s/iter; left time: 518.1575s\n",
      "\titers: 800, epoch: 9 | loss: 0.0739248\n",
      "\tspeed: 0.0517s/iter; left time: 517.8308s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719263\n",
      "\tspeed: 0.0518s/iter; left time: 514.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.59s\n",
      "Steps: 902 | Train Loss: 0.0762764 Vali Loss: 0.1386382 Test Loss: 0.1837785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0757313\n",
      "\tspeed: 0.1425s/iter; left time: 1399.7111s\n",
      "\titers: 200, epoch: 10 | loss: 0.0703537\n",
      "\tspeed: 0.0512s/iter; left time: 497.8154s\n",
      "\titers: 300, epoch: 10 | loss: 0.0718045\n",
      "\tspeed: 0.0513s/iter; left time: 493.2416s\n",
      "\titers: 400, epoch: 10 | loss: 0.0759848\n",
      "\tspeed: 0.0512s/iter; left time: 487.4466s\n",
      "\titers: 500, epoch: 10 | loss: 0.0713861\n",
      "\tspeed: 0.0512s/iter; left time: 482.5811s\n",
      "\titers: 600, epoch: 10 | loss: 0.0714854\n",
      "\tspeed: 0.0512s/iter; left time: 477.5115s\n",
      "\titers: 700, epoch: 10 | loss: 0.0705916\n",
      "\tspeed: 0.0512s/iter; left time: 472.0964s\n",
      "\titers: 800, epoch: 10 | loss: 0.0715127\n",
      "\tspeed: 0.0511s/iter; left time: 466.4510s\n",
      "\titers: 900, epoch: 10 | loss: 0.0668258\n",
      "\tspeed: 0.0511s/iter; left time: 461.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.54s\n",
      "Steps: 902 | Train Loss: 0.0727178 Vali Loss: 0.1394037 Test Loss: 0.1799662\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06533545255661011, rmse:0.2556079924106598, mae:0.17534701526165009, rse:0.8861599564552307\n",
      "Intermediate time for GB and pred_len 168: 00h:17m:42.97s\n",
      "Intermediate time for GB: 00h:46m:50.95s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2269582\n",
      "\tspeed: 0.0550s/iter; left time: 992.0042s\n",
      "\titers: 200, epoch: 1 | loss: 0.2340235\n",
      "\tspeed: 0.0340s/iter; left time: 609.4055s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960561\n",
      "\tspeed: 0.0340s/iter; left time: 605.0591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1941898\n",
      "\tspeed: 0.0340s/iter; left time: 602.1440s\n",
      "\titers: 500, epoch: 1 | loss: 0.1761629\n",
      "\tspeed: 0.0340s/iter; left time: 598.6742s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717397\n",
      "\tspeed: 0.0340s/iter; left time: 595.3969s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656946\n",
      "\tspeed: 0.0340s/iter; left time: 592.7206s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516853\n",
      "\tspeed: 0.0341s/iter; left time: 590.1445s\n",
      "\titers: 900, epoch: 1 | loss: 0.1433492\n",
      "\tspeed: 0.0340s/iter; left time: 585.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.53s\n",
      "Steps: 906 | Train Loss: 0.1867150 Vali Loss: 0.1149514 Test Loss: 0.1356010\n",
      "Validation loss decreased (inf --> 0.114951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169975\n",
      "\tspeed: 0.0965s/iter; left time: 1651.4534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949514\n",
      "\tspeed: 0.0340s/iter; left time: 578.8318s\n",
      "\titers: 300, epoch: 2 | loss: 0.0899529\n",
      "\tspeed: 0.0340s/iter; left time: 575.2054s\n",
      "\titers: 400, epoch: 2 | loss: 0.0936027\n",
      "\tspeed: 0.0340s/iter; left time: 571.3918s\n",
      "\titers: 500, epoch: 2 | loss: 0.0845074\n",
      "\tspeed: 0.0340s/iter; left time: 569.1422s\n",
      "\titers: 600, epoch: 2 | loss: 0.0868874\n",
      "\tspeed: 0.0340s/iter; left time: 564.8397s\n",
      "\titers: 700, epoch: 2 | loss: 0.0824947\n",
      "\tspeed: 0.0341s/iter; left time: 562.8252s\n",
      "\titers: 800, epoch: 2 | loss: 0.0807727\n",
      "\tspeed: 0.0341s/iter; left time: 559.1457s\n",
      "\titers: 900, epoch: 2 | loss: 0.0765388\n",
      "\tspeed: 0.0341s/iter; left time: 556.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0929535 Vali Loss: 0.0793667 Test Loss: 0.1067031\n",
      "Validation loss decreased (0.114951 --> 0.079367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0782373\n",
      "\tspeed: 0.0961s/iter; left time: 1557.6559s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824538\n",
      "\tspeed: 0.0341s/iter; left time: 548.9010s\n",
      "\titers: 300, epoch: 3 | loss: 0.0756728\n",
      "\tspeed: 0.0341s/iter; left time: 545.3158s\n",
      "\titers: 400, epoch: 3 | loss: 0.0700887\n",
      "\tspeed: 0.0341s/iter; left time: 542.1123s\n",
      "\titers: 500, epoch: 3 | loss: 0.0729940\n",
      "\tspeed: 0.0340s/iter; left time: 538.0838s\n",
      "\titers: 600, epoch: 3 | loss: 0.0716531\n",
      "\tspeed: 0.0340s/iter; left time: 534.1571s\n",
      "\titers: 700, epoch: 3 | loss: 0.0698253\n",
      "\tspeed: 0.0340s/iter; left time: 530.2364s\n",
      "\titers: 800, epoch: 3 | loss: 0.0800202\n",
      "\tspeed: 0.0340s/iter; left time: 527.0752s\n",
      "\titers: 900, epoch: 3 | loss: 0.0685005\n",
      "\tspeed: 0.0340s/iter; left time: 523.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0724489 Vali Loss: 0.0711922 Test Loss: 0.0986497\n",
      "Validation loss decreased (0.079367 --> 0.071192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0684435\n",
      "\tspeed: 0.0961s/iter; left time: 1470.2668s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712164\n",
      "\tspeed: 0.0340s/iter; left time: 516.3544s\n",
      "\titers: 300, epoch: 4 | loss: 0.0667114\n",
      "\tspeed: 0.0340s/iter; left time: 513.2033s\n",
      "\titers: 400, epoch: 4 | loss: 0.0691570\n",
      "\tspeed: 0.0340s/iter; left time: 509.5055s\n",
      "\titers: 500, epoch: 4 | loss: 0.0596550\n",
      "\tspeed: 0.0340s/iter; left time: 506.2716s\n",
      "\titers: 600, epoch: 4 | loss: 0.0636415\n",
      "\tspeed: 0.0340s/iter; left time: 503.0966s\n",
      "\titers: 700, epoch: 4 | loss: 0.0748894\n",
      "\tspeed: 0.0340s/iter; left time: 499.3996s\n",
      "\titers: 800, epoch: 4 | loss: 0.0641811\n",
      "\tspeed: 0.0340s/iter; left time: 496.2536s\n",
      "\titers: 900, epoch: 4 | loss: 0.0688866\n",
      "\tspeed: 0.0340s/iter; left time: 493.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0664552 Vali Loss: 0.0674176 Test Loss: 0.0996465\n",
      "Validation loss decreased (0.071192 --> 0.067418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659110\n",
      "\tspeed: 0.0963s/iter; left time: 1386.2203s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593955\n",
      "\tspeed: 0.0340s/iter; left time: 486.4223s\n",
      "\titers: 300, epoch: 5 | loss: 0.0572287\n",
      "\tspeed: 0.0341s/iter; left time: 483.8240s\n",
      "\titers: 400, epoch: 5 | loss: 0.0633422\n",
      "\tspeed: 0.0341s/iter; left time: 480.0095s\n",
      "\titers: 500, epoch: 5 | loss: 0.0599107\n",
      "\tspeed: 0.0340s/iter; left time: 476.1896s\n",
      "\titers: 600, epoch: 5 | loss: 0.0616285\n",
      "\tspeed: 0.0340s/iter; left time: 472.5554s\n",
      "\titers: 700, epoch: 5 | loss: 0.0670126\n",
      "\tspeed: 0.0341s/iter; left time: 469.9486s\n",
      "\titers: 800, epoch: 5 | loss: 0.0574715\n",
      "\tspeed: 0.0340s/iter; left time: 465.9960s\n",
      "\titers: 900, epoch: 5 | loss: 0.0618266\n",
      "\tspeed: 0.0341s/iter; left time: 463.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0625747 Vali Loss: 0.0616929 Test Loss: 0.0898060\n",
      "Validation loss decreased (0.067418 --> 0.061693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630031\n",
      "\tspeed: 0.0964s/iter; left time: 1300.5169s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529410\n",
      "\tspeed: 0.0341s/iter; left time: 456.7115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0593784\n",
      "\tspeed: 0.0341s/iter; left time: 452.8869s\n",
      "\titers: 400, epoch: 6 | loss: 0.0604928\n",
      "\tspeed: 0.0341s/iter; left time: 449.6964s\n",
      "\titers: 500, epoch: 6 | loss: 0.0600843\n",
      "\tspeed: 0.0341s/iter; left time: 445.9873s\n",
      "\titers: 600, epoch: 6 | loss: 0.0581049\n",
      "\tspeed: 0.0340s/iter; left time: 442.1294s\n",
      "\titers: 700, epoch: 6 | loss: 0.0540081\n",
      "\tspeed: 0.0340s/iter; left time: 438.9322s\n",
      "\titers: 800, epoch: 6 | loss: 0.0625412\n",
      "\tspeed: 0.0341s/iter; left time: 436.3913s\n",
      "\titers: 900, epoch: 6 | loss: 0.0629828\n",
      "\tspeed: 0.0340s/iter; left time: 432.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0593687 Vali Loss: 0.0626056 Test Loss: 0.0942342\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566213\n",
      "\tspeed: 0.0931s/iter; left time: 1171.3166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0615168\n",
      "\tspeed: 0.0341s/iter; left time: 425.2691s\n",
      "\titers: 300, epoch: 7 | loss: 0.0562484\n",
      "\tspeed: 0.0340s/iter; left time: 421.6475s\n",
      "\titers: 400, epoch: 7 | loss: 0.0569425\n",
      "\tspeed: 0.0340s/iter; left time: 417.6220s\n",
      "\titers: 500, epoch: 7 | loss: 0.0591812\n",
      "\tspeed: 0.0340s/iter; left time: 414.2646s\n",
      "\titers: 600, epoch: 7 | loss: 0.0496640\n",
      "\tspeed: 0.0340s/iter; left time: 410.5183s\n",
      "\titers: 700, epoch: 7 | loss: 0.0547029\n",
      "\tspeed: 0.0341s/iter; left time: 408.5837s\n",
      "\titers: 800, epoch: 7 | loss: 0.0546945\n",
      "\tspeed: 0.0341s/iter; left time: 404.6913s\n",
      "\titers: 900, epoch: 7 | loss: 0.0594512\n",
      "\tspeed: 0.0340s/iter; left time: 400.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0569890 Vali Loss: 0.0593294 Test Loss: 0.0925540\n",
      "Validation loss decreased (0.061693 --> 0.059329).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0525238\n",
      "\tspeed: 0.0961s/iter; left time: 1122.0307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0508008\n",
      "\tspeed: 0.0341s/iter; left time: 395.2702s\n",
      "\titers: 300, epoch: 8 | loss: 0.0481101\n",
      "\tspeed: 0.0341s/iter; left time: 391.3141s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521681\n",
      "\tspeed: 0.0340s/iter; left time: 387.3520s\n",
      "\titers: 500, epoch: 8 | loss: 0.0577647\n",
      "\tspeed: 0.0341s/iter; left time: 384.1358s\n",
      "\titers: 600, epoch: 8 | loss: 0.0543726\n",
      "\tspeed: 0.0341s/iter; left time: 380.7608s\n",
      "\titers: 700, epoch: 8 | loss: 0.0620679\n",
      "\tspeed: 0.0340s/iter; left time: 377.0847s\n",
      "\titers: 800, epoch: 8 | loss: 0.0583911\n",
      "\tspeed: 0.0341s/iter; left time: 374.1237s\n",
      "\titers: 900, epoch: 8 | loss: 0.0578499\n",
      "\tspeed: 0.0341s/iter; left time: 371.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0550839 Vali Loss: 0.0594405 Test Loss: 0.0994523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0505213\n",
      "\tspeed: 0.0943s/iter; left time: 1016.4260s\n",
      "\titers: 200, epoch: 9 | loss: 0.0526453\n",
      "\tspeed: 0.0341s/iter; left time: 363.7700s\n",
      "\titers: 300, epoch: 9 | loss: 0.0561748\n",
      "\tspeed: 0.0340s/iter; left time: 359.7932s\n",
      "\titers: 400, epoch: 9 | loss: 0.0582262\n",
      "\tspeed: 0.0340s/iter; left time: 356.2626s\n",
      "\titers: 500, epoch: 9 | loss: 0.0561789\n",
      "\tspeed: 0.0340s/iter; left time: 353.0543s\n",
      "\titers: 600, epoch: 9 | loss: 0.0563085\n",
      "\tspeed: 0.0340s/iter; left time: 349.3051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0522479\n",
      "\tspeed: 0.0340s/iter; left time: 345.8892s\n",
      "\titers: 800, epoch: 9 | loss: 0.0538578\n",
      "\tspeed: 0.0341s/iter; left time: 343.1276s\n",
      "\titers: 900, epoch: 9 | loss: 0.0456325\n",
      "\tspeed: 0.0341s/iter; left time: 339.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0536204 Vali Loss: 0.0587028 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.059329 --> 0.058703).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546516\n",
      "\tspeed: 0.0962s/iter; left time: 949.1378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576164\n",
      "\tspeed: 0.0341s/iter; left time: 332.6549s\n",
      "\titers: 300, epoch: 10 | loss: 0.0522396\n",
      "\tspeed: 0.0341s/iter; left time: 329.2737s\n",
      "\titers: 400, epoch: 10 | loss: 0.0645304\n",
      "\tspeed: 0.0341s/iter; left time: 326.1944s\n",
      "\titers: 500, epoch: 10 | loss: 0.0542212\n",
      "\tspeed: 0.0341s/iter; left time: 322.6437s\n",
      "\titers: 600, epoch: 10 | loss: 0.0521068\n",
      "\tspeed: 0.0341s/iter; left time: 319.2733s\n",
      "\titers: 700, epoch: 10 | loss: 0.0592318\n",
      "\tspeed: 0.0341s/iter; left time: 315.9926s\n",
      "\titers: 800, epoch: 10 | loss: 0.0469309\n",
      "\tspeed: 0.0341s/iter; left time: 312.1414s\n",
      "\titers: 900, epoch: 10 | loss: 0.0504858\n",
      "\tspeed: 0.0341s/iter; left time: 309.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0521291 Vali Loss: 0.0587004 Test Loss: 0.0948160\n",
      "Validation loss decreased (0.058703 --> 0.058700).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0521655\n",
      "\tspeed: 0.0968s/iter; left time: 867.6632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465787\n",
      "\tspeed: 0.0340s/iter; left time: 301.1818s\n",
      "\titers: 300, epoch: 11 | loss: 0.0509172\n",
      "\tspeed: 0.0340s/iter; left time: 297.5199s\n",
      "\titers: 400, epoch: 11 | loss: 0.0459693\n",
      "\tspeed: 0.0340s/iter; left time: 294.1597s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552192\n",
      "\tspeed: 0.0340s/iter; left time: 290.9819s\n",
      "\titers: 600, epoch: 11 | loss: 0.0559179\n",
      "\tspeed: 0.0340s/iter; left time: 287.9101s\n",
      "\titers: 700, epoch: 11 | loss: 0.0514091\n",
      "\tspeed: 0.0340s/iter; left time: 284.3034s\n",
      "\titers: 800, epoch: 11 | loss: 0.0528125\n",
      "\tspeed: 0.0340s/iter; left time: 281.0131s\n",
      "\titers: 900, epoch: 11 | loss: 0.0530001\n",
      "\tspeed: 0.0341s/iter; left time: 278.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0510566 Vali Loss: 0.0590035 Test Loss: 0.0986896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558984\n",
      "\tspeed: 0.0930s/iter; left time: 748.7564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513471\n",
      "\tspeed: 0.0340s/iter; left time: 270.8496s\n",
      "\titers: 300, epoch: 12 | loss: 0.0471879\n",
      "\tspeed: 0.0340s/iter; left time: 267.1381s\n",
      "\titers: 400, epoch: 12 | loss: 0.0593381\n",
      "\tspeed: 0.0341s/iter; left time: 264.3435s\n",
      "\titers: 500, epoch: 12 | loss: 0.0527025\n",
      "\tspeed: 0.0340s/iter; left time: 260.3050s\n",
      "\titers: 600, epoch: 12 | loss: 0.0466901\n",
      "\tspeed: 0.0340s/iter; left time: 257.1148s\n",
      "\titers: 700, epoch: 12 | loss: 0.0478527\n",
      "\tspeed: 0.0341s/iter; left time: 254.0793s\n",
      "\titers: 800, epoch: 12 | loss: 0.0519875\n",
      "\tspeed: 0.0340s/iter; left time: 250.2279s\n",
      "\titers: 900, epoch: 12 | loss: 0.0480679\n",
      "\tspeed: 0.0341s/iter; left time: 247.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0497550 Vali Loss: 0.0586147 Test Loss: 0.0984036\n",
      "Validation loss decreased (0.058700 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0475071\n",
      "\tspeed: 0.0975s/iter; left time: 697.0758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0483188\n",
      "\tspeed: 0.0340s/iter; left time: 239.9376s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545818\n",
      "\tspeed: 0.0340s/iter; left time: 236.5292s\n",
      "\titers: 400, epoch: 13 | loss: 0.0468574\n",
      "\tspeed: 0.0341s/iter; left time: 233.2553s\n",
      "\titers: 500, epoch: 13 | loss: 0.0488363\n",
      "\tspeed: 0.0341s/iter; left time: 230.0322s\n",
      "\titers: 600, epoch: 13 | loss: 0.0478834\n",
      "\tspeed: 0.0341s/iter; left time: 226.4960s\n",
      "\titers: 700, epoch: 13 | loss: 0.0478704\n",
      "\tspeed: 0.0341s/iter; left time: 223.1881s\n",
      "\titers: 800, epoch: 13 | loss: 0.0492090\n",
      "\tspeed: 0.0341s/iter; left time: 219.5957s\n",
      "\titers: 900, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.0341s/iter; left time: 216.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0488156 Vali Loss: 0.0577360 Test Loss: 0.0999878\n",
      "Validation loss decreased (0.058615 --> 0.057736).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0482094\n",
      "\tspeed: 0.0963s/iter; left time: 600.9922s\n",
      "\titers: 200, epoch: 14 | loss: 0.0487748\n",
      "\tspeed: 0.0340s/iter; left time: 209.1014s\n",
      "\titers: 300, epoch: 14 | loss: 0.0462699\n",
      "\tspeed: 0.0340s/iter; left time: 205.6403s\n",
      "\titers: 400, epoch: 14 | loss: 0.0482816\n",
      "\tspeed: 0.0340s/iter; left time: 202.0444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0434202\n",
      "\tspeed: 0.0340s/iter; left time: 198.6776s\n",
      "\titers: 600, epoch: 14 | loss: 0.0466136\n",
      "\tspeed: 0.0340s/iter; left time: 195.1986s\n",
      "\titers: 700, epoch: 14 | loss: 0.0498906\n",
      "\tspeed: 0.0340s/iter; left time: 191.8812s\n",
      "\titers: 800, epoch: 14 | loss: 0.0559277\n",
      "\tspeed: 0.0340s/iter; left time: 188.5343s\n",
      "\titers: 900, epoch: 14 | loss: 0.0500410\n",
      "\tspeed: 0.0340s/iter; left time: 185.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0481153 Vali Loss: 0.0569008 Test Loss: 0.0974887\n",
      "Validation loss decreased (0.057736 --> 0.056901).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0479455\n",
      "\tspeed: 0.0969s/iter; left time: 516.9925s\n",
      "\titers: 200, epoch: 15 | loss: 0.0423490\n",
      "\tspeed: 0.0340s/iter; left time: 178.2323s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470223\n",
      "\tspeed: 0.0340s/iter; left time: 174.7335s\n",
      "\titers: 400, epoch: 15 | loss: 0.0487020\n",
      "\tspeed: 0.0339s/iter; left time: 170.9948s\n",
      "\titers: 500, epoch: 15 | loss: 0.0482308\n",
      "\tspeed: 0.0341s/iter; left time: 168.3506s\n",
      "\titers: 600, epoch: 15 | loss: 0.0490022\n",
      "\tspeed: 0.0340s/iter; left time: 164.6517s\n",
      "\titers: 700, epoch: 15 | loss: 0.0457250\n",
      "\tspeed: 0.0341s/iter; left time: 161.4815s\n",
      "\titers: 800, epoch: 15 | loss: 0.0414258\n",
      "\tspeed: 0.0341s/iter; left time: 158.1757s\n",
      "\titers: 900, epoch: 15 | loss: 0.0480889\n",
      "\tspeed: 0.0341s/iter; left time: 154.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0471749 Vali Loss: 0.0581755 Test Loss: 0.1011218\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0504668\n",
      "\tspeed: 0.0941s/iter; left time: 417.0276s\n",
      "\titers: 200, epoch: 16 | loss: 0.0505805\n",
      "\tspeed: 0.0341s/iter; left time: 147.6880s\n",
      "\titers: 300, epoch: 16 | loss: 0.0436730\n",
      "\tspeed: 0.0341s/iter; left time: 144.1782s\n",
      "\titers: 400, epoch: 16 | loss: 0.0441560\n",
      "\tspeed: 0.0341s/iter; left time: 140.7082s\n",
      "\titers: 500, epoch: 16 | loss: 0.0476777\n",
      "\tspeed: 0.0340s/iter; left time: 137.1863s\n",
      "\titers: 600, epoch: 16 | loss: 0.0439132\n",
      "\tspeed: 0.0340s/iter; left time: 133.7169s\n",
      "\titers: 700, epoch: 16 | loss: 0.0488481\n",
      "\tspeed: 0.0341s/iter; left time: 130.6403s\n",
      "\titers: 800, epoch: 16 | loss: 0.0411422\n",
      "\tspeed: 0.0341s/iter; left time: 127.0459s\n",
      "\titers: 900, epoch: 16 | loss: 0.0461350\n",
      "\tspeed: 0.0341s/iter; left time: 123.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0463692 Vali Loss: 0.0586193 Test Loss: 0.1046662\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0439602\n",
      "\tspeed: 0.0929s/iter; left time: 327.3871s\n",
      "\titers: 200, epoch: 17 | loss: 0.0481706\n",
      "\tspeed: 0.0340s/iter; left time: 116.5163s\n",
      "\titers: 300, epoch: 17 | loss: 0.0420253\n",
      "\tspeed: 0.0340s/iter; left time: 112.9836s\n",
      "\titers: 400, epoch: 17 | loss: 0.0496195\n",
      "\tspeed: 0.0340s/iter; left time: 109.5946s\n",
      "\titers: 500, epoch: 17 | loss: 0.0452397\n",
      "\tspeed: 0.0340s/iter; left time: 106.2796s\n",
      "\titers: 600, epoch: 17 | loss: 0.0468022\n",
      "\tspeed: 0.0340s/iter; left time: 102.8425s\n",
      "\titers: 700, epoch: 17 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 99.4661s\n",
      "\titers: 800, epoch: 17 | loss: 0.0520706\n",
      "\tspeed: 0.0341s/iter; left time: 96.2139s\n",
      "\titers: 900, epoch: 17 | loss: 0.0444759\n",
      "\tspeed: 0.0340s/iter; left time: 92.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0455342 Vali Loss: 0.0581641 Test Loss: 0.1017385\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0446145\n",
      "\tspeed: 0.0929s/iter; left time: 243.4311s\n",
      "\titers: 200, epoch: 18 | loss: 0.0440156\n",
      "\tspeed: 0.0340s/iter; left time: 85.6971s\n",
      "\titers: 300, epoch: 18 | loss: 0.0425779\n",
      "\tspeed: 0.0340s/iter; left time: 82.2397s\n",
      "\titers: 400, epoch: 18 | loss: 0.0449517\n",
      "\tspeed: 0.0340s/iter; left time: 78.9489s\n",
      "\titers: 500, epoch: 18 | loss: 0.0484834\n",
      "\tspeed: 0.0340s/iter; left time: 75.5547s\n",
      "\titers: 600, epoch: 18 | loss: 0.0420635\n",
      "\tspeed: 0.0340s/iter; left time: 72.1029s\n",
      "\titers: 700, epoch: 18 | loss: 0.0470141\n",
      "\tspeed: 0.0340s/iter; left time: 68.6295s\n",
      "\titers: 800, epoch: 18 | loss: 0.0419604\n",
      "\tspeed: 0.0341s/iter; left time: 65.3850s\n",
      "\titers: 900, epoch: 18 | loss: 0.0463720\n",
      "\tspeed: 0.0340s/iter; left time: 61.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0450904 Vali Loss: 0.0583875 Test Loss: 0.1041857\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0424898\n",
      "\tspeed: 0.0931s/iter; left time: 159.4494s\n",
      "\titers: 200, epoch: 19 | loss: 0.0434248\n",
      "\tspeed: 0.0340s/iter; left time: 54.8737s\n",
      "\titers: 300, epoch: 19 | loss: 0.0410817\n",
      "\tspeed: 0.0340s/iter; left time: 51.4603s\n",
      "\titers: 400, epoch: 19 | loss: 0.0418899\n",
      "\tspeed: 0.0340s/iter; left time: 48.0451s\n",
      "\titers: 500, epoch: 19 | loss: 0.0446364\n",
      "\tspeed: 0.0341s/iter; left time: 44.7165s\n",
      "\titers: 600, epoch: 19 | loss: 0.0444938\n",
      "\tspeed: 0.0340s/iter; left time: 41.2340s\n",
      "\titers: 700, epoch: 19 | loss: 0.0418383\n",
      "\tspeed: 0.0341s/iter; left time: 37.9425s\n",
      "\titers: 800, epoch: 19 | loss: 0.0464259\n",
      "\tspeed: 0.0340s/iter; left time: 34.4403s\n",
      "\titers: 900, epoch: 19 | loss: 0.0461343\n",
      "\tspeed: 0.0340s/iter; left time: 31.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0444866 Vali Loss: 0.0587221 Test Loss: 0.1070130\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027461538091301918, rmse:0.16571523249149323, mae:0.09743039309978485, rse:0.4869214594364166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2149062\n",
      "\tspeed: 0.0359s/iter; left time: 647.8177s\n",
      "\titers: 200, epoch: 1 | loss: 0.2208412\n",
      "\tspeed: 0.0340s/iter; left time: 609.6411s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960506\n",
      "\tspeed: 0.0341s/iter; left time: 607.1201s\n",
      "\titers: 400, epoch: 1 | loss: 0.1785244\n",
      "\tspeed: 0.0341s/iter; left time: 604.3089s\n",
      "\titers: 500, epoch: 1 | loss: 0.1606690\n",
      "\tspeed: 0.0341s/iter; left time: 601.1981s\n",
      "\titers: 600, epoch: 1 | loss: 0.1587723\n",
      "\tspeed: 0.0341s/iter; left time: 597.8329s\n",
      "\titers: 700, epoch: 1 | loss: 0.1492396\n",
      "\tspeed: 0.0341s/iter; left time: 593.4278s\n",
      "\titers: 800, epoch: 1 | loss: 0.1445469\n",
      "\tspeed: 0.0341s/iter; left time: 590.6606s\n",
      "\titers: 900, epoch: 1 | loss: 0.1369113\n",
      "\tspeed: 0.0341s/iter; left time: 587.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.1828038 Vali Loss: 0.1089664 Test Loss: 0.1298395\n",
      "Validation loss decreased (inf --> 0.108966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1135225\n",
      "\tspeed: 0.0967s/iter; left time: 1655.7642s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148164\n",
      "\tspeed: 0.0341s/iter; left time: 579.4230s\n",
      "\titers: 300, epoch: 2 | loss: 0.0936463\n",
      "\tspeed: 0.0340s/iter; left time: 575.6874s\n",
      "\titers: 400, epoch: 2 | loss: 0.0820305\n",
      "\tspeed: 0.0340s/iter; left time: 571.7097s\n",
      "\titers: 500, epoch: 2 | loss: 0.0843619\n",
      "\tspeed: 0.0340s/iter; left time: 568.8378s\n",
      "\titers: 600, epoch: 2 | loss: 0.0846980\n",
      "\tspeed: 0.0341s/iter; left time: 565.9215s\n",
      "\titers: 700, epoch: 2 | loss: 0.0829176\n",
      "\tspeed: 0.0341s/iter; left time: 562.3783s\n",
      "\titers: 800, epoch: 2 | loss: 0.0821716\n",
      "\tspeed: 0.0341s/iter; left time: 559.9984s\n",
      "\titers: 900, epoch: 2 | loss: 0.0759475\n",
      "\tspeed: 0.0341s/iter; left time: 555.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0933928 Vali Loss: 0.0766692 Test Loss: 0.1036709\n",
      "Validation loss decreased (0.108966 --> 0.076669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689353\n",
      "\tspeed: 0.0964s/iter; left time: 1562.7546s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678947\n",
      "\tspeed: 0.0341s/iter; left time: 548.5724s\n",
      "\titers: 300, epoch: 3 | loss: 0.0727085\n",
      "\tspeed: 0.0340s/iter; left time: 544.8113s\n",
      "\titers: 400, epoch: 3 | loss: 0.0748758\n",
      "\tspeed: 0.0341s/iter; left time: 542.3137s\n",
      "\titers: 500, epoch: 3 | loss: 0.0773622\n",
      "\tspeed: 0.0341s/iter; left time: 538.4005s\n",
      "\titers: 600, epoch: 3 | loss: 0.0685271\n",
      "\tspeed: 0.0341s/iter; left time: 535.4238s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751804\n",
      "\tspeed: 0.0341s/iter; left time: 532.3713s\n",
      "\titers: 800, epoch: 3 | loss: 0.0565176\n",
      "\tspeed: 0.0341s/iter; left time: 528.6195s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646926\n",
      "\tspeed: 0.0341s/iter; left time: 524.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0711776 Vali Loss: 0.0796852 Test Loss: 0.1065500\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657408\n",
      "\tspeed: 0.0928s/iter; left time: 1419.9932s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647836\n",
      "\tspeed: 0.0341s/iter; left time: 518.5229s\n",
      "\titers: 300, epoch: 4 | loss: 0.0649817\n",
      "\tspeed: 0.0341s/iter; left time: 514.9193s\n",
      "\titers: 400, epoch: 4 | loss: 0.0786881\n",
      "\tspeed: 0.0341s/iter; left time: 512.0881s\n",
      "\titers: 500, epoch: 4 | loss: 0.0712274\n",
      "\tspeed: 0.0341s/iter; left time: 507.5204s\n",
      "\titers: 600, epoch: 4 | loss: 0.0682974\n",
      "\tspeed: 0.0342s/iter; left time: 505.6659s\n",
      "\titers: 700, epoch: 4 | loss: 0.0697354\n",
      "\tspeed: 0.0342s/iter; left time: 502.1557s\n",
      "\titers: 800, epoch: 4 | loss: 0.0585399\n",
      "\tspeed: 0.0341s/iter; left time: 498.6690s\n",
      "\titers: 900, epoch: 4 | loss: 0.0596235\n",
      "\tspeed: 0.0341s/iter; left time: 494.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0653138 Vali Loss: 0.0680534 Test Loss: 0.0976341\n",
      "Validation loss decreased (0.076669 --> 0.068053).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0725577\n",
      "\tspeed: 0.0963s/iter; left time: 1386.6411s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573841\n",
      "\tspeed: 0.0340s/iter; left time: 486.6671s\n",
      "\titers: 300, epoch: 5 | loss: 0.0539423\n",
      "\tspeed: 0.0341s/iter; left time: 483.5814s\n",
      "\titers: 400, epoch: 5 | loss: 0.0593723\n",
      "\tspeed: 0.0341s/iter; left time: 480.2758s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631876\n",
      "\tspeed: 0.0340s/iter; left time: 476.5368s\n",
      "\titers: 600, epoch: 5 | loss: 0.0533562\n",
      "\tspeed: 0.0341s/iter; left time: 473.4310s\n",
      "\titers: 700, epoch: 5 | loss: 0.0583013\n",
      "\tspeed: 0.0341s/iter; left time: 470.4378s\n",
      "\titers: 800, epoch: 5 | loss: 0.0527938\n",
      "\tspeed: 0.0340s/iter; left time: 466.2385s\n",
      "\titers: 900, epoch: 5 | loss: 0.0549873\n",
      "\tspeed: 0.0341s/iter; left time: 463.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0610250 Vali Loss: 0.0610558 Test Loss: 0.0921888\n",
      "Validation loss decreased (0.068053 --> 0.061056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0580953\n",
      "\tspeed: 0.0960s/iter; left time: 1295.5002s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602082\n",
      "\tspeed: 0.0340s/iter; left time: 455.9594s\n",
      "\titers: 300, epoch: 6 | loss: 0.0604460\n",
      "\tspeed: 0.0340s/iter; left time: 452.2778s\n",
      "\titers: 400, epoch: 6 | loss: 0.0563742\n",
      "\tspeed: 0.0341s/iter; left time: 449.4301s\n",
      "\titers: 500, epoch: 6 | loss: 0.0530320\n",
      "\tspeed: 0.0341s/iter; left time: 445.9065s\n",
      "\titers: 600, epoch: 6 | loss: 0.0533875\n",
      "\tspeed: 0.0340s/iter; left time: 441.9325s\n",
      "\titers: 700, epoch: 6 | loss: 0.0524571\n",
      "\tspeed: 0.0340s/iter; left time: 438.9373s\n",
      "\titers: 800, epoch: 6 | loss: 0.0500506\n",
      "\tspeed: 0.0340s/iter; left time: 435.2579s\n",
      "\titers: 900, epoch: 6 | loss: 0.0613379\n",
      "\tspeed: 0.0340s/iter; left time: 432.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0579149 Vali Loss: 0.0589280 Test Loss: 0.0870637\n",
      "Validation loss decreased (0.061056 --> 0.058928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542730\n",
      "\tspeed: 0.0957s/iter; left time: 1203.9772s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584979\n",
      "\tspeed: 0.0341s/iter; left time: 425.1150s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552041\n",
      "\tspeed: 0.0341s/iter; left time: 421.9635s\n",
      "\titers: 400, epoch: 7 | loss: 0.0513719\n",
      "\tspeed: 0.0340s/iter; left time: 418.0528s\n",
      "\titers: 500, epoch: 7 | loss: 0.0545608\n",
      "\tspeed: 0.0341s/iter; left time: 415.9115s\n",
      "\titers: 600, epoch: 7 | loss: 0.0571133\n",
      "\tspeed: 0.0341s/iter; left time: 411.7257s\n",
      "\titers: 700, epoch: 7 | loss: 0.0540548\n",
      "\tspeed: 0.0341s/iter; left time: 408.3959s\n",
      "\titers: 800, epoch: 7 | loss: 0.0513388\n",
      "\tspeed: 0.0341s/iter; left time: 405.2208s\n",
      "\titers: 900, epoch: 7 | loss: 0.0515127\n",
      "\tspeed: 0.0341s/iter; left time: 401.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0555515 Vali Loss: 0.0638483 Test Loss: 0.0944871\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0527631\n",
      "\tspeed: 0.0929s/iter; left time: 1085.3560s\n",
      "\titers: 200, epoch: 8 | loss: 0.0519219\n",
      "\tspeed: 0.0341s/iter; left time: 394.8668s\n",
      "\titers: 300, epoch: 8 | loss: 0.0529470\n",
      "\tspeed: 0.0341s/iter; left time: 391.2811s\n",
      "\titers: 400, epoch: 8 | loss: 0.0566683\n",
      "\tspeed: 0.0341s/iter; left time: 387.8255s\n",
      "\titers: 500, epoch: 8 | loss: 0.0511631\n",
      "\tspeed: 0.0341s/iter; left time: 384.8334s\n",
      "\titers: 600, epoch: 8 | loss: 0.0515833\n",
      "\tspeed: 0.0341s/iter; left time: 381.1682s\n",
      "\titers: 700, epoch: 8 | loss: 0.0480705\n",
      "\tspeed: 0.0341s/iter; left time: 377.5911s\n",
      "\titers: 800, epoch: 8 | loss: 0.0580791\n",
      "\tspeed: 0.0340s/iter; left time: 373.7311s\n",
      "\titers: 900, epoch: 8 | loss: 0.0615418\n",
      "\tspeed: 0.0341s/iter; left time: 370.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0541977 Vali Loss: 0.0600997 Test Loss: 0.0928956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0542574\n",
      "\tspeed: 0.0933s/iter; left time: 1004.7664s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516183\n",
      "\tspeed: 0.0340s/iter; left time: 363.3126s\n",
      "\titers: 300, epoch: 9 | loss: 0.0530071\n",
      "\tspeed: 0.0340s/iter; left time: 359.3725s\n",
      "\titers: 400, epoch: 9 | loss: 0.0483792\n",
      "\tspeed: 0.0340s/iter; left time: 356.3748s\n",
      "\titers: 500, epoch: 9 | loss: 0.0543778\n",
      "\tspeed: 0.0340s/iter; left time: 353.1151s\n",
      "\titers: 600, epoch: 9 | loss: 0.0531961\n",
      "\tspeed: 0.0340s/iter; left time: 349.6051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0557334\n",
      "\tspeed: 0.0340s/iter; left time: 346.2001s\n",
      "\titers: 800, epoch: 9 | loss: 0.0548735\n",
      "\tspeed: 0.0340s/iter; left time: 342.9241s\n",
      "\titers: 900, epoch: 9 | loss: 0.0554635\n",
      "\tspeed: 0.0340s/iter; left time: 339.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0527868 Vali Loss: 0.0606648 Test Loss: 0.0891905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564716\n",
      "\tspeed: 0.0931s/iter; left time: 918.4250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536913\n",
      "\tspeed: 0.0340s/iter; left time: 332.3861s\n",
      "\titers: 300, epoch: 10 | loss: 0.0534131\n",
      "\tspeed: 0.0341s/iter; left time: 329.2227s\n",
      "\titers: 400, epoch: 10 | loss: 0.0569648\n",
      "\tspeed: 0.0340s/iter; left time: 325.5396s\n",
      "\titers: 500, epoch: 10 | loss: 0.0553950\n",
      "\tspeed: 0.0340s/iter; left time: 322.3328s\n",
      "\titers: 600, epoch: 10 | loss: 0.0504877\n",
      "\tspeed: 0.0341s/iter; left time: 319.2523s\n",
      "\titers: 700, epoch: 10 | loss: 0.0442066\n",
      "\tspeed: 0.0341s/iter; left time: 315.9050s\n",
      "\titers: 800, epoch: 10 | loss: 0.0492407\n",
      "\tspeed: 0.0341s/iter; left time: 312.2782s\n",
      "\titers: 900, epoch: 10 | loss: 0.0494081\n",
      "\tspeed: 0.0341s/iter; left time: 308.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0516848 Vali Loss: 0.0591269 Test Loss: 0.0909714\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0543662\n",
      "\tspeed: 0.0930s/iter; left time: 833.5490s\n",
      "\titers: 200, epoch: 11 | loss: 0.0554431\n",
      "\tspeed: 0.0340s/iter; left time: 301.3541s\n",
      "\titers: 300, epoch: 11 | loss: 0.0557188\n",
      "\tspeed: 0.0341s/iter; left time: 298.3951s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493816\n",
      "\tspeed: 0.0340s/iter; left time: 294.7068s\n",
      "\titers: 500, epoch: 11 | loss: 0.0470877\n",
      "\tspeed: 0.0341s/iter; left time: 291.9255s\n",
      "\titers: 600, epoch: 11 | loss: 0.0478654\n",
      "\tspeed: 0.0341s/iter; left time: 288.4091s\n",
      "\titers: 700, epoch: 11 | loss: 0.0479112\n",
      "\tspeed: 0.0341s/iter; left time: 284.7780s\n",
      "\titers: 800, epoch: 11 | loss: 0.0557325\n",
      "\tspeed: 0.0341s/iter; left time: 281.5655s\n",
      "\titers: 900, epoch: 11 | loss: 0.0540772\n",
      "\tspeed: 0.0341s/iter; left time: 277.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0503803 Vali Loss: 0.0596729 Test Loss: 0.0918079\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019272608682513237, rmse:0.13882581889629364, mae:0.08702108263969421, rse:0.4079122245311737\n",
      "Intermediate time for ES and pred_len 24: 00h:18m:37.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2373950\n",
      "\tspeed: 0.0630s/iter; left time: 1132.0348s\n",
      "\titers: 200, epoch: 1 | loss: 0.2127535\n",
      "\tspeed: 0.0421s/iter; left time: 753.0910s\n",
      "\titers: 300, epoch: 1 | loss: 0.2200992\n",
      "\tspeed: 0.0421s/iter; left time: 748.5457s\n",
      "\titers: 400, epoch: 1 | loss: 0.2059206\n",
      "\tspeed: 0.0421s/iter; left time: 744.3850s\n",
      "\titers: 500, epoch: 1 | loss: 0.1971000\n",
      "\tspeed: 0.0421s/iter; left time: 740.1027s\n",
      "\titers: 600, epoch: 1 | loss: 0.1864508\n",
      "\tspeed: 0.0421s/iter; left time: 736.0255s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921179\n",
      "\tspeed: 0.0422s/iter; left time: 733.0808s\n",
      "\titers: 800, epoch: 1 | loss: 0.1733235\n",
      "\tspeed: 0.0421s/iter; left time: 727.6188s\n",
      "\titers: 900, epoch: 1 | loss: 0.1764061\n",
      "\tspeed: 0.0425s/iter; left time: 730.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 904 | Train Loss: 0.2055957 Vali Loss: 0.1704240 Test Loss: 0.2081109\n",
      "Validation loss decreased (inf --> 0.170424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474789\n",
      "\tspeed: 0.1169s/iter; left time: 1995.5735s\n",
      "\titers: 200, epoch: 2 | loss: 0.1373694\n",
      "\tspeed: 0.0420s/iter; left time: 713.7136s\n",
      "\titers: 300, epoch: 2 | loss: 0.1301654\n",
      "\tspeed: 0.0421s/iter; left time: 710.1622s\n",
      "\titers: 400, epoch: 2 | loss: 0.1124775\n",
      "\tspeed: 0.0421s/iter; left time: 706.2904s\n",
      "\titers: 500, epoch: 2 | loss: 0.1012060\n",
      "\tspeed: 0.0421s/iter; left time: 701.8246s\n",
      "\titers: 600, epoch: 2 | loss: 0.1080255\n",
      "\tspeed: 0.0421s/iter; left time: 698.2995s\n",
      "\titers: 700, epoch: 2 | loss: 0.0986939\n",
      "\tspeed: 0.0421s/iter; left time: 693.9462s\n",
      "\titers: 800, epoch: 2 | loss: 0.0948638\n",
      "\tspeed: 0.0421s/iter; left time: 689.3840s\n",
      "\titers: 900, epoch: 2 | loss: 0.0981427\n",
      "\tspeed: 0.0421s/iter; left time: 684.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 904 | Train Loss: 0.1190556 Vali Loss: 0.0968713 Test Loss: 0.1262738\n",
      "Validation loss decreased (0.170424 --> 0.096871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954394\n",
      "\tspeed: 0.1166s/iter; left time: 1886.4918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901963\n",
      "\tspeed: 0.0421s/iter; left time: 676.3143s\n",
      "\titers: 300, epoch: 3 | loss: 0.0962261\n",
      "\tspeed: 0.0421s/iter; left time: 672.3038s\n",
      "\titers: 400, epoch: 3 | loss: 0.0960315\n",
      "\tspeed: 0.0421s/iter; left time: 668.6412s\n",
      "\titers: 500, epoch: 3 | loss: 0.0871150\n",
      "\tspeed: 0.0420s/iter; left time: 663.1879s\n",
      "\titers: 600, epoch: 3 | loss: 0.0901583\n",
      "\tspeed: 0.0421s/iter; left time: 659.3545s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950876\n",
      "\tspeed: 0.0420s/iter; left time: 654.3531s\n",
      "\titers: 800, epoch: 3 | loss: 0.0905125\n",
      "\tspeed: 0.0420s/iter; left time: 650.5121s\n",
      "\titers: 900, epoch: 3 | loss: 0.0831911\n",
      "\tspeed: 0.0421s/iter; left time: 646.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0922454 Vali Loss: 0.0891734 Test Loss: 0.1277304\n",
      "Validation loss decreased (0.096871 --> 0.089173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0830763\n",
      "\tspeed: 0.1176s/iter; left time: 1796.2948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0852754\n",
      "\tspeed: 0.0421s/iter; left time: 638.2523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0858199\n",
      "\tspeed: 0.0421s/iter; left time: 634.1683s\n",
      "\titers: 400, epoch: 4 | loss: 0.0820458\n",
      "\tspeed: 0.0421s/iter; left time: 629.8990s\n",
      "\titers: 500, epoch: 4 | loss: 0.0901307\n",
      "\tspeed: 0.0420s/iter; left time: 625.0486s\n",
      "\titers: 600, epoch: 4 | loss: 0.0855317\n",
      "\tspeed: 0.0421s/iter; left time: 621.2486s\n",
      "\titers: 700, epoch: 4 | loss: 0.0796080\n",
      "\tspeed: 0.0421s/iter; left time: 617.0458s\n",
      "\titers: 800, epoch: 4 | loss: 0.0797859\n",
      "\tspeed: 0.0421s/iter; left time: 612.8719s\n",
      "\titers: 900, epoch: 4 | loss: 0.0875236\n",
      "\tspeed: 0.0421s/iter; left time: 608.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0864976 Vali Loss: 0.0881260 Test Loss: 0.1281893\n",
      "Validation loss decreased (0.089173 --> 0.088126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0831923\n",
      "\tspeed: 0.1170s/iter; left time: 1681.0620s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823494\n",
      "\tspeed: 0.0421s/iter; left time: 600.7790s\n",
      "\titers: 300, epoch: 5 | loss: 0.0849803\n",
      "\tspeed: 0.0421s/iter; left time: 596.2569s\n",
      "\titers: 400, epoch: 5 | loss: 0.0798522\n",
      "\tspeed: 0.0421s/iter; left time: 592.0255s\n",
      "\titers: 500, epoch: 5 | loss: 0.0811485\n",
      "\tspeed: 0.0421s/iter; left time: 588.2881s\n",
      "\titers: 600, epoch: 5 | loss: 0.0798577\n",
      "\tspeed: 0.0421s/iter; left time: 583.7078s\n",
      "\titers: 700, epoch: 5 | loss: 0.0791995\n",
      "\tspeed: 0.0421s/iter; left time: 579.9353s\n",
      "\titers: 800, epoch: 5 | loss: 0.0825909\n",
      "\tspeed: 0.0422s/iter; left time: 576.0551s\n",
      "\titers: 900, epoch: 5 | loss: 0.0805139\n",
      "\tspeed: 0.0421s/iter; left time: 570.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0819588 Vali Loss: 0.0869265 Test Loss: 0.1323719\n",
      "Validation loss decreased (0.088126 --> 0.086926).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814526\n",
      "\tspeed: 0.1178s/iter; left time: 1585.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821762\n",
      "\tspeed: 0.0421s/iter; left time: 562.3599s\n",
      "\titers: 300, epoch: 6 | loss: 0.0794167\n",
      "\tspeed: 0.0421s/iter; left time: 558.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0752672\n",
      "\tspeed: 0.0421s/iter; left time: 554.3897s\n",
      "\titers: 500, epoch: 6 | loss: 0.0766867\n",
      "\tspeed: 0.0420s/iter; left time: 549.1725s\n",
      "\titers: 600, epoch: 6 | loss: 0.0775365\n",
      "\tspeed: 0.0421s/iter; left time: 545.3077s\n",
      "\titers: 700, epoch: 6 | loss: 0.0771111\n",
      "\tspeed: 0.0421s/iter; left time: 541.3962s\n",
      "\titers: 800, epoch: 6 | loss: 0.0805728\n",
      "\tspeed: 0.0421s/iter; left time: 537.0451s\n",
      "\titers: 900, epoch: 6 | loss: 0.0751420\n",
      "\tspeed: 0.0421s/iter; left time: 533.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0784264 Vali Loss: 0.0879058 Test Loss: 0.1440845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763488\n",
      "\tspeed: 0.1153s/iter; left time: 1447.5681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769644\n",
      "\tspeed: 0.0420s/iter; left time: 523.5385s\n",
      "\titers: 300, epoch: 7 | loss: 0.0803116\n",
      "\tspeed: 0.0421s/iter; left time: 519.9943s\n",
      "\titers: 400, epoch: 7 | loss: 0.0778039\n",
      "\tspeed: 0.0421s/iter; left time: 515.5707s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726631\n",
      "\tspeed: 0.0421s/iter; left time: 511.8159s\n",
      "\titers: 600, epoch: 7 | loss: 0.0671688\n",
      "\tspeed: 0.0421s/iter; left time: 507.5547s\n",
      "\titers: 700, epoch: 7 | loss: 0.0728735\n",
      "\tspeed: 0.0418s/iter; left time: 499.7380s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 491.7005s\n",
      "\titers: 900, epoch: 7 | loss: 0.0791964\n",
      "\tspeed: 0.0415s/iter; left time: 487.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 904 | Train Loss: 0.0751993 Vali Loss: 0.0868586 Test Loss: 0.1397843\n",
      "Validation loss decreased (0.086926 --> 0.086859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776971\n",
      "\tspeed: 0.1174s/iter; left time: 1368.3659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721895\n",
      "\tspeed: 0.0416s/iter; left time: 480.0903s\n",
      "\titers: 300, epoch: 8 | loss: 0.0700485\n",
      "\tspeed: 0.0415s/iter; left time: 475.8155s\n",
      "\titers: 400, epoch: 8 | loss: 0.0711599\n",
      "\tspeed: 0.0416s/iter; left time: 471.8501s\n",
      "\titers: 500, epoch: 8 | loss: 0.0706868\n",
      "\tspeed: 0.0415s/iter; left time: 467.5249s\n",
      "\titers: 600, epoch: 8 | loss: 0.0683769\n",
      "\tspeed: 0.0416s/iter; left time: 463.6050s\n",
      "\titers: 700, epoch: 8 | loss: 0.0641797\n",
      "\tspeed: 0.0416s/iter; left time: 459.2867s\n",
      "\titers: 800, epoch: 8 | loss: 0.0709313\n",
      "\tspeed: 0.0416s/iter; left time: 455.4383s\n",
      "\titers: 900, epoch: 8 | loss: 0.0689372\n",
      "\tspeed: 0.0416s/iter; left time: 451.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0718957 Vali Loss: 0.0874921 Test Loss: 0.1515969\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0712285\n",
      "\tspeed: 0.1141s/iter; left time: 1225.9544s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697914\n",
      "\tspeed: 0.0415s/iter; left time: 441.5640s\n",
      "\titers: 300, epoch: 9 | loss: 0.0708499\n",
      "\tspeed: 0.0415s/iter; left time: 437.6952s\n",
      "\titers: 400, epoch: 9 | loss: 0.0671885\n",
      "\tspeed: 0.0415s/iter; left time: 433.7513s\n",
      "\titers: 500, epoch: 9 | loss: 0.0713352\n",
      "\tspeed: 0.0415s/iter; left time: 429.1352s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717964\n",
      "\tspeed: 0.0415s/iter; left time: 425.3757s\n",
      "\titers: 700, epoch: 9 | loss: 0.0682684\n",
      "\tspeed: 0.0415s/iter; left time: 421.1203s\n",
      "\titers: 800, epoch: 9 | loss: 0.0685369\n",
      "\tspeed: 0.0415s/iter; left time: 417.1008s\n",
      "\titers: 900, epoch: 9 | loss: 0.0697512\n",
      "\tspeed: 0.0415s/iter; left time: 412.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0691556 Vali Loss: 0.0882018 Test Loss: 0.1587183\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682209\n",
      "\tspeed: 0.1132s/iter; left time: 1114.3122s\n",
      "\titers: 200, epoch: 10 | loss: 0.0657655\n",
      "\tspeed: 0.0414s/iter; left time: 403.9179s\n",
      "\titers: 300, epoch: 10 | loss: 0.0661185\n",
      "\tspeed: 0.0415s/iter; left time: 400.0127s\n",
      "\titers: 400, epoch: 10 | loss: 0.0667656\n",
      "\tspeed: 0.0414s/iter; left time: 395.5766s\n",
      "\titers: 500, epoch: 10 | loss: 0.0639189\n",
      "\tspeed: 0.0415s/iter; left time: 391.6025s\n",
      "\titers: 600, epoch: 10 | loss: 0.0679160\n",
      "\tspeed: 0.0415s/iter; left time: 387.4287s\n",
      "\titers: 700, epoch: 10 | loss: 0.0706274\n",
      "\tspeed: 0.0414s/iter; left time: 383.2033s\n",
      "\titers: 800, epoch: 10 | loss: 0.0604116\n",
      "\tspeed: 0.0414s/iter; left time: 379.0521s\n",
      "\titers: 900, epoch: 10 | loss: 0.0648436\n",
      "\tspeed: 0.0414s/iter; left time: 374.8803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 904 | Train Loss: 0.0665796 Vali Loss: 0.0873402 Test Loss: 0.1584590\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0683132\n",
      "\tspeed: 0.1138s/iter; left time: 1017.2489s\n",
      "\titers: 200, epoch: 11 | loss: 0.0653537\n",
      "\tspeed: 0.0415s/iter; left time: 367.2876s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655010\n",
      "\tspeed: 0.0415s/iter; left time: 363.0876s\n",
      "\titers: 400, epoch: 11 | loss: 0.0705099\n",
      "\tspeed: 0.0415s/iter; left time: 358.8113s\n",
      "\titers: 500, epoch: 11 | loss: 0.0668215\n",
      "\tspeed: 0.0415s/iter; left time: 354.5913s\n",
      "\titers: 600, epoch: 11 | loss: 0.0674020\n",
      "\tspeed: 0.0415s/iter; left time: 350.3595s\n",
      "\titers: 700, epoch: 11 | loss: 0.0653524\n",
      "\tspeed: 0.0415s/iter; left time: 346.5444s\n",
      "\titers: 800, epoch: 11 | loss: 0.0633563\n",
      "\tspeed: 0.0415s/iter; left time: 342.0408s\n",
      "\titers: 900, epoch: 11 | loss: 0.0604338\n",
      "\tspeed: 0.0416s/iter; left time: 338.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0644156 Vali Loss: 0.0880552 Test Loss: 0.1590489\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583263\n",
      "\tspeed: 0.1149s/iter; left time: 923.2915s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638356\n",
      "\tspeed: 0.0415s/iter; left time: 329.0060s\n",
      "\titers: 300, epoch: 12 | loss: 0.0610895\n",
      "\tspeed: 0.0415s/iter; left time: 325.0781s\n",
      "\titers: 400, epoch: 12 | loss: 0.0576380\n",
      "\tspeed: 0.0415s/iter; left time: 321.0412s\n",
      "\titers: 500, epoch: 12 | loss: 0.0655818\n",
      "\tspeed: 0.0415s/iter; left time: 316.7267s\n",
      "\titers: 600, epoch: 12 | loss: 0.0575109\n",
      "\tspeed: 0.0418s/iter; left time: 314.9701s\n",
      "\titers: 700, epoch: 12 | loss: 0.0618829\n",
      "\tspeed: 0.0420s/iter; left time: 312.4757s\n",
      "\titers: 800, epoch: 12 | loss: 0.0603857\n",
      "\tspeed: 0.0420s/iter; left time: 308.1376s\n",
      "\titers: 900, epoch: 12 | loss: 0.0614875\n",
      "\tspeed: 0.0420s/iter; left time: 304.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 904 | Train Loss: 0.0624188 Vali Loss: 0.0871061 Test Loss: 0.1609867\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04883919283747673, rmse:0.2209959179162979, mae:0.1398049145936966, rse:0.6492194533348083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2255370\n",
      "\tspeed: 0.0439s/iter; left time: 789.5778s\n",
      "\titers: 200, epoch: 1 | loss: 0.2166498\n",
      "\tspeed: 0.0415s/iter; left time: 742.5966s\n",
      "\titers: 300, epoch: 1 | loss: 0.2044076\n",
      "\tspeed: 0.0415s/iter; left time: 738.6653s\n",
      "\titers: 400, epoch: 1 | loss: 0.2036429\n",
      "\tspeed: 0.0416s/iter; left time: 735.0498s\n",
      "\titers: 500, epoch: 1 | loss: 0.1952279\n",
      "\tspeed: 0.0416s/iter; left time: 730.7050s\n",
      "\titers: 600, epoch: 1 | loss: 0.1890704\n",
      "\tspeed: 0.0416s/iter; left time: 726.8284s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774556\n",
      "\tspeed: 0.0416s/iter; left time: 722.6038s\n",
      "\titers: 800, epoch: 1 | loss: 0.1774660\n",
      "\tspeed: 0.0416s/iter; left time: 718.2065s\n",
      "\titers: 900, epoch: 1 | loss: 0.1773101\n",
      "\tspeed: 0.0415s/iter; left time: 713.2413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.2017067 Vali Loss: 0.1653294 Test Loss: 0.2053860\n",
      "Validation loss decreased (inf --> 0.165329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482454\n",
      "\tspeed: 0.1171s/iter; left time: 2000.5558s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250862\n",
      "\tspeed: 0.0415s/iter; left time: 704.8476s\n",
      "\titers: 300, epoch: 2 | loss: 0.1308347\n",
      "\tspeed: 0.0415s/iter; left time: 700.7665s\n",
      "\titers: 400, epoch: 2 | loss: 0.1253198\n",
      "\tspeed: 0.0415s/iter; left time: 696.8225s\n",
      "\titers: 500, epoch: 2 | loss: 0.1118068\n",
      "\tspeed: 0.0415s/iter; left time: 692.3480s\n",
      "\titers: 600, epoch: 2 | loss: 0.1140664\n",
      "\tspeed: 0.0416s/iter; left time: 688.8759s\n",
      "\titers: 700, epoch: 2 | loss: 0.1062072\n",
      "\tspeed: 0.0416s/iter; left time: 684.9127s\n",
      "\titers: 800, epoch: 2 | loss: 0.1010479\n",
      "\tspeed: 0.0416s/iter; left time: 680.5475s\n",
      "\titers: 900, epoch: 2 | loss: 0.0990625\n",
      "\tspeed: 0.0416s/iter; left time: 676.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.1223058 Vali Loss: 0.0981640 Test Loss: 0.1313140\n",
      "Validation loss decreased (0.165329 --> 0.098164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0917345\n",
      "\tspeed: 0.1206s/iter; left time: 1950.2871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0968400\n",
      "\tspeed: 0.0415s/iter; left time: 667.5402s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922163\n",
      "\tspeed: 0.0415s/iter; left time: 663.6097s\n",
      "\titers: 400, epoch: 3 | loss: 0.0844943\n",
      "\tspeed: 0.0416s/iter; left time: 659.5445s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870728\n",
      "\tspeed: 0.0416s/iter; left time: 655.7148s\n",
      "\titers: 600, epoch: 3 | loss: 0.0913326\n",
      "\tspeed: 0.0416s/iter; left time: 651.5126s\n",
      "\titers: 700, epoch: 3 | loss: 0.0907997\n",
      "\tspeed: 0.0415s/iter; left time: 646.4715s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945480\n",
      "\tspeed: 0.0416s/iter; left time: 643.3192s\n",
      "\titers: 900, epoch: 3 | loss: 0.0911530\n",
      "\tspeed: 0.0416s/iter; left time: 639.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.0923384 Vali Loss: 0.0945549 Test Loss: 0.1335031\n",
      "Validation loss decreased (0.098164 --> 0.094555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901370\n",
      "\tspeed: 0.1166s/iter; left time: 1779.6277s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939121\n",
      "\tspeed: 0.0416s/iter; left time: 630.3666s\n",
      "\titers: 300, epoch: 4 | loss: 0.0888266\n",
      "\tspeed: 0.0416s/iter; left time: 626.5277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0939008\n",
      "\tspeed: 0.0416s/iter; left time: 622.4458s\n",
      "\titers: 500, epoch: 4 | loss: 0.0792086\n",
      "\tspeed: 0.0416s/iter; left time: 618.3303s\n",
      "\titers: 600, epoch: 4 | loss: 0.0830760\n",
      "\tspeed: 0.0416s/iter; left time: 613.8589s\n",
      "\titers: 700, epoch: 4 | loss: 0.0812820\n",
      "\tspeed: 0.0416s/iter; left time: 609.6404s\n",
      "\titers: 800, epoch: 4 | loss: 0.0889937\n",
      "\tspeed: 0.0416s/iter; left time: 605.5328s\n",
      "\titers: 900, epoch: 4 | loss: 0.0849229\n",
      "\tspeed: 0.0416s/iter; left time: 601.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0863824 Vali Loss: 0.0888520 Test Loss: 0.1328815\n",
      "Validation loss decreased (0.094555 --> 0.088852).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871914\n",
      "\tspeed: 0.1170s/iter; left time: 1680.2305s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801925\n",
      "\tspeed: 0.0416s/iter; left time: 592.9057s\n",
      "\titers: 300, epoch: 5 | loss: 0.0851149\n",
      "\tspeed: 0.0415s/iter; left time: 587.8497s\n",
      "\titers: 400, epoch: 5 | loss: 0.0847745\n",
      "\tspeed: 0.0415s/iter; left time: 583.5027s\n",
      "\titers: 500, epoch: 5 | loss: 0.0800787\n",
      "\tspeed: 0.0415s/iter; left time: 579.6990s\n",
      "\titers: 600, epoch: 5 | loss: 0.0951516\n",
      "\tspeed: 0.0415s/iter; left time: 575.3423s\n",
      "\titers: 700, epoch: 5 | loss: 0.0797609\n",
      "\tspeed: 0.0415s/iter; left time: 570.9798s\n",
      "\titers: 800, epoch: 5 | loss: 0.0892005\n",
      "\tspeed: 0.0415s/iter; left time: 567.0856s\n",
      "\titers: 900, epoch: 5 | loss: 0.0754987\n",
      "\tspeed: 0.0415s/iter; left time: 562.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0823251 Vali Loss: 0.0867483 Test Loss: 0.1332777\n",
      "Validation loss decreased (0.088852 --> 0.086748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733105\n",
      "\tspeed: 0.1167s/iter; left time: 1570.2430s\n",
      "\titers: 200, epoch: 6 | loss: 0.0700598\n",
      "\tspeed: 0.0415s/iter; left time: 554.4218s\n",
      "\titers: 300, epoch: 6 | loss: 0.0821968\n",
      "\tspeed: 0.0415s/iter; left time: 550.3302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788260\n",
      "\tspeed: 0.0415s/iter; left time: 546.0061s\n",
      "\titers: 500, epoch: 6 | loss: 0.0736750\n",
      "\tspeed: 0.0415s/iter; left time: 541.9977s\n",
      "\titers: 600, epoch: 6 | loss: 0.0731835\n",
      "\tspeed: 0.0416s/iter; left time: 538.6953s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804928\n",
      "\tspeed: 0.0416s/iter; left time: 534.4559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0761644\n",
      "\tspeed: 0.0415s/iter; left time: 529.8287s\n",
      "\titers: 900, epoch: 6 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 525.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0791167 Vali Loss: 0.0868076 Test Loss: 0.1432561\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792830\n",
      "\tspeed: 0.1135s/iter; left time: 1425.4236s\n",
      "\titers: 200, epoch: 7 | loss: 0.0736702\n",
      "\tspeed: 0.0416s/iter; left time: 518.0054s\n",
      "\titers: 300, epoch: 7 | loss: 0.0709306\n",
      "\tspeed: 0.0416s/iter; left time: 513.8523s\n",
      "\titers: 400, epoch: 7 | loss: 0.0709575\n",
      "\tspeed: 0.0416s/iter; left time: 509.4117s\n",
      "\titers: 500, epoch: 7 | loss: 0.0705057\n",
      "\tspeed: 0.0416s/iter; left time: 506.0713s\n",
      "\titers: 600, epoch: 7 | loss: 0.0775761\n",
      "\tspeed: 0.0416s/iter; left time: 501.3616s\n",
      "\titers: 700, epoch: 7 | loss: 0.0763834\n",
      "\tspeed: 0.0416s/iter; left time: 497.1976s\n",
      "\titers: 800, epoch: 7 | loss: 0.0740358\n",
      "\tspeed: 0.0416s/iter; left time: 492.9521s\n",
      "\titers: 900, epoch: 7 | loss: 0.0736507\n",
      "\tspeed: 0.0416s/iter; left time: 488.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0762565 Vali Loss: 0.0854730 Test Loss: 0.1467339\n",
      "Validation loss decreased (0.086748 --> 0.085473).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729528\n",
      "\tspeed: 0.1162s/iter; left time: 1353.5860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0769066\n",
      "\tspeed: 0.0415s/iter; left time: 479.8011s\n",
      "\titers: 300, epoch: 8 | loss: 0.0709053\n",
      "\tspeed: 0.0415s/iter; left time: 475.2179s\n",
      "\titers: 400, epoch: 8 | loss: 0.0712793\n",
      "\tspeed: 0.0415s/iter; left time: 471.3423s\n",
      "\titers: 500, epoch: 8 | loss: 0.0678615\n",
      "\tspeed: 0.0416s/iter; left time: 467.9069s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719967\n",
      "\tspeed: 0.0416s/iter; left time: 463.7415s\n",
      "\titers: 700, epoch: 8 | loss: 0.0767970\n",
      "\tspeed: 0.0416s/iter; left time: 459.7097s\n",
      "\titers: 800, epoch: 8 | loss: 0.0820074\n",
      "\tspeed: 0.0416s/iter; left time: 455.3627s\n",
      "\titers: 900, epoch: 8 | loss: 0.0792067\n",
      "\tspeed: 0.0416s/iter; left time: 451.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0729809 Vali Loss: 0.0853084 Test Loss: 0.1464679\n",
      "Validation loss decreased (0.085473 --> 0.085308).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0680521\n",
      "\tspeed: 0.1170s/iter; left time: 1257.4653s\n",
      "\titers: 200, epoch: 9 | loss: 0.0709191\n",
      "\tspeed: 0.0416s/iter; left time: 442.6350s\n",
      "\titers: 300, epoch: 9 | loss: 0.0691477\n",
      "\tspeed: 0.0416s/iter; left time: 438.5318s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703399\n",
      "\tspeed: 0.0416s/iter; left time: 434.4762s\n",
      "\titers: 500, epoch: 9 | loss: 0.0686584\n",
      "\tspeed: 0.0416s/iter; left time: 430.2977s\n",
      "\titers: 600, epoch: 9 | loss: 0.0730306\n",
      "\tspeed: 0.0416s/iter; left time: 426.3882s\n",
      "\titers: 700, epoch: 9 | loss: 0.0717609\n",
      "\tspeed: 0.0416s/iter; left time: 422.0754s\n",
      "\titers: 800, epoch: 9 | loss: 0.0705330\n",
      "\tspeed: 0.0416s/iter; left time: 417.9879s\n",
      "\titers: 900, epoch: 9 | loss: 0.0692707\n",
      "\tspeed: 0.0416s/iter; left time: 413.4969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0702632 Vali Loss: 0.0855913 Test Loss: 0.1535130\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698408\n",
      "\tspeed: 0.1140s/iter; left time: 1121.8448s\n",
      "\titers: 200, epoch: 10 | loss: 0.0679938\n",
      "\tspeed: 0.0415s/iter; left time: 404.7121s\n",
      "\titers: 300, epoch: 10 | loss: 0.0702723\n",
      "\tspeed: 0.0415s/iter; left time: 400.3426s\n",
      "\titers: 400, epoch: 10 | loss: 0.0665980\n",
      "\tspeed: 0.0415s/iter; left time: 396.1537s\n",
      "\titers: 500, epoch: 10 | loss: 0.0640535\n",
      "\tspeed: 0.0415s/iter; left time: 392.4156s\n",
      "\titers: 600, epoch: 10 | loss: 0.0687447\n",
      "\tspeed: 0.0416s/iter; left time: 388.9352s\n",
      "\titers: 700, epoch: 10 | loss: 0.0636232\n",
      "\tspeed: 0.0415s/iter; left time: 383.7071s\n",
      "\titers: 800, epoch: 10 | loss: 0.0637815\n",
      "\tspeed: 0.0415s/iter; left time: 379.4254s\n",
      "\titers: 900, epoch: 10 | loss: 0.0650070\n",
      "\tspeed: 0.0415s/iter; left time: 375.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0675522 Vali Loss: 0.0878237 Test Loss: 0.1574765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680077\n",
      "\tspeed: 0.1152s/iter; left time: 1029.7413s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625419\n",
      "\tspeed: 0.0416s/iter; left time: 367.5794s\n",
      "\titers: 300, epoch: 11 | loss: 0.0644673\n",
      "\tspeed: 0.0415s/iter; left time: 363.0404s\n",
      "\titers: 400, epoch: 11 | loss: 0.0685582\n",
      "\tspeed: 0.0415s/iter; left time: 358.5762s\n",
      "\titers: 500, epoch: 11 | loss: 0.0674249\n",
      "\tspeed: 0.0415s/iter; left time: 354.2847s\n",
      "\titers: 600, epoch: 11 | loss: 0.0653215\n",
      "\tspeed: 0.0415s/iter; left time: 350.3671s\n",
      "\titers: 700, epoch: 11 | loss: 0.0610816\n",
      "\tspeed: 0.0415s/iter; left time: 346.5466s\n",
      "\titers: 800, epoch: 11 | loss: 0.0660871\n",
      "\tspeed: 0.0415s/iter; left time: 342.1604s\n",
      "\titers: 900, epoch: 11 | loss: 0.0601333\n",
      "\tspeed: 0.0415s/iter; left time: 337.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0652383 Vali Loss: 0.0865308 Test Loss: 0.1594289\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594552\n",
      "\tspeed: 0.1140s/iter; left time: 916.4326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654352\n",
      "\tspeed: 0.0415s/iter; left time: 329.3632s\n",
      "\titers: 300, epoch: 12 | loss: 0.0618489\n",
      "\tspeed: 0.0415s/iter; left time: 325.2592s\n",
      "\titers: 400, epoch: 12 | loss: 0.0673705\n",
      "\tspeed: 0.0415s/iter; left time: 321.0622s\n",
      "\titers: 500, epoch: 12 | loss: 0.0666839\n",
      "\tspeed: 0.0415s/iter; left time: 316.9643s\n",
      "\titers: 600, epoch: 12 | loss: 0.0667761\n",
      "\tspeed: 0.0415s/iter; left time: 312.8686s\n",
      "\titers: 700, epoch: 12 | loss: 0.0607388\n",
      "\tspeed: 0.0415s/iter; left time: 308.6200s\n",
      "\titers: 800, epoch: 12 | loss: 0.0608705\n",
      "\tspeed: 0.0415s/iter; left time: 304.4714s\n",
      "\titers: 900, epoch: 12 | loss: 0.0617118\n",
      "\tspeed: 0.0415s/iter; left time: 300.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0632101 Vali Loss: 0.0859873 Test Loss: 0.1564025\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0644529\n",
      "\tspeed: 0.1137s/iter; left time: 811.0558s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554359\n",
      "\tspeed: 0.0416s/iter; left time: 292.4215s\n",
      "\titers: 300, epoch: 13 | loss: 0.0615502\n",
      "\tspeed: 0.0416s/iter; left time: 288.4158s\n",
      "\titers: 400, epoch: 13 | loss: 0.0606781\n",
      "\tspeed: 0.0416s/iter; left time: 284.2330s\n",
      "\titers: 500, epoch: 13 | loss: 0.0597327\n",
      "\tspeed: 0.0416s/iter; left time: 280.1644s\n",
      "\titers: 600, epoch: 13 | loss: 0.0621458\n",
      "\tspeed: 0.0416s/iter; left time: 275.8850s\n",
      "\titers: 700, epoch: 13 | loss: 0.0588029\n",
      "\tspeed: 0.0416s/iter; left time: 271.6671s\n",
      "\titers: 800, epoch: 13 | loss: 0.0633195\n",
      "\tspeed: 0.0416s/iter; left time: 267.5730s\n",
      "\titers: 900, epoch: 13 | loss: 0.0699742\n",
      "\tspeed: 0.0416s/iter; left time: 263.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0609191 Vali Loss: 0.0863986 Test Loss: 0.1637643\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05644026771187782, rmse:0.2375716120004654, mae:0.14639423787593842, rse:0.6979138851165771\n",
      "Intermediate time for ES and pred_len 96: 00h:19m:00.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2492964\n",
      "\tspeed: 0.0712s/iter; left time: 1277.1901s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172240\n",
      "\tspeed: 0.0504s/iter; left time: 899.7993s\n",
      "\titers: 300, epoch: 1 | loss: 0.2131199\n",
      "\tspeed: 0.0505s/iter; left time: 896.4523s\n",
      "\titers: 400, epoch: 1 | loss: 0.2037690\n",
      "\tspeed: 0.0505s/iter; left time: 891.4202s\n",
      "\titers: 500, epoch: 1 | loss: 0.1987259\n",
      "\tspeed: 0.0505s/iter; left time: 885.4587s\n",
      "\titers: 600, epoch: 1 | loss: 0.1937901\n",
      "\tspeed: 0.0505s/iter; left time: 880.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921680\n",
      "\tspeed: 0.0506s/iter; left time: 876.8671s\n",
      "\titers: 800, epoch: 1 | loss: 0.1843900\n",
      "\tspeed: 0.0506s/iter; left time: 871.9005s\n",
      "\titers: 900, epoch: 1 | loss: 0.1844022\n",
      "\tspeed: 0.0505s/iter; left time: 865.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 902 | Train Loss: 0.2083722 Vali Loss: 0.1819980 Test Loss: 0.2220403\n",
      "Validation loss decreased (inf --> 0.181998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1653086\n",
      "\tspeed: 0.1417s/iter; left time: 2413.8571s\n",
      "\titers: 200, epoch: 2 | loss: 0.1531178\n",
      "\tspeed: 0.0504s/iter; left time: 853.2940s\n",
      "\titers: 300, epoch: 2 | loss: 0.1426768\n",
      "\tspeed: 0.0504s/iter; left time: 849.1057s\n",
      "\titers: 400, epoch: 2 | loss: 0.1295031\n",
      "\tspeed: 0.0504s/iter; left time: 844.0830s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160058\n",
      "\tspeed: 0.0504s/iter; left time: 838.5864s\n",
      "\titers: 600, epoch: 2 | loss: 0.1129280\n",
      "\tspeed: 0.0504s/iter; left time: 834.3003s\n",
      "\titers: 700, epoch: 2 | loss: 0.1077385\n",
      "\tspeed: 0.0504s/iter; left time: 827.7760s\n",
      "\titers: 800, epoch: 2 | loss: 0.1035756\n",
      "\tspeed: 0.0504s/iter; left time: 824.1451s\n",
      "\titers: 900, epoch: 2 | loss: 0.0996339\n",
      "\tspeed: 0.0504s/iter; left time: 818.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1298264 Vali Loss: 0.1035160 Test Loss: 0.1475300\n",
      "Validation loss decreased (0.181998 --> 0.103516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033866\n",
      "\tspeed: 0.1412s/iter; left time: 2278.6888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975054\n",
      "\tspeed: 0.0505s/iter; left time: 809.1720s\n",
      "\titers: 300, epoch: 3 | loss: 0.0915680\n",
      "\tspeed: 0.0504s/iter; left time: 803.1125s\n",
      "\titers: 400, epoch: 3 | loss: 0.0927011\n",
      "\tspeed: 0.0504s/iter; left time: 798.1891s\n",
      "\titers: 500, epoch: 3 | loss: 0.0954466\n",
      "\tspeed: 0.0504s/iter; left time: 793.2339s\n",
      "\titers: 600, epoch: 3 | loss: 0.1021520\n",
      "\tspeed: 0.0504s/iter; left time: 788.3923s\n",
      "\titers: 700, epoch: 3 | loss: 0.0969066\n",
      "\tspeed: 0.0504s/iter; left time: 783.1803s\n",
      "\titers: 800, epoch: 3 | loss: 0.0930721\n",
      "\tspeed: 0.0504s/iter; left time: 778.3916s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931172\n",
      "\tspeed: 0.0504s/iter; left time: 773.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0972800 Vali Loss: 0.0986148 Test Loss: 0.1403995\n",
      "Validation loss decreased (0.103516 --> 0.098615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0925042\n",
      "\tspeed: 0.1410s/iter; left time: 2147.4261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977211\n",
      "\tspeed: 0.0504s/iter; left time: 763.3308s\n",
      "\titers: 300, epoch: 4 | loss: 0.0909184\n",
      "\tspeed: 0.0504s/iter; left time: 758.0967s\n",
      "\titers: 400, epoch: 4 | loss: 0.0948582\n",
      "\tspeed: 0.0505s/iter; left time: 753.4728s\n",
      "\titers: 500, epoch: 4 | loss: 0.0912337\n",
      "\tspeed: 0.0504s/iter; left time: 748.1623s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878440\n",
      "\tspeed: 0.0504s/iter; left time: 743.1452s\n",
      "\titers: 700, epoch: 4 | loss: 0.0873194\n",
      "\tspeed: 0.0504s/iter; left time: 737.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.0957726\n",
      "\tspeed: 0.0504s/iter; left time: 733.0270s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906419\n",
      "\tspeed: 0.0504s/iter; left time: 727.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0912431 Vali Loss: 0.0933874 Test Loss: 0.1351360\n",
      "Validation loss decreased (0.098615 --> 0.093387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860944\n",
      "\tspeed: 0.1425s/iter; left time: 2042.0201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0850665\n",
      "\tspeed: 0.0504s/iter; left time: 717.2623s\n",
      "\titers: 300, epoch: 5 | loss: 0.0901280\n",
      "\tspeed: 0.0504s/iter; left time: 712.9415s\n",
      "\titers: 400, epoch: 5 | loss: 0.0854654\n",
      "\tspeed: 0.0506s/iter; left time: 709.8097s\n",
      "\titers: 500, epoch: 5 | loss: 0.0851015\n",
      "\tspeed: 0.0506s/iter; left time: 705.2464s\n",
      "\titers: 600, epoch: 5 | loss: 0.0846908\n",
      "\tspeed: 0.0506s/iter; left time: 699.8147s\n",
      "\titers: 700, epoch: 5 | loss: 0.0850851\n",
      "\tspeed: 0.0506s/iter; left time: 694.3147s\n",
      "\titers: 800, epoch: 5 | loss: 0.0879443\n",
      "\tspeed: 0.0504s/iter; left time: 687.0974s\n",
      "\titers: 900, epoch: 5 | loss: 0.0815824\n",
      "\tspeed: 0.0504s/iter; left time: 682.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0865540 Vali Loss: 0.0953768 Test Loss: 0.1449964\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0880546\n",
      "\tspeed: 0.1384s/iter; left time: 1858.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0880220\n",
      "\tspeed: 0.0504s/iter; left time: 672.1573s\n",
      "\titers: 300, epoch: 6 | loss: 0.0851828\n",
      "\tspeed: 0.0504s/iter; left time: 667.0128s\n",
      "\titers: 400, epoch: 6 | loss: 0.0814955\n",
      "\tspeed: 0.0504s/iter; left time: 662.3892s\n",
      "\titers: 500, epoch: 6 | loss: 0.0808422\n",
      "\tspeed: 0.0504s/iter; left time: 656.7175s\n",
      "\titers: 600, epoch: 6 | loss: 0.0843075\n",
      "\tspeed: 0.0504s/iter; left time: 652.3007s\n",
      "\titers: 700, epoch: 6 | loss: 0.0827094\n",
      "\tspeed: 0.0505s/iter; left time: 648.1374s\n",
      "\titers: 800, epoch: 6 | loss: 0.0847130\n",
      "\tspeed: 0.0504s/iter; left time: 641.5816s\n",
      "\titers: 900, epoch: 6 | loss: 0.0832033\n",
      "\tspeed: 0.0504s/iter; left time: 636.7428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0824581 Vali Loss: 0.0938004 Test Loss: 0.1515495\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0807643\n",
      "\tspeed: 0.1365s/iter; left time: 1709.5910s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733612\n",
      "\tspeed: 0.0504s/iter; left time: 626.5840s\n",
      "\titers: 300, epoch: 7 | loss: 0.0787084\n",
      "\tspeed: 0.0504s/iter; left time: 621.0739s\n",
      "\titers: 400, epoch: 7 | loss: 0.0756619\n",
      "\tspeed: 0.0504s/iter; left time: 616.5083s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772191\n",
      "\tspeed: 0.0504s/iter; left time: 611.6287s\n",
      "\titers: 600, epoch: 7 | loss: 0.0766708\n",
      "\tspeed: 0.0505s/iter; left time: 606.9050s\n",
      "\titers: 700, epoch: 7 | loss: 0.0778410\n",
      "\tspeed: 0.0504s/iter; left time: 601.0559s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783041\n",
      "\tspeed: 0.0504s/iter; left time: 596.3140s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758551\n",
      "\tspeed: 0.0505s/iter; left time: 592.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0786968 Vali Loss: 0.0945030 Test Loss: 0.1575315\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0765909\n",
      "\tspeed: 0.1369s/iter; left time: 1591.5120s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756120\n",
      "\tspeed: 0.0504s/iter; left time: 580.6304s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762664\n",
      "\tspeed: 0.0504s/iter; left time: 575.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0798623\n",
      "\tspeed: 0.0504s/iter; left time: 570.8086s\n",
      "\titers: 500, epoch: 8 | loss: 0.0781074\n",
      "\tspeed: 0.0505s/iter; left time: 566.7603s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719266\n",
      "\tspeed: 0.0504s/iter; left time: 561.2141s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752170\n",
      "\tspeed: 0.0504s/iter; left time: 555.5328s\n",
      "\titers: 800, epoch: 8 | loss: 0.0754173\n",
      "\tspeed: 0.0505s/iter; left time: 552.1497s\n",
      "\titers: 900, epoch: 8 | loss: 0.0684457\n",
      "\tspeed: 0.0505s/iter; left time: 546.4118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0753874 Vali Loss: 0.0934107 Test Loss: 0.1613924\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704094\n",
      "\tspeed: 0.1380s/iter; left time: 1480.5162s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717454\n",
      "\tspeed: 0.0504s/iter; left time: 535.8080s\n",
      "\titers: 300, epoch: 9 | loss: 0.0741613\n",
      "\tspeed: 0.0504s/iter; left time: 530.6156s\n",
      "\titers: 400, epoch: 9 | loss: 0.0742769\n",
      "\tspeed: 0.0504s/iter; left time: 525.9377s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733934\n",
      "\tspeed: 0.0504s/iter; left time: 520.7536s\n",
      "\titers: 600, epoch: 9 | loss: 0.0716762\n",
      "\tspeed: 0.0505s/iter; left time: 515.9702s\n",
      "\titers: 700, epoch: 9 | loss: 0.0709206\n",
      "\tspeed: 0.0504s/iter; left time: 510.4875s\n",
      "\titers: 800, epoch: 9 | loss: 0.0728439\n",
      "\tspeed: 0.0504s/iter; left time: 505.7294s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723040\n",
      "\tspeed: 0.0504s/iter; left time: 500.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0723324 Vali Loss: 0.0969553 Test Loss: 0.1759281\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04438893124461174, rmse:0.2106868028640747, mae:0.13518424332141876, rse:0.6188546419143677\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2389837\n",
      "\tspeed: 0.0525s/iter; left time: 941.8531s\n",
      "\titers: 200, epoch: 1 | loss: 0.2256297\n",
      "\tspeed: 0.0505s/iter; left time: 901.0100s\n",
      "\titers: 300, epoch: 1 | loss: 0.2167884\n",
      "\tspeed: 0.0504s/iter; left time: 893.7508s\n",
      "\titers: 400, epoch: 1 | loss: 0.2074835\n",
      "\tspeed: 0.0505s/iter; left time: 891.2074s\n",
      "\titers: 500, epoch: 1 | loss: 0.2109853\n",
      "\tspeed: 0.0505s/iter; left time: 885.3476s\n",
      "\titers: 600, epoch: 1 | loss: 0.2032430\n",
      "\tspeed: 0.0504s/iter; left time: 879.2211s\n",
      "\titers: 700, epoch: 1 | loss: 0.1951404\n",
      "\tspeed: 0.0505s/iter; left time: 875.8518s\n",
      "\titers: 800, epoch: 1 | loss: 0.1859338\n",
      "\tspeed: 0.0504s/iter; left time: 868.6547s\n",
      "\titers: 900, epoch: 1 | loss: 0.1889469\n",
      "\tspeed: 0.0504s/iter; left time: 864.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.2128992 Vali Loss: 0.1829299 Test Loss: 0.2247479\n",
      "Validation loss decreased (inf --> 0.182930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1616415\n",
      "\tspeed: 0.1418s/iter; left time: 2415.6081s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435303\n",
      "\tspeed: 0.0504s/iter; left time: 854.1932s\n",
      "\titers: 300, epoch: 2 | loss: 0.1445888\n",
      "\tspeed: 0.0504s/iter; left time: 849.3128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1351373\n",
      "\tspeed: 0.0504s/iter; left time: 843.8295s\n",
      "\titers: 500, epoch: 2 | loss: 0.1191210\n",
      "\tspeed: 0.0504s/iter; left time: 839.0269s\n",
      "\titers: 600, epoch: 2 | loss: 0.1166453\n",
      "\tspeed: 0.0505s/iter; left time: 834.4495s\n",
      "\titers: 700, epoch: 2 | loss: 0.1043696\n",
      "\tspeed: 0.0505s/iter; left time: 829.7016s\n",
      "\titers: 800, epoch: 2 | loss: 0.0989133\n",
      "\tspeed: 0.0505s/iter; left time: 824.4989s\n",
      "\titers: 900, epoch: 2 | loss: 0.1004393\n",
      "\tspeed: 0.0504s/iter; left time: 819.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.80s\n",
      "Steps: 902 | Train Loss: 0.1309356 Vali Loss: 0.1029980 Test Loss: 0.1407493\n",
      "Validation loss decreased (0.182930 --> 0.102998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012470\n",
      "\tspeed: 0.1409s/iter; left time: 2274.3233s\n",
      "\titers: 200, epoch: 3 | loss: 0.0983157\n",
      "\tspeed: 0.0505s/iter; left time: 809.2159s\n",
      "\titers: 300, epoch: 3 | loss: 0.0947418\n",
      "\tspeed: 0.0504s/iter; left time: 802.6096s\n",
      "\titers: 400, epoch: 3 | loss: 0.0990990\n",
      "\tspeed: 0.0504s/iter; left time: 798.1440s\n",
      "\titers: 500, epoch: 3 | loss: 0.0928705\n",
      "\tspeed: 0.0505s/iter; left time: 795.0857s\n",
      "\titers: 600, epoch: 3 | loss: 0.0926267\n",
      "\tspeed: 0.0505s/iter; left time: 788.9751s\n",
      "\titers: 700, epoch: 3 | loss: 0.0929120\n",
      "\tspeed: 0.0505s/iter; left time: 784.3314s\n",
      "\titers: 800, epoch: 3 | loss: 0.0964417\n",
      "\tspeed: 0.0505s/iter; left time: 778.9006s\n",
      "\titers: 900, epoch: 3 | loss: 0.0912257\n",
      "\tspeed: 0.0505s/iter; left time: 773.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0973411 Vali Loss: 0.0984464 Test Loss: 0.1338115\n",
      "Validation loss decreased (0.102998 --> 0.098446).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919027\n",
      "\tspeed: 0.1410s/iter; left time: 2148.1578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967809\n",
      "\tspeed: 0.0504s/iter; left time: 762.2060s\n",
      "\titers: 300, epoch: 4 | loss: 0.0983866\n",
      "\tspeed: 0.0504s/iter; left time: 758.0238s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937310\n",
      "\tspeed: 0.0504s/iter; left time: 752.4804s\n",
      "\titers: 500, epoch: 4 | loss: 0.0924264\n",
      "\tspeed: 0.0504s/iter; left time: 747.6431s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878538\n",
      "\tspeed: 0.0504s/iter; left time: 742.4975s\n",
      "\titers: 700, epoch: 4 | loss: 0.0897520\n",
      "\tspeed: 0.0504s/iter; left time: 737.5460s\n",
      "\titers: 800, epoch: 4 | loss: 0.0854635\n",
      "\tspeed: 0.0505s/iter; left time: 734.1163s\n",
      "\titers: 900, epoch: 4 | loss: 0.0885362\n",
      "\tspeed: 0.0504s/iter; left time: 728.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0909175 Vali Loss: 0.0953376 Test Loss: 0.1429246\n",
      "Validation loss decreased (0.098446 --> 0.095338).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0883355\n",
      "\tspeed: 0.1403s/iter; left time: 2010.8001s\n",
      "\titers: 200, epoch: 5 | loss: 0.0869098\n",
      "\tspeed: 0.0504s/iter; left time: 717.2617s\n",
      "\titers: 300, epoch: 5 | loss: 0.0865536\n",
      "\tspeed: 0.0504s/iter; left time: 712.0929s\n",
      "\titers: 400, epoch: 5 | loss: 0.0860558\n",
      "\tspeed: 0.0504s/iter; left time: 707.2679s\n",
      "\titers: 500, epoch: 5 | loss: 0.0856702\n",
      "\tspeed: 0.0504s/iter; left time: 702.2311s\n",
      "\titers: 600, epoch: 5 | loss: 0.0879596\n",
      "\tspeed: 0.0504s/iter; left time: 697.0911s\n",
      "\titers: 700, epoch: 5 | loss: 0.0895608\n",
      "\tspeed: 0.0504s/iter; left time: 691.9814s\n",
      "\titers: 800, epoch: 5 | loss: 0.0870850\n",
      "\tspeed: 0.0504s/iter; left time: 687.2620s\n",
      "\titers: 900, epoch: 5 | loss: 0.0834234\n",
      "\tspeed: 0.0504s/iter; left time: 682.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0860294 Vali Loss: 0.0938435 Test Loss: 0.1573096\n",
      "Validation loss decreased (0.095338 --> 0.093843).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0819926\n",
      "\tspeed: 0.1410s/iter; left time: 1893.2018s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884785\n",
      "\tspeed: 0.0505s/iter; left time: 673.4415s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834609\n",
      "\tspeed: 0.0505s/iter; left time: 667.7094s\n",
      "\titers: 400, epoch: 6 | loss: 0.0848006\n",
      "\tspeed: 0.0504s/iter; left time: 662.3203s\n",
      "\titers: 500, epoch: 6 | loss: 0.0842216\n",
      "\tspeed: 0.0504s/iter; left time: 656.7688s\n",
      "\titers: 600, epoch: 6 | loss: 0.0790967\n",
      "\tspeed: 0.0505s/iter; left time: 653.3962s\n",
      "\titers: 700, epoch: 6 | loss: 0.0801027\n",
      "\tspeed: 0.0505s/iter; left time: 648.2780s\n",
      "\titers: 800, epoch: 6 | loss: 0.0799710\n",
      "\tspeed: 0.0504s/iter; left time: 642.1083s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813835\n",
      "\tspeed: 0.0506s/iter; left time: 638.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0821843 Vali Loss: 0.0972141 Test Loss: 0.1531661\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797309\n",
      "\tspeed: 0.1377s/iter; left time: 1725.4798s\n",
      "\titers: 200, epoch: 7 | loss: 0.0862694\n",
      "\tspeed: 0.0511s/iter; left time: 635.3108s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818903\n",
      "\tspeed: 0.0511s/iter; left time: 629.6545s\n",
      "\titers: 400, epoch: 7 | loss: 0.0793917\n",
      "\tspeed: 0.0511s/iter; left time: 624.5239s\n",
      "\titers: 500, epoch: 7 | loss: 0.0825225\n",
      "\tspeed: 0.0511s/iter; left time: 619.4273s\n",
      "\titers: 600, epoch: 7 | loss: 0.0773069\n",
      "\tspeed: 0.0511s/iter; left time: 614.2800s\n",
      "\titers: 700, epoch: 7 | loss: 0.0710885\n",
      "\tspeed: 0.0506s/iter; left time: 603.8980s\n",
      "\titers: 800, epoch: 7 | loss: 0.0778921\n",
      "\tspeed: 0.0504s/iter; left time: 596.4990s\n",
      "\titers: 900, epoch: 7 | loss: 0.0772341\n",
      "\tspeed: 0.0504s/iter; left time: 590.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.15s\n",
      "Steps: 902 | Train Loss: 0.0783491 Vali Loss: 0.0925858 Test Loss: 0.1583009\n",
      "Validation loss decreased (0.093843 --> 0.092586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754644\n",
      "\tspeed: 0.1407s/iter; left time: 1635.5573s\n",
      "\titers: 200, epoch: 8 | loss: 0.0817999\n",
      "\tspeed: 0.0511s/iter; left time: 589.0371s\n",
      "\titers: 300, epoch: 8 | loss: 0.0772513\n",
      "\tspeed: 0.0511s/iter; left time: 583.9912s\n",
      "\titers: 400, epoch: 8 | loss: 0.0731126\n",
      "\tspeed: 0.0506s/iter; left time: 573.3439s\n",
      "\titers: 500, epoch: 8 | loss: 0.0765568\n",
      "\tspeed: 0.0506s/iter; left time: 567.7213s\n",
      "\titers: 600, epoch: 8 | loss: 0.0775171\n",
      "\tspeed: 0.0505s/iter; left time: 562.0332s\n",
      "\titers: 700, epoch: 8 | loss: 0.0783013\n",
      "\tspeed: 0.0505s/iter; left time: 556.3621s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769860\n",
      "\tspeed: 0.0504s/iter; left time: 550.9337s\n",
      "\titers: 900, epoch: 8 | loss: 0.0720528\n",
      "\tspeed: 0.0504s/iter; left time: 546.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0750094 Vali Loss: 0.0931359 Test Loss: 0.1548578\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725504\n",
      "\tspeed: 0.1379s/iter; left time: 1478.9149s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699559\n",
      "\tspeed: 0.0504s/iter; left time: 535.1801s\n",
      "\titers: 300, epoch: 9 | loss: 0.0776160\n",
      "\tspeed: 0.0504s/iter; left time: 530.1342s\n",
      "\titers: 400, epoch: 9 | loss: 0.0731432\n",
      "\tspeed: 0.0504s/iter; left time: 525.0941s\n",
      "\titers: 500, epoch: 9 | loss: 0.0761598\n",
      "\tspeed: 0.0504s/iter; left time: 520.3729s\n",
      "\titers: 600, epoch: 9 | loss: 0.0740233\n",
      "\tspeed: 0.0504s/iter; left time: 515.5336s\n",
      "\titers: 700, epoch: 9 | loss: 0.0749604\n",
      "\tspeed: 0.0504s/iter; left time: 510.5437s\n",
      "\titers: 800, epoch: 9 | loss: 0.0692300\n",
      "\tspeed: 0.0504s/iter; left time: 505.5818s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723800\n",
      "\tspeed: 0.0505s/iter; left time: 500.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0717975 Vali Loss: 0.0956336 Test Loss: 0.1646968\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0664784\n",
      "\tspeed: 0.1388s/iter; left time: 1363.0090s\n",
      "\titers: 200, epoch: 10 | loss: 0.0747654\n",
      "\tspeed: 0.0504s/iter; left time: 489.7599s\n",
      "\titers: 300, epoch: 10 | loss: 0.0689450\n",
      "\tspeed: 0.0504s/iter; left time: 485.1702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0679197\n",
      "\tspeed: 0.0504s/iter; left time: 480.0177s\n",
      "\titers: 500, epoch: 10 | loss: 0.0737662\n",
      "\tspeed: 0.0505s/iter; left time: 475.8619s\n",
      "\titers: 600, epoch: 10 | loss: 0.0641387\n",
      "\tspeed: 0.0504s/iter; left time: 470.0892s\n",
      "\titers: 700, epoch: 10 | loss: 0.0697696\n",
      "\tspeed: 0.0504s/iter; left time: 464.7363s\n",
      "\titers: 800, epoch: 10 | loss: 0.0677867\n",
      "\tspeed: 0.0504s/iter; left time: 459.8094s\n",
      "\titers: 900, epoch: 10 | loss: 0.0695094\n",
      "\tspeed: 0.0504s/iter; left time: 454.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 902 | Train Loss: 0.0689554 Vali Loss: 0.0961502 Test Loss: 0.1730712\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672925\n",
      "\tspeed: 0.1373s/iter; left time: 1224.9632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0610949\n",
      "\tspeed: 0.0505s/iter; left time: 445.6581s\n",
      "\titers: 300, epoch: 11 | loss: 0.0667393\n",
      "\tspeed: 0.0505s/iter; left time: 440.8279s\n",
      "\titers: 400, epoch: 11 | loss: 0.0678346\n",
      "\tspeed: 0.0505s/iter; left time: 435.7379s\n",
      "\titers: 500, epoch: 11 | loss: 0.0672898\n",
      "\tspeed: 0.0505s/iter; left time: 429.9508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0637237\n",
      "\tspeed: 0.0504s/iter; left time: 424.2824s\n",
      "\titers: 700, epoch: 11 | loss: 0.0640562\n",
      "\tspeed: 0.0504s/iter; left time: 419.1978s\n",
      "\titers: 800, epoch: 11 | loss: 0.0617589\n",
      "\tspeed: 0.0504s/iter; left time: 414.6768s\n",
      "\titers: 900, epoch: 11 | loss: 0.0612631\n",
      "\tspeed: 0.0504s/iter; left time: 409.3253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0663154 Vali Loss: 0.0945666 Test Loss: 0.1649144\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646060\n",
      "\tspeed: 0.1378s/iter; left time: 1104.9374s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642981\n",
      "\tspeed: 0.0504s/iter; left time: 399.1010s\n",
      "\titers: 300, epoch: 12 | loss: 0.0621096\n",
      "\tspeed: 0.0504s/iter; left time: 394.0479s\n",
      "\titers: 400, epoch: 12 | loss: 0.0637253\n",
      "\tspeed: 0.0504s/iter; left time: 388.9243s\n",
      "\titers: 500, epoch: 12 | loss: 0.0630992\n",
      "\tspeed: 0.0504s/iter; left time: 383.9630s\n",
      "\titers: 600, epoch: 12 | loss: 0.0635810\n",
      "\tspeed: 0.0504s/iter; left time: 378.8416s\n",
      "\titers: 700, epoch: 12 | loss: 0.0700417\n",
      "\tspeed: 0.0504s/iter; left time: 373.9896s\n",
      "\titers: 800, epoch: 12 | loss: 0.0633632\n",
      "\tspeed: 0.0504s/iter; left time: 368.9444s\n",
      "\titers: 900, epoch: 12 | loss: 0.0606417\n",
      "\tspeed: 0.0504s/iter; left time: 363.8252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 902 | Train Loss: 0.0640580 Vali Loss: 0.0962546 Test Loss: 0.1658105\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.060231514275074005, rmse:0.24542109668254852, mae:0.15826410055160522, rse:0.7208803296089172\n",
      "Intermediate time for ES and pred_len 168: 00h:19m:19.39s\n",
      "Intermediate time for ES: 00h:56m:56.97s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1754016\n",
      "\tspeed: 0.0559s/iter; left time: 1007.9014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1718795\n",
      "\tspeed: 0.0346s/iter; left time: 619.4958s\n",
      "\titers: 300, epoch: 1 | loss: 0.1623744\n",
      "\tspeed: 0.0345s/iter; left time: 615.5059s\n",
      "\titers: 400, epoch: 1 | loss: 0.1527693\n",
      "\tspeed: 0.0345s/iter; left time: 612.0520s\n",
      "\titers: 500, epoch: 1 | loss: 0.1545722\n",
      "\tspeed: 0.0345s/iter; left time: 608.5005s\n",
      "\titers: 600, epoch: 1 | loss: 0.1503175\n",
      "\tspeed: 0.0345s/iter; left time: 605.0299s\n",
      "\titers: 700, epoch: 1 | loss: 0.1476793\n",
      "\tspeed: 0.0345s/iter; left time: 601.1617s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516313\n",
      "\tspeed: 0.0345s/iter; left time: 597.7319s\n",
      "\titers: 900, epoch: 1 | loss: 0.1358661\n",
      "\tspeed: 0.0345s/iter; left time: 593.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.99s\n",
      "Steps: 906 | Train Loss: 0.1572264 Vali Loss: 0.1465191 Test Loss: 0.1681759\n",
      "Validation loss decreased (inf --> 0.146519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1367733\n",
      "\tspeed: 0.0988s/iter; left time: 1691.4399s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841815\n",
      "\tspeed: 0.0345s/iter; left time: 586.9984s\n",
      "\titers: 300, epoch: 2 | loss: 0.0651053\n",
      "\tspeed: 0.0345s/iter; left time: 583.7436s\n",
      "\titers: 400, epoch: 2 | loss: 0.0618266\n",
      "\tspeed: 0.0345s/iter; left time: 579.9539s\n",
      "\titers: 500, epoch: 2 | loss: 0.0634880\n",
      "\tspeed: 0.0342s/iter; left time: 571.3485s\n",
      "\titers: 600, epoch: 2 | loss: 0.0748803\n",
      "\tspeed: 0.0339s/iter; left time: 563.6168s\n",
      "\titers: 700, epoch: 2 | loss: 0.0605217\n",
      "\tspeed: 0.0339s/iter; left time: 559.9852s\n",
      "\titers: 800, epoch: 2 | loss: 0.0677919\n",
      "\tspeed: 0.0339s/iter; left time: 557.1336s\n",
      "\titers: 900, epoch: 2 | loss: 0.0628310\n",
      "\tspeed: 0.0339s/iter; left time: 553.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0795633 Vali Loss: 0.0664881 Test Loss: 0.0766027\n",
      "Validation loss decreased (0.146519 --> 0.066488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0596052\n",
      "\tspeed: 0.0963s/iter; left time: 1561.5185s\n",
      "\titers: 200, epoch: 3 | loss: 0.0513732\n",
      "\tspeed: 0.0339s/iter; left time: 546.1884s\n",
      "\titers: 300, epoch: 3 | loss: 0.0622984\n",
      "\tspeed: 0.0339s/iter; left time: 542.8349s\n",
      "\titers: 400, epoch: 3 | loss: 0.0550099\n",
      "\tspeed: 0.0339s/iter; left time: 539.8263s\n",
      "\titers: 500, epoch: 3 | loss: 0.0614815\n",
      "\tspeed: 0.0339s/iter; left time: 536.5546s\n",
      "\titers: 600, epoch: 3 | loss: 0.0572914\n",
      "\tspeed: 0.0340s/iter; left time: 533.4422s\n",
      "\titers: 700, epoch: 3 | loss: 0.0545936\n",
      "\tspeed: 0.0339s/iter; left time: 529.3358s\n",
      "\titers: 800, epoch: 3 | loss: 0.0497180\n",
      "\tspeed: 0.0340s/iter; left time: 527.2602s\n",
      "\titers: 900, epoch: 3 | loss: 0.0469406\n",
      "\tspeed: 0.0340s/iter; left time: 523.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0554530 Vali Loss: 0.0634343 Test Loss: 0.0724585\n",
      "Validation loss decreased (0.066488 --> 0.063434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495711\n",
      "\tspeed: 0.0963s/iter; left time: 1474.0030s\n",
      "\titers: 200, epoch: 4 | loss: 0.0469635\n",
      "\tspeed: 0.0340s/iter; left time: 516.6050s\n",
      "\titers: 300, epoch: 4 | loss: 0.0530830\n",
      "\tspeed: 0.0340s/iter; left time: 513.3490s\n",
      "\titers: 400, epoch: 4 | loss: 0.0561377\n",
      "\tspeed: 0.0340s/iter; left time: 509.8152s\n",
      "\titers: 500, epoch: 4 | loss: 0.0476814\n",
      "\tspeed: 0.0340s/iter; left time: 507.0071s\n",
      "\titers: 600, epoch: 4 | loss: 0.0456952\n",
      "\tspeed: 0.0340s/iter; left time: 503.4136s\n",
      "\titers: 700, epoch: 4 | loss: 0.0571596\n",
      "\tspeed: 0.0341s/iter; left time: 500.8640s\n",
      "\titers: 800, epoch: 4 | loss: 0.0540078\n",
      "\tspeed: 0.0340s/iter; left time: 496.0978s\n",
      "\titers: 900, epoch: 4 | loss: 0.0462834\n",
      "\tspeed: 0.0340s/iter; left time: 492.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0518115 Vali Loss: 0.0635223 Test Loss: 0.0695745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0488895\n",
      "\tspeed: 0.0948s/iter; left time: 1364.1187s\n",
      "\titers: 200, epoch: 5 | loss: 0.0499913\n",
      "\tspeed: 0.0339s/iter; left time: 485.1753s\n",
      "\titers: 300, epoch: 5 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 481.4244s\n",
      "\titers: 400, epoch: 5 | loss: 0.0502475\n",
      "\tspeed: 0.0339s/iter; left time: 478.0747s\n",
      "\titers: 500, epoch: 5 | loss: 0.0491475\n",
      "\tspeed: 0.0339s/iter; left time: 474.6270s\n",
      "\titers: 600, epoch: 5 | loss: 0.0568916\n",
      "\tspeed: 0.0339s/iter; left time: 471.4574s\n",
      "\titers: 700, epoch: 5 | loss: 0.0549902\n",
      "\tspeed: 0.0339s/iter; left time: 468.3713s\n",
      "\titers: 800, epoch: 5 | loss: 0.0451431\n",
      "\tspeed: 0.0340s/iter; left time: 465.8810s\n",
      "\titers: 900, epoch: 5 | loss: 0.0446936\n",
      "\tspeed: 0.0340s/iter; left time: 462.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.01s\n",
      "Steps: 906 | Train Loss: 0.0493321 Vali Loss: 0.0611000 Test Loss: 0.0659227\n",
      "Validation loss decreased (0.063434 --> 0.061100).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0444498\n",
      "\tspeed: 0.0979s/iter; left time: 1320.1492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0404346\n",
      "\tspeed: 0.0340s/iter; left time: 455.4152s\n",
      "\titers: 300, epoch: 6 | loss: 0.0465716\n",
      "\tspeed: 0.0341s/iter; left time: 452.5626s\n",
      "\titers: 400, epoch: 6 | loss: 0.0545136\n",
      "\tspeed: 0.0340s/iter; left time: 448.8263s\n",
      "\titers: 500, epoch: 6 | loss: 0.0427680\n",
      "\tspeed: 0.0340s/iter; left time: 445.3560s\n",
      "\titers: 600, epoch: 6 | loss: 0.0515021\n",
      "\tspeed: 0.0340s/iter; left time: 442.2144s\n",
      "\titers: 700, epoch: 6 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 438.8689s\n",
      "\titers: 800, epoch: 6 | loss: 0.0440863\n",
      "\tspeed: 0.0340s/iter; left time: 435.0576s\n",
      "\titers: 900, epoch: 6 | loss: 0.0484343\n",
      "\tspeed: 0.0340s/iter; left time: 431.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0473150 Vali Loss: 0.0597577 Test Loss: 0.0665739\n",
      "Validation loss decreased (0.061100 --> 0.059758).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0403488\n",
      "\tspeed: 0.0966s/iter; left time: 1215.3639s\n",
      "\titers: 200, epoch: 7 | loss: 0.0512392\n",
      "\tspeed: 0.0341s/iter; left time: 425.2229s\n",
      "\titers: 300, epoch: 7 | loss: 0.0439793\n",
      "\tspeed: 0.0340s/iter; left time: 421.6574s\n",
      "\titers: 400, epoch: 7 | loss: 0.0472125\n",
      "\tspeed: 0.0341s/iter; left time: 419.0718s\n",
      "\titers: 500, epoch: 7 | loss: 0.0420035\n",
      "\tspeed: 0.0341s/iter; left time: 415.1392s\n",
      "\titers: 600, epoch: 7 | loss: 0.0384621\n",
      "\tspeed: 0.0340s/iter; left time: 411.1737s\n",
      "\titers: 700, epoch: 7 | loss: 0.0459063\n",
      "\tspeed: 0.0340s/iter; left time: 407.8058s\n",
      "\titers: 800, epoch: 7 | loss: 0.0440278\n",
      "\tspeed: 0.0340s/iter; left time: 404.4169s\n",
      "\titers: 900, epoch: 7 | loss: 0.0393112\n",
      "\tspeed: 0.0341s/iter; left time: 401.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0454778 Vali Loss: 0.0590582 Test Loss: 0.0647275\n",
      "Validation loss decreased (0.059758 --> 0.059058).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406533\n",
      "\tspeed: 0.0963s/iter; left time: 1124.3786s\n",
      "\titers: 200, epoch: 8 | loss: 0.0469764\n",
      "\tspeed: 0.0340s/iter; left time: 393.9680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0392994\n",
      "\tspeed: 0.0341s/iter; left time: 390.9760s\n",
      "\titers: 400, epoch: 8 | loss: 0.0500969\n",
      "\tspeed: 0.0340s/iter; left time: 386.7208s\n",
      "\titers: 500, epoch: 8 | loss: 0.0434114\n",
      "\tspeed: 0.0341s/iter; left time: 384.0735s\n",
      "\titers: 600, epoch: 8 | loss: 0.0427843\n",
      "\tspeed: 0.0340s/iter; left time: 380.4872s\n",
      "\titers: 700, epoch: 8 | loss: 0.0442753\n",
      "\tspeed: 0.0340s/iter; left time: 377.0512s\n",
      "\titers: 800, epoch: 8 | loss: 0.0417612\n",
      "\tspeed: 0.0341s/iter; left time: 373.8817s\n",
      "\titers: 900, epoch: 8 | loss: 0.0468672\n",
      "\tspeed: 0.0340s/iter; left time: 370.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0443256 Vali Loss: 0.0590278 Test Loss: 0.0666126\n",
      "Validation loss decreased (0.059058 --> 0.059028).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409645\n",
      "\tspeed: 0.0981s/iter; left time: 1056.9135s\n",
      "\titers: 200, epoch: 9 | loss: 0.0432575\n",
      "\tspeed: 0.0340s/iter; left time: 363.3648s\n",
      "\titers: 300, epoch: 9 | loss: 0.0464971\n",
      "\tspeed: 0.0340s/iter; left time: 359.6136s\n",
      "\titers: 400, epoch: 9 | loss: 0.0420422\n",
      "\tspeed: 0.0340s/iter; left time: 356.5808s\n",
      "\titers: 500, epoch: 9 | loss: 0.0445137\n",
      "\tspeed: 0.0340s/iter; left time: 352.9895s\n",
      "\titers: 600, epoch: 9 | loss: 0.0377047\n",
      "\tspeed: 0.0340s/iter; left time: 349.1521s\n",
      "\titers: 700, epoch: 9 | loss: 0.0373535\n",
      "\tspeed: 0.0340s/iter; left time: 345.8586s\n",
      "\titers: 800, epoch: 9 | loss: 0.0378851\n",
      "\tspeed: 0.0341s/iter; left time: 343.0847s\n",
      "\titers: 900, epoch: 9 | loss: 0.0343114\n",
      "\tspeed: 0.0340s/iter; left time: 339.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0427961 Vali Loss: 0.0573571 Test Loss: 0.0648689\n",
      "Validation loss decreased (0.059028 --> 0.057357).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0417384\n",
      "\tspeed: 0.0961s/iter; left time: 948.5302s\n",
      "\titers: 200, epoch: 10 | loss: 0.0398730\n",
      "\tspeed: 0.0341s/iter; left time: 332.5684s\n",
      "\titers: 300, epoch: 10 | loss: 0.0431907\n",
      "\tspeed: 0.0341s/iter; left time: 329.3007s\n",
      "\titers: 400, epoch: 10 | loss: 0.0450556\n",
      "\tspeed: 0.0340s/iter; left time: 325.5051s\n",
      "\titers: 500, epoch: 10 | loss: 0.0350549\n",
      "\tspeed: 0.0340s/iter; left time: 321.8316s\n",
      "\titers: 600, epoch: 10 | loss: 0.0404603\n",
      "\tspeed: 0.0340s/iter; left time: 318.3607s\n",
      "\titers: 700, epoch: 10 | loss: 0.0432734\n",
      "\tspeed: 0.0340s/iter; left time: 315.3881s\n",
      "\titers: 800, epoch: 10 | loss: 0.0391883\n",
      "\tspeed: 0.0340s/iter; left time: 311.7923s\n",
      "\titers: 900, epoch: 10 | loss: 0.0427314\n",
      "\tspeed: 0.0340s/iter; left time: 308.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0417776 Vali Loss: 0.0574123 Test Loss: 0.0637241\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417736\n",
      "\tspeed: 0.0940s/iter; left time: 842.1604s\n",
      "\titers: 200, epoch: 11 | loss: 0.0475188\n",
      "\tspeed: 0.0346s/iter; left time: 306.1956s\n",
      "\titers: 300, epoch: 11 | loss: 0.0371066\n",
      "\tspeed: 0.0345s/iter; left time: 302.6752s\n",
      "\titers: 400, epoch: 11 | loss: 0.0418829\n",
      "\tspeed: 0.0346s/iter; left time: 299.4190s\n",
      "\titers: 500, epoch: 11 | loss: 0.0450594\n",
      "\tspeed: 0.0345s/iter; left time: 295.7692s\n",
      "\titers: 600, epoch: 11 | loss: 0.0439484\n",
      "\tspeed: 0.0346s/iter; left time: 292.4431s\n",
      "\titers: 700, epoch: 11 | loss: 0.0418536\n",
      "\tspeed: 0.0347s/iter; left time: 290.4458s\n",
      "\titers: 800, epoch: 11 | loss: 0.0409613\n",
      "\tspeed: 0.0346s/iter; left time: 285.9516s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418191\n",
      "\tspeed: 0.0346s/iter; left time: 282.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0406990 Vali Loss: 0.0576143 Test Loss: 0.0632747\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0370599\n",
      "\tspeed: 0.0946s/iter; left time: 761.8586s\n",
      "\titers: 200, epoch: 12 | loss: 0.0422251\n",
      "\tspeed: 0.0341s/iter; left time: 270.9392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0389508\n",
      "\tspeed: 0.0340s/iter; left time: 267.0887s\n",
      "\titers: 400, epoch: 12 | loss: 0.0401749\n",
      "\tspeed: 0.0340s/iter; left time: 263.7060s\n",
      "\titers: 500, epoch: 12 | loss: 0.0385777\n",
      "\tspeed: 0.0340s/iter; left time: 260.1403s\n",
      "\titers: 600, epoch: 12 | loss: 0.0389454\n",
      "\tspeed: 0.0339s/iter; left time: 256.3173s\n",
      "\titers: 700, epoch: 12 | loss: 0.0357124\n",
      "\tspeed: 0.0340s/iter; left time: 253.4781s\n",
      "\titers: 800, epoch: 12 | loss: 0.0377932\n",
      "\tspeed: 0.0340s/iter; left time: 250.0363s\n",
      "\titers: 900, epoch: 12 | loss: 0.0412504\n",
      "\tspeed: 0.0340s/iter; left time: 246.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0396205 Vali Loss: 0.0564137 Test Loss: 0.0632015\n",
      "Validation loss decreased (0.057357 --> 0.056414).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0420268\n",
      "\tspeed: 0.0988s/iter; left time: 706.5339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0387494\n",
      "\tspeed: 0.0340s/iter; left time: 239.5933s\n",
      "\titers: 300, epoch: 13 | loss: 0.0355878\n",
      "\tspeed: 0.0340s/iter; left time: 236.3251s\n",
      "\titers: 400, epoch: 13 | loss: 0.0343830\n",
      "\tspeed: 0.0339s/iter; left time: 232.1565s\n",
      "\titers: 500, epoch: 13 | loss: 0.0421653\n",
      "\tspeed: 0.0340s/iter; left time: 229.2012s\n",
      "\titers: 600, epoch: 13 | loss: 0.0360691\n",
      "\tspeed: 0.0339s/iter; left time: 225.5456s\n",
      "\titers: 700, epoch: 13 | loss: 0.0363027\n",
      "\tspeed: 0.0340s/iter; left time: 222.5785s\n",
      "\titers: 800, epoch: 13 | loss: 0.0376486\n",
      "\tspeed: 0.0339s/iter; left time: 218.7247s\n",
      "\titers: 900, epoch: 13 | loss: 0.0431237\n",
      "\tspeed: 0.0340s/iter; left time: 215.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0385994 Vali Loss: 0.0564743 Test Loss: 0.0633992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0412338\n",
      "\tspeed: 0.0937s/iter; left time: 584.9274s\n",
      "\titers: 200, epoch: 14 | loss: 0.0365248\n",
      "\tspeed: 0.0339s/iter; left time: 208.4826s\n",
      "\titers: 300, epoch: 14 | loss: 0.0365122\n",
      "\tspeed: 0.0340s/iter; left time: 205.2606s\n",
      "\titers: 400, epoch: 14 | loss: 0.0376992\n",
      "\tspeed: 0.0340s/iter; left time: 202.1956s\n",
      "\titers: 500, epoch: 14 | loss: 0.0416844\n",
      "\tspeed: 0.0340s/iter; left time: 198.5506s\n",
      "\titers: 600, epoch: 14 | loss: 0.0383253\n",
      "\tspeed: 0.0339s/iter; left time: 194.8081s\n",
      "\titers: 700, epoch: 14 | loss: 0.0366903\n",
      "\tspeed: 0.0341s/iter; left time: 192.1697s\n",
      "\titers: 800, epoch: 14 | loss: 0.0462296\n",
      "\tspeed: 0.0340s/iter; left time: 188.3393s\n",
      "\titers: 900, epoch: 14 | loss: 0.0353763\n",
      "\tspeed: 0.0340s/iter; left time: 185.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0376544 Vali Loss: 0.0559921 Test Loss: 0.0616274\n",
      "Validation loss decreased (0.056414 --> 0.055992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0385241\n",
      "\tspeed: 0.0967s/iter; left time: 516.1917s\n",
      "\titers: 200, epoch: 15 | loss: 0.0367979\n",
      "\tspeed: 0.0339s/iter; left time: 177.7850s\n",
      "\titers: 300, epoch: 15 | loss: 0.0331814\n",
      "\tspeed: 0.0340s/iter; left time: 174.4053s\n",
      "\titers: 400, epoch: 15 | loss: 0.0364987\n",
      "\tspeed: 0.0340s/iter; left time: 171.0100s\n",
      "\titers: 500, epoch: 15 | loss: 0.0332029\n",
      "\tspeed: 0.0340s/iter; left time: 168.0468s\n",
      "\titers: 600, epoch: 15 | loss: 0.0384601\n",
      "\tspeed: 0.0339s/iter; left time: 163.9847s\n",
      "\titers: 700, epoch: 15 | loss: 0.0368570\n",
      "\tspeed: 0.0339s/iter; left time: 160.6274s\n",
      "\titers: 800, epoch: 15 | loss: 0.0354397\n",
      "\tspeed: 0.0339s/iter; left time: 157.0704s\n",
      "\titers: 900, epoch: 15 | loss: 0.0366562\n",
      "\tspeed: 0.0339s/iter; left time: 153.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0369873 Vali Loss: 0.0558398 Test Loss: 0.0628962\n",
      "Validation loss decreased (0.055992 --> 0.055840).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0392919\n",
      "\tspeed: 0.0961s/iter; left time: 426.0157s\n",
      "\titers: 200, epoch: 16 | loss: 0.0445064\n",
      "\tspeed: 0.0339s/iter; left time: 146.8060s\n",
      "\titers: 300, epoch: 16 | loss: 0.0404944\n",
      "\tspeed: 0.0339s/iter; left time: 143.4647s\n",
      "\titers: 400, epoch: 16 | loss: 0.0348784\n",
      "\tspeed: 0.0339s/iter; left time: 140.0167s\n",
      "\titers: 500, epoch: 16 | loss: 0.0308083\n",
      "\tspeed: 0.0340s/iter; left time: 136.9805s\n",
      "\titers: 600, epoch: 16 | loss: 0.0367714\n",
      "\tspeed: 0.0339s/iter; left time: 133.3032s\n",
      "\titers: 700, epoch: 16 | loss: 0.0356430\n",
      "\tspeed: 0.0339s/iter; left time: 129.9085s\n",
      "\titers: 800, epoch: 16 | loss: 0.0364897\n",
      "\tspeed: 0.0340s/iter; left time: 126.9509s\n",
      "\titers: 900, epoch: 16 | loss: 0.0351077\n",
      "\tspeed: 0.0340s/iter; left time: 123.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0361995 Vali Loss: 0.0570393 Test Loss: 0.0630939\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0382720\n",
      "\tspeed: 0.0941s/iter; left time: 331.8666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0357151\n",
      "\tspeed: 0.0340s/iter; left time: 116.4433s\n",
      "\titers: 300, epoch: 17 | loss: 0.0355730\n",
      "\tspeed: 0.0340s/iter; left time: 113.2038s\n",
      "\titers: 400, epoch: 17 | loss: 0.0348953\n",
      "\tspeed: 0.0345s/iter; left time: 111.3173s\n",
      "\titers: 500, epoch: 17 | loss: 0.0320778\n",
      "\tspeed: 0.0345s/iter; left time: 107.8330s\n",
      "\titers: 600, epoch: 17 | loss: 0.0328302\n",
      "\tspeed: 0.0345s/iter; left time: 104.5112s\n",
      "\titers: 700, epoch: 17 | loss: 0.0377763\n",
      "\tspeed: 0.0345s/iter; left time: 100.9964s\n",
      "\titers: 800, epoch: 17 | loss: 0.0368321\n",
      "\tspeed: 0.0346s/iter; left time: 97.6821s\n",
      "\titers: 900, epoch: 17 | loss: 0.0395076\n",
      "\tspeed: 0.0345s/iter; left time: 93.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0355288 Vali Loss: 0.0563765 Test Loss: 0.0635618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0334214\n",
      "\tspeed: 0.0942s/iter; left time: 246.8353s\n",
      "\titers: 200, epoch: 18 | loss: 0.0349425\n",
      "\tspeed: 0.0341s/iter; left time: 85.7858s\n",
      "\titers: 300, epoch: 18 | loss: 0.0340762\n",
      "\tspeed: 0.0341s/iter; left time: 82.3672s\n",
      "\titers: 400, epoch: 18 | loss: 0.0363117\n",
      "\tspeed: 0.0341s/iter; left time: 78.9903s\n",
      "\titers: 500, epoch: 18 | loss: 0.0395520\n",
      "\tspeed: 0.0340s/iter; left time: 75.5496s\n",
      "\titers: 600, epoch: 18 | loss: 0.0366950\n",
      "\tspeed: 0.0341s/iter; left time: 72.1646s\n",
      "\titers: 700, epoch: 18 | loss: 0.0427621\n",
      "\tspeed: 0.0340s/iter; left time: 68.7282s\n",
      "\titers: 800, epoch: 18 | loss: 0.0320136\n",
      "\tspeed: 0.0340s/iter; left time: 65.3171s\n",
      "\titers: 900, epoch: 18 | loss: 0.0407823\n",
      "\tspeed: 0.0341s/iter; left time: 61.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0349199 Vali Loss: 0.0566797 Test Loss: 0.0626437\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0350009\n",
      "\tspeed: 0.0930s/iter; left time: 159.3698s\n",
      "\titers: 200, epoch: 19 | loss: 0.0359370\n",
      "\tspeed: 0.0340s/iter; left time: 54.8002s\n",
      "\titers: 300, epoch: 19 | loss: 0.0364045\n",
      "\tspeed: 0.0340s/iter; left time: 51.4413s\n",
      "\titers: 400, epoch: 19 | loss: 0.0337826\n",
      "\tspeed: 0.0340s/iter; left time: 47.9738s\n",
      "\titers: 500, epoch: 19 | loss: 0.0354946\n",
      "\tspeed: 0.0340s/iter; left time: 44.6339s\n",
      "\titers: 600, epoch: 19 | loss: 0.0339434\n",
      "\tspeed: 0.0340s/iter; left time: 41.2057s\n",
      "\titers: 700, epoch: 19 | loss: 0.0348568\n",
      "\tspeed: 0.0340s/iter; left time: 37.8161s\n",
      "\titers: 800, epoch: 19 | loss: 0.0328255\n",
      "\tspeed: 0.0340s/iter; left time: 34.4323s\n",
      "\titers: 900, epoch: 19 | loss: 0.0363572\n",
      "\tspeed: 0.0340s/iter; left time: 31.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0345114 Vali Loss: 0.0565572 Test Loss: 0.0630916\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0393753\n",
      "\tspeed: 0.0944s/iter; left time: 76.2104s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383313\n",
      "\tspeed: 0.0339s/iter; left time: 23.9371s\n",
      "\titers: 300, epoch: 20 | loss: 0.0362157\n",
      "\tspeed: 0.0339s/iter; left time: 20.5805s\n",
      "\titers: 400, epoch: 20 | loss: 0.0314259\n",
      "\tspeed: 0.0340s/iter; left time: 17.2133s\n",
      "\titers: 500, epoch: 20 | loss: 0.0358881\n",
      "\tspeed: 0.0340s/iter; left time: 13.8198s\n",
      "\titers: 600, epoch: 20 | loss: 0.0343928\n",
      "\tspeed: 0.0340s/iter; left time: 10.4321s\n",
      "\titers: 700, epoch: 20 | loss: 0.0340157\n",
      "\tspeed: 0.0339s/iter; left time: 7.0263s\n",
      "\titers: 800, epoch: 20 | loss: 0.0352002\n",
      "\tspeed: 0.0339s/iter; left time: 3.6284s\n",
      "\titers: 900, epoch: 20 | loss: 0.0332215\n",
      "\tspeed: 0.0340s/iter; left time: 0.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0340116 Vali Loss: 0.0563868 Test Loss: 0.0630755\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012454495765268803, rmse:0.11159971356391907, mae:0.06283904612064362, rse:0.4306430518627167\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1799639\n",
      "\tspeed: 0.0362s/iter; left time: 652.4446s\n",
      "\titers: 200, epoch: 1 | loss: 0.1643134\n",
      "\tspeed: 0.0340s/iter; left time: 610.0871s\n",
      "\titers: 300, epoch: 1 | loss: 0.1678073\n",
      "\tspeed: 0.0340s/iter; left time: 606.4789s\n",
      "\titers: 400, epoch: 1 | loss: 0.1560568\n",
      "\tspeed: 0.0340s/iter; left time: 603.2615s\n",
      "\titers: 500, epoch: 1 | loss: 0.1497856\n",
      "\tspeed: 0.0340s/iter; left time: 599.3590s\n",
      "\titers: 600, epoch: 1 | loss: 0.1513730\n",
      "\tspeed: 0.0340s/iter; left time: 596.2770s\n",
      "\titers: 700, epoch: 1 | loss: 0.1495658\n",
      "\tspeed: 0.0341s/iter; left time: 593.4248s\n",
      "\titers: 800, epoch: 1 | loss: 0.1475314\n",
      "\tspeed: 0.0340s/iter; left time: 589.2816s\n",
      "\titers: 900, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0340s/iter; left time: 586.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.1621176 Vali Loss: 0.1434601 Test Loss: 0.1637105\n",
      "Validation loss decreased (inf --> 0.143460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1280499\n",
      "\tspeed: 0.0969s/iter; left time: 1658.2526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0996244\n",
      "\tspeed: 0.0341s/iter; left time: 580.6063s\n",
      "\titers: 300, epoch: 2 | loss: 0.1066693\n",
      "\tspeed: 0.0341s/iter; left time: 576.4870s\n",
      "\titers: 400, epoch: 2 | loss: 0.0870007\n",
      "\tspeed: 0.0341s/iter; left time: 573.9577s\n",
      "\titers: 500, epoch: 2 | loss: 0.0831003\n",
      "\tspeed: 0.0341s/iter; left time: 570.0731s\n",
      "\titers: 600, epoch: 2 | loss: 0.0833607\n",
      "\tspeed: 0.0341s/iter; left time: 566.2976s\n",
      "\titers: 700, epoch: 2 | loss: 0.0783962\n",
      "\tspeed: 0.0340s/iter; left time: 561.6904s\n",
      "\titers: 800, epoch: 2 | loss: 0.0747123\n",
      "\tspeed: 0.0340s/iter; left time: 558.8937s\n",
      "\titers: 900, epoch: 2 | loss: 0.0690103\n",
      "\tspeed: 0.0341s/iter; left time: 555.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0950980 Vali Loss: 0.0901362 Test Loss: 0.1025138\n",
      "Validation loss decreased (0.143460 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686186\n",
      "\tspeed: 0.0970s/iter; left time: 1573.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774667\n",
      "\tspeed: 0.0340s/iter; left time: 547.6336s\n",
      "\titers: 300, epoch: 3 | loss: 0.0744100\n",
      "\tspeed: 0.0341s/iter; left time: 545.1095s\n",
      "\titers: 400, epoch: 3 | loss: 0.0659564\n",
      "\tspeed: 0.0340s/iter; left time: 540.8907s\n",
      "\titers: 500, epoch: 3 | loss: 0.0685518\n",
      "\tspeed: 0.0340s/iter; left time: 538.1349s\n",
      "\titers: 600, epoch: 3 | loss: 0.0650003\n",
      "\tspeed: 0.0340s/iter; left time: 534.8691s\n",
      "\titers: 700, epoch: 3 | loss: 0.0603844\n",
      "\tspeed: 0.0340s/iter; left time: 531.0855s\n",
      "\titers: 800, epoch: 3 | loss: 0.0562463\n",
      "\tspeed: 0.0340s/iter; left time: 527.6460s\n",
      "\titers: 900, epoch: 3 | loss: 0.0498774\n",
      "\tspeed: 0.0341s/iter; left time: 524.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0693412 Vali Loss: 0.0679662 Test Loss: 0.0759230\n",
      "Validation loss decreased (0.090136 --> 0.067966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609032\n",
      "\tspeed: 0.1011s/iter; left time: 1547.7745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538243\n",
      "\tspeed: 0.0341s/iter; left time: 517.9878s\n",
      "\titers: 300, epoch: 4 | loss: 0.0516822\n",
      "\tspeed: 0.0341s/iter; left time: 514.3943s\n",
      "\titers: 400, epoch: 4 | loss: 0.0576723\n",
      "\tspeed: 0.0340s/iter; left time: 510.6228s\n",
      "\titers: 500, epoch: 4 | loss: 0.0511567\n",
      "\tspeed: 0.0340s/iter; left time: 506.6648s\n",
      "\titers: 600, epoch: 4 | loss: 0.0473879\n",
      "\tspeed: 0.0340s/iter; left time: 503.3008s\n",
      "\titers: 700, epoch: 4 | loss: 0.0561181\n",
      "\tspeed: 0.0341s/iter; left time: 500.8967s\n",
      "\titers: 800, epoch: 4 | loss: 0.0411501\n",
      "\tspeed: 0.0340s/iter; left time: 496.7483s\n",
      "\titers: 900, epoch: 4 | loss: 0.0510259\n",
      "\tspeed: 0.0341s/iter; left time: 493.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0531958 Vali Loss: 0.0632272 Test Loss: 0.0694707\n",
      "Validation loss decreased (0.067966 --> 0.063227).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619297\n",
      "\tspeed: 0.0968s/iter; left time: 1393.6483s\n",
      "\titers: 200, epoch: 5 | loss: 0.0546464\n",
      "\tspeed: 0.0340s/iter; left time: 486.8072s\n",
      "\titers: 300, epoch: 5 | loss: 0.0613711\n",
      "\tspeed: 0.0341s/iter; left time: 483.9119s\n",
      "\titers: 400, epoch: 5 | loss: 0.0470468\n",
      "\tspeed: 0.0341s/iter; left time: 480.5576s\n",
      "\titers: 500, epoch: 5 | loss: 0.0465499\n",
      "\tspeed: 0.0341s/iter; left time: 477.5381s\n",
      "\titers: 600, epoch: 5 | loss: 0.0433100\n",
      "\tspeed: 0.0341s/iter; left time: 474.1792s\n",
      "\titers: 700, epoch: 5 | loss: 0.0539502\n",
      "\tspeed: 0.0341s/iter; left time: 470.8634s\n",
      "\titers: 800, epoch: 5 | loss: 0.0489548\n",
      "\tspeed: 0.0341s/iter; left time: 467.0049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0480206\n",
      "\tspeed: 0.0340s/iter; left time: 462.8215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0503956 Vali Loss: 0.0638788 Test Loss: 0.0694296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0558476\n",
      "\tspeed: 0.0931s/iter; left time: 1255.5520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0517960\n",
      "\tspeed: 0.0341s/iter; left time: 456.0462s\n",
      "\titers: 300, epoch: 6 | loss: 0.0477182\n",
      "\tspeed: 0.0340s/iter; left time: 451.8443s\n",
      "\titers: 400, epoch: 6 | loss: 0.0510341\n",
      "\tspeed: 0.0340s/iter; left time: 449.0183s\n",
      "\titers: 500, epoch: 6 | loss: 0.0578296\n",
      "\tspeed: 0.0341s/iter; left time: 446.2099s\n",
      "\titers: 600, epoch: 6 | loss: 0.0474456\n",
      "\tspeed: 0.0340s/iter; left time: 442.1500s\n",
      "\titers: 700, epoch: 6 | loss: 0.0449998\n",
      "\tspeed: 0.0340s/iter; left time: 438.3822s\n",
      "\titers: 800, epoch: 6 | loss: 0.0488756\n",
      "\tspeed: 0.0341s/iter; left time: 435.7082s\n",
      "\titers: 900, epoch: 6 | loss: 0.0458535\n",
      "\tspeed: 0.0341s/iter; left time: 432.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0484827 Vali Loss: 0.0618802 Test Loss: 0.0675384\n",
      "Validation loss decreased (0.063227 --> 0.061880).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504562\n",
      "\tspeed: 0.0961s/iter; left time: 1209.5752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0376698\n",
      "\tspeed: 0.0340s/iter; left time: 424.8540s\n",
      "\titers: 300, epoch: 7 | loss: 0.0475422\n",
      "\tspeed: 0.0340s/iter; left time: 421.4028s\n",
      "\titers: 400, epoch: 7 | loss: 0.0474081\n",
      "\tspeed: 0.0340s/iter; left time: 417.7398s\n",
      "\titers: 500, epoch: 7 | loss: 0.0480068\n",
      "\tspeed: 0.0341s/iter; left time: 415.1552s\n",
      "\titers: 600, epoch: 7 | loss: 0.0499294\n",
      "\tspeed: 0.0340s/iter; left time: 411.3285s\n",
      "\titers: 700, epoch: 7 | loss: 0.0466667\n",
      "\tspeed: 0.0341s/iter; left time: 409.0004s\n",
      "\titers: 800, epoch: 7 | loss: 0.0481679\n",
      "\tspeed: 0.0347s/iter; left time: 412.2438s\n",
      "\titers: 900, epoch: 7 | loss: 0.0472499\n",
      "\tspeed: 0.0346s/iter; left time: 408.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 906 | Train Loss: 0.0468621 Vali Loss: 0.0617771 Test Loss: 0.0675191\n",
      "Validation loss decreased (0.061880 --> 0.061777).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513489\n",
      "\tspeed: 0.0969s/iter; left time: 1132.0153s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440349\n",
      "\tspeed: 0.0341s/iter; left time: 394.6745s\n",
      "\titers: 300, epoch: 8 | loss: 0.0446530\n",
      "\tspeed: 0.0340s/iter; left time: 390.7435s\n",
      "\titers: 400, epoch: 8 | loss: 0.0405290\n",
      "\tspeed: 0.0340s/iter; left time: 387.3347s\n",
      "\titers: 500, epoch: 8 | loss: 0.0435242\n",
      "\tspeed: 0.0341s/iter; left time: 384.3399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0423415\n",
      "\tspeed: 0.0340s/iter; left time: 380.4947s\n",
      "\titers: 700, epoch: 8 | loss: 0.0417117\n",
      "\tspeed: 0.0341s/iter; left time: 377.3020s\n",
      "\titers: 800, epoch: 8 | loss: 0.0462200\n",
      "\tspeed: 0.0341s/iter; left time: 374.0436s\n",
      "\titers: 900, epoch: 8 | loss: 0.0429036\n",
      "\tspeed: 0.0340s/iter; left time: 370.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0452779 Vali Loss: 0.0590413 Test Loss: 0.0656133\n",
      "Validation loss decreased (0.061777 --> 0.059041).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0433994\n",
      "\tspeed: 0.0971s/iter; left time: 1045.5309s\n",
      "\titers: 200, epoch: 9 | loss: 0.0410988\n",
      "\tspeed: 0.0340s/iter; left time: 363.1287s\n",
      "\titers: 300, epoch: 9 | loss: 0.0437933\n",
      "\tspeed: 0.0340s/iter; left time: 359.9408s\n",
      "\titers: 400, epoch: 9 | loss: 0.0443417\n",
      "\tspeed: 0.0340s/iter; left time: 356.3902s\n",
      "\titers: 500, epoch: 9 | loss: 0.0440277\n",
      "\tspeed: 0.0340s/iter; left time: 353.1507s\n",
      "\titers: 600, epoch: 9 | loss: 0.0452474\n",
      "\tspeed: 0.0340s/iter; left time: 349.6943s\n",
      "\titers: 700, epoch: 9 | loss: 0.0401173\n",
      "\tspeed: 0.0341s/iter; left time: 346.4884s\n",
      "\titers: 800, epoch: 9 | loss: 0.0455280\n",
      "\tspeed: 0.0340s/iter; left time: 342.8749s\n",
      "\titers: 900, epoch: 9 | loss: 0.0525242\n",
      "\tspeed: 0.0340s/iter; left time: 339.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0436650 Vali Loss: 0.0592790 Test Loss: 0.0648833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0408640\n",
      "\tspeed: 0.0932s/iter; left time: 919.7983s\n",
      "\titers: 200, epoch: 10 | loss: 0.0427431\n",
      "\tspeed: 0.0341s/iter; left time: 332.7807s\n",
      "\titers: 300, epoch: 10 | loss: 0.0461511\n",
      "\tspeed: 0.0340s/iter; left time: 328.8849s\n",
      "\titers: 400, epoch: 10 | loss: 0.0389742\n",
      "\tspeed: 0.0340s/iter; left time: 325.4653s\n",
      "\titers: 500, epoch: 10 | loss: 0.0366748\n",
      "\tspeed: 0.0340s/iter; left time: 322.2732s\n",
      "\titers: 600, epoch: 10 | loss: 0.0407804\n",
      "\tspeed: 0.0340s/iter; left time: 318.5451s\n",
      "\titers: 700, epoch: 10 | loss: 0.0439256\n",
      "\tspeed: 0.0341s/iter; left time: 315.6877s\n",
      "\titers: 800, epoch: 10 | loss: 0.0396320\n",
      "\tspeed: 0.0340s/iter; left time: 311.9610s\n",
      "\titers: 900, epoch: 10 | loss: 0.0464057\n",
      "\tspeed: 0.0341s/iter; left time: 308.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0421371 Vali Loss: 0.0582751 Test Loss: 0.0668456\n",
      "Validation loss decreased (0.059041 --> 0.058275).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0364203\n",
      "\tspeed: 0.0983s/iter; left time: 881.0335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0393139\n",
      "\tspeed: 0.0346s/iter; left time: 306.7814s\n",
      "\titers: 300, epoch: 11 | loss: 0.0412469\n",
      "\tspeed: 0.0347s/iter; left time: 303.6201s\n",
      "\titers: 400, epoch: 11 | loss: 0.0424502\n",
      "\tspeed: 0.0344s/iter; left time: 298.1432s\n",
      "\titers: 500, epoch: 11 | loss: 0.0420882\n",
      "\tspeed: 0.0341s/iter; left time: 291.6435s\n",
      "\titers: 600, epoch: 11 | loss: 0.0404220\n",
      "\tspeed: 0.0340s/iter; left time: 287.9176s\n",
      "\titers: 700, epoch: 11 | loss: 0.0364543\n",
      "\tspeed: 0.0340s/iter; left time: 284.3522s\n",
      "\titers: 800, epoch: 11 | loss: 0.0391739\n",
      "\tspeed: 0.0341s/iter; left time: 281.5530s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418266\n",
      "\tspeed: 0.0341s/iter; left time: 277.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.33s\n",
      "Steps: 906 | Train Loss: 0.0407368 Vali Loss: 0.0578185 Test Loss: 0.0662903\n",
      "Validation loss decreased (0.058275 --> 0.057818).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0390506\n",
      "\tspeed: 0.0988s/iter; left time: 795.8017s\n",
      "\titers: 200, epoch: 12 | loss: 0.0443430\n",
      "\tspeed: 0.0341s/iter; left time: 271.1316s\n",
      "\titers: 300, epoch: 12 | loss: 0.0402047\n",
      "\tspeed: 0.0341s/iter; left time: 267.5208s\n",
      "\titers: 400, epoch: 12 | loss: 0.0388500\n",
      "\tspeed: 0.0341s/iter; left time: 264.2932s\n",
      "\titers: 500, epoch: 12 | loss: 0.0390783\n",
      "\tspeed: 0.0341s/iter; left time: 260.9770s\n",
      "\titers: 600, epoch: 12 | loss: 0.0352140\n",
      "\tspeed: 0.0341s/iter; left time: 257.9070s\n",
      "\titers: 700, epoch: 12 | loss: 0.0395783\n",
      "\tspeed: 0.0341s/iter; left time: 254.4347s\n",
      "\titers: 800, epoch: 12 | loss: 0.0411608\n",
      "\tspeed: 0.0341s/iter; left time: 250.6289s\n",
      "\titers: 900, epoch: 12 | loss: 0.0375333\n",
      "\tspeed: 0.0341s/iter; left time: 247.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0397211 Vali Loss: 0.0578994 Test Loss: 0.0657681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463221\n",
      "\tspeed: 0.0943s/iter; left time: 674.1530s\n",
      "\titers: 200, epoch: 13 | loss: 0.0320999\n",
      "\tspeed: 0.0341s/iter; left time: 240.3496s\n",
      "\titers: 300, epoch: 13 | loss: 0.0338570\n",
      "\tspeed: 0.0340s/iter; left time: 236.4549s\n",
      "\titers: 400, epoch: 13 | loss: 0.0367805\n",
      "\tspeed: 0.0340s/iter; left time: 232.9457s\n",
      "\titers: 500, epoch: 13 | loss: 0.0399524\n",
      "\tspeed: 0.0340s/iter; left time: 229.3342s\n",
      "\titers: 600, epoch: 13 | loss: 0.0407709\n",
      "\tspeed: 0.0340s/iter; left time: 226.0676s\n",
      "\titers: 700, epoch: 13 | loss: 0.0385915\n",
      "\tspeed: 0.0340s/iter; left time: 222.9273s\n",
      "\titers: 800, epoch: 13 | loss: 0.0377566\n",
      "\tspeed: 0.0341s/iter; left time: 219.7198s\n",
      "\titers: 900, epoch: 13 | loss: 0.0359108\n",
      "\tspeed: 0.0341s/iter; left time: 216.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0386944 Vali Loss: 0.0576511 Test Loss: 0.0644637\n",
      "Validation loss decreased (0.057818 --> 0.057651).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0370453\n",
      "\tspeed: 0.0966s/iter; left time: 603.2771s\n",
      "\titers: 200, epoch: 14 | loss: 0.0355818\n",
      "\tspeed: 0.0341s/iter; left time: 209.5007s\n",
      "\titers: 300, epoch: 14 | loss: 0.0373862\n",
      "\tspeed: 0.0341s/iter; left time: 206.0621s\n",
      "\titers: 400, epoch: 14 | loss: 0.0363934\n",
      "\tspeed: 0.0341s/iter; left time: 202.8280s\n",
      "\titers: 500, epoch: 14 | loss: 0.0408763\n",
      "\tspeed: 0.0341s/iter; left time: 199.0434s\n",
      "\titers: 600, epoch: 14 | loss: 0.0316915\n",
      "\tspeed: 0.0341s/iter; left time: 195.7352s\n",
      "\titers: 700, epoch: 14 | loss: 0.0352258\n",
      "\tspeed: 0.0340s/iter; left time: 191.6210s\n",
      "\titers: 800, epoch: 14 | loss: 0.0406870\n",
      "\tspeed: 0.0340s/iter; left time: 188.4585s\n",
      "\titers: 900, epoch: 14 | loss: 0.0330149\n",
      "\tspeed: 0.0341s/iter; left time: 185.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0376825 Vali Loss: 0.0588694 Test Loss: 0.0671663\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0404172\n",
      "\tspeed: 0.0934s/iter; left time: 498.3921s\n",
      "\titers: 200, epoch: 15 | loss: 0.0358362\n",
      "\tspeed: 0.0339s/iter; left time: 177.7817s\n",
      "\titers: 300, epoch: 15 | loss: 0.0366841\n",
      "\tspeed: 0.0340s/iter; left time: 174.6389s\n",
      "\titers: 400, epoch: 15 | loss: 0.0430892\n",
      "\tspeed: 0.0340s/iter; left time: 171.3631s\n",
      "\titers: 500, epoch: 15 | loss: 0.0377812\n",
      "\tspeed: 0.0339s/iter; left time: 167.5859s\n",
      "\titers: 600, epoch: 15 | loss: 0.0361609\n",
      "\tspeed: 0.0340s/iter; left time: 164.3873s\n",
      "\titers: 700, epoch: 15 | loss: 0.0323415\n",
      "\tspeed: 0.0340s/iter; left time: 160.8702s\n",
      "\titers: 800, epoch: 15 | loss: 0.0385448\n",
      "\tspeed: 0.0340s/iter; left time: 157.5110s\n",
      "\titers: 900, epoch: 15 | loss: 0.0349694\n",
      "\tspeed: 0.0340s/iter; left time: 154.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.02s\n",
      "Steps: 906 | Train Loss: 0.0371047 Vali Loss: 0.0579351 Test Loss: 0.0650045\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0371176\n",
      "\tspeed: 0.0933s/iter; left time: 413.5632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0388558\n",
      "\tspeed: 0.0340s/iter; left time: 147.1480s\n",
      "\titers: 300, epoch: 16 | loss: 0.0379867\n",
      "\tspeed: 0.0340s/iter; left time: 143.8585s\n",
      "\titers: 400, epoch: 16 | loss: 0.0419456\n",
      "\tspeed: 0.0340s/iter; left time: 140.3840s\n",
      "\titers: 500, epoch: 16 | loss: 0.0323641\n",
      "\tspeed: 0.0340s/iter; left time: 137.0274s\n",
      "\titers: 600, epoch: 16 | loss: 0.0388941\n",
      "\tspeed: 0.0340s/iter; left time: 133.6431s\n",
      "\titers: 700, epoch: 16 | loss: 0.0388042\n",
      "\tspeed: 0.0340s/iter; left time: 130.1446s\n",
      "\titers: 800, epoch: 16 | loss: 0.0336426\n",
      "\tspeed: 0.0340s/iter; left time: 126.8455s\n",
      "\titers: 900, epoch: 16 | loss: 0.0334118\n",
      "\tspeed: 0.0340s/iter; left time: 123.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0364606 Vali Loss: 0.0591877 Test Loss: 0.0641280\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0336711\n",
      "\tspeed: 0.0932s/iter; left time: 328.4885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0368703\n",
      "\tspeed: 0.0340s/iter; left time: 116.6046s\n",
      "\titers: 300, epoch: 17 | loss: 0.0379302\n",
      "\tspeed: 0.0341s/iter; left time: 113.4628s\n",
      "\titers: 400, epoch: 17 | loss: 0.0395388\n",
      "\tspeed: 0.0340s/iter; left time: 109.7315s\n",
      "\titers: 500, epoch: 17 | loss: 0.0376200\n",
      "\tspeed: 0.0340s/iter; left time: 106.2791s\n",
      "\titers: 600, epoch: 17 | loss: 0.0365006\n",
      "\tspeed: 0.0341s/iter; left time: 103.0427s\n",
      "\titers: 700, epoch: 17 | loss: 0.0371170\n",
      "\tspeed: 0.0341s/iter; left time: 99.6480s\n",
      "\titers: 800, epoch: 17 | loss: 0.0356720\n",
      "\tspeed: 0.0340s/iter; left time: 96.0678s\n",
      "\titers: 900, epoch: 17 | loss: 0.0351860\n",
      "\tspeed: 0.0341s/iter; left time: 92.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0358196 Vali Loss: 0.0584597 Test Loss: 0.0634428\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0369047\n",
      "\tspeed: 0.0937s/iter; left time: 245.2724s\n",
      "\titers: 200, epoch: 18 | loss: 0.0333894\n",
      "\tspeed: 0.0341s/iter; left time: 85.8503s\n",
      "\titers: 300, epoch: 18 | loss: 0.0319502\n",
      "\tspeed: 0.0341s/iter; left time: 82.3783s\n",
      "\titers: 400, epoch: 18 | loss: 0.0355705\n",
      "\tspeed: 0.0341s/iter; left time: 79.0800s\n",
      "\titers: 500, epoch: 18 | loss: 0.0322271\n",
      "\tspeed: 0.0340s/iter; left time: 75.5469s\n",
      "\titers: 600, epoch: 18 | loss: 0.0342900\n",
      "\tspeed: 0.0341s/iter; left time: 72.2025s\n",
      "\titers: 700, epoch: 18 | loss: 0.0366018\n",
      "\tspeed: 0.0341s/iter; left time: 68.7861s\n",
      "\titers: 800, epoch: 18 | loss: 0.0388807\n",
      "\tspeed: 0.0340s/iter; left time: 65.3016s\n",
      "\titers: 900, epoch: 18 | loss: 0.0359373\n",
      "\tspeed: 0.0341s/iter; left time: 62.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0352443 Vali Loss: 0.0587067 Test Loss: 0.0646590\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01250072754919529, rmse:0.11180665343999863, mae:0.06438585370779037, rse:0.4314415752887726\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:35.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1902333\n",
      "\tspeed: 0.0636s/iter; left time: 1142.9379s\n",
      "\titers: 200, epoch: 1 | loss: 0.1634794\n",
      "\tspeed: 0.0419s/iter; left time: 749.2805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1666822\n",
      "\tspeed: 0.0420s/iter; left time: 746.1554s\n",
      "\titers: 400, epoch: 1 | loss: 0.1558330\n",
      "\tspeed: 0.0419s/iter; left time: 741.1753s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509849\n",
      "\tspeed: 0.0420s/iter; left time: 738.1542s\n",
      "\titers: 600, epoch: 1 | loss: 0.1476412\n",
      "\tspeed: 0.0420s/iter; left time: 734.5278s\n",
      "\titers: 700, epoch: 1 | loss: 0.1512190\n",
      "\tspeed: 0.0420s/iter; left time: 730.4839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1417792\n",
      "\tspeed: 0.0420s/iter; left time: 726.5070s\n",
      "\titers: 900, epoch: 1 | loss: 0.1403145\n",
      "\tspeed: 0.0424s/iter; left time: 729.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 904 | Train Loss: 0.1621709 Vali Loss: 0.1583142 Test Loss: 0.1844553\n",
      "Validation loss decreased (inf --> 0.158314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330157\n",
      "\tspeed: 0.1175s/iter; left time: 2006.5724s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246072\n",
      "\tspeed: 0.0420s/iter; left time: 713.5594s\n",
      "\titers: 300, epoch: 2 | loss: 0.1126059\n",
      "\tspeed: 0.0421s/iter; left time: 710.1757s\n",
      "\titers: 400, epoch: 2 | loss: 0.1093363\n",
      "\tspeed: 0.0421s/iter; left time: 705.6017s\n",
      "\titers: 500, epoch: 2 | loss: 0.1034709\n",
      "\tspeed: 0.0421s/iter; left time: 701.4904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1020617\n",
      "\tspeed: 0.0420s/iter; left time: 696.0989s\n",
      "\titers: 700, epoch: 2 | loss: 0.0958327\n",
      "\tspeed: 0.0420s/iter; left time: 692.4386s\n",
      "\titers: 800, epoch: 2 | loss: 0.0837372\n",
      "\tspeed: 0.0418s/iter; left time: 684.7476s\n",
      "\titers: 900, epoch: 2 | loss: 0.0910152\n",
      "\tspeed: 0.0415s/iter; left time: 675.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.1095183 Vali Loss: 0.1063607 Test Loss: 0.1212249\n",
      "Validation loss decreased (0.158314 --> 0.106361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888553\n",
      "\tspeed: 0.1167s/iter; left time: 1886.6447s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888103\n",
      "\tspeed: 0.0421s/iter; left time: 676.2275s\n",
      "\titers: 300, epoch: 3 | loss: 0.0863014\n",
      "\tspeed: 0.0421s/iter; left time: 671.7998s\n",
      "\titers: 400, epoch: 3 | loss: 0.0804213\n",
      "\tspeed: 0.0421s/iter; left time: 667.5718s\n",
      "\titers: 500, epoch: 3 | loss: 0.0833842\n",
      "\tspeed: 0.0421s/iter; left time: 663.2878s\n",
      "\titers: 600, epoch: 3 | loss: 0.0776550\n",
      "\tspeed: 0.0421s/iter; left time: 659.6652s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751079\n",
      "\tspeed: 0.0420s/iter; left time: 654.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0775777\n",
      "\tspeed: 0.0415s/iter; left time: 641.7995s\n",
      "\titers: 900, epoch: 3 | loss: 0.0718875\n",
      "\tspeed: 0.0415s/iter; left time: 637.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 904 | Train Loss: 0.0825873 Vali Loss: 0.0874852 Test Loss: 0.1007140\n",
      "Validation loss decreased (0.106361 --> 0.087485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0644550\n",
      "\tspeed: 0.1176s/iter; left time: 1794.9362s\n",
      "\titers: 200, epoch: 4 | loss: 0.0673058\n",
      "\tspeed: 0.0414s/iter; left time: 628.7548s\n",
      "\titers: 300, epoch: 4 | loss: 0.0663593\n",
      "\tspeed: 0.0414s/iter; left time: 624.2688s\n",
      "\titers: 400, epoch: 4 | loss: 0.0698647\n",
      "\tspeed: 0.0415s/iter; left time: 620.4678s\n",
      "\titers: 500, epoch: 4 | loss: 0.0648271\n",
      "\tspeed: 0.0415s/iter; left time: 616.3495s\n",
      "\titers: 600, epoch: 4 | loss: 0.0635923\n",
      "\tspeed: 0.0414s/iter; left time: 612.1505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0624922\n",
      "\tspeed: 0.0415s/iter; left time: 608.3211s\n",
      "\titers: 800, epoch: 4 | loss: 0.0619351\n",
      "\tspeed: 0.0414s/iter; left time: 603.8803s\n",
      "\titers: 900, epoch: 4 | loss: 0.0630612\n",
      "\tspeed: 0.0415s/iter; left time: 600.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.74s\n",
      "Steps: 904 | Train Loss: 0.0674741 Vali Loss: 0.0844296 Test Loss: 0.0921732\n",
      "Validation loss decreased (0.087485 --> 0.084430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639159\n",
      "\tspeed: 0.1174s/iter; left time: 1686.5920s\n",
      "\titers: 200, epoch: 5 | loss: 0.0614217\n",
      "\tspeed: 0.0416s/iter; left time: 592.8504s\n",
      "\titers: 300, epoch: 5 | loss: 0.0670402\n",
      "\tspeed: 0.0415s/iter; left time: 588.2780s\n",
      "\titers: 400, epoch: 5 | loss: 0.0595234\n",
      "\tspeed: 0.0415s/iter; left time: 583.8364s\n",
      "\titers: 500, epoch: 5 | loss: 0.0611329\n",
      "\tspeed: 0.0415s/iter; left time: 579.7432s\n",
      "\titers: 600, epoch: 5 | loss: 0.0632634\n",
      "\tspeed: 0.0415s/iter; left time: 575.5308s\n",
      "\titers: 700, epoch: 5 | loss: 0.0614533\n",
      "\tspeed: 0.0415s/iter; left time: 571.4856s\n",
      "\titers: 800, epoch: 5 | loss: 0.0643962\n",
      "\tspeed: 0.0415s/iter; left time: 567.3923s\n",
      "\titers: 900, epoch: 5 | loss: 0.0656714\n",
      "\tspeed: 0.0415s/iter; left time: 563.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0626034 Vali Loss: 0.0815981 Test Loss: 0.0909119\n",
      "Validation loss decreased (0.084430 --> 0.081598).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579641\n",
      "\tspeed: 0.1187s/iter; left time: 1598.3911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0595998\n",
      "\tspeed: 0.0415s/iter; left time: 554.7178s\n",
      "\titers: 300, epoch: 6 | loss: 0.0583193\n",
      "\tspeed: 0.0415s/iter; left time: 550.5876s\n",
      "\titers: 400, epoch: 6 | loss: 0.0573336\n",
      "\tspeed: 0.0415s/iter; left time: 546.7790s\n",
      "\titers: 500, epoch: 6 | loss: 0.0537359\n",
      "\tspeed: 0.0416s/iter; left time: 542.7198s\n",
      "\titers: 600, epoch: 6 | loss: 0.0568817\n",
      "\tspeed: 0.0415s/iter; left time: 537.9688s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555145\n",
      "\tspeed: 0.0415s/iter; left time: 533.7798s\n",
      "\titers: 800, epoch: 6 | loss: 0.0552718\n",
      "\tspeed: 0.0415s/iter; left time: 530.2181s\n",
      "\titers: 900, epoch: 6 | loss: 0.0597004\n",
      "\tspeed: 0.0416s/iter; left time: 526.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0590999 Vali Loss: 0.0809355 Test Loss: 0.0917555\n",
      "Validation loss decreased (0.081598 --> 0.080936).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0539223\n",
      "\tspeed: 0.1172s/iter; left time: 1472.2428s\n",
      "\titers: 200, epoch: 7 | loss: 0.0613421\n",
      "\tspeed: 0.0415s/iter; left time: 516.5350s\n",
      "\titers: 300, epoch: 7 | loss: 0.0540870\n",
      "\tspeed: 0.0415s/iter; left time: 512.4116s\n",
      "\titers: 400, epoch: 7 | loss: 0.0517807\n",
      "\tspeed: 0.0415s/iter; left time: 508.2118s\n",
      "\titers: 500, epoch: 7 | loss: 0.0519386\n",
      "\tspeed: 0.0415s/iter; left time: 504.1703s\n",
      "\titers: 600, epoch: 7 | loss: 0.0478697\n",
      "\tspeed: 0.0415s/iter; left time: 500.2220s\n",
      "\titers: 700, epoch: 7 | loss: 0.0569892\n",
      "\tspeed: 0.0415s/iter; left time: 495.9877s\n",
      "\titers: 800, epoch: 7 | loss: 0.0547691\n",
      "\tspeed: 0.0415s/iter; left time: 491.9064s\n",
      "\titers: 900, epoch: 7 | loss: 0.0566718\n",
      "\tspeed: 0.0415s/iter; left time: 487.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0561235 Vali Loss: 0.0818110 Test Loss: 0.0925347\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0545926\n",
      "\tspeed: 0.1134s/iter; left time: 1320.9235s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537039\n",
      "\tspeed: 0.0415s/iter; left time: 479.6749s\n",
      "\titers: 300, epoch: 8 | loss: 0.0538438\n",
      "\tspeed: 0.0420s/iter; left time: 481.5297s\n",
      "\titers: 400, epoch: 8 | loss: 0.0485980\n",
      "\tspeed: 0.0421s/iter; left time: 477.8452s\n",
      "\titers: 500, epoch: 8 | loss: 0.0490118\n",
      "\tspeed: 0.0421s/iter; left time: 473.5320s\n",
      "\titers: 600, epoch: 8 | loss: 0.0507474\n",
      "\tspeed: 0.0421s/iter; left time: 469.4826s\n",
      "\titers: 700, epoch: 8 | loss: 0.0488948\n",
      "\tspeed: 0.0421s/iter; left time: 465.4635s\n",
      "\titers: 800, epoch: 8 | loss: 0.0515667\n",
      "\tspeed: 0.0421s/iter; left time: 461.2118s\n",
      "\titers: 900, epoch: 8 | loss: 0.0471621\n",
      "\tspeed: 0.0421s/iter; left time: 456.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 904 | Train Loss: 0.0534966 Vali Loss: 0.0834365 Test Loss: 0.0937311\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0504029\n",
      "\tspeed: 0.1146s/iter; left time: 1232.1206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0501226\n",
      "\tspeed: 0.0421s/iter; left time: 447.8415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0521222\n",
      "\tspeed: 0.0421s/iter; left time: 443.8949s\n",
      "\titers: 400, epoch: 9 | loss: 0.0458085\n",
      "\tspeed: 0.0421s/iter; left time: 439.7019s\n",
      "\titers: 500, epoch: 9 | loss: 0.0503745\n",
      "\tspeed: 0.0421s/iter; left time: 435.3861s\n",
      "\titers: 600, epoch: 9 | loss: 0.0523974\n",
      "\tspeed: 0.0421s/iter; left time: 431.0932s\n",
      "\titers: 700, epoch: 9 | loss: 0.0510676\n",
      "\tspeed: 0.0421s/iter; left time: 426.9360s\n",
      "\titers: 800, epoch: 9 | loss: 0.0508459\n",
      "\tspeed: 0.0421s/iter; left time: 422.6381s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501447\n",
      "\tspeed: 0.0421s/iter; left time: 418.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0511315 Vali Loss: 0.0806643 Test Loss: 0.0902437\n",
      "Validation loss decreased (0.080936 --> 0.080664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0479229\n",
      "\tspeed: 0.1181s/iter; left time: 1162.5802s\n",
      "\titers: 200, epoch: 10 | loss: 0.0458388\n",
      "\tspeed: 0.0421s/iter; left time: 410.0027s\n",
      "\titers: 300, epoch: 10 | loss: 0.0468625\n",
      "\tspeed: 0.0422s/iter; left time: 406.5477s\n",
      "\titers: 400, epoch: 10 | loss: 0.0468525\n",
      "\tspeed: 0.0421s/iter; left time: 402.3018s\n",
      "\titers: 500, epoch: 10 | loss: 0.0479589\n",
      "\tspeed: 0.0421s/iter; left time: 397.7641s\n",
      "\titers: 600, epoch: 10 | loss: 0.0515600\n",
      "\tspeed: 0.0421s/iter; left time: 393.0768s\n",
      "\titers: 700, epoch: 10 | loss: 0.0529387\n",
      "\tspeed: 0.0421s/iter; left time: 388.9255s\n",
      "\titers: 800, epoch: 10 | loss: 0.0519285\n",
      "\tspeed: 0.0421s/iter; left time: 385.1772s\n",
      "\titers: 900, epoch: 10 | loss: 0.0498877\n",
      "\tspeed: 0.0421s/iter; left time: 380.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0491287 Vali Loss: 0.0825551 Test Loss: 0.0938539\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0456407\n",
      "\tspeed: 0.1147s/iter; left time: 1025.6345s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484030\n",
      "\tspeed: 0.0415s/iter; left time: 367.2298s\n",
      "\titers: 300, epoch: 11 | loss: 0.0500798\n",
      "\tspeed: 0.0415s/iter; left time: 363.0895s\n",
      "\titers: 400, epoch: 11 | loss: 0.0489990\n",
      "\tspeed: 0.0415s/iter; left time: 358.7714s\n",
      "\titers: 500, epoch: 11 | loss: 0.0480193\n",
      "\tspeed: 0.0415s/iter; left time: 354.8332s\n",
      "\titers: 600, epoch: 11 | loss: 0.0455437\n",
      "\tspeed: 0.0415s/iter; left time: 350.5578s\n",
      "\titers: 700, epoch: 11 | loss: 0.0465373\n",
      "\tspeed: 0.0415s/iter; left time: 346.4876s\n",
      "\titers: 800, epoch: 11 | loss: 0.0471579\n",
      "\tspeed: 0.0415s/iter; left time: 342.2289s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470960\n",
      "\tspeed: 0.0415s/iter; left time: 338.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.0474263 Vali Loss: 0.0815087 Test Loss: 0.0885854\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0434840\n",
      "\tspeed: 0.1146s/iter; left time: 920.6887s\n",
      "\titers: 200, epoch: 12 | loss: 0.0445123\n",
      "\tspeed: 0.0420s/iter; left time: 333.5449s\n",
      "\titers: 300, epoch: 12 | loss: 0.0451364\n",
      "\tspeed: 0.0420s/iter; left time: 329.3751s\n",
      "\titers: 400, epoch: 12 | loss: 0.0416487\n",
      "\tspeed: 0.0420s/iter; left time: 325.0469s\n",
      "\titers: 500, epoch: 12 | loss: 0.0491649\n",
      "\tspeed: 0.0420s/iter; left time: 320.6819s\n",
      "\titers: 600, epoch: 12 | loss: 0.0467862\n",
      "\tspeed: 0.0420s/iter; left time: 316.8661s\n",
      "\titers: 700, epoch: 12 | loss: 0.0475624\n",
      "\tspeed: 0.0420s/iter; left time: 312.2396s\n",
      "\titers: 800, epoch: 12 | loss: 0.0455075\n",
      "\tspeed: 0.0420s/iter; left time: 308.3541s\n",
      "\titers: 900, epoch: 12 | loss: 0.0451173\n",
      "\tspeed: 0.0420s/iter; left time: 304.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 904 | Train Loss: 0.0458701 Vali Loss: 0.0813544 Test Loss: 0.0891244\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434529\n",
      "\tspeed: 0.1139s/iter; left time: 812.5212s\n",
      "\titers: 200, epoch: 13 | loss: 0.0425601\n",
      "\tspeed: 0.0414s/iter; left time: 291.4937s\n",
      "\titers: 300, epoch: 13 | loss: 0.0390885\n",
      "\tspeed: 0.0415s/iter; left time: 287.4257s\n",
      "\titers: 400, epoch: 13 | loss: 0.0431902\n",
      "\tspeed: 0.0415s/iter; left time: 283.3661s\n",
      "\titers: 500, epoch: 13 | loss: 0.0442528\n",
      "\tspeed: 0.0415s/iter; left time: 279.1462s\n",
      "\titers: 600, epoch: 13 | loss: 0.0448327\n",
      "\tspeed: 0.0414s/iter; left time: 274.9087s\n",
      "\titers: 700, epoch: 13 | loss: 0.0427357\n",
      "\tspeed: 0.0415s/iter; left time: 270.9401s\n",
      "\titers: 800, epoch: 13 | loss: 0.0454790\n",
      "\tspeed: 0.0415s/iter; left time: 266.7131s\n",
      "\titers: 900, epoch: 13 | loss: 0.0471705\n",
      "\tspeed: 0.0415s/iter; left time: 262.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 904 | Train Loss: 0.0444942 Vali Loss: 0.0826097 Test Loss: 0.0910248\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0420628\n",
      "\tspeed: 0.1133s/iter; left time: 705.8496s\n",
      "\titers: 200, epoch: 14 | loss: 0.0434183\n",
      "\tspeed: 0.0415s/iter; left time: 254.3482s\n",
      "\titers: 300, epoch: 14 | loss: 0.0415930\n",
      "\tspeed: 0.0415s/iter; left time: 250.2050s\n",
      "\titers: 400, epoch: 14 | loss: 0.0413548\n",
      "\tspeed: 0.0415s/iter; left time: 245.9290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0413789\n",
      "\tspeed: 0.0415s/iter; left time: 241.9992s\n",
      "\titers: 600, epoch: 14 | loss: 0.0463429\n",
      "\tspeed: 0.0415s/iter; left time: 237.8058s\n",
      "\titers: 700, epoch: 14 | loss: 0.0457477\n",
      "\tspeed: 0.0415s/iter; left time: 233.6698s\n",
      "\titers: 800, epoch: 14 | loss: 0.0433612\n",
      "\tspeed: 0.0415s/iter; left time: 229.5864s\n",
      "\titers: 900, epoch: 14 | loss: 0.0437617\n",
      "\tspeed: 0.0416s/iter; left time: 225.8041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0433176 Vali Loss: 0.0822506 Test Loss: 0.0912996\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022864822298288345, rmse:0.1512111872434616, mae:0.09028714150190353, rse:0.5849250555038452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1801853\n",
      "\tspeed: 0.0440s/iter; left time: 791.3338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1757706\n",
      "\tspeed: 0.0415s/iter; left time: 742.3598s\n",
      "\titers: 300, epoch: 1 | loss: 0.1683250\n",
      "\tspeed: 0.0416s/iter; left time: 738.8906s\n",
      "\titers: 400, epoch: 1 | loss: 0.1585326\n",
      "\tspeed: 0.0416s/iter; left time: 734.6853s\n",
      "\titers: 500, epoch: 1 | loss: 0.1467624\n",
      "\tspeed: 0.0415s/iter; left time: 730.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1519888\n",
      "\tspeed: 0.0415s/iter; left time: 726.2310s\n",
      "\titers: 700, epoch: 1 | loss: 0.1499733\n",
      "\tspeed: 0.0415s/iter; left time: 722.0790s\n",
      "\titers: 800, epoch: 1 | loss: 0.1427606\n",
      "\tspeed: 0.0416s/iter; left time: 718.2521s\n",
      "\titers: 900, epoch: 1 | loss: 0.1468351\n",
      "\tspeed: 0.0416s/iter; left time: 713.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1637526 Vali Loss: 0.1575865 Test Loss: 0.1835811\n",
      "Validation loss decreased (inf --> 0.157586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303630\n",
      "\tspeed: 0.1164s/iter; left time: 1988.3099s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302949\n",
      "\tspeed: 0.0415s/iter; left time: 705.1301s\n",
      "\titers: 300, epoch: 2 | loss: 0.1157242\n",
      "\tspeed: 0.0415s/iter; left time: 700.7159s\n",
      "\titers: 400, epoch: 2 | loss: 0.1105489\n",
      "\tspeed: 0.0415s/iter; left time: 696.8772s\n",
      "\titers: 500, epoch: 2 | loss: 0.1054600\n",
      "\tspeed: 0.0415s/iter; left time: 692.2461s\n",
      "\titers: 600, epoch: 2 | loss: 0.1001050\n",
      "\tspeed: 0.0415s/iter; left time: 688.4405s\n",
      "\titers: 700, epoch: 2 | loss: 0.1084336\n",
      "\tspeed: 0.0416s/iter; left time: 684.7686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0790982\n",
      "\tspeed: 0.0415s/iter; left time: 680.0364s\n",
      "\titers: 900, epoch: 2 | loss: 0.0886261\n",
      "\tspeed: 0.0415s/iter; left time: 676.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1079180 Vali Loss: 0.1051555 Test Loss: 0.1193966\n",
      "Validation loss decreased (0.157586 --> 0.105156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0876562\n",
      "\tspeed: 0.1174s/iter; left time: 1899.3789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0827423\n",
      "\tspeed: 0.0416s/iter; left time: 668.4151s\n",
      "\titers: 300, epoch: 3 | loss: 0.0847814\n",
      "\tspeed: 0.0420s/iter; left time: 671.6212s\n",
      "\titers: 400, epoch: 3 | loss: 0.0777887\n",
      "\tspeed: 0.0422s/iter; left time: 669.6548s\n",
      "\titers: 500, epoch: 3 | loss: 0.0885318\n",
      "\tspeed: 0.0422s/iter; left time: 665.4361s\n",
      "\titers: 600, epoch: 3 | loss: 0.0824113\n",
      "\tspeed: 0.0422s/iter; left time: 660.7655s\n",
      "\titers: 700, epoch: 3 | loss: 0.0705649\n",
      "\tspeed: 0.0421s/iter; left time: 656.3357s\n",
      "\titers: 800, epoch: 3 | loss: 0.0739427\n",
      "\tspeed: 0.0422s/iter; left time: 652.2881s\n",
      "\titers: 900, epoch: 3 | loss: 0.0669540\n",
      "\tspeed: 0.0422s/iter; left time: 648.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.0807194 Vali Loss: 0.0859751 Test Loss: 0.0970179\n",
      "Validation loss decreased (0.105156 --> 0.085975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0694406\n",
      "\tspeed: 0.1169s/iter; left time: 1785.3883s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649310\n",
      "\tspeed: 0.0421s/iter; left time: 639.1821s\n",
      "\titers: 300, epoch: 4 | loss: 0.0693028\n",
      "\tspeed: 0.0421s/iter; left time: 634.7391s\n",
      "\titers: 400, epoch: 4 | loss: 0.0685778\n",
      "\tspeed: 0.0421s/iter; left time: 630.5093s\n",
      "\titers: 500, epoch: 4 | loss: 0.0600520\n",
      "\tspeed: 0.0421s/iter; left time: 626.5364s\n",
      "\titers: 600, epoch: 4 | loss: 0.0625884\n",
      "\tspeed: 0.0421s/iter; left time: 622.2753s\n",
      "\titers: 700, epoch: 4 | loss: 0.0620745\n",
      "\tspeed: 0.0422s/iter; left time: 618.5591s\n",
      "\titers: 800, epoch: 4 | loss: 0.0639772\n",
      "\tspeed: 0.0421s/iter; left time: 613.7473s\n",
      "\titers: 900, epoch: 4 | loss: 0.0614068\n",
      "\tspeed: 0.0422s/iter; left time: 609.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0670069 Vali Loss: 0.0825358 Test Loss: 0.0950642\n",
      "Validation loss decreased (0.085975 --> 0.082536).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0631184\n",
      "\tspeed: 0.1167s/iter; left time: 1676.0975s\n",
      "\titers: 200, epoch: 5 | loss: 0.0672402\n",
      "\tspeed: 0.0422s/iter; left time: 601.3006s\n",
      "\titers: 300, epoch: 5 | loss: 0.0590044\n",
      "\tspeed: 0.0421s/iter; left time: 596.7791s\n",
      "\titers: 400, epoch: 5 | loss: 0.0598044\n",
      "\tspeed: 0.0421s/iter; left time: 592.5886s\n",
      "\titers: 500, epoch: 5 | loss: 0.0639175\n",
      "\tspeed: 0.0422s/iter; left time: 588.8828s\n",
      "\titers: 600, epoch: 5 | loss: 0.0653268\n",
      "\tspeed: 0.0422s/iter; left time: 584.6260s\n",
      "\titers: 700, epoch: 5 | loss: 0.0598224\n",
      "\tspeed: 0.0422s/iter; left time: 580.9071s\n",
      "\titers: 800, epoch: 5 | loss: 0.0627552\n",
      "\tspeed: 0.0422s/iter; left time: 576.0732s\n",
      "\titers: 900, epoch: 5 | loss: 0.0581154\n",
      "\tspeed: 0.0422s/iter; left time: 572.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 904 | Train Loss: 0.0621152 Vali Loss: 0.0814626 Test Loss: 0.0897293\n",
      "Validation loss decreased (0.082536 --> 0.081463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614372\n",
      "\tspeed: 0.1186s/iter; left time: 1596.5839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612931\n",
      "\tspeed: 0.0422s/iter; left time: 563.4863s\n",
      "\titers: 300, epoch: 6 | loss: 0.0573931\n",
      "\tspeed: 0.0422s/iter; left time: 559.7017s\n",
      "\titers: 400, epoch: 6 | loss: 0.0569089\n",
      "\tspeed: 0.0422s/iter; left time: 555.2582s\n",
      "\titers: 500, epoch: 6 | loss: 0.0555158\n",
      "\tspeed: 0.0422s/iter; left time: 551.2511s\n",
      "\titers: 600, epoch: 6 | loss: 0.0548578\n",
      "\tspeed: 0.0422s/iter; left time: 546.4935s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584947\n",
      "\tspeed: 0.0422s/iter; left time: 542.6575s\n",
      "\titers: 800, epoch: 6 | loss: 0.0564002\n",
      "\tspeed: 0.0422s/iter; left time: 538.6592s\n",
      "\titers: 900, epoch: 6 | loss: 0.0607242\n",
      "\tspeed: 0.0422s/iter; left time: 534.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.0587400 Vali Loss: 0.0810837 Test Loss: 0.0917180\n",
      "Validation loss decreased (0.081463 --> 0.081084).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583565\n",
      "\tspeed: 0.1175s/iter; left time: 1475.7372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0520255\n",
      "\tspeed: 0.0421s/iter; left time: 524.7099s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552256\n",
      "\tspeed: 0.0422s/iter; left time: 521.0978s\n",
      "\titers: 400, epoch: 7 | loss: 0.0547102\n",
      "\tspeed: 0.0422s/iter; left time: 516.6803s\n",
      "\titers: 500, epoch: 7 | loss: 0.0543888\n",
      "\tspeed: 0.0422s/iter; left time: 512.5356s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582229\n",
      "\tspeed: 0.0421s/iter; left time: 507.9209s\n",
      "\titers: 700, epoch: 7 | loss: 0.0542132\n",
      "\tspeed: 0.0421s/iter; left time: 503.5968s\n",
      "\titers: 800, epoch: 7 | loss: 0.0564435\n",
      "\tspeed: 0.0421s/iter; left time: 499.4522s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559337\n",
      "\tspeed: 0.0422s/iter; left time: 495.7002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.0559357 Vali Loss: 0.0815365 Test Loss: 0.0903651\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0521917\n",
      "\tspeed: 0.1150s/iter; left time: 1340.4555s\n",
      "\titers: 200, epoch: 8 | loss: 0.0473949\n",
      "\tspeed: 0.0418s/iter; left time: 483.2140s\n",
      "\titers: 300, epoch: 8 | loss: 0.0566309\n",
      "\tspeed: 0.0415s/iter; left time: 475.8055s\n",
      "\titers: 400, epoch: 8 | loss: 0.0504954\n",
      "\tspeed: 0.0415s/iter; left time: 471.6473s\n",
      "\titers: 500, epoch: 8 | loss: 0.0503554\n",
      "\tspeed: 0.0416s/iter; left time: 467.7012s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523519\n",
      "\tspeed: 0.0417s/iter; left time: 465.5451s\n",
      "\titers: 700, epoch: 8 | loss: 0.0601990\n",
      "\tspeed: 0.0422s/iter; left time: 466.3816s\n",
      "\titers: 800, epoch: 8 | loss: 0.0574024\n",
      "\tspeed: 0.0422s/iter; left time: 462.0786s\n",
      "\titers: 900, epoch: 8 | loss: 0.0504944\n",
      "\tspeed: 0.0422s/iter; left time: 458.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 904 | Train Loss: 0.0534219 Vali Loss: 0.0815038 Test Loss: 0.0924361\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0555919\n",
      "\tspeed: 0.1144s/iter; left time: 1229.5071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0495185\n",
      "\tspeed: 0.0422s/iter; left time: 449.3055s\n",
      "\titers: 300, epoch: 9 | loss: 0.0503814\n",
      "\tspeed: 0.0422s/iter; left time: 444.9955s\n",
      "\titers: 400, epoch: 9 | loss: 0.0510218\n",
      "\tspeed: 0.0422s/iter; left time: 440.9606s\n",
      "\titers: 500, epoch: 9 | loss: 0.0455104\n",
      "\tspeed: 0.0422s/iter; left time: 436.7347s\n",
      "\titers: 600, epoch: 9 | loss: 0.0525810\n",
      "\tspeed: 0.0422s/iter; left time: 432.1226s\n",
      "\titers: 700, epoch: 9 | loss: 0.0497616\n",
      "\tspeed: 0.0422s/iter; left time: 428.2829s\n",
      "\titers: 800, epoch: 9 | loss: 0.0543077\n",
      "\tspeed: 0.0422s/iter; left time: 424.1257s\n",
      "\titers: 900, epoch: 9 | loss: 0.0499346\n",
      "\tspeed: 0.0422s/iter; left time: 419.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 904 | Train Loss: 0.0513986 Vali Loss: 0.0811884 Test Loss: 0.0904090\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0520169\n",
      "\tspeed: 0.1141s/iter; left time: 1123.7260s\n",
      "\titers: 200, epoch: 10 | loss: 0.0472272\n",
      "\tspeed: 0.0421s/iter; left time: 410.3697s\n",
      "\titers: 300, epoch: 10 | loss: 0.0494040\n",
      "\tspeed: 0.0421s/iter; left time: 406.2686s\n",
      "\titers: 400, epoch: 10 | loss: 0.0476900\n",
      "\tspeed: 0.0422s/iter; left time: 402.5648s\n",
      "\titers: 500, epoch: 10 | loss: 0.0437683\n",
      "\tspeed: 0.0422s/iter; left time: 398.5206s\n",
      "\titers: 600, epoch: 10 | loss: 0.0510910\n",
      "\tspeed: 0.0422s/iter; left time: 394.2528s\n",
      "\titers: 700, epoch: 10 | loss: 0.0468750\n",
      "\tspeed: 0.0422s/iter; left time: 389.9539s\n",
      "\titers: 800, epoch: 10 | loss: 0.0480250\n",
      "\tspeed: 0.0421s/iter; left time: 385.1841s\n",
      "\titers: 900, epoch: 10 | loss: 0.0472614\n",
      "\tspeed: 0.0421s/iter; left time: 381.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0495849 Vali Loss: 0.0814730 Test Loss: 0.0901214\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0507243\n",
      "\tspeed: 0.1141s/iter; left time: 1020.6024s\n",
      "\titers: 200, epoch: 11 | loss: 0.0478392\n",
      "\tspeed: 0.0422s/iter; left time: 372.7031s\n",
      "\titers: 300, epoch: 11 | loss: 0.0494696\n",
      "\tspeed: 0.0421s/iter; left time: 367.6222s\n",
      "\titers: 400, epoch: 11 | loss: 0.0495104\n",
      "\tspeed: 0.0416s/iter; left time: 359.1142s\n",
      "\titers: 500, epoch: 11 | loss: 0.0487904\n",
      "\tspeed: 0.0416s/iter; left time: 355.1483s\n",
      "\titers: 600, epoch: 11 | loss: 0.0512776\n",
      "\tspeed: 0.0415s/iter; left time: 350.6539s\n",
      "\titers: 700, epoch: 11 | loss: 0.0480168\n",
      "\tspeed: 0.0416s/iter; left time: 346.8143s\n",
      "\titers: 800, epoch: 11 | loss: 0.0467180\n",
      "\tspeed: 0.0416s/iter; left time: 342.6088s\n",
      "\titers: 900, epoch: 11 | loss: 0.0499095\n",
      "\tspeed: 0.0416s/iter; left time: 338.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.0479882 Vali Loss: 0.0793715 Test Loss: 0.0891887\n",
      "Validation loss decreased (0.081084 --> 0.079371).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468300\n",
      "\tspeed: 0.1166s/iter; left time: 937.1695s\n",
      "\titers: 200, epoch: 12 | loss: 0.0471748\n",
      "\tspeed: 0.0415s/iter; left time: 329.6437s\n",
      "\titers: 300, epoch: 12 | loss: 0.0472506\n",
      "\tspeed: 0.0415s/iter; left time: 325.5373s\n",
      "\titers: 400, epoch: 12 | loss: 0.0449921\n",
      "\tspeed: 0.0415s/iter; left time: 321.2439s\n",
      "\titers: 500, epoch: 12 | loss: 0.0452186\n",
      "\tspeed: 0.0416s/iter; left time: 317.3878s\n",
      "\titers: 600, epoch: 12 | loss: 0.0509672\n",
      "\tspeed: 0.0415s/iter; left time: 313.1249s\n",
      "\titers: 700, epoch: 12 | loss: 0.0462397\n",
      "\tspeed: 0.0416s/iter; left time: 309.5066s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501083\n",
      "\tspeed: 0.0415s/iter; left time: 304.8201s\n",
      "\titers: 900, epoch: 12 | loss: 0.0409865\n",
      "\tspeed: 0.0415s/iter; left time: 300.6787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0465710 Vali Loss: 0.0800179 Test Loss: 0.0904158\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0508476\n",
      "\tspeed: 0.1133s/iter; left time: 808.3958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0427458\n",
      "\tspeed: 0.0415s/iter; left time: 292.0275s\n",
      "\titers: 300, epoch: 13 | loss: 0.0444610\n",
      "\tspeed: 0.0415s/iter; left time: 287.6441s\n",
      "\titers: 400, epoch: 13 | loss: 0.0467233\n",
      "\tspeed: 0.0415s/iter; left time: 283.5360s\n",
      "\titers: 500, epoch: 13 | loss: 0.0473262\n",
      "\tspeed: 0.0415s/iter; left time: 279.3990s\n",
      "\titers: 600, epoch: 13 | loss: 0.0471629\n",
      "\tspeed: 0.0415s/iter; left time: 275.2035s\n",
      "\titers: 700, epoch: 13 | loss: 0.0465323\n",
      "\tspeed: 0.0415s/iter; left time: 271.1061s\n",
      "\titers: 800, epoch: 13 | loss: 0.0462343\n",
      "\tspeed: 0.0415s/iter; left time: 267.0899s\n",
      "\titers: 900, epoch: 13 | loss: 0.0459190\n",
      "\tspeed: 0.0415s/iter; left time: 262.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0452570 Vali Loss: 0.0803579 Test Loss: 0.0906105\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0445291\n",
      "\tspeed: 0.1147s/iter; left time: 714.6974s\n",
      "\titers: 200, epoch: 14 | loss: 0.0431228\n",
      "\tspeed: 0.0416s/iter; left time: 254.9392s\n",
      "\titers: 300, epoch: 14 | loss: 0.0411837\n",
      "\tspeed: 0.0416s/iter; left time: 250.7114s\n",
      "\titers: 400, epoch: 14 | loss: 0.0460565\n",
      "\tspeed: 0.0416s/iter; left time: 246.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0461464\n",
      "\tspeed: 0.0416s/iter; left time: 242.3795s\n",
      "\titers: 600, epoch: 14 | loss: 0.0450274\n",
      "\tspeed: 0.0416s/iter; left time: 238.2954s\n",
      "\titers: 700, epoch: 14 | loss: 0.0455625\n",
      "\tspeed: 0.0416s/iter; left time: 234.2062s\n",
      "\titers: 800, epoch: 14 | loss: 0.0467562\n",
      "\tspeed: 0.0416s/iter; left time: 230.0066s\n",
      "\titers: 900, epoch: 14 | loss: 0.0428233\n",
      "\tspeed: 0.0416s/iter; left time: 225.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0440268 Vali Loss: 0.0806199 Test Loss: 0.0894073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441201\n",
      "\tspeed: 0.1141s/iter; left time: 607.4821s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444535\n",
      "\tspeed: 0.0416s/iter; left time: 217.3685s\n",
      "\titers: 300, epoch: 15 | loss: 0.0421129\n",
      "\tspeed: 0.0416s/iter; left time: 213.2131s\n",
      "\titers: 400, epoch: 15 | loss: 0.0428866\n",
      "\tspeed: 0.0416s/iter; left time: 208.9029s\n",
      "\titers: 500, epoch: 15 | loss: 0.0471378\n",
      "\tspeed: 0.0416s/iter; left time: 204.8338s\n",
      "\titers: 600, epoch: 15 | loss: 0.0420919\n",
      "\tspeed: 0.0415s/iter; left time: 200.3340s\n",
      "\titers: 700, epoch: 15 | loss: 0.0439522\n",
      "\tspeed: 0.0415s/iter; left time: 196.2551s\n",
      "\titers: 800, epoch: 15 | loss: 0.0430104\n",
      "\tspeed: 0.0415s/iter; left time: 192.0512s\n",
      "\titers: 900, epoch: 15 | loss: 0.0440404\n",
      "\tspeed: 0.0415s/iter; left time: 188.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.0429491 Vali Loss: 0.0811198 Test Loss: 0.0907875\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0435821\n",
      "\tspeed: 0.1137s/iter; left time: 502.4845s\n",
      "\titers: 200, epoch: 16 | loss: 0.0400924\n",
      "\tspeed: 0.0415s/iter; left time: 179.4197s\n",
      "\titers: 300, epoch: 16 | loss: 0.0406727\n",
      "\tspeed: 0.0415s/iter; left time: 175.2932s\n",
      "\titers: 400, epoch: 16 | loss: 0.0391660\n",
      "\tspeed: 0.0415s/iter; left time: 171.1423s\n",
      "\titers: 500, epoch: 16 | loss: 0.0432506\n",
      "\tspeed: 0.0415s/iter; left time: 167.0319s\n",
      "\titers: 600, epoch: 16 | loss: 0.0443221\n",
      "\tspeed: 0.0415s/iter; left time: 162.8413s\n",
      "\titers: 700, epoch: 16 | loss: 0.0404722\n",
      "\tspeed: 0.0416s/iter; left time: 158.7643s\n",
      "\titers: 800, epoch: 16 | loss: 0.0418555\n",
      "\tspeed: 0.0415s/iter; left time: 154.5318s\n",
      "\titers: 900, epoch: 16 | loss: 0.0435021\n",
      "\tspeed: 0.0415s/iter; left time: 150.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0420716 Vali Loss: 0.0813945 Test Loss: 0.0900143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022085649892687798, rmse:0.14861240983009338, mae:0.08917967230081558, rse:0.5748723149299622\n",
      "Intermediate time for FR and pred_len 96: 00h:22m:47.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1909381\n",
      "\tspeed: 0.0731s/iter; left time: 1312.3339s\n",
      "\titers: 200, epoch: 1 | loss: 0.1680391\n",
      "\tspeed: 0.0507s/iter; left time: 904.6320s\n",
      "\titers: 300, epoch: 1 | loss: 0.1600669\n",
      "\tspeed: 0.0508s/iter; left time: 900.5058s\n",
      "\titers: 400, epoch: 1 | loss: 0.1592189\n",
      "\tspeed: 0.0508s/iter; left time: 896.9464s\n",
      "\titers: 500, epoch: 1 | loss: 0.1627102\n",
      "\tspeed: 0.0507s/iter; left time: 889.1758s\n",
      "\titers: 600, epoch: 1 | loss: 0.1537818\n",
      "\tspeed: 0.0509s/iter; left time: 887.1121s\n",
      "\titers: 700, epoch: 1 | loss: 0.1487422\n",
      "\tspeed: 0.0509s/iter; left time: 882.5645s\n",
      "\titers: 800, epoch: 1 | loss: 0.1472233\n",
      "\tspeed: 0.0508s/iter; left time: 876.6289s\n",
      "\titers: 900, epoch: 1 | loss: 0.1481563\n",
      "\tspeed: 0.0508s/iter; left time: 871.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1627582 Vali Loss: 0.1600794 Test Loss: 0.1866036\n",
      "Validation loss decreased (inf --> 0.160079).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1354579\n",
      "\tspeed: 0.1418s/iter; left time: 2415.9916s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132466\n",
      "\tspeed: 0.0504s/iter; left time: 852.9638s\n",
      "\titers: 300, epoch: 2 | loss: 0.1104991\n",
      "\tspeed: 0.0503s/iter; left time: 847.4892s\n",
      "\titers: 400, epoch: 2 | loss: 0.1086443\n",
      "\tspeed: 0.0503s/iter; left time: 841.3644s\n",
      "\titers: 500, epoch: 2 | loss: 0.1163496\n",
      "\tspeed: 0.0503s/iter; left time: 837.1216s\n",
      "\titers: 600, epoch: 2 | loss: 0.1089604\n",
      "\tspeed: 0.0504s/iter; left time: 834.3447s\n",
      "\titers: 700, epoch: 2 | loss: 0.1045236\n",
      "\tspeed: 0.0504s/iter; left time: 828.4931s\n",
      "\titers: 800, epoch: 2 | loss: 0.0951248\n",
      "\tspeed: 0.0503s/iter; left time: 821.6065s\n",
      "\titers: 900, epoch: 2 | loss: 0.0957951\n",
      "\tspeed: 0.0503s/iter; left time: 817.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.1135591 Vali Loss: 0.1164185 Test Loss: 0.1333146\n",
      "Validation loss decreased (0.160079 --> 0.116418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982654\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013190\n",
      "\tspeed: 0.0505s/iter; left time: 809.4094s\n",
      "\titers: 300, epoch: 3 | loss: 0.0925633\n",
      "\tspeed: 0.0504s/iter; left time: 803.6832s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857650\n",
      "\tspeed: 0.0504s/iter; left time: 798.1677s\n",
      "\titers: 500, epoch: 3 | loss: 0.0912207\n",
      "\tspeed: 0.0504s/iter; left time: 792.8329s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933190\n",
      "\tspeed: 0.0504s/iter; left time: 787.6501s\n",
      "\titers: 700, epoch: 3 | loss: 0.0857234\n",
      "\tspeed: 0.0504s/iter; left time: 783.2593s\n",
      "\titers: 800, epoch: 3 | loss: 0.0845863\n",
      "\tspeed: 0.0504s/iter; left time: 777.4839s\n",
      "\titers: 900, epoch: 3 | loss: 0.0849761\n",
      "\tspeed: 0.0504s/iter; left time: 772.3460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0924629 Vali Loss: 0.1071270 Test Loss: 0.1229606\n",
      "Validation loss decreased (0.116418 --> 0.107127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786718\n",
      "\tspeed: 0.1427s/iter; left time: 2173.8139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772330\n",
      "\tspeed: 0.0508s/iter; left time: 769.2309s\n",
      "\titers: 300, epoch: 4 | loss: 0.0676827\n",
      "\tspeed: 0.0508s/iter; left time: 764.0135s\n",
      "\titers: 400, epoch: 4 | loss: 0.0790973\n",
      "\tspeed: 0.0508s/iter; left time: 758.7215s\n",
      "\titers: 500, epoch: 4 | loss: 0.0708028\n",
      "\tspeed: 0.0508s/iter; left time: 753.5663s\n",
      "\titers: 600, epoch: 4 | loss: 0.0716025\n",
      "\tspeed: 0.0508s/iter; left time: 748.6905s\n",
      "\titers: 700, epoch: 4 | loss: 0.0682254\n",
      "\tspeed: 0.0509s/iter; left time: 744.3430s\n",
      "\titers: 800, epoch: 4 | loss: 0.0689737\n",
      "\tspeed: 0.0509s/iter; left time: 740.2185s\n",
      "\titers: 900, epoch: 4 | loss: 0.0658434\n",
      "\tspeed: 0.0509s/iter; left time: 735.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 902 | Train Loss: 0.0725442 Vali Loss: 0.0860735 Test Loss: 0.0965769\n",
      "Validation loss decreased (0.107127 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0697073\n",
      "\tspeed: 0.1409s/iter; left time: 2019.6899s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624888\n",
      "\tspeed: 0.0504s/iter; left time: 716.8856s\n",
      "\titers: 300, epoch: 5 | loss: 0.0617630\n",
      "\tspeed: 0.0504s/iter; left time: 711.9624s\n",
      "\titers: 400, epoch: 5 | loss: 0.0649016\n",
      "\tspeed: 0.0504s/iter; left time: 707.4037s\n",
      "\titers: 500, epoch: 5 | loss: 0.0683278\n",
      "\tspeed: 0.0503s/iter; left time: 701.4687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693546\n",
      "\tspeed: 0.0504s/iter; left time: 696.8262s\n",
      "\titers: 700, epoch: 5 | loss: 0.0664765\n",
      "\tspeed: 0.0504s/iter; left time: 691.6092s\n",
      "\titers: 800, epoch: 5 | loss: 0.0678215\n",
      "\tspeed: 0.0504s/iter; left time: 687.0570s\n",
      "\titers: 900, epoch: 5 | loss: 0.0628805\n",
      "\tspeed: 0.0504s/iter; left time: 681.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0666008 Vali Loss: 0.0907133 Test Loss: 0.1022113\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630694\n",
      "\tspeed: 0.1370s/iter; left time: 1839.6319s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735694\n",
      "\tspeed: 0.0509s/iter; left time: 678.4986s\n",
      "\titers: 300, epoch: 6 | loss: 0.0657603\n",
      "\tspeed: 0.0504s/iter; left time: 667.1797s\n",
      "\titers: 400, epoch: 6 | loss: 0.0630703\n",
      "\tspeed: 0.0504s/iter; left time: 662.3338s\n",
      "\titers: 500, epoch: 6 | loss: 0.0608161\n",
      "\tspeed: 0.0505s/iter; left time: 657.7881s\n",
      "\titers: 600, epoch: 6 | loss: 0.0605147\n",
      "\tspeed: 0.0504s/iter; left time: 652.2240s\n",
      "\titers: 700, epoch: 6 | loss: 0.0623604\n",
      "\tspeed: 0.0505s/iter; left time: 647.8566s\n",
      "\titers: 800, epoch: 6 | loss: 0.0683586\n",
      "\tspeed: 0.0504s/iter; left time: 641.5434s\n",
      "\titers: 900, epoch: 6 | loss: 0.0637278\n",
      "\tspeed: 0.0504s/iter; left time: 636.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0630607 Vali Loss: 0.0877217 Test Loss: 0.1008626\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606438\n",
      "\tspeed: 0.1377s/iter; left time: 1725.1466s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599479\n",
      "\tspeed: 0.0508s/iter; left time: 631.3995s\n",
      "\titers: 300, epoch: 7 | loss: 0.0584510\n",
      "\tspeed: 0.0508s/iter; left time: 626.5690s\n",
      "\titers: 400, epoch: 7 | loss: 0.0613597\n",
      "\tspeed: 0.0508s/iter; left time: 621.3450s\n",
      "\titers: 500, epoch: 7 | loss: 0.0601924\n",
      "\tspeed: 0.0508s/iter; left time: 615.9718s\n",
      "\titers: 600, epoch: 7 | loss: 0.0676273\n",
      "\tspeed: 0.0508s/iter; left time: 611.1803s\n",
      "\titers: 700, epoch: 7 | loss: 0.0549083\n",
      "\tspeed: 0.0508s/iter; left time: 606.1187s\n",
      "\titers: 800, epoch: 7 | loss: 0.0545960\n",
      "\tspeed: 0.0508s/iter; left time: 600.9414s\n",
      "\titers: 900, epoch: 7 | loss: 0.0554606\n",
      "\tspeed: 0.0504s/iter; left time: 591.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0600904 Vali Loss: 0.0871552 Test Loss: 0.0970986\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0598685\n",
      "\tspeed: 0.1370s/iter; left time: 1592.5344s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554238\n",
      "\tspeed: 0.0505s/iter; left time: 582.0014s\n",
      "\titers: 300, epoch: 8 | loss: 0.0563658\n",
      "\tspeed: 0.0505s/iter; left time: 576.7205s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521641\n",
      "\tspeed: 0.0504s/iter; left time: 570.6692s\n",
      "\titers: 500, epoch: 8 | loss: 0.0586885\n",
      "\tspeed: 0.0504s/iter; left time: 566.0399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0537777\n",
      "\tspeed: 0.0504s/iter; left time: 560.2831s\n",
      "\titers: 700, epoch: 8 | loss: 0.0583096\n",
      "\tspeed: 0.0505s/iter; left time: 556.6289s\n",
      "\titers: 800, epoch: 8 | loss: 0.0598436\n",
      "\tspeed: 0.0505s/iter; left time: 551.8235s\n",
      "\titers: 900, epoch: 8 | loss: 0.0546309\n",
      "\tspeed: 0.0504s/iter; left time: 546.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0570632 Vali Loss: 0.0868398 Test Loss: 0.0970632\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570800\n",
      "\tspeed: 0.1395s/iter; left time: 1495.6201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0570607\n",
      "\tspeed: 0.0510s/iter; left time: 541.7118s\n",
      "\titers: 300, epoch: 9 | loss: 0.0564059\n",
      "\tspeed: 0.0508s/iter; left time: 534.7881s\n",
      "\titers: 400, epoch: 9 | loss: 0.0511184\n",
      "\tspeed: 0.0508s/iter; left time: 529.3799s\n",
      "\titers: 500, epoch: 9 | loss: 0.0548899\n",
      "\tspeed: 0.0509s/iter; left time: 525.9523s\n",
      "\titers: 600, epoch: 9 | loss: 0.0602870\n",
      "\tspeed: 0.0506s/iter; left time: 517.3814s\n",
      "\titers: 700, epoch: 9 | loss: 0.0530320\n",
      "\tspeed: 0.0504s/iter; left time: 510.6846s\n",
      "\titers: 800, epoch: 9 | loss: 0.0585114\n",
      "\tspeed: 0.0504s/iter; left time: 505.1865s\n",
      "\titers: 900, epoch: 9 | loss: 0.0489683\n",
      "\tspeed: 0.0504s/iter; left time: 499.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0545657 Vali Loss: 0.0866638 Test Loss: 0.0968798\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024343758821487427, rmse:0.15602487325668335, mae:0.09656928479671478, rse:0.6042738556861877\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1787698\n",
      "\tspeed: 0.0528s/iter; left time: 947.9105s\n",
      "\titers: 200, epoch: 1 | loss: 0.1756977\n",
      "\tspeed: 0.0507s/iter; left time: 904.1720s\n",
      "\titers: 300, epoch: 1 | loss: 0.1726988\n",
      "\tspeed: 0.0503s/iter; left time: 892.9432s\n",
      "\titers: 400, epoch: 1 | loss: 0.1645466\n",
      "\tspeed: 0.0504s/iter; left time: 888.6241s\n",
      "\titers: 500, epoch: 1 | loss: 0.1546046\n",
      "\tspeed: 0.0504s/iter; left time: 883.5847s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575418\n",
      "\tspeed: 0.0504s/iter; left time: 878.7539s\n",
      "\titers: 700, epoch: 1 | loss: 0.1498622\n",
      "\tspeed: 0.0503s/iter; left time: 873.0147s\n",
      "\titers: 800, epoch: 1 | loss: 0.1442681\n",
      "\tspeed: 0.0504s/iter; left time: 869.3829s\n",
      "\titers: 900, epoch: 1 | loss: 0.1440777\n",
      "\tspeed: 0.0504s/iter; left time: 863.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.1643646 Vali Loss: 0.1578211 Test Loss: 0.1845102\n",
      "Validation loss decreased (inf --> 0.157821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1305881\n",
      "\tspeed: 0.1433s/iter; left time: 2441.5336s\n",
      "\titers: 200, epoch: 2 | loss: 0.1231588\n",
      "\tspeed: 0.0508s/iter; left time: 860.5270s\n",
      "\titers: 300, epoch: 2 | loss: 0.1234287\n",
      "\tspeed: 0.0509s/iter; left time: 856.2911s\n",
      "\titers: 400, epoch: 2 | loss: 0.1189174\n",
      "\tspeed: 0.0506s/iter; left time: 846.5236s\n",
      "\titers: 500, epoch: 2 | loss: 0.1040148\n",
      "\tspeed: 0.0504s/iter; left time: 838.9250s\n",
      "\titers: 600, epoch: 2 | loss: 0.1109011\n",
      "\tspeed: 0.0505s/iter; left time: 835.5339s\n",
      "\titers: 700, epoch: 2 | loss: 0.0989013\n",
      "\tspeed: 0.0510s/iter; left time: 838.0980s\n",
      "\titers: 800, epoch: 2 | loss: 0.1028772\n",
      "\tspeed: 0.0510s/iter; left time: 832.7449s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027167\n",
      "\tspeed: 0.0509s/iter; left time: 826.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 902 | Train Loss: 0.1155884 Vali Loss: 0.1181208 Test Loss: 0.1364703\n",
      "Validation loss decreased (0.157821 --> 0.118121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007679\n",
      "\tspeed: 0.1420s/iter; left time: 2291.0337s\n",
      "\titers: 200, epoch: 3 | loss: 0.0926124\n",
      "\tspeed: 0.0504s/iter; left time: 808.8751s\n",
      "\titers: 300, epoch: 3 | loss: 0.0921094\n",
      "\tspeed: 0.0504s/iter; left time: 802.8691s\n",
      "\titers: 400, epoch: 3 | loss: 0.0896702\n",
      "\tspeed: 0.0505s/iter; left time: 799.8326s\n",
      "\titers: 500, epoch: 3 | loss: 0.0918375\n",
      "\tspeed: 0.0505s/iter; left time: 794.0894s\n",
      "\titers: 600, epoch: 3 | loss: 0.0904693\n",
      "\tspeed: 0.0505s/iter; left time: 789.4782s\n",
      "\titers: 700, epoch: 3 | loss: 0.0870313\n",
      "\tspeed: 0.0505s/iter; left time: 785.1167s\n",
      "\titers: 800, epoch: 3 | loss: 0.0861187\n",
      "\tspeed: 0.0504s/iter; left time: 778.1310s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808909\n",
      "\tspeed: 0.0504s/iter; left time: 773.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0923859 Vali Loss: 0.0995988 Test Loss: 0.1143600\n",
      "Validation loss decreased (0.118121 --> 0.099599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0715621\n",
      "\tspeed: 0.1421s/iter; left time: 2165.4658s\n",
      "\titers: 200, epoch: 4 | loss: 0.0746090\n",
      "\tspeed: 0.0504s/iter; left time: 763.2307s\n",
      "\titers: 300, epoch: 4 | loss: 0.0718534\n",
      "\tspeed: 0.0505s/iter; left time: 759.2869s\n",
      "\titers: 400, epoch: 4 | loss: 0.0711537\n",
      "\tspeed: 0.0505s/iter; left time: 754.1019s\n",
      "\titers: 500, epoch: 4 | loss: 0.0706193\n",
      "\tspeed: 0.0505s/iter; left time: 749.3533s\n",
      "\titers: 600, epoch: 4 | loss: 0.0673912\n",
      "\tspeed: 0.0509s/iter; left time: 749.8819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0730096\n",
      "\tspeed: 0.0509s/iter; left time: 745.2173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0678658\n",
      "\tspeed: 0.0509s/iter; left time: 739.5509s\n",
      "\titers: 900, epoch: 4 | loss: 0.0666774\n",
      "\tspeed: 0.0504s/iter; left time: 728.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 902 | Train Loss: 0.0718374 Vali Loss: 0.0865255 Test Loss: 0.0977247\n",
      "Validation loss decreased (0.099599 --> 0.086525).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0699938\n",
      "\tspeed: 0.1422s/iter; left time: 2037.8694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737990\n",
      "\tspeed: 0.0509s/iter; left time: 724.3411s\n",
      "\titers: 300, epoch: 5 | loss: 0.0675461\n",
      "\tspeed: 0.0508s/iter; left time: 718.6058s\n",
      "\titers: 400, epoch: 5 | loss: 0.0678671\n",
      "\tspeed: 0.0505s/iter; left time: 709.2199s\n",
      "\titers: 500, epoch: 5 | loss: 0.0709195\n",
      "\tspeed: 0.0504s/iter; left time: 702.5562s\n",
      "\titers: 600, epoch: 5 | loss: 0.0634956\n",
      "\tspeed: 0.0504s/iter; left time: 697.4582s\n",
      "\titers: 700, epoch: 5 | loss: 0.0716952\n",
      "\tspeed: 0.0504s/iter; left time: 692.1110s\n",
      "\titers: 800, epoch: 5 | loss: 0.0626705\n",
      "\tspeed: 0.0504s/iter; left time: 686.9049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0658662\n",
      "\tspeed: 0.0506s/iter; left time: 684.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.0667991 Vali Loss: 0.0870556 Test Loss: 0.0983676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631729\n",
      "\tspeed: 0.1376s/iter; left time: 1847.8868s\n",
      "\titers: 200, epoch: 6 | loss: 0.0667560\n",
      "\tspeed: 0.0504s/iter; left time: 672.2412s\n",
      "\titers: 300, epoch: 6 | loss: 0.0655189\n",
      "\tspeed: 0.0505s/iter; left time: 667.6030s\n",
      "\titers: 400, epoch: 6 | loss: 0.0713132\n",
      "\tspeed: 0.0505s/iter; left time: 663.0947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0651720\n",
      "\tspeed: 0.0505s/iter; left time: 658.5894s\n",
      "\titers: 600, epoch: 6 | loss: 0.0628549\n",
      "\tspeed: 0.0504s/iter; left time: 651.5607s\n",
      "\titers: 700, epoch: 6 | loss: 0.0626928\n",
      "\tspeed: 0.0505s/iter; left time: 647.3282s\n",
      "\titers: 800, epoch: 6 | loss: 0.0640463\n",
      "\tspeed: 0.0504s/iter; left time: 641.8127s\n",
      "\titers: 900, epoch: 6 | loss: 0.0650508\n",
      "\tspeed: 0.0504s/iter; left time: 636.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0635975 Vali Loss: 0.0885732 Test Loss: 0.0982766\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599360\n",
      "\tspeed: 0.1378s/iter; left time: 1725.9544s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667914\n",
      "\tspeed: 0.0504s/iter; left time: 626.5123s\n",
      "\titers: 300, epoch: 7 | loss: 0.0598708\n",
      "\tspeed: 0.0505s/iter; left time: 622.5029s\n",
      "\titers: 400, epoch: 7 | loss: 0.0618586\n",
      "\tspeed: 0.0504s/iter; left time: 616.3025s\n",
      "\titers: 500, epoch: 7 | loss: 0.0605755\n",
      "\tspeed: 0.0505s/iter; left time: 612.4694s\n",
      "\titers: 600, epoch: 7 | loss: 0.0601703\n",
      "\tspeed: 0.0505s/iter; left time: 607.2587s\n",
      "\titers: 700, epoch: 7 | loss: 0.0572209\n",
      "\tspeed: 0.0505s/iter; left time: 602.3009s\n",
      "\titers: 800, epoch: 7 | loss: 0.0604722\n",
      "\tspeed: 0.0505s/iter; left time: 597.2390s\n",
      "\titers: 900, epoch: 7 | loss: 0.0577094\n",
      "\tspeed: 0.0504s/iter; left time: 591.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0607851 Vali Loss: 0.0876664 Test Loss: 0.0979006\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569773\n",
      "\tspeed: 0.1371s/iter; left time: 1593.5984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633521\n",
      "\tspeed: 0.0504s/iter; left time: 580.9436s\n",
      "\titers: 300, epoch: 8 | loss: 0.0593943\n",
      "\tspeed: 0.0504s/iter; left time: 576.3091s\n",
      "\titers: 400, epoch: 8 | loss: 0.0533727\n",
      "\tspeed: 0.0504s/iter; left time: 571.3853s\n",
      "\titers: 500, epoch: 8 | loss: 0.0565611\n",
      "\tspeed: 0.0504s/iter; left time: 566.2452s\n",
      "\titers: 600, epoch: 8 | loss: 0.0577994\n",
      "\tspeed: 0.0504s/iter; left time: 561.2605s\n",
      "\titers: 700, epoch: 8 | loss: 0.0628309\n",
      "\tspeed: 0.0504s/iter; left time: 556.1685s\n",
      "\titers: 800, epoch: 8 | loss: 0.0571598\n",
      "\tspeed: 0.0505s/iter; left time: 551.2688s\n",
      "\titers: 900, epoch: 8 | loss: 0.0570874\n",
      "\tspeed: 0.0504s/iter; left time: 546.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0579347 Vali Loss: 0.0868271 Test Loss: 0.0977674\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0567947\n",
      "\tspeed: 0.1387s/iter; left time: 1487.3222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0572171\n",
      "\tspeed: 0.0505s/iter; left time: 536.7575s\n",
      "\titers: 300, epoch: 9 | loss: 0.0628344\n",
      "\tspeed: 0.0508s/iter; left time: 534.4601s\n",
      "\titers: 400, epoch: 9 | loss: 0.0569898\n",
      "\tspeed: 0.0505s/iter; left time: 526.7027s\n",
      "\titers: 500, epoch: 9 | loss: 0.0498729\n",
      "\tspeed: 0.0504s/iter; left time: 520.5277s\n",
      "\titers: 600, epoch: 9 | loss: 0.0571429\n",
      "\tspeed: 0.0509s/iter; left time: 520.5847s\n",
      "\titers: 700, epoch: 9 | loss: 0.0585564\n",
      "\tspeed: 0.0509s/iter; left time: 515.6574s\n",
      "\titers: 800, epoch: 9 | loss: 0.0577915\n",
      "\tspeed: 0.0504s/iter; left time: 505.6153s\n",
      "\titers: 900, epoch: 9 | loss: 0.0516842\n",
      "\tspeed: 0.0507s/iter; left time: 503.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0556215 Vali Loss: 0.0889604 Test Loss: 0.0997862\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024290841072797775, rmse:0.155855193734169, mae:0.09771759808063507, rse:0.6036167144775391\n",
      "Intermediate time for FR and pred_len 168: 00h:16m:38.56s\n",
      "Intermediate time for FR: 01h:03m:01.02s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2289756\n",
      "\tspeed: 0.0571s/iter; left time: 1028.6264s\n",
      "\titers: 200, epoch: 1 | loss: 0.2147405\n",
      "\tspeed: 0.0344s/iter; left time: 616.8185s\n",
      "\titers: 300, epoch: 1 | loss: 0.2024794\n",
      "\tspeed: 0.0344s/iter; left time: 612.3553s\n",
      "\titers: 400, epoch: 1 | loss: 0.1978398\n",
      "\tspeed: 0.0344s/iter; left time: 608.9401s\n",
      "\titers: 500, epoch: 1 | loss: 0.1838570\n",
      "\tspeed: 0.0344s/iter; left time: 605.7099s\n",
      "\titers: 600, epoch: 1 | loss: 0.1871906\n",
      "\tspeed: 0.0342s/iter; left time: 599.0307s\n",
      "\titers: 700, epoch: 1 | loss: 0.1718587\n",
      "\tspeed: 0.0338s/iter; left time: 589.5431s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741228\n",
      "\tspeed: 0.0338s/iter; left time: 585.1718s\n",
      "\titers: 900, epoch: 1 | loss: 0.1741925\n",
      "\tspeed: 0.0339s/iter; left time: 583.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.1946895 Vali Loss: 0.1531637 Test Loss: 0.1688930\n",
      "Validation loss decreased (inf --> 0.153164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200996\n",
      "\tspeed: 0.0980s/iter; left time: 1676.6751s\n",
      "\titers: 200, epoch: 2 | loss: 0.0943886\n",
      "\tspeed: 0.0344s/iter; left time: 585.0408s\n",
      "\titers: 300, epoch: 2 | loss: 0.0873010\n",
      "\tspeed: 0.0344s/iter; left time: 581.0857s\n",
      "\titers: 400, epoch: 2 | loss: 0.0911078\n",
      "\tspeed: 0.0344s/iter; left time: 577.9463s\n",
      "\titers: 500, epoch: 2 | loss: 0.0900601\n",
      "\tspeed: 0.0344s/iter; left time: 574.3511s\n",
      "\titers: 600, epoch: 2 | loss: 0.0939043\n",
      "\tspeed: 0.0343s/iter; left time: 570.6688s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763428\n",
      "\tspeed: 0.0343s/iter; left time: 566.8765s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738119\n",
      "\tspeed: 0.0343s/iter; left time: 563.4438s\n",
      "\titers: 900, epoch: 2 | loss: 0.0727385\n",
      "\tspeed: 0.0343s/iter; left time: 560.2103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0941843 Vali Loss: 0.0731850 Test Loss: 0.0763463\n",
      "Validation loss decreased (0.153164 --> 0.073185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689264\n",
      "\tspeed: 0.0987s/iter; left time: 1600.0744s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680265\n",
      "\tspeed: 0.0338s/iter; left time: 544.5820s\n",
      "\titers: 300, epoch: 3 | loss: 0.0720875\n",
      "\tspeed: 0.0338s/iter; left time: 541.3244s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637039\n",
      "\tspeed: 0.0338s/iter; left time: 538.2675s\n",
      "\titers: 500, epoch: 3 | loss: 0.0603021\n",
      "\tspeed: 0.0338s/iter; left time: 534.1296s\n",
      "\titers: 600, epoch: 3 | loss: 0.0701781\n",
      "\tspeed: 0.0338s/iter; left time: 531.0419s\n",
      "\titers: 700, epoch: 3 | loss: 0.0690891\n",
      "\tspeed: 0.0338s/iter; left time: 527.4586s\n",
      "\titers: 800, epoch: 3 | loss: 0.0771389\n",
      "\tspeed: 0.0338s/iter; left time: 524.0841s\n",
      "\titers: 900, epoch: 3 | loss: 0.0653842\n",
      "\tspeed: 0.0338s/iter; left time: 520.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.91s\n",
      "Steps: 906 | Train Loss: 0.0697471 Vali Loss: 0.0669245 Test Loss: 0.0713615\n",
      "Validation loss decreased (0.073185 --> 0.066924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727013\n",
      "\tspeed: 0.0986s/iter; left time: 1508.1638s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631000\n",
      "\tspeed: 0.0344s/iter; left time: 522.7673s\n",
      "\titers: 300, epoch: 4 | loss: 0.0641052\n",
      "\tspeed: 0.0344s/iter; left time: 519.2833s\n",
      "\titers: 400, epoch: 4 | loss: 0.0677283\n",
      "\tspeed: 0.0344s/iter; left time: 515.5153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0661093\n",
      "\tspeed: 0.0344s/iter; left time: 512.0733s\n",
      "\titers: 600, epoch: 4 | loss: 0.0596208\n",
      "\tspeed: 0.0344s/iter; left time: 509.0584s\n",
      "\titers: 700, epoch: 4 | loss: 0.0618208\n",
      "\tspeed: 0.0344s/iter; left time: 505.2721s\n",
      "\titers: 800, epoch: 4 | loss: 0.0644566\n",
      "\tspeed: 0.0344s/iter; left time: 501.6529s\n",
      "\titers: 900, epoch: 4 | loss: 0.0667040\n",
      "\tspeed: 0.0344s/iter; left time: 498.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.44s\n",
      "Steps: 906 | Train Loss: 0.0649319 Vali Loss: 0.0651137 Test Loss: 0.0699982\n",
      "Validation loss decreased (0.066924 --> 0.065114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597008\n",
      "\tspeed: 0.1023s/iter; left time: 1472.9348s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717447\n",
      "\tspeed: 0.0344s/iter; left time: 491.7666s\n",
      "\titers: 300, epoch: 5 | loss: 0.0594414\n",
      "\tspeed: 0.0344s/iter; left time: 487.9869s\n",
      "\titers: 400, epoch: 5 | loss: 0.0574381\n",
      "\tspeed: 0.0344s/iter; left time: 484.3206s\n",
      "\titers: 500, epoch: 5 | loss: 0.0629130\n",
      "\tspeed: 0.0344s/iter; left time: 481.3928s\n",
      "\titers: 600, epoch: 5 | loss: 0.0602561\n",
      "\tspeed: 0.0341s/iter; left time: 473.7533s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723139\n",
      "\tspeed: 0.0338s/iter; left time: 466.4928s\n",
      "\titers: 800, epoch: 5 | loss: 0.0493080\n",
      "\tspeed: 0.0339s/iter; left time: 463.7789s\n",
      "\titers: 900, epoch: 5 | loss: 0.0612842\n",
      "\tspeed: 0.0338s/iter; left time: 459.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.0610163 Vali Loss: 0.0614561 Test Loss: 0.0658055\n",
      "Validation loss decreased (0.065114 --> 0.061456).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591033\n",
      "\tspeed: 0.0984s/iter; left time: 1327.4845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583568\n",
      "\tspeed: 0.0345s/iter; left time: 461.3400s\n",
      "\titers: 300, epoch: 6 | loss: 0.0663953\n",
      "\tspeed: 0.0344s/iter; left time: 457.4677s\n",
      "\titers: 400, epoch: 6 | loss: 0.0580835\n",
      "\tspeed: 0.0344s/iter; left time: 454.0186s\n",
      "\titers: 500, epoch: 6 | loss: 0.0495465\n",
      "\tspeed: 0.0344s/iter; left time: 450.4742s\n",
      "\titers: 600, epoch: 6 | loss: 0.0566977\n",
      "\tspeed: 0.0344s/iter; left time: 447.1341s\n",
      "\titers: 700, epoch: 6 | loss: 0.0582300\n",
      "\tspeed: 0.0344s/iter; left time: 443.7517s\n",
      "\titers: 800, epoch: 6 | loss: 0.0565420\n",
      "\tspeed: 0.0344s/iter; left time: 439.5191s\n",
      "\titers: 900, epoch: 6 | loss: 0.0544238\n",
      "\tspeed: 0.0344s/iter; left time: 436.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0582357 Vali Loss: 0.0605395 Test Loss: 0.0657733\n",
      "Validation loss decreased (0.061456 --> 0.060540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0518394\n",
      "\tspeed: 0.0998s/iter; left time: 1255.3815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625482\n",
      "\tspeed: 0.0339s/iter; left time: 423.0757s\n",
      "\titers: 300, epoch: 7 | loss: 0.0538388\n",
      "\tspeed: 0.0339s/iter; left time: 419.8996s\n",
      "\titers: 400, epoch: 7 | loss: 0.0608252\n",
      "\tspeed: 0.0339s/iter; left time: 416.6479s\n",
      "\titers: 500, epoch: 7 | loss: 0.0573636\n",
      "\tspeed: 0.0339s/iter; left time: 412.7597s\n",
      "\titers: 600, epoch: 7 | loss: 0.0511362\n",
      "\tspeed: 0.0339s/iter; left time: 409.0841s\n",
      "\titers: 700, epoch: 7 | loss: 0.0534262\n",
      "\tspeed: 0.0339s/iter; left time: 405.9108s\n",
      "\titers: 800, epoch: 7 | loss: 0.0597523\n",
      "\tspeed: 0.0339s/iter; left time: 402.6076s\n",
      "\titers: 900, epoch: 7 | loss: 0.0498654\n",
      "\tspeed: 0.0339s/iter; left time: 399.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.99s\n",
      "Steps: 906 | Train Loss: 0.0561592 Vali Loss: 0.0586244 Test Loss: 0.0642837\n",
      "Validation loss decreased (0.060540 --> 0.058624).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0509520\n",
      "\tspeed: 0.0982s/iter; left time: 1147.2853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0509359\n",
      "\tspeed: 0.0344s/iter; left time: 398.2165s\n",
      "\titers: 300, epoch: 8 | loss: 0.0527956\n",
      "\tspeed: 0.0344s/iter; left time: 394.5786s\n",
      "\titers: 400, epoch: 8 | loss: 0.0565501\n",
      "\tspeed: 0.0344s/iter; left time: 391.4198s\n",
      "\titers: 500, epoch: 8 | loss: 0.0532382\n",
      "\tspeed: 0.0344s/iter; left time: 387.9617s\n",
      "\titers: 600, epoch: 8 | loss: 0.0565472\n",
      "\tspeed: 0.0344s/iter; left time: 384.0717s\n",
      "\titers: 700, epoch: 8 | loss: 0.0503138\n",
      "\tspeed: 0.0344s/iter; left time: 380.9368s\n",
      "\titers: 800, epoch: 8 | loss: 0.0552599\n",
      "\tspeed: 0.0344s/iter; left time: 377.7964s\n",
      "\titers: 900, epoch: 8 | loss: 0.0519355\n",
      "\tspeed: 0.0344s/iter; left time: 374.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0541787 Vali Loss: 0.0579991 Test Loss: 0.0646259\n",
      "Validation loss decreased (0.058624 --> 0.057999).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463596\n",
      "\tspeed: 0.0994s/iter; left time: 1071.2717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533909\n",
      "\tspeed: 0.0339s/iter; left time: 362.2133s\n",
      "\titers: 300, epoch: 9 | loss: 0.0609420\n",
      "\tspeed: 0.0339s/iter; left time: 357.8963s\n",
      "\titers: 400, epoch: 9 | loss: 0.0476018\n",
      "\tspeed: 0.0338s/iter; left time: 354.5008s\n",
      "\titers: 500, epoch: 9 | loss: 0.0494947\n",
      "\tspeed: 0.0344s/iter; left time: 356.5728s\n",
      "\titers: 600, epoch: 9 | loss: 0.0558363\n",
      "\tspeed: 0.0344s/iter; left time: 353.4206s\n",
      "\titers: 700, epoch: 9 | loss: 0.0526480\n",
      "\tspeed: 0.0344s/iter; left time: 349.5025s\n",
      "\titers: 800, epoch: 9 | loss: 0.0504616\n",
      "\tspeed: 0.0344s/iter; left time: 346.5170s\n",
      "\titers: 900, epoch: 9 | loss: 0.0483640\n",
      "\tspeed: 0.0344s/iter; left time: 342.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 906 | Train Loss: 0.0524793 Vali Loss: 0.0583450 Test Loss: 0.0629489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541091\n",
      "\tspeed: 0.0952s/iter; left time: 939.3233s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536419\n",
      "\tspeed: 0.0344s/iter; left time: 336.0498s\n",
      "\titers: 300, epoch: 10 | loss: 0.0514194\n",
      "\tspeed: 0.0344s/iter; left time: 332.4185s\n",
      "\titers: 400, epoch: 10 | loss: 0.0504203\n",
      "\tspeed: 0.0344s/iter; left time: 328.9377s\n",
      "\titers: 500, epoch: 10 | loss: 0.0432660\n",
      "\tspeed: 0.0344s/iter; left time: 326.0878s\n",
      "\titers: 600, epoch: 10 | loss: 0.0556666\n",
      "\tspeed: 0.0344s/iter; left time: 322.5387s\n",
      "\titers: 700, epoch: 10 | loss: 0.0505122\n",
      "\tspeed: 0.0344s/iter; left time: 318.9934s\n",
      "\titers: 800, epoch: 10 | loss: 0.0518186\n",
      "\tspeed: 0.0344s/iter; left time: 315.5373s\n",
      "\titers: 900, epoch: 10 | loss: 0.0462847\n",
      "\tspeed: 0.0344s/iter; left time: 312.0584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0511121 Vali Loss: 0.0566754 Test Loss: 0.0640028\n",
      "Validation loss decreased (0.057999 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0522779\n",
      "\tspeed: 0.0990s/iter; left time: 886.7043s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463553\n",
      "\tspeed: 0.0339s/iter; left time: 300.1341s\n",
      "\titers: 300, epoch: 11 | loss: 0.0524409\n",
      "\tspeed: 0.0339s/iter; left time: 296.7200s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493511\n",
      "\tspeed: 0.0339s/iter; left time: 293.1921s\n",
      "\titers: 500, epoch: 11 | loss: 0.0535235\n",
      "\tspeed: 0.0339s/iter; left time: 289.8067s\n",
      "\titers: 600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.0339s/iter; left time: 286.5283s\n",
      "\titers: 700, epoch: 11 | loss: 0.0487254\n",
      "\tspeed: 0.0339s/iter; left time: 283.1318s\n",
      "\titers: 800, epoch: 11 | loss: 0.0524150\n",
      "\tspeed: 0.0340s/iter; left time: 280.5251s\n",
      "\titers: 900, epoch: 11 | loss: 0.0441130\n",
      "\tspeed: 0.0344s/iter; left time: 280.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0498137 Vali Loss: 0.0567335 Test Loss: 0.0640843\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454959\n",
      "\tspeed: 0.0955s/iter; left time: 769.3419s\n",
      "\titers: 200, epoch: 12 | loss: 0.0510769\n",
      "\tspeed: 0.0344s/iter; left time: 273.4583s\n",
      "\titers: 300, epoch: 12 | loss: 0.0456563\n",
      "\tspeed: 0.0344s/iter; left time: 270.4168s\n",
      "\titers: 400, epoch: 12 | loss: 0.0503837\n",
      "\tspeed: 0.0344s/iter; left time: 266.6420s\n",
      "\titers: 500, epoch: 12 | loss: 0.0526142\n",
      "\tspeed: 0.0344s/iter; left time: 263.1913s\n",
      "\titers: 600, epoch: 12 | loss: 0.0477144\n",
      "\tspeed: 0.0344s/iter; left time: 259.7137s\n",
      "\titers: 700, epoch: 12 | loss: 0.0439736\n",
      "\tspeed: 0.0344s/iter; left time: 256.6034s\n",
      "\titers: 800, epoch: 12 | loss: 0.0518971\n",
      "\tspeed: 0.0344s/iter; left time: 253.0095s\n",
      "\titers: 900, epoch: 12 | loss: 0.0473772\n",
      "\tspeed: 0.0339s/iter; left time: 246.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0486576 Vali Loss: 0.0559295 Test Loss: 0.0642169\n",
      "Validation loss decreased (0.056675 --> 0.055930).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0414750\n",
      "\tspeed: 0.0990s/iter; left time: 707.4082s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494478\n",
      "\tspeed: 0.0344s/iter; left time: 242.4017s\n",
      "\titers: 300, epoch: 13 | loss: 0.0469200\n",
      "\tspeed: 0.0344s/iter; left time: 239.2543s\n",
      "\titers: 400, epoch: 13 | loss: 0.0549754\n",
      "\tspeed: 0.0344s/iter; left time: 235.6954s\n",
      "\titers: 500, epoch: 13 | loss: 0.0429797\n",
      "\tspeed: 0.0344s/iter; left time: 232.2055s\n",
      "\titers: 600, epoch: 13 | loss: 0.0493610\n",
      "\tspeed: 0.0344s/iter; left time: 228.8044s\n",
      "\titers: 700, epoch: 13 | loss: 0.0470018\n",
      "\tspeed: 0.0344s/iter; left time: 225.2410s\n",
      "\titers: 800, epoch: 13 | loss: 0.0505446\n",
      "\tspeed: 0.0344s/iter; left time: 222.0993s\n",
      "\titers: 900, epoch: 13 | loss: 0.0527018\n",
      "\tspeed: 0.0344s/iter; left time: 218.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.48s\n",
      "Steps: 906 | Train Loss: 0.0474767 Vali Loss: 0.0565293 Test Loss: 0.0645984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0478024\n",
      "\tspeed: 0.0952s/iter; left time: 594.1187s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465574\n",
      "\tspeed: 0.0345s/iter; left time: 211.7217s\n",
      "\titers: 300, epoch: 14 | loss: 0.0409424\n",
      "\tspeed: 0.0344s/iter; left time: 208.0992s\n",
      "\titers: 400, epoch: 14 | loss: 0.0393596\n",
      "\tspeed: 0.0344s/iter; left time: 204.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0479720\n",
      "\tspeed: 0.0344s/iter; left time: 200.9919s\n",
      "\titers: 600, epoch: 14 | loss: 0.0455824\n",
      "\tspeed: 0.0344s/iter; left time: 197.4515s\n",
      "\titers: 700, epoch: 14 | loss: 0.0412655\n",
      "\tspeed: 0.0340s/iter; left time: 191.9091s\n",
      "\titers: 800, epoch: 14 | loss: 0.0518019\n",
      "\tspeed: 0.0339s/iter; left time: 187.7954s\n",
      "\titers: 900, epoch: 14 | loss: 0.0401611\n",
      "\tspeed: 0.0342s/iter; left time: 186.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.0464986 Vali Loss: 0.0564530 Test Loss: 0.0648331\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453141\n",
      "\tspeed: 0.0946s/iter; left time: 504.9078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0427157\n",
      "\tspeed: 0.0339s/iter; left time: 177.6196s\n",
      "\titers: 300, epoch: 15 | loss: 0.0424050\n",
      "\tspeed: 0.0339s/iter; left time: 174.0996s\n",
      "\titers: 400, epoch: 15 | loss: 0.0450250\n",
      "\tspeed: 0.0340s/iter; left time: 171.1165s\n",
      "\titers: 500, epoch: 15 | loss: 0.0498884\n",
      "\tspeed: 0.0339s/iter; left time: 167.4988s\n",
      "\titers: 600, epoch: 15 | loss: 0.0426898\n",
      "\tspeed: 0.0339s/iter; left time: 163.9400s\n",
      "\titers: 700, epoch: 15 | loss: 0.0478519\n",
      "\tspeed: 0.0339s/iter; left time: 160.6394s\n",
      "\titers: 800, epoch: 15 | loss: 0.0399454\n",
      "\tspeed: 0.0339s/iter; left time: 157.2868s\n",
      "\titers: 900, epoch: 15 | loss: 0.0482494\n",
      "\tspeed: 0.0339s/iter; left time: 153.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0455909 Vali Loss: 0.0574777 Test Loss: 0.0649152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0477243\n",
      "\tspeed: 0.0966s/iter; left time: 428.0084s\n",
      "\titers: 200, epoch: 16 | loss: 0.0499466\n",
      "\tspeed: 0.0344s/iter; left time: 149.0762s\n",
      "\titers: 300, epoch: 16 | loss: 0.0453695\n",
      "\tspeed: 0.0344s/iter; left time: 145.5417s\n",
      "\titers: 400, epoch: 16 | loss: 0.0438813\n",
      "\tspeed: 0.0344s/iter; left time: 142.2158s\n",
      "\titers: 500, epoch: 16 | loss: 0.0471978\n",
      "\tspeed: 0.0344s/iter; left time: 138.8512s\n",
      "\titers: 600, epoch: 16 | loss: 0.0432691\n",
      "\tspeed: 0.0344s/iter; left time: 135.0316s\n",
      "\titers: 700, epoch: 16 | loss: 0.0403846\n",
      "\tspeed: 0.0344s/iter; left time: 131.8651s\n",
      "\titers: 800, epoch: 16 | loss: 0.0475129\n",
      "\tspeed: 0.0344s/iter; left time: 128.3959s\n",
      "\titers: 900, epoch: 16 | loss: 0.0473321\n",
      "\tspeed: 0.0344s/iter; left time: 125.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0446047 Vali Loss: 0.0561414 Test Loss: 0.0642355\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387600\n",
      "\tspeed: 0.0965s/iter; left time: 340.1043s\n",
      "\titers: 200, epoch: 17 | loss: 0.0365247\n",
      "\tspeed: 0.0344s/iter; left time: 117.9369s\n",
      "\titers: 300, epoch: 17 | loss: 0.0416560\n",
      "\tspeed: 0.0344s/iter; left time: 114.4035s\n",
      "\titers: 400, epoch: 17 | loss: 0.0426961\n",
      "\tspeed: 0.0344s/iter; left time: 110.9422s\n",
      "\titers: 500, epoch: 17 | loss: 0.0431453\n",
      "\tspeed: 0.0344s/iter; left time: 107.5261s\n",
      "\titers: 600, epoch: 17 | loss: 0.0430919\n",
      "\tspeed: 0.0344s/iter; left time: 104.1321s\n",
      "\titers: 700, epoch: 17 | loss: 0.0497445\n",
      "\tspeed: 0.0344s/iter; left time: 100.7481s\n",
      "\titers: 800, epoch: 17 | loss: 0.0412744\n",
      "\tspeed: 0.0344s/iter; left time: 97.1845s\n",
      "\titers: 900, epoch: 17 | loss: 0.0451680\n",
      "\tspeed: 0.0344s/iter; left time: 93.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0439459 Vali Loss: 0.0560204 Test Loss: 0.0647921\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01203176286071539, rmse:0.1096893921494484, mae:0.06421584635972977, rse:0.4145238697528839\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2498116\n",
      "\tspeed: 0.0370s/iter; left time: 666.5389s\n",
      "\titers: 200, epoch: 1 | loss: 0.2011735\n",
      "\tspeed: 0.0340s/iter; left time: 608.7283s\n",
      "\titers: 300, epoch: 1 | loss: 0.2150934\n",
      "\tspeed: 0.0338s/iter; left time: 602.7235s\n",
      "\titers: 400, epoch: 1 | loss: 0.1960537\n",
      "\tspeed: 0.0339s/iter; left time: 600.7765s\n",
      "\titers: 500, epoch: 1 | loss: 0.1826794\n",
      "\tspeed: 0.0342s/iter; left time: 603.0035s\n",
      "\titers: 600, epoch: 1 | loss: 0.1927706\n",
      "\tspeed: 0.0340s/iter; left time: 595.9660s\n",
      "\titers: 700, epoch: 1 | loss: 0.1779167\n",
      "\tspeed: 0.0344s/iter; left time: 599.7866s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746279\n",
      "\tspeed: 0.0344s/iter; left time: 595.2989s\n",
      "\titers: 900, epoch: 1 | loss: 0.1654574\n",
      "\tspeed: 0.0341s/iter; left time: 587.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.1992125 Vali Loss: 0.1432941 Test Loss: 0.1544233\n",
      "Validation loss decreased (inf --> 0.143294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1207117\n",
      "\tspeed: 0.0978s/iter; left time: 1673.5689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950160\n",
      "\tspeed: 0.0344s/iter; left time: 585.2503s\n",
      "\titers: 300, epoch: 2 | loss: 0.1002817\n",
      "\tspeed: 0.0344s/iter; left time: 581.7880s\n",
      "\titers: 400, epoch: 2 | loss: 0.0960616\n",
      "\tspeed: 0.0344s/iter; left time: 578.6741s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890009\n",
      "\tspeed: 0.0344s/iter; left time: 575.1517s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752527\n",
      "\tspeed: 0.0344s/iter; left time: 571.0349s\n",
      "\titers: 700, epoch: 2 | loss: 0.0765394\n",
      "\tspeed: 0.0344s/iter; left time: 567.7912s\n",
      "\titers: 800, epoch: 2 | loss: 0.0737386\n",
      "\tspeed: 0.0345s/iter; left time: 565.7726s\n",
      "\titers: 900, epoch: 2 | loss: 0.0719303\n",
      "\tspeed: 0.0344s/iter; left time: 561.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0930362 Vali Loss: 0.0793414 Test Loss: 0.0821712\n",
      "Validation loss decreased (0.143294 --> 0.079341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749184\n",
      "\tspeed: 0.0985s/iter; left time: 1596.5709s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750817\n",
      "\tspeed: 0.0354s/iter; left time: 570.6225s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689839\n",
      "\tspeed: 0.0354s/iter; left time: 567.1619s\n",
      "\titers: 400, epoch: 3 | loss: 0.0704358\n",
      "\tspeed: 0.0353s/iter; left time: 562.2200s\n",
      "\titers: 500, epoch: 3 | loss: 0.0624443\n",
      "\tspeed: 0.0347s/iter; left time: 548.4937s\n",
      "\titers: 600, epoch: 3 | loss: 0.0694029\n",
      "\tspeed: 0.0347s/iter; left time: 544.7530s\n",
      "\titers: 700, epoch: 3 | loss: 0.0815309\n",
      "\tspeed: 0.0347s/iter; left time: 541.4119s\n",
      "\titers: 800, epoch: 3 | loss: 0.0664670\n",
      "\tspeed: 0.0347s/iter; left time: 537.6137s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646821\n",
      "\tspeed: 0.0347s/iter; left time: 534.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.02s\n",
      "Steps: 906 | Train Loss: 0.0724885 Vali Loss: 0.0685023 Test Loss: 0.0725131\n",
      "Validation loss decreased (0.079341 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744193\n",
      "\tspeed: 0.0981s/iter; left time: 1501.0904s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712759\n",
      "\tspeed: 0.0347s/iter; left time: 527.5156s\n",
      "\titers: 300, epoch: 4 | loss: 0.0668154\n",
      "\tspeed: 0.0346s/iter; left time: 523.0114s\n",
      "\titers: 400, epoch: 4 | loss: 0.0690735\n",
      "\tspeed: 0.0347s/iter; left time: 520.1602s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684960\n",
      "\tspeed: 0.0347s/iter; left time: 517.1179s\n",
      "\titers: 600, epoch: 4 | loss: 0.0681758\n",
      "\tspeed: 0.0347s/iter; left time: 513.0677s\n",
      "\titers: 700, epoch: 4 | loss: 0.0672854\n",
      "\tspeed: 0.0347s/iter; left time: 509.7975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0688433\n",
      "\tspeed: 0.0347s/iter; left time: 506.9368s\n",
      "\titers: 900, epoch: 4 | loss: 0.0717380\n",
      "\tspeed: 0.0347s/iter; left time: 503.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.71s\n",
      "Steps: 906 | Train Loss: 0.0678150 Vali Loss: 0.0665552 Test Loss: 0.0727431\n",
      "Validation loss decreased (0.068502 --> 0.066555).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659932\n",
      "\tspeed: 0.0981s/iter; left time: 1412.5186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691543\n",
      "\tspeed: 0.0349s/iter; left time: 498.3155s\n",
      "\titers: 300, epoch: 5 | loss: 0.0622396\n",
      "\tspeed: 0.0347s/iter; left time: 492.6222s\n",
      "\titers: 400, epoch: 5 | loss: 0.0609198\n",
      "\tspeed: 0.0347s/iter; left time: 488.8965s\n",
      "\titers: 500, epoch: 5 | loss: 0.0666150\n",
      "\tspeed: 0.0347s/iter; left time: 485.7598s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587350\n",
      "\tspeed: 0.0347s/iter; left time: 482.1804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0578601\n",
      "\tspeed: 0.0348s/iter; left time: 480.5091s\n",
      "\titers: 800, epoch: 5 | loss: 0.0598911\n",
      "\tspeed: 0.0347s/iter; left time: 475.9499s\n",
      "\titers: 900, epoch: 5 | loss: 0.0647039\n",
      "\tspeed: 0.0350s/iter; left time: 476.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0635315 Vali Loss: 0.0618177 Test Loss: 0.0684821\n",
      "Validation loss decreased (0.066555 --> 0.061818).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551207\n",
      "\tspeed: 0.0990s/iter; left time: 1335.9846s\n",
      "\titers: 200, epoch: 6 | loss: 0.0664826\n",
      "\tspeed: 0.0354s/iter; left time: 473.8274s\n",
      "\titers: 300, epoch: 6 | loss: 0.0643861\n",
      "\tspeed: 0.0349s/iter; left time: 464.2556s\n",
      "\titers: 400, epoch: 6 | loss: 0.0645496\n",
      "\tspeed: 0.0348s/iter; left time: 459.4172s\n",
      "\titers: 500, epoch: 6 | loss: 0.0522045\n",
      "\tspeed: 0.0348s/iter; left time: 456.0432s\n",
      "\titers: 600, epoch: 6 | loss: 0.0588533\n",
      "\tspeed: 0.0348s/iter; left time: 452.3222s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584210\n",
      "\tspeed: 0.0349s/iter; left time: 449.8974s\n",
      "\titers: 800, epoch: 6 | loss: 0.0518436\n",
      "\tspeed: 0.0348s/iter; left time: 445.5703s\n",
      "\titers: 900, epoch: 6 | loss: 0.0592274\n",
      "\tspeed: 0.0348s/iter; left time: 441.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.00s\n",
      "Steps: 906 | Train Loss: 0.0598389 Vali Loss: 0.0608522 Test Loss: 0.0686492\n",
      "Validation loss decreased (0.061818 --> 0.060852).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570249\n",
      "\tspeed: 0.1002s/iter; left time: 1261.3629s\n",
      "\titers: 200, epoch: 7 | loss: 0.0546420\n",
      "\tspeed: 0.0348s/iter; left time: 434.3797s\n",
      "\titers: 300, epoch: 7 | loss: 0.0586133\n",
      "\tspeed: 0.0348s/iter; left time: 431.3394s\n",
      "\titers: 400, epoch: 7 | loss: 0.0534843\n",
      "\tspeed: 0.0347s/iter; left time: 426.7654s\n",
      "\titers: 500, epoch: 7 | loss: 0.0500044\n",
      "\tspeed: 0.0347s/iter; left time: 422.9477s\n",
      "\titers: 600, epoch: 7 | loss: 0.0479839\n",
      "\tspeed: 0.0348s/iter; left time: 420.8973s\n",
      "\titers: 700, epoch: 7 | loss: 0.0544220\n",
      "\tspeed: 0.0348s/iter; left time: 417.2883s\n",
      "\titers: 800, epoch: 7 | loss: 0.0504415\n",
      "\tspeed: 0.0348s/iter; left time: 413.2339s\n",
      "\titers: 900, epoch: 7 | loss: 0.0664917\n",
      "\tspeed: 0.0347s/iter; left time: 409.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.82s\n",
      "Steps: 906 | Train Loss: 0.0572039 Vali Loss: 0.0600482 Test Loss: 0.0666491\n",
      "Validation loss decreased (0.060852 --> 0.060048).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569239\n",
      "\tspeed: 0.0975s/iter; left time: 1139.1124s\n",
      "\titers: 200, epoch: 8 | loss: 0.0524420\n",
      "\tspeed: 0.0347s/iter; left time: 402.1669s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549767\n",
      "\tspeed: 0.0347s/iter; left time: 398.7406s\n",
      "\titers: 400, epoch: 8 | loss: 0.0569074\n",
      "\tspeed: 0.0347s/iter; left time: 394.5755s\n",
      "\titers: 500, epoch: 8 | loss: 0.0560224\n",
      "\tspeed: 0.0347s/iter; left time: 391.2381s\n",
      "\titers: 600, epoch: 8 | loss: 0.0586272\n",
      "\tspeed: 0.0347s/iter; left time: 387.4443s\n",
      "\titers: 700, epoch: 8 | loss: 0.0534134\n",
      "\tspeed: 0.0347s/iter; left time: 384.2815s\n",
      "\titers: 800, epoch: 8 | loss: 0.0507184\n",
      "\tspeed: 0.0347s/iter; left time: 381.3517s\n",
      "\titers: 900, epoch: 8 | loss: 0.0588685\n",
      "\tspeed: 0.0347s/iter; left time: 377.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0554143 Vali Loss: 0.0588686 Test Loss: 0.0643074\n",
      "Validation loss decreased (0.060048 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554289\n",
      "\tspeed: 0.0976s/iter; left time: 1051.5838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0491354\n",
      "\tspeed: 0.0348s/iter; left time: 371.0447s\n",
      "\titers: 300, epoch: 9 | loss: 0.0533709\n",
      "\tspeed: 0.0346s/iter; left time: 366.2234s\n",
      "\titers: 400, epoch: 9 | loss: 0.0478047\n",
      "\tspeed: 0.0346s/iter; left time: 362.6454s\n",
      "\titers: 500, epoch: 9 | loss: 0.0562404\n",
      "\tspeed: 0.0347s/iter; left time: 359.5503s\n",
      "\titers: 600, epoch: 9 | loss: 0.0546994\n",
      "\tspeed: 0.0347s/iter; left time: 356.9094s\n",
      "\titers: 700, epoch: 9 | loss: 0.0573833\n",
      "\tspeed: 0.0347s/iter; left time: 352.8255s\n",
      "\titers: 800, epoch: 9 | loss: 0.0525519\n",
      "\tspeed: 0.0347s/iter; left time: 349.5498s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501279\n",
      "\tspeed: 0.0347s/iter; left time: 346.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.75s\n",
      "Steps: 906 | Train Loss: 0.0537802 Vali Loss: 0.0572465 Test Loss: 0.0636292\n",
      "Validation loss decreased (0.058869 --> 0.057246).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570313\n",
      "\tspeed: 0.0972s/iter; left time: 959.5169s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489191\n",
      "\tspeed: 0.0346s/iter; left time: 337.5840s\n",
      "\titers: 300, epoch: 10 | loss: 0.0466328\n",
      "\tspeed: 0.0347s/iter; left time: 335.0048s\n",
      "\titers: 400, epoch: 10 | loss: 0.0506991\n",
      "\tspeed: 0.0345s/iter; left time: 330.5165s\n",
      "\titers: 500, epoch: 10 | loss: 0.0551326\n",
      "\tspeed: 0.0346s/iter; left time: 327.4180s\n",
      "\titers: 600, epoch: 10 | loss: 0.0489854\n",
      "\tspeed: 0.0347s/iter; left time: 324.7745s\n",
      "\titers: 700, epoch: 10 | loss: 0.0582220\n",
      "\tspeed: 0.0346s/iter; left time: 320.6847s\n",
      "\titers: 800, epoch: 10 | loss: 0.0630818\n",
      "\tspeed: 0.0346s/iter; left time: 317.2015s\n",
      "\titers: 900, epoch: 10 | loss: 0.0590224\n",
      "\tspeed: 0.0347s/iter; left time: 314.2078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.64s\n",
      "Steps: 906 | Train Loss: 0.0524546 Vali Loss: 0.0584495 Test Loss: 0.0668093\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541355\n",
      "\tspeed: 0.0950s/iter; left time: 850.9173s\n",
      "\titers: 200, epoch: 11 | loss: 0.0514751\n",
      "\tspeed: 0.0347s/iter; left time: 307.1480s\n",
      "\titers: 300, epoch: 11 | loss: 0.0508684\n",
      "\tspeed: 0.0347s/iter; left time: 304.1859s\n",
      "\titers: 400, epoch: 11 | loss: 0.0488365\n",
      "\tspeed: 0.0347s/iter; left time: 300.4539s\n",
      "\titers: 500, epoch: 11 | loss: 0.0411242\n",
      "\tspeed: 0.0347s/iter; left time: 297.1902s\n",
      "\titers: 600, epoch: 11 | loss: 0.0533406\n",
      "\tspeed: 0.0347s/iter; left time: 293.6787s\n",
      "\titers: 700, epoch: 11 | loss: 0.0518379\n",
      "\tspeed: 0.0346s/iter; left time: 288.9753s\n",
      "\titers: 800, epoch: 11 | loss: 0.0526628\n",
      "\tspeed: 0.0346s/iter; left time: 285.9920s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498659\n",
      "\tspeed: 0.0346s/iter; left time: 282.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0511982 Vali Loss: 0.0571466 Test Loss: 0.0659549\n",
      "Validation loss decreased (0.057246 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0479833\n",
      "\tspeed: 0.0978s/iter; left time: 787.9345s\n",
      "\titers: 200, epoch: 12 | loss: 0.0515542\n",
      "\tspeed: 0.0347s/iter; left time: 276.0988s\n",
      "\titers: 300, epoch: 12 | loss: 0.0507848\n",
      "\tspeed: 0.0347s/iter; left time: 272.2591s\n",
      "\titers: 400, epoch: 12 | loss: 0.0510435\n",
      "\tspeed: 0.0347s/iter; left time: 268.7503s\n",
      "\titers: 500, epoch: 12 | loss: 0.0462130\n",
      "\tspeed: 0.0347s/iter; left time: 265.9512s\n",
      "\titers: 600, epoch: 12 | loss: 0.0533448\n",
      "\tspeed: 0.0347s/iter; left time: 262.1570s\n",
      "\titers: 700, epoch: 12 | loss: 0.0432821\n",
      "\tspeed: 0.0346s/iter; left time: 258.2145s\n",
      "\titers: 800, epoch: 12 | loss: 0.0530810\n",
      "\tspeed: 0.0347s/iter; left time: 255.3143s\n",
      "\titers: 900, epoch: 12 | loss: 0.0456739\n",
      "\tspeed: 0.0347s/iter; left time: 251.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.72s\n",
      "Steps: 906 | Train Loss: 0.0497971 Vali Loss: 0.0571572 Test Loss: 0.0657481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0520588\n",
      "\tspeed: 0.0957s/iter; left time: 683.8958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0471978\n",
      "\tspeed: 0.0353s/iter; left time: 248.8270s\n",
      "\titers: 300, epoch: 13 | loss: 0.0492734\n",
      "\tspeed: 0.0347s/iter; left time: 240.9171s\n",
      "\titers: 400, epoch: 13 | loss: 0.0487693\n",
      "\tspeed: 0.0347s/iter; left time: 237.8179s\n",
      "\titers: 500, epoch: 13 | loss: 0.0490274\n",
      "\tspeed: 0.0350s/iter; left time: 235.9805s\n",
      "\titers: 600, epoch: 13 | loss: 0.0444182\n",
      "\tspeed: 0.0345s/iter; left time: 229.6636s\n",
      "\titers: 700, epoch: 13 | loss: 0.0454526\n",
      "\tspeed: 0.0347s/iter; left time: 227.3076s\n",
      "\titers: 800, epoch: 13 | loss: 0.0502009\n",
      "\tspeed: 0.0347s/iter; left time: 224.0524s\n",
      "\titers: 900, epoch: 13 | loss: 0.0519659\n",
      "\tspeed: 0.0347s/iter; left time: 220.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0487688 Vali Loss: 0.0568870 Test Loss: 0.0654286\n",
      "Validation loss decreased (0.057147 --> 0.056887).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0472592\n",
      "\tspeed: 0.0989s/iter; left time: 617.6909s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461481\n",
      "\tspeed: 0.0346s/iter; left time: 212.8299s\n",
      "\titers: 300, epoch: 14 | loss: 0.0439564\n",
      "\tspeed: 0.0347s/iter; left time: 209.6598s\n",
      "\titers: 400, epoch: 14 | loss: 0.0481552\n",
      "\tspeed: 0.0346s/iter; left time: 205.6444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0552839\n",
      "\tspeed: 0.0346s/iter; left time: 202.3369s\n",
      "\titers: 600, epoch: 14 | loss: 0.0544599\n",
      "\tspeed: 0.0346s/iter; left time: 198.9589s\n",
      "\titers: 700, epoch: 14 | loss: 0.0492873\n",
      "\tspeed: 0.0346s/iter; left time: 195.4065s\n",
      "\titers: 800, epoch: 14 | loss: 0.0519501\n",
      "\tspeed: 0.0347s/iter; left time: 192.1339s\n",
      "\titers: 900, epoch: 14 | loss: 0.0444011\n",
      "\tspeed: 0.0347s/iter; left time: 188.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.0478288 Vali Loss: 0.0574118 Test Loss: 0.0649276\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518620\n",
      "\tspeed: 0.0950s/iter; left time: 506.9968s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447321\n",
      "\tspeed: 0.0346s/iter; left time: 181.3134s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470643\n",
      "\tspeed: 0.0346s/iter; left time: 177.8876s\n",
      "\titers: 400, epoch: 15 | loss: 0.0505560\n",
      "\tspeed: 0.0348s/iter; left time: 175.1414s\n",
      "\titers: 500, epoch: 15 | loss: 0.0455437\n",
      "\tspeed: 0.0347s/iter; left time: 171.4088s\n",
      "\titers: 600, epoch: 15 | loss: 0.0463022\n",
      "\tspeed: 0.0346s/iter; left time: 167.5804s\n",
      "\titers: 700, epoch: 15 | loss: 0.0565158\n",
      "\tspeed: 0.0347s/iter; left time: 164.3168s\n",
      "\titers: 800, epoch: 15 | loss: 0.0485040\n",
      "\tspeed: 0.0346s/iter; left time: 160.5875s\n",
      "\titers: 900, epoch: 15 | loss: 0.0463231\n",
      "\tspeed: 0.0346s/iter; left time: 157.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0470613 Vali Loss: 0.0568892 Test Loss: 0.0665978\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476478\n",
      "\tspeed: 0.0958s/iter; left time: 424.5514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0442408\n",
      "\tspeed: 0.0347s/iter; left time: 150.2413s\n",
      "\titers: 300, epoch: 16 | loss: 0.0460189\n",
      "\tspeed: 0.0347s/iter; left time: 146.8148s\n",
      "\titers: 400, epoch: 16 | loss: 0.0477852\n",
      "\tspeed: 0.0347s/iter; left time: 143.2491s\n",
      "\titers: 500, epoch: 16 | loss: 0.0508246\n",
      "\tspeed: 0.0347s/iter; left time: 139.7995s\n",
      "\titers: 600, epoch: 16 | loss: 0.0476234\n",
      "\tspeed: 0.0347s/iter; left time: 136.2444s\n",
      "\titers: 700, epoch: 16 | loss: 0.0496349\n",
      "\tspeed: 0.0347s/iter; left time: 132.8671s\n",
      "\titers: 800, epoch: 16 | loss: 0.0451010\n",
      "\tspeed: 0.0347s/iter; left time: 129.3319s\n",
      "\titers: 900, epoch: 16 | loss: 0.0472244\n",
      "\tspeed: 0.0347s/iter; left time: 125.8357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.73s\n",
      "Steps: 906 | Train Loss: 0.0462200 Vali Loss: 0.0565890 Test Loss: 0.0651991\n",
      "Validation loss decreased (0.056887 --> 0.056589).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0511533\n",
      "\tspeed: 0.0990s/iter; left time: 348.8845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410157\n",
      "\tspeed: 0.0347s/iter; left time: 118.8367s\n",
      "\titers: 300, epoch: 17 | loss: 0.0532006\n",
      "\tspeed: 0.0346s/iter; left time: 115.1362s\n",
      "\titers: 400, epoch: 17 | loss: 0.0506476\n",
      "\tspeed: 0.0347s/iter; left time: 111.8803s\n",
      "\titers: 500, epoch: 17 | loss: 0.0444746\n",
      "\tspeed: 0.0347s/iter; left time: 108.5460s\n",
      "\titers: 600, epoch: 17 | loss: 0.0454823\n",
      "\tspeed: 0.0347s/iter; left time: 104.8775s\n",
      "\titers: 700, epoch: 17 | loss: 0.0417460\n",
      "\tspeed: 0.0348s/iter; left time: 101.7171s\n",
      "\titers: 800, epoch: 17 | loss: 0.0485935\n",
      "\tspeed: 0.0347s/iter; left time: 98.1239s\n",
      "\titers: 900, epoch: 17 | loss: 0.0427209\n",
      "\tspeed: 0.0347s/iter; left time: 94.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.77s\n",
      "Steps: 906 | Train Loss: 0.0454245 Vali Loss: 0.0563723 Test Loss: 0.0671997\n",
      "Validation loss decreased (0.056589 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0397315\n",
      "\tspeed: 0.0992s/iter; left time: 259.7061s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411270\n",
      "\tspeed: 0.0354s/iter; left time: 89.2592s\n",
      "\titers: 300, epoch: 18 | loss: 0.0484297\n",
      "\tspeed: 0.0353s/iter; left time: 85.4810s\n",
      "\titers: 400, epoch: 18 | loss: 0.0467603\n",
      "\tspeed: 0.0347s/iter; left time: 80.3745s\n",
      "\titers: 500, epoch: 18 | loss: 0.0422288\n",
      "\tspeed: 0.0347s/iter; left time: 77.1078s\n",
      "\titers: 600, epoch: 18 | loss: 0.0504954\n",
      "\tspeed: 0.0347s/iter; left time: 73.4995s\n",
      "\titers: 700, epoch: 18 | loss: 0.0396327\n",
      "\tspeed: 0.0347s/iter; left time: 70.1133s\n",
      "\titers: 800, epoch: 18 | loss: 0.0461913\n",
      "\tspeed: 0.0348s/iter; left time: 66.7656s\n",
      "\titers: 900, epoch: 18 | loss: 0.0522097\n",
      "\tspeed: 0.0353s/iter; left time: 64.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.05s\n",
      "Steps: 906 | Train Loss: 0.0448353 Vali Loss: 0.0574077 Test Loss: 0.0666983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0404343\n",
      "\tspeed: 0.0962s/iter; left time: 164.8634s\n",
      "\titers: 200, epoch: 19 | loss: 0.0435289\n",
      "\tspeed: 0.0354s/iter; left time: 57.0615s\n",
      "\titers: 300, epoch: 19 | loss: 0.0437113\n",
      "\tspeed: 0.0354s/iter; left time: 53.5034s\n",
      "\titers: 400, epoch: 19 | loss: 0.0464690\n",
      "\tspeed: 0.0347s/iter; left time: 49.0817s\n",
      "\titers: 500, epoch: 19 | loss: 0.0434488\n",
      "\tspeed: 0.0345s/iter; left time: 45.3597s\n",
      "\titers: 600, epoch: 19 | loss: 0.0420474\n",
      "\tspeed: 0.0346s/iter; left time: 41.9174s\n",
      "\titers: 700, epoch: 19 | loss: 0.0488688\n",
      "\tspeed: 0.0346s/iter; left time: 38.4872s\n",
      "\titers: 800, epoch: 19 | loss: 0.0425040\n",
      "\tspeed: 0.0347s/iter; left time: 35.1069s\n",
      "\titers: 900, epoch: 19 | loss: 0.0387297\n",
      "\tspeed: 0.0346s/iter; left time: 31.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.91s\n",
      "Steps: 906 | Train Loss: 0.0441012 Vali Loss: 0.0579686 Test Loss: 0.0662565\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443658\n",
      "\tspeed: 0.0947s/iter; left time: 76.3905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0434084\n",
      "\tspeed: 0.0346s/iter; left time: 24.4717s\n",
      "\titers: 300, epoch: 20 | loss: 0.0444593\n",
      "\tspeed: 0.0347s/iter; left time: 21.0411s\n",
      "\titers: 400, epoch: 20 | loss: 0.0421418\n",
      "\tspeed: 0.0346s/iter; left time: 17.5626s\n",
      "\titers: 500, epoch: 20 | loss: 0.0421504\n",
      "\tspeed: 0.0346s/iter; left time: 14.0774s\n",
      "\titers: 600, epoch: 20 | loss: 0.0476669\n",
      "\tspeed: 0.0347s/iter; left time: 10.6547s\n",
      "\titers: 700, epoch: 20 | loss: 0.0507700\n",
      "\tspeed: 0.0346s/iter; left time: 7.1550s\n",
      "\titers: 800, epoch: 20 | loss: 0.0446998\n",
      "\tspeed: 0.0346s/iter; left time: 3.7025s\n",
      "\titers: 900, epoch: 20 | loss: 0.0413743\n",
      "\tspeed: 0.0346s/iter; left time: 0.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.65s\n",
      "Steps: 906 | Train Loss: 0.0435656 Vali Loss: 0.0569343 Test Loss: 0.0663891\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013082382269203663, rmse:0.11437824368476868, mae:0.06724400073289871, rse:0.43224334716796875\n",
      "Intermediate time for IT and pred_len 24: 00h:23m:18.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2329149\n",
      "\tspeed: 0.0654s/iter; left time: 1176.2400s\n",
      "\titers: 200, epoch: 1 | loss: 0.2132984\n",
      "\tspeed: 0.0419s/iter; left time: 749.7176s\n",
      "\titers: 300, epoch: 1 | loss: 0.2021164\n",
      "\tspeed: 0.0419s/iter; left time: 745.8109s\n",
      "\titers: 400, epoch: 1 | loss: 0.1994694\n",
      "\tspeed: 0.0419s/iter; left time: 741.5871s\n",
      "\titers: 500, epoch: 1 | loss: 0.1993076\n",
      "\tspeed: 0.0419s/iter; left time: 737.5135s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911502\n",
      "\tspeed: 0.0420s/iter; left time: 733.4970s\n",
      "\titers: 700, epoch: 1 | loss: 0.1889577\n",
      "\tspeed: 0.0419s/iter; left time: 728.8116s\n",
      "\titers: 800, epoch: 1 | loss: 0.1783947\n",
      "\tspeed: 0.0415s/iter; left time: 717.1408s\n",
      "\titers: 900, epoch: 1 | loss: 0.1868250\n",
      "\tspeed: 0.0420s/iter; left time: 720.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 904 | Train Loss: 0.2045878 Vali Loss: 0.1702724 Test Loss: 0.1878111\n",
      "Validation loss decreased (inf --> 0.170272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1723534\n",
      "\tspeed: 0.1170s/iter; left time: 1998.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.1603348\n",
      "\tspeed: 0.0415s/iter; left time: 704.5081s\n",
      "\titers: 300, epoch: 2 | loss: 0.1485798\n",
      "\tspeed: 0.0415s/iter; left time: 700.8199s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373307\n",
      "\tspeed: 0.0415s/iter; left time: 696.6399s\n",
      "\titers: 500, epoch: 2 | loss: 0.1285997\n",
      "\tspeed: 0.0415s/iter; left time: 692.2526s\n",
      "\titers: 600, epoch: 2 | loss: 0.1198477\n",
      "\tspeed: 0.0415s/iter; left time: 688.1834s\n",
      "\titers: 700, epoch: 2 | loss: 0.1147303\n",
      "\tspeed: 0.0415s/iter; left time: 683.9993s\n",
      "\titers: 800, epoch: 2 | loss: 0.1007503\n",
      "\tspeed: 0.0415s/iter; left time: 679.8908s\n",
      "\titers: 900, epoch: 2 | loss: 0.0971180\n",
      "\tspeed: 0.0415s/iter; left time: 676.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1339202 Vali Loss: 0.0941798 Test Loss: 0.1007875\n",
      "Validation loss decreased (0.170272 --> 0.094180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933497\n",
      "\tspeed: 0.1176s/iter; left time: 1901.4621s\n",
      "\titers: 200, epoch: 3 | loss: 0.0936517\n",
      "\tspeed: 0.0420s/iter; left time: 675.2535s\n",
      "\titers: 300, epoch: 3 | loss: 0.0927260\n",
      "\tspeed: 0.0420s/iter; left time: 670.9438s\n",
      "\titers: 400, epoch: 3 | loss: 0.0904723\n",
      "\tspeed: 0.0420s/iter; left time: 666.9150s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878174\n",
      "\tspeed: 0.0419s/iter; left time: 661.3822s\n",
      "\titers: 600, epoch: 3 | loss: 0.0923175\n",
      "\tspeed: 0.0415s/iter; left time: 650.1710s\n",
      "\titers: 700, epoch: 3 | loss: 0.0842094\n",
      "\tspeed: 0.0415s/iter; left time: 645.7592s\n",
      "\titers: 800, epoch: 3 | loss: 0.0947829\n",
      "\tspeed: 0.0416s/iter; left time: 643.4295s\n",
      "\titers: 900, epoch: 3 | loss: 0.0795053\n",
      "\tspeed: 0.0420s/iter; left time: 645.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 904 | Train Loss: 0.0910683 Vali Loss: 0.0842124 Test Loss: 0.0916354\n",
      "Validation loss decreased (0.094180 --> 0.084212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810681\n",
      "\tspeed: 0.1176s/iter; left time: 1795.0221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898334\n",
      "\tspeed: 0.0415s/iter; left time: 629.5262s\n",
      "\titers: 300, epoch: 4 | loss: 0.0877813\n",
      "\tspeed: 0.0415s/iter; left time: 625.5383s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827008\n",
      "\tspeed: 0.0415s/iter; left time: 620.9080s\n",
      "\titers: 500, epoch: 4 | loss: 0.0800275\n",
      "\tspeed: 0.0415s/iter; left time: 617.5306s\n",
      "\titers: 600, epoch: 4 | loss: 0.0795660\n",
      "\tspeed: 0.0415s/iter; left time: 613.3683s\n",
      "\titers: 700, epoch: 4 | loss: 0.0887710\n",
      "\tspeed: 0.0415s/iter; left time: 609.4629s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751216\n",
      "\tspeed: 0.0415s/iter; left time: 605.2594s\n",
      "\titers: 900, epoch: 4 | loss: 0.0814652\n",
      "\tspeed: 0.0415s/iter; left time: 600.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0842684 Vali Loss: 0.0824417 Test Loss: 0.0909199\n",
      "Validation loss decreased (0.084212 --> 0.082442).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819404\n",
      "\tspeed: 0.1164s/iter; left time: 1672.1114s\n",
      "\titers: 200, epoch: 5 | loss: 0.0734804\n",
      "\tspeed: 0.0415s/iter; left time: 591.8577s\n",
      "\titers: 300, epoch: 5 | loss: 0.0850687\n",
      "\tspeed: 0.0415s/iter; left time: 587.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.0805629\n",
      "\tspeed: 0.0415s/iter; left time: 583.3193s\n",
      "\titers: 500, epoch: 5 | loss: 0.0772669\n",
      "\tspeed: 0.0415s/iter; left time: 579.6728s\n",
      "\titers: 600, epoch: 5 | loss: 0.0835028\n",
      "\tspeed: 0.0415s/iter; left time: 575.0510s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755597\n",
      "\tspeed: 0.0415s/iter; left time: 571.0340s\n",
      "\titers: 800, epoch: 5 | loss: 0.0821126\n",
      "\tspeed: 0.0415s/iter; left time: 566.8882s\n",
      "\titers: 900, epoch: 5 | loss: 0.0793681\n",
      "\tspeed: 0.0415s/iter; left time: 563.0824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0794752 Vali Loss: 0.0815711 Test Loss: 0.0942506\n",
      "Validation loss decreased (0.082442 --> 0.081571).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839607\n",
      "\tspeed: 0.1197s/iter; left time: 1610.7661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795517\n",
      "\tspeed: 0.0415s/iter; left time: 555.1379s\n",
      "\titers: 300, epoch: 6 | loss: 0.0796291\n",
      "\tspeed: 0.0415s/iter; left time: 550.8724s\n",
      "\titers: 400, epoch: 6 | loss: 0.0740407\n",
      "\tspeed: 0.0415s/iter; left time: 546.6841s\n",
      "\titers: 500, epoch: 6 | loss: 0.0732674\n",
      "\tspeed: 0.0415s/iter; left time: 542.1567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0717258\n",
      "\tspeed: 0.0415s/iter; left time: 538.1807s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781353\n",
      "\tspeed: 0.0415s/iter; left time: 533.8559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0775410\n",
      "\tspeed: 0.0415s/iter; left time: 529.6971s\n",
      "\titers: 900, epoch: 6 | loss: 0.0719830\n",
      "\tspeed: 0.0415s/iter; left time: 526.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0759981 Vali Loss: 0.0810199 Test Loss: 0.0920831\n",
      "Validation loss decreased (0.081571 --> 0.081020).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723580\n",
      "\tspeed: 0.1173s/iter; left time: 1472.4495s\n",
      "\titers: 200, epoch: 7 | loss: 0.0775005\n",
      "\tspeed: 0.0415s/iter; left time: 516.4661s\n",
      "\titers: 300, epoch: 7 | loss: 0.0755266\n",
      "\tspeed: 0.0415s/iter; left time: 512.4093s\n",
      "\titers: 400, epoch: 7 | loss: 0.0716491\n",
      "\tspeed: 0.0415s/iter; left time: 508.4572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726988\n",
      "\tspeed: 0.0415s/iter; left time: 504.2027s\n",
      "\titers: 600, epoch: 7 | loss: 0.0645041\n",
      "\tspeed: 0.0415s/iter; left time: 500.0718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0743607\n",
      "\tspeed: 0.0415s/iter; left time: 496.0049s\n",
      "\titers: 800, epoch: 7 | loss: 0.0622560\n",
      "\tspeed: 0.0415s/iter; left time: 491.8869s\n",
      "\titers: 900, epoch: 7 | loss: 0.0748020\n",
      "\tspeed: 0.0415s/iter; left time: 487.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0728088 Vali Loss: 0.0797380 Test Loss: 0.0911746\n",
      "Validation loss decreased (0.081020 --> 0.079738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803198\n",
      "\tspeed: 0.1181s/iter; left time: 1376.5631s\n",
      "\titers: 200, epoch: 8 | loss: 0.0780065\n",
      "\tspeed: 0.0415s/iter; left time: 479.7795s\n",
      "\titers: 300, epoch: 8 | loss: 0.0705057\n",
      "\tspeed: 0.0415s/iter; left time: 475.6276s\n",
      "\titers: 400, epoch: 8 | loss: 0.0695511\n",
      "\tspeed: 0.0416s/iter; left time: 471.7291s\n",
      "\titers: 500, epoch: 8 | loss: 0.0667554\n",
      "\tspeed: 0.0415s/iter; left time: 467.1372s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727597\n",
      "\tspeed: 0.0415s/iter; left time: 463.1018s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681027\n",
      "\tspeed: 0.0415s/iter; left time: 459.0644s\n",
      "\titers: 800, epoch: 8 | loss: 0.0727258\n",
      "\tspeed: 0.0415s/iter; left time: 454.9328s\n",
      "\titers: 900, epoch: 8 | loss: 0.0665395\n",
      "\tspeed: 0.0415s/iter; left time: 450.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0701697 Vali Loss: 0.0797013 Test Loss: 0.0913741\n",
      "Validation loss decreased (0.079738 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698563\n",
      "\tspeed: 0.1180s/iter; left time: 1268.2817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0712313\n",
      "\tspeed: 0.0415s/iter; left time: 441.8347s\n",
      "\titers: 300, epoch: 9 | loss: 0.0642897\n",
      "\tspeed: 0.0415s/iter; left time: 437.9253s\n",
      "\titers: 400, epoch: 9 | loss: 0.0650743\n",
      "\tspeed: 0.0415s/iter; left time: 433.4531s\n",
      "\titers: 500, epoch: 9 | loss: 0.0677874\n",
      "\tspeed: 0.0416s/iter; left time: 430.0321s\n",
      "\titers: 600, epoch: 9 | loss: 0.0642288\n",
      "\tspeed: 0.0416s/iter; left time: 426.0446s\n",
      "\titers: 700, epoch: 9 | loss: 0.0613472\n",
      "\tspeed: 0.0415s/iter; left time: 421.6572s\n",
      "\titers: 800, epoch: 9 | loss: 0.0655759\n",
      "\tspeed: 0.0416s/iter; left time: 417.8767s\n",
      "\titers: 900, epoch: 9 | loss: 0.0630118\n",
      "\tspeed: 0.0415s/iter; left time: 413.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0675159 Vali Loss: 0.0817569 Test Loss: 0.0939381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0707889\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9164s\n",
      "\titers: 200, epoch: 10 | loss: 0.0646257\n",
      "\tspeed: 0.0415s/iter; left time: 404.3090s\n",
      "\titers: 300, epoch: 10 | loss: 0.0597870\n",
      "\tspeed: 0.0415s/iter; left time: 400.0274s\n",
      "\titers: 400, epoch: 10 | loss: 0.0606851\n",
      "\tspeed: 0.0415s/iter; left time: 396.0367s\n",
      "\titers: 500, epoch: 10 | loss: 0.0722949\n",
      "\tspeed: 0.0415s/iter; left time: 391.8655s\n",
      "\titers: 600, epoch: 10 | loss: 0.0613441\n",
      "\tspeed: 0.0415s/iter; left time: 387.7212s\n",
      "\titers: 700, epoch: 10 | loss: 0.0637856\n",
      "\tspeed: 0.0415s/iter; left time: 383.5531s\n",
      "\titers: 800, epoch: 10 | loss: 0.0674466\n",
      "\tspeed: 0.0415s/iter; left time: 379.4913s\n",
      "\titers: 900, epoch: 10 | loss: 0.0660359\n",
      "\tspeed: 0.0415s/iter; left time: 375.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0650114 Vali Loss: 0.0814649 Test Loss: 0.0932802\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628955\n",
      "\tspeed: 0.1142s/iter; left time: 1021.1997s\n",
      "\titers: 200, epoch: 11 | loss: 0.0667712\n",
      "\tspeed: 0.0415s/iter; left time: 367.1091s\n",
      "\titers: 300, epoch: 11 | loss: 0.0622564\n",
      "\tspeed: 0.0415s/iter; left time: 362.8662s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667247\n",
      "\tspeed: 0.0415s/iter; left time: 358.5564s\n",
      "\titers: 500, epoch: 11 | loss: 0.0588989\n",
      "\tspeed: 0.0415s/iter; left time: 354.8069s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601503\n",
      "\tspeed: 0.0415s/iter; left time: 350.5460s\n",
      "\titers: 700, epoch: 11 | loss: 0.0651884\n",
      "\tspeed: 0.0415s/iter; left time: 346.4933s\n",
      "\titers: 800, epoch: 11 | loss: 0.0648965\n",
      "\tspeed: 0.0415s/iter; left time: 342.2225s\n",
      "\titers: 900, epoch: 11 | loss: 0.0662556\n",
      "\tspeed: 0.0415s/iter; left time: 338.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.76s\n",
      "Steps: 904 | Train Loss: 0.0628507 Vali Loss: 0.0824759 Test Loss: 0.0953183\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586193\n",
      "\tspeed: 0.1132s/iter; left time: 910.0730s\n",
      "\titers: 200, epoch: 12 | loss: 0.0632593\n",
      "\tspeed: 0.0414s/iter; left time: 328.9784s\n",
      "\titers: 300, epoch: 12 | loss: 0.0581805\n",
      "\tspeed: 0.0414s/iter; left time: 324.8005s\n",
      "\titers: 400, epoch: 12 | loss: 0.0527286\n",
      "\tspeed: 0.0415s/iter; left time: 320.8751s\n",
      "\titers: 500, epoch: 12 | loss: 0.0617137\n",
      "\tspeed: 0.0415s/iter; left time: 316.7904s\n",
      "\titers: 600, epoch: 12 | loss: 0.0588900\n",
      "\tspeed: 0.0414s/iter; left time: 312.4074s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644570\n",
      "\tspeed: 0.0415s/iter; left time: 308.3568s\n",
      "\titers: 800, epoch: 12 | loss: 0.0602104\n",
      "\tspeed: 0.0415s/iter; left time: 304.2294s\n",
      "\titers: 900, epoch: 12 | loss: 0.0594495\n",
      "\tspeed: 0.0415s/iter; left time: 300.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 904 | Train Loss: 0.0606359 Vali Loss: 0.0830488 Test Loss: 0.0953343\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596162\n",
      "\tspeed: 0.1131s/iter; left time: 807.0245s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571232\n",
      "\tspeed: 0.0415s/iter; left time: 291.9264s\n",
      "\titers: 300, epoch: 13 | loss: 0.0555218\n",
      "\tspeed: 0.0415s/iter; left time: 287.6298s\n",
      "\titers: 400, epoch: 13 | loss: 0.0576127\n",
      "\tspeed: 0.0415s/iter; left time: 283.7168s\n",
      "\titers: 500, epoch: 13 | loss: 0.0613527\n",
      "\tspeed: 0.0415s/iter; left time: 279.3836s\n",
      "\titers: 600, epoch: 13 | loss: 0.0561092\n",
      "\tspeed: 0.0415s/iter; left time: 275.2104s\n",
      "\titers: 700, epoch: 13 | loss: 0.0549113\n",
      "\tspeed: 0.0415s/iter; left time: 271.0120s\n",
      "\titers: 800, epoch: 13 | loss: 0.0601151\n",
      "\tspeed: 0.0415s/iter; left time: 266.8849s\n",
      "\titers: 900, epoch: 13 | loss: 0.0564174\n",
      "\tspeed: 0.0415s/iter; left time: 262.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0588037 Vali Loss: 0.0848033 Test Loss: 0.0960292\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022316191345453262, rmse:0.14938604831695557, mae:0.09133996814489365, rse:0.5648447275161743\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2292959\n",
      "\tspeed: 0.0439s/iter; left time: 790.0637s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081810\n",
      "\tspeed: 0.0416s/iter; left time: 743.1444s\n",
      "\titers: 300, epoch: 1 | loss: 0.2096158\n",
      "\tspeed: 0.0416s/iter; left time: 738.9012s\n",
      "\titers: 400, epoch: 1 | loss: 0.2077726\n",
      "\tspeed: 0.0416s/iter; left time: 734.8712s\n",
      "\titers: 500, epoch: 1 | loss: 0.1998558\n",
      "\tspeed: 0.0416s/iter; left time: 730.8517s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957197\n",
      "\tspeed: 0.0416s/iter; left time: 726.7343s\n",
      "\titers: 700, epoch: 1 | loss: 0.1891191\n",
      "\tspeed: 0.0416s/iter; left time: 722.6622s\n",
      "\titers: 800, epoch: 1 | loss: 0.1786730\n",
      "\tspeed: 0.0416s/iter; left time: 718.8404s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799013\n",
      "\tspeed: 0.0416s/iter; left time: 714.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.2049319 Vali Loss: 0.1680077 Test Loss: 0.1860517\n",
      "Validation loss decreased (inf --> 0.168008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652640\n",
      "\tspeed: 0.1168s/iter; left time: 1995.2893s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542776\n",
      "\tspeed: 0.0416s/iter; left time: 705.8684s\n",
      "\titers: 300, epoch: 2 | loss: 0.1318608\n",
      "\tspeed: 0.0416s/iter; left time: 701.9676s\n",
      "\titers: 400, epoch: 2 | loss: 0.1279899\n",
      "\tspeed: 0.0416s/iter; left time: 697.8615s\n",
      "\titers: 500, epoch: 2 | loss: 0.1211760\n",
      "\tspeed: 0.0416s/iter; left time: 693.6336s\n",
      "\titers: 600, epoch: 2 | loss: 0.1045376\n",
      "\tspeed: 0.0416s/iter; left time: 689.3137s\n",
      "\titers: 700, epoch: 2 | loss: 0.1058448\n",
      "\tspeed: 0.0416s/iter; left time: 685.0528s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937553\n",
      "\tspeed: 0.0416s/iter; left time: 681.1193s\n",
      "\titers: 900, epoch: 2 | loss: 0.0992664\n",
      "\tspeed: 0.0416s/iter; left time: 676.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1267896 Vali Loss: 0.0913177 Test Loss: 0.0968462\n",
      "Validation loss decreased (0.168008 --> 0.091318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0841759\n",
      "\tspeed: 0.1182s/iter; left time: 1911.4221s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893953\n",
      "\tspeed: 0.0422s/iter; left time: 678.8770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0954204\n",
      "\tspeed: 0.0421s/iter; left time: 673.1054s\n",
      "\titers: 400, epoch: 3 | loss: 0.1050853\n",
      "\tspeed: 0.0421s/iter; left time: 668.4050s\n",
      "\titers: 500, epoch: 3 | loss: 0.0887890\n",
      "\tspeed: 0.0421s/iter; left time: 664.0398s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911384\n",
      "\tspeed: 0.0421s/iter; left time: 660.1369s\n",
      "\titers: 700, epoch: 3 | loss: 0.0956997\n",
      "\tspeed: 0.0421s/iter; left time: 655.4478s\n",
      "\titers: 800, epoch: 3 | loss: 0.0855911\n",
      "\tspeed: 0.0421s/iter; left time: 651.3994s\n",
      "\titers: 900, epoch: 3 | loss: 0.0926109\n",
      "\tspeed: 0.0421s/iter; left time: 647.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 904 | Train Loss: 0.0894015 Vali Loss: 0.0832333 Test Loss: 0.0903517\n",
      "Validation loss decreased (0.091318 --> 0.083233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.1173s/iter; left time: 1791.4033s\n",
      "\titers: 200, epoch: 4 | loss: 0.0908587\n",
      "\tspeed: 0.0416s/iter; left time: 630.3665s\n",
      "\titers: 300, epoch: 4 | loss: 0.0815956\n",
      "\tspeed: 0.0416s/iter; left time: 626.1857s\n",
      "\titers: 400, epoch: 4 | loss: 0.0794364\n",
      "\tspeed: 0.0415s/iter; left time: 621.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.0824227\n",
      "\tspeed: 0.0416s/iter; left time: 618.1104s\n",
      "\titers: 600, epoch: 4 | loss: 0.0863480\n",
      "\tspeed: 0.0416s/iter; left time: 613.9127s\n",
      "\titers: 700, epoch: 4 | loss: 0.0751134\n",
      "\tspeed: 0.0416s/iter; left time: 609.5003s\n",
      "\titers: 800, epoch: 4 | loss: 0.0925940\n",
      "\tspeed: 0.0416s/iter; left time: 605.9970s\n",
      "\titers: 900, epoch: 4 | loss: 0.0779531\n",
      "\tspeed: 0.0416s/iter; left time: 601.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0827076 Vali Loss: 0.0849494 Test Loss: 0.0960318\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767040\n",
      "\tspeed: 0.1147s/iter; left time: 1646.9957s\n",
      "\titers: 200, epoch: 5 | loss: 0.0699800\n",
      "\tspeed: 0.0416s/iter; left time: 593.1308s\n",
      "\titers: 300, epoch: 5 | loss: 0.0853455\n",
      "\tspeed: 0.0416s/iter; left time: 588.8973s\n",
      "\titers: 400, epoch: 5 | loss: 0.0704516\n",
      "\tspeed: 0.0416s/iter; left time: 585.1993s\n",
      "\titers: 500, epoch: 5 | loss: 0.0756307\n",
      "\tspeed: 0.0416s/iter; left time: 580.8204s\n",
      "\titers: 600, epoch: 5 | loss: 0.0742427\n",
      "\tspeed: 0.0416s/iter; left time: 576.6748s\n",
      "\titers: 700, epoch: 5 | loss: 0.0752169\n",
      "\tspeed: 0.0416s/iter; left time: 572.6171s\n",
      "\titers: 800, epoch: 5 | loss: 0.0806310\n",
      "\tspeed: 0.0416s/iter; left time: 568.3955s\n",
      "\titers: 900, epoch: 5 | loss: 0.0723156\n",
      "\tspeed: 0.0416s/iter; left time: 564.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0782667 Vali Loss: 0.0774129 Test Loss: 0.0860390\n",
      "Validation loss decreased (0.083233 --> 0.077413).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741043\n",
      "\tspeed: 0.1177s/iter; left time: 1584.3770s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707103\n",
      "\tspeed: 0.0419s/iter; left time: 559.2264s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718977\n",
      "\tspeed: 0.0416s/iter; left time: 551.5400s\n",
      "\titers: 400, epoch: 6 | loss: 0.0712616\n",
      "\tspeed: 0.0416s/iter; left time: 547.3957s\n",
      "\titers: 500, epoch: 6 | loss: 0.0730634\n",
      "\tspeed: 0.0416s/iter; left time: 543.2703s\n",
      "\titers: 600, epoch: 6 | loss: 0.0824830\n",
      "\tspeed: 0.0416s/iter; left time: 539.1506s\n",
      "\titers: 700, epoch: 6 | loss: 0.0697925\n",
      "\tspeed: 0.0416s/iter; left time: 535.2309s\n",
      "\titers: 800, epoch: 6 | loss: 0.0703837\n",
      "\tspeed: 0.0416s/iter; left time: 530.9931s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704858\n",
      "\tspeed: 0.0416s/iter; left time: 526.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 904 | Train Loss: 0.0749824 Vali Loss: 0.0792238 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748432\n",
      "\tspeed: 0.1146s/iter; left time: 1439.4933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809488\n",
      "\tspeed: 0.0421s/iter; left time: 524.7787s\n",
      "\titers: 300, epoch: 7 | loss: 0.0747016\n",
      "\tspeed: 0.0421s/iter; left time: 520.0955s\n",
      "\titers: 400, epoch: 7 | loss: 0.0723035\n",
      "\tspeed: 0.0420s/iter; left time: 515.3437s\n",
      "\titers: 500, epoch: 7 | loss: 0.0700389\n",
      "\tspeed: 0.0418s/iter; left time: 508.5885s\n",
      "\titers: 600, epoch: 7 | loss: 0.0682066\n",
      "\tspeed: 0.0420s/iter; left time: 506.9452s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772949\n",
      "\tspeed: 0.0421s/iter; left time: 503.4054s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649828\n",
      "\tspeed: 0.0421s/iter; left time: 499.1290s\n",
      "\titers: 900, epoch: 7 | loss: 0.0713191\n",
      "\tspeed: 0.0420s/iter; left time: 494.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 904 | Train Loss: 0.0719335 Vali Loss: 0.0794691 Test Loss: 0.0918467\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724586\n",
      "\tspeed: 0.1142s/iter; left time: 1330.5487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0715756\n",
      "\tspeed: 0.0415s/iter; left time: 479.8969s\n",
      "\titers: 300, epoch: 8 | loss: 0.0657794\n",
      "\tspeed: 0.0415s/iter; left time: 475.6346s\n",
      "\titers: 400, epoch: 8 | loss: 0.0654476\n",
      "\tspeed: 0.0415s/iter; left time: 471.6994s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704021\n",
      "\tspeed: 0.0415s/iter; left time: 467.4944s\n",
      "\titers: 600, epoch: 8 | loss: 0.0675833\n",
      "\tspeed: 0.0416s/iter; left time: 463.5340s\n",
      "\titers: 700, epoch: 8 | loss: 0.0698371\n",
      "\tspeed: 0.0416s/iter; left time: 459.3636s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766558\n",
      "\tspeed: 0.0415s/iter; left time: 455.0782s\n",
      "\titers: 900, epoch: 8 | loss: 0.0691651\n",
      "\tspeed: 0.0416s/iter; left time: 451.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0692788 Vali Loss: 0.0809576 Test Loss: 0.0899754\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0643936\n",
      "\tspeed: 0.1136s/iter; left time: 1221.2237s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613265\n",
      "\tspeed: 0.0415s/iter; left time: 441.8698s\n",
      "\titers: 300, epoch: 9 | loss: 0.0656117\n",
      "\tspeed: 0.0415s/iter; left time: 437.8691s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665474\n",
      "\tspeed: 0.0415s/iter; left time: 433.7844s\n",
      "\titers: 500, epoch: 9 | loss: 0.0646721\n",
      "\tspeed: 0.0415s/iter; left time: 429.7658s\n",
      "\titers: 600, epoch: 9 | loss: 0.0673045\n",
      "\tspeed: 0.0415s/iter; left time: 425.3731s\n",
      "\titers: 700, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0415s/iter; left time: 421.4103s\n",
      "\titers: 800, epoch: 9 | loss: 0.0713633\n",
      "\tspeed: 0.0415s/iter; left time: 417.2159s\n",
      "\titers: 900, epoch: 9 | loss: 0.0673369\n",
      "\tspeed: 0.0415s/iter; left time: 413.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0662697 Vali Loss: 0.0811222 Test Loss: 0.0916531\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0716086\n",
      "\tspeed: 0.1136s/iter; left time: 1118.5103s\n",
      "\titers: 200, epoch: 10 | loss: 0.0616231\n",
      "\tspeed: 0.0416s/iter; left time: 405.1216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0624919\n",
      "\tspeed: 0.0416s/iter; left time: 400.7687s\n",
      "\titers: 400, epoch: 10 | loss: 0.0612750\n",
      "\tspeed: 0.0416s/iter; left time: 396.6213s\n",
      "\titers: 500, epoch: 10 | loss: 0.0687094\n",
      "\tspeed: 0.0416s/iter; left time: 392.6357s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689967\n",
      "\tspeed: 0.0416s/iter; left time: 388.3021s\n",
      "\titers: 700, epoch: 10 | loss: 0.0666971\n",
      "\tspeed: 0.0416s/iter; left time: 384.3920s\n",
      "\titers: 800, epoch: 10 | loss: 0.0618813\n",
      "\tspeed: 0.0416s/iter; left time: 380.2382s\n",
      "\titers: 900, epoch: 10 | loss: 0.0615688\n",
      "\tspeed: 0.0416s/iter; left time: 375.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0640776 Vali Loss: 0.0819628 Test Loss: 0.0911019\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019260551780462265, rmse:0.13878239691257477, mae:0.08605317771434784, rse:0.5247511863708496\n",
      "Intermediate time for IT and pred_len 96: 00h:17m:29.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2417706\n",
      "\tspeed: 0.0736s/iter; left time: 1320.0040s\n",
      "\titers: 200, epoch: 1 | loss: 0.2105667\n",
      "\tspeed: 0.0507s/iter; left time: 905.0718s\n",
      "\titers: 300, epoch: 1 | loss: 0.2133086\n",
      "\tspeed: 0.0508s/iter; left time: 900.7788s\n",
      "\titers: 400, epoch: 1 | loss: 0.2001980\n",
      "\tspeed: 0.0508s/iter; left time: 896.6578s\n",
      "\titers: 500, epoch: 1 | loss: 0.1996722\n",
      "\tspeed: 0.0509s/iter; left time: 892.1233s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957152\n",
      "\tspeed: 0.0508s/iter; left time: 886.5263s\n",
      "\titers: 700, epoch: 1 | loss: 0.1911985\n",
      "\tspeed: 0.0508s/iter; left time: 881.4821s\n",
      "\titers: 800, epoch: 1 | loss: 0.1923567\n",
      "\tspeed: 0.0504s/iter; left time: 869.0295s\n",
      "\titers: 900, epoch: 1 | loss: 0.1911421\n",
      "\tspeed: 0.0507s/iter; left time: 869.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.2067105 Vali Loss: 0.1742837 Test Loss: 0.1910858\n",
      "Validation loss decreased (inf --> 0.174284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1741898\n",
      "\tspeed: 0.1420s/iter; left time: 2419.5547s\n",
      "\titers: 200, epoch: 2 | loss: 0.1590756\n",
      "\tspeed: 0.0504s/iter; left time: 853.3194s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492482\n",
      "\tspeed: 0.0504s/iter; left time: 848.3516s\n",
      "\titers: 400, epoch: 2 | loss: 0.1439626\n",
      "\tspeed: 0.0504s/iter; left time: 843.9217s\n",
      "\titers: 500, epoch: 2 | loss: 0.1376841\n",
      "\tspeed: 0.0504s/iter; left time: 837.8947s\n",
      "\titers: 600, epoch: 2 | loss: 0.1318157\n",
      "\tspeed: 0.0504s/iter; left time: 834.1674s\n",
      "\titers: 700, epoch: 2 | loss: 0.1226903\n",
      "\tspeed: 0.0505s/iter; left time: 829.4095s\n",
      "\titers: 800, epoch: 2 | loss: 0.1155013\n",
      "\tspeed: 0.0504s/iter; left time: 823.6467s\n",
      "\titers: 900, epoch: 2 | loss: 0.1036045\n",
      "\tspeed: 0.0503s/iter; left time: 817.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1425180 Vali Loss: 0.0997220 Test Loss: 0.1080564\n",
      "Validation loss decreased (0.174284 --> 0.099722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1070874\n",
      "\tspeed: 0.1400s/iter; left time: 2259.1733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982135\n",
      "\tspeed: 0.0504s/iter; left time: 808.0465s\n",
      "\titers: 300, epoch: 3 | loss: 0.0975068\n",
      "\tspeed: 0.0504s/iter; left time: 803.1246s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913634\n",
      "\tspeed: 0.0505s/iter; left time: 799.1843s\n",
      "\titers: 500, epoch: 3 | loss: 0.0938966\n",
      "\tspeed: 0.0504s/iter; left time: 792.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963875\n",
      "\tspeed: 0.0504s/iter; left time: 787.6281s\n",
      "\titers: 700, epoch: 3 | loss: 0.0930466\n",
      "\tspeed: 0.0504s/iter; left time: 782.8578s\n",
      "\titers: 800, epoch: 3 | loss: 0.0894339\n",
      "\tspeed: 0.0504s/iter; left time: 777.7969s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931466\n",
      "\tspeed: 0.0503s/iter; left time: 771.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0965498 Vali Loss: 0.0912357 Test Loss: 0.1002337\n",
      "Validation loss decreased (0.099722 --> 0.091236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912320\n",
      "\tspeed: 0.1400s/iter; left time: 2132.5732s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867965\n",
      "\tspeed: 0.0507s/iter; left time: 766.7007s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868980\n",
      "\tspeed: 0.0504s/iter; left time: 757.3387s\n",
      "\titers: 400, epoch: 4 | loss: 0.0909916\n",
      "\tspeed: 0.0505s/iter; left time: 754.3584s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869087\n",
      "\tspeed: 0.0504s/iter; left time: 747.6462s\n",
      "\titers: 600, epoch: 4 | loss: 0.0885214\n",
      "\tspeed: 0.0505s/iter; left time: 743.8012s\n",
      "\titers: 700, epoch: 4 | loss: 0.0855719\n",
      "\tspeed: 0.0504s/iter; left time: 736.8779s\n",
      "\titers: 800, epoch: 4 | loss: 0.0911454\n",
      "\tspeed: 0.0505s/iter; left time: 733.7025s\n",
      "\titers: 900, epoch: 4 | loss: 0.0852361\n",
      "\tspeed: 0.0505s/iter; left time: 729.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 902 | Train Loss: 0.0885773 Vali Loss: 0.0855312 Test Loss: 0.0943597\n",
      "Validation loss decreased (0.091236 --> 0.085531).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867432\n",
      "\tspeed: 0.1406s/iter; left time: 2015.7843s\n",
      "\titers: 200, epoch: 5 | loss: 0.0810685\n",
      "\tspeed: 0.0508s/iter; left time: 723.4109s\n",
      "\titers: 300, epoch: 5 | loss: 0.0855442\n",
      "\tspeed: 0.0509s/iter; left time: 718.7145s\n",
      "\titers: 400, epoch: 5 | loss: 0.0874002\n",
      "\tspeed: 0.0508s/iter; left time: 713.4811s\n",
      "\titers: 500, epoch: 5 | loss: 0.0819072\n",
      "\tspeed: 0.0508s/iter; left time: 708.2703s\n",
      "\titers: 600, epoch: 5 | loss: 0.0860219\n",
      "\tspeed: 0.0505s/iter; left time: 698.6841s\n",
      "\titers: 700, epoch: 5 | loss: 0.0811444\n",
      "\tspeed: 0.0504s/iter; left time: 692.2963s\n",
      "\titers: 800, epoch: 5 | loss: 0.0809208\n",
      "\tspeed: 0.0504s/iter; left time: 687.4578s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855082\n",
      "\tspeed: 0.0504s/iter; left time: 682.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0836334 Vali Loss: 0.0855765 Test Loss: 0.0958990\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0837307\n",
      "\tspeed: 0.1369s/iter; left time: 1838.9239s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879220\n",
      "\tspeed: 0.0504s/iter; left time: 671.5331s\n",
      "\titers: 300, epoch: 6 | loss: 0.0843503\n",
      "\tspeed: 0.0504s/iter; left time: 667.0104s\n",
      "\titers: 400, epoch: 6 | loss: 0.0791846\n",
      "\tspeed: 0.0505s/iter; left time: 662.9974s\n",
      "\titers: 500, epoch: 6 | loss: 0.0788330\n",
      "\tspeed: 0.0504s/iter; left time: 656.3321s\n",
      "\titers: 600, epoch: 6 | loss: 0.0786551\n",
      "\tspeed: 0.0504s/iter; left time: 651.4243s\n",
      "\titers: 700, epoch: 6 | loss: 0.0774791\n",
      "\tspeed: 0.0503s/iter; left time: 645.9442s\n",
      "\titers: 800, epoch: 6 | loss: 0.0832842\n",
      "\tspeed: 0.0504s/iter; left time: 641.4467s\n",
      "\titers: 900, epoch: 6 | loss: 0.0777149\n",
      "\tspeed: 0.0504s/iter; left time: 636.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0799680 Vali Loss: 0.0855314 Test Loss: 0.0941967\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832227\n",
      "\tspeed: 0.1374s/iter; left time: 1721.4858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769130\n",
      "\tspeed: 0.0504s/iter; left time: 626.6860s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797686\n",
      "\tspeed: 0.0504s/iter; left time: 621.5318s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803033\n",
      "\tspeed: 0.0504s/iter; left time: 616.8940s\n",
      "\titers: 500, epoch: 7 | loss: 0.0713358\n",
      "\tspeed: 0.0504s/iter; left time: 611.6196s\n",
      "\titers: 600, epoch: 7 | loss: 0.0767121\n",
      "\tspeed: 0.0504s/iter; left time: 606.4779s\n",
      "\titers: 700, epoch: 7 | loss: 0.0724495\n",
      "\tspeed: 0.0504s/iter; left time: 601.4541s\n",
      "\titers: 800, epoch: 7 | loss: 0.0772860\n",
      "\tspeed: 0.0504s/iter; left time: 596.5747s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758775\n",
      "\tspeed: 0.0504s/iter; left time: 591.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0763688 Vali Loss: 0.0862588 Test Loss: 0.0960034\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746740\n",
      "\tspeed: 0.1380s/iter; left time: 1604.7483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710704\n",
      "\tspeed: 0.0504s/iter; left time: 581.3052s\n",
      "\titers: 300, epoch: 8 | loss: 0.0767001\n",
      "\tspeed: 0.0504s/iter; left time: 576.2394s\n",
      "\titers: 400, epoch: 8 | loss: 0.0722365\n",
      "\tspeed: 0.0505s/iter; left time: 571.5276s\n",
      "\titers: 500, epoch: 8 | loss: 0.0735169\n",
      "\tspeed: 0.0504s/iter; left time: 566.0925s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702938\n",
      "\tspeed: 0.0504s/iter; left time: 561.0255s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752317\n",
      "\tspeed: 0.0504s/iter; left time: 556.1749s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745411\n",
      "\tspeed: 0.0504s/iter; left time: 551.2586s\n",
      "\titers: 900, epoch: 8 | loss: 0.0704616\n",
      "\tspeed: 0.0505s/iter; left time: 546.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0728395 Vali Loss: 0.0874766 Test Loss: 0.0982277\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0669056\n",
      "\tspeed: 0.1385s/iter; left time: 1485.4205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704915\n",
      "\tspeed: 0.0505s/iter; left time: 536.4953s\n",
      "\titers: 300, epoch: 9 | loss: 0.0730468\n",
      "\tspeed: 0.0505s/iter; left time: 531.1503s\n",
      "\titers: 400, epoch: 9 | loss: 0.0681769\n",
      "\tspeed: 0.0504s/iter; left time: 525.8961s\n",
      "\titers: 500, epoch: 9 | loss: 0.0706938\n",
      "\tspeed: 0.0504s/iter; left time: 520.7010s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717596\n",
      "\tspeed: 0.0504s/iter; left time: 515.5981s\n",
      "\titers: 700, epoch: 9 | loss: 0.0657810\n",
      "\tspeed: 0.0504s/iter; left time: 510.4238s\n",
      "\titers: 800, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0504s/iter; left time: 505.3338s\n",
      "\titers: 900, epoch: 9 | loss: 0.0668692\n",
      "\tspeed: 0.0504s/iter; left time: 500.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0693792 Vali Loss: 0.0873247 Test Loss: 0.0969773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020803824067115784, rmse:0.14423531293869019, mae:0.09436223655939102, rse:0.5457460880279541\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2284859\n",
      "\tspeed: 0.0530s/iter; left time: 950.1871s\n",
      "\titers: 200, epoch: 1 | loss: 0.2267227\n",
      "\tspeed: 0.0508s/iter; left time: 906.6906s\n",
      "\titers: 300, epoch: 1 | loss: 0.2108397\n",
      "\tspeed: 0.0504s/iter; left time: 893.5250s\n",
      "\titers: 400, epoch: 1 | loss: 0.2069933\n",
      "\tspeed: 0.0504s/iter; left time: 889.6918s\n",
      "\titers: 500, epoch: 1 | loss: 0.2013356\n",
      "\tspeed: 0.0504s/iter; left time: 884.5309s\n",
      "\titers: 600, epoch: 1 | loss: 0.1998173\n",
      "\tspeed: 0.0504s/iter; left time: 879.8400s\n",
      "\titers: 700, epoch: 1 | loss: 0.1979535\n",
      "\tspeed: 0.0507s/iter; left time: 879.3869s\n",
      "\titers: 800, epoch: 1 | loss: 0.1894962\n",
      "\tspeed: 0.0504s/iter; left time: 869.3943s\n",
      "\titers: 900, epoch: 1 | loss: 0.1864503\n",
      "\tspeed: 0.0504s/iter; left time: 864.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.2082656 Vali Loss: 0.1732536 Test Loss: 0.1907203\n",
      "Validation loss decreased (inf --> 0.173254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1713080\n",
      "\tspeed: 0.1403s/iter; left time: 2391.2121s\n",
      "\titers: 200, epoch: 2 | loss: 0.1709103\n",
      "\tspeed: 0.0504s/iter; left time: 853.8744s\n",
      "\titers: 300, epoch: 2 | loss: 0.1648743\n",
      "\tspeed: 0.0504s/iter; left time: 849.1595s\n",
      "\titers: 400, epoch: 2 | loss: 0.1496821\n",
      "\tspeed: 0.0506s/iter; left time: 846.7754s\n",
      "\titers: 500, epoch: 2 | loss: 0.1361954\n",
      "\tspeed: 0.0506s/iter; left time: 841.4153s\n",
      "\titers: 600, epoch: 2 | loss: 0.1361084\n",
      "\tspeed: 0.0505s/iter; left time: 835.2886s\n",
      "\titers: 700, epoch: 2 | loss: 0.1295184\n",
      "\tspeed: 0.0504s/iter; left time: 829.2730s\n",
      "\titers: 800, epoch: 2 | loss: 0.1168782\n",
      "\tspeed: 0.0504s/iter; left time: 824.1832s\n",
      "\titers: 900, epoch: 2 | loss: 0.1084049\n",
      "\tspeed: 0.0504s/iter; left time: 819.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1460171 Vali Loss: 0.0987828 Test Loss: 0.1063009\n",
      "Validation loss decreased (0.173254 --> 0.098783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1028040\n",
      "\tspeed: 0.1409s/iter; left time: 2274.2749s\n",
      "\titers: 200, epoch: 3 | loss: 0.1012544\n",
      "\tspeed: 0.0504s/iter; left time: 808.7178s\n",
      "\titers: 300, epoch: 3 | loss: 0.0942322\n",
      "\tspeed: 0.0505s/iter; left time: 804.2001s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913546\n",
      "\tspeed: 0.0505s/iter; left time: 799.2814s\n",
      "\titers: 500, epoch: 3 | loss: 0.0966000\n",
      "\tspeed: 0.0506s/iter; left time: 796.0874s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914325\n",
      "\tspeed: 0.0505s/iter; left time: 789.9978s\n",
      "\titers: 700, epoch: 3 | loss: 0.0900648\n",
      "\tspeed: 0.0504s/iter; left time: 783.6762s\n",
      "\titers: 800, epoch: 3 | loss: 0.0941671\n",
      "\tspeed: 0.0504s/iter; left time: 778.7342s\n",
      "\titers: 900, epoch: 3 | loss: 0.0972075\n",
      "\tspeed: 0.0504s/iter; left time: 773.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0964605 Vali Loss: 0.0890032 Test Loss: 0.0937895\n",
      "Validation loss decreased (0.098783 --> 0.089003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857249\n",
      "\tspeed: 0.1414s/iter; left time: 2154.7841s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923728\n",
      "\tspeed: 0.0510s/iter; left time: 772.5200s\n",
      "\titers: 300, epoch: 4 | loss: 0.0903793\n",
      "\tspeed: 0.0511s/iter; left time: 768.5896s\n",
      "\titers: 400, epoch: 4 | loss: 0.0886440\n",
      "\tspeed: 0.0510s/iter; left time: 761.8474s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932834\n",
      "\tspeed: 0.0510s/iter; left time: 757.3216s\n",
      "\titers: 600, epoch: 4 | loss: 0.0853107\n",
      "\tspeed: 0.0510s/iter; left time: 751.9702s\n",
      "\titers: 700, epoch: 4 | loss: 0.0900107\n",
      "\tspeed: 0.0510s/iter; left time: 746.5617s\n",
      "\titers: 800, epoch: 4 | loss: 0.0842938\n",
      "\tspeed: 0.0512s/iter; left time: 743.4796s\n",
      "\titers: 900, epoch: 4 | loss: 0.0850098\n",
      "\tspeed: 0.0510s/iter; left time: 736.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.39s\n",
      "Steps: 902 | Train Loss: 0.0881512 Vali Loss: 0.0848641 Test Loss: 0.0966458\n",
      "Validation loss decreased (0.089003 --> 0.084864).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882770\n",
      "\tspeed: 0.1422s/iter; left time: 2038.8512s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824666\n",
      "\tspeed: 0.0504s/iter; left time: 717.6569s\n",
      "\titers: 300, epoch: 5 | loss: 0.0812579\n",
      "\tspeed: 0.0504s/iter; left time: 712.7247s\n",
      "\titers: 400, epoch: 5 | loss: 0.0867619\n",
      "\tspeed: 0.0504s/iter; left time: 707.9227s\n",
      "\titers: 500, epoch: 5 | loss: 0.0906413\n",
      "\tspeed: 0.0504s/iter; left time: 702.4616s\n",
      "\titers: 600, epoch: 5 | loss: 0.0816955\n",
      "\tspeed: 0.0504s/iter; left time: 697.5462s\n",
      "\titers: 700, epoch: 5 | loss: 0.0825760\n",
      "\tspeed: 0.0504s/iter; left time: 692.3392s\n",
      "\titers: 800, epoch: 5 | loss: 0.0871430\n",
      "\tspeed: 0.0505s/iter; left time: 688.0002s\n",
      "\titers: 900, epoch: 5 | loss: 0.0818188\n",
      "\tspeed: 0.0505s/iter; left time: 682.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0832878 Vali Loss: 0.0822736 Test Loss: 0.0991102\n",
      "Validation loss decreased (0.084864 --> 0.082274).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807753\n",
      "\tspeed: 0.1417s/iter; left time: 1903.7318s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926194\n",
      "\tspeed: 0.0504s/iter; left time: 672.3669s\n",
      "\titers: 300, epoch: 6 | loss: 0.0734528\n",
      "\tspeed: 0.0504s/iter; left time: 667.3297s\n",
      "\titers: 400, epoch: 6 | loss: 0.0836199\n",
      "\tspeed: 0.0504s/iter; left time: 662.0244s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807985\n",
      "\tspeed: 0.0504s/iter; left time: 657.1533s\n",
      "\titers: 600, epoch: 6 | loss: 0.0781274\n",
      "\tspeed: 0.0504s/iter; left time: 651.9781s\n",
      "\titers: 700, epoch: 6 | loss: 0.0795121\n",
      "\tspeed: 0.0504s/iter; left time: 647.0378s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790593\n",
      "\tspeed: 0.0505s/iter; left time: 642.5466s\n",
      "\titers: 900, epoch: 6 | loss: 0.0770177\n",
      "\tspeed: 0.0504s/iter; left time: 637.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0793978 Vali Loss: 0.0833777 Test Loss: 0.0989826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754626\n",
      "\tspeed: 0.1373s/iter; left time: 1720.0845s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837843\n",
      "\tspeed: 0.0504s/iter; left time: 626.6227s\n",
      "\titers: 300, epoch: 7 | loss: 0.0735349\n",
      "\tspeed: 0.0505s/iter; left time: 622.1110s\n",
      "\titers: 400, epoch: 7 | loss: 0.0791819\n",
      "\tspeed: 0.0505s/iter; left time: 617.3518s\n",
      "\titers: 500, epoch: 7 | loss: 0.0693690\n",
      "\tspeed: 0.0504s/iter; left time: 611.2815s\n",
      "\titers: 600, epoch: 7 | loss: 0.0743524\n",
      "\tspeed: 0.0504s/iter; left time: 606.8297s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732933\n",
      "\tspeed: 0.0505s/iter; left time: 602.0026s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761782\n",
      "\tspeed: 0.0504s/iter; left time: 596.3598s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737806\n",
      "\tspeed: 0.0505s/iter; left time: 591.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0760379 Vali Loss: 0.0858319 Test Loss: 0.0968157\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726987\n",
      "\tspeed: 0.1384s/iter; left time: 1609.0217s\n",
      "\titers: 200, epoch: 8 | loss: 0.0783981\n",
      "\tspeed: 0.0504s/iter; left time: 581.5175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806944\n",
      "\tspeed: 0.0505s/iter; left time: 576.9424s\n",
      "\titers: 400, epoch: 8 | loss: 0.0715075\n",
      "\tspeed: 0.0505s/iter; left time: 572.5696s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0504s/iter; left time: 566.3231s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702019\n",
      "\tspeed: 0.0505s/iter; left time: 561.4528s\n",
      "\titers: 700, epoch: 8 | loss: 0.0728789\n",
      "\tspeed: 0.0504s/iter; left time: 556.0862s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746686\n",
      "\tspeed: 0.0504s/iter; left time: 551.0988s\n",
      "\titers: 900, epoch: 8 | loss: 0.0702752\n",
      "\tspeed: 0.0504s/iter; left time: 545.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0726852 Vali Loss: 0.0867959 Test Loss: 0.0998598\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0709978\n",
      "\tspeed: 0.1381s/iter; left time: 1481.3268s\n",
      "\titers: 200, epoch: 9 | loss: 0.0679601\n",
      "\tspeed: 0.0510s/iter; left time: 541.8042s\n",
      "\titers: 300, epoch: 9 | loss: 0.0751877\n",
      "\tspeed: 0.0511s/iter; left time: 537.3441s\n",
      "\titers: 400, epoch: 9 | loss: 0.0699946\n",
      "\tspeed: 0.0510s/iter; left time: 531.8428s\n",
      "\titers: 500, epoch: 9 | loss: 0.0732694\n",
      "\tspeed: 0.0511s/iter; left time: 527.1437s\n",
      "\titers: 600, epoch: 9 | loss: 0.0649203\n",
      "\tspeed: 0.0510s/iter; left time: 521.5651s\n",
      "\titers: 700, epoch: 9 | loss: 0.0642313\n",
      "\tspeed: 0.0510s/iter; left time: 516.1117s\n",
      "\titers: 800, epoch: 9 | loss: 0.0708400\n",
      "\tspeed: 0.0510s/iter; left time: 511.2901s\n",
      "\titers: 900, epoch: 9 | loss: 0.0663069\n",
      "\tspeed: 0.0506s/iter; left time: 501.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 902 | Train Loss: 0.0691620 Vali Loss: 0.0897910 Test Loss: 0.1007773\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0708059\n",
      "\tspeed: 0.1368s/iter; left time: 1344.0071s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699524\n",
      "\tspeed: 0.0504s/iter; left time: 490.3308s\n",
      "\titers: 300, epoch: 10 | loss: 0.0707789\n",
      "\tspeed: 0.0504s/iter; left time: 485.3786s\n",
      "\titers: 400, epoch: 10 | loss: 0.0686859\n",
      "\tspeed: 0.0504s/iter; left time: 480.1413s\n",
      "\titers: 500, epoch: 10 | loss: 0.0652517\n",
      "\tspeed: 0.0504s/iter; left time: 474.8593s\n",
      "\titers: 600, epoch: 10 | loss: 0.0646466\n",
      "\tspeed: 0.0504s/iter; left time: 470.0499s\n",
      "\titers: 700, epoch: 10 | loss: 0.0682247\n",
      "\tspeed: 0.0504s/iter; left time: 465.0166s\n",
      "\titers: 800, epoch: 10 | loss: 0.0651449\n",
      "\tspeed: 0.0506s/iter; left time: 461.9457s\n",
      "\titers: 900, epoch: 10 | loss: 0.0604966\n",
      "\tspeed: 0.0505s/iter; left time: 455.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0659150 Vali Loss: 0.0909240 Test Loss: 0.1030022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023398978635668755, rmse:0.15296724438667297, mae:0.09908542037010193, rse:0.578785240650177\n",
      "Intermediate time for IT and pred_len 168: 00h:17m:32.00s\n",
      "Intermediate time for IT: 00h:58m:20.06s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[26], line 98\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m hours, mins, secs \u001b[38;5;241m=\u001b[39m running_time(start, end)\n",
      "\u001b[1;32m     97\u001b[0m statement_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time: \u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mm:\u001b[39m\u001b[38;5;132;01m{:05.2f}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hours, mins, secs)\n",
      "\u001b[0;32m---> 98\u001b[0m \u001b[43mlog_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement_5\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(statement_5)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0263  0.1622  0.1042\n",
       "        96         0.0430  0.2074  0.1434\n",
       "        168        0.0534  0.2311  0.1585\n",
       "ES      24         0.0234  0.1523  0.0922\n",
       "        96         0.0526  0.2293  0.1431\n",
       "        168        0.0523  0.2281  0.1467\n",
       "FR      24         0.0125  0.1117  0.0636\n",
       "        96         0.0225  0.1499  0.0897\n",
       "        168        0.0243  0.1559  0.0971\n",
       "GB      24         0.0325  0.1802  0.1202\n",
       "        96         0.0506  0.2249  0.1575\n",
       "        168        0.0603  0.2454  0.1703\n",
       "IT      24         0.0126  0.1120  0.0657\n",
       "        96         0.0208  0.1441  0.0887\n",
       "        168        0.0221  0.1486  0.0967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 336\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1367688\n",
      "\tspeed: 0.0628s/iter; left time: 1400.2306s\n",
      "\titers: 200, epoch: 1 | loss: 0.1245904\n",
      "\tspeed: 0.0345s/iter; left time: 765.3702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 224 | Train Loss: 0.1417825 Vali Loss: 0.1297619 Test Loss: 0.1346998\n",
      "Validation loss decreased (inf --> 0.129762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0874328\n",
      "\tspeed: 0.0635s/iter; left time: 1401.7784s\n",
      "\titers: 200, epoch: 2 | loss: 0.0836909\n",
      "\tspeed: 0.0345s/iter; left time: 757.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0895919 Vali Loss: 0.0937259 Test Loss: 0.0950073\n",
      "Validation loss decreased (0.129762 --> 0.093726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0783313\n",
      "\tspeed: 0.0633s/iter; left time: 1384.1834s\n",
      "\titers: 200, epoch: 3 | loss: 0.0797411\n",
      "\tspeed: 0.0345s/iter; left time: 749.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0798404 Vali Loss: 0.0909569 Test Loss: 0.0923144\n",
      "Validation loss decreased (0.093726 --> 0.090957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808882\n",
      "\tspeed: 0.0628s/iter; left time: 1359.2269s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815994\n",
      "\tspeed: 0.0345s/iter; left time: 742.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0774217 Vali Loss: 0.0891894 Test Loss: 0.0911084\n",
      "Validation loss decreased (0.090957 --> 0.089189).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0768369\n",
      "\tspeed: 0.0632s/iter; left time: 1352.9602s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743422\n",
      "\tspeed: 0.0344s/iter; left time: 733.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0758960 Vali Loss: 0.0885748 Test Loss: 0.0902168\n",
      "Validation loss decreased (0.089189 --> 0.088575).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834458\n",
      "\tspeed: 0.0628s/iter; left time: 1329.6335s\n",
      "\titers: 200, epoch: 6 | loss: 0.0734622\n",
      "\tspeed: 0.0346s/iter; left time: 729.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0749218 Vali Loss: 0.0881808 Test Loss: 0.0901664\n",
      "Validation loss decreased (0.088575 --> 0.088181).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0725648\n",
      "\tspeed: 0.0633s/iter; left time: 1326.1223s\n",
      "\titers: 200, epoch: 7 | loss: 0.0770377\n",
      "\tspeed: 0.0345s/iter; left time: 719.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0741599 Vali Loss: 0.0878329 Test Loss: 0.0895589\n",
      "Validation loss decreased (0.088181 --> 0.087833).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711806\n",
      "\tspeed: 0.0636s/iter; left time: 1317.6002s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732410\n",
      "\tspeed: 0.0345s/iter; left time: 712.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0736808 Vali Loss: 0.0885085 Test Loss: 0.0895575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778364\n",
      "\tspeed: 0.0624s/iter; left time: 1279.5035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757419\n",
      "\tspeed: 0.0347s/iter; left time: 707.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0733049 Vali Loss: 0.0876978 Test Loss: 0.0892725\n",
      "Validation loss decreased (0.087833 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0761590\n",
      "\tspeed: 0.0636s/iter; left time: 1289.7004s\n",
      "\titers: 200, epoch: 10 | loss: 0.0707892\n",
      "\tspeed: 0.0345s/iter; left time: 696.8224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0727617 Vali Loss: 0.0874244 Test Loss: 0.0888162\n",
      "Validation loss decreased (0.087698 --> 0.087424).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0676915\n",
      "\tspeed: 0.0635s/iter; left time: 1274.3989s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720713\n",
      "\tspeed: 0.0345s/iter; left time: 689.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0725552 Vali Loss: 0.0870095 Test Loss: 0.0886139\n",
      "Validation loss decreased (0.087424 --> 0.087009).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712213\n",
      "\tspeed: 0.0647s/iter; left time: 1283.4834s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730992\n",
      "\tspeed: 0.0350s/iter; left time: 691.6769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0722883 Vali Loss: 0.0866656 Test Loss: 0.0887256\n",
      "Validation loss decreased (0.087009 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0674988\n",
      "\tspeed: 0.0642s/iter; left time: 1259.2798s\n",
      "\titers: 200, epoch: 13 | loss: 0.0707361\n",
      "\tspeed: 0.0351s/iter; left time: 685.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0719704 Vali Loss: 0.0869405 Test Loss: 0.0882807\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707829\n",
      "\tspeed: 0.0645s/iter; left time: 1250.1434s\n",
      "\titers: 200, epoch: 14 | loss: 0.0731093\n",
      "\tspeed: 0.0345s/iter; left time: 665.6738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0718117 Vali Loss: 0.0862150 Test Loss: 0.0881431\n",
      "Validation loss decreased (0.086666 --> 0.086215).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719475\n",
      "\tspeed: 0.0639s/iter; left time: 1223.7001s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660407\n",
      "\tspeed: 0.0345s/iter; left time: 658.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0716887 Vali Loss: 0.0862614 Test Loss: 0.0880773\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0720187\n",
      "\tspeed: 0.0624s/iter; left time: 1181.7610s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700876\n",
      "\tspeed: 0.0345s/iter; left time: 650.7287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0715163 Vali Loss: 0.0862754 Test Loss: 0.0883428\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0736424\n",
      "\tspeed: 0.0628s/iter; left time: 1175.3796s\n",
      "\titers: 200, epoch: 17 | loss: 0.0725535\n",
      "\tspeed: 0.0350s/iter; left time: 651.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0714457 Vali Loss: 0.0860176 Test Loss: 0.0878601\n",
      "Validation loss decreased (0.086215 --> 0.086018).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720800\n",
      "\tspeed: 0.0662s/iter; left time: 1224.6140s\n",
      "\titers: 200, epoch: 18 | loss: 0.0806113\n",
      "\tspeed: 0.0350s/iter; left time: 644.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0713567 Vali Loss: 0.0858511 Test Loss: 0.0880465\n",
      "Validation loss decreased (0.086018 --> 0.085851).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661596\n",
      "\tspeed: 0.0644s/iter; left time: 1177.2278s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682769\n",
      "\tspeed: 0.0350s/iter; left time: 636.6683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0712430 Vali Loss: 0.0859923 Test Loss: 0.0881765\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0680708\n",
      "\tspeed: 0.0637s/iter; left time: 1148.6941s\n",
      "\titers: 200, epoch: 20 | loss: 0.0721421\n",
      "\tspeed: 0.0351s/iter; left time: 629.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0710715 Vali Loss: 0.0858214 Test Loss: 0.0879637\n",
      "Validation loss decreased (0.085851 --> 0.085821).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0671154\n",
      "\tspeed: 0.0645s/iter; left time: 1149.0170s\n",
      "\titers: 200, epoch: 21 | loss: 0.0730100\n",
      "\tspeed: 0.0350s/iter; left time: 619.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0709879 Vali Loss: 0.0858328 Test Loss: 0.0878991\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0640760\n",
      "\tspeed: 0.0634s/iter; left time: 1114.8550s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681176\n",
      "\tspeed: 0.0351s/iter; left time: 613.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0709690 Vali Loss: 0.0858622 Test Loss: 0.0879610\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0712698\n",
      "\tspeed: 0.0636s/iter; left time: 1104.4965s\n",
      "\titers: 200, epoch: 23 | loss: 0.0667570\n",
      "\tspeed: 0.0351s/iter; left time: 605.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0708771 Vali Loss: 0.0858069 Test Loss: 0.0878305\n",
      "Validation loss decreased (0.085821 --> 0.085807).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0693972\n",
      "\tspeed: 0.0651s/iter; left time: 1115.8562s\n",
      "\titers: 200, epoch: 24 | loss: 0.0692556\n",
      "\tspeed: 0.0351s/iter; left time: 597.9210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0708486 Vali Loss: 0.0856658 Test Loss: 0.0877898\n",
      "Validation loss decreased (0.085807 --> 0.085666).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0699250\n",
      "\tspeed: 0.0645s/iter; left time: 1091.0211s\n",
      "\titers: 200, epoch: 25 | loss: 0.0798727\n",
      "\tspeed: 0.0351s/iter; left time: 590.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0708131 Vali Loss: 0.0857214 Test Loss: 0.0877753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0697506\n",
      "\tspeed: 0.0649s/iter; left time: 1084.2420s\n",
      "\titers: 200, epoch: 26 | loss: 0.0687230\n",
      "\tspeed: 0.0351s/iter; left time: 581.9424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0707461 Vali Loss: 0.0856136 Test Loss: 0.0875972\n",
      "Validation loss decreased (0.085666 --> 0.085614).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0745587\n",
      "\tspeed: 0.0651s/iter; left time: 1073.4175s\n",
      "\titers: 200, epoch: 27 | loss: 0.0744420\n",
      "\tspeed: 0.0351s/iter; left time: 574.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0706360 Vali Loss: 0.0857599 Test Loss: 0.0877222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0682002\n",
      "\tspeed: 0.0640s/iter; left time: 1040.4624s\n",
      "\titers: 200, epoch: 28 | loss: 0.0733372\n",
      "\tspeed: 0.0351s/iter; left time: 567.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0706084 Vali Loss: 0.0856512 Test Loss: 0.0877045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0717218\n",
      "\tspeed: 0.0634s/iter; left time: 1016.2640s\n",
      "\titers: 200, epoch: 29 | loss: 0.0664676\n",
      "\tspeed: 0.0347s/iter; left time: 553.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0706563 Vali Loss: 0.0856150 Test Loss: 0.0877161\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0762165\n",
      "\tspeed: 0.0641s/iter; left time: 1012.6755s\n",
      "\titers: 200, epoch: 30 | loss: 0.0719173\n",
      "\tspeed: 0.0351s/iter; left time: 551.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0705385 Vali Loss: 0.0856017 Test Loss: 0.0877515\n",
      "Validation loss decreased (0.085614 --> 0.085602).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0697288\n",
      "\tspeed: 0.0657s/iter; left time: 1024.1216s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669441\n",
      "\tspeed: 0.0351s/iter; left time: 543.4688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0705516 Vali Loss: 0.0855314 Test Loss: 0.0876253\n",
      "Validation loss decreased (0.085602 --> 0.085531).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0652949\n",
      "\tspeed: 0.0647s/iter; left time: 993.4007s\n",
      "\titers: 200, epoch: 32 | loss: 0.0733190\n",
      "\tspeed: 0.0351s/iter; left time: 535.4359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.0705164 Vali Loss: 0.0855905 Test Loss: 0.0876133\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0756751\n",
      "\tspeed: 0.0634s/iter; left time: 960.0686s\n",
      "\titers: 200, epoch: 33 | loss: 0.0652215\n",
      "\tspeed: 0.0350s/iter; left time: 526.3089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0705262 Vali Loss: 0.0855893 Test Loss: 0.0876473\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0703901\n",
      "\tspeed: 0.0640s/iter; left time: 954.4139s\n",
      "\titers: 200, epoch: 34 | loss: 0.0733109\n",
      "\tspeed: 0.0351s/iter; left time: 520.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0704702 Vali Loss: 0.0856044 Test Loss: 0.0876274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0708346\n",
      "\tspeed: 0.0647s/iter; left time: 949.6245s\n",
      "\titers: 200, epoch: 35 | loss: 0.0658687\n",
      "\tspeed: 0.0351s/iter; left time: 512.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0704458 Vali Loss: 0.0855822 Test Loss: 0.0876436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0695963\n",
      "\tspeed: 0.0641s/iter; left time: 927.1935s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763912\n",
      "\tspeed: 0.0350s/iter; left time: 502.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0704712 Vali Loss: 0.0856099 Test Loss: 0.0876519\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0776208\n",
      "\tspeed: 0.0651s/iter; left time: 926.7347s\n",
      "\titers: 200, epoch: 37 | loss: 0.0732721\n",
      "\tspeed: 0.0350s/iter; left time: 495.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0704133 Vali Loss: 0.0856230 Test Loss: 0.0876302\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0693206\n",
      "\tspeed: 0.0647s/iter; left time: 906.4526s\n",
      "\titers: 200, epoch: 38 | loss: 0.0663587\n",
      "\tspeed: 0.0351s/iter; left time: 487.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0704773 Vali Loss: 0.0855760 Test Loss: 0.0876636\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0746389\n",
      "\tspeed: 0.0641s/iter; left time: 884.4819s\n",
      "\titers: 200, epoch: 39 | loss: 0.0675292\n",
      "\tspeed: 0.0350s/iter; left time: 479.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0703812 Vali Loss: 0.0855172 Test Loss: 0.0876569\n",
      "Validation loss decreased (0.085531 --> 0.085517).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0679469\n",
      "\tspeed: 0.0652s/iter; left time: 884.0008s\n",
      "\titers: 200, epoch: 40 | loss: 0.0760854\n",
      "\tspeed: 0.0351s/iter; left time: 472.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0703983 Vali Loss: 0.0856338 Test Loss: 0.0876461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0657282\n",
      "\tspeed: 0.0642s/iter; left time: 856.6081s\n",
      "\titers: 200, epoch: 41 | loss: 0.0685808\n",
      "\tspeed: 0.0351s/iter; left time: 464.3759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0704297 Vali Loss: 0.0854791 Test Loss: 0.0876108\n",
      "Validation loss decreased (0.085517 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0685432\n",
      "\tspeed: 0.0645s/iter; left time: 846.5376s\n",
      "\titers: 200, epoch: 42 | loss: 0.0772268\n",
      "\tspeed: 0.0350s/iter; left time: 456.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0704295 Vali Loss: 0.0856170 Test Loss: 0.0876517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0754281\n",
      "\tspeed: 0.0636s/iter; left time: 820.4934s\n",
      "\titers: 200, epoch: 43 | loss: 0.0719534\n",
      "\tspeed: 0.0351s/iter; left time: 448.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0704678 Vali Loss: 0.0855464 Test Loss: 0.0876139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0648393\n",
      "\tspeed: 0.0643s/iter; left time: 814.3549s\n",
      "\titers: 200, epoch: 44 | loss: 0.0716240\n",
      "\tspeed: 0.0350s/iter; left time: 440.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0703761 Vali Loss: 0.0855283 Test Loss: 0.0876206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0702064\n",
      "\tspeed: 0.0641s/iter; left time: 797.7895s\n",
      "\titers: 200, epoch: 45 | loss: 0.0723583\n",
      "\tspeed: 0.0350s/iter; left time: 432.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703306 Vali Loss: 0.0855358 Test Loss: 0.0876488\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0701229\n",
      "\tspeed: 0.0640s/iter; left time: 782.3163s\n",
      "\titers: 200, epoch: 46 | loss: 0.0754933\n",
      "\tspeed: 0.0350s/iter; left time: 424.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703833 Vali Loss: 0.0855528 Test Loss: 0.0876253\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0710274\n",
      "\tspeed: 0.0636s/iter; left time: 763.3012s\n",
      "\titers: 200, epoch: 47 | loss: 0.0696812\n",
      "\tspeed: 0.0350s/iter; left time: 416.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0702940 Vali Loss: 0.0855598 Test Loss: 0.0876733\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0711155\n",
      "\tspeed: 0.0637s/iter; left time: 750.0359s\n",
      "\titers: 200, epoch: 48 | loss: 0.0701874\n",
      "\tspeed: 0.0350s/iter; left time: 408.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703315 Vali Loss: 0.0855006 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0714043\n",
      "\tspeed: 0.0633s/iter; left time: 731.4278s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752779\n",
      "\tspeed: 0.0351s/iter; left time: 401.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0703117 Vali Loss: 0.0853899 Test Loss: 0.0876294\n",
      "Validation loss decreased (0.085479 --> 0.085390).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0675540\n",
      "\tspeed: 0.0640s/iter; left time: 724.8751s\n",
      "\titers: 200, epoch: 50 | loss: 0.0672784\n",
      "\tspeed: 0.0346s/iter; left time: 388.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0703544 Vali Loss: 0.0856176 Test Loss: 0.0876256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0672196\n",
      "\tspeed: 0.0634s/iter; left time: 703.6005s\n",
      "\titers: 200, epoch: 51 | loss: 0.0705316\n",
      "\tspeed: 0.0350s/iter; left time: 385.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0703640 Vali Loss: 0.0855282 Test Loss: 0.0876138\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0726501\n",
      "\tspeed: 0.0631s/iter; left time: 686.5334s\n",
      "\titers: 200, epoch: 52 | loss: 0.0750476\n",
      "\tspeed: 0.0349s/iter; left time: 376.5507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0702915 Vali Loss: 0.0854718 Test Loss: 0.0876108\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0707266\n",
      "\tspeed: 0.0647s/iter; left time: 689.6367s\n",
      "\titers: 200, epoch: 53 | loss: 0.0753433\n",
      "\tspeed: 0.0350s/iter; left time: 369.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703226 Vali Loss: 0.0855451 Test Loss: 0.0876203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0707714\n",
      "\tspeed: 0.0643s/iter; left time: 670.5706s\n",
      "\titers: 200, epoch: 54 | loss: 0.0693999\n",
      "\tspeed: 0.0351s/iter; left time: 362.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.0702514 Vali Loss: 0.0855230 Test Loss: 0.0876223\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0683633\n",
      "\tspeed: 0.0641s/iter; left time: 653.6339s\n",
      "\titers: 200, epoch: 55 | loss: 0.0732801\n",
      "\tspeed: 0.0351s/iter; left time: 354.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703378 Vali Loss: 0.0854774 Test Loss: 0.0876248\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0726792\n",
      "\tspeed: 0.0639s/iter; left time: 637.5809s\n",
      "\titers: 200, epoch: 56 | loss: 0.0682346\n",
      "\tspeed: 0.0350s/iter; left time: 346.2214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703922 Vali Loss: 0.0854243 Test Loss: 0.0876170\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0713991\n",
      "\tspeed: 0.0637s/iter; left time: 621.7716s\n",
      "\titers: 200, epoch: 57 | loss: 0.0715152\n",
      "\tspeed: 0.0351s/iter; left time: 338.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703222 Vali Loss: 0.0855278 Test Loss: 0.0876308\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0724774\n",
      "\tspeed: 0.0642s/iter; left time: 611.7987s\n",
      "\titers: 200, epoch: 58 | loss: 0.0744438\n",
      "\tspeed: 0.0350s/iter; left time: 330.5905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0703177 Vali Loss: 0.0855277 Test Loss: 0.0876161\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0699353\n",
      "\tspeed: 0.0631s/iter; left time: 587.1480s\n",
      "\titers: 200, epoch: 59 | loss: 0.0727263\n",
      "\tspeed: 0.0351s/iter; left time: 322.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0702569 Vali Loss: 0.0854934 Test Loss: 0.0876463\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02089524082839489, rmse:0.1445518583059311, mae:0.08762942254543304, rse:0.5101435780525208\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1392107\n",
      "\tspeed: 0.0367s/iter; left time: 819.2585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1223771\n",
      "\tspeed: 0.0351s/iter; left time: 778.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1422910 Vali Loss: 0.1295708 Test Loss: 0.1351053\n",
      "Validation loss decreased (inf --> 0.129571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0875246\n",
      "\tspeed: 0.0641s/iter; left time: 1414.8089s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827769\n",
      "\tspeed: 0.0346s/iter; left time: 760.8563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0894109 Vali Loss: 0.0936834 Test Loss: 0.0941651\n",
      "Validation loss decreased (0.129571 --> 0.093683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0772660\n",
      "\tspeed: 0.0643s/iter; left time: 1404.3236s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733927\n",
      "\tspeed: 0.0350s/iter; left time: 761.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0796623 Vali Loss: 0.0904186 Test Loss: 0.0915907\n",
      "Validation loss decreased (0.093683 --> 0.090419).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0783105\n",
      "\tspeed: 0.0636s/iter; left time: 1375.9841s\n",
      "\titers: 200, epoch: 4 | loss: 0.0769419\n",
      "\tspeed: 0.0347s/iter; left time: 747.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0773948 Vali Loss: 0.0894107 Test Loss: 0.0908844\n",
      "Validation loss decreased (0.090419 --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0744560\n",
      "\tspeed: 0.0657s/iter; left time: 1406.5184s\n",
      "\titers: 200, epoch: 5 | loss: 0.0756037\n",
      "\tspeed: 0.0349s/iter; left time: 742.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0760975 Vali Loss: 0.0888506 Test Loss: 0.0901179\n",
      "Validation loss decreased (0.089411 --> 0.088851).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0701576\n",
      "\tspeed: 0.0640s/iter; left time: 1356.6075s\n",
      "\titers: 200, epoch: 6 | loss: 0.0759827\n",
      "\tspeed: 0.0350s/iter; left time: 738.6457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0751048 Vali Loss: 0.0878141 Test Loss: 0.0899050\n",
      "Validation loss decreased (0.088851 --> 0.087814).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718560\n",
      "\tspeed: 0.0642s/iter; left time: 1344.5501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0740832\n",
      "\tspeed: 0.0350s/iter; left time: 730.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0743345 Vali Loss: 0.0880151 Test Loss: 0.0895214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0741832\n",
      "\tspeed: 0.0634s/iter; left time: 1314.3061s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740128\n",
      "\tspeed: 0.0350s/iter; left time: 722.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0737370 Vali Loss: 0.0874614 Test Loss: 0.0890989\n",
      "Validation loss decreased (0.087814 --> 0.087461).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0691896\n",
      "\tspeed: 0.0642s/iter; left time: 1317.2019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0766630\n",
      "\tspeed: 0.0350s/iter; left time: 714.6621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0733119 Vali Loss: 0.0871451 Test Loss: 0.0889235\n",
      "Validation loss decreased (0.087461 --> 0.087145).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0766472\n",
      "\tspeed: 0.0641s/iter; left time: 1300.4002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0736008\n",
      "\tspeed: 0.0350s/iter; left time: 707.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0729019 Vali Loss: 0.0868081 Test Loss: 0.0888383\n",
      "Validation loss decreased (0.087145 --> 0.086808).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0757230\n",
      "\tspeed: 0.0642s/iter; left time: 1287.6677s\n",
      "\titers: 200, epoch: 11 | loss: 0.0731116\n",
      "\tspeed: 0.0350s/iter; left time: 699.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0726183 Vali Loss: 0.0872676 Test Loss: 0.0886142\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0696218\n",
      "\tspeed: 0.0628s/iter; left time: 1245.7935s\n",
      "\titers: 200, epoch: 12 | loss: 0.0717855\n",
      "\tspeed: 0.0346s/iter; left time: 682.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0723210 Vali Loss: 0.0864866 Test Loss: 0.0882929\n",
      "Validation loss decreased (0.086808 --> 0.086487).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0699662\n",
      "\tspeed: 0.0642s/iter; left time: 1259.0415s\n",
      "\titers: 200, epoch: 13 | loss: 0.0678303\n",
      "\tspeed: 0.0350s/iter; left time: 682.5925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0721329 Vali Loss: 0.0864594 Test Loss: 0.0883254\n",
      "Validation loss decreased (0.086487 --> 0.086459).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0744527\n",
      "\tspeed: 0.0644s/iter; left time: 1249.1821s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712838\n",
      "\tspeed: 0.0350s/iter; left time: 675.9706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0718629 Vali Loss: 0.0865285 Test Loss: 0.0879603\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717863\n",
      "\tspeed: 0.0633s/iter; left time: 1213.9027s\n",
      "\titers: 200, epoch: 15 | loss: 0.0759115\n",
      "\tspeed: 0.0347s/iter; left time: 660.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0717239 Vali Loss: 0.0863706 Test Loss: 0.0881227\n",
      "Validation loss decreased (0.086459 --> 0.086371).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746718\n",
      "\tspeed: 0.0629s/iter; left time: 1191.8480s\n",
      "\titers: 200, epoch: 16 | loss: 0.0667765\n",
      "\tspeed: 0.0345s/iter; left time: 650.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0715664 Vali Loss: 0.0860702 Test Loss: 0.0879821\n",
      "Validation loss decreased (0.086371 --> 0.086070).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0709616\n",
      "\tspeed: 0.0637s/iter; left time: 1192.5170s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683452\n",
      "\tspeed: 0.0350s/iter; left time: 652.3987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0713874 Vali Loss: 0.0860104 Test Loss: 0.0880817\n",
      "Validation loss decreased (0.086070 --> 0.086010).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0693563\n",
      "\tspeed: 0.0640s/iter; left time: 1182.8188s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700895\n",
      "\tspeed: 0.0351s/iter; left time: 645.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0712817 Vali Loss: 0.0859047 Test Loss: 0.0879939\n",
      "Validation loss decreased (0.086010 --> 0.085905).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0706147\n",
      "\tspeed: 0.0658s/iter; left time: 1203.0016s\n",
      "\titers: 200, epoch: 19 | loss: 0.0703915\n",
      "\tspeed: 0.0351s/iter; left time: 637.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0711656 Vali Loss: 0.0858420 Test Loss: 0.0879358\n",
      "Validation loss decreased (0.085905 --> 0.085842).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0707204\n",
      "\tspeed: 0.0643s/iter; left time: 1161.1114s\n",
      "\titers: 200, epoch: 20 | loss: 0.0687749\n",
      "\tspeed: 0.0347s/iter; left time: 622.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0711148 Vali Loss: 0.0861993 Test Loss: 0.0881098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0706116\n",
      "\tspeed: 0.0628s/iter; left time: 1119.3175s\n",
      "\titers: 200, epoch: 21 | loss: 0.0679988\n",
      "\tspeed: 0.0346s/iter; left time: 612.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0709843 Vali Loss: 0.0860575 Test Loss: 0.0881536\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0746522\n",
      "\tspeed: 0.0635s/iter; left time: 1117.3407s\n",
      "\titers: 200, epoch: 22 | loss: 0.0689951\n",
      "\tspeed: 0.0351s/iter; left time: 613.2882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0709407 Vali Loss: 0.0859087 Test Loss: 0.0879257\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0744749\n",
      "\tspeed: 0.0639s/iter; left time: 1109.7295s\n",
      "\titers: 200, epoch: 23 | loss: 0.0743252\n",
      "\tspeed: 0.0350s/iter; left time: 605.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0709424 Vali Loss: 0.0857921 Test Loss: 0.0877810\n",
      "Validation loss decreased (0.085842 --> 0.085792).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0665782\n",
      "\tspeed: 0.0639s/iter; left time: 1095.9036s\n",
      "\titers: 200, epoch: 24 | loss: 0.0703265\n",
      "\tspeed: 0.0350s/iter; left time: 596.9037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0707643 Vali Loss: 0.0856805 Test Loss: 0.0881121\n",
      "Validation loss decreased (0.085792 --> 0.085680).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0697950\n",
      "\tspeed: 0.0659s/iter; left time: 1114.5497s\n",
      "\titers: 200, epoch: 25 | loss: 0.0696788\n",
      "\tspeed: 0.0350s/iter; left time: 589.0380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0707121 Vali Loss: 0.0857703 Test Loss: 0.0879429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0674330\n",
      "\tspeed: 0.0638s/iter; left time: 1066.3491s\n",
      "\titers: 200, epoch: 26 | loss: 0.0725871\n",
      "\tspeed: 0.0350s/iter; left time: 580.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0707476 Vali Loss: 0.0856222 Test Loss: 0.0878290\n",
      "Validation loss decreased (0.085680 --> 0.085622).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0723486\n",
      "\tspeed: 0.0643s/iter; left time: 1058.7603s\n",
      "\titers: 200, epoch: 27 | loss: 0.0718315\n",
      "\tspeed: 0.0351s/iter; left time: 574.1262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0706553 Vali Loss: 0.0857146 Test Loss: 0.0879704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0654385\n",
      "\tspeed: 0.0635s/iter; left time: 1032.2765s\n",
      "\titers: 200, epoch: 28 | loss: 0.0727765\n",
      "\tspeed: 0.0348s/iter; left time: 561.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0706182 Vali Loss: 0.0855102 Test Loss: 0.0878463\n",
      "Validation loss decreased (0.085622 --> 0.085510).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0711899\n",
      "\tspeed: 0.0637s/iter; left time: 1020.7695s\n",
      "\titers: 200, epoch: 29 | loss: 0.0700434\n",
      "\tspeed: 0.0350s/iter; left time: 558.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0705729 Vali Loss: 0.0858183 Test Loss: 0.0878769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0739872\n",
      "\tspeed: 0.0634s/iter; left time: 1002.3237s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765059\n",
      "\tspeed: 0.0350s/iter; left time: 549.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0705351 Vali Loss: 0.0855984 Test Loss: 0.0878054\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0739572\n",
      "\tspeed: 0.0632s/iter; left time: 984.7762s\n",
      "\titers: 200, epoch: 31 | loss: 0.0708882\n",
      "\tspeed: 0.0350s/iter; left time: 542.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0705233 Vali Loss: 0.0855951 Test Loss: 0.0878898\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0687875\n",
      "\tspeed: 0.0635s/iter; left time: 975.6175s\n",
      "\titers: 200, epoch: 32 | loss: 0.0646325\n",
      "\tspeed: 0.0350s/iter; left time: 534.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0705301 Vali Loss: 0.0855611 Test Loss: 0.0877873\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0695308\n",
      "\tspeed: 0.0636s/iter; left time: 962.5616s\n",
      "\titers: 200, epoch: 33 | loss: 0.0709703\n",
      "\tspeed: 0.0350s/iter; left time: 526.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0704562 Vali Loss: 0.0856102 Test Loss: 0.0878550\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0721221\n",
      "\tspeed: 0.0635s/iter; left time: 946.1815s\n",
      "\titers: 200, epoch: 34 | loss: 0.0697934\n",
      "\tspeed: 0.0350s/iter; left time: 518.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0704322 Vali Loss: 0.0856775 Test Loss: 0.0878189\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0723047\n",
      "\tspeed: 0.0633s/iter; left time: 929.7682s\n",
      "\titers: 200, epoch: 35 | loss: 0.0704416\n",
      "\tspeed: 0.0346s/iter; left time: 505.3163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0704091 Vali Loss: 0.0855530 Test Loss: 0.0878015\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697463\n",
      "\tspeed: 0.0639s/iter; left time: 923.6397s\n",
      "\titers: 200, epoch: 36 | loss: 0.0740611\n",
      "\tspeed: 0.0351s/iter; left time: 503.5750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0704309 Vali Loss: 0.0854530 Test Loss: 0.0877506\n",
      "Validation loss decreased (0.085510 --> 0.085453).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669694\n",
      "\tspeed: 0.0643s/iter; left time: 914.7893s\n",
      "\titers: 200, epoch: 37 | loss: 0.0725200\n",
      "\tspeed: 0.0351s/iter; left time: 495.8601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0703749 Vali Loss: 0.0856628 Test Loss: 0.0877849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0704496\n",
      "\tspeed: 0.0636s/iter; left time: 891.0638s\n",
      "\titers: 200, epoch: 38 | loss: 0.0702864\n",
      "\tspeed: 0.0347s/iter; left time: 482.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0703885 Vali Loss: 0.0855724 Test Loss: 0.0878162\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0651617\n",
      "\tspeed: 0.0632s/iter; left time: 871.0702s\n",
      "\titers: 200, epoch: 39 | loss: 0.0684052\n",
      "\tspeed: 0.0351s/iter; left time: 480.1610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0703234 Vali Loss: 0.0856100 Test Loss: 0.0878053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0719843\n",
      "\tspeed: 0.0638s/iter; left time: 865.9075s\n",
      "\titers: 200, epoch: 40 | loss: 0.0726390\n",
      "\tspeed: 0.0350s/iter; left time: 471.5732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703533 Vali Loss: 0.0855090 Test Loss: 0.0878113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0710737\n",
      "\tspeed: 0.0637s/iter; left time: 849.2821s\n",
      "\titers: 200, epoch: 41 | loss: 0.0723475\n",
      "\tspeed: 0.0350s/iter; left time: 463.7678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703102 Vali Loss: 0.0855023 Test Loss: 0.0877571\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0698876\n",
      "\tspeed: 0.0629s/iter; left time: 825.2851s\n",
      "\titers: 200, epoch: 42 | loss: 0.0711496\n",
      "\tspeed: 0.0345s/iter; left time: 449.2065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0702633 Vali Loss: 0.0856002 Test Loss: 0.0877695\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0757993\n",
      "\tspeed: 0.0627s/iter; left time: 808.1306s\n",
      "\titers: 200, epoch: 43 | loss: 0.0712027\n",
      "\tspeed: 0.0346s/iter; left time: 442.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0702882 Vali Loss: 0.0853861 Test Loss: 0.0877757\n",
      "Validation loss decreased (0.085453 --> 0.085386).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0706222\n",
      "\tspeed: 0.0645s/iter; left time: 817.0567s\n",
      "\titers: 200, epoch: 44 | loss: 0.0712676\n",
      "\tspeed: 0.0351s/iter; left time: 440.7956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0703147 Vali Loss: 0.0855626 Test Loss: 0.0877548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0697095\n",
      "\tspeed: 0.0635s/iter; left time: 790.6435s\n",
      "\titers: 200, epoch: 45 | loss: 0.0717822\n",
      "\tspeed: 0.0350s/iter; left time: 432.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703315 Vali Loss: 0.0854310 Test Loss: 0.0877551\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0681447\n",
      "\tspeed: 0.0637s/iter; left time: 778.3059s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663517\n",
      "\tspeed: 0.0350s/iter; left time: 424.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0702682 Vali Loss: 0.0855846 Test Loss: 0.0877398\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0777841\n",
      "\tspeed: 0.0632s/iter; left time: 757.8800s\n",
      "\titers: 200, epoch: 47 | loss: 0.0680706\n",
      "\tspeed: 0.0351s/iter; left time: 417.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0702969 Vali Loss: 0.0854859 Test Loss: 0.0877611\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0757864\n",
      "\tspeed: 0.0640s/iter; left time: 754.0087s\n",
      "\titers: 200, epoch: 48 | loss: 0.0718232\n",
      "\tspeed: 0.0351s/iter; left time: 409.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0703018 Vali Loss: 0.0854713 Test Loss: 0.0877413\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0736973\n",
      "\tspeed: 0.0635s/iter; left time: 733.4895s\n",
      "\titers: 200, epoch: 49 | loss: 0.0686348\n",
      "\tspeed: 0.0351s/iter; left time: 401.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0703128 Vali Loss: 0.0855502 Test Loss: 0.0877463\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0714738\n",
      "\tspeed: 0.0635s/iter; left time: 718.7358s\n",
      "\titers: 200, epoch: 50 | loss: 0.0690084\n",
      "\tspeed: 0.0349s/iter; left time: 391.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0702437 Vali Loss: 0.0855177 Test Loss: 0.0877286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0728555\n",
      "\tspeed: 0.0636s/iter; left time: 706.0794s\n",
      "\titers: 200, epoch: 51 | loss: 0.0691143\n",
      "\tspeed: 0.0350s/iter; left time: 385.2018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0702183 Vali Loss: 0.0855559 Test Loss: 0.0877540\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0702601\n",
      "\tspeed: 0.0633s/iter; left time: 688.6613s\n",
      "\titers: 200, epoch: 52 | loss: 0.0702171\n",
      "\tspeed: 0.0345s/iter; left time: 371.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0702743 Vali Loss: 0.0855097 Test Loss: 0.0877607\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0725170\n",
      "\tspeed: 0.0625s/iter; left time: 665.3974s\n",
      "\titers: 200, epoch: 53 | loss: 0.0697442\n",
      "\tspeed: 0.0350s/iter; left time: 369.8652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0702812 Vali Loss: 0.0855764 Test Loss: 0.0877520\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020985262468457222, rmse:0.14486290514469147, mae:0.08777573704719543, rse:0.5112412571907043\n",
      "Intermediate time for DE and pred_len 24: 00h:18m:39.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1482347\n",
      "\tspeed: 0.0555s/iter; left time: 1236.5948s\n",
      "\titers: 200, epoch: 1 | loss: 0.1378018\n",
      "\tspeed: 0.0349s/iter; left time: 774.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 224 | Train Loss: 0.1484325 Vali Loss: 0.1405515 Test Loss: 0.1490075\n",
      "Validation loss decreased (inf --> 0.140551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1195954\n",
      "\tspeed: 0.0657s/iter; left time: 1450.0514s\n",
      "\titers: 200, epoch: 2 | loss: 0.1069368\n",
      "\tspeed: 0.0350s/iter; left time: 768.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1145010 Vali Loss: 0.1213328 Test Loss: 0.1295046\n",
      "Validation loss decreased (0.140551 --> 0.121333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1037384\n",
      "\tspeed: 0.0653s/iter; left time: 1426.7104s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071076\n",
      "\tspeed: 0.0349s/iter; left time: 758.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1064909 Vali Loss: 0.1196142 Test Loss: 0.1285274\n",
      "Validation loss decreased (0.121333 --> 0.119614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1046638\n",
      "\tspeed: 0.0655s/iter; left time: 1417.1729s\n",
      "\titers: 200, epoch: 4 | loss: 0.1002790\n",
      "\tspeed: 0.0349s/iter; left time: 752.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1044976 Vali Loss: 0.1190749 Test Loss: 0.1282010\n",
      "Validation loss decreased (0.119614 --> 0.119075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1033227\n",
      "\tspeed: 0.0668s/iter; left time: 1430.7280s\n",
      "\titers: 200, epoch: 5 | loss: 0.0970878\n",
      "\tspeed: 0.0350s/iter; left time: 744.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1033116 Vali Loss: 0.1186551 Test Loss: 0.1275626\n",
      "Validation loss decreased (0.119075 --> 0.118655).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1100062\n",
      "\tspeed: 0.0664s/iter; left time: 1407.0752s\n",
      "\titers: 200, epoch: 6 | loss: 0.1083277\n",
      "\tspeed: 0.0349s/iter; left time: 736.3467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1024692 Vali Loss: 0.1179186 Test Loss: 0.1264673\n",
      "Validation loss decreased (0.118655 --> 0.117919).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021854\n",
      "\tspeed: 0.0656s/iter; left time: 1373.9547s\n",
      "\titers: 200, epoch: 7 | loss: 0.0952686\n",
      "\tspeed: 0.0349s/iter; left time: 728.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1016764 Vali Loss: 0.1185184 Test Loss: 0.1276702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995753\n",
      "\tspeed: 0.0638s/iter; left time: 1322.7426s\n",
      "\titers: 200, epoch: 8 | loss: 0.0976494\n",
      "\tspeed: 0.0349s/iter; left time: 719.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1011224 Vali Loss: 0.1183860 Test Loss: 0.1271428\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1000763\n",
      "\tspeed: 0.0640s/iter; left time: 1312.9803s\n",
      "\titers: 200, epoch: 9 | loss: 0.1019372\n",
      "\tspeed: 0.0349s/iter; left time: 713.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1005771 Vali Loss: 0.1178224 Test Loss: 0.1268350\n",
      "Validation loss decreased (0.117919 --> 0.117822).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1002124\n",
      "\tspeed: 0.0653s/iter; left time: 1325.4450s\n",
      "\titers: 200, epoch: 10 | loss: 0.0973505\n",
      "\tspeed: 0.0349s/iter; left time: 704.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1000270 Vali Loss: 0.1172706 Test Loss: 0.1271694\n",
      "Validation loss decreased (0.117822 --> 0.117271).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969001\n",
      "\tspeed: 0.0675s/iter; left time: 1354.8926s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031166\n",
      "\tspeed: 0.0349s/iter; left time: 697.3719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0997477 Vali Loss: 0.1172982 Test Loss: 0.1272332\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1018357\n",
      "\tspeed: 0.0652s/iter; left time: 1292.8790s\n",
      "\titers: 200, epoch: 12 | loss: 0.0972093\n",
      "\tspeed: 0.0349s/iter; left time: 689.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0992934 Vali Loss: 0.1170973 Test Loss: 0.1279319\n",
      "Validation loss decreased (0.117271 --> 0.117097).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0960486\n",
      "\tspeed: 0.0648s/iter; left time: 1271.1910s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997497\n",
      "\tspeed: 0.0349s/iter; left time: 681.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0989598 Vali Loss: 0.1168318 Test Loss: 0.1276354\n",
      "Validation loss decreased (0.117097 --> 0.116832).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0996718\n",
      "\tspeed: 0.0652s/iter; left time: 1264.1271s\n",
      "\titers: 200, epoch: 14 | loss: 0.0947404\n",
      "\tspeed: 0.0349s/iter; left time: 673.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0986475 Vali Loss: 0.1169735 Test Loss: 0.1274173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0974905\n",
      "\tspeed: 0.0648s/iter; left time: 1242.4220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981231\n",
      "\tspeed: 0.0349s/iter; left time: 665.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0983453 Vali Loss: 0.1166716 Test Loss: 0.1279067\n",
      "Validation loss decreased (0.116832 --> 0.116672).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1014924\n",
      "\tspeed: 0.0669s/iter; left time: 1267.4986s\n",
      "\titers: 200, epoch: 16 | loss: 0.1034701\n",
      "\tspeed: 0.0349s/iter; left time: 658.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0980670 Vali Loss: 0.1167677 Test Loss: 0.1272575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973124\n",
      "\tspeed: 0.0644s/iter; left time: 1205.7622s\n",
      "\titers: 200, epoch: 17 | loss: 0.0980472\n",
      "\tspeed: 0.0350s/iter; left time: 650.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0978883 Vali Loss: 0.1168754 Test Loss: 0.1276267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0963466\n",
      "\tspeed: 0.0644s/iter; left time: 1190.3490s\n",
      "\titers: 200, epoch: 18 | loss: 0.0919128\n",
      "\tspeed: 0.0349s/iter; left time: 642.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0976455 Vali Loss: 0.1169622 Test Loss: 0.1281606\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0941686\n",
      "\tspeed: 0.0644s/iter; left time: 1175.8828s\n",
      "\titers: 200, epoch: 19 | loss: 0.0953647\n",
      "\tspeed: 0.0349s/iter; left time: 634.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0973529 Vali Loss: 0.1170276 Test Loss: 0.1279060\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0978062\n",
      "\tspeed: 0.0641s/iter; left time: 1156.8529s\n",
      "\titers: 200, epoch: 20 | loss: 0.1034515\n",
      "\tspeed: 0.0349s/iter; left time: 626.7534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0972285 Vali Loss: 0.1168277 Test Loss: 0.1283830\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0988373\n",
      "\tspeed: 0.0639s/iter; left time: 1137.9045s\n",
      "\titers: 200, epoch: 21 | loss: 0.0931606\n",
      "\tspeed: 0.0349s/iter; left time: 618.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0970570 Vali Loss: 0.1168306 Test Loss: 0.1278056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0968445\n",
      "\tspeed: 0.0641s/iter; left time: 1128.0690s\n",
      "\titers: 200, epoch: 22 | loss: 0.0998393\n",
      "\tspeed: 0.0350s/iter; left time: 612.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0969466 Vali Loss: 0.1167267 Test Loss: 0.1278561\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0969927\n",
      "\tspeed: 0.0635s/iter; left time: 1102.3828s\n",
      "\titers: 200, epoch: 23 | loss: 0.1014693\n",
      "\tspeed: 0.0349s/iter; left time: 603.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0967281 Vali Loss: 0.1169685 Test Loss: 0.1281257\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1025194\n",
      "\tspeed: 0.0652s/iter; left time: 1118.5924s\n",
      "\titers: 200, epoch: 24 | loss: 0.0958392\n",
      "\tspeed: 0.0349s/iter; left time: 595.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0965891 Vali Loss: 0.1168502 Test Loss: 0.1280141\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0956000\n",
      "\tspeed: 0.0642s/iter; left time: 1087.1668s\n",
      "\titers: 200, epoch: 25 | loss: 0.0918060\n",
      "\tspeed: 0.0349s/iter; left time: 587.5898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0964858 Vali Loss: 0.1168534 Test Loss: 0.1277497\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037491124123334885, rmse:0.1936262547969818, mae:0.12790675461292267, rse:0.6856697201728821\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1453957\n",
      "\tspeed: 0.0365s/iter; left time: 814.5013s\n",
      "\titers: 200, epoch: 1 | loss: 0.1340858\n",
      "\tspeed: 0.0349s/iter; left time: 774.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1494136 Vali Loss: 0.1402564 Test Loss: 0.1483569\n",
      "Validation loss decreased (inf --> 0.140256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1099396\n",
      "\tspeed: 0.0653s/iter; left time: 1441.4807s\n",
      "\titers: 200, epoch: 2 | loss: 0.1089450\n",
      "\tspeed: 0.0350s/iter; left time: 768.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1142612 Vali Loss: 0.1222496 Test Loss: 0.1299090\n",
      "Validation loss decreased (0.140256 --> 0.122250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056904\n",
      "\tspeed: 0.0648s/iter; left time: 1415.0327s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076379\n",
      "\tspeed: 0.0349s/iter; left time: 758.5977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1065370 Vali Loss: 0.1204718 Test Loss: 0.1293942\n",
      "Validation loss decreased (0.122250 --> 0.120472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1011825\n",
      "\tspeed: 0.0651s/iter; left time: 1408.1162s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051529\n",
      "\tspeed: 0.0349s/iter; left time: 751.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1047850 Vali Loss: 0.1190891 Test Loss: 0.1283439\n",
      "Validation loss decreased (0.120472 --> 0.119089).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018035\n",
      "\tspeed: 0.0652s/iter; left time: 1395.1045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0959603\n",
      "\tspeed: 0.0349s/iter; left time: 742.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1035709 Vali Loss: 0.1188063 Test Loss: 0.1279118\n",
      "Validation loss decreased (0.119089 --> 0.118806).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0992174\n",
      "\tspeed: 0.0642s/iter; left time: 1359.4596s\n",
      "\titers: 200, epoch: 6 | loss: 0.1054772\n",
      "\tspeed: 0.0349s/iter; left time: 735.9433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1025895 Vali Loss: 0.1180930 Test Loss: 0.1277300\n",
      "Validation loss decreased (0.118806 --> 0.118093).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013398\n",
      "\tspeed: 0.0650s/iter; left time: 1362.2456s\n",
      "\titers: 200, epoch: 7 | loss: 0.0996996\n",
      "\tspeed: 0.0349s/iter; left time: 727.1248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1018984 Vali Loss: 0.1179579 Test Loss: 0.1278235\n",
      "Validation loss decreased (0.118093 --> 0.117958).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006072\n",
      "\tspeed: 0.0675s/iter; left time: 1400.2892s\n",
      "\titers: 200, epoch: 8 | loss: 0.0998495\n",
      "\tspeed: 0.0349s/iter; left time: 721.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1011631 Vali Loss: 0.1176284 Test Loss: 0.1280497\n",
      "Validation loss decreased (0.117958 --> 0.117628).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0995732\n",
      "\tspeed: 0.0659s/iter; left time: 1351.6445s\n",
      "\titers: 200, epoch: 9 | loss: 0.0970091\n",
      "\tspeed: 0.0350s/iter; left time: 713.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1004982 Vali Loss: 0.1173580 Test Loss: 0.1289639\n",
      "Validation loss decreased (0.117628 --> 0.117358).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1010281\n",
      "\tspeed: 0.0653s/iter; left time: 1324.5542s\n",
      "\titers: 200, epoch: 10 | loss: 0.0961296\n",
      "\tspeed: 0.0349s/iter; left time: 704.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0999256 Vali Loss: 0.1177550 Test Loss: 0.1276098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1018762\n",
      "\tspeed: 0.0645s/iter; left time: 1293.0266s\n",
      "\titers: 200, epoch: 11 | loss: 0.0979215\n",
      "\tspeed: 0.0349s/iter; left time: 697.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0992263 Vali Loss: 0.1176204 Test Loss: 0.1281647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0985747\n",
      "\tspeed: 0.0642s/iter; left time: 1274.5039s\n",
      "\titers: 200, epoch: 12 | loss: 0.1021433\n",
      "\tspeed: 0.0349s/iter; left time: 688.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0986819 Vali Loss: 0.1175718 Test Loss: 0.1288873\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029676\n",
      "\tspeed: 0.0642s/iter; left time: 1259.5668s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993051\n",
      "\tspeed: 0.0349s/iter; left time: 681.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0982463 Vali Loss: 0.1174938 Test Loss: 0.1275150\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0970475\n",
      "\tspeed: 0.0647s/iter; left time: 1254.4670s\n",
      "\titers: 200, epoch: 14 | loss: 0.0948543\n",
      "\tspeed: 0.0349s/iter; left time: 673.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0978403 Vali Loss: 0.1172675 Test Loss: 0.1285813\n",
      "Validation loss decreased (0.117358 --> 0.117267).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0957331\n",
      "\tspeed: 0.0650s/iter; left time: 1246.3146s\n",
      "\titers: 200, epoch: 15 | loss: 0.0929094\n",
      "\tspeed: 0.0350s/iter; left time: 666.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0973781 Vali Loss: 0.1176463 Test Loss: 0.1286512\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1026521\n",
      "\tspeed: 0.0644s/iter; left time: 1220.0673s\n",
      "\titers: 200, epoch: 16 | loss: 0.1015639\n",
      "\tspeed: 0.0350s/iter; left time: 659.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0970437 Vali Loss: 0.1176449 Test Loss: 0.1301728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0968726\n",
      "\tspeed: 0.0640s/iter; left time: 1198.7500s\n",
      "\titers: 200, epoch: 17 | loss: 0.0935973\n",
      "\tspeed: 0.0349s/iter; left time: 648.8111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0967689 Vali Loss: 0.1177664 Test Loss: 0.1295637\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0874706\n",
      "\tspeed: 0.0639s/iter; left time: 1181.7644s\n",
      "\titers: 200, epoch: 18 | loss: 0.0967437\n",
      "\tspeed: 0.0349s/iter; left time: 642.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0964619 Vali Loss: 0.1176769 Test Loss: 0.1294305\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0988394\n",
      "\tspeed: 0.0645s/iter; left time: 1178.4609s\n",
      "\titers: 200, epoch: 19 | loss: 0.0924114\n",
      "\tspeed: 0.0349s/iter; left time: 634.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0962537 Vali Loss: 0.1178822 Test Loss: 0.1303212\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1004734\n",
      "\tspeed: 0.0646s/iter; left time: 1166.5721s\n",
      "\titers: 200, epoch: 20 | loss: 0.0981680\n",
      "\tspeed: 0.0349s/iter; left time: 627.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0959195 Vali Loss: 0.1175593 Test Loss: 0.1291494\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0966209\n",
      "\tspeed: 0.0642s/iter; left time: 1144.7604s\n",
      "\titers: 200, epoch: 21 | loss: 0.0967935\n",
      "\tspeed: 0.0349s/iter; left time: 619.0208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0957571 Vali Loss: 0.1175417 Test Loss: 0.1290626\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0940960\n",
      "\tspeed: 0.0648s/iter; left time: 1139.8663s\n",
      "\titers: 200, epoch: 22 | loss: 0.0918512\n",
      "\tspeed: 0.0349s/iter; left time: 611.4818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0955669 Vali Loss: 0.1178742 Test Loss: 0.1291731\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0918518\n",
      "\tspeed: 0.0645s/iter; left time: 1120.5052s\n",
      "\titers: 200, epoch: 23 | loss: 0.0954803\n",
      "\tspeed: 0.0349s/iter; left time: 603.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0954497 Vali Loss: 0.1179387 Test Loss: 0.1295711\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0978012\n",
      "\tspeed: 0.0643s/iter; left time: 1102.6532s\n",
      "\titers: 200, epoch: 24 | loss: 0.0950696\n",
      "\tspeed: 0.0349s/iter; left time: 595.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0952225 Vali Loss: 0.1179368 Test Loss: 0.1301759\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03774594888091087, rmse:0.19428317248821259, mae:0.1285812258720398, rse:0.687995970249176\n",
      "Intermediate time for DE and pred_len 96: 00h:08m:20.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1507415\n",
      "\tspeed: 0.0565s/iter; left time: 1253.2475s\n",
      "\titers: 200, epoch: 1 | loss: 0.1394623\n",
      "\tspeed: 0.0353s/iter; left time: 780.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 223 | Train Loss: 0.1507555 Vali Loss: 0.1426712 Test Loss: 0.1519588\n",
      "Validation loss decreased (inf --> 0.142671).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1239280\n",
      "\tspeed: 0.0646s/iter; left time: 1420.2945s\n",
      "\titers: 200, epoch: 2 | loss: 0.1124039\n",
      "\tspeed: 0.0352s/iter; left time: 769.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1201247 Vali Loss: 0.1261942 Test Loss: 0.1356402\n",
      "Validation loss decreased (0.142671 --> 0.126194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1163913\n",
      "\tspeed: 0.0657s/iter; left time: 1429.3826s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123442\n",
      "\tspeed: 0.0353s/iter; left time: 763.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1126438 Vali Loss: 0.1250066 Test Loss: 0.1347315\n",
      "Validation loss decreased (0.126194 --> 0.125007).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090862\n",
      "\tspeed: 0.0653s/iter; left time: 1405.7824s\n",
      "\titers: 200, epoch: 4 | loss: 0.1161309\n",
      "\tspeed: 0.0352s/iter; left time: 755.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1107866 Vali Loss: 0.1232045 Test Loss: 0.1346235\n",
      "Validation loss decreased (0.125007 --> 0.123204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1066427\n",
      "\tspeed: 0.0651s/iter; left time: 1387.8638s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132237\n",
      "\tspeed: 0.0353s/iter; left time: 748.4983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1096003 Vali Loss: 0.1234181 Test Loss: 0.1344385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1043037\n",
      "\tspeed: 0.0655s/iter; left time: 1380.7604s\n",
      "\titers: 200, epoch: 6 | loss: 0.1133910\n",
      "\tspeed: 0.0354s/iter; left time: 743.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1086403 Vali Loss: 0.1231625 Test Loss: 0.1348926\n",
      "Validation loss decreased (0.123204 --> 0.123162).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1089526\n",
      "\tspeed: 0.0661s/iter; left time: 1378.2731s\n",
      "\titers: 200, epoch: 7 | loss: 0.1089387\n",
      "\tspeed: 0.0353s/iter; left time: 733.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1077927 Vali Loss: 0.1226179 Test Loss: 0.1336366\n",
      "Validation loss decreased (0.123162 --> 0.122618).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039010\n",
      "\tspeed: 0.0656s/iter; left time: 1354.2406s\n",
      "\titers: 200, epoch: 8 | loss: 0.1120105\n",
      "\tspeed: 0.0352s/iter; left time: 723.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1070246 Vali Loss: 0.1223381 Test Loss: 0.1333994\n",
      "Validation loss decreased (0.122618 --> 0.122338).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1057785\n",
      "\tspeed: 0.0652s/iter; left time: 1331.8512s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990716\n",
      "\tspeed: 0.0353s/iter; left time: 718.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1064019 Vali Loss: 0.1225220 Test Loss: 0.1338606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033412\n",
      "\tspeed: 0.0658s/iter; left time: 1327.9691s\n",
      "\titers: 200, epoch: 10 | loss: 0.1036346\n",
      "\tspeed: 0.0353s/iter; left time: 709.8865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1057795 Vali Loss: 0.1224171 Test Loss: 0.1343879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1061738\n",
      "\tspeed: 0.0662s/iter; left time: 1321.8669s\n",
      "\titers: 200, epoch: 11 | loss: 0.1002536\n",
      "\tspeed: 0.0353s/iter; left time: 700.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1053096 Vali Loss: 0.1229281 Test Loss: 0.1340355\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1030056\n",
      "\tspeed: 0.0662s/iter; left time: 1306.6333s\n",
      "\titers: 200, epoch: 12 | loss: 0.1087899\n",
      "\tspeed: 0.0354s/iter; left time: 695.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.1048512 Vali Loss: 0.1225468 Test Loss: 0.1339203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1101046\n",
      "\tspeed: 0.0663s/iter; left time: 1294.6883s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058030\n",
      "\tspeed: 0.0355s/iter; left time: 689.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 223 | Train Loss: 0.1043782 Vali Loss: 0.1226395 Test Loss: 0.1338739\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0977369\n",
      "\tspeed: 0.0666s/iter; left time: 1286.3567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1103711\n",
      "\tspeed: 0.0354s/iter; left time: 680.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.1040082 Vali Loss: 0.1224431 Test Loss: 0.1337946\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1058028\n",
      "\tspeed: 0.0662s/iter; left time: 1262.5629s\n",
      "\titers: 200, epoch: 15 | loss: 0.1130442\n",
      "\tspeed: 0.0353s/iter; left time: 669.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1035960 Vali Loss: 0.1227261 Test Loss: 0.1344341\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1064806\n",
      "\tspeed: 0.0661s/iter; left time: 1246.9260s\n",
      "\titers: 200, epoch: 16 | loss: 0.1113944\n",
      "\tspeed: 0.0353s/iter; left time: 662.4881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1032039 Vali Loss: 0.1225822 Test Loss: 0.1335773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1022041\n",
      "\tspeed: 0.0658s/iter; left time: 1226.8881s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060120\n",
      "\tspeed: 0.0352s/iter; left time: 653.0047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1029293 Vali Loss: 0.1228268 Test Loss: 0.1333598\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1026201\n",
      "\tspeed: 0.0646s/iter; left time: 1189.0348s\n",
      "\titers: 200, epoch: 18 | loss: 0.1053459\n",
      "\tspeed: 0.0354s/iter; left time: 647.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1026233 Vali Loss: 0.1227413 Test Loss: 0.1338267\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039008963853120804, rmse:0.1975068747997284, mae:0.13339932262897491, rse:0.6995851993560791\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1544944\n",
      "\tspeed: 0.0373s/iter; left time: 827.3811s\n",
      "\titers: 200, epoch: 1 | loss: 0.1355311\n",
      "\tspeed: 0.0354s/iter; left time: 781.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1520427 Vali Loss: 0.1427960 Test Loss: 0.1520984\n",
      "Validation loss decreased (inf --> 0.142796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182963\n",
      "\tspeed: 0.0708s/iter; left time: 1555.6418s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188139\n",
      "\tspeed: 0.0353s/iter; left time: 772.7556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1200457 Vali Loss: 0.1262973 Test Loss: 0.1363670\n",
      "Validation loss decreased (0.142796 --> 0.126297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161436\n",
      "\tspeed: 0.0676s/iter; left time: 1470.4189s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097982\n",
      "\tspeed: 0.0353s/iter; left time: 765.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.1127010 Vali Loss: 0.1251050 Test Loss: 0.1347768\n",
      "Validation loss decreased (0.126297 --> 0.125105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086838\n",
      "\tspeed: 0.0672s/iter; left time: 1447.5902s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126017\n",
      "\tspeed: 0.0354s/iter; left time: 757.8176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.1107704 Vali Loss: 0.1242438 Test Loss: 0.1353610\n",
      "Validation loss decreased (0.125105 --> 0.124244).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1123698\n",
      "\tspeed: 0.0679s/iter; left time: 1446.9317s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103449\n",
      "\tspeed: 0.0354s/iter; left time: 751.1190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.1094124 Vali Loss: 0.1243619 Test Loss: 0.1337075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1061258\n",
      "\tspeed: 0.0664s/iter; left time: 1399.4721s\n",
      "\titers: 200, epoch: 6 | loss: 0.1109948\n",
      "\tspeed: 0.0354s/iter; left time: 741.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1085605 Vali Loss: 0.1231010 Test Loss: 0.1342797\n",
      "Validation loss decreased (0.124244 --> 0.123101).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1108833\n",
      "\tspeed: 0.0689s/iter; left time: 1437.7100s\n",
      "\titers: 200, epoch: 7 | loss: 0.1095173\n",
      "\tspeed: 0.0353s/iter; left time: 732.1155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.1077194 Vali Loss: 0.1238700 Test Loss: 0.1350289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1087225\n",
      "\tspeed: 0.0656s/iter; left time: 1353.1610s\n",
      "\titers: 200, epoch: 8 | loss: 0.1082283\n",
      "\tspeed: 0.0352s/iter; left time: 723.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1069829 Vali Loss: 0.1235352 Test Loss: 0.1347286\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044433\n",
      "\tspeed: 0.0665s/iter; left time: 1356.8686s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087776\n",
      "\tspeed: 0.0353s/iter; left time: 716.2507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.1062971 Vali Loss: 0.1230259 Test Loss: 0.1345029\n",
      "Validation loss decreased (0.123101 --> 0.123026).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1045399\n",
      "\tspeed: 0.0660s/iter; left time: 1333.8079s\n",
      "\titers: 200, epoch: 10 | loss: 0.1105393\n",
      "\tspeed: 0.0352s/iter; left time: 707.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1056225 Vali Loss: 0.1232725 Test Loss: 0.1349387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1027120\n",
      "\tspeed: 0.0652s/iter; left time: 1302.6396s\n",
      "\titers: 200, epoch: 11 | loss: 0.1093096\n",
      "\tspeed: 0.0352s/iter; left time: 699.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1050379 Vali Loss: 0.1236330 Test Loss: 0.1350731\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1042112\n",
      "\tspeed: 0.0656s/iter; left time: 1295.8879s\n",
      "\titers: 200, epoch: 12 | loss: 0.1065711\n",
      "\tspeed: 0.0352s/iter; left time: 691.4895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1045088 Vali Loss: 0.1236756 Test Loss: 0.1343073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1077220\n",
      "\tspeed: 0.0653s/iter; left time: 1275.4218s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064898\n",
      "\tspeed: 0.0352s/iter; left time: 684.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1040355 Vali Loss: 0.1237444 Test Loss: 0.1347824\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1031265\n",
      "\tspeed: 0.0656s/iter; left time: 1266.7221s\n",
      "\titers: 200, epoch: 14 | loss: 0.1016434\n",
      "\tspeed: 0.0352s/iter; left time: 675.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1035480 Vali Loss: 0.1237950 Test Loss: 0.1351177\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1026230\n",
      "\tspeed: 0.0650s/iter; left time: 1240.5683s\n",
      "\titers: 200, epoch: 15 | loss: 0.1009728\n",
      "\tspeed: 0.0353s/iter; left time: 670.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1030570 Vali Loss: 0.1239436 Test Loss: 0.1357483\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1040640\n",
      "\tspeed: 0.0653s/iter; left time: 1232.1764s\n",
      "\titers: 200, epoch: 16 | loss: 0.1080976\n",
      "\tspeed: 0.0352s/iter; left time: 661.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1027642 Vali Loss: 0.1238374 Test Loss: 0.1346043\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0998133\n",
      "\tspeed: 0.0650s/iter; left time: 1211.1566s\n",
      "\titers: 200, epoch: 17 | loss: 0.1025198\n",
      "\tspeed: 0.0352s/iter; left time: 653.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1024307 Vali Loss: 0.1237371 Test Loss: 0.1349805\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1031220\n",
      "\tspeed: 0.0652s/iter; left time: 1200.4195s\n",
      "\titers: 200, epoch: 18 | loss: 0.1065352\n",
      "\tspeed: 0.0352s/iter; left time: 643.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1021159 Vali Loss: 0.1244268 Test Loss: 0.1352319\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1081941\n",
      "\tspeed: 0.0648s/iter; left time: 1177.7916s\n",
      "\titers: 200, epoch: 19 | loss: 0.0990949\n",
      "\tspeed: 0.0353s/iter; left time: 637.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1018482 Vali Loss: 0.1244729 Test Loss: 0.1345668\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039633940905332565, rmse:0.19908274710178375, mae:0.13450299203395844, rse:0.7051671147346497\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:28.03s\n",
      "Intermediate time for DE: 00h:33m:27.71s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1247611\n",
      "\tspeed: 0.0558s/iter; left time: 1244.1610s\n",
      "\titers: 200, epoch: 1 | loss: 0.1143526\n",
      "\tspeed: 0.0347s/iter; left time: 770.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.1303075 Vali Loss: 0.1216880 Test Loss: 0.1408380\n",
      "Validation loss decreased (inf --> 0.121688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0842563\n",
      "\tspeed: 0.0633s/iter; left time: 1397.0355s\n",
      "\titers: 200, epoch: 2 | loss: 0.0819014\n",
      "\tspeed: 0.0347s/iter; left time: 762.2064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0865726 Vali Loss: 0.0919034 Test Loss: 0.1031424\n",
      "Validation loss decreased (0.121688 --> 0.091903).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0737688\n",
      "\tspeed: 0.0640s/iter; left time: 1398.7147s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824103\n",
      "\tspeed: 0.0346s/iter; left time: 753.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0793790 Vali Loss: 0.0899726 Test Loss: 0.1024645\n",
      "Validation loss decreased (0.091903 --> 0.089973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745010\n",
      "\tspeed: 0.0638s/iter; left time: 1380.5545s\n",
      "\titers: 200, epoch: 4 | loss: 0.0775107\n",
      "\tspeed: 0.0346s/iter; left time: 745.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0779003 Vali Loss: 0.0899798 Test Loss: 0.1021317\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760180\n",
      "\tspeed: 0.0632s/iter; left time: 1351.9856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0761515\n",
      "\tspeed: 0.0347s/iter; left time: 739.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0769876 Vali Loss: 0.0892471 Test Loss: 0.1017458\n",
      "Validation loss decreased (0.089973 --> 0.089247).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797190\n",
      "\tspeed: 0.0651s/iter; left time: 1379.9193s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811191\n",
      "\tspeed: 0.0346s/iter; left time: 729.4924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0762330 Vali Loss: 0.0888480 Test Loss: 0.1014709\n",
      "Validation loss decreased (0.089247 --> 0.088848).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748599\n",
      "\tspeed: 0.0634s/iter; left time: 1329.1301s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804287\n",
      "\tspeed: 0.0346s/iter; left time: 722.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0756670 Vali Loss: 0.0888771 Test Loss: 0.1014206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729555\n",
      "\tspeed: 0.0628s/iter; left time: 1301.0260s\n",
      "\titers: 200, epoch: 8 | loss: 0.0766028\n",
      "\tspeed: 0.0346s/iter; left time: 714.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0751839 Vali Loss: 0.0885889 Test Loss: 0.1005207\n",
      "Validation loss decreased (0.088848 --> 0.088589).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738455\n",
      "\tspeed: 0.0640s/iter; left time: 1313.1392s\n",
      "\titers: 200, epoch: 9 | loss: 0.0790517\n",
      "\tspeed: 0.0347s/iter; left time: 707.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0748482 Vali Loss: 0.0887364 Test Loss: 0.1007120\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808676\n",
      "\tspeed: 0.0633s/iter; left time: 1283.8025s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732426\n",
      "\tspeed: 0.0346s/iter; left time: 698.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0745424 Vali Loss: 0.0878483 Test Loss: 0.1010135\n",
      "Validation loss decreased (0.088589 --> 0.087848).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775793\n",
      "\tspeed: 0.0641s/iter; left time: 1285.4172s\n",
      "\titers: 200, epoch: 11 | loss: 0.0736117\n",
      "\tspeed: 0.0349s/iter; left time: 697.2037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0742537 Vali Loss: 0.0881625 Test Loss: 0.1001913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777474\n",
      "\tspeed: 0.0634s/iter; left time: 1257.3928s\n",
      "\titers: 200, epoch: 12 | loss: 0.0713382\n",
      "\tspeed: 0.0346s/iter; left time: 682.9296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0739927 Vali Loss: 0.0879092 Test Loss: 0.1006771\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727023\n",
      "\tspeed: 0.0635s/iter; left time: 1244.7479s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719952\n",
      "\tspeed: 0.0346s/iter; left time: 675.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0738306 Vali Loss: 0.0878730 Test Loss: 0.1001283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774384\n",
      "\tspeed: 0.0628s/iter; left time: 1216.7017s\n",
      "\titers: 200, epoch: 14 | loss: 0.0698902\n",
      "\tspeed: 0.0346s/iter; left time: 666.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0736871 Vali Loss: 0.0878024 Test Loss: 0.0998933\n",
      "Validation loss decreased (0.087848 --> 0.087802).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0668057\n",
      "\tspeed: 0.0631s/iter; left time: 1209.3785s\n",
      "\titers: 200, epoch: 15 | loss: 0.0690141\n",
      "\tspeed: 0.0346s/iter; left time: 659.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0734897 Vali Loss: 0.0879864 Test Loss: 0.0999247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0698143\n",
      "\tspeed: 0.0629s/iter; left time: 1190.8123s\n",
      "\titers: 200, epoch: 16 | loss: 0.0734518\n",
      "\tspeed: 0.0346s/iter; left time: 651.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0733458 Vali Loss: 0.0874913 Test Loss: 0.1001951\n",
      "Validation loss decreased (0.087802 --> 0.087491).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0736844\n",
      "\tspeed: 0.0640s/iter; left time: 1197.4207s\n",
      "\titers: 200, epoch: 17 | loss: 0.0768669\n",
      "\tspeed: 0.0348s/iter; left time: 646.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0732595 Vali Loss: 0.0875177 Test Loss: 0.0997549\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0741299\n",
      "\tspeed: 0.0640s/iter; left time: 1183.0326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0742703\n",
      "\tspeed: 0.0350s/iter; left time: 642.9208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0731418 Vali Loss: 0.0874550 Test Loss: 0.0996348\n",
      "Validation loss decreased (0.087491 --> 0.087455).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0699841\n",
      "\tspeed: 0.0642s/iter; left time: 1172.9832s\n",
      "\titers: 200, epoch: 19 | loss: 0.0730995\n",
      "\tspeed: 0.0349s/iter; left time: 634.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0730212 Vali Loss: 0.0877180 Test Loss: 0.0997454\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0643637\n",
      "\tspeed: 0.0643s/iter; left time: 1160.1479s\n",
      "\titers: 200, epoch: 20 | loss: 0.0709331\n",
      "\tspeed: 0.0350s/iter; left time: 628.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0728930 Vali Loss: 0.0877011 Test Loss: 0.0996751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751462\n",
      "\tspeed: 0.0637s/iter; left time: 1134.3896s\n",
      "\titers: 200, epoch: 21 | loss: 0.0707488\n",
      "\tspeed: 0.0349s/iter; left time: 619.0375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0728144 Vali Loss: 0.0874716 Test Loss: 0.0995260\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0719383\n",
      "\tspeed: 0.0637s/iter; left time: 1120.6512s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672770\n",
      "\tspeed: 0.0347s/iter; left time: 607.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0727698 Vali Loss: 0.0873257 Test Loss: 0.0995231\n",
      "Validation loss decreased (0.087455 --> 0.087326).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0714904\n",
      "\tspeed: 0.0639s/iter; left time: 1109.9431s\n",
      "\titers: 200, epoch: 23 | loss: 0.0683171\n",
      "\tspeed: 0.0349s/iter; left time: 603.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0726941 Vali Loss: 0.0873660 Test Loss: 0.0995859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0714073\n",
      "\tspeed: 0.0647s/iter; left time: 1109.3182s\n",
      "\titers: 200, epoch: 24 | loss: 0.0715693\n",
      "\tspeed: 0.0347s/iter; left time: 592.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0726770 Vali Loss: 0.0874997 Test Loss: 0.0994603\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0732493\n",
      "\tspeed: 0.0636s/iter; left time: 1076.2132s\n",
      "\titers: 200, epoch: 25 | loss: 0.0759301\n",
      "\tspeed: 0.0348s/iter; left time: 585.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0726538 Vali Loss: 0.0872884 Test Loss: 0.0994575\n",
      "Validation loss decreased (0.087326 --> 0.087288).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0728130\n",
      "\tspeed: 0.0644s/iter; left time: 1074.8188s\n",
      "\titers: 200, epoch: 26 | loss: 0.0702365\n",
      "\tspeed: 0.0348s/iter; left time: 577.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0725412 Vali Loss: 0.0874340 Test Loss: 0.0995555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0715932\n",
      "\tspeed: 0.0643s/iter; left time: 1059.7496s\n",
      "\titers: 200, epoch: 27 | loss: 0.0756999\n",
      "\tspeed: 0.0348s/iter; left time: 570.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0725176 Vali Loss: 0.0873506 Test Loss: 0.0995875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0779321\n",
      "\tspeed: 0.0645s/iter; left time: 1047.8914s\n",
      "\titers: 200, epoch: 28 | loss: 0.0751987\n",
      "\tspeed: 0.0348s/iter; left time: 562.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0724977 Vali Loss: 0.0874352 Test Loss: 0.0996355\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0739681\n",
      "\tspeed: 0.0635s/iter; left time: 1018.1905s\n",
      "\titers: 200, epoch: 29 | loss: 0.0670358\n",
      "\tspeed: 0.0349s/iter; left time: 555.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0724848 Vali Loss: 0.0873351 Test Loss: 0.0994455\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0750490\n",
      "\tspeed: 0.0636s/iter; left time: 1005.8042s\n",
      "\titers: 200, epoch: 30 | loss: 0.0703685\n",
      "\tspeed: 0.0348s/iter; left time: 546.9924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0724388 Vali Loss: 0.0873482 Test Loss: 0.0995752\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0659054\n",
      "\tspeed: 0.0642s/iter; left time: 1000.2697s\n",
      "\titers: 200, epoch: 31 | loss: 0.0735366\n",
      "\tspeed: 0.0347s/iter; left time: 536.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0723950 Vali Loss: 0.0873012 Test Loss: 0.0995835\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0729537\n",
      "\tspeed: 0.0638s/iter; left time: 979.4407s\n",
      "\titers: 200, epoch: 32 | loss: 0.0747104\n",
      "\tspeed: 0.0347s/iter; left time: 528.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0724255 Vali Loss: 0.0871513 Test Loss: 0.0994224\n",
      "Validation loss decreased (0.087288 --> 0.087151).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0718319\n",
      "\tspeed: 0.0641s/iter; left time: 969.5907s\n",
      "\titers: 200, epoch: 33 | loss: 0.0706718\n",
      "\tspeed: 0.0350s/iter; left time: 525.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0723458 Vali Loss: 0.0873818 Test Loss: 0.0996012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0731219\n",
      "\tspeed: 0.0642s/iter; left time: 956.6806s\n",
      "\titers: 200, epoch: 34 | loss: 0.0744082\n",
      "\tspeed: 0.0349s/iter; left time: 516.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0723610 Vali Loss: 0.0873346 Test Loss: 0.0995087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0775548\n",
      "\tspeed: 0.0644s/iter; left time: 946.3281s\n",
      "\titers: 200, epoch: 35 | loss: 0.0756403\n",
      "\tspeed: 0.0348s/iter; left time: 506.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722907 Vali Loss: 0.0872204 Test Loss: 0.0994593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0693678\n",
      "\tspeed: 0.0644s/iter; left time: 931.7252s\n",
      "\titers: 200, epoch: 36 | loss: 0.0769135\n",
      "\tspeed: 0.0348s/iter; left time: 500.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0722630 Vali Loss: 0.0873873 Test Loss: 0.0995016\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0758929\n",
      "\tspeed: 0.0639s/iter; left time: 909.2940s\n",
      "\titers: 200, epoch: 37 | loss: 0.0711693\n",
      "\tspeed: 0.0349s/iter; left time: 492.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722736 Vali Loss: 0.0873873 Test Loss: 0.0995036\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0748579\n",
      "\tspeed: 0.0636s/iter; left time: 890.5803s\n",
      "\titers: 200, epoch: 38 | loss: 0.0678177\n",
      "\tspeed: 0.0349s/iter; left time: 485.7531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0723373 Vali Loss: 0.0872301 Test Loss: 0.0994893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0759173\n",
      "\tspeed: 0.0643s/iter; left time: 887.1000s\n",
      "\titers: 200, epoch: 39 | loss: 0.0677600\n",
      "\tspeed: 0.0349s/iter; left time: 477.9075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722983 Vali Loss: 0.0873828 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0664773\n",
      "\tspeed: 0.0641s/iter; left time: 869.5366s\n",
      "\titers: 200, epoch: 40 | loss: 0.0749151\n",
      "\tspeed: 0.0348s/iter; left time: 468.5489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0722886 Vali Loss: 0.0873415 Test Loss: 0.0994757\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0701831\n",
      "\tspeed: 0.0634s/iter; left time: 846.3775s\n",
      "\titers: 200, epoch: 41 | loss: 0.0715847\n",
      "\tspeed: 0.0348s/iter; left time: 461.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0722711 Vali Loss: 0.0873553 Test Loss: 0.0995072\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0718809\n",
      "\tspeed: 0.0640s/iter; left time: 839.9377s\n",
      "\titers: 200, epoch: 42 | loss: 0.0766828\n",
      "\tspeed: 0.0348s/iter; left time: 453.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722978 Vali Loss: 0.0871924 Test Loss: 0.0994866\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024902237579226494, rmse:0.1578044295310974, mae:0.09942235052585602, rse:0.5443805456161499\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1294022\n",
      "\tspeed: 0.0366s/iter; left time: 815.8341s\n",
      "\titers: 200, epoch: 1 | loss: 0.1100414\n",
      "\tspeed: 0.0348s/iter; left time: 773.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1292062 Vali Loss: 0.1214272 Test Loss: 0.1407624\n",
      "Validation loss decreased (inf --> 0.121427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0821685\n",
      "\tspeed: 0.0641s/iter; left time: 1414.7766s\n",
      "\titers: 200, epoch: 2 | loss: 0.0775632\n",
      "\tspeed: 0.0347s/iter; left time: 762.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0862068 Vali Loss: 0.0915956 Test Loss: 0.1032231\n",
      "Validation loss decreased (0.121427 --> 0.091596).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0783461\n",
      "\tspeed: 0.0655s/iter; left time: 1431.7536s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811940\n",
      "\tspeed: 0.0345s/iter; left time: 751.2520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0792170 Vali Loss: 0.0905060 Test Loss: 0.1026404\n",
      "Validation loss decreased (0.091596 --> 0.090506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764677\n",
      "\tspeed: 0.0641s/iter; left time: 1385.6705s\n",
      "\titers: 200, epoch: 4 | loss: 0.0736082\n",
      "\tspeed: 0.0350s/iter; left time: 753.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0779272 Vali Loss: 0.0898439 Test Loss: 0.1022563\n",
      "Validation loss decreased (0.090506 --> 0.089844).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765094\n",
      "\tspeed: 0.0648s/iter; left time: 1386.1139s\n",
      "\titers: 200, epoch: 5 | loss: 0.0694353\n",
      "\tspeed: 0.0349s/iter; left time: 744.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0769795 Vali Loss: 0.0891885 Test Loss: 0.1018237\n",
      "Validation loss decreased (0.089844 --> 0.089189).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713069\n",
      "\tspeed: 0.0642s/iter; left time: 1359.7395s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752044\n",
      "\tspeed: 0.0349s/iter; left time: 735.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0762907 Vali Loss: 0.0893766 Test Loss: 0.1015955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0740957\n",
      "\tspeed: 0.0640s/iter; left time: 1340.8557s\n",
      "\titers: 200, epoch: 7 | loss: 0.0764063\n",
      "\tspeed: 0.0348s/iter; left time: 726.4902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0757188 Vali Loss: 0.0887840 Test Loss: 0.1008570\n",
      "Validation loss decreased (0.089189 --> 0.088784).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771523\n",
      "\tspeed: 0.0656s/iter; left time: 1360.2810s\n",
      "\titers: 200, epoch: 8 | loss: 0.0754328\n",
      "\tspeed: 0.0347s/iter; left time: 715.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0752649 Vali Loss: 0.0886348 Test Loss: 0.1005910\n",
      "Validation loss decreased (0.088784 --> 0.088635).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779897\n",
      "\tspeed: 0.0644s/iter; left time: 1321.5204s\n",
      "\titers: 200, epoch: 9 | loss: 0.0770550\n",
      "\tspeed: 0.0349s/iter; left time: 712.7659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0748893 Vali Loss: 0.0889522 Test Loss: 0.1009389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0761693\n",
      "\tspeed: 0.0643s/iter; left time: 1304.1839s\n",
      "\titers: 200, epoch: 10 | loss: 0.0766291\n",
      "\tspeed: 0.0348s/iter; left time: 703.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0745797 Vali Loss: 0.0884298 Test Loss: 0.1007179\n",
      "Validation loss decreased (0.088635 --> 0.088430).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0719477\n",
      "\tspeed: 0.0646s/iter; left time: 1295.5196s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769291\n",
      "\tspeed: 0.0347s/iter; left time: 692.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0742787 Vali Loss: 0.0886163 Test Loss: 0.1001683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0740210\n",
      "\tspeed: 0.0639s/iter; left time: 1268.5145s\n",
      "\titers: 200, epoch: 12 | loss: 0.0742159\n",
      "\tspeed: 0.0348s/iter; left time: 686.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0740577 Vali Loss: 0.0879692 Test Loss: 0.1004901\n",
      "Validation loss decreased (0.088430 --> 0.087969).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0732761\n",
      "\tspeed: 0.0639s/iter; left time: 1253.5710s\n",
      "\titers: 200, epoch: 13 | loss: 0.0700531\n",
      "\tspeed: 0.0349s/iter; left time: 680.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0738108 Vali Loss: 0.0882454 Test Loss: 0.1005620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0684145\n",
      "\tspeed: 0.0638s/iter; left time: 1236.3197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0773976\n",
      "\tspeed: 0.0348s/iter; left time: 671.3657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0735779 Vali Loss: 0.0877776 Test Loss: 0.1004058\n",
      "Validation loss decreased (0.087969 --> 0.087778).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0761139\n",
      "\tspeed: 0.0649s/iter; left time: 1243.6362s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705998\n",
      "\tspeed: 0.0348s/iter; left time: 663.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0734446 Vali Loss: 0.0877527 Test Loss: 0.0998809\n",
      "Validation loss decreased (0.087778 --> 0.087753).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0744571\n",
      "\tspeed: 0.0638s/iter; left time: 1208.7728s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772809\n",
      "\tspeed: 0.0349s/iter; left time: 657.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0732838 Vali Loss: 0.0875569 Test Loss: 0.0996925\n",
      "Validation loss decreased (0.087753 --> 0.087557).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727495\n",
      "\tspeed: 0.0639s/iter; left time: 1195.6310s\n",
      "\titers: 200, epoch: 17 | loss: 0.0665621\n",
      "\tspeed: 0.0348s/iter; left time: 648.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0731827 Vali Loss: 0.0876051 Test Loss: 0.0996813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726492\n",
      "\tspeed: 0.0641s/iter; left time: 1185.7530s\n",
      "\titers: 200, epoch: 18 | loss: 0.0750291\n",
      "\tspeed: 0.0349s/iter; left time: 641.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0730682 Vali Loss: 0.0875404 Test Loss: 0.0999407\n",
      "Validation loss decreased (0.087557 --> 0.087540).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730098\n",
      "\tspeed: 0.0647s/iter; left time: 1182.0659s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705551\n",
      "\tspeed: 0.0348s/iter; left time: 631.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0729243 Vali Loss: 0.0874838 Test Loss: 0.0997166\n",
      "Validation loss decreased (0.087540 --> 0.087484).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0755711\n",
      "\tspeed: 0.0639s/iter; left time: 1152.8097s\n",
      "\titers: 200, epoch: 20 | loss: 0.0745831\n",
      "\tspeed: 0.0345s/iter; left time: 619.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0728972 Vali Loss: 0.0875051 Test Loss: 0.0995769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0715922\n",
      "\tspeed: 0.0639s/iter; left time: 1139.4025s\n",
      "\titers: 200, epoch: 21 | loss: 0.0721797\n",
      "\tspeed: 0.0348s/iter; left time: 617.2905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0727267 Vali Loss: 0.0874295 Test Loss: 0.0997128\n",
      "Validation loss decreased (0.087484 --> 0.087430).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712320\n",
      "\tspeed: 0.0641s/iter; left time: 1127.1981s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738316\n",
      "\tspeed: 0.0349s/iter; left time: 610.3731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0727076 Vali Loss: 0.0874886 Test Loss: 0.0997229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0712695\n",
      "\tspeed: 0.0633s/iter; left time: 1100.1265s\n",
      "\titers: 200, epoch: 23 | loss: 0.0734331\n",
      "\tspeed: 0.0348s/iter; left time: 600.3232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0726605 Vali Loss: 0.0873657 Test Loss: 0.0994976\n",
      "Validation loss decreased (0.087430 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0750479\n",
      "\tspeed: 0.0639s/iter; left time: 1095.6060s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773794\n",
      "\tspeed: 0.0349s/iter; left time: 594.3260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0725569 Vali Loss: 0.0873323 Test Loss: 0.0994945\n",
      "Validation loss decreased (0.087366 --> 0.087332).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0760816\n",
      "\tspeed: 0.0639s/iter; left time: 1080.9921s\n",
      "\titers: 200, epoch: 25 | loss: 0.0709737\n",
      "\tspeed: 0.0349s/iter; left time: 586.7352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0725265 Vali Loss: 0.0873971 Test Loss: 0.0997336\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0730899\n",
      "\tspeed: 0.0637s/iter; left time: 1064.1483s\n",
      "\titers: 200, epoch: 26 | loss: 0.0703386\n",
      "\tspeed: 0.0348s/iter; left time: 578.4166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0724307 Vali Loss: 0.0873005 Test Loss: 0.0994930\n",
      "Validation loss decreased (0.087332 --> 0.087300).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776443\n",
      "\tspeed: 0.0635s/iter; left time: 1046.7604s\n",
      "\titers: 200, epoch: 27 | loss: 0.0700019\n",
      "\tspeed: 0.0349s/iter; left time: 571.4085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0723723 Vali Loss: 0.0873162 Test Loss: 0.0995671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0728972\n",
      "\tspeed: 0.0630s/iter; left time: 1024.0821s\n",
      "\titers: 200, epoch: 28 | loss: 0.0704893\n",
      "\tspeed: 0.0348s/iter; left time: 562.5983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0723526 Vali Loss: 0.0874381 Test Loss: 0.0995070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0719698\n",
      "\tspeed: 0.0637s/iter; left time: 1021.6506s\n",
      "\titers: 200, epoch: 29 | loss: 0.0737825\n",
      "\tspeed: 0.0349s/iter; left time: 555.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0723145 Vali Loss: 0.0872210 Test Loss: 0.0994940\n",
      "Validation loss decreased (0.087300 --> 0.087221).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0719350\n",
      "\tspeed: 0.0646s/iter; left time: 1021.0514s\n",
      "\titers: 200, epoch: 30 | loss: 0.0680640\n",
      "\tspeed: 0.0349s/iter; left time: 547.8738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0723107 Vali Loss: 0.0873842 Test Loss: 0.0995497\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0712590\n",
      "\tspeed: 0.0639s/iter; left time: 995.7126s\n",
      "\titers: 200, epoch: 31 | loss: 0.0753886\n",
      "\tspeed: 0.0351s/iter; left time: 543.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722937 Vali Loss: 0.0872571 Test Loss: 0.0995097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0728941\n",
      "\tspeed: 0.0638s/iter; left time: 980.0293s\n",
      "\titers: 200, epoch: 32 | loss: 0.0735612\n",
      "\tspeed: 0.0349s/iter; left time: 532.3796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0722469 Vali Loss: 0.0872312 Test Loss: 0.0996675\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0726290\n",
      "\tspeed: 0.0635s/iter; left time: 961.6007s\n",
      "\titers: 200, epoch: 33 | loss: 0.0751589\n",
      "\tspeed: 0.0349s/iter; left time: 525.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0722370 Vali Loss: 0.0873351 Test Loss: 0.0995702\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0691960\n",
      "\tspeed: 0.0635s/iter; left time: 946.1783s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734838\n",
      "\tspeed: 0.0350s/iter; left time: 517.7410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0722115 Vali Loss: 0.0873230 Test Loss: 0.0995916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694353\n",
      "\tspeed: 0.0639s/iter; left time: 937.6417s\n",
      "\titers: 200, epoch: 35 | loss: 0.0798021\n",
      "\tspeed: 0.0348s/iter; left time: 508.0222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0722289 Vali Loss: 0.0873763 Test Loss: 0.0996190\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0709907\n",
      "\tspeed: 0.0638s/iter; left time: 922.1747s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716150\n",
      "\tspeed: 0.0348s/iter; left time: 499.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0721395 Vali Loss: 0.0874136 Test Loss: 0.0995644\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0730195\n",
      "\tspeed: 0.0633s/iter; left time: 901.1820s\n",
      "\titers: 200, epoch: 37 | loss: 0.0703072\n",
      "\tspeed: 0.0348s/iter; left time: 492.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0721677 Vali Loss: 0.0873755 Test Loss: 0.0996328\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0705547\n",
      "\tspeed: 0.0639s/iter; left time: 894.9312s\n",
      "\titers: 200, epoch: 38 | loss: 0.0721194\n",
      "\tspeed: 0.0349s/iter; left time: 485.1501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0721829 Vali Loss: 0.0873100 Test Loss: 0.0995601\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0740595\n",
      "\tspeed: 0.0640s/iter; left time: 883.1529s\n",
      "\titers: 200, epoch: 39 | loss: 0.0759868\n",
      "\tspeed: 0.0347s/iter; left time: 475.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0721212 Vali Loss: 0.0872104 Test Loss: 0.0995649\n",
      "Validation loss decreased (0.087221 --> 0.087210).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0714033\n",
      "\tspeed: 0.0633s/iter; left time: 859.0234s\n",
      "\titers: 200, epoch: 40 | loss: 0.0775736\n",
      "\tspeed: 0.0350s/iter; left time: 470.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0721288 Vali Loss: 0.0872514 Test Loss: 0.0995313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0671455\n",
      "\tspeed: 0.0642s/iter; left time: 856.3591s\n",
      "\titers: 200, epoch: 41 | loss: 0.0723835\n",
      "\tspeed: 0.0349s/iter; left time: 461.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0721268 Vali Loss: 0.0872710 Test Loss: 0.0995070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0769761\n",
      "\tspeed: 0.0639s/iter; left time: 838.7137s\n",
      "\titers: 200, epoch: 42 | loss: 0.0741773\n",
      "\tspeed: 0.0350s/iter; left time: 455.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0721263 Vali Loss: 0.0873013 Test Loss: 0.0995426\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0737671\n",
      "\tspeed: 0.0642s/iter; left time: 827.4074s\n",
      "\titers: 200, epoch: 43 | loss: 0.0743199\n",
      "\tspeed: 0.0349s/iter; left time: 446.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0721220 Vali Loss: 0.0872798 Test Loss: 0.0995181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0705272\n",
      "\tspeed: 0.0637s/iter; left time: 806.8180s\n",
      "\titers: 200, epoch: 44 | loss: 0.0677232\n",
      "\tspeed: 0.0348s/iter; left time: 437.4343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0721261 Vali Loss: 0.0872802 Test Loss: 0.0995224\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0704778\n",
      "\tspeed: 0.0637s/iter; left time: 792.6969s\n",
      "\titers: 200, epoch: 45 | loss: 0.0697315\n",
      "\tspeed: 0.0348s/iter; left time: 429.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0721031 Vali Loss: 0.0872046 Test Loss: 0.0995535\n",
      "Validation loss decreased (0.087210 --> 0.087205).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0701408\n",
      "\tspeed: 0.0641s/iter; left time: 782.7890s\n",
      "\titers: 200, epoch: 46 | loss: 0.0692527\n",
      "\tspeed: 0.0347s/iter; left time: 420.3872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0720786 Vali Loss: 0.0872790 Test Loss: 0.0995581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0739510\n",
      "\tspeed: 0.0636s/iter; left time: 762.9644s\n",
      "\titers: 200, epoch: 47 | loss: 0.0746403\n",
      "\tspeed: 0.0347s/iter; left time: 412.9681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0720801 Vali Loss: 0.0872303 Test Loss: 0.0995519\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0728113\n",
      "\tspeed: 0.0638s/iter; left time: 751.0546s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714614\n",
      "\tspeed: 0.0350s/iter; left time: 408.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720379 Vali Loss: 0.0872027 Test Loss: 0.0995157\n",
      "Validation loss decreased (0.087205 --> 0.087203).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0716667\n",
      "\tspeed: 0.0644s/iter; left time: 743.8222s\n",
      "\titers: 200, epoch: 49 | loss: 0.0703278\n",
      "\tspeed: 0.0348s/iter; left time: 398.6068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720567 Vali Loss: 0.0872355 Test Loss: 0.0995463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738860\n",
      "\tspeed: 0.0640s/iter; left time: 724.4079s\n",
      "\titers: 200, epoch: 50 | loss: 0.0701296\n",
      "\tspeed: 0.0349s/iter; left time: 391.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720803 Vali Loss: 0.0873472 Test Loss: 0.0995371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0700471\n",
      "\tspeed: 0.0636s/iter; left time: 706.5781s\n",
      "\titers: 200, epoch: 51 | loss: 0.0730366\n",
      "\tspeed: 0.0347s/iter; left time: 381.4985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0720552 Vali Loss: 0.0871913 Test Loss: 0.0995232\n",
      "Validation loss decreased (0.087203 --> 0.087191).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0715506\n",
      "\tspeed: 0.0639s/iter; left time: 695.4474s\n",
      "\titers: 200, epoch: 52 | loss: 0.0788366\n",
      "\tspeed: 0.0348s/iter; left time: 375.4280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0720206 Vali Loss: 0.0872680 Test Loss: 0.0995176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0734903\n",
      "\tspeed: 0.0643s/iter; left time: 684.5959s\n",
      "\titers: 200, epoch: 53 | loss: 0.0793007\n",
      "\tspeed: 0.0349s/iter; left time: 368.0538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0720622 Vali Loss: 0.0872800 Test Loss: 0.0995366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0712500\n",
      "\tspeed: 0.0634s/iter; left time: 661.1482s\n",
      "\titers: 200, epoch: 54 | loss: 0.0738263\n",
      "\tspeed: 0.0348s/iter; left time: 359.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0720450 Vali Loss: 0.0871872 Test Loss: 0.0995247\n",
      "Validation loss decreased (0.087191 --> 0.087187).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0750317\n",
      "\tspeed: 0.0639s/iter; left time: 652.5881s\n",
      "\titers: 200, epoch: 55 | loss: 0.0706412\n",
      "\tspeed: 0.0348s/iter; left time: 351.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0720524 Vali Loss: 0.0873139 Test Loss: 0.0995383\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0734314\n",
      "\tspeed: 0.0638s/iter; left time: 636.8701s\n",
      "\titers: 200, epoch: 56 | loss: 0.0661391\n",
      "\tspeed: 0.0349s/iter; left time: 344.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0720490 Vali Loss: 0.0872193 Test Loss: 0.0995244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0745966\n",
      "\tspeed: 0.0640s/iter; left time: 624.8213s\n",
      "\titers: 200, epoch: 57 | loss: 0.0707790\n",
      "\tspeed: 0.0346s/iter; left time: 334.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0720485 Vali Loss: 0.0872726 Test Loss: 0.0995388\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0686515\n",
      "\tspeed: 0.0636s/iter; left time: 606.3552s\n",
      "\titers: 200, epoch: 58 | loss: 0.0735711\n",
      "\tspeed: 0.0347s/iter; left time: 327.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0720425 Vali Loss: 0.0873438 Test Loss: 0.0995281\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0719042\n",
      "\tspeed: 0.0633s/iter; left time: 589.0766s\n",
      "\titers: 200, epoch: 59 | loss: 0.0699061\n",
      "\tspeed: 0.0348s/iter; left time: 320.8892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0720623 Vali Loss: 0.0872118 Test Loss: 0.0995263\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0748541\n",
      "\tspeed: 0.0638s/iter; left time: 579.6535s\n",
      "\titers: 200, epoch: 60 | loss: 0.0702347\n",
      "\tspeed: 0.0347s/iter; left time: 311.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0720553 Vali Loss: 0.0872779 Test Loss: 0.0995289\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0715567\n",
      "\tspeed: 0.0638s/iter; left time: 565.5470s\n",
      "\titers: 200, epoch: 61 | loss: 0.0686040\n",
      "\tspeed: 0.0347s/iter; left time: 303.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0720097 Vali Loss: 0.0872293 Test Loss: 0.0995297\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0671754\n",
      "\tspeed: 0.0635s/iter; left time: 548.6304s\n",
      "\titers: 200, epoch: 62 | loss: 0.0716106\n",
      "\tspeed: 0.0348s/iter; left time: 296.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0720588 Vali Loss: 0.0872945 Test Loss: 0.0995347\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0733839\n",
      "\tspeed: 0.0634s/iter; left time: 533.6843s\n",
      "\titers: 200, epoch: 63 | loss: 0.0701204\n",
      "\tspeed: 0.0349s/iter; left time: 290.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0719997 Vali Loss: 0.0872096 Test Loss: 0.0995342\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0736200\n",
      "\tspeed: 0.0638s/iter; left time: 522.5718s\n",
      "\titers: 200, epoch: 64 | loss: 0.0726243\n",
      "\tspeed: 0.0348s/iter; left time: 281.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0720378 Vali Loss: 0.0870822 Test Loss: 0.0995322\n",
      "Validation loss decreased (0.087187 --> 0.087082).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0737420\n",
      "\tspeed: 0.0646s/iter; left time: 514.4248s\n",
      "\titers: 200, epoch: 65 | loss: 0.0728158\n",
      "\tspeed: 0.0350s/iter; left time: 274.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0720535 Vali Loss: 0.0872863 Test Loss: 0.0995258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0738135\n",
      "\tspeed: 0.0633s/iter; left time: 490.0502s\n",
      "\titers: 200, epoch: 66 | loss: 0.0672279\n",
      "\tspeed: 0.0350s/iter; left time: 267.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0720467 Vali Loss: 0.0873255 Test Loss: 0.0995291\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0702585\n",
      "\tspeed: 0.0634s/iter; left time: 476.4806s\n",
      "\titers: 200, epoch: 67 | loss: 0.0712751\n",
      "\tspeed: 0.0350s/iter; left time: 259.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0719875 Vali Loss: 0.0872351 Test Loss: 0.0995178\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0701834\n",
      "\tspeed: 0.0636s/iter; left time: 464.1901s\n",
      "\titers: 200, epoch: 68 | loss: 0.0745251\n",
      "\tspeed: 0.0350s/iter; left time: 251.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720706 Vali Loss: 0.0872722 Test Loss: 0.0995202\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0687376\n",
      "\tspeed: 0.0638s/iter; left time: 450.8925s\n",
      "\titers: 200, epoch: 69 | loss: 0.0743411\n",
      "\tspeed: 0.0345s/iter; left time: 240.4222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0720265 Vali Loss: 0.0873333 Test Loss: 0.0995157\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0683332\n",
      "\tspeed: 0.0636s/iter; left time: 435.2781s\n",
      "\titers: 200, epoch: 70 | loss: 0.0714080\n",
      "\tspeed: 0.0350s/iter; left time: 235.9815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720460 Vali Loss: 0.0872303 Test Loss: 0.0995237\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0679881\n",
      "\tspeed: 0.0640s/iter; left time: 424.0507s\n",
      "\titers: 200, epoch: 71 | loss: 0.0746943\n",
      "\tspeed: 0.0348s/iter; left time: 227.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0720076 Vali Loss: 0.0872077 Test Loss: 0.0995299\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0696613\n",
      "\tspeed: 0.0637s/iter; left time: 407.5976s\n",
      "\titers: 200, epoch: 72 | loss: 0.0704112\n",
      "\tspeed: 0.0349s/iter; left time: 219.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720320 Vali Loss: 0.0873409 Test Loss: 0.0995243\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0660415\n",
      "\tspeed: 0.0639s/iter; left time: 394.3002s\n",
      "\titers: 200, epoch: 73 | loss: 0.0716211\n",
      "\tspeed: 0.0349s/iter; left time: 211.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0720218 Vali Loss: 0.0872789 Test Loss: 0.0995323\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0706911\n",
      "\tspeed: 0.0640s/iter; left time: 380.5219s\n",
      "\titers: 200, epoch: 74 | loss: 0.0775421\n",
      "\tspeed: 0.0352s/iter; left time: 205.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0720320 Vali Loss: 0.0872372 Test Loss: 0.0995224\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02484327182173729, rmse:0.1576174795627594, mae:0.09953224658966064, rse:0.5437356233596802\n",
      "Intermediate time for GB and pred_len 24: 00h:19m:15.51s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1368649\n",
      "\tspeed: 0.0554s/iter; left time: 1234.6488s\n",
      "\titers: 200, epoch: 1 | loss: 0.1319336\n",
      "\tspeed: 0.0348s/iter; left time: 773.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.1355056 Vali Loss: 0.1317134 Test Loss: 0.1549273\n",
      "Validation loss decreased (inf --> 0.131713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1101865\n",
      "\tspeed: 0.0658s/iter; left time: 1452.8023s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015781\n",
      "\tspeed: 0.0349s/iter; left time: 767.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1090339 Vali Loss: 0.1182640 Test Loss: 0.1402453\n",
      "Validation loss decreased (0.131713 --> 0.118264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019381\n",
      "\tspeed: 0.0643s/iter; left time: 1406.1548s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028636\n",
      "\tspeed: 0.0348s/iter; left time: 757.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1039787 Vali Loss: 0.1176117 Test Loss: 0.1411680\n",
      "Validation loss decreased (0.118264 --> 0.117612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016131\n",
      "\tspeed: 0.0666s/iter; left time: 1440.7773s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025104\n",
      "\tspeed: 0.0348s/iter; left time: 749.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1026030 Vali Loss: 0.1165771 Test Loss: 0.1399828\n",
      "Validation loss decreased (0.117612 --> 0.116577).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1020755\n",
      "\tspeed: 0.0639s/iter; left time: 1366.8705s\n",
      "\titers: 200, epoch: 5 | loss: 0.0942004\n",
      "\tspeed: 0.0348s/iter; left time: 740.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1014609 Vali Loss: 0.1165077 Test Loss: 0.1414991\n",
      "Validation loss decreased (0.116577 --> 0.116508).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1025276\n",
      "\tspeed: 0.0648s/iter; left time: 1373.1437s\n",
      "\titers: 200, epoch: 6 | loss: 0.1029382\n",
      "\tspeed: 0.0348s/iter; left time: 733.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1005378 Vali Loss: 0.1160497 Test Loss: 0.1398813\n",
      "Validation loss decreased (0.116508 --> 0.116050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1035333\n",
      "\tspeed: 0.0643s/iter; left time: 1347.0922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0968630\n",
      "\tspeed: 0.0348s/iter; left time: 725.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0997119 Vali Loss: 0.1159672 Test Loss: 0.1391855\n",
      "Validation loss decreased (0.116050 --> 0.115967).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1007003\n",
      "\tspeed: 0.0631s/iter; left time: 1307.9745s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977097\n",
      "\tspeed: 0.0348s/iter; left time: 717.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0988782 Vali Loss: 0.1170164 Test Loss: 0.1406159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0989300\n",
      "\tspeed: 0.0641s/iter; left time: 1314.0850s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987533\n",
      "\tspeed: 0.0348s/iter; left time: 711.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0981571 Vali Loss: 0.1171109 Test Loss: 0.1431257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996781\n",
      "\tspeed: 0.0636s/iter; left time: 1290.0351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0938317\n",
      "\tspeed: 0.0348s/iter; left time: 703.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0975499 Vali Loss: 0.1171131 Test Loss: 0.1413700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0966019\n",
      "\tspeed: 0.0648s/iter; left time: 1299.9283s\n",
      "\titers: 200, epoch: 11 | loss: 0.0990978\n",
      "\tspeed: 0.0348s/iter; left time: 694.8137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0969347 Vali Loss: 0.1170274 Test Loss: 0.1427449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012876\n",
      "\tspeed: 0.0646s/iter; left time: 1280.6423s\n",
      "\titers: 200, epoch: 12 | loss: 0.0973939\n",
      "\tspeed: 0.0348s/iter; left time: 687.4680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0964552 Vali Loss: 0.1163485 Test Loss: 0.1403130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0965584\n",
      "\tspeed: 0.0634s/iter; left time: 1244.4086s\n",
      "\titers: 200, epoch: 13 | loss: 0.0978759\n",
      "\tspeed: 0.0348s/iter; left time: 679.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0960863 Vali Loss: 0.1174094 Test Loss: 0.1429162\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0961191\n",
      "\tspeed: 0.0655s/iter; left time: 1270.0212s\n",
      "\titers: 200, epoch: 14 | loss: 0.0933269\n",
      "\tspeed: 0.0353s/iter; left time: 681.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 224 | Train Loss: 0.0955543 Vali Loss: 0.1173004 Test Loss: 0.1413187\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0903248\n",
      "\tspeed: 0.0648s/iter; left time: 1242.7000s\n",
      "\titers: 200, epoch: 15 | loss: 0.0932759\n",
      "\tspeed: 0.0349s/iter; left time: 664.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0952487 Vali Loss: 0.1174274 Test Loss: 0.1424316\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0980628\n",
      "\tspeed: 0.0643s/iter; left time: 1218.5882s\n",
      "\titers: 200, epoch: 16 | loss: 0.0997342\n",
      "\tspeed: 0.0353s/iter; left time: 664.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0949437 Vali Loss: 0.1175647 Test Loss: 0.1428966\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0929104\n",
      "\tspeed: 0.0666s/iter; left time: 1245.6502s\n",
      "\titers: 200, epoch: 17 | loss: 0.0939656\n",
      "\tspeed: 0.0352s/iter; left time: 656.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0946952 Vali Loss: 0.1172830 Test Loss: 0.1419807\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04162506014108658, rmse:0.20402219891548157, mae:0.13918548822402954, rse:0.7055371999740601\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1341442\n",
      "\tspeed: 0.0374s/iter; left time: 834.2353s\n",
      "\titers: 200, epoch: 1 | loss: 0.1214196\n",
      "\tspeed: 0.0352s/iter; left time: 780.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.1354141 Vali Loss: 0.1306381 Test Loss: 0.1532616\n",
      "Validation loss decreased (inf --> 0.130638).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1061506\n",
      "\tspeed: 0.0676s/iter; left time: 1491.4995s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015642\n",
      "\tspeed: 0.0351s/iter; left time: 771.7400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.1090903 Vali Loss: 0.1179282 Test Loss: 0.1399687\n",
      "Validation loss decreased (0.130638 --> 0.117928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033960\n",
      "\tspeed: 0.0667s/iter; left time: 1458.3606s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050560\n",
      "\tspeed: 0.0351s/iter; left time: 763.6208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.1041172 Vali Loss: 0.1176966 Test Loss: 0.1399309\n",
      "Validation loss decreased (0.117928 --> 0.117697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971541\n",
      "\tspeed: 0.0711s/iter; left time: 1538.1264s\n",
      "\titers: 200, epoch: 4 | loss: 0.1045809\n",
      "\tspeed: 0.0352s/iter; left time: 757.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.1028417 Vali Loss: 0.1172740 Test Loss: 0.1405992\n",
      "Validation loss decreased (0.117697 --> 0.117274).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0983329\n",
      "\tspeed: 0.0662s/iter; left time: 1416.0438s\n",
      "\titers: 200, epoch: 5 | loss: 0.1046617\n",
      "\tspeed: 0.0353s/iter; left time: 751.0190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 224 | Train Loss: 0.1018973 Vali Loss: 0.1172741 Test Loss: 0.1405071\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947971\n",
      "\tspeed: 0.0661s/iter; left time: 1400.4396s\n",
      "\titers: 200, epoch: 6 | loss: 0.1064766\n",
      "\tspeed: 0.0352s/iter; left time: 741.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 224 | Train Loss: 0.1011226 Vali Loss: 0.1168439 Test Loss: 0.1397677\n",
      "Validation loss decreased (0.117274 --> 0.116844).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0962860\n",
      "\tspeed: 0.0659s/iter; left time: 1380.9897s\n",
      "\titers: 200, epoch: 7 | loss: 0.0969255\n",
      "\tspeed: 0.0351s/iter; left time: 732.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.1002986 Vali Loss: 0.1166861 Test Loss: 0.1398334\n",
      "Validation loss decreased (0.116844 --> 0.116686).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994120\n",
      "\tspeed: 0.0673s/iter; left time: 1394.4946s\n",
      "\titers: 200, epoch: 8 | loss: 0.0989460\n",
      "\tspeed: 0.0351s/iter; left time: 724.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.0996260 Vali Loss: 0.1169189 Test Loss: 0.1393265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0979606\n",
      "\tspeed: 0.0655s/iter; left time: 1343.2435s\n",
      "\titers: 200, epoch: 9 | loss: 0.1020230\n",
      "\tspeed: 0.0352s/iter; left time: 717.6583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 224 | Train Loss: 0.0990757 Vali Loss: 0.1167031 Test Loss: 0.1406324\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0977345\n",
      "\tspeed: 0.0664s/iter; left time: 1346.3870s\n",
      "\titers: 200, epoch: 10 | loss: 0.0989595\n",
      "\tspeed: 0.0350s/iter; left time: 706.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0984879 Vali Loss: 0.1169406 Test Loss: 0.1403176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0949658\n",
      "\tspeed: 0.0658s/iter; left time: 1320.7527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0942378\n",
      "\tspeed: 0.0350s/iter; left time: 698.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0980638 Vali Loss: 0.1169103 Test Loss: 0.1412480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0967921\n",
      "\tspeed: 0.0652s/iter; left time: 1292.5768s\n",
      "\titers: 200, epoch: 12 | loss: 0.1010688\n",
      "\tspeed: 0.0350s/iter; left time: 690.3093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0976295 Vali Loss: 0.1171023 Test Loss: 0.1417844\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0940424\n",
      "\tspeed: 0.0652s/iter; left time: 1279.0231s\n",
      "\titers: 200, epoch: 13 | loss: 0.0925433\n",
      "\tspeed: 0.0351s/iter; left time: 683.9504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0971849 Vali Loss: 0.1174168 Test Loss: 0.1420580\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0973356\n",
      "\tspeed: 0.0647s/iter; left time: 1254.7673s\n",
      "\titers: 200, epoch: 14 | loss: 0.0963790\n",
      "\tspeed: 0.0349s/iter; left time: 673.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0968083 Vali Loss: 0.1169749 Test Loss: 0.1419740\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0981661\n",
      "\tspeed: 0.0649s/iter; left time: 1244.3622s\n",
      "\titers: 200, epoch: 15 | loss: 0.0942422\n",
      "\tspeed: 0.0349s/iter; left time: 665.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0964964 Vali Loss: 0.1174841 Test Loss: 0.1431663\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0933076\n",
      "\tspeed: 0.0658s/iter; left time: 1245.5415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0971909\n",
      "\tspeed: 0.0349s/iter; left time: 656.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0962417 Vali Loss: 0.1168250 Test Loss: 0.1426309\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0938393\n",
      "\tspeed: 0.0647s/iter; left time: 1210.1833s\n",
      "\titers: 200, epoch: 17 | loss: 0.0952472\n",
      "\tspeed: 0.0348s/iter; left time: 647.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0959215 Vali Loss: 0.1170430 Test Loss: 0.1408603\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04170362278819084, rmse:0.2042146474123001, mae:0.139833465218544, rse:0.7062026858329773\n",
      "Intermediate time for GB and pred_len 96: 00h:05m:53.14s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1350723\n",
      "\tspeed: 0.0527s/iter; left time: 1170.6034s\n",
      "\titers: 200, epoch: 1 | loss: 0.1271851\n",
      "\tspeed: 0.0360s/iter; left time: 795.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 223 | Train Loss: 0.1370788 Vali Loss: 0.1339603 Test Loss: 0.1580056\n",
      "Validation loss decreased (inf --> 0.133960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1142252\n",
      "\tspeed: 0.0650s/iter; left time: 1428.2764s\n",
      "\titers: 200, epoch: 2 | loss: 0.1071705\n",
      "\tspeed: 0.0352s/iter; left time: 771.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1134985 Vali Loss: 0.1227696 Test Loss: 0.1473785\n",
      "Validation loss decreased (0.133960 --> 0.122770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099929\n",
      "\tspeed: 0.0664s/iter; left time: 1444.4058s\n",
      "\titers: 200, epoch: 3 | loss: 0.1064361\n",
      "\tspeed: 0.0352s/iter; left time: 762.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.1086618 Vali Loss: 0.1216080 Test Loss: 0.1464609\n",
      "Validation loss decreased (0.122770 --> 0.121608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087356\n",
      "\tspeed: 0.0647s/iter; left time: 1393.1307s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129826\n",
      "\tspeed: 0.0352s/iter; left time: 753.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1071192 Vali Loss: 0.1217823 Test Loss: 0.1464874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1034026\n",
      "\tspeed: 0.0643s/iter; left time: 1369.7788s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095601\n",
      "\tspeed: 0.0352s/iter; left time: 746.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1057389 Vali Loss: 0.1211913 Test Loss: 0.1467036\n",
      "Validation loss decreased (0.121608 --> 0.121191).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1024049\n",
      "\tspeed: 0.0649s/iter; left time: 1368.0309s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049406\n",
      "\tspeed: 0.0352s/iter; left time: 739.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1045543 Vali Loss: 0.1217408 Test Loss: 0.1483685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1023685\n",
      "\tspeed: 0.0635s/iter; left time: 1325.5652s\n",
      "\titers: 200, epoch: 7 | loss: 0.0984707\n",
      "\tspeed: 0.0352s/iter; left time: 731.3103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1035728 Vali Loss: 0.1217344 Test Loss: 0.1492728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1017310\n",
      "\tspeed: 0.0651s/iter; left time: 1344.0573s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068790\n",
      "\tspeed: 0.0353s/iter; left time: 724.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.1027208 Vali Loss: 0.1218432 Test Loss: 0.1475727\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1029130\n",
      "\tspeed: 0.0652s/iter; left time: 1331.2002s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979883\n",
      "\tspeed: 0.0352s/iter; left time: 714.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1020829 Vali Loss: 0.1217830 Test Loss: 0.1499628\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0992078\n",
      "\tspeed: 0.0639s/iter; left time: 1290.4150s\n",
      "\titers: 200, epoch: 10 | loss: 0.1015885\n",
      "\tspeed: 0.0352s/iter; left time: 706.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1014156 Vali Loss: 0.1225091 Test Loss: 0.1514542\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1001842\n",
      "\tspeed: 0.0637s/iter; left time: 1272.7056s\n",
      "\titers: 200, epoch: 11 | loss: 0.0997025\n",
      "\tspeed: 0.0352s/iter; left time: 698.6270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1008091 Vali Loss: 0.1216951 Test Loss: 0.1483363\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0969195\n",
      "\tspeed: 0.0637s/iter; left time: 1257.3692s\n",
      "\titers: 200, epoch: 12 | loss: 0.1000460\n",
      "\tspeed: 0.0352s/iter; left time: 691.6470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.1002690 Vali Loss: 0.1222479 Test Loss: 0.1495636\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1010885\n",
      "\tspeed: 0.0633s/iter; left time: 1236.6747s\n",
      "\titers: 200, epoch: 13 | loss: 0.1027193\n",
      "\tspeed: 0.0351s/iter; left time: 682.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0998652 Vali Loss: 0.1220233 Test Loss: 0.1502681\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981189\n",
      "\tspeed: 0.0650s/iter; left time: 1253.8337s\n",
      "\titers: 200, epoch: 14 | loss: 0.0994089\n",
      "\tspeed: 0.0353s/iter; left time: 678.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0994364 Vali Loss: 0.1225578 Test Loss: 0.1513837\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1023321\n",
      "\tspeed: 0.0644s/iter; left time: 1227.9761s\n",
      "\titers: 200, epoch: 15 | loss: 0.1032972\n",
      "\tspeed: 0.0351s/iter; left time: 667.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0990828 Vali Loss: 0.1228028 Test Loss: 0.1514718\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04451335221529007, rmse:0.21098187565803528, mae:0.1467035859823227, rse:0.731504499912262\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1345446\n",
      "\tspeed: 0.0403s/iter; left time: 895.2149s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272192\n",
      "\tspeed: 0.0363s/iter; left time: 801.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 223 | Train Loss: 0.1373576 Vali Loss: 0.1342064 Test Loss: 0.1581632\n",
      "Validation loss decreased (inf --> 0.134206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1134878\n",
      "\tspeed: 0.0663s/iter; left time: 1457.3118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108844\n",
      "\tspeed: 0.0351s/iter; left time: 768.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1132910 Vali Loss: 0.1233612 Test Loss: 0.1481872\n",
      "Validation loss decreased (0.134206 --> 0.123361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1113022\n",
      "\tspeed: 0.0662s/iter; left time: 1440.4657s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082540\n",
      "\tspeed: 0.0360s/iter; left time: 779.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.1087626 Vali Loss: 0.1223666 Test Loss: 0.1467507\n",
      "Validation loss decreased (0.123361 --> 0.122367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1096119\n",
      "\tspeed: 0.0676s/iter; left time: 1456.1337s\n",
      "\titers: 200, epoch: 4 | loss: 0.1078516\n",
      "\tspeed: 0.0352s/iter; left time: 753.7685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1072762 Vali Loss: 0.1222670 Test Loss: 0.1473828\n",
      "Validation loss decreased (0.122367 --> 0.122267).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074537\n",
      "\tspeed: 0.0667s/iter; left time: 1421.4816s\n",
      "\titers: 200, epoch: 5 | loss: 0.1054640\n",
      "\tspeed: 0.0353s/iter; left time: 749.0800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1057186 Vali Loss: 0.1218859 Test Loss: 0.1465276\n",
      "Validation loss decreased (0.122267 --> 0.121886).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062931\n",
      "\tspeed: 0.0656s/iter; left time: 1383.5166s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022995\n",
      "\tspeed: 0.0352s/iter; left time: 739.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1044480 Vali Loss: 0.1219488 Test Loss: 0.1476138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1007487\n",
      "\tspeed: 0.0651s/iter; left time: 1359.1230s\n",
      "\titers: 200, epoch: 7 | loss: 0.1070287\n",
      "\tspeed: 0.0353s/iter; left time: 733.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1035077 Vali Loss: 0.1217108 Test Loss: 0.1468497\n",
      "Validation loss decreased (0.121886 --> 0.121711).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016237\n",
      "\tspeed: 0.0663s/iter; left time: 1367.4301s\n",
      "\titers: 200, epoch: 8 | loss: 0.1010307\n",
      "\tspeed: 0.0351s/iter; left time: 721.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1026994 Vali Loss: 0.1222955 Test Loss: 0.1479983\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1011974\n",
      "\tspeed: 0.0652s/iter; left time: 1330.5172s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042520\n",
      "\tspeed: 0.0353s/iter; left time: 717.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1019803 Vali Loss: 0.1226025 Test Loss: 0.1500250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0998199\n",
      "\tspeed: 0.0646s/iter; left time: 1303.9361s\n",
      "\titers: 200, epoch: 10 | loss: 0.1032624\n",
      "\tspeed: 0.0352s/iter; left time: 706.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1012618 Vali Loss: 0.1232424 Test Loss: 0.1511443\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1019999\n",
      "\tspeed: 0.0647s/iter; left time: 1291.8289s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031724\n",
      "\tspeed: 0.0352s/iter; left time: 698.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1005646 Vali Loss: 0.1225561 Test Loss: 0.1496281\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1002238\n",
      "\tspeed: 0.0654s/iter; left time: 1292.4244s\n",
      "\titers: 200, epoch: 12 | loss: 0.0998397\n",
      "\tspeed: 0.0353s/iter; left time: 693.8179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0999939 Vali Loss: 0.1233360 Test Loss: 0.1489431\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1030586\n",
      "\tspeed: 0.0655s/iter; left time: 1278.9109s\n",
      "\titers: 200, epoch: 13 | loss: 0.1004540\n",
      "\tspeed: 0.0354s/iter; left time: 688.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0993963 Vali Loss: 0.1238692 Test Loss: 0.1506494\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0976809\n",
      "\tspeed: 0.0663s/iter; left time: 1280.0108s\n",
      "\titers: 200, epoch: 14 | loss: 0.0994988\n",
      "\tspeed: 0.0354s/iter; left time: 679.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0990119 Vali Loss: 0.1232814 Test Loss: 0.1509458\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0972044\n",
      "\tspeed: 0.0653s/iter; left time: 1245.5241s\n",
      "\titers: 200, epoch: 15 | loss: 0.1007163\n",
      "\tspeed: 0.0352s/iter; left time: 667.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0985824 Vali Loss: 0.1235543 Test Loss: 0.1504480\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1012219\n",
      "\tspeed: 0.0649s/iter; left time: 1223.5909s\n",
      "\titers: 200, epoch: 16 | loss: 0.0998645\n",
      "\tspeed: 0.0354s/iter; left time: 664.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0982247 Vali Loss: 0.1236940 Test Loss: 0.1515266\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0975052\n",
      "\tspeed: 0.0646s/iter; left time: 1203.0937s\n",
      "\titers: 200, epoch: 17 | loss: 0.0969503\n",
      "\tspeed: 0.0352s/iter; left time: 652.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0978876 Vali Loss: 0.1239806 Test Loss: 0.1516184\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.044920217245817184, rmse:0.21194389462471008, mae:0.1468495875597, rse:0.734839916229248\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:34.71s\n",
      "Intermediate time for GB: 00h:30m:43.37s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1298670\n",
      "\tspeed: 0.0415s/iter; left time: 925.1134s\n",
      "\titers: 200, epoch: 1 | loss: 0.1123726\n",
      "\tspeed: 0.0216s/iter; left time: 480.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.1356300 Vali Loss: 0.0979842 Test Loss: 0.1105413\n",
      "Validation loss decreased (inf --> 0.097984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0737654\n",
      "\tspeed: 0.0425s/iter; left time: 938.7700s\n",
      "\titers: 200, epoch: 2 | loss: 0.0692282\n",
      "\tspeed: 0.0218s/iter; left time: 478.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0770465 Vali Loss: 0.0648699 Test Loss: 0.0713267\n",
      "Validation loss decreased (0.097984 --> 0.064870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0633628\n",
      "\tspeed: 0.0425s/iter; left time: 928.2808s\n",
      "\titers: 200, epoch: 3 | loss: 0.0653490\n",
      "\tspeed: 0.0215s/iter; left time: 468.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0655215 Vali Loss: 0.0602665 Test Loss: 0.0663078\n",
      "Validation loss decreased (0.064870 --> 0.060267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0622144\n",
      "\tspeed: 0.0423s/iter; left time: 914.6301s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639108\n",
      "\tspeed: 0.0218s/iter; left time: 468.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0624059 Vali Loss: 0.0590331 Test Loss: 0.0655046\n",
      "Validation loss decreased (0.060267 --> 0.059033).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597853\n",
      "\tspeed: 0.0424s/iter; left time: 906.5143s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606989\n",
      "\tspeed: 0.0214s/iter; left time: 456.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0604129 Vali Loss: 0.0572534 Test Loss: 0.0634984\n",
      "Validation loss decreased (0.059033 --> 0.057253).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0565692\n",
      "\tspeed: 0.0425s/iter; left time: 900.4499s\n",
      "\titers: 200, epoch: 6 | loss: 0.0577320\n",
      "\tspeed: 0.0215s/iter; left time: 452.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0591839 Vali Loss: 0.0567175 Test Loss: 0.0627465\n",
      "Validation loss decreased (0.057253 --> 0.056717).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0643436\n",
      "\tspeed: 0.0439s/iter; left time: 920.9720s\n",
      "\titers: 200, epoch: 7 | loss: 0.0603589\n",
      "\tspeed: 0.0215s/iter; left time: 447.9992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0582673 Vali Loss: 0.0561868 Test Loss: 0.0623379\n",
      "Validation loss decreased (0.056717 --> 0.056187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0601041\n",
      "\tspeed: 0.0428s/iter; left time: 888.0656s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537687\n",
      "\tspeed: 0.0216s/iter; left time: 445.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0575629 Vali Loss: 0.0555081 Test Loss: 0.0619841\n",
      "Validation loss decreased (0.056187 --> 0.055508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580762\n",
      "\tspeed: 0.0425s/iter; left time: 871.5189s\n",
      "\titers: 200, epoch: 9 | loss: 0.0556999\n",
      "\tspeed: 0.0216s/iter; left time: 440.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0568983 Vali Loss: 0.0552543 Test Loss: 0.0613716\n",
      "Validation loss decreased (0.055508 --> 0.055254).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0595903\n",
      "\tspeed: 0.0458s/iter; left time: 929.6966s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543491\n",
      "\tspeed: 0.0214s/iter; left time: 432.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0564607 Vali Loss: 0.0551281 Test Loss: 0.0614527\n",
      "Validation loss decreased (0.055254 --> 0.055128).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582845\n",
      "\tspeed: 0.0424s/iter; left time: 850.2137s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565036\n",
      "\tspeed: 0.0218s/iter; left time: 435.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0559774 Vali Loss: 0.0546737 Test Loss: 0.0609168\n",
      "Validation loss decreased (0.055128 --> 0.054674).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0554969\n",
      "\tspeed: 0.0420s/iter; left time: 832.4733s\n",
      "\titers: 200, epoch: 12 | loss: 0.0551604\n",
      "\tspeed: 0.0214s/iter; left time: 423.1634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0556352 Vali Loss: 0.0545354 Test Loss: 0.0609479\n",
      "Validation loss decreased (0.054674 --> 0.054535).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0534320\n",
      "\tspeed: 0.0419s/iter; left time: 820.9269s\n",
      "\titers: 200, epoch: 13 | loss: 0.0509334\n",
      "\tspeed: 0.0214s/iter; left time: 417.7691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0552956 Vali Loss: 0.0544649 Test Loss: 0.0605663\n",
      "Validation loss decreased (0.054535 --> 0.054465).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0569654\n",
      "\tspeed: 0.0422s/iter; left time: 817.9739s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535476\n",
      "\tspeed: 0.0214s/iter; left time: 413.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0550428 Vali Loss: 0.0541201 Test Loss: 0.0604142\n",
      "Validation loss decreased (0.054465 --> 0.054120).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0538801\n",
      "\tspeed: 0.0420s/iter; left time: 805.3141s\n",
      "\titers: 200, epoch: 15 | loss: 0.0547211\n",
      "\tspeed: 0.0214s/iter; left time: 408.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0548103 Vali Loss: 0.0540373 Test Loss: 0.0603104\n",
      "Validation loss decreased (0.054120 --> 0.054037).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0519740\n",
      "\tspeed: 0.0420s/iter; left time: 795.2942s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552315\n",
      "\tspeed: 0.0214s/iter; left time: 403.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0545696 Vali Loss: 0.0540554 Test Loss: 0.0603579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0531541\n",
      "\tspeed: 0.0414s/iter; left time: 774.3167s\n",
      "\titers: 200, epoch: 17 | loss: 0.0551341\n",
      "\tspeed: 0.0214s/iter; left time: 399.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0544336 Vali Loss: 0.0536491 Test Loss: 0.0599721\n",
      "Validation loss decreased (0.054037 --> 0.053649).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0536914\n",
      "\tspeed: 0.0424s/iter; left time: 784.8796s\n",
      "\titers: 200, epoch: 18 | loss: 0.0528644\n",
      "\tspeed: 0.0214s/iter; left time: 394.0977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0543115 Vali Loss: 0.0535106 Test Loss: 0.0598589\n",
      "Validation loss decreased (0.053649 --> 0.053511).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0545141\n",
      "\tspeed: 0.0417s/iter; left time: 762.2365s\n",
      "\titers: 200, epoch: 19 | loss: 0.0527273\n",
      "\tspeed: 0.0214s/iter; left time: 389.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0541158 Vali Loss: 0.0536582 Test Loss: 0.0598251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546011\n",
      "\tspeed: 0.0414s/iter; left time: 747.1655s\n",
      "\titers: 200, epoch: 20 | loss: 0.0573375\n",
      "\tspeed: 0.0215s/iter; left time: 385.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0539415 Vali Loss: 0.0535942 Test Loss: 0.0599157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0545147\n",
      "\tspeed: 0.0415s/iter; left time: 740.1909s\n",
      "\titers: 200, epoch: 21 | loss: 0.0549585\n",
      "\tspeed: 0.0214s/iter; left time: 379.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0538274 Vali Loss: 0.0534529 Test Loss: 0.0598036\n",
      "Validation loss decreased (0.053511 --> 0.053453).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0553077\n",
      "\tspeed: 0.0421s/iter; left time: 740.9730s\n",
      "\titers: 200, epoch: 22 | loss: 0.0515996\n",
      "\tspeed: 0.0214s/iter; left time: 375.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0537420 Vali Loss: 0.0532791 Test Loss: 0.0596330\n",
      "Validation loss decreased (0.053453 --> 0.053279).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529407\n",
      "\tspeed: 0.0424s/iter; left time: 736.2075s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524024\n",
      "\tspeed: 0.0214s/iter; left time: 369.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0536276 Vali Loss: 0.0534068 Test Loss: 0.0596825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0540160\n",
      "\tspeed: 0.0415s/iter; left time: 711.4182s\n",
      "\titers: 200, epoch: 24 | loss: 0.0539657\n",
      "\tspeed: 0.0214s/iter; left time: 365.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0535633 Vali Loss: 0.0532834 Test Loss: 0.0595174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0576103\n",
      "\tspeed: 0.0412s/iter; left time: 697.8098s\n",
      "\titers: 200, epoch: 25 | loss: 0.0518737\n",
      "\tspeed: 0.0214s/iter; left time: 360.7308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0534328 Vali Loss: 0.0533031 Test Loss: 0.0596040\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0532881\n",
      "\tspeed: 0.0419s/iter; left time: 700.1183s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546579\n",
      "\tspeed: 0.0214s/iter; left time: 355.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0534073 Vali Loss: 0.0533640 Test Loss: 0.0595210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0513663\n",
      "\tspeed: 0.0416s/iter; left time: 685.9145s\n",
      "\titers: 200, epoch: 27 | loss: 0.0566319\n",
      "\tspeed: 0.0214s/iter; left time: 350.4075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0533159 Vali Loss: 0.0533430 Test Loss: 0.0594933\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0499575\n",
      "\tspeed: 0.0414s/iter; left time: 672.8622s\n",
      "\titers: 200, epoch: 28 | loss: 0.0530464\n",
      "\tspeed: 0.0214s/iter; left time: 345.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0532951 Vali Loss: 0.0531354 Test Loss: 0.0594555\n",
      "Validation loss decreased (0.053279 --> 0.053135).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0519671\n",
      "\tspeed: 0.0419s/iter; left time: 672.1155s\n",
      "\titers: 200, epoch: 29 | loss: 0.0520967\n",
      "\tspeed: 0.0214s/iter; left time: 340.8831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0532587 Vali Loss: 0.0530812 Test Loss: 0.0593866\n",
      "Validation loss decreased (0.053135 --> 0.053081).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0520738\n",
      "\tspeed: 0.0419s/iter; left time: 661.8670s\n",
      "\titers: 200, epoch: 30 | loss: 0.0531664\n",
      "\tspeed: 0.0214s/iter; left time: 336.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0532055 Vali Loss: 0.0530917 Test Loss: 0.0593216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0540286\n",
      "\tspeed: 0.0413s/iter; left time: 643.5799s\n",
      "\titers: 200, epoch: 31 | loss: 0.0566464\n",
      "\tspeed: 0.0214s/iter; left time: 331.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0531638 Vali Loss: 0.0529826 Test Loss: 0.0593910\n",
      "Validation loss decreased (0.053081 --> 0.052983).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0526562\n",
      "\tspeed: 0.0419s/iter; left time: 642.9197s\n",
      "\titers: 200, epoch: 32 | loss: 0.0515179\n",
      "\tspeed: 0.0214s/iter; left time: 326.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0530721 Vali Loss: 0.0531143 Test Loss: 0.0594014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543895\n",
      "\tspeed: 0.0417s/iter; left time: 630.7297s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532493\n",
      "\tspeed: 0.0214s/iter; left time: 321.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0531146 Vali Loss: 0.0529428 Test Loss: 0.0592363\n",
      "Validation loss decreased (0.052983 --> 0.052943).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0551238\n",
      "\tspeed: 0.0419s/iter; left time: 624.0518s\n",
      "\titers: 200, epoch: 34 | loss: 0.0514019\n",
      "\tspeed: 0.0214s/iter; left time: 316.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0530357 Vali Loss: 0.0529991 Test Loss: 0.0592847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0537152\n",
      "\tspeed: 0.0423s/iter; left time: 621.6852s\n",
      "\titers: 200, epoch: 35 | loss: 0.0518303\n",
      "\tspeed: 0.0214s/iter; left time: 311.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0530443 Vali Loss: 0.0530798 Test Loss: 0.0592918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0553218\n",
      "\tspeed: 0.0414s/iter; left time: 598.5321s\n",
      "\titers: 200, epoch: 36 | loss: 0.0520547\n",
      "\tspeed: 0.0214s/iter; left time: 307.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0530445 Vali Loss: 0.0529497 Test Loss: 0.0592279\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0513291\n",
      "\tspeed: 0.0418s/iter; left time: 594.7580s\n",
      "\titers: 200, epoch: 37 | loss: 0.0541513\n",
      "\tspeed: 0.0215s/iter; left time: 303.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0529879 Vali Loss: 0.0529939 Test Loss: 0.0592844\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0505443\n",
      "\tspeed: 0.0414s/iter; left time: 580.7580s\n",
      "\titers: 200, epoch: 38 | loss: 0.0543361\n",
      "\tspeed: 0.0214s/iter; left time: 297.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0529520 Vali Loss: 0.0529140 Test Loss: 0.0591908\n",
      "Validation loss decreased (0.052943 --> 0.052914).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0533418\n",
      "\tspeed: 0.0423s/iter; left time: 583.4322s\n",
      "\titers: 200, epoch: 39 | loss: 0.0524147\n",
      "\tspeed: 0.0214s/iter; left time: 293.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0529510 Vali Loss: 0.0529290 Test Loss: 0.0592367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0498722\n",
      "\tspeed: 0.0417s/iter; left time: 565.8636s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535404\n",
      "\tspeed: 0.0214s/iter; left time: 288.1348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0529404 Vali Loss: 0.0529907 Test Loss: 0.0593157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0529301\n",
      "\tspeed: 0.0413s/iter; left time: 551.5026s\n",
      "\titers: 200, epoch: 41 | loss: 0.0534077\n",
      "\tspeed: 0.0214s/iter; left time: 283.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0529699 Vali Loss: 0.0529282 Test Loss: 0.0591911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0561879\n",
      "\tspeed: 0.0416s/iter; left time: 546.1652s\n",
      "\titers: 200, epoch: 42 | loss: 0.0530915\n",
      "\tspeed: 0.0214s/iter; left time: 279.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0528961 Vali Loss: 0.0529526 Test Loss: 0.0591979\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0507365\n",
      "\tspeed: 0.0415s/iter; left time: 535.1932s\n",
      "\titers: 200, epoch: 43 | loss: 0.0523150\n",
      "\tspeed: 0.0214s/iter; left time: 273.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0529152 Vali Loss: 0.0529601 Test Loss: 0.0592044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0551199\n",
      "\tspeed: 0.0412s/iter; left time: 521.8868s\n",
      "\titers: 200, epoch: 44 | loss: 0.0540401\n",
      "\tspeed: 0.0214s/iter; left time: 269.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0528878 Vali Loss: 0.0529594 Test Loss: 0.0591871\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0514586\n",
      "\tspeed: 0.0414s/iter; left time: 514.9899s\n",
      "\titers: 200, epoch: 45 | loss: 0.0563003\n",
      "\tspeed: 0.0214s/iter; left time: 264.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0528507 Vali Loss: 0.0529300 Test Loss: 0.0591909\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0518282\n",
      "\tspeed: 0.0424s/iter; left time: 518.3305s\n",
      "\titers: 200, epoch: 46 | loss: 0.0541125\n",
      "\tspeed: 0.0291s/iter; left time: 352.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0528566 Vali Loss: 0.0529993 Test Loss: 0.0592228\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0548774\n",
      "\tspeed: 0.0644s/iter; left time: 772.8957s\n",
      "\titers: 200, epoch: 47 | loss: 0.0509543\n",
      "\tspeed: 0.0302s/iter; left time: 358.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0528889 Vali Loss: 0.0529689 Test Loss: 0.0591520\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0550609\n",
      "\tspeed: 0.0623s/iter; left time: 733.8610s\n",
      "\titers: 200, epoch: 48 | loss: 0.0504436\n",
      "\tspeed: 0.0286s/iter; left time: 334.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0528672 Vali Loss: 0.0529224 Test Loss: 0.0591862\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009746785275638103, rmse:0.0987258106470108, mae:0.05919082462787628, rse:0.29053810238838196\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1293662\n",
      "\tspeed: 0.0318s/iter; left time: 709.4411s\n",
      "\titers: 200, epoch: 1 | loss: 0.1084518\n",
      "\tspeed: 0.0289s/iter; left time: 641.7149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.1345529 Vali Loss: 0.0963300 Test Loss: 0.1083074\n",
      "Validation loss decreased (inf --> 0.096330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0789599\n",
      "\tspeed: 0.0652s/iter; left time: 1439.4350s\n",
      "\titers: 200, epoch: 2 | loss: 0.0650750\n",
      "\tspeed: 0.0287s/iter; left time: 631.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0765589 Vali Loss: 0.0644628 Test Loss: 0.0710606\n",
      "Validation loss decreased (0.096330 --> 0.064463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675499\n",
      "\tspeed: 0.0652s/iter; left time: 1425.6710s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669633\n",
      "\tspeed: 0.0291s/iter; left time: 633.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0658001 Vali Loss: 0.0607895 Test Loss: 0.0672820\n",
      "Validation loss decreased (0.064463 --> 0.060790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629823\n",
      "\tspeed: 0.0656s/iter; left time: 1418.6444s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621647\n",
      "\tspeed: 0.0294s/iter; left time: 632.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0626464 Vali Loss: 0.0587480 Test Loss: 0.0651175\n",
      "Validation loss decreased (0.060790 --> 0.058748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635245\n",
      "\tspeed: 0.0677s/iter; left time: 1450.1443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605056\n",
      "\tspeed: 0.0298s/iter; left time: 634.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0606723 Vali Loss: 0.0572892 Test Loss: 0.0640903\n",
      "Validation loss decreased (0.058748 --> 0.057289).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0567591\n",
      "\tspeed: 0.0640s/iter; left time: 1355.6710s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588183\n",
      "\tspeed: 0.0277s/iter; left time: 584.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0593251 Vali Loss: 0.0569096 Test Loss: 0.0635448\n",
      "Validation loss decreased (0.057289 --> 0.056910).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0578025\n",
      "\tspeed: 0.0652s/iter; left time: 1365.5753s\n",
      "\titers: 200, epoch: 7 | loss: 0.0593312\n",
      "\tspeed: 0.0290s/iter; left time: 604.8559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0583814 Vali Loss: 0.0562718 Test Loss: 0.0629522\n",
      "Validation loss decreased (0.056910 --> 0.056272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578907\n",
      "\tspeed: 0.0652s/iter; left time: 1352.3167s\n",
      "\titers: 200, epoch: 8 | loss: 0.0588079\n",
      "\tspeed: 0.0288s/iter; left time: 593.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0575537 Vali Loss: 0.0556826 Test Loss: 0.0618967\n",
      "Validation loss decreased (0.056272 --> 0.055683).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0617650\n",
      "\tspeed: 0.0658s/iter; left time: 1349.5814s\n",
      "\titers: 200, epoch: 9 | loss: 0.0534514\n",
      "\tspeed: 0.0297s/iter; left time: 606.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0570048 Vali Loss: 0.0552326 Test Loss: 0.0617484\n",
      "Validation loss decreased (0.055683 --> 0.055233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0555236\n",
      "\tspeed: 0.0649s/iter; left time: 1316.9155s\n",
      "\titers: 200, epoch: 10 | loss: 0.0538077\n",
      "\tspeed: 0.0296s/iter; left time: 597.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0564032 Vali Loss: 0.0549955 Test Loss: 0.0614280\n",
      "Validation loss decreased (0.055233 --> 0.054996).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0555907\n",
      "\tspeed: 0.0657s/iter; left time: 1318.1450s\n",
      "\titers: 200, epoch: 11 | loss: 0.0555988\n",
      "\tspeed: 0.0303s/iter; left time: 604.8530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0560193 Vali Loss: 0.0549655 Test Loss: 0.0613595\n",
      "Validation loss decreased (0.054996 --> 0.054965).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0571024\n",
      "\tspeed: 0.0640s/iter; left time: 1269.6588s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571437\n",
      "\tspeed: 0.0281s/iter; left time: 553.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0556331 Vali Loss: 0.0542642 Test Loss: 0.0607060\n",
      "Validation loss decreased (0.054965 --> 0.054264).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0581487\n",
      "\tspeed: 0.0424s/iter; left time: 831.8920s\n",
      "\titers: 200, epoch: 13 | loss: 0.0553184\n",
      "\tspeed: 0.0215s/iter; left time: 418.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0552673 Vali Loss: 0.0543863 Test Loss: 0.0610524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0572586\n",
      "\tspeed: 0.0413s/iter; left time: 801.2507s\n",
      "\titers: 200, epoch: 14 | loss: 0.0559977\n",
      "\tspeed: 0.0215s/iter; left time: 413.9933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0550050 Vali Loss: 0.0541198 Test Loss: 0.0608031\n",
      "Validation loss decreased (0.054264 --> 0.054120).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0553904\n",
      "\tspeed: 0.0426s/iter; left time: 816.1232s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553633\n",
      "\tspeed: 0.0215s/iter; left time: 409.0780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0547834 Vali Loss: 0.0540436 Test Loss: 0.0606437\n",
      "Validation loss decreased (0.054120 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0587407\n",
      "\tspeed: 0.0419s/iter; left time: 792.7311s\n",
      "\titers: 200, epoch: 16 | loss: 0.0548178\n",
      "\tspeed: 0.0215s/iter; left time: 404.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0545800 Vali Loss: 0.0537979 Test Loss: 0.0604315\n",
      "Validation loss decreased (0.054044 --> 0.053798).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0535629\n",
      "\tspeed: 0.0417s/iter; left time: 780.6646s\n",
      "\titers: 200, epoch: 17 | loss: 0.0531620\n",
      "\tspeed: 0.0215s/iter; left time: 400.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0544193 Vali Loss: 0.0537036 Test Loss: 0.0601052\n",
      "Validation loss decreased (0.053798 --> 0.053704).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549918\n",
      "\tspeed: 0.0418s/iter; left time: 773.0078s\n",
      "\titers: 200, epoch: 18 | loss: 0.0571273\n",
      "\tspeed: 0.0215s/iter; left time: 395.0622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0541914 Vali Loss: 0.0537891 Test Loss: 0.0603252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0533558\n",
      "\tspeed: 0.0414s/iter; left time: 757.0526s\n",
      "\titers: 200, epoch: 19 | loss: 0.0556851\n",
      "\tspeed: 0.0214s/iter; left time: 389.5046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0540281 Vali Loss: 0.0535258 Test Loss: 0.0600036\n",
      "Validation loss decreased (0.053704 --> 0.053526).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0534450\n",
      "\tspeed: 0.0425s/iter; left time: 766.9382s\n",
      "\titers: 200, epoch: 20 | loss: 0.0529109\n",
      "\tspeed: 0.0221s/iter; left time: 395.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0539696 Vali Loss: 0.0535217 Test Loss: 0.0600964\n",
      "Validation loss decreased (0.053526 --> 0.053522).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0576730\n",
      "\tspeed: 0.0432s/iter; left time: 769.2263s\n",
      "\titers: 200, epoch: 21 | loss: 0.0562272\n",
      "\tspeed: 0.0221s/iter; left time: 392.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0538568 Vali Loss: 0.0534423 Test Loss: 0.0600823\n",
      "Validation loss decreased (0.053522 --> 0.053442).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0584354\n",
      "\tspeed: 0.0442s/iter; left time: 777.9576s\n",
      "\titers: 200, epoch: 22 | loss: 0.0571613\n",
      "\tspeed: 0.0225s/iter; left time: 393.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0537330 Vali Loss: 0.0532508 Test Loss: 0.0599182\n",
      "Validation loss decreased (0.053442 --> 0.053251).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0563859\n",
      "\tspeed: 0.0434s/iter; left time: 754.4608s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520345\n",
      "\tspeed: 0.0222s/iter; left time: 383.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0536130 Vali Loss: 0.0533164 Test Loss: 0.0597778\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0567659\n",
      "\tspeed: 0.0421s/iter; left time: 722.7890s\n",
      "\titers: 200, epoch: 24 | loss: 0.0521040\n",
      "\tspeed: 0.0215s/iter; left time: 366.4917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0535649 Vali Loss: 0.0533078 Test Loss: 0.0597867\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0589507\n",
      "\tspeed: 0.0411s/iter; left time: 696.2132s\n",
      "\titers: 200, epoch: 25 | loss: 0.0548259\n",
      "\tspeed: 0.0215s/iter; left time: 361.5470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0534987 Vali Loss: 0.0532403 Test Loss: 0.0597370\n",
      "Validation loss decreased (0.053251 --> 0.053240).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0520487\n",
      "\tspeed: 0.0413s/iter; left time: 690.3747s\n",
      "\titers: 200, epoch: 26 | loss: 0.0558275\n",
      "\tspeed: 0.0215s/iter; left time: 356.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0534454 Vali Loss: 0.0532098 Test Loss: 0.0596481\n",
      "Validation loss decreased (0.053240 --> 0.053210).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0561691\n",
      "\tspeed: 0.0413s/iter; left time: 680.4006s\n",
      "\titers: 200, epoch: 27 | loss: 0.0522081\n",
      "\tspeed: 0.0215s/iter; left time: 351.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0533647 Vali Loss: 0.0530668 Test Loss: 0.0596505\n",
      "Validation loss decreased (0.053210 --> 0.053067).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0550688\n",
      "\tspeed: 0.0424s/iter; left time: 688.9829s\n",
      "\titers: 200, epoch: 28 | loss: 0.0555525\n",
      "\tspeed: 0.0214s/iter; left time: 345.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0532714 Vali Loss: 0.0531859 Test Loss: 0.0597596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0558985\n",
      "\tspeed: 0.0411s/iter; left time: 659.2092s\n",
      "\titers: 200, epoch: 29 | loss: 0.0521408\n",
      "\tspeed: 0.0214s/iter; left time: 341.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0532727 Vali Loss: 0.0530185 Test Loss: 0.0596468\n",
      "Validation loss decreased (0.053067 --> 0.053018).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537556\n",
      "\tspeed: 0.0424s/iter; left time: 670.5603s\n",
      "\titers: 200, epoch: 30 | loss: 0.0534977\n",
      "\tspeed: 0.0218s/iter; left time: 342.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0531877 Vali Loss: 0.0531073 Test Loss: 0.0596250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550343\n",
      "\tspeed: 0.0417s/iter; left time: 649.7372s\n",
      "\titers: 200, epoch: 31 | loss: 0.0521811\n",
      "\tspeed: 0.0215s/iter; left time: 332.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0531241 Vali Loss: 0.0531039 Test Loss: 0.0596747\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0539435\n",
      "\tspeed: 0.0410s/iter; left time: 630.3320s\n",
      "\titers: 200, epoch: 32 | loss: 0.0491288\n",
      "\tspeed: 0.0215s/iter; left time: 327.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0531421 Vali Loss: 0.0530996 Test Loss: 0.0596391\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0556729\n",
      "\tspeed: 0.0426s/iter; left time: 645.3928s\n",
      "\titers: 200, epoch: 33 | loss: 0.0493943\n",
      "\tspeed: 0.0214s/iter; left time: 322.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0531437 Vali Loss: 0.0530059 Test Loss: 0.0595869\n",
      "Validation loss decreased (0.053018 --> 0.053006).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0569810\n",
      "\tspeed: 0.0419s/iter; left time: 624.5279s\n",
      "\titers: 200, epoch: 34 | loss: 0.0548855\n",
      "\tspeed: 0.0215s/iter; left time: 318.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0530963 Vali Loss: 0.0529684 Test Loss: 0.0595935\n",
      "Validation loss decreased (0.053006 --> 0.052968).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0478047\n",
      "\tspeed: 0.0416s/iter; left time: 610.6880s\n",
      "\titers: 200, epoch: 35 | loss: 0.0539466\n",
      "\tspeed: 0.0215s/iter; left time: 313.8541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0530745 Vali Loss: 0.0529274 Test Loss: 0.0595120\n",
      "Validation loss decreased (0.052968 --> 0.052927).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0559533\n",
      "\tspeed: 0.0414s/iter; left time: 599.0636s\n",
      "\titers: 200, epoch: 36 | loss: 0.0502705\n",
      "\tspeed: 0.0216s/iter; left time: 309.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0530489 Vali Loss: 0.0529619 Test Loss: 0.0595732\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0493505\n",
      "\tspeed: 0.0426s/iter; left time: 606.0205s\n",
      "\titers: 200, epoch: 37 | loss: 0.0535447\n",
      "\tspeed: 0.0215s/iter; left time: 303.3882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0529914 Vali Loss: 0.0528805 Test Loss: 0.0595912\n",
      "Validation loss decreased (0.052927 --> 0.052880).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0518180\n",
      "\tspeed: 0.0434s/iter; left time: 607.7462s\n",
      "\titers: 200, epoch: 38 | loss: 0.0555135\n",
      "\tspeed: 0.0215s/iter; left time: 299.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0529215 Vali Loss: 0.0529901 Test Loss: 0.0595285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0510964\n",
      "\tspeed: 0.0413s/iter; left time: 569.6215s\n",
      "\titers: 200, epoch: 39 | loss: 0.0501677\n",
      "\tspeed: 0.0215s/iter; left time: 293.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0529102 Vali Loss: 0.0529945 Test Loss: 0.0595707\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0501363\n",
      "\tspeed: 0.0417s/iter; left time: 564.9890s\n",
      "\titers: 200, epoch: 40 | loss: 0.0531555\n",
      "\tspeed: 0.0214s/iter; left time: 287.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0529804 Vali Loss: 0.0529899 Test Loss: 0.0595702\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0537074\n",
      "\tspeed: 0.0425s/iter; left time: 566.4713s\n",
      "\titers: 200, epoch: 41 | loss: 0.0501498\n",
      "\tspeed: 0.0219s/iter; left time: 289.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0529319 Vali Loss: 0.0529200 Test Loss: 0.0594739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0506166\n",
      "\tspeed: 0.0432s/iter; left time: 566.6907s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538463\n",
      "\tspeed: 0.0217s/iter; left time: 282.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0528967 Vali Loss: 0.0529337 Test Loss: 0.0594169\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0551537\n",
      "\tspeed: 0.0412s/iter; left time: 531.4690s\n",
      "\titers: 200, epoch: 43 | loss: 0.0541291\n",
      "\tspeed: 0.0215s/iter; left time: 274.4972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528578 Vali Loss: 0.0529309 Test Loss: 0.0595201\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0572280\n",
      "\tspeed: 0.0413s/iter; left time: 523.6465s\n",
      "\titers: 200, epoch: 44 | loss: 0.0526779\n",
      "\tspeed: 0.0215s/iter; left time: 270.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0528968 Vali Loss: 0.0529269 Test Loss: 0.0594907\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0542270\n",
      "\tspeed: 0.0411s/iter; left time: 510.9956s\n",
      "\titers: 200, epoch: 45 | loss: 0.0519096\n",
      "\tspeed: 0.0215s/iter; left time: 265.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528364 Vali Loss: 0.0528504 Test Loss: 0.0594572\n",
      "Validation loss decreased (0.052880 --> 0.052850).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0567479\n",
      "\tspeed: 0.0413s/iter; left time: 504.6692s\n",
      "\titers: 200, epoch: 46 | loss: 0.0533641\n",
      "\tspeed: 0.0214s/iter; left time: 259.9578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0529016 Vali Loss: 0.0528505 Test Loss: 0.0594816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0534554\n",
      "\tspeed: 0.0414s/iter; left time: 497.0698s\n",
      "\titers: 200, epoch: 47 | loss: 0.0475648\n",
      "\tspeed: 0.0214s/iter; left time: 254.7002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0529094 Vali Loss: 0.0529142 Test Loss: 0.0594686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0500164\n",
      "\tspeed: 0.0409s/iter; left time: 482.0654s\n",
      "\titers: 200, epoch: 48 | loss: 0.0512429\n",
      "\tspeed: 0.0214s/iter; left time: 250.3545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0528236 Vali Loss: 0.0529287 Test Loss: 0.0594930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0520317\n",
      "\tspeed: 0.0410s/iter; left time: 473.6480s\n",
      "\titers: 200, epoch: 49 | loss: 0.0548631\n",
      "\tspeed: 0.0215s/iter; left time: 246.0004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0528925 Vali Loss: 0.0528737 Test Loss: 0.0594869\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0503222\n",
      "\tspeed: 0.0416s/iter; left time: 471.1628s\n",
      "\titers: 200, epoch: 50 | loss: 0.0584875\n",
      "\tspeed: 0.0215s/iter; left time: 241.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0529061 Vali Loss: 0.0528876 Test Loss: 0.0594881\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0538329\n",
      "\tspeed: 0.0412s/iter; left time: 457.4212s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508686\n",
      "\tspeed: 0.0214s/iter; left time: 235.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0529147 Vali Loss: 0.0528679 Test Loss: 0.0594729\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0548518\n",
      "\tspeed: 0.0410s/iter; left time: 446.1536s\n",
      "\titers: 200, epoch: 52 | loss: 0.0500622\n",
      "\tspeed: 0.0215s/iter; left time: 231.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528688 Vali Loss: 0.0529081 Test Loss: 0.0595482\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0533494\n",
      "\tspeed: 0.0410s/iter; left time: 436.8176s\n",
      "\titers: 200, epoch: 53 | loss: 0.0526474\n",
      "\tspeed: 0.0214s/iter; left time: 226.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528629 Vali Loss: 0.0528537 Test Loss: 0.0594607\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0490567\n",
      "\tspeed: 0.0410s/iter; left time: 427.4118s\n",
      "\titers: 200, epoch: 54 | loss: 0.0554540\n",
      "\tspeed: 0.0215s/iter; left time: 221.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528439 Vali Loss: 0.0528962 Test Loss: 0.0594534\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0542135\n",
      "\tspeed: 0.0409s/iter; left time: 417.3109s\n",
      "\titers: 200, epoch: 55 | loss: 0.0503127\n",
      "\tspeed: 0.0214s/iter; left time: 216.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0528382 Vali Loss: 0.0529034 Test Loss: 0.0594242\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009812770411372185, rmse:0.09905942529439926, mae:0.0594572052359581, rse:0.2915199100971222\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:48.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1332297\n",
      "\tspeed: 0.0417s/iter; left time: 930.1454s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161591\n",
      "\tspeed: 0.0217s/iter; left time: 481.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.1391611 Vali Loss: 0.1071773 Test Loss: 0.1206285\n",
      "Validation loss decreased (inf --> 0.107177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0941705\n",
      "\tspeed: 0.0435s/iter; left time: 959.3545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0863278\n",
      "\tspeed: 0.0217s/iter; left time: 476.7819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0945481 Vali Loss: 0.0842169 Test Loss: 0.0952008\n",
      "Validation loss decreased (0.107177 --> 0.084217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853028\n",
      "\tspeed: 0.0435s/iter; left time: 949.6591s\n",
      "\titers: 200, epoch: 3 | loss: 0.0818383\n",
      "\tspeed: 0.0217s/iter; left time: 471.7924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0852690 Vali Loss: 0.0808030 Test Loss: 0.0915490\n",
      "Validation loss decreased (0.084217 --> 0.080803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816073\n",
      "\tspeed: 0.0435s/iter; left time: 941.9031s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809784\n",
      "\tspeed: 0.0216s/iter; left time: 465.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0822740 Vali Loss: 0.0797453 Test Loss: 0.0898073\n",
      "Validation loss decreased (0.080803 --> 0.079745).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0792374\n",
      "\tspeed: 0.0441s/iter; left time: 944.8809s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757089\n",
      "\tspeed: 0.0217s/iter; left time: 461.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0803611 Vali Loss: 0.0778018 Test Loss: 0.0881068\n",
      "Validation loss decreased (0.079745 --> 0.077802).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0795092\n",
      "\tspeed: 0.0436s/iter; left time: 924.4390s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789749\n",
      "\tspeed: 0.0217s/iter; left time: 457.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0788301 Vali Loss: 0.0771582 Test Loss: 0.0877509\n",
      "Validation loss decreased (0.077802 --> 0.077158).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0790475\n",
      "\tspeed: 0.0460s/iter; left time: 964.5120s\n",
      "\titers: 200, epoch: 7 | loss: 0.0745670\n",
      "\tspeed: 0.0220s/iter; left time: 459.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0777580 Vali Loss: 0.0771757 Test Loss: 0.0872566\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777936\n",
      "\tspeed: 0.0441s/iter; left time: 913.3973s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750555\n",
      "\tspeed: 0.0217s/iter; left time: 447.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0770578 Vali Loss: 0.0767780 Test Loss: 0.0872838\n",
      "Validation loss decreased (0.077158 --> 0.076778).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780691\n",
      "\tspeed: 0.0451s/iter; left time: 924.7646s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749124\n",
      "\tspeed: 0.0217s/iter; left time: 441.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0764970 Vali Loss: 0.0762103 Test Loss: 0.0868660\n",
      "Validation loss decreased (0.076778 --> 0.076210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0785373\n",
      "\tspeed: 0.0436s/iter; left time: 883.4298s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794437\n",
      "\tspeed: 0.0217s/iter; left time: 437.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0760310 Vali Loss: 0.0769392 Test Loss: 0.0869758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762078\n",
      "\tspeed: 0.0428s/iter; left time: 859.6081s\n",
      "\titers: 200, epoch: 11 | loss: 0.0778385\n",
      "\tspeed: 0.0216s/iter; left time: 432.1209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0756567 Vali Loss: 0.0762321 Test Loss: 0.0867211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0756245\n",
      "\tspeed: 0.0442s/iter; left time: 876.4685s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754605\n",
      "\tspeed: 0.0221s/iter; left time: 435.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0753354 Vali Loss: 0.0762274 Test Loss: 0.0863326\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0720821\n",
      "\tspeed: 0.0442s/iter; left time: 867.0172s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751733\n",
      "\tspeed: 0.0220s/iter; left time: 429.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0749704 Vali Loss: 0.0764599 Test Loss: 0.0865470\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0714084\n",
      "\tspeed: 0.0442s/iter; left time: 857.2234s\n",
      "\titers: 200, epoch: 14 | loss: 0.0755144\n",
      "\tspeed: 0.0221s/iter; left time: 425.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0747233 Vali Loss: 0.0763372 Test Loss: 0.0863980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0716580\n",
      "\tspeed: 0.0439s/iter; left time: 841.8246s\n",
      "\titers: 200, epoch: 15 | loss: 0.0775909\n",
      "\tspeed: 0.0222s/iter; left time: 422.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0744484 Vali Loss: 0.0765933 Test Loss: 0.0861666\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736896\n",
      "\tspeed: 0.0439s/iter; left time: 832.1675s\n",
      "\titers: 200, epoch: 16 | loss: 0.0758602\n",
      "\tspeed: 0.0220s/iter; left time: 415.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0742457 Vali Loss: 0.0764040 Test Loss: 0.0862437\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0725069\n",
      "\tspeed: 0.0442s/iter; left time: 827.3303s\n",
      "\titers: 200, epoch: 17 | loss: 0.0767296\n",
      "\tspeed: 0.0219s/iter; left time: 406.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0740250 Vali Loss: 0.0760664 Test Loss: 0.0861376\n",
      "Validation loss decreased (0.076210 --> 0.076066).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756056\n",
      "\tspeed: 0.0444s/iter; left time: 821.8125s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748916\n",
      "\tspeed: 0.0221s/iter; left time: 406.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0738281 Vali Loss: 0.0759807 Test Loss: 0.0860244\n",
      "Validation loss decreased (0.076066 --> 0.075981).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731047\n",
      "\tspeed: 0.0447s/iter; left time: 816.4096s\n",
      "\titers: 200, epoch: 19 | loss: 0.0784042\n",
      "\tspeed: 0.0216s/iter; left time: 392.8607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0736200 Vali Loss: 0.0764765 Test Loss: 0.0861464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727690\n",
      "\tspeed: 0.0444s/iter; left time: 801.0104s\n",
      "\titers: 200, epoch: 20 | loss: 0.0742854\n",
      "\tspeed: 0.0220s/iter; left time: 394.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0734715 Vali Loss: 0.0762892 Test Loss: 0.0858324\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0738453\n",
      "\tspeed: 0.0442s/iter; left time: 786.9141s\n",
      "\titers: 200, epoch: 21 | loss: 0.0691860\n",
      "\tspeed: 0.0220s/iter; left time: 389.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0733689 Vali Loss: 0.0761795 Test Loss: 0.0859565\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0759191\n",
      "\tspeed: 0.0436s/iter; left time: 767.1634s\n",
      "\titers: 200, epoch: 22 | loss: 0.0734370\n",
      "\tspeed: 0.0216s/iter; left time: 378.2755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0732245 Vali Loss: 0.0762098 Test Loss: 0.0859345\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716394\n",
      "\tspeed: 0.0438s/iter; left time: 761.2500s\n",
      "\titers: 200, epoch: 23 | loss: 0.0756265\n",
      "\tspeed: 0.0220s/iter; left time: 380.0267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0731301 Vali Loss: 0.0761251 Test Loss: 0.0857689\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0742317\n",
      "\tspeed: 0.0442s/iter; left time: 757.6276s\n",
      "\titers: 200, epoch: 24 | loss: 0.0704160\n",
      "\tspeed: 0.0220s/iter; left time: 374.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0730227 Vali Loss: 0.0763680 Test Loss: 0.0857616\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0700089\n",
      "\tspeed: 0.0437s/iter; left time: 739.1891s\n",
      "\titers: 200, epoch: 25 | loss: 0.0757303\n",
      "\tspeed: 0.0221s/iter; left time: 372.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0729131 Vali Loss: 0.0763017 Test Loss: 0.0859688\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696479\n",
      "\tspeed: 0.0443s/iter; left time: 740.0703s\n",
      "\titers: 200, epoch: 26 | loss: 0.0717671\n",
      "\tspeed: 0.0220s/iter; left time: 365.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0728213 Vali Loss: 0.0761310 Test Loss: 0.0858499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0723027\n",
      "\tspeed: 0.0443s/iter; left time: 729.3346s\n",
      "\titers: 200, epoch: 27 | loss: 0.0721262\n",
      "\tspeed: 0.0220s/iter; left time: 360.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0727642 Vali Loss: 0.0762699 Test Loss: 0.0858156\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0749497\n",
      "\tspeed: 0.0437s/iter; left time: 710.9215s\n",
      "\titers: 200, epoch: 28 | loss: 0.0732277\n",
      "\tspeed: 0.0222s/iter; left time: 358.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0727659 Vali Loss: 0.0766016 Test Loss: 0.0858246\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018519887700676918, rmse:0.1360877901315689, mae:0.08602438867092133, rse:0.39978498220443726\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364289\n",
      "\tspeed: 0.0239s/iter; left time: 533.9565s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157521\n",
      "\tspeed: 0.0220s/iter; left time: 488.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1400037 Vali Loss: 0.1071459 Test Loss: 0.1205795\n",
      "Validation loss decreased (inf --> 0.107146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934064\n",
      "\tspeed: 0.0444s/iter; left time: 979.6636s\n",
      "\titers: 200, epoch: 2 | loss: 0.0874522\n",
      "\tspeed: 0.0222s/iter; left time: 487.3257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0941851 Vali Loss: 0.0842902 Test Loss: 0.0953378\n",
      "Validation loss decreased (0.107146 --> 0.084290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0808377\n",
      "\tspeed: 0.0458s/iter; left time: 1000.3210s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814818\n",
      "\tspeed: 0.0220s/iter; left time: 479.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0852042 Vali Loss: 0.0804398 Test Loss: 0.0912278\n",
      "Validation loss decreased (0.084290 --> 0.080440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0785727\n",
      "\tspeed: 0.0444s/iter; left time: 959.2951s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764470\n",
      "\tspeed: 0.0220s/iter; left time: 472.6305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0821069 Vali Loss: 0.0790448 Test Loss: 0.0897176\n",
      "Validation loss decreased (0.080440 --> 0.079045).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797067\n",
      "\tspeed: 0.0443s/iter; left time: 948.8321s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774974\n",
      "\tspeed: 0.0221s/iter; left time: 470.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0802850 Vali Loss: 0.0777845 Test Loss: 0.0883287\n",
      "Validation loss decreased (0.079045 --> 0.077784).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0815331\n",
      "\tspeed: 0.0448s/iter; left time: 947.8551s\n",
      "\titers: 200, epoch: 6 | loss: 0.0785194\n",
      "\tspeed: 0.0217s/iter; left time: 456.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0790606 Vali Loss: 0.0768606 Test Loss: 0.0875707\n",
      "Validation loss decreased (0.077784 --> 0.076861).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752414\n",
      "\tspeed: 0.0441s/iter; left time: 924.7015s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835284\n",
      "\tspeed: 0.0220s/iter; left time: 459.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0780382 Vali Loss: 0.0763432 Test Loss: 0.0872044\n",
      "Validation loss decreased (0.076861 --> 0.076343).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805481\n",
      "\tspeed: 0.0446s/iter; left time: 924.5303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0737994\n",
      "\tspeed: 0.0220s/iter; left time: 454.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0772798 Vali Loss: 0.0775445 Test Loss: 0.0873029\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0717554\n",
      "\tspeed: 0.0440s/iter; left time: 901.7004s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795396\n",
      "\tspeed: 0.0220s/iter; left time: 449.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0766658 Vali Loss: 0.0762876 Test Loss: 0.0868978\n",
      "Validation loss decreased (0.076343 --> 0.076288).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0765349\n",
      "\tspeed: 0.0466s/iter; left time: 946.1368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771625\n",
      "\tspeed: 0.0220s/iter; left time: 444.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0761583 Vali Loss: 0.0772299 Test Loss: 0.0867038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0756112\n",
      "\tspeed: 0.0443s/iter; left time: 889.2690s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756049\n",
      "\tspeed: 0.0220s/iter; left time: 438.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0757773 Vali Loss: 0.0769829 Test Loss: 0.0866484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710362\n",
      "\tspeed: 0.0437s/iter; left time: 867.7980s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768368\n",
      "\tspeed: 0.0217s/iter; left time: 428.3425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0753701 Vali Loss: 0.0770634 Test Loss: 0.0865114\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729874\n",
      "\tspeed: 0.0430s/iter; left time: 843.6619s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761825\n",
      "\tspeed: 0.0217s/iter; left time: 422.5762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0751306 Vali Loss: 0.0765685 Test Loss: 0.0862346\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0740429\n",
      "\tspeed: 0.0428s/iter; left time: 830.2993s\n",
      "\titers: 200, epoch: 14 | loss: 0.0755326\n",
      "\tspeed: 0.0220s/iter; left time: 423.7912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0747906 Vali Loss: 0.0765621 Test Loss: 0.0862255\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0729103\n",
      "\tspeed: 0.0441s/iter; left time: 845.9604s\n",
      "\titers: 200, epoch: 15 | loss: 0.0782577\n",
      "\tspeed: 0.0216s/iter; left time: 411.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0744873 Vali Loss: 0.0768213 Test Loss: 0.0861763\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0729717\n",
      "\tspeed: 0.0439s/iter; left time: 832.0039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731197\n",
      "\tspeed: 0.0220s/iter; left time: 414.6705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0742818 Vali Loss: 0.0768293 Test Loss: 0.0860981\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0708489\n",
      "\tspeed: 0.0437s/iter; left time: 817.7381s\n",
      "\titers: 200, epoch: 17 | loss: 0.0760538\n",
      "\tspeed: 0.0219s/iter; left time: 407.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0741524 Vali Loss: 0.0769240 Test Loss: 0.0859786\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739125\n",
      "\tspeed: 0.0434s/iter; left time: 802.4670s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764256\n",
      "\tspeed: 0.0218s/iter; left time: 400.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0739181 Vali Loss: 0.0766715 Test Loss: 0.0856658\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0719711\n",
      "\tspeed: 0.0437s/iter; left time: 798.6670s\n",
      "\titers: 200, epoch: 19 | loss: 0.0718806\n",
      "\tspeed: 0.0220s/iter; left time: 399.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0737924 Vali Loss: 0.0768021 Test Loss: 0.0859819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01872049644589424, rmse:0.1368228644132614, mae:0.08689781278371811, rse:0.4019443988800049\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:20.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1371511\n",
      "\tspeed: 0.0431s/iter; left time: 957.0872s\n",
      "\titers: 200, epoch: 1 | loss: 0.1227827\n",
      "\tspeed: 0.0219s/iter; left time: 484.2198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.1408815 Vali Loss: 0.1098873 Test Loss: 0.1227970\n",
      "Validation loss decreased (inf --> 0.109887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982690\n",
      "\tspeed: 0.0436s/iter; left time: 957.6706s\n",
      "\titers: 200, epoch: 2 | loss: 0.0899111\n",
      "\tspeed: 0.0220s/iter; left time: 480.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0986082 Vali Loss: 0.0894303 Test Loss: 0.1008918\n",
      "Validation loss decreased (0.109887 --> 0.089430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925034\n",
      "\tspeed: 0.0459s/iter; left time: 998.0934s\n",
      "\titers: 200, epoch: 3 | loss: 0.0911533\n",
      "\tspeed: 0.0220s/iter; left time: 475.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0898377 Vali Loss: 0.0864183 Test Loss: 0.0965754\n",
      "Validation loss decreased (0.089430 --> 0.086418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891801\n",
      "\tspeed: 0.0461s/iter; left time: 991.5692s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856469\n",
      "\tspeed: 0.0219s/iter; left time: 468.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0869450 Vali Loss: 0.0846574 Test Loss: 0.0945920\n",
      "Validation loss decreased (0.086418 --> 0.084657).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867344\n",
      "\tspeed: 0.0451s/iter; left time: 961.4708s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823247\n",
      "\tspeed: 0.0222s/iter; left time: 470.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0850013 Vali Loss: 0.0836166 Test Loss: 0.0936938\n",
      "Validation loss decreased (0.084657 --> 0.083617).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0818506\n",
      "\tspeed: 0.0461s/iter; left time: 971.8492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827280\n",
      "\tspeed: 0.0221s/iter; left time: 463.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0836792 Vali Loss: 0.0826987 Test Loss: 0.0931292\n",
      "Validation loss decreased (0.083617 --> 0.082699).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0840494\n",
      "\tspeed: 0.0443s/iter; left time: 924.1657s\n",
      "\titers: 200, epoch: 7 | loss: 0.0833823\n",
      "\tspeed: 0.0221s/iter; left time: 457.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827394 Vali Loss: 0.0826297 Test Loss: 0.0929716\n",
      "Validation loss decreased (0.082699 --> 0.082630).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0779127\n",
      "\tspeed: 0.0441s/iter; left time: 909.9998s\n",
      "\titers: 200, epoch: 8 | loss: 0.0823919\n",
      "\tspeed: 0.0221s/iter; left time: 454.6208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0819783 Vali Loss: 0.0829825 Test Loss: 0.0930039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0815135\n",
      "\tspeed: 0.0439s/iter; left time: 896.0783s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792302\n",
      "\tspeed: 0.0221s/iter; left time: 448.2927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0814724 Vali Loss: 0.0823861 Test Loss: 0.0924516\n",
      "Validation loss decreased (0.082630 --> 0.082386).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0806117\n",
      "\tspeed: 0.0449s/iter; left time: 907.1549s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819467\n",
      "\tspeed: 0.0221s/iter; left time: 443.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0809605 Vali Loss: 0.0830070 Test Loss: 0.0925872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803210\n",
      "\tspeed: 0.0443s/iter; left time: 884.0139s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776389\n",
      "\tspeed: 0.0221s/iter; left time: 439.3498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0805181 Vali Loss: 0.0824888 Test Loss: 0.0920700\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0784427\n",
      "\tspeed: 0.0445s/iter; left time: 879.3256s\n",
      "\titers: 200, epoch: 12 | loss: 0.0817352\n",
      "\tspeed: 0.0221s/iter; left time: 433.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0801262 Vali Loss: 0.0825620 Test Loss: 0.0920309\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784058\n",
      "\tspeed: 0.0444s/iter; left time: 866.6500s\n",
      "\titers: 200, epoch: 13 | loss: 0.0791594\n",
      "\tspeed: 0.0221s/iter; left time: 428.7736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0797856 Vali Loss: 0.0826020 Test Loss: 0.0922435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787506\n",
      "\tspeed: 0.0445s/iter; left time: 857.9827s\n",
      "\titers: 200, epoch: 14 | loss: 0.0820662\n",
      "\tspeed: 0.0220s/iter; left time: 423.0954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0795397 Vali Loss: 0.0828208 Test Loss: 0.0920756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0799818\n",
      "\tspeed: 0.0444s/iter; left time: 846.2871s\n",
      "\titers: 200, epoch: 15 | loss: 0.0836569\n",
      "\tspeed: 0.0222s/iter; left time: 421.5801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0791791 Vali Loss: 0.0830119 Test Loss: 0.0925421\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803613\n",
      "\tspeed: 0.0445s/iter; left time: 838.8854s\n",
      "\titers: 200, epoch: 16 | loss: 0.0813428\n",
      "\tspeed: 0.0221s/iter; left time: 414.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0789562 Vali Loss: 0.0830018 Test Loss: 0.0920970\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776634\n",
      "\tspeed: 0.0437s/iter; left time: 814.4495s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778937\n",
      "\tspeed: 0.0223s/iter; left time: 414.1436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0787209 Vali Loss: 0.0829465 Test Loss: 0.0920361\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758516\n",
      "\tspeed: 0.0439s/iter; left time: 807.3381s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807445\n",
      "\tspeed: 0.0221s/iter; left time: 404.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0785428 Vali Loss: 0.0829375 Test Loss: 0.0922001\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0786880\n",
      "\tspeed: 0.0433s/iter; left time: 787.0556s\n",
      "\titers: 200, epoch: 19 | loss: 0.0784285\n",
      "\tspeed: 0.0221s/iter; left time: 399.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0783526 Vali Loss: 0.0831563 Test Loss: 0.0923600\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020858457311987877, rmse:0.14442457258701324, mae:0.0924515426158905, rse:0.42430639266967773\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1416378\n",
      "\tspeed: 0.0240s/iter; left time: 533.2813s\n",
      "\titers: 200, epoch: 1 | loss: 0.1206775\n",
      "\tspeed: 0.0221s/iter; left time: 487.9725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1433732 Vali Loss: 0.1106227 Test Loss: 0.1235818\n",
      "Validation loss decreased (inf --> 0.110623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0965256\n",
      "\tspeed: 0.0476s/iter; left time: 1045.4600s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879358\n",
      "\tspeed: 0.0221s/iter; left time: 483.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0986671 Vali Loss: 0.0892200 Test Loss: 0.1002943\n",
      "Validation loss decreased (0.110623 --> 0.089220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0900791\n",
      "\tspeed: 0.0452s/iter; left time: 984.1647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855783\n",
      "\tspeed: 0.0222s/iter; left time: 480.0283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0895850 Vali Loss: 0.0860697 Test Loss: 0.0960548\n",
      "Validation loss decreased (0.089220 --> 0.086070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842056\n",
      "\tspeed: 0.0446s/iter; left time: 960.3908s\n",
      "\titers: 200, epoch: 4 | loss: 0.0830727\n",
      "\tspeed: 0.0221s/iter; left time: 474.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0864703 Vali Loss: 0.0838934 Test Loss: 0.0944798\n",
      "Validation loss decreased (0.086070 --> 0.083893).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0832796\n",
      "\tspeed: 0.0447s/iter; left time: 952.0413s\n",
      "\titers: 200, epoch: 5 | loss: 0.0871448\n",
      "\tspeed: 0.0219s/iter; left time: 465.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0844791 Vali Loss: 0.0831082 Test Loss: 0.0936069\n",
      "Validation loss decreased (0.083893 --> 0.083108).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0846262\n",
      "\tspeed: 0.0445s/iter; left time: 938.9771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0852027\n",
      "\tspeed: 0.0221s/iter; left time: 464.2929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0834561 Vali Loss: 0.0830709 Test Loss: 0.0935564\n",
      "Validation loss decreased (0.083108 --> 0.083071).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847440\n",
      "\tspeed: 0.0455s/iter; left time: 949.1190s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831410\n",
      "\tspeed: 0.0220s/iter; left time: 457.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0826277 Vali Loss: 0.0826569 Test Loss: 0.0930395\n",
      "Validation loss decreased (0.083071 --> 0.082657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0808602\n",
      "\tspeed: 0.0440s/iter; left time: 908.6797s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827895\n",
      "\tspeed: 0.0221s/iter; left time: 453.6333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0819853 Vali Loss: 0.0825806 Test Loss: 0.0925253\n",
      "Validation loss decreased (0.082657 --> 0.082581).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0802193\n",
      "\tspeed: 0.0442s/iter; left time: 903.1668s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813650\n",
      "\tspeed: 0.0221s/iter; left time: 448.7456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0814423 Vali Loss: 0.0826175 Test Loss: 0.0924374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0803851\n",
      "\tspeed: 0.0437s/iter; left time: 881.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843623\n",
      "\tspeed: 0.0221s/iter; left time: 444.4712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0809958 Vali Loss: 0.0825905 Test Loss: 0.0925625\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784597\n",
      "\tspeed: 0.0438s/iter; left time: 874.7353s\n",
      "\titers: 200, epoch: 11 | loss: 0.0814741\n",
      "\tspeed: 0.0222s/iter; left time: 441.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0805374 Vali Loss: 0.0820461 Test Loss: 0.0924563\n",
      "Validation loss decreased (0.082581 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0822926\n",
      "\tspeed: 0.0447s/iter; left time: 883.5980s\n",
      "\titers: 200, epoch: 12 | loss: 0.0823805\n",
      "\tspeed: 0.0219s/iter; left time: 429.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0801536 Vali Loss: 0.0823830 Test Loss: 0.0922299\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0833190\n",
      "\tspeed: 0.0434s/iter; left time: 847.9632s\n",
      "\titers: 200, epoch: 13 | loss: 0.0803181\n",
      "\tspeed: 0.0221s/iter; left time: 429.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0798562 Vali Loss: 0.0828258 Test Loss: 0.0923265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0816601\n",
      "\tspeed: 0.0444s/iter; left time: 857.0395s\n",
      "\titers: 200, epoch: 14 | loss: 0.0748084\n",
      "\tspeed: 0.0221s/iter; left time: 425.1065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0794810 Vali Loss: 0.0823014 Test Loss: 0.0921245\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0809139\n",
      "\tspeed: 0.0435s/iter; left time: 830.8637s\n",
      "\titers: 200, epoch: 15 | loss: 0.0805807\n",
      "\tspeed: 0.0218s/iter; left time: 414.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0792117 Vali Loss: 0.0821576 Test Loss: 0.0920450\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0775555\n",
      "\tspeed: 0.0438s/iter; left time: 825.4251s\n",
      "\titers: 200, epoch: 16 | loss: 0.0795938\n",
      "\tspeed: 0.0218s/iter; left time: 409.1957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0789975 Vali Loss: 0.0824763 Test Loss: 0.0922513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0802612\n",
      "\tspeed: 0.0435s/iter; left time: 810.9450s\n",
      "\titers: 200, epoch: 17 | loss: 0.0768068\n",
      "\tspeed: 0.0219s/iter; left time: 405.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0787426 Vali Loss: 0.0821692 Test Loss: 0.0918640\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0813671\n",
      "\tspeed: 0.0435s/iter; left time: 799.9900s\n",
      "\titers: 200, epoch: 18 | loss: 0.0809227\n",
      "\tspeed: 0.0224s/iter; left time: 410.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0786182 Vali Loss: 0.0820150 Test Loss: 0.0919387\n",
      "Validation loss decreased (0.082046 --> 0.082015).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0761748\n",
      "\tspeed: 0.0454s/iter; left time: 826.1178s\n",
      "\titers: 200, epoch: 19 | loss: 0.0772933\n",
      "\tspeed: 0.0218s/iter; left time: 394.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0783593 Vali Loss: 0.0820760 Test Loss: 0.0920268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808013\n",
      "\tspeed: 0.0443s/iter; left time: 795.3875s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756472\n",
      "\tspeed: 0.0222s/iter; left time: 397.0049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0782636 Vali Loss: 0.0823677 Test Loss: 0.0921934\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0758733\n",
      "\tspeed: 0.0436s/iter; left time: 772.7565s\n",
      "\titers: 200, epoch: 21 | loss: 0.0818431\n",
      "\tspeed: 0.0222s/iter; left time: 391.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0780603 Vali Loss: 0.0821686 Test Loss: 0.0919804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0801528\n",
      "\tspeed: 0.0439s/iter; left time: 769.1960s\n",
      "\titers: 200, epoch: 22 | loss: 0.0809199\n",
      "\tspeed: 0.0221s/iter; left time: 385.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0779162 Vali Loss: 0.0819730 Test Loss: 0.0918904\n",
      "Validation loss decreased (0.082015 --> 0.081973).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0790167\n",
      "\tspeed: 0.0444s/iter; left time: 768.0712s\n",
      "\titers: 200, epoch: 23 | loss: 0.0766708\n",
      "\tspeed: 0.0222s/iter; left time: 382.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0778633 Vali Loss: 0.0820230 Test Loss: 0.0918854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778143\n",
      "\tspeed: 0.0439s/iter; left time: 748.9760s\n",
      "\titers: 200, epoch: 24 | loss: 0.0770918\n",
      "\tspeed: 0.0221s/iter; left time: 374.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0777084 Vali Loss: 0.0823111 Test Loss: 0.0919581\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0791645\n",
      "\tspeed: 0.0433s/iter; left time: 729.8076s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791114\n",
      "\tspeed: 0.0222s/iter; left time: 372.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0776045 Vali Loss: 0.0821355 Test Loss: 0.0919659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763448\n",
      "\tspeed: 0.0433s/iter; left time: 719.9132s\n",
      "\titers: 200, epoch: 26 | loss: 0.0797044\n",
      "\tspeed: 0.0220s/iter; left time: 363.4543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0774850 Vali Loss: 0.0822134 Test Loss: 0.0920656\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0781592\n",
      "\tspeed: 0.0437s/iter; left time: 716.9720s\n",
      "\titers: 200, epoch: 27 | loss: 0.0789439\n",
      "\tspeed: 0.0222s/iter; left time: 362.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0774893 Vali Loss: 0.0823164 Test Loss: 0.0920151\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0792652\n",
      "\tspeed: 0.0437s/iter; left time: 706.6205s\n",
      "\titers: 200, epoch: 28 | loss: 0.0782811\n",
      "\tspeed: 0.0221s/iter; left time: 355.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0774097 Vali Loss: 0.0823641 Test Loss: 0.0919414\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0776437\n",
      "\tspeed: 0.0438s/iter; left time: 699.1514s\n",
      "\titers: 200, epoch: 29 | loss: 0.0749454\n",
      "\tspeed: 0.0221s/iter; left time: 350.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0773713 Vali Loss: 0.0820460 Test Loss: 0.0919861\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0779056\n",
      "\tspeed: 0.0440s/iter; left time: 692.3035s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780373\n",
      "\tspeed: 0.0223s/iter; left time: 347.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0773109 Vali Loss: 0.0820088 Test Loss: 0.0918328\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0740423\n",
      "\tspeed: 0.0436s/iter; left time: 676.0932s\n",
      "\titers: 200, epoch: 31 | loss: 0.0736742\n",
      "\tspeed: 0.0219s/iter; left time: 338.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0772445 Vali Loss: 0.0823042 Test Loss: 0.0919686\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0764585\n",
      "\tspeed: 0.0434s/iter; left time: 662.7398s\n",
      "\titers: 200, epoch: 32 | loss: 0.0738416\n",
      "\tspeed: 0.0220s/iter; left time: 333.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0771388 Vali Loss: 0.0822374 Test Loss: 0.0918902\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020912274718284607, rmse:0.14461076259613037, mae:0.09189040958881378, rse:0.4248534142971039\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:49.05s\n",
      "Intermediate time for ES: 00h:22m:57.49s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0922521\n",
      "\tspeed: 0.0425s/iter; left time: 947.8985s\n",
      "\titers: 200, epoch: 1 | loss: 0.0812449\n",
      "\tspeed: 0.0215s/iter; left time: 476.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0996994 Vali Loss: 0.0825629 Test Loss: 0.0893525\n",
      "Validation loss decreased (inf --> 0.082563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0520459\n",
      "\tspeed: 0.0423s/iter; left time: 933.5048s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500034\n",
      "\tspeed: 0.0215s/iter; left time: 472.2770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0567640 Vali Loss: 0.0583316 Test Loss: 0.0614145\n",
      "Validation loss decreased (0.082563 --> 0.058332).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0495024\n",
      "\tspeed: 0.0437s/iter; left time: 955.2372s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475531\n",
      "\tspeed: 0.0215s/iter; left time: 467.4622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0492882 Vali Loss: 0.0560770 Test Loss: 0.0598704\n",
      "Validation loss decreased (0.058332 --> 0.056077).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0476345\n",
      "\tspeed: 0.0428s/iter; left time: 926.7450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0488735\n",
      "\tspeed: 0.0215s/iter; left time: 462.8029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0474713 Vali Loss: 0.0546836 Test Loss: 0.0583130\n",
      "Validation loss decreased (0.056077 --> 0.054684).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449141\n",
      "\tspeed: 0.0428s/iter; left time: 915.3990s\n",
      "\titers: 200, epoch: 5 | loss: 0.0493240\n",
      "\tspeed: 0.0215s/iter; left time: 457.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0462544 Vali Loss: 0.0537629 Test Loss: 0.0576841\n",
      "Validation loss decreased (0.054684 --> 0.053763).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0468459\n",
      "\tspeed: 0.0429s/iter; left time: 909.4078s\n",
      "\titers: 200, epoch: 6 | loss: 0.0431960\n",
      "\tspeed: 0.0215s/iter; left time: 452.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0453632 Vali Loss: 0.0533166 Test Loss: 0.0578590\n",
      "Validation loss decreased (0.053763 --> 0.053317).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0491544\n",
      "\tspeed: 0.0449s/iter; left time: 940.4948s\n",
      "\titers: 200, epoch: 7 | loss: 0.0457480\n",
      "\tspeed: 0.0214s/iter; left time: 447.2324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0447199 Vali Loss: 0.0527121 Test Loss: 0.0568390\n",
      "Validation loss decreased (0.053317 --> 0.052712).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0443586\n",
      "\tspeed: 0.0419s/iter; left time: 869.0640s\n",
      "\titers: 200, epoch: 8 | loss: 0.0445202\n",
      "\tspeed: 0.0215s/iter; left time: 443.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0441812 Vali Loss: 0.0527890 Test Loss: 0.0566774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0408554\n",
      "\tspeed: 0.0425s/iter; left time: 872.2932s\n",
      "\titers: 200, epoch: 9 | loss: 0.0461555\n",
      "\tspeed: 0.0215s/iter; left time: 438.3208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0437338 Vali Loss: 0.0520447 Test Loss: 0.0563787\n",
      "Validation loss decreased (0.052712 --> 0.052045).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0437757\n",
      "\tspeed: 0.0417s/iter; left time: 846.6063s\n",
      "\titers: 200, epoch: 10 | loss: 0.0445507\n",
      "\tspeed: 0.0215s/iter; left time: 433.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0433935 Vali Loss: 0.0518005 Test Loss: 0.0563349\n",
      "Validation loss decreased (0.052045 --> 0.051801).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0438122\n",
      "\tspeed: 0.0417s/iter; left time: 837.0607s\n",
      "\titers: 200, epoch: 11 | loss: 0.0429363\n",
      "\tspeed: 0.0215s/iter; left time: 428.3583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0430161 Vali Loss: 0.0522235 Test Loss: 0.0565345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0411467\n",
      "\tspeed: 0.0417s/iter; left time: 826.2400s\n",
      "\titers: 200, epoch: 12 | loss: 0.0405442\n",
      "\tspeed: 0.0215s/iter; left time: 424.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0428260 Vali Loss: 0.0518053 Test Loss: 0.0561477\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0412936\n",
      "\tspeed: 0.0417s/iter; left time: 818.5467s\n",
      "\titers: 200, epoch: 13 | loss: 0.0395719\n",
      "\tspeed: 0.0215s/iter; left time: 419.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0425413 Vali Loss: 0.0517742 Test Loss: 0.0559564\n",
      "Validation loss decreased (0.051801 --> 0.051774).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0403675\n",
      "\tspeed: 0.0423s/iter; left time: 820.5047s\n",
      "\titers: 200, epoch: 14 | loss: 0.0414157\n",
      "\tspeed: 0.0214s/iter; left time: 413.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0424343 Vali Loss: 0.0514468 Test Loss: 0.0557802\n",
      "Validation loss decreased (0.051774 --> 0.051447).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0426468\n",
      "\tspeed: 0.0421s/iter; left time: 807.7905s\n",
      "\titers: 200, epoch: 15 | loss: 0.0391918\n",
      "\tspeed: 0.0215s/iter; left time: 409.2574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0421790 Vali Loss: 0.0513702 Test Loss: 0.0555155\n",
      "Validation loss decreased (0.051447 --> 0.051370).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0403348\n",
      "\tspeed: 0.0428s/iter; left time: 810.4751s\n",
      "\titers: 200, epoch: 16 | loss: 0.0393993\n",
      "\tspeed: 0.0215s/iter; left time: 404.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0420683 Vali Loss: 0.0514457 Test Loss: 0.0555897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0450992\n",
      "\tspeed: 0.0425s/iter; left time: 795.9175s\n",
      "\titers: 200, epoch: 17 | loss: 0.0421486\n",
      "\tspeed: 0.0214s/iter; left time: 398.9217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0419303 Vali Loss: 0.0512448 Test Loss: 0.0554233\n",
      "Validation loss decreased (0.051370 --> 0.051245).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0403684\n",
      "\tspeed: 0.0429s/iter; left time: 794.1835s\n",
      "\titers: 200, epoch: 18 | loss: 0.0409335\n",
      "\tspeed: 0.0215s/iter; left time: 395.0408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0417574 Vali Loss: 0.0510831 Test Loss: 0.0553910\n",
      "Validation loss decreased (0.051245 --> 0.051083).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0401357\n",
      "\tspeed: 0.0430s/iter; left time: 785.6362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0408954\n",
      "\tspeed: 0.0215s/iter; left time: 391.0297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0416991 Vali Loss: 0.0510762 Test Loss: 0.0553376\n",
      "Validation loss decreased (0.051083 --> 0.051076).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0409482\n",
      "\tspeed: 0.0433s/iter; left time: 781.9704s\n",
      "\titers: 200, epoch: 20 | loss: 0.0409341\n",
      "\tspeed: 0.0215s/iter; left time: 386.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0416068 Vali Loss: 0.0510023 Test Loss: 0.0553288\n",
      "Validation loss decreased (0.051076 --> 0.051002).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0404203\n",
      "\tspeed: 0.0427s/iter; left time: 761.7496s\n",
      "\titers: 200, epoch: 21 | loss: 0.0410889\n",
      "\tspeed: 0.0215s/iter; left time: 381.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0415698 Vali Loss: 0.0508564 Test Loss: 0.0550962\n",
      "Validation loss decreased (0.051002 --> 0.050856).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0403117\n",
      "\tspeed: 0.0424s/iter; left time: 746.4463s\n",
      "\titers: 200, epoch: 22 | loss: 0.0373952\n",
      "\tspeed: 0.0215s/iter; left time: 376.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0414609 Vali Loss: 0.0509924 Test Loss: 0.0551219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0411772\n",
      "\tspeed: 0.0429s/iter; left time: 744.8622s\n",
      "\titers: 200, epoch: 23 | loss: 0.0424629\n",
      "\tspeed: 0.0216s/iter; left time: 372.4648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0414060 Vali Loss: 0.0508895 Test Loss: 0.0551569\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0405278\n",
      "\tspeed: 0.0424s/iter; left time: 727.3471s\n",
      "\titers: 200, epoch: 24 | loss: 0.0411978\n",
      "\tspeed: 0.0215s/iter; left time: 367.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0412959 Vali Loss: 0.0509129 Test Loss: 0.0550991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0425501\n",
      "\tspeed: 0.0426s/iter; left time: 721.2167s\n",
      "\titers: 200, epoch: 25 | loss: 0.0411540\n",
      "\tspeed: 0.0216s/iter; left time: 362.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0412592 Vali Loss: 0.0508587 Test Loss: 0.0550704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0394458\n",
      "\tspeed: 0.0423s/iter; left time: 706.3543s\n",
      "\titers: 200, epoch: 26 | loss: 0.0386719\n",
      "\tspeed: 0.0216s/iter; left time: 357.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0412041 Vali Loss: 0.0508418 Test Loss: 0.0550752\n",
      "Validation loss decreased (0.050856 --> 0.050842).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0422570\n",
      "\tspeed: 0.0426s/iter; left time: 701.2355s\n",
      "\titers: 200, epoch: 27 | loss: 0.0422133\n",
      "\tspeed: 0.0216s/iter; left time: 353.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0411766 Vali Loss: 0.0507948 Test Loss: 0.0549831\n",
      "Validation loss decreased (0.050842 --> 0.050795).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0433984\n",
      "\tspeed: 0.0430s/iter; left time: 699.3788s\n",
      "\titers: 200, epoch: 28 | loss: 0.0385938\n",
      "\tspeed: 0.0215s/iter; left time: 347.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0411127 Vali Loss: 0.0508499 Test Loss: 0.0549632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0416224\n",
      "\tspeed: 0.0421s/iter; left time: 674.7613s\n",
      "\titers: 200, epoch: 29 | loss: 0.0386376\n",
      "\tspeed: 0.0215s/iter; left time: 342.5243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0410932 Vali Loss: 0.0508310 Test Loss: 0.0549747\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0433105\n",
      "\tspeed: 0.0421s/iter; left time: 665.7271s\n",
      "\titers: 200, epoch: 30 | loss: 0.0391017\n",
      "\tspeed: 0.0215s/iter; left time: 338.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0410636 Vali Loss: 0.0507713 Test Loss: 0.0549669\n",
      "Validation loss decreased (0.050795 --> 0.050771).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0414751\n",
      "\tspeed: 0.0430s/iter; left time: 670.4624s\n",
      "\titers: 200, epoch: 31 | loss: 0.0422406\n",
      "\tspeed: 0.0215s/iter; left time: 332.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0410644 Vali Loss: 0.0506221 Test Loss: 0.0549534\n",
      "Validation loss decreased (0.050771 --> 0.050622).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0418209\n",
      "\tspeed: 0.0424s/iter; left time: 651.7325s\n",
      "\titers: 200, epoch: 32 | loss: 0.0422630\n",
      "\tspeed: 0.0215s/iter; left time: 327.3840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0410220 Vali Loss: 0.0507005 Test Loss: 0.0549489\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0426691\n",
      "\tspeed: 0.0424s/iter; left time: 641.4093s\n",
      "\titers: 200, epoch: 33 | loss: 0.0416015\n",
      "\tspeed: 0.0215s/iter; left time: 323.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0409873 Vali Loss: 0.0507150 Test Loss: 0.0549289\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0416027\n",
      "\tspeed: 0.0418s/iter; left time: 622.5068s\n",
      "\titers: 200, epoch: 34 | loss: 0.0409058\n",
      "\tspeed: 0.0216s/iter; left time: 319.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0409342 Vali Loss: 0.0506125 Test Loss: 0.0549289\n",
      "Validation loss decreased (0.050622 --> 0.050613).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0403508\n",
      "\tspeed: 0.0426s/iter; left time: 625.2090s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405536\n",
      "\tspeed: 0.0215s/iter; left time: 313.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0408995 Vali Loss: 0.0507281 Test Loss: 0.0549348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0392013\n",
      "\tspeed: 0.0421s/iter; left time: 609.1346s\n",
      "\titers: 200, epoch: 36 | loss: 0.0411728\n",
      "\tspeed: 0.0215s/iter; left time: 308.4275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0408982 Vali Loss: 0.0506589 Test Loss: 0.0548898\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0416915\n",
      "\tspeed: 0.0423s/iter; left time: 601.5837s\n",
      "\titers: 200, epoch: 37 | loss: 0.0390842\n",
      "\tspeed: 0.0215s/iter; left time: 304.4565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0408846 Vali Loss: 0.0507030 Test Loss: 0.0549103\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0409159\n",
      "\tspeed: 0.0423s/iter; left time: 593.3613s\n",
      "\titers: 200, epoch: 38 | loss: 0.0409505\n",
      "\tspeed: 0.0215s/iter; left time: 299.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0409132 Vali Loss: 0.0506096 Test Loss: 0.0548936\n",
      "Validation loss decreased (0.050613 --> 0.050610).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0411741\n",
      "\tspeed: 0.0427s/iter; left time: 588.1627s\n",
      "\titers: 200, epoch: 39 | loss: 0.0376427\n",
      "\tspeed: 0.0215s/iter; left time: 294.4152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0409005 Vali Loss: 0.0506769 Test Loss: 0.0549118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0395384\n",
      "\tspeed: 0.0424s/iter; left time: 574.6687s\n",
      "\titers: 200, epoch: 40 | loss: 0.0426256\n",
      "\tspeed: 0.0215s/iter; left time: 289.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0409154 Vali Loss: 0.0506234 Test Loss: 0.0548656\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0414726\n",
      "\tspeed: 0.0421s/iter; left time: 562.0373s\n",
      "\titers: 200, epoch: 41 | loss: 0.0398386\n",
      "\tspeed: 0.0215s/iter; left time: 285.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0408911 Vali Loss: 0.0507312 Test Loss: 0.0548805\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0405780\n",
      "\tspeed: 0.0422s/iter; left time: 553.3428s\n",
      "\titers: 200, epoch: 42 | loss: 0.0422252\n",
      "\tspeed: 0.0215s/iter; left time: 280.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0408209 Vali Loss: 0.0506364 Test Loss: 0.0548718\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0415202\n",
      "\tspeed: 0.0419s/iter; left time: 539.9324s\n",
      "\titers: 200, epoch: 43 | loss: 0.0395535\n",
      "\tspeed: 0.0215s/iter; left time: 275.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408415 Vali Loss: 0.0506668 Test Loss: 0.0549047\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0404969\n",
      "\tspeed: 0.0420s/iter; left time: 532.7165s\n",
      "\titers: 200, epoch: 44 | loss: 0.0420321\n",
      "\tspeed: 0.0215s/iter; left time: 270.7686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0407556 Vali Loss: 0.0506703 Test Loss: 0.0548576\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0391747\n",
      "\tspeed: 0.0419s/iter; left time: 521.5592s\n",
      "\titers: 200, epoch: 45 | loss: 0.0422009\n",
      "\tspeed: 0.0217s/iter; left time: 267.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0408116 Vali Loss: 0.0506479 Test Loss: 0.0548571\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0392307\n",
      "\tspeed: 0.0425s/iter; left time: 519.7234s\n",
      "\titers: 200, epoch: 46 | loss: 0.0397813\n",
      "\tspeed: 0.0216s/iter; left time: 261.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408009 Vali Loss: 0.0506997 Test Loss: 0.0548701\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0399628\n",
      "\tspeed: 0.0427s/iter; left time: 511.7138s\n",
      "\titers: 200, epoch: 47 | loss: 0.0388421\n",
      "\tspeed: 0.0216s/iter; left time: 256.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0408245 Vali Loss: 0.0506524 Test Loss: 0.0548776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0390960\n",
      "\tspeed: 0.0423s/iter; left time: 498.5000s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420657\n",
      "\tspeed: 0.0215s/iter; left time: 250.7819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0407882 Vali Loss: 0.0506609 Test Loss: 0.0548543\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010016716085374355, rmse:0.10008354485034943, mae:0.054893556982278824, rse:0.3861195147037506\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0940180\n",
      "\tspeed: 0.0231s/iter; left time: 515.0449s\n",
      "\titers: 200, epoch: 1 | loss: 0.0811646\n",
      "\tspeed: 0.0226s/iter; left time: 502.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0985810 Vali Loss: 0.0815797 Test Loss: 0.0878834\n",
      "Validation loss decreased (inf --> 0.081580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0547407\n",
      "\tspeed: 0.0418s/iter; left time: 923.6693s\n",
      "\titers: 200, epoch: 2 | loss: 0.0527672\n",
      "\tspeed: 0.0214s/iter; left time: 471.2093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0564906 Vali Loss: 0.0584410 Test Loss: 0.0619229\n",
      "Validation loss decreased (0.081580 --> 0.058441).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0509167\n",
      "\tspeed: 0.0423s/iter; left time: 923.3342s\n",
      "\titers: 200, epoch: 3 | loss: 0.0542123\n",
      "\tspeed: 0.0216s/iter; left time: 469.8124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0495092 Vali Loss: 0.0563004 Test Loss: 0.0599003\n",
      "Validation loss decreased (0.058441 --> 0.056300).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0503906\n",
      "\tspeed: 0.0417s/iter; left time: 902.1710s\n",
      "\titers: 200, epoch: 4 | loss: 0.0471535\n",
      "\tspeed: 0.0215s/iter; left time: 462.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0475974 Vali Loss: 0.0549461 Test Loss: 0.0588412\n",
      "Validation loss decreased (0.056300 --> 0.054946).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476107\n",
      "\tspeed: 0.0422s/iter; left time: 904.3479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0449724\n",
      "\tspeed: 0.0215s/iter; left time: 457.5166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0462843 Vali Loss: 0.0539974 Test Loss: 0.0577919\n",
      "Validation loss decreased (0.054946 --> 0.053997).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0439290\n",
      "\tspeed: 0.0416s/iter; left time: 880.4346s\n",
      "\titers: 200, epoch: 6 | loss: 0.0464236\n",
      "\tspeed: 0.0214s/iter; left time: 452.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0454219 Vali Loss: 0.0535343 Test Loss: 0.0576241\n",
      "Validation loss decreased (0.053997 --> 0.053534).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0494572\n",
      "\tspeed: 0.0415s/iter; left time: 870.2077s\n",
      "\titers: 200, epoch: 7 | loss: 0.0432118\n",
      "\tspeed: 0.0215s/iter; left time: 447.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0447667 Vali Loss: 0.0527882 Test Loss: 0.0570822\n",
      "Validation loss decreased (0.053534 --> 0.052788).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0438109\n",
      "\tspeed: 0.0419s/iter; left time: 868.5354s\n",
      "\titers: 200, epoch: 8 | loss: 0.0465241\n",
      "\tspeed: 0.0215s/iter; left time: 443.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0442507 Vali Loss: 0.0526180 Test Loss: 0.0566874\n",
      "Validation loss decreased (0.052788 --> 0.052618).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0438274\n",
      "\tspeed: 0.0417s/iter; left time: 855.1131s\n",
      "\titers: 200, epoch: 9 | loss: 0.0437961\n",
      "\tspeed: 0.0214s/iter; left time: 437.4264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0438381 Vali Loss: 0.0523469 Test Loss: 0.0564449\n",
      "Validation loss decreased (0.052618 --> 0.052347).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0446142\n",
      "\tspeed: 0.0419s/iter; left time: 849.1826s\n",
      "\titers: 200, epoch: 10 | loss: 0.0449577\n",
      "\tspeed: 0.0215s/iter; left time: 433.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0435067 Vali Loss: 0.0523818 Test Loss: 0.0562804\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0418613\n",
      "\tspeed: 0.0417s/iter; left time: 837.2890s\n",
      "\titers: 200, epoch: 11 | loss: 0.0410403\n",
      "\tspeed: 0.0214s/iter; left time: 428.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0431693 Vali Loss: 0.0520130 Test Loss: 0.0562456\n",
      "Validation loss decreased (0.052347 --> 0.052013).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0410794\n",
      "\tspeed: 0.0424s/iter; left time: 840.4497s\n",
      "\titers: 200, epoch: 12 | loss: 0.0447178\n",
      "\tspeed: 0.0217s/iter; left time: 428.7528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0429229 Vali Loss: 0.0518238 Test Loss: 0.0557078\n",
      "Validation loss decreased (0.052013 --> 0.051824).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0441225\n",
      "\tspeed: 0.0422s/iter; left time: 828.1300s\n",
      "\titers: 200, epoch: 13 | loss: 0.0456641\n",
      "\tspeed: 0.0215s/iter; left time: 420.0370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0426047 Vali Loss: 0.0517077 Test Loss: 0.0557766\n",
      "Validation loss decreased (0.051824 --> 0.051708).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0459377\n",
      "\tspeed: 0.0423s/iter; left time: 819.4231s\n",
      "\titers: 200, epoch: 14 | loss: 0.0429569\n",
      "\tspeed: 0.0215s/iter; left time: 413.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0424634 Vali Loss: 0.0515609 Test Loss: 0.0555726\n",
      "Validation loss decreased (0.051708 --> 0.051561).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0418947\n",
      "\tspeed: 0.0423s/iter; left time: 810.7354s\n",
      "\titers: 200, epoch: 15 | loss: 0.0403961\n",
      "\tspeed: 0.0215s/iter; left time: 410.1931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0422723 Vali Loss: 0.0516485 Test Loss: 0.0555203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0437004\n",
      "\tspeed: 0.0418s/iter; left time: 792.5764s\n",
      "\titers: 200, epoch: 16 | loss: 0.0413640\n",
      "\tspeed: 0.0215s/iter; left time: 405.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0421250 Vali Loss: 0.0515568 Test Loss: 0.0554397\n",
      "Validation loss decreased (0.051561 --> 0.051557).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0406406\n",
      "\tspeed: 0.0418s/iter; left time: 782.4832s\n",
      "\titers: 200, epoch: 17 | loss: 0.0441466\n",
      "\tspeed: 0.0215s/iter; left time: 400.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0420131 Vali Loss: 0.0512235 Test Loss: 0.0554602\n",
      "Validation loss decreased (0.051557 --> 0.051224).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0433222\n",
      "\tspeed: 0.0416s/iter; left time: 769.9233s\n",
      "\titers: 200, epoch: 18 | loss: 0.0430924\n",
      "\tspeed: 0.0214s/iter; left time: 394.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0418719 Vali Loss: 0.0512055 Test Loss: 0.0552408\n",
      "Validation loss decreased (0.051224 --> 0.051205).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426369\n",
      "\tspeed: 0.0416s/iter; left time: 760.6100s\n",
      "\titers: 200, epoch: 19 | loss: 0.0433245\n",
      "\tspeed: 0.0218s/iter; left time: 396.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0417454 Vali Loss: 0.0513827 Test Loss: 0.0552300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0394716\n",
      "\tspeed: 0.0410s/iter; left time: 740.5760s\n",
      "\titers: 200, epoch: 20 | loss: 0.0419463\n",
      "\tspeed: 0.0215s/iter; left time: 385.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0416507 Vali Loss: 0.0510610 Test Loss: 0.0551008\n",
      "Validation loss decreased (0.051205 --> 0.051061).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0443189\n",
      "\tspeed: 0.0418s/iter; left time: 744.1442s\n",
      "\titers: 200, epoch: 21 | loss: 0.0422500\n",
      "\tspeed: 0.0215s/iter; left time: 381.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0415985 Vali Loss: 0.0510450 Test Loss: 0.0550852\n",
      "Validation loss decreased (0.051061 --> 0.051045).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0415483\n",
      "\tspeed: 0.0424s/iter; left time: 746.0996s\n",
      "\titers: 200, epoch: 22 | loss: 0.0417514\n",
      "\tspeed: 0.0215s/iter; left time: 376.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0414773 Vali Loss: 0.0510601 Test Loss: 0.0551181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0409127\n",
      "\tspeed: 0.0417s/iter; left time: 723.8984s\n",
      "\titers: 200, epoch: 23 | loss: 0.0378122\n",
      "\tspeed: 0.0215s/iter; left time: 372.0310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0414204 Vali Loss: 0.0511174 Test Loss: 0.0549930\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404224\n",
      "\tspeed: 0.0419s/iter; left time: 718.4501s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383398\n",
      "\tspeed: 0.0215s/iter; left time: 366.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413695 Vali Loss: 0.0510455 Test Loss: 0.0550411\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0420883\n",
      "\tspeed: 0.0420s/iter; left time: 711.4346s\n",
      "\titers: 200, epoch: 25 | loss: 0.0421899\n",
      "\tspeed: 0.0215s/iter; left time: 361.5762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413075 Vali Loss: 0.0509951 Test Loss: 0.0549542\n",
      "Validation loss decreased (0.051045 --> 0.050995).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0420696\n",
      "\tspeed: 0.0420s/iter; left time: 700.7044s\n",
      "\titers: 200, epoch: 26 | loss: 0.0436400\n",
      "\tspeed: 0.0215s/iter; left time: 357.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0412557 Vali Loss: 0.0510270 Test Loss: 0.0549796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0397224\n",
      "\tspeed: 0.0415s/iter; left time: 683.3222s\n",
      "\titers: 200, epoch: 27 | loss: 0.0414697\n",
      "\tspeed: 0.0215s/iter; left time: 352.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0411798 Vali Loss: 0.0510181 Test Loss: 0.0549279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0402837\n",
      "\tspeed: 0.0416s/iter; left time: 676.6137s\n",
      "\titers: 200, epoch: 28 | loss: 0.0395990\n",
      "\tspeed: 0.0217s/iter; left time: 350.0390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0411676 Vali Loss: 0.0508765 Test Loss: 0.0548455\n",
      "Validation loss decreased (0.050995 --> 0.050877).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0431604\n",
      "\tspeed: 0.0423s/iter; left time: 678.0381s\n",
      "\titers: 200, epoch: 29 | loss: 0.0448217\n",
      "\tspeed: 0.0215s/iter; left time: 342.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0411104 Vali Loss: 0.0509340 Test Loss: 0.0548963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0396297\n",
      "\tspeed: 0.0419s/iter; left time: 662.2532s\n",
      "\titers: 200, epoch: 30 | loss: 0.0401898\n",
      "\tspeed: 0.0215s/iter; left time: 338.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0410535 Vali Loss: 0.0508783 Test Loss: 0.0548398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0424194\n",
      "\tspeed: 0.0419s/iter; left time: 652.6878s\n",
      "\titers: 200, epoch: 31 | loss: 0.0421256\n",
      "\tspeed: 0.0215s/iter; left time: 333.3608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0410388 Vali Loss: 0.0509510 Test Loss: 0.0549230\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403462\n",
      "\tspeed: 0.0419s/iter; left time: 643.4572s\n",
      "\titers: 200, epoch: 32 | loss: 0.0405740\n",
      "\tspeed: 0.0215s/iter; left time: 328.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0410345 Vali Loss: 0.0509338 Test Loss: 0.0548709\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0424508\n",
      "\tspeed: 0.0412s/iter; left time: 623.5558s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424387\n",
      "\tspeed: 0.0215s/iter; left time: 322.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0410337 Vali Loss: 0.0508014 Test Loss: 0.0548693\n",
      "Validation loss decreased (0.050877 --> 0.050801).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425914\n",
      "\tspeed: 0.0418s/iter; left time: 622.6931s\n",
      "\titers: 200, epoch: 34 | loss: 0.0439500\n",
      "\tspeed: 0.0215s/iter; left time: 318.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0409841 Vali Loss: 0.0508157 Test Loss: 0.0548066\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0389932\n",
      "\tspeed: 0.0415s/iter; left time: 609.1774s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397014\n",
      "\tspeed: 0.0214s/iter; left time: 312.7479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0410068 Vali Loss: 0.0508392 Test Loss: 0.0548442\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0464640\n",
      "\tspeed: 0.0411s/iter; left time: 594.7469s\n",
      "\titers: 200, epoch: 36 | loss: 0.0403094\n",
      "\tspeed: 0.0214s/iter; left time: 307.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0409958 Vali Loss: 0.0508789 Test Loss: 0.0548256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0416844\n",
      "\tspeed: 0.0413s/iter; left time: 588.2420s\n",
      "\titers: 200, epoch: 37 | loss: 0.0424580\n",
      "\tspeed: 0.0217s/iter; left time: 306.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0409988 Vali Loss: 0.0508576 Test Loss: 0.0548103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0412942\n",
      "\tspeed: 0.0411s/iter; left time: 575.6771s\n",
      "\titers: 200, epoch: 38 | loss: 0.0398131\n",
      "\tspeed: 0.0215s/iter; left time: 298.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0409599 Vali Loss: 0.0508449 Test Loss: 0.0548017\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0384120\n",
      "\tspeed: 0.0418s/iter; left time: 575.8292s\n",
      "\titers: 200, epoch: 39 | loss: 0.0388602\n",
      "\tspeed: 0.0216s/iter; left time: 295.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0409116 Vali Loss: 0.0508882 Test Loss: 0.0547815\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0404700\n",
      "\tspeed: 0.0424s/iter; left time: 575.6196s\n",
      "\titers: 200, epoch: 40 | loss: 0.0422975\n",
      "\tspeed: 0.0215s/iter; left time: 289.4939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0409106 Vali Loss: 0.0508732 Test Loss: 0.0547946\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0435542\n",
      "\tspeed: 0.0420s/iter; left time: 559.7524s\n",
      "\titers: 200, epoch: 41 | loss: 0.0390764\n",
      "\tspeed: 0.0215s/iter; left time: 284.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0409192 Vali Loss: 0.0507594 Test Loss: 0.0547728\n",
      "Validation loss decreased (0.050801 --> 0.050759).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0391905\n",
      "\tspeed: 0.0419s/iter; left time: 549.8152s\n",
      "\titers: 200, epoch: 42 | loss: 0.0429931\n",
      "\tspeed: 0.0215s/iter; left time: 279.7507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408616 Vali Loss: 0.0507772 Test Loss: 0.0547837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0392766\n",
      "\tspeed: 0.0415s/iter; left time: 535.4667s\n",
      "\titers: 200, epoch: 43 | loss: 0.0411831\n",
      "\tspeed: 0.0215s/iter; left time: 275.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408704 Vali Loss: 0.0508098 Test Loss: 0.0547636\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0396020\n",
      "\tspeed: 0.0413s/iter; left time: 523.3345s\n",
      "\titers: 200, epoch: 44 | loss: 0.0393277\n",
      "\tspeed: 0.0215s/iter; left time: 269.8332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0408363 Vali Loss: 0.0508037 Test Loss: 0.0547695\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0387644\n",
      "\tspeed: 0.0413s/iter; left time: 513.7123s\n",
      "\titers: 200, epoch: 45 | loss: 0.0421335\n",
      "\tspeed: 0.0215s/iter; left time: 265.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0408626 Vali Loss: 0.0506989 Test Loss: 0.0547564\n",
      "Validation loss decreased (0.050759 --> 0.050699).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0406405\n",
      "\tspeed: 0.0419s/iter; left time: 512.6697s\n",
      "\titers: 200, epoch: 46 | loss: 0.0428052\n",
      "\tspeed: 0.0217s/iter; left time: 263.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0408595 Vali Loss: 0.0507874 Test Loss: 0.0547676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0410502\n",
      "\tspeed: 0.0421s/iter; left time: 505.5465s\n",
      "\titers: 200, epoch: 47 | loss: 0.0448898\n",
      "\tspeed: 0.0214s/iter; left time: 255.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408573 Vali Loss: 0.0507810 Test Loss: 0.0547585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0398445\n",
      "\tspeed: 0.0415s/iter; left time: 489.0927s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420685\n",
      "\tspeed: 0.0216s/iter; left time: 252.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0408299 Vali Loss: 0.0508557 Test Loss: 0.0547524\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0405456\n",
      "\tspeed: 0.0420s/iter; left time: 485.2478s\n",
      "\titers: 200, epoch: 49 | loss: 0.0427208\n",
      "\tspeed: 0.0215s/iter; left time: 246.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0408837 Vali Loss: 0.0507540 Test Loss: 0.0547544\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0361435\n",
      "\tspeed: 0.0422s/iter; left time: 477.6179s\n",
      "\titers: 200, epoch: 50 | loss: 0.0382484\n",
      "\tspeed: 0.0216s/iter; left time: 242.2424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0408478 Vali Loss: 0.0506820 Test Loss: 0.0547631\n",
      "Validation loss decreased (0.050699 --> 0.050682).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0445019\n",
      "\tspeed: 0.0425s/iter; left time: 471.6133s\n",
      "\titers: 200, epoch: 51 | loss: 0.0388521\n",
      "\tspeed: 0.0215s/iter; left time: 236.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408830 Vali Loss: 0.0507521 Test Loss: 0.0547523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0406499\n",
      "\tspeed: 0.0416s/iter; left time: 452.9308s\n",
      "\titers: 200, epoch: 52 | loss: 0.0429437\n",
      "\tspeed: 0.0215s/iter; left time: 231.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0408319 Vali Loss: 0.0507899 Test Loss: 0.0547480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0416919\n",
      "\tspeed: 0.0412s/iter; left time: 438.9077s\n",
      "\titers: 200, epoch: 53 | loss: 0.0413610\n",
      "\tspeed: 0.0214s/iter; left time: 226.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0408248 Vali Loss: 0.0508078 Test Loss: 0.0547522\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0437568\n",
      "\tspeed: 0.0412s/iter; left time: 429.8241s\n",
      "\titers: 200, epoch: 54 | loss: 0.0390082\n",
      "\tspeed: 0.0216s/iter; left time: 223.0394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0408348 Vali Loss: 0.0507491 Test Loss: 0.0547398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0412294\n",
      "\tspeed: 0.0414s/iter; left time: 422.3950s\n",
      "\titers: 200, epoch: 55 | loss: 0.0422725\n",
      "\tspeed: 0.0215s/iter; left time: 217.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0408018 Vali Loss: 0.0506723 Test Loss: 0.0547446\n",
      "Validation loss decreased (0.050682 --> 0.050672).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0357394\n",
      "\tspeed: 0.0421s/iter; left time: 420.0608s\n",
      "\titers: 200, epoch: 56 | loss: 0.0403160\n",
      "\tspeed: 0.0215s/iter; left time: 212.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0408179 Vali Loss: 0.0507600 Test Loss: 0.0547436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0411189\n",
      "\tspeed: 0.0426s/iter; left time: 415.9175s\n",
      "\titers: 200, epoch: 57 | loss: 0.0414192\n",
      "\tspeed: 0.0216s/iter; left time: 208.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0407903 Vali Loss: 0.0507926 Test Loss: 0.0547505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0448384\n",
      "\tspeed: 0.0417s/iter; left time: 397.6587s\n",
      "\titers: 200, epoch: 58 | loss: 0.0411332\n",
      "\tspeed: 0.0215s/iter; left time: 202.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0407991 Vali Loss: 0.0506882 Test Loss: 0.0547508\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0408990\n",
      "\tspeed: 0.0418s/iter; left time: 388.9810s\n",
      "\titers: 200, epoch: 59 | loss: 0.0420822\n",
      "\tspeed: 0.0215s/iter; left time: 198.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0407626 Vali Loss: 0.0507821 Test Loss: 0.0547550\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0430488\n",
      "\tspeed: 0.0419s/iter; left time: 380.6301s\n",
      "\titers: 200, epoch: 60 | loss: 0.0396329\n",
      "\tspeed: 0.0215s/iter; left time: 193.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408477 Vali Loss: 0.0507961 Test Loss: 0.0547467\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0413525\n",
      "\tspeed: 0.0415s/iter; left time: 368.0602s\n",
      "\titers: 200, epoch: 61 | loss: 0.0401741\n",
      "\tspeed: 0.0214s/iter; left time: 187.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408173 Vali Loss: 0.0507987 Test Loss: 0.0547463\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0387825\n",
      "\tspeed: 0.0415s/iter; left time: 358.2815s\n",
      "\titers: 200, epoch: 62 | loss: 0.0394390\n",
      "\tspeed: 0.0215s/iter; left time: 183.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0407836 Vali Loss: 0.0507470 Test Loss: 0.0547525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0403911\n",
      "\tspeed: 0.0421s/iter; left time: 354.4683s\n",
      "\titers: 200, epoch: 63 | loss: 0.0425924\n",
      "\tspeed: 0.0215s/iter; left time: 178.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0408110 Vali Loss: 0.0508126 Test Loss: 0.0547508\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0444756\n",
      "\tspeed: 0.0411s/iter; left time: 336.8800s\n",
      "\titers: 200, epoch: 64 | loss: 0.0423716\n",
      "\tspeed: 0.0216s/iter; left time: 174.9172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0407980 Vali Loss: 0.0507530 Test Loss: 0.0547486\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0426044\n",
      "\tspeed: 0.0415s/iter; left time: 330.1787s\n",
      "\titers: 200, epoch: 65 | loss: 0.0408079\n",
      "\tspeed: 0.0215s/iter; left time: 168.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408118 Vali Loss: 0.0507080 Test Loss: 0.0547459\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009919346310198307, rmse:0.09959591180086136, mae:0.05474460497498512, rse:0.38423827290534973\n",
      "Intermediate time for FR and pred_len 24: 00h:12m:08.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0983297\n",
      "\tspeed: 0.0384s/iter; left time: 855.7373s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873794\n",
      "\tspeed: 0.0216s/iter; left time: 480.5010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.1030776 Vali Loss: 0.0901118 Test Loss: 0.0987749\n",
      "Validation loss decreased (inf --> 0.090112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0738971\n",
      "\tspeed: 0.0431s/iter; left time: 951.6776s\n",
      "\titers: 200, epoch: 2 | loss: 0.0630338\n",
      "\tspeed: 0.0217s/iter; left time: 476.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0707665 Vali Loss: 0.0750541 Test Loss: 0.0844004\n",
      "Validation loss decreased (0.090112 --> 0.075054).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0650598\n",
      "\tspeed: 0.0435s/iter; left time: 949.9409s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631248\n",
      "\tspeed: 0.0217s/iter; left time: 471.7754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0642128 Vali Loss: 0.0723514 Test Loss: 0.0823486\n",
      "Validation loss decreased (0.075054 --> 0.072351).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0607355\n",
      "\tspeed: 0.0440s/iter; left time: 950.7292s\n",
      "\titers: 200, epoch: 4 | loss: 0.0640049\n",
      "\tspeed: 0.0216s/iter; left time: 465.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0623594 Vali Loss: 0.0713185 Test Loss: 0.0813607\n",
      "Validation loss decreased (0.072351 --> 0.071319).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619086\n",
      "\tspeed: 0.0435s/iter; left time: 931.5489s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585843\n",
      "\tspeed: 0.0220s/iter; left time: 468.9614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0611954 Vali Loss: 0.0714547 Test Loss: 0.0812930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645285\n",
      "\tspeed: 0.0431s/iter; left time: 912.7486s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585685\n",
      "\tspeed: 0.0216s/iter; left time: 455.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0603605 Vali Loss: 0.0708528 Test Loss: 0.0804025\n",
      "Validation loss decreased (0.071319 --> 0.070853).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0626411\n",
      "\tspeed: 0.0446s/iter; left time: 933.7562s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578498\n",
      "\tspeed: 0.0217s/iter; left time: 451.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0597481 Vali Loss: 0.0707155 Test Loss: 0.0805117\n",
      "Validation loss decreased (0.070853 --> 0.070716).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0617545\n",
      "\tspeed: 0.0435s/iter; left time: 901.0683s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570553\n",
      "\tspeed: 0.0217s/iter; left time: 446.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0593218 Vali Loss: 0.0705569 Test Loss: 0.0800213\n",
      "Validation loss decreased (0.070716 --> 0.070557).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0579642\n",
      "\tspeed: 0.0434s/iter; left time: 890.5296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584911\n",
      "\tspeed: 0.0217s/iter; left time: 442.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0589101 Vali Loss: 0.0703659 Test Loss: 0.0803864\n",
      "Validation loss decreased (0.070557 --> 0.070366).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590099\n",
      "\tspeed: 0.0434s/iter; left time: 880.5747s\n",
      "\titers: 200, epoch: 10 | loss: 0.0567615\n",
      "\tspeed: 0.0217s/iter; left time: 438.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0585553 Vali Loss: 0.0703196 Test Loss: 0.0800212\n",
      "Validation loss decreased (0.070366 --> 0.070320).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0599887\n",
      "\tspeed: 0.0446s/iter; left time: 894.9401s\n",
      "\titers: 200, epoch: 11 | loss: 0.0570798\n",
      "\tspeed: 0.0217s/iter; left time: 432.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0582727 Vali Loss: 0.0701688 Test Loss: 0.0800953\n",
      "Validation loss decreased (0.070320 --> 0.070169).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0576352\n",
      "\tspeed: 0.0434s/iter; left time: 861.7227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0568199\n",
      "\tspeed: 0.0217s/iter; left time: 428.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0579524 Vali Loss: 0.0703713 Test Loss: 0.0804924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0579580\n",
      "\tspeed: 0.0433s/iter; left time: 850.0240s\n",
      "\titers: 200, epoch: 13 | loss: 0.0583147\n",
      "\tspeed: 0.0218s/iter; left time: 425.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0577693 Vali Loss: 0.0704499 Test Loss: 0.0805893\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0565304\n",
      "\tspeed: 0.0428s/iter; left time: 830.3617s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569390\n",
      "\tspeed: 0.0217s/iter; left time: 418.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0574804 Vali Loss: 0.0702373 Test Loss: 0.0797039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0535891\n",
      "\tspeed: 0.0431s/iter; left time: 826.8398s\n",
      "\titers: 200, epoch: 15 | loss: 0.0597033\n",
      "\tspeed: 0.0217s/iter; left time: 414.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0573015 Vali Loss: 0.0701684 Test Loss: 0.0799846\n",
      "Validation loss decreased (0.070169 --> 0.070168).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0587517\n",
      "\tspeed: 0.0440s/iter; left time: 833.5395s\n",
      "\titers: 200, epoch: 16 | loss: 0.0592023\n",
      "\tspeed: 0.0216s/iter; left time: 407.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0571309 Vali Loss: 0.0702232 Test Loss: 0.0806227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0566779\n",
      "\tspeed: 0.0436s/iter; left time: 815.7265s\n",
      "\titers: 200, epoch: 17 | loss: 0.0592846\n",
      "\tspeed: 0.0216s/iter; left time: 402.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0569611 Vali Loss: 0.0698579 Test Loss: 0.0801451\n",
      "Validation loss decreased (0.070168 --> 0.069858).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570536\n",
      "\tspeed: 0.0444s/iter; left time: 821.9055s\n",
      "\titers: 200, epoch: 18 | loss: 0.0556913\n",
      "\tspeed: 0.0217s/iter; left time: 398.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0567850 Vali Loss: 0.0699912 Test Loss: 0.0802466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0593845\n",
      "\tspeed: 0.0436s/iter; left time: 796.4150s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588323\n",
      "\tspeed: 0.0217s/iter; left time: 393.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0567055 Vali Loss: 0.0699999 Test Loss: 0.0801822\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0558082\n",
      "\tspeed: 0.0427s/iter; left time: 770.2813s\n",
      "\titers: 200, epoch: 20 | loss: 0.0583261\n",
      "\tspeed: 0.0216s/iter; left time: 387.7001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0564659 Vali Loss: 0.0700179 Test Loss: 0.0798926\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0592596\n",
      "\tspeed: 0.0426s/iter; left time: 758.5438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0513039\n",
      "\tspeed: 0.0216s/iter; left time: 383.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0563980 Vali Loss: 0.0699883 Test Loss: 0.0799807\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0577759\n",
      "\tspeed: 0.0442s/iter; left time: 778.3173s\n",
      "\titers: 200, epoch: 22 | loss: 0.0578416\n",
      "\tspeed: 0.0216s/iter; left time: 378.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0562179 Vali Loss: 0.0699354 Test Loss: 0.0799568\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0544326\n",
      "\tspeed: 0.0434s/iter; left time: 754.8422s\n",
      "\titers: 200, epoch: 23 | loss: 0.0578180\n",
      "\tspeed: 0.0217s/iter; left time: 375.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0561494 Vali Loss: 0.0698742 Test Loss: 0.0802392\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0568733\n",
      "\tspeed: 0.0430s/iter; left time: 736.5739s\n",
      "\titers: 200, epoch: 24 | loss: 0.0529017\n",
      "\tspeed: 0.0217s/iter; left time: 369.3269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0560583 Vali Loss: 0.0699539 Test Loss: 0.0801342\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0557823\n",
      "\tspeed: 0.0424s/iter; left time: 717.9630s\n",
      "\titers: 200, epoch: 25 | loss: 0.0551363\n",
      "\tspeed: 0.0216s/iter; left time: 363.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0560021 Vali Loss: 0.0699088 Test Loss: 0.0804561\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0538700\n",
      "\tspeed: 0.0429s/iter; left time: 716.0849s\n",
      "\titers: 200, epoch: 26 | loss: 0.0609172\n",
      "\tspeed: 0.0216s/iter; left time: 358.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0559135 Vali Loss: 0.0698714 Test Loss: 0.0803807\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0539667\n",
      "\tspeed: 0.0423s/iter; left time: 697.6702s\n",
      "\titers: 200, epoch: 27 | loss: 0.0567633\n",
      "\tspeed: 0.0216s/iter; left time: 354.4264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0558816 Vali Loss: 0.0698992 Test Loss: 0.0803587\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018861200660467148, rmse:0.13733609020709991, mae:0.08014506101608276, rse:0.5312525033950806\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1032781\n",
      "\tspeed: 0.0231s/iter; left time: 516.0998s\n",
      "\titers: 200, epoch: 1 | loss: 0.0894776\n",
      "\tspeed: 0.0216s/iter; left time: 479.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.1047901 Vali Loss: 0.0910749 Test Loss: 0.0999701\n",
      "Validation loss decreased (inf --> 0.091075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0712828\n",
      "\tspeed: 0.0468s/iter; left time: 1033.9531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0676155\n",
      "\tspeed: 0.0217s/iter; left time: 477.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0711220 Vali Loss: 0.0756139 Test Loss: 0.0835577\n",
      "Validation loss decreased (0.091075 --> 0.075614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0628007\n",
      "\tspeed: 0.0441s/iter; left time: 963.9997s\n",
      "\titers: 200, epoch: 3 | loss: 0.0555193\n",
      "\tspeed: 0.0217s/iter; left time: 472.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0647038 Vali Loss: 0.0731150 Test Loss: 0.0823915\n",
      "Validation loss decreased (0.075614 --> 0.073115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0636035\n",
      "\tspeed: 0.0430s/iter; left time: 930.1500s\n",
      "\titers: 200, epoch: 4 | loss: 0.0652026\n",
      "\tspeed: 0.0217s/iter; left time: 467.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0626577 Vali Loss: 0.0717546 Test Loss: 0.0811954\n",
      "Validation loss decreased (0.073115 --> 0.071755).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0632059\n",
      "\tspeed: 0.0425s/iter; left time: 910.4904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0579741\n",
      "\tspeed: 0.0217s/iter; left time: 462.7122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0615232 Vali Loss: 0.0715645 Test Loss: 0.0811813\n",
      "Validation loss decreased (0.071755 --> 0.071564).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582235\n",
      "\tspeed: 0.0437s/iter; left time: 925.8519s\n",
      "\titers: 200, epoch: 6 | loss: 0.0580052\n",
      "\tspeed: 0.0217s/iter; left time: 457.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0607924 Vali Loss: 0.0712702 Test Loss: 0.0806161\n",
      "Validation loss decreased (0.071564 --> 0.071270).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606383\n",
      "\tspeed: 0.0433s/iter; left time: 908.3003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0575075\n",
      "\tspeed: 0.0217s/iter; left time: 452.4672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0601940 Vali Loss: 0.0708291 Test Loss: 0.0806453\n",
      "Validation loss decreased (0.071270 --> 0.070829).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0588592\n",
      "\tspeed: 0.0428s/iter; left time: 888.2033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603692\n",
      "\tspeed: 0.0217s/iter; left time: 448.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0596949 Vali Loss: 0.0709005 Test Loss: 0.0803103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0615383\n",
      "\tspeed: 0.0433s/iter; left time: 887.9445s\n",
      "\titers: 200, epoch: 9 | loss: 0.0605315\n",
      "\tspeed: 0.0220s/iter; left time: 448.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0592601 Vali Loss: 0.0706775 Test Loss: 0.0795777\n",
      "Validation loss decreased (0.070829 --> 0.070678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0565319\n",
      "\tspeed: 0.0430s/iter; left time: 872.0712s\n",
      "\titers: 200, epoch: 10 | loss: 0.0625511\n",
      "\tspeed: 0.0217s/iter; left time: 438.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0588624 Vali Loss: 0.0705330 Test Loss: 0.0799241\n",
      "Validation loss decreased (0.070678 --> 0.070533).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603376\n",
      "\tspeed: 0.0435s/iter; left time: 872.4423s\n",
      "\titers: 200, epoch: 11 | loss: 0.0558318\n",
      "\tspeed: 0.0217s/iter; left time: 433.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0584514 Vali Loss: 0.0705527 Test Loss: 0.0801024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0569655\n",
      "\tspeed: 0.0424s/iter; left time: 841.4143s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550287\n",
      "\tspeed: 0.0217s/iter; left time: 427.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0582022 Vali Loss: 0.0704530 Test Loss: 0.0802243\n",
      "Validation loss decreased (0.070533 --> 0.070453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0553624\n",
      "\tspeed: 0.0430s/iter; left time: 843.6581s\n",
      "\titers: 200, epoch: 13 | loss: 0.0517322\n",
      "\tspeed: 0.0217s/iter; left time: 424.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0579518 Vali Loss: 0.0704887 Test Loss: 0.0800117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0581793\n",
      "\tspeed: 0.0444s/iter; left time: 860.1556s\n",
      "\titers: 200, epoch: 14 | loss: 0.0584791\n",
      "\tspeed: 0.0220s/iter; left time: 424.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0576507 Vali Loss: 0.0705824 Test Loss: 0.0800150\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0578372\n",
      "\tspeed: 0.0435s/iter; left time: 832.8330s\n",
      "\titers: 200, epoch: 15 | loss: 0.0582060\n",
      "\tspeed: 0.0221s/iter; left time: 420.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0574322 Vali Loss: 0.0704745 Test Loss: 0.0797117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0524944\n",
      "\tspeed: 0.0435s/iter; left time: 823.0660s\n",
      "\titers: 200, epoch: 16 | loss: 0.0564282\n",
      "\tspeed: 0.0221s/iter; left time: 415.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0572118 Vali Loss: 0.0703373 Test Loss: 0.0801632\n",
      "Validation loss decreased (0.070453 --> 0.070337).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0578217\n",
      "\tspeed: 0.0444s/iter; left time: 831.5576s\n",
      "\titers: 200, epoch: 17 | loss: 0.0534884\n",
      "\tspeed: 0.0220s/iter; left time: 410.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0569978 Vali Loss: 0.0703569 Test Loss: 0.0804921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0571577\n",
      "\tspeed: 0.0441s/iter; left time: 815.6317s\n",
      "\titers: 200, epoch: 18 | loss: 0.0606384\n",
      "\tspeed: 0.0220s/iter; left time: 404.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0568611 Vali Loss: 0.0703310 Test Loss: 0.0799506\n",
      "Validation loss decreased (0.070337 --> 0.070331).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0588245\n",
      "\tspeed: 0.0442s/iter; left time: 808.0324s\n",
      "\titers: 200, epoch: 19 | loss: 0.0577377\n",
      "\tspeed: 0.0220s/iter; left time: 399.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0567295 Vali Loss: 0.0702524 Test Loss: 0.0801056\n",
      "Validation loss decreased (0.070331 --> 0.070252).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0559638\n",
      "\tspeed: 0.0454s/iter; left time: 818.4913s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549757\n",
      "\tspeed: 0.0216s/iter; left time: 388.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0566067 Vali Loss: 0.0703415 Test Loss: 0.0802463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0549327\n",
      "\tspeed: 0.0446s/iter; left time: 794.7913s\n",
      "\titers: 200, epoch: 21 | loss: 0.0608082\n",
      "\tspeed: 0.0216s/iter; left time: 383.6225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0564841 Vali Loss: 0.0702290 Test Loss: 0.0805072\n",
      "Validation loss decreased (0.070252 --> 0.070229).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0592940\n",
      "\tspeed: 0.0443s/iter; left time: 779.7626s\n",
      "\titers: 200, epoch: 22 | loss: 0.0558173\n",
      "\tspeed: 0.0216s/iter; left time: 378.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0563649 Vali Loss: 0.0702395 Test Loss: 0.0803802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0558129\n",
      "\tspeed: 0.0431s/iter; left time: 749.0281s\n",
      "\titers: 200, epoch: 23 | loss: 0.0593890\n",
      "\tspeed: 0.0215s/iter; left time: 371.1769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0562945 Vali Loss: 0.0703073 Test Loss: 0.0803660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0532952\n",
      "\tspeed: 0.0431s/iter; left time: 739.8801s\n",
      "\titers: 200, epoch: 24 | loss: 0.0554837\n",
      "\tspeed: 0.0216s/iter; left time: 367.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0562333 Vali Loss: 0.0703218 Test Loss: 0.0802923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0542953\n",
      "\tspeed: 0.0435s/iter; left time: 736.1684s\n",
      "\titers: 200, epoch: 25 | loss: 0.0565853\n",
      "\tspeed: 0.0218s/iter; left time: 367.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0560876 Vali Loss: 0.0701977 Test Loss: 0.0802869\n",
      "Validation loss decreased (0.070229 --> 0.070198).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0535866\n",
      "\tspeed: 0.0444s/iter; left time: 742.1888s\n",
      "\titers: 200, epoch: 26 | loss: 0.0557473\n",
      "\tspeed: 0.0216s/iter; left time: 359.1860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0560681 Vali Loss: 0.0702118 Test Loss: 0.0804627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0606934\n",
      "\tspeed: 0.0437s/iter; left time: 719.5641s\n",
      "\titers: 200, epoch: 27 | loss: 0.0583474\n",
      "\tspeed: 0.0217s/iter; left time: 354.6906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0559604 Vali Loss: 0.0702397 Test Loss: 0.0805286\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0589630\n",
      "\tspeed: 0.0433s/iter; left time: 703.7252s\n",
      "\titers: 200, epoch: 28 | loss: 0.0527305\n",
      "\tspeed: 0.0216s/iter; left time: 348.8420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0559436 Vali Loss: 0.0702620 Test Loss: 0.0804100\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0570246\n",
      "\tspeed: 0.0432s/iter; left time: 692.2432s\n",
      "\titers: 200, epoch: 29 | loss: 0.0549005\n",
      "\tspeed: 0.0215s/iter; left time: 343.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0558244 Vali Loss: 0.0701727 Test Loss: 0.0805837\n",
      "Validation loss decreased (0.070198 --> 0.070173).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0535036\n",
      "\tspeed: 0.0433s/iter; left time: 685.0157s\n",
      "\titers: 200, epoch: 30 | loss: 0.0551645\n",
      "\tspeed: 0.0216s/iter; left time: 339.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0558304 Vali Loss: 0.0702336 Test Loss: 0.0805002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0563684\n",
      "\tspeed: 0.0435s/iter; left time: 678.4751s\n",
      "\titers: 200, epoch: 31 | loss: 0.0534183\n",
      "\tspeed: 0.0216s/iter; left time: 335.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0557455 Vali Loss: 0.0702535 Test Loss: 0.0807959\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0550654\n",
      "\tspeed: 0.0432s/iter; left time: 663.7461s\n",
      "\titers: 200, epoch: 32 | loss: 0.0573682\n",
      "\tspeed: 0.0216s/iter; left time: 329.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0557698 Vali Loss: 0.0701754 Test Loss: 0.0805221\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0573631\n",
      "\tspeed: 0.0438s/iter; left time: 662.1867s\n",
      "\titers: 200, epoch: 33 | loss: 0.0551623\n",
      "\tspeed: 0.0217s/iter; left time: 325.8215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0557085 Vali Loss: 0.0701568 Test Loss: 0.0806537\n",
      "Validation loss decreased (0.070173 --> 0.070157).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0532169\n",
      "\tspeed: 0.0440s/iter; left time: 655.7614s\n",
      "\titers: 200, epoch: 34 | loss: 0.0594344\n",
      "\tspeed: 0.0216s/iter; left time: 320.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0556768 Vali Loss: 0.0701958 Test Loss: 0.0807552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0556454\n",
      "\tspeed: 0.0437s/iter; left time: 642.0102s\n",
      "\titers: 200, epoch: 35 | loss: 0.0524563\n",
      "\tspeed: 0.0216s/iter; left time: 315.0750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0556534 Vali Loss: 0.0702344 Test Loss: 0.0806114\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0558845\n",
      "\tspeed: 0.0435s/iter; left time: 628.5348s\n",
      "\titers: 200, epoch: 36 | loss: 0.0558818\n",
      "\tspeed: 0.0216s/iter; left time: 309.7534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0556243 Vali Loss: 0.0702542 Test Loss: 0.0806097\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0586675\n",
      "\tspeed: 0.0439s/iter; left time: 625.3746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0590788\n",
      "\tspeed: 0.0218s/iter; left time: 308.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0556311 Vali Loss: 0.0702658 Test Loss: 0.0807087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0518341\n",
      "\tspeed: 0.0437s/iter; left time: 613.0300s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564199\n",
      "\tspeed: 0.0217s/iter; left time: 302.4222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0556050 Vali Loss: 0.0701945 Test Loss: 0.0806469\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0538694\n",
      "\tspeed: 0.0434s/iter; left time: 598.8646s\n",
      "\titers: 200, epoch: 39 | loss: 0.0558340\n",
      "\tspeed: 0.0216s/iter; left time: 295.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0555526 Vali Loss: 0.0701788 Test Loss: 0.0806311\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0528037\n",
      "\tspeed: 0.0431s/iter; left time: 584.4127s\n",
      "\titers: 200, epoch: 40 | loss: 0.0563718\n",
      "\tspeed: 0.0216s/iter; left time: 291.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0555443 Vali Loss: 0.0701902 Test Loss: 0.0807230\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0537868\n",
      "\tspeed: 0.0433s/iter; left time: 577.6882s\n",
      "\titers: 200, epoch: 41 | loss: 0.0518138\n",
      "\tspeed: 0.0216s/iter; left time: 285.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0555225 Vali Loss: 0.0701703 Test Loss: 0.0806849\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0544420\n",
      "\tspeed: 0.0431s/iter; left time: 565.0525s\n",
      "\titers: 200, epoch: 42 | loss: 0.0537285\n",
      "\tspeed: 0.0218s/iter; left time: 284.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0554823 Vali Loss: 0.0701914 Test Loss: 0.0806764\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0557889\n",
      "\tspeed: 0.0433s/iter; left time: 558.7477s\n",
      "\titers: 200, epoch: 43 | loss: 0.0549040\n",
      "\tspeed: 0.0217s/iter; left time: 277.7320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0555147 Vali Loss: 0.0701696 Test Loss: 0.0807534\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019456075504422188, rmse:0.13948503136634827, mae:0.08065373450517654, rse:0.5395652055740356\n",
      "Intermediate time for FR and pred_len 96: 00h:07m:46.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1047884\n",
      "\tspeed: 0.0392s/iter; left time: 870.5918s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905137\n",
      "\tspeed: 0.0219s/iter; left time: 484.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.1047934 Vali Loss: 0.0926547 Test Loss: 0.1004540\n",
      "Validation loss decreased (inf --> 0.092655).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0788349\n",
      "\tspeed: 0.0436s/iter; left time: 957.8971s\n",
      "\titers: 200, epoch: 2 | loss: 0.0704296\n",
      "\tspeed: 0.0219s/iter; left time: 478.1683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0745576 Vali Loss: 0.0787413 Test Loss: 0.0877721\n",
      "Validation loss decreased (0.092655 --> 0.078741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726744\n",
      "\tspeed: 0.0461s/iter; left time: 1003.8582s\n",
      "\titers: 200, epoch: 3 | loss: 0.0646740\n",
      "\tspeed: 0.0218s/iter; left time: 472.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0679738 Vali Loss: 0.0758159 Test Loss: 0.0870918\n",
      "Validation loss decreased (0.078741 --> 0.075816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0661758\n",
      "\tspeed: 0.0438s/iter; left time: 942.9623s\n",
      "\titers: 200, epoch: 4 | loss: 0.0691870\n",
      "\tspeed: 0.0230s/iter; left time: 493.3638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0661650 Vali Loss: 0.0754182 Test Loss: 0.0868940\n",
      "Validation loss decreased (0.075816 --> 0.075418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0674820\n",
      "\tspeed: 0.0446s/iter; left time: 950.9199s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653155\n",
      "\tspeed: 0.0219s/iter; left time: 464.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0651712 Vali Loss: 0.0750074 Test Loss: 0.0866200\n",
      "Validation loss decreased (0.075418 --> 0.075007).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616626\n",
      "\tspeed: 0.0441s/iter; left time: 930.8986s\n",
      "\titers: 200, epoch: 6 | loss: 0.0650689\n",
      "\tspeed: 0.0219s/iter; left time: 459.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0644060 Vali Loss: 0.0744523 Test Loss: 0.0859786\n",
      "Validation loss decreased (0.075007 --> 0.074452).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0669554\n",
      "\tspeed: 0.0444s/iter; left time: 926.1003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0649517\n",
      "\tspeed: 0.0219s/iter; left time: 454.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0638422 Vali Loss: 0.0745442 Test Loss: 0.0857981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0588743\n",
      "\tspeed: 0.0445s/iter; left time: 918.5246s\n",
      "\titers: 200, epoch: 8 | loss: 0.0675873\n",
      "\tspeed: 0.0221s/iter; left time: 452.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0633962 Vali Loss: 0.0744216 Test Loss: 0.0862436\n",
      "Validation loss decreased (0.074452 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0661422\n",
      "\tspeed: 0.0476s/iter; left time: 971.3270s\n",
      "\titers: 200, epoch: 9 | loss: 0.0585471\n",
      "\tspeed: 0.0220s/iter; left time: 447.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0630006 Vali Loss: 0.0740434 Test Loss: 0.0856501\n",
      "Validation loss decreased (0.074422 --> 0.074043).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0613344\n",
      "\tspeed: 0.0447s/iter; left time: 902.4052s\n",
      "\titers: 200, epoch: 10 | loss: 0.0612494\n",
      "\tspeed: 0.0219s/iter; left time: 440.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0626160 Vali Loss: 0.0743081 Test Loss: 0.0863929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0670712\n",
      "\tspeed: 0.0439s/iter; left time: 875.9893s\n",
      "\titers: 200, epoch: 11 | loss: 0.0583281\n",
      "\tspeed: 0.0219s/iter; left time: 435.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0622482 Vali Loss: 0.0741598 Test Loss: 0.0864162\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608478\n",
      "\tspeed: 0.0440s/iter; left time: 868.2588s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624133\n",
      "\tspeed: 0.0220s/iter; left time: 432.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0619888 Vali Loss: 0.0738946 Test Loss: 0.0866426\n",
      "Validation loss decreased (0.074043 --> 0.073895).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0636746\n",
      "\tspeed: 0.0450s/iter; left time: 879.3674s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627672\n",
      "\tspeed: 0.0219s/iter; left time: 426.1501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0616880 Vali Loss: 0.0738143 Test Loss: 0.0860346\n",
      "Validation loss decreased (0.073895 --> 0.073814).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0624642\n",
      "\tspeed: 0.0443s/iter; left time: 854.8143s\n",
      "\titers: 200, epoch: 14 | loss: 0.0638702\n",
      "\tspeed: 0.0219s/iter; left time: 420.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0613845 Vali Loss: 0.0736747 Test Loss: 0.0871212\n",
      "Validation loss decreased (0.073814 --> 0.073675).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0590320\n",
      "\tspeed: 0.0445s/iter; left time: 849.5554s\n",
      "\titers: 200, epoch: 15 | loss: 0.0655731\n",
      "\tspeed: 0.0220s/iter; left time: 417.2130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0611519 Vali Loss: 0.0736324 Test Loss: 0.0870632\n",
      "Validation loss decreased (0.073675 --> 0.073632).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0640928\n",
      "\tspeed: 0.0650s/iter; left time: 1225.0424s\n",
      "\titers: 200, epoch: 16 | loss: 0.0616290\n",
      "\tspeed: 0.0218s/iter; left time: 409.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0609798 Vali Loss: 0.0734827 Test Loss: 0.0866049\n",
      "Validation loss decreased (0.073632 --> 0.073483).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604246\n",
      "\tspeed: 0.0441s/iter; left time: 822.2732s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624319\n",
      "\tspeed: 0.0218s/iter; left time: 404.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0607425 Vali Loss: 0.0735642 Test Loss: 0.0867476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0618308\n",
      "\tspeed: 0.0427s/iter; left time: 786.8634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607101\n",
      "\tspeed: 0.0219s/iter; left time: 400.1761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0605658 Vali Loss: 0.0736799 Test Loss: 0.0873466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0592976\n",
      "\tspeed: 0.0436s/iter; left time: 792.9547s\n",
      "\titers: 200, epoch: 19 | loss: 0.0594642\n",
      "\tspeed: 0.0219s/iter; left time: 396.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0603905 Vali Loss: 0.0734560 Test Loss: 0.0871987\n",
      "Validation loss decreased (0.073483 --> 0.073456).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0620754\n",
      "\tspeed: 0.0485s/iter; left time: 871.3446s\n",
      "\titers: 200, epoch: 20 | loss: 0.0573160\n",
      "\tspeed: 0.0219s/iter; left time: 391.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0602677 Vali Loss: 0.0735216 Test Loss: 0.0873157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0580598\n",
      "\tspeed: 0.0437s/iter; left time: 775.6477s\n",
      "\titers: 200, epoch: 21 | loss: 0.0585812\n",
      "\tspeed: 0.0220s/iter; left time: 388.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0600737 Vali Loss: 0.0736293 Test Loss: 0.0872346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0590039\n",
      "\tspeed: 0.0437s/iter; left time: 765.1823s\n",
      "\titers: 200, epoch: 22 | loss: 0.0674177\n",
      "\tspeed: 0.0218s/iter; left time: 379.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0599695 Vali Loss: 0.0734638 Test Loss: 0.0870055\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0582113\n",
      "\tspeed: 0.0427s/iter; left time: 737.6877s\n",
      "\titers: 200, epoch: 23 | loss: 0.0604661\n",
      "\tspeed: 0.0218s/iter; left time: 375.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0599225 Vali Loss: 0.0735764 Test Loss: 0.0871852\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0626521\n",
      "\tspeed: 0.0431s/iter; left time: 735.4977s\n",
      "\titers: 200, epoch: 24 | loss: 0.0589243\n",
      "\tspeed: 0.0219s/iter; left time: 370.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0598028 Vali Loss: 0.0733565 Test Loss: 0.0873794\n",
      "Validation loss decreased (0.073456 --> 0.073357).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0609070\n",
      "\tspeed: 0.0433s/iter; left time: 728.8259s\n",
      "\titers: 200, epoch: 25 | loss: 0.0620830\n",
      "\tspeed: 0.0218s/iter; left time: 365.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0597322 Vali Loss: 0.0734481 Test Loss: 0.0877511\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0621876\n",
      "\tspeed: 0.0435s/iter; left time: 723.9194s\n",
      "\titers: 200, epoch: 26 | loss: 0.0597988\n",
      "\tspeed: 0.0231s/iter; left time: 381.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0596620 Vali Loss: 0.0735329 Test Loss: 0.0874375\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0575571\n",
      "\tspeed: 0.0474s/iter; left time: 777.1925s\n",
      "\titers: 200, epoch: 27 | loss: 0.0595516\n",
      "\tspeed: 0.0233s/iter; left time: 380.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0595835 Vali Loss: 0.0735385 Test Loss: 0.0872694\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0571845\n",
      "\tspeed: 0.0468s/iter; left time: 757.1358s\n",
      "\titers: 200, epoch: 28 | loss: 0.0591345\n",
      "\tspeed: 0.0230s/iter; left time: 370.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 223 | Train Loss: 0.0595673 Vali Loss: 0.0735461 Test Loss: 0.0874079\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0607052\n",
      "\tspeed: 0.0465s/iter; left time: 741.5111s\n",
      "\titers: 200, epoch: 29 | loss: 0.0591063\n",
      "\tspeed: 0.0231s/iter; left time: 366.5983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0594623 Vali Loss: 0.0735023 Test Loss: 0.0872798\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0604437\n",
      "\tspeed: 0.0472s/iter; left time: 742.1106s\n",
      "\titers: 200, epoch: 30 | loss: 0.0607099\n",
      "\tspeed: 0.0231s/iter; left time: 361.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0594588 Vali Loss: 0.0735614 Test Loss: 0.0872892\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565619\n",
      "\tspeed: 0.0474s/iter; left time: 735.9722s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581741\n",
      "\tspeed: 0.0219s/iter; left time: 338.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0593974 Vali Loss: 0.0736041 Test Loss: 0.0871876\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0587226\n",
      "\tspeed: 0.0429s/iter; left time: 655.0997s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621920\n",
      "\tspeed: 0.0227s/iter; left time: 344.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0593082 Vali Loss: 0.0735738 Test Loss: 0.0873199\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0554282\n",
      "\tspeed: 0.0444s/iter; left time: 669.5626s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604258\n",
      "\tspeed: 0.0220s/iter; left time: 328.6217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0593511 Vali Loss: 0.0736037 Test Loss: 0.0871515\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592100\n",
      "\tspeed: 0.0434s/iter; left time: 644.7742s\n",
      "\titers: 200, epoch: 34 | loss: 0.0617456\n",
      "\tspeed: 0.0219s/iter; left time: 322.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0593144 Vali Loss: 0.0734652 Test Loss: 0.0874648\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021824315190315247, rmse:0.14773054420948029, mae:0.08737940341234207, rse:0.5721744298934937\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1030251\n",
      "\tspeed: 0.0237s/iter; left time: 527.1668s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873107\n",
      "\tspeed: 0.0219s/iter; left time: 483.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.1060435 Vali Loss: 0.0924741 Test Loss: 0.1004310\n",
      "Validation loss decreased (inf --> 0.092474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753420\n",
      "\tspeed: 0.0446s/iter; left time: 980.5810s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722338\n",
      "\tspeed: 0.0219s/iter; left time: 479.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0746925 Vali Loss: 0.0789645 Test Loss: 0.0883745\n",
      "Validation loss decreased (0.092474 --> 0.078965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0748482\n",
      "\tspeed: 0.0438s/iter; left time: 953.5283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639371\n",
      "\tspeed: 0.0219s/iter; left time: 473.5125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0683263 Vali Loss: 0.0765230 Test Loss: 0.0874017\n",
      "Validation loss decreased (0.078965 --> 0.076523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0649893\n",
      "\tspeed: 0.0435s/iter; left time: 936.2423s\n",
      "\titers: 200, epoch: 4 | loss: 0.0676690\n",
      "\tspeed: 0.0219s/iter; left time: 468.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0665618 Vali Loss: 0.0752665 Test Loss: 0.0865758\n",
      "Validation loss decreased (0.076523 --> 0.075266).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637639\n",
      "\tspeed: 0.0436s/iter; left time: 929.9842s\n",
      "\titers: 200, epoch: 5 | loss: 0.0627055\n",
      "\tspeed: 0.0219s/iter; left time: 464.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0654805 Vali Loss: 0.0751391 Test Loss: 0.0866270\n",
      "Validation loss decreased (0.075266 --> 0.075139).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0607501\n",
      "\tspeed: 0.0438s/iter; left time: 924.1653s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692497\n",
      "\tspeed: 0.0227s/iter; left time: 475.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0646013 Vali Loss: 0.0746873 Test Loss: 0.0865874\n",
      "Validation loss decreased (0.075139 --> 0.074687).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0634956\n",
      "\tspeed: 0.0484s/iter; left time: 1010.2585s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679322\n",
      "\tspeed: 0.0219s/iter; left time: 454.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0640746 Vali Loss: 0.0748270 Test Loss: 0.0862303\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0644977\n",
      "\tspeed: 0.0425s/iter; left time: 878.0276s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633362\n",
      "\tspeed: 0.0219s/iter; left time: 448.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0635260 Vali Loss: 0.0745034 Test Loss: 0.0873248\n",
      "Validation loss decreased (0.074687 --> 0.074503).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667399\n",
      "\tspeed: 0.0437s/iter; left time: 892.5737s\n",
      "\titers: 200, epoch: 9 | loss: 0.0659375\n",
      "\tspeed: 0.0218s/iter; left time: 443.1858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0631061 Vali Loss: 0.0743013 Test Loss: 0.0870588\n",
      "Validation loss decreased (0.074503 --> 0.074301).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633721\n",
      "\tspeed: 0.0435s/iter; left time: 879.2894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0638513\n",
      "\tspeed: 0.0218s/iter; left time: 438.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0628241 Vali Loss: 0.0743637 Test Loss: 0.0876514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0634327\n",
      "\tspeed: 0.0424s/iter; left time: 845.9228s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602419\n",
      "\tspeed: 0.0219s/iter; left time: 435.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0623999 Vali Loss: 0.0743283 Test Loss: 0.0879305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0590030\n",
      "\tspeed: 0.0425s/iter; left time: 839.7887s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654228\n",
      "\tspeed: 0.0219s/iter; left time: 429.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0621592 Vali Loss: 0.0739127 Test Loss: 0.0869534\n",
      "Validation loss decreased (0.074301 --> 0.073913).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0614395\n",
      "\tspeed: 0.0433s/iter; left time: 846.3625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0617297\n",
      "\tspeed: 0.0221s/iter; left time: 429.3154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0618787 Vali Loss: 0.0739848 Test Loss: 0.0876936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0613653\n",
      "\tspeed: 0.0429s/iter; left time: 828.9427s\n",
      "\titers: 200, epoch: 14 | loss: 0.0604087\n",
      "\tspeed: 0.0219s/iter; left time: 420.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0615930 Vali Loss: 0.0742752 Test Loss: 0.0876290\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0601074\n",
      "\tspeed: 0.0429s/iter; left time: 817.6393s\n",
      "\titers: 200, epoch: 15 | loss: 0.0587391\n",
      "\tspeed: 0.0219s/iter; left time: 416.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0614255 Vali Loss: 0.0740568 Test Loss: 0.0875472\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0572025\n",
      "\tspeed: 0.0430s/iter; left time: 810.4544s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580056\n",
      "\tspeed: 0.0220s/iter; left time: 412.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0612101 Vali Loss: 0.0742002 Test Loss: 0.0879717\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624616\n",
      "\tspeed: 0.0433s/iter; left time: 806.9121s\n",
      "\titers: 200, epoch: 17 | loss: 0.0583068\n",
      "\tspeed: 0.0218s/iter; left time: 404.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0609643 Vali Loss: 0.0740941 Test Loss: 0.0877149\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0642678\n",
      "\tspeed: 0.0425s/iter; left time: 783.3063s\n",
      "\titers: 200, epoch: 18 | loss: 0.0621655\n",
      "\tspeed: 0.0219s/iter; left time: 400.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0608562 Vali Loss: 0.0742891 Test Loss: 0.0880853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0588711\n",
      "\tspeed: 0.0429s/iter; left time: 781.0086s\n",
      "\titers: 200, epoch: 19 | loss: 0.0606055\n",
      "\tspeed: 0.0219s/iter; left time: 395.7317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0606920 Vali Loss: 0.0741619 Test Loss: 0.0881231\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0604822\n",
      "\tspeed: 0.0427s/iter; left time: 766.8363s\n",
      "\titers: 200, epoch: 20 | loss: 0.0585233\n",
      "\tspeed: 0.0219s/iter; left time: 390.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0605764 Vali Loss: 0.0740427 Test Loss: 0.0882085\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0645385\n",
      "\tspeed: 0.0433s/iter; left time: 767.8030s\n",
      "\titers: 200, epoch: 21 | loss: 0.0592120\n",
      "\tspeed: 0.0220s/iter; left time: 388.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0604268 Vali Loss: 0.0741126 Test Loss: 0.0880485\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0602419\n",
      "\tspeed: 0.0432s/iter; left time: 757.4638s\n",
      "\titers: 200, epoch: 22 | loss: 0.0623940\n",
      "\tspeed: 0.0218s/iter; left time: 380.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0602788 Vali Loss: 0.0741272 Test Loss: 0.0879747\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021077584475278854, rmse:0.14518120884895325, mae:0.08695334941148758, rse:0.5623005628585815\n",
      "Intermediate time for FR and pred_len 168: 00h:06m:22.98s\n",
      "Intermediate time for FR: 00h:26m:17.57s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1374330\n",
      "\tspeed: 0.0387s/iter; left time: 862.9607s\n",
      "\titers: 200, epoch: 1 | loss: 0.1158889\n",
      "\tspeed: 0.0215s/iter; left time: 478.1446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.1433002 Vali Loss: 0.0977289 Test Loss: 0.1001484\n",
      "Validation loss decreased (inf --> 0.097729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0775924\n",
      "\tspeed: 0.0432s/iter; left time: 952.8440s\n",
      "\titers: 200, epoch: 2 | loss: 0.0677988\n",
      "\tspeed: 0.0215s/iter; left time: 472.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0783026 Vali Loss: 0.0629715 Test Loss: 0.0662288\n",
      "Validation loss decreased (0.097729 --> 0.062971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0624642\n",
      "\tspeed: 0.0422s/iter; left time: 922.7846s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655993\n",
      "\tspeed: 0.0216s/iter; left time: 469.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0658234 Vali Loss: 0.0603904 Test Loss: 0.0630145\n",
      "Validation loss decreased (0.062971 --> 0.060390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0631800\n",
      "\tspeed: 0.0434s/iter; left time: 939.1106s\n",
      "\titers: 200, epoch: 4 | loss: 0.0595277\n",
      "\tspeed: 0.0215s/iter; left time: 463.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0628593 Vali Loss: 0.0585107 Test Loss: 0.0609076\n",
      "Validation loss decreased (0.060390 --> 0.058511).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0594525\n",
      "\tspeed: 0.0423s/iter; left time: 905.9711s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608826\n",
      "\tspeed: 0.0215s/iter; left time: 458.7495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0610891 Vali Loss: 0.0580950 Test Loss: 0.0601172\n",
      "Validation loss decreased (0.058511 --> 0.058095).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0573971\n",
      "\tspeed: 0.0420s/iter; left time: 889.7540s\n",
      "\titers: 200, epoch: 6 | loss: 0.0560708\n",
      "\tspeed: 0.0215s/iter; left time: 452.7179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0600967 Vali Loss: 0.0572676 Test Loss: 0.0596117\n",
      "Validation loss decreased (0.058095 --> 0.057268).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608855\n",
      "\tspeed: 0.0440s/iter; left time: 921.4481s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570359\n",
      "\tspeed: 0.0215s/iter; left time: 448.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0591829 Vali Loss: 0.0568020 Test Loss: 0.0589726\n",
      "Validation loss decreased (0.057268 --> 0.056802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575192\n",
      "\tspeed: 0.0431s/iter; left time: 892.6632s\n",
      "\titers: 200, epoch: 8 | loss: 0.0575466\n",
      "\tspeed: 0.0223s/iter; left time: 460.9618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0585594 Vali Loss: 0.0562999 Test Loss: 0.0586725\n",
      "Validation loss decreased (0.056802 --> 0.056300).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0555504\n",
      "\tspeed: 0.0503s/iter; left time: 1032.0147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0592853\n",
      "\tspeed: 0.0221s/iter; left time: 451.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0579470 Vali Loss: 0.0564453 Test Loss: 0.0588011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576661\n",
      "\tspeed: 0.0455s/iter; left time: 923.5975s\n",
      "\titers: 200, epoch: 10 | loss: 0.0568854\n",
      "\tspeed: 0.0225s/iter; left time: 453.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0575693 Vali Loss: 0.0561655 Test Loss: 0.0585279\n",
      "Validation loss decreased (0.056300 --> 0.056166).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0594519\n",
      "\tspeed: 0.0458s/iter; left time: 918.5862s\n",
      "\titers: 200, epoch: 11 | loss: 0.0520067\n",
      "\tspeed: 0.0216s/iter; left time: 431.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0571156 Vali Loss: 0.0558879 Test Loss: 0.0580664\n",
      "Validation loss decreased (0.056166 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538387\n",
      "\tspeed: 0.0429s/iter; left time: 850.0227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0570092\n",
      "\tspeed: 0.0215s/iter; left time: 424.9661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0567892 Vali Loss: 0.0556625 Test Loss: 0.0577564\n",
      "Validation loss decreased (0.055888 --> 0.055663).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0555708\n",
      "\tspeed: 0.0446s/iter; left time: 874.8027s\n",
      "\titers: 200, epoch: 13 | loss: 0.0566810\n",
      "\tspeed: 0.0215s/iter; left time: 419.2879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0565807 Vali Loss: 0.0555824 Test Loss: 0.0578818\n",
      "Validation loss decreased (0.055663 --> 0.055582).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0610963\n",
      "\tspeed: 0.0430s/iter; left time: 834.2712s\n",
      "\titers: 200, epoch: 14 | loss: 0.0550782\n",
      "\tspeed: 0.0215s/iter; left time: 414.8392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0562441 Vali Loss: 0.0554863 Test Loss: 0.0576335\n",
      "Validation loss decreased (0.055582 --> 0.055486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0569684\n",
      "\tspeed: 0.0439s/iter; left time: 840.9450s\n",
      "\titers: 200, epoch: 15 | loss: 0.0562406\n",
      "\tspeed: 0.0215s/iter; left time: 409.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0559479 Vali Loss: 0.0552672 Test Loss: 0.0574207\n",
      "Validation loss decreased (0.055486 --> 0.055267).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0571631\n",
      "\tspeed: 0.0423s/iter; left time: 800.5171s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558663\n",
      "\tspeed: 0.0216s/iter; left time: 406.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0558095 Vali Loss: 0.0551484 Test Loss: 0.0572730\n",
      "Validation loss decreased (0.055267 --> 0.055148).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0583936\n",
      "\tspeed: 0.0422s/iter; left time: 790.5099s\n",
      "\titers: 200, epoch: 17 | loss: 0.0574635\n",
      "\tspeed: 0.0215s/iter; left time: 399.8954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0557455 Vali Loss: 0.0550383 Test Loss: 0.0572293\n",
      "Validation loss decreased (0.055148 --> 0.055038).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0537376\n",
      "\tspeed: 0.0428s/iter; left time: 792.0817s\n",
      "\titers: 200, epoch: 18 | loss: 0.0576277\n",
      "\tspeed: 0.0215s/iter; left time: 395.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0555075 Vali Loss: 0.0550554 Test Loss: 0.0572817\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0551231\n",
      "\tspeed: 0.0418s/iter; left time: 763.7701s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589218\n",
      "\tspeed: 0.0216s/iter; left time: 392.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0553814 Vali Loss: 0.0549142 Test Loss: 0.0571010\n",
      "Validation loss decreased (0.055038 --> 0.054914).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545368\n",
      "\tspeed: 0.0424s/iter; left time: 765.5982s\n",
      "\titers: 200, epoch: 20 | loss: 0.0538168\n",
      "\tspeed: 0.0215s/iter; left time: 385.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0551741 Vali Loss: 0.0548667 Test Loss: 0.0570449\n",
      "Validation loss decreased (0.054914 --> 0.054867).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563235\n",
      "\tspeed: 0.0423s/iter; left time: 753.9084s\n",
      "\titers: 200, epoch: 21 | loss: 0.0539313\n",
      "\tspeed: 0.0215s/iter; left time: 380.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0551580 Vali Loss: 0.0548767 Test Loss: 0.0570842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0526196\n",
      "\tspeed: 0.0419s/iter; left time: 736.9703s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502118\n",
      "\tspeed: 0.0215s/iter; left time: 376.7583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0550031 Vali Loss: 0.0548935 Test Loss: 0.0570054\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0541094\n",
      "\tspeed: 0.0419s/iter; left time: 727.3902s\n",
      "\titers: 200, epoch: 23 | loss: 0.0508736\n",
      "\tspeed: 0.0215s/iter; left time: 371.8530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0548972 Vali Loss: 0.0548363 Test Loss: 0.0570776\n",
      "Validation loss decreased (0.054867 --> 0.054836).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583407\n",
      "\tspeed: 0.0424s/iter; left time: 727.6081s\n",
      "\titers: 200, epoch: 24 | loss: 0.0550409\n",
      "\tspeed: 0.0215s/iter; left time: 367.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0548103 Vali Loss: 0.0546860 Test Loss: 0.0570549\n",
      "Validation loss decreased (0.054836 --> 0.054686).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0517474\n",
      "\tspeed: 0.0428s/iter; left time: 723.7147s\n",
      "\titers: 200, epoch: 25 | loss: 0.0576478\n",
      "\tspeed: 0.0215s/iter; left time: 361.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0547476 Vali Loss: 0.0545434 Test Loss: 0.0568930\n",
      "Validation loss decreased (0.054686 --> 0.054543).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0559251\n",
      "\tspeed: 0.0426s/iter; left time: 711.4819s\n",
      "\titers: 200, epoch: 26 | loss: 0.0555410\n",
      "\tspeed: 0.0215s/iter; left time: 356.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0546784 Vali Loss: 0.0545894 Test Loss: 0.0568467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0570185\n",
      "\tspeed: 0.0416s/iter; left time: 685.9364s\n",
      "\titers: 200, epoch: 27 | loss: 0.0575861\n",
      "\tspeed: 0.0215s/iter; left time: 352.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0546277 Vali Loss: 0.0546435 Test Loss: 0.0568211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563731\n",
      "\tspeed: 0.0421s/iter; left time: 683.4429s\n",
      "\titers: 200, epoch: 28 | loss: 0.0524455\n",
      "\tspeed: 0.0215s/iter; left time: 348.0128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0545354 Vali Loss: 0.0544690 Test Loss: 0.0567674\n",
      "Validation loss decreased (0.054543 --> 0.054469).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0574244\n",
      "\tspeed: 0.0436s/iter; left time: 698.9941s\n",
      "\titers: 200, epoch: 29 | loss: 0.0525602\n",
      "\tspeed: 0.0215s/iter; left time: 342.2197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0545589 Vali Loss: 0.0544414 Test Loss: 0.0568940\n",
      "Validation loss decreased (0.054469 --> 0.054441).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0544800\n",
      "\tspeed: 0.0423s/iter; left time: 668.6601s\n",
      "\titers: 200, epoch: 30 | loss: 0.0563679\n",
      "\tspeed: 0.0214s/iter; left time: 336.7709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0544876 Vali Loss: 0.0545130 Test Loss: 0.0568038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0518920\n",
      "\tspeed: 0.0420s/iter; left time: 654.6807s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554251\n",
      "\tspeed: 0.0215s/iter; left time: 332.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0544764 Vali Loss: 0.0544562 Test Loss: 0.0567921\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0543855\n",
      "\tspeed: 0.0416s/iter; left time: 639.2368s\n",
      "\titers: 200, epoch: 32 | loss: 0.0567700\n",
      "\tspeed: 0.0215s/iter; left time: 328.3042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0544112 Vali Loss: 0.0544896 Test Loss: 0.0567369\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0550720\n",
      "\tspeed: 0.0417s/iter; left time: 631.5866s\n",
      "\titers: 200, epoch: 33 | loss: 0.0551676\n",
      "\tspeed: 0.0217s/iter; left time: 325.6444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0544500 Vali Loss: 0.0544095 Test Loss: 0.0567518\n",
      "Validation loss decreased (0.054441 --> 0.054409).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0567886\n",
      "\tspeed: 0.0428s/iter; left time: 637.9667s\n",
      "\titers: 200, epoch: 34 | loss: 0.0572906\n",
      "\tspeed: 0.0215s/iter; left time: 317.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0542808 Vali Loss: 0.0543764 Test Loss: 0.0567341\n",
      "Validation loss decreased (0.054409 --> 0.054376).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0533894\n",
      "\tspeed: 0.0421s/iter; left time: 618.8881s\n",
      "\titers: 200, epoch: 35 | loss: 0.0561079\n",
      "\tspeed: 0.0215s/iter; left time: 312.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0543705 Vali Loss: 0.0544325 Test Loss: 0.0567682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0552642\n",
      "\tspeed: 0.0413s/iter; left time: 597.8618s\n",
      "\titers: 200, epoch: 36 | loss: 0.0545737\n",
      "\tspeed: 0.0216s/iter; left time: 309.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0542740 Vali Loss: 0.0544421 Test Loss: 0.0566902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0536100\n",
      "\tspeed: 0.0419s/iter; left time: 595.9987s\n",
      "\titers: 200, epoch: 37 | loss: 0.0506984\n",
      "\tspeed: 0.0215s/iter; left time: 303.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0543074 Vali Loss: 0.0543864 Test Loss: 0.0567062\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0541290\n",
      "\tspeed: 0.0424s/iter; left time: 594.1564s\n",
      "\titers: 200, epoch: 38 | loss: 0.0560373\n",
      "\tspeed: 0.0216s/iter; left time: 300.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0542180 Vali Loss: 0.0543355 Test Loss: 0.0566822\n",
      "Validation loss decreased (0.054376 --> 0.054335).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0512705\n",
      "\tspeed: 0.0437s/iter; left time: 602.9437s\n",
      "\titers: 200, epoch: 39 | loss: 0.0553241\n",
      "\tspeed: 0.0216s/iter; left time: 295.5520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0542341 Vali Loss: 0.0543868 Test Loss: 0.0566607\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0553307\n",
      "\tspeed: 0.0427s/iter; left time: 579.6505s\n",
      "\titers: 200, epoch: 40 | loss: 0.0515860\n",
      "\tspeed: 0.0216s/iter; left time: 290.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0542228 Vali Loss: 0.0544044 Test Loss: 0.0566717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0563626\n",
      "\tspeed: 0.0426s/iter; left time: 568.5501s\n",
      "\titers: 200, epoch: 41 | loss: 0.0504337\n",
      "\tspeed: 0.0216s/iter; left time: 285.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0542287 Vali Loss: 0.0543635 Test Loss: 0.0566482\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523032\n",
      "\tspeed: 0.0426s/iter; left time: 558.5696s\n",
      "\titers: 200, epoch: 42 | loss: 0.0582025\n",
      "\tspeed: 0.0216s/iter; left time: 281.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0542033 Vali Loss: 0.0543002 Test Loss: 0.0566480\n",
      "Validation loss decreased (0.054335 --> 0.054300).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522139\n",
      "\tspeed: 0.0430s/iter; left time: 554.8457s\n",
      "\titers: 200, epoch: 43 | loss: 0.0509002\n",
      "\tspeed: 0.0216s/iter; left time: 275.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0541778 Vali Loss: 0.0543848 Test Loss: 0.0566356\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0540905\n",
      "\tspeed: 0.0426s/iter; left time: 539.3402s\n",
      "\titers: 200, epoch: 44 | loss: 0.0551286\n",
      "\tspeed: 0.0216s/iter; left time: 271.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0542117 Vali Loss: 0.0542866 Test Loss: 0.0566235\n",
      "Validation loss decreased (0.054300 --> 0.054287).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0567412\n",
      "\tspeed: 0.0425s/iter; left time: 528.8247s\n",
      "\titers: 200, epoch: 45 | loss: 0.0568375\n",
      "\tspeed: 0.0215s/iter; left time: 265.2501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0541866 Vali Loss: 0.0543479 Test Loss: 0.0566406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0504196\n",
      "\tspeed: 0.0422s/iter; left time: 515.7030s\n",
      "\titers: 200, epoch: 46 | loss: 0.0570223\n",
      "\tspeed: 0.0215s/iter; left time: 260.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0541373 Vali Loss: 0.0543584 Test Loss: 0.0566015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0615442\n",
      "\tspeed: 0.0419s/iter; left time: 503.1153s\n",
      "\titers: 200, epoch: 47 | loss: 0.0499255\n",
      "\tspeed: 0.0215s/iter; left time: 256.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0542002 Vali Loss: 0.0543194 Test Loss: 0.0566245\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0552510\n",
      "\tspeed: 0.0418s/iter; left time: 491.7875s\n",
      "\titers: 200, epoch: 48 | loss: 0.0520807\n",
      "\tspeed: 0.0215s/iter; left time: 251.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0541524 Vali Loss: 0.0542495 Test Loss: 0.0566311\n",
      "Validation loss decreased (0.054287 --> 0.054249).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0545694\n",
      "\tspeed: 0.0431s/iter; left time: 497.9741s\n",
      "\titers: 200, epoch: 49 | loss: 0.0505374\n",
      "\tspeed: 0.0216s/iter; left time: 246.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0541052 Vali Loss: 0.0543268 Test Loss: 0.0566165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0538755\n",
      "\tspeed: 0.0420s/iter; left time: 475.8218s\n",
      "\titers: 200, epoch: 50 | loss: 0.0503643\n",
      "\tspeed: 0.0215s/iter; left time: 241.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541240 Vali Loss: 0.0543155 Test Loss: 0.0566461\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0532780\n",
      "\tspeed: 0.0421s/iter; left time: 467.4958s\n",
      "\titers: 200, epoch: 51 | loss: 0.0521176\n",
      "\tspeed: 0.0215s/iter; left time: 236.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0542104 Vali Loss: 0.0542844 Test Loss: 0.0566410\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0516743\n",
      "\tspeed: 0.0426s/iter; left time: 462.9884s\n",
      "\titers: 200, epoch: 52 | loss: 0.0522399\n",
      "\tspeed: 0.0215s/iter; left time: 231.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0541466 Vali Loss: 0.0543077 Test Loss: 0.0566177\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0549785\n",
      "\tspeed: 0.0419s/iter; left time: 446.0280s\n",
      "\titers: 200, epoch: 53 | loss: 0.0513716\n",
      "\tspeed: 0.0214s/iter; left time: 226.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0541321 Vali Loss: 0.0543021 Test Loss: 0.0566411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0541234\n",
      "\tspeed: 0.0416s/iter; left time: 434.0395s\n",
      "\titers: 200, epoch: 54 | loss: 0.0581750\n",
      "\tspeed: 0.0214s/iter; left time: 221.1079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0541015 Vali Loss: 0.0542947 Test Loss: 0.0566174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0550104\n",
      "\tspeed: 0.0420s/iter; left time: 428.2857s\n",
      "\titers: 200, epoch: 55 | loss: 0.0567199\n",
      "\tspeed: 0.0215s/iter; left time: 217.4224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0540815 Vali Loss: 0.0543251 Test Loss: 0.0566403\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0526870\n",
      "\tspeed: 0.0414s/iter; left time: 412.9114s\n",
      "\titers: 200, epoch: 56 | loss: 0.0572773\n",
      "\tspeed: 0.0215s/iter; left time: 212.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0541013 Vali Loss: 0.0543307 Test Loss: 0.0566290\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0561683\n",
      "\tspeed: 0.0421s/iter; left time: 411.0681s\n",
      "\titers: 200, epoch: 57 | loss: 0.0537422\n",
      "\tspeed: 0.0214s/iter; left time: 206.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0541649 Vali Loss: 0.0542578 Test Loss: 0.0566242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0534977\n",
      "\tspeed: 0.0416s/iter; left time: 396.9521s\n",
      "\titers: 200, epoch: 58 | loss: 0.0546461\n",
      "\tspeed: 0.0215s/iter; left time: 202.9552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0540974 Vali Loss: 0.0542856 Test Loss: 0.0566259\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010082419961690903, rmse:0.10041125118732452, mae:0.05663115531206131, rse:0.3794046938419342\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1339007\n",
      "\tspeed: 0.0230s/iter; left time: 513.2802s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141043\n",
      "\tspeed: 0.0214s/iter; left time: 475.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1399536 Vali Loss: 0.0962337 Test Loss: 0.0982868\n",
      "Validation loss decreased (inf --> 0.096234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0758613\n",
      "\tspeed: 0.0427s/iter; left time: 943.6928s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685552\n",
      "\tspeed: 0.0214s/iter; left time: 471.1924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0781022 Vali Loss: 0.0632921 Test Loss: 0.0665533\n",
      "Validation loss decreased (0.096234 --> 0.063292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0699126\n",
      "\tspeed: 0.0418s/iter; left time: 913.8944s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639520\n",
      "\tspeed: 0.0214s/iter; left time: 466.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0657198 Vali Loss: 0.0600900 Test Loss: 0.0626587\n",
      "Validation loss decreased (0.063292 --> 0.060090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0661892\n",
      "\tspeed: 0.0423s/iter; left time: 914.6747s\n",
      "\titers: 200, epoch: 4 | loss: 0.0630479\n",
      "\tspeed: 0.0229s/iter; left time: 493.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0628259 Vali Loss: 0.0587901 Test Loss: 0.0611407\n",
      "Validation loss decreased (0.060090 --> 0.058790).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0577873\n",
      "\tspeed: 0.0424s/iter; left time: 906.6851s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615354\n",
      "\tspeed: 0.0216s/iter; left time: 460.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0611608 Vali Loss: 0.0579751 Test Loss: 0.0604489\n",
      "Validation loss decreased (0.058790 --> 0.057975).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0578371\n",
      "\tspeed: 0.0431s/iter; left time: 912.0520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608955\n",
      "\tspeed: 0.0226s/iter; left time: 476.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0600812 Vali Loss: 0.0574840 Test Loss: 0.0594247\n",
      "Validation loss decreased (0.057975 --> 0.057484).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0610436\n",
      "\tspeed: 0.0435s/iter; left time: 911.5468s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580292\n",
      "\tspeed: 0.0217s/iter; left time: 452.0387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0593069 Vali Loss: 0.0566896 Test Loss: 0.0590364\n",
      "Validation loss decreased (0.057484 --> 0.056690).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0619234\n",
      "\tspeed: 0.0415s/iter; left time: 859.4763s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609879\n",
      "\tspeed: 0.0221s/iter; left time: 455.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0586601 Vali Loss: 0.0566635 Test Loss: 0.0588564\n",
      "Validation loss decreased (0.056690 --> 0.056664).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0585691\n",
      "\tspeed: 0.0458s/iter; left time: 938.8217s\n",
      "\titers: 200, epoch: 9 | loss: 0.0596622\n",
      "\tspeed: 0.0223s/iter; left time: 455.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0580095 Vali Loss: 0.0562204 Test Loss: 0.0584780\n",
      "Validation loss decreased (0.056664 --> 0.056220).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0566555\n",
      "\tspeed: 0.0449s/iter; left time: 910.3337s\n",
      "\titers: 200, epoch: 10 | loss: 0.0590553\n",
      "\tspeed: 0.0216s/iter; left time: 435.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0575709 Vali Loss: 0.0561185 Test Loss: 0.0584787\n",
      "Validation loss decreased (0.056220 --> 0.056119).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0580545\n",
      "\tspeed: 0.0429s/iter; left time: 860.4079s\n",
      "\titers: 200, epoch: 11 | loss: 0.0536545\n",
      "\tspeed: 0.0216s/iter; left time: 430.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0572077 Vali Loss: 0.0559147 Test Loss: 0.0581077\n",
      "Validation loss decreased (0.056119 --> 0.055915).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0606991\n",
      "\tspeed: 0.0431s/iter; left time: 854.4795s\n",
      "\titers: 200, epoch: 12 | loss: 0.0579197\n",
      "\tspeed: 0.0215s/iter; left time: 425.1358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0568025 Vali Loss: 0.0556031 Test Loss: 0.0580129\n",
      "Validation loss decreased (0.055915 --> 0.055603).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552645\n",
      "\tspeed: 0.0420s/iter; left time: 824.5466s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575264\n",
      "\tspeed: 0.0215s/iter; left time: 419.5667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0565975 Vali Loss: 0.0555254 Test Loss: 0.0578121\n",
      "Validation loss decreased (0.055603 --> 0.055525).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575443\n",
      "\tspeed: 0.0425s/iter; left time: 823.6450s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548009\n",
      "\tspeed: 0.0215s/iter; left time: 414.6678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0563294 Vali Loss: 0.0552340 Test Loss: 0.0577625\n",
      "Validation loss decreased (0.055525 --> 0.055234).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0540166\n",
      "\tspeed: 0.0424s/iter; left time: 812.8717s\n",
      "\titers: 200, epoch: 15 | loss: 0.0579367\n",
      "\tspeed: 0.0215s/iter; left time: 409.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0561100 Vali Loss: 0.0552688 Test Loss: 0.0576236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0556957\n",
      "\tspeed: 0.0419s/iter; left time: 794.0030s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567376\n",
      "\tspeed: 0.0215s/iter; left time: 404.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0559282 Vali Loss: 0.0551624 Test Loss: 0.0576666\n",
      "Validation loss decreased (0.055234 --> 0.055162).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571628\n",
      "\tspeed: 0.0421s/iter; left time: 787.8706s\n",
      "\titers: 200, epoch: 17 | loss: 0.0562587\n",
      "\tspeed: 0.0215s/iter; left time: 399.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0557251 Vali Loss: 0.0550474 Test Loss: 0.0573440\n",
      "Validation loss decreased (0.055162 --> 0.055047).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599124\n",
      "\tspeed: 0.0419s/iter; left time: 774.9591s\n",
      "\titers: 200, epoch: 18 | loss: 0.0596398\n",
      "\tspeed: 0.0215s/iter; left time: 395.4013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0555403 Vali Loss: 0.0551596 Test Loss: 0.0574187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0568367\n",
      "\tspeed: 0.0420s/iter; left time: 767.4066s\n",
      "\titers: 200, epoch: 19 | loss: 0.0576186\n",
      "\tspeed: 0.0216s/iter; left time: 392.3985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0553967 Vali Loss: 0.0548926 Test Loss: 0.0574379\n",
      "Validation loss decreased (0.055047 --> 0.054893).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0516709\n",
      "\tspeed: 0.0453s/iter; left time: 816.6746s\n",
      "\titers: 200, epoch: 20 | loss: 0.0532392\n",
      "\tspeed: 0.0215s/iter; left time: 386.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0553269 Vali Loss: 0.0547914 Test Loss: 0.0572598\n",
      "Validation loss decreased (0.054893 --> 0.054791).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0612929\n",
      "\tspeed: 0.0421s/iter; left time: 750.4024s\n",
      "\titers: 200, epoch: 21 | loss: 0.0586444\n",
      "\tspeed: 0.0215s/iter; left time: 381.2295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0551592 Vali Loss: 0.0546671 Test Loss: 0.0571164\n",
      "Validation loss decreased (0.054791 --> 0.054667).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0550500\n",
      "\tspeed: 0.0422s/iter; left time: 742.9936s\n",
      "\titers: 200, epoch: 22 | loss: 0.0568175\n",
      "\tspeed: 0.0215s/iter; left time: 376.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0550600 Vali Loss: 0.0547517 Test Loss: 0.0573194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0562241\n",
      "\tspeed: 0.0428s/iter; left time: 743.8595s\n",
      "\titers: 200, epoch: 23 | loss: 0.0562010\n",
      "\tspeed: 0.0228s/iter; left time: 393.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0549301 Vali Loss: 0.0546346 Test Loss: 0.0571809\n",
      "Validation loss decreased (0.054667 --> 0.054635).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0601251\n",
      "\tspeed: 0.0428s/iter; left time: 734.4827s\n",
      "\titers: 200, epoch: 24 | loss: 0.0503643\n",
      "\tspeed: 0.0215s/iter; left time: 366.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0549245 Vali Loss: 0.0546147 Test Loss: 0.0570558\n",
      "Validation loss decreased (0.054635 --> 0.054615).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0540612\n",
      "\tspeed: 0.0419s/iter; left time: 709.3509s\n",
      "\titers: 200, epoch: 25 | loss: 0.0536494\n",
      "\tspeed: 0.0215s/iter; left time: 361.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0548452 Vali Loss: 0.0545980 Test Loss: 0.0569985\n",
      "Validation loss decreased (0.054615 --> 0.054598).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537542\n",
      "\tspeed: 0.0421s/iter; left time: 702.6177s\n",
      "\titers: 200, epoch: 26 | loss: 0.0526753\n",
      "\tspeed: 0.0215s/iter; left time: 357.0427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0547378 Vali Loss: 0.0545814 Test Loss: 0.0569343\n",
      "Validation loss decreased (0.054598 --> 0.054581).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0547489\n",
      "\tspeed: 0.0419s/iter; left time: 690.7546s\n",
      "\titers: 200, epoch: 27 | loss: 0.0570755\n",
      "\tspeed: 0.0215s/iter; left time: 352.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0547119 Vali Loss: 0.0545830 Test Loss: 0.0570169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0561430\n",
      "\tspeed: 0.0415s/iter; left time: 674.9793s\n",
      "\titers: 200, epoch: 28 | loss: 0.0547058\n",
      "\tspeed: 0.0215s/iter; left time: 347.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0545742 Vali Loss: 0.0545249 Test Loss: 0.0569628\n",
      "Validation loss decreased (0.054581 --> 0.054525).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0583723\n",
      "\tspeed: 0.0422s/iter; left time: 676.5188s\n",
      "\titers: 200, epoch: 29 | loss: 0.0564685\n",
      "\tspeed: 0.0215s/iter; left time: 342.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0545637 Vali Loss: 0.0545397 Test Loss: 0.0569412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0561986\n",
      "\tspeed: 0.0416s/iter; left time: 657.9660s\n",
      "\titers: 200, epoch: 30 | loss: 0.0567871\n",
      "\tspeed: 0.0215s/iter; left time: 337.5733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0545386 Vali Loss: 0.0545551 Test Loss: 0.0570078\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525878\n",
      "\tspeed: 0.0414s/iter; left time: 645.1905s\n",
      "\titers: 200, epoch: 31 | loss: 0.0560188\n",
      "\tspeed: 0.0215s/iter; left time: 332.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0545423 Vali Loss: 0.0544267 Test Loss: 0.0569337\n",
      "Validation loss decreased (0.054525 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0561851\n",
      "\tspeed: 0.0420s/iter; left time: 644.7535s\n",
      "\titers: 200, epoch: 32 | loss: 0.0548819\n",
      "\tspeed: 0.0215s/iter; left time: 328.3451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0544458 Vali Loss: 0.0544618 Test Loss: 0.0569152\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0567685\n",
      "\tspeed: 0.0417s/iter; left time: 631.1441s\n",
      "\titers: 200, epoch: 33 | loss: 0.0507412\n",
      "\tspeed: 0.0215s/iter; left time: 322.9943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0544456 Vali Loss: 0.0544538 Test Loss: 0.0569001\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0559536\n",
      "\tspeed: 0.0415s/iter; left time: 618.2945s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519906\n",
      "\tspeed: 0.0217s/iter; left time: 321.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0544656 Vali Loss: 0.0543858 Test Loss: 0.0568676\n",
      "Validation loss decreased (0.054427 --> 0.054386).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0530760\n",
      "\tspeed: 0.0421s/iter; left time: 618.2376s\n",
      "\titers: 200, epoch: 35 | loss: 0.0572495\n",
      "\tspeed: 0.0214s/iter; left time: 312.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0543739 Vali Loss: 0.0543999 Test Loss: 0.0568235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0515960\n",
      "\tspeed: 0.0415s/iter; left time: 599.8871s\n",
      "\titers: 200, epoch: 36 | loss: 0.0520151\n",
      "\tspeed: 0.0215s/iter; left time: 308.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0543862 Vali Loss: 0.0544744 Test Loss: 0.0568320\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519809\n",
      "\tspeed: 0.0411s/iter; left time: 585.2617s\n",
      "\titers: 200, epoch: 37 | loss: 0.0528668\n",
      "\tspeed: 0.0214s/iter; left time: 302.7780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0543618 Vali Loss: 0.0543376 Test Loss: 0.0568573\n",
      "Validation loss decreased (0.054386 --> 0.054338).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0481222\n",
      "\tspeed: 0.0415s/iter; left time: 580.9310s\n",
      "\titers: 200, epoch: 38 | loss: 0.0524703\n",
      "\tspeed: 0.0215s/iter; left time: 298.5175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0543674 Vali Loss: 0.0543297 Test Loss: 0.0567856\n",
      "Validation loss decreased (0.054338 --> 0.054330).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0495181\n",
      "\tspeed: 0.0421s/iter; left time: 580.1197s\n",
      "\titers: 200, epoch: 39 | loss: 0.0553799\n",
      "\tspeed: 0.0216s/iter; left time: 295.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0543520 Vali Loss: 0.0543180 Test Loss: 0.0568032\n",
      "Validation loss decreased (0.054330 --> 0.054318).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0504843\n",
      "\tspeed: 0.0422s/iter; left time: 572.5507s\n",
      "\titers: 200, epoch: 40 | loss: 0.0588645\n",
      "\tspeed: 0.0215s/iter; left time: 289.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542695 Vali Loss: 0.0543380 Test Loss: 0.0567912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0527855\n",
      "\tspeed: 0.0424s/iter; left time: 565.6425s\n",
      "\titers: 200, epoch: 41 | loss: 0.0544314\n",
      "\tspeed: 0.0216s/iter; left time: 285.3730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0542629 Vali Loss: 0.0542896 Test Loss: 0.0567976\n",
      "Validation loss decreased (0.054318 --> 0.054290).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0549833\n",
      "\tspeed: 0.0427s/iter; left time: 560.7264s\n",
      "\titers: 200, epoch: 42 | loss: 0.0532383\n",
      "\tspeed: 0.0215s/iter; left time: 279.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0542868 Vali Loss: 0.0543523 Test Loss: 0.0568203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0568126\n",
      "\tspeed: 0.0421s/iter; left time: 542.6577s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514674\n",
      "\tspeed: 0.0215s/iter; left time: 274.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542430 Vali Loss: 0.0542852 Test Loss: 0.0567927\n",
      "Validation loss decreased (0.054290 --> 0.054285).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0501885\n",
      "\tspeed: 0.0420s/iter; left time: 531.4756s\n",
      "\titers: 200, epoch: 44 | loss: 0.0552518\n",
      "\tspeed: 0.0215s/iter; left time: 270.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542934 Vali Loss: 0.0543582 Test Loss: 0.0568084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0562726\n",
      "\tspeed: 0.0415s/iter; left time: 515.9442s\n",
      "\titers: 200, epoch: 45 | loss: 0.0504332\n",
      "\tspeed: 0.0215s/iter; left time: 264.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542283 Vali Loss: 0.0543477 Test Loss: 0.0567937\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0542384\n",
      "\tspeed: 0.0414s/iter; left time: 506.4311s\n",
      "\titers: 200, epoch: 46 | loss: 0.0558192\n",
      "\tspeed: 0.0215s/iter; left time: 260.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0542461 Vali Loss: 0.0542401 Test Loss: 0.0567593\n",
      "Validation loss decreased (0.054285 --> 0.054240).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0504797\n",
      "\tspeed: 0.0419s/iter; left time: 502.1016s\n",
      "\titers: 200, epoch: 47 | loss: 0.0510444\n",
      "\tspeed: 0.0215s/iter; left time: 255.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0542229 Vali Loss: 0.0542685 Test Loss: 0.0567701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0544625\n",
      "\tspeed: 0.0417s/iter; left time: 490.3522s\n",
      "\titers: 200, epoch: 48 | loss: 0.0507336\n",
      "\tspeed: 0.0215s/iter; left time: 250.7579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0542012 Vali Loss: 0.0542531 Test Loss: 0.0567833\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0530913\n",
      "\tspeed: 0.0416s/iter; left time: 480.1390s\n",
      "\titers: 200, epoch: 49 | loss: 0.0551386\n",
      "\tspeed: 0.0215s/iter; left time: 246.1235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0542225 Vali Loss: 0.0543325 Test Loss: 0.0567598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0575082\n",
      "\tspeed: 0.0414s/iter; left time: 469.1199s\n",
      "\titers: 200, epoch: 50 | loss: 0.0569181\n",
      "\tspeed: 0.0215s/iter; left time: 241.6682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0542435 Vali Loss: 0.0542675 Test Loss: 0.0567403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0515808\n",
      "\tspeed: 0.0416s/iter; left time: 462.1814s\n",
      "\titers: 200, epoch: 51 | loss: 0.0543517\n",
      "\tspeed: 0.0215s/iter; left time: 236.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0541939 Vali Loss: 0.0543161 Test Loss: 0.0567576\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0573124\n",
      "\tspeed: 0.0417s/iter; left time: 453.6181s\n",
      "\titers: 200, epoch: 52 | loss: 0.0572194\n",
      "\tspeed: 0.0215s/iter; left time: 231.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542125 Vali Loss: 0.0542657 Test Loss: 0.0567574\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548075\n",
      "\tspeed: 0.0416s/iter; left time: 443.1604s\n",
      "\titers: 200, epoch: 53 | loss: 0.0537419\n",
      "\tspeed: 0.0215s/iter; left time: 226.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0541289 Vali Loss: 0.0543118 Test Loss: 0.0567842\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0553229\n",
      "\tspeed: 0.0416s/iter; left time: 433.7731s\n",
      "\titers: 200, epoch: 54 | loss: 0.0521511\n",
      "\tspeed: 0.0215s/iter; left time: 222.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0541357 Vali Loss: 0.0542761 Test Loss: 0.0567637\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0553007\n",
      "\tspeed: 0.0413s/iter; left time: 421.0953s\n",
      "\titers: 200, epoch: 55 | loss: 0.0530715\n",
      "\tspeed: 0.0214s/iter; left time: 216.7450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0541912 Vali Loss: 0.0542760 Test Loss: 0.0567585\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0504087\n",
      "\tspeed: 0.0423s/iter; left time: 422.5515s\n",
      "\titers: 200, epoch: 56 | loss: 0.0479576\n",
      "\tspeed: 0.0215s/iter; left time: 212.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0542497 Vali Loss: 0.0543618 Test Loss: 0.0567582\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010097073391079903, rmse:0.10048419237136841, mae:0.056759271770715714, rse:0.3796803057193756\n",
      "Intermediate time for IT and pred_len 24: 00h:12m:19.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1433646\n",
      "\tspeed: 0.0396s/iter; left time: 883.5584s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212559\n",
      "\tspeed: 0.0217s/iter; left time: 482.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.1473529 Vali Loss: 0.1059236 Test Loss: 0.1091757\n",
      "Validation loss decreased (inf --> 0.105924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939879\n",
      "\tspeed: 0.0447s/iter; left time: 986.7471s\n",
      "\titers: 200, epoch: 2 | loss: 0.0863891\n",
      "\tspeed: 0.0218s/iter; left time: 479.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0960089 Vali Loss: 0.0815498 Test Loss: 0.0867262\n",
      "Validation loss decreased (0.105924 --> 0.081550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0871378\n",
      "\tspeed: 0.0454s/iter; left time: 992.8374s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831973\n",
      "\tspeed: 0.0217s/iter; left time: 472.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0850101 Vali Loss: 0.0794443 Test Loss: 0.0841026\n",
      "Validation loss decreased (0.081550 --> 0.079444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0812133\n",
      "\tspeed: 0.0450s/iter; left time: 973.8450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0790372\n",
      "\tspeed: 0.0216s/iter; left time: 464.3268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0823363 Vali Loss: 0.0782349 Test Loss: 0.0829694\n",
      "Validation loss decreased (0.079444 --> 0.078235).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0832534\n",
      "\tspeed: 0.0458s/iter; left time: 979.5085s\n",
      "\titers: 200, epoch: 5 | loss: 0.0769817\n",
      "\tspeed: 0.0215s/iter; left time: 458.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0807391 Vali Loss: 0.0775910 Test Loss: 0.0827967\n",
      "Validation loss decreased (0.078235 --> 0.077591).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808219\n",
      "\tspeed: 0.0448s/iter; left time: 949.2460s\n",
      "\titers: 200, epoch: 6 | loss: 0.0782687\n",
      "\tspeed: 0.0216s/iter; left time: 454.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0796117 Vali Loss: 0.0771666 Test Loss: 0.0820095\n",
      "Validation loss decreased (0.077591 --> 0.077167).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812690\n",
      "\tspeed: 0.0446s/iter; left time: 934.5929s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776338\n",
      "\tspeed: 0.0218s/iter; left time: 453.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788419 Vali Loss: 0.0774109 Test Loss: 0.0818435\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776714\n",
      "\tspeed: 0.0450s/iter; left time: 933.4285s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733576\n",
      "\tspeed: 0.0216s/iter; left time: 445.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0782516 Vali Loss: 0.0767141 Test Loss: 0.0815252\n",
      "Validation loss decreased (0.077167 --> 0.076714).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766985\n",
      "\tspeed: 0.0454s/iter; left time: 930.1062s\n",
      "\titers: 200, epoch: 9 | loss: 0.0736232\n",
      "\tspeed: 0.0217s/iter; left time: 443.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0776290 Vali Loss: 0.0765005 Test Loss: 0.0814253\n",
      "Validation loss decreased (0.076714 --> 0.076500).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748372\n",
      "\tspeed: 0.0465s/iter; left time: 942.5729s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812864\n",
      "\tspeed: 0.0220s/iter; left time: 443.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0771783 Vali Loss: 0.0761293 Test Loss: 0.0814734\n",
      "Validation loss decreased (0.076500 --> 0.076129).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0786125\n",
      "\tspeed: 0.0457s/iter; left time: 916.0055s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764634\n",
      "\tspeed: 0.0217s/iter; left time: 432.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0767350 Vali Loss: 0.0762045 Test Loss: 0.0813731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778665\n",
      "\tspeed: 0.0461s/iter; left time: 914.5062s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785554\n",
      "\tspeed: 0.0219s/iter; left time: 431.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0763418 Vali Loss: 0.0763918 Test Loss: 0.0808504\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0762286\n",
      "\tspeed: 0.0454s/iter; left time: 890.5104s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784456\n",
      "\tspeed: 0.0216s/iter; left time: 421.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0759782 Vali Loss: 0.0761209 Test Loss: 0.0813225\n",
      "Validation loss decreased (0.076129 --> 0.076121).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0739343\n",
      "\tspeed: 0.0459s/iter; left time: 889.8396s\n",
      "\titers: 200, epoch: 14 | loss: 0.0739252\n",
      "\tspeed: 0.0216s/iter; left time: 416.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0757679 Vali Loss: 0.0759335 Test Loss: 0.0811224\n",
      "Validation loss decreased (0.076121 --> 0.075933).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0749016\n",
      "\tspeed: 0.0454s/iter; left time: 870.4722s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770666\n",
      "\tspeed: 0.0217s/iter; left time: 412.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0754548 Vali Loss: 0.0756607 Test Loss: 0.0810303\n",
      "Validation loss decreased (0.075933 --> 0.075661).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0806594\n",
      "\tspeed: 0.0453s/iter; left time: 857.2411s\n",
      "\titers: 200, epoch: 16 | loss: 0.0761695\n",
      "\tspeed: 0.0216s/iter; left time: 406.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0751871 Vali Loss: 0.0757019 Test Loss: 0.0809847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0746581\n",
      "\tspeed: 0.0446s/iter; left time: 834.3823s\n",
      "\titers: 200, epoch: 17 | loss: 0.0754967\n",
      "\tspeed: 0.0218s/iter; left time: 405.2360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0749323 Vali Loss: 0.0758358 Test Loss: 0.0809507\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732008\n",
      "\tspeed: 0.0445s/iter; left time: 823.2419s\n",
      "\titers: 200, epoch: 18 | loss: 0.0779007\n",
      "\tspeed: 0.0216s/iter; left time: 397.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0747036 Vali Loss: 0.0759469 Test Loss: 0.0809412\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0724184\n",
      "\tspeed: 0.0444s/iter; left time: 811.3415s\n",
      "\titers: 200, epoch: 19 | loss: 0.0737137\n",
      "\tspeed: 0.0216s/iter; left time: 391.6548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0745281 Vali Loss: 0.0757514 Test Loss: 0.0808921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718322\n",
      "\tspeed: 0.0444s/iter; left time: 801.2356s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762629\n",
      "\tspeed: 0.0216s/iter; left time: 387.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0743800 Vali Loss: 0.0755283 Test Loss: 0.0808734\n",
      "Validation loss decreased (0.075661 --> 0.075528).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0759146\n",
      "\tspeed: 0.0451s/iter; left time: 803.2794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0684599\n",
      "\tspeed: 0.0215s/iter; left time: 381.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0742292 Vali Loss: 0.0756518 Test Loss: 0.0808270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0738885\n",
      "\tspeed: 0.0440s/iter; left time: 774.9254s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745332\n",
      "\tspeed: 0.0216s/iter; left time: 377.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0740918 Vali Loss: 0.0756381 Test Loss: 0.0808619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729938\n",
      "\tspeed: 0.0443s/iter; left time: 769.2571s\n",
      "\titers: 200, epoch: 23 | loss: 0.0732825\n",
      "\tspeed: 0.0216s/iter; left time: 372.5277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0739742 Vali Loss: 0.0756273 Test Loss: 0.0809168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0743445\n",
      "\tspeed: 0.0443s/iter; left time: 760.3355s\n",
      "\titers: 200, epoch: 24 | loss: 0.0705981\n",
      "\tspeed: 0.0216s/iter; left time: 367.6034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0738092 Vali Loss: 0.0755313 Test Loss: 0.0807313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0738085\n",
      "\tspeed: 0.0440s/iter; left time: 744.3838s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721504\n",
      "\tspeed: 0.0215s/iter; left time: 361.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0737232 Vali Loss: 0.0755362 Test Loss: 0.0807986\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0731233\n",
      "\tspeed: 0.0442s/iter; left time: 738.4531s\n",
      "\titers: 200, epoch: 26 | loss: 0.0758551\n",
      "\tspeed: 0.0215s/iter; left time: 356.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0736521 Vali Loss: 0.0756361 Test Loss: 0.0806783\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0743266\n",
      "\tspeed: 0.0438s/iter; left time: 720.8751s\n",
      "\titers: 200, epoch: 27 | loss: 0.0698974\n",
      "\tspeed: 0.0215s/iter; left time: 352.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0735762 Vali Loss: 0.0754788 Test Loss: 0.0807603\n",
      "Validation loss decreased (0.075528 --> 0.075479).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751837\n",
      "\tspeed: 0.0452s/iter; left time: 734.6244s\n",
      "\titers: 200, epoch: 28 | loss: 0.0731141\n",
      "\tspeed: 0.0217s/iter; left time: 350.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0735002 Vali Loss: 0.0754889 Test Loss: 0.0807897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751689\n",
      "\tspeed: 0.0441s/iter; left time: 706.3757s\n",
      "\titers: 200, epoch: 29 | loss: 0.0736159\n",
      "\tspeed: 0.0216s/iter; left time: 343.3696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0734566 Vali Loss: 0.0755240 Test Loss: 0.0807610\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0738715\n",
      "\tspeed: 0.0441s/iter; left time: 697.2098s\n",
      "\titers: 200, epoch: 30 | loss: 0.0719647\n",
      "\tspeed: 0.0215s/iter; left time: 337.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0733744 Vali Loss: 0.0754651 Test Loss: 0.0807601\n",
      "Validation loss decreased (0.075479 --> 0.075465).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0729038\n",
      "\tspeed: 0.0446s/iter; left time: 694.8872s\n",
      "\titers: 200, epoch: 31 | loss: 0.0689847\n",
      "\tspeed: 0.0215s/iter; left time: 332.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0733588 Vali Loss: 0.0753535 Test Loss: 0.0807255\n",
      "Validation loss decreased (0.075465 --> 0.075353).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745260\n",
      "\tspeed: 0.0449s/iter; left time: 689.1201s\n",
      "\titers: 200, epoch: 32 | loss: 0.0766175\n",
      "\tspeed: 0.0215s/iter; left time: 328.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0733026 Vali Loss: 0.0754213 Test Loss: 0.0807602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0729493\n",
      "\tspeed: 0.0438s/iter; left time: 662.3797s\n",
      "\titers: 200, epoch: 33 | loss: 0.0766584\n",
      "\tspeed: 0.0215s/iter; left time: 323.7146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0732236 Vali Loss: 0.0754487 Test Loss: 0.0807684\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0716890\n",
      "\tspeed: 0.0443s/iter; left time: 660.8058s\n",
      "\titers: 200, epoch: 34 | loss: 0.0735889\n",
      "\tspeed: 0.0216s/iter; left time: 319.4177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0732531 Vali Loss: 0.0754548 Test Loss: 0.0806353\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0696270\n",
      "\tspeed: 0.0449s/iter; left time: 659.7019s\n",
      "\titers: 200, epoch: 35 | loss: 0.0766874\n",
      "\tspeed: 0.0216s/iter; left time: 315.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0731100 Vali Loss: 0.0755045 Test Loss: 0.0807201\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0703087\n",
      "\tspeed: 0.0442s/iter; left time: 638.5704s\n",
      "\titers: 200, epoch: 36 | loss: 0.0714593\n",
      "\tspeed: 0.0216s/iter; left time: 309.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0731055 Vali Loss: 0.0754781 Test Loss: 0.0806610\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0758762\n",
      "\tspeed: 0.0444s/iter; left time: 631.4376s\n",
      "\titers: 200, epoch: 37 | loss: 0.0731670\n",
      "\tspeed: 0.0216s/iter; left time: 305.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0731075 Vali Loss: 0.0754173 Test Loss: 0.0806954\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0697639\n",
      "\tspeed: 0.0441s/iter; left time: 617.8716s\n",
      "\titers: 200, epoch: 38 | loss: 0.0755937\n",
      "\tspeed: 0.0218s/iter; left time: 303.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0731257 Vali Loss: 0.0754439 Test Loss: 0.0806976\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0759557\n",
      "\tspeed: 0.0453s/iter; left time: 624.1583s\n",
      "\titers: 200, epoch: 39 | loss: 0.0707281\n",
      "\tspeed: 0.0216s/iter; left time: 296.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0729984 Vali Loss: 0.0753766 Test Loss: 0.0807144\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0764052\n",
      "\tspeed: 0.0443s/iter; left time: 601.1612s\n",
      "\titers: 200, epoch: 40 | loss: 0.0715780\n",
      "\tspeed: 0.0216s/iter; left time: 290.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0729825 Vali Loss: 0.0754518 Test Loss: 0.0807007\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0715062\n",
      "\tspeed: 0.0439s/iter; left time: 585.4115s\n",
      "\titers: 200, epoch: 41 | loss: 0.0701509\n",
      "\tspeed: 0.0215s/iter; left time: 284.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0730492 Vali Loss: 0.0754098 Test Loss: 0.0807260\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01877465285360813, rmse:0.13702063262462616, mae:0.0807255357503891, rse:0.518089771270752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1459661\n",
      "\tspeed: 0.0238s/iter; left time: 530.4907s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247804\n",
      "\tspeed: 0.0217s/iter; left time: 481.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.1497117 Vali Loss: 0.1045378 Test Loss: 0.1075363\n",
      "Validation loss decreased (inf --> 0.104538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922936\n",
      "\tspeed: 0.0450s/iter; left time: 994.3522s\n",
      "\titers: 200, epoch: 2 | loss: 0.0891406\n",
      "\tspeed: 0.0215s/iter; left time: 473.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0954378 Vali Loss: 0.0816565 Test Loss: 0.0866409\n",
      "Validation loss decreased (0.104538 --> 0.081656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853540\n",
      "\tspeed: 0.0439s/iter; left time: 958.4826s\n",
      "\titers: 200, epoch: 3 | loss: 0.0826844\n",
      "\tspeed: 0.0215s/iter; left time: 467.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0847442 Vali Loss: 0.0796094 Test Loss: 0.0843733\n",
      "Validation loss decreased (0.081656 --> 0.079609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0833012\n",
      "\tspeed: 0.0440s/iter; left time: 950.7788s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823414\n",
      "\tspeed: 0.0215s/iter; left time: 463.4647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0823746 Vali Loss: 0.0784748 Test Loss: 0.0831609\n",
      "Validation loss decreased (0.079609 --> 0.078475).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836823\n",
      "\tspeed: 0.0436s/iter; left time: 933.7550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0796879\n",
      "\tspeed: 0.0215s/iter; left time: 458.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0807883 Vali Loss: 0.0778282 Test Loss: 0.0820207\n",
      "Validation loss decreased (0.078475 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791352\n",
      "\tspeed: 0.0451s/iter; left time: 954.7004s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799545\n",
      "\tspeed: 0.0216s/iter; left time: 454.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0796759 Vali Loss: 0.0770614 Test Loss: 0.0820792\n",
      "Validation loss decreased (0.077828 --> 0.077061).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798625\n",
      "\tspeed: 0.0451s/iter; left time: 944.7145s\n",
      "\titers: 200, epoch: 7 | loss: 0.0812351\n",
      "\tspeed: 0.0216s/iter; left time: 450.1130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0788559 Vali Loss: 0.0769180 Test Loss: 0.0818045\n",
      "Validation loss decreased (0.077061 --> 0.076918).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0809850\n",
      "\tspeed: 0.0448s/iter; left time: 929.5170s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805078\n",
      "\tspeed: 0.0216s/iter; left time: 444.8003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0781953 Vali Loss: 0.0767658 Test Loss: 0.0813461\n",
      "Validation loss decreased (0.076918 --> 0.076766).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0786429\n",
      "\tspeed: 0.0449s/iter; left time: 921.5056s\n",
      "\titers: 200, epoch: 9 | loss: 0.0787557\n",
      "\tspeed: 0.0217s/iter; left time: 442.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0777116 Vali Loss: 0.0766431 Test Loss: 0.0813732\n",
      "Validation loss decreased (0.076766 --> 0.076643).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710135\n",
      "\tspeed: 0.0454s/iter; left time: 921.2600s\n",
      "\titers: 200, epoch: 10 | loss: 0.0788388\n",
      "\tspeed: 0.0216s/iter; left time: 436.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0772423 Vali Loss: 0.0764634 Test Loss: 0.0812182\n",
      "Validation loss decreased (0.076643 --> 0.076463).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754263\n",
      "\tspeed: 0.0450s/iter; left time: 902.1501s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782367\n",
      "\tspeed: 0.0219s/iter; left time: 436.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0767409 Vali Loss: 0.0766913 Test Loss: 0.0811143\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0721509\n",
      "\tspeed: 0.0444s/iter; left time: 879.9076s\n",
      "\titers: 200, epoch: 12 | loss: 0.0761303\n",
      "\tspeed: 0.0217s/iter; left time: 427.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0764047 Vali Loss: 0.0762266 Test Loss: 0.0809278\n",
      "Validation loss decreased (0.076463 --> 0.076227).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0755092\n",
      "\tspeed: 0.0452s/iter; left time: 887.3947s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821566\n",
      "\tspeed: 0.0215s/iter; left time: 419.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0761268 Vali Loss: 0.0763812 Test Loss: 0.0809663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770738\n",
      "\tspeed: 0.0440s/iter; left time: 852.5639s\n",
      "\titers: 200, epoch: 14 | loss: 0.0739617\n",
      "\tspeed: 0.0216s/iter; left time: 417.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0757809 Vali Loss: 0.0760833 Test Loss: 0.0813010\n",
      "Validation loss decreased (0.076227 --> 0.076083).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0753371\n",
      "\tspeed: 0.0467s/iter; left time: 895.2428s\n",
      "\titers: 200, epoch: 15 | loss: 0.0721794\n",
      "\tspeed: 0.0216s/iter; left time: 412.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0754893 Vali Loss: 0.0766485 Test Loss: 0.0808966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0714540\n",
      "\tspeed: 0.0441s/iter; left time: 835.2408s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698306\n",
      "\tspeed: 0.0216s/iter; left time: 407.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0752596 Vali Loss: 0.0760262 Test Loss: 0.0809308\n",
      "Validation loss decreased (0.076083 --> 0.076026).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0736729\n",
      "\tspeed: 0.0452s/iter; left time: 845.4754s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726572\n",
      "\tspeed: 0.0217s/iter; left time: 403.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0750120 Vali Loss: 0.0761923 Test Loss: 0.0809701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0712701\n",
      "\tspeed: 0.0444s/iter; left time: 821.9156s\n",
      "\titers: 200, epoch: 18 | loss: 0.0761875\n",
      "\tspeed: 0.0216s/iter; left time: 397.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0748339 Vali Loss: 0.0759431 Test Loss: 0.0810259\n",
      "Validation loss decreased (0.076026 --> 0.075943).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0756008\n",
      "\tspeed: 0.0448s/iter; left time: 818.3437s\n",
      "\titers: 200, epoch: 19 | loss: 0.0748152\n",
      "\tspeed: 0.0216s/iter; left time: 392.1397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0745641 Vali Loss: 0.0760044 Test Loss: 0.0807937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0730420\n",
      "\tspeed: 0.0441s/iter; left time: 795.3639s\n",
      "\titers: 200, epoch: 20 | loss: 0.0788026\n",
      "\tspeed: 0.0217s/iter; left time: 388.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0744072 Vali Loss: 0.0759645 Test Loss: 0.0807254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724824\n",
      "\tspeed: 0.0442s/iter; left time: 787.9841s\n",
      "\titers: 200, epoch: 21 | loss: 0.0685167\n",
      "\tspeed: 0.0215s/iter; left time: 381.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0742567 Vali Loss: 0.0760825 Test Loss: 0.0808017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0752234\n",
      "\tspeed: 0.0443s/iter; left time: 778.9897s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743604\n",
      "\tspeed: 0.0215s/iter; left time: 376.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0741405 Vali Loss: 0.0760217 Test Loss: 0.0810972\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0794114\n",
      "\tspeed: 0.0442s/iter; left time: 767.4136s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742750\n",
      "\tspeed: 0.0216s/iter; left time: 372.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0739611 Vali Loss: 0.0759342 Test Loss: 0.0811735\n",
      "Validation loss decreased (0.075943 --> 0.075934).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0722461\n",
      "\tspeed: 0.0444s/iter; left time: 761.7404s\n",
      "\titers: 200, epoch: 24 | loss: 0.0766169\n",
      "\tspeed: 0.0216s/iter; left time: 368.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0738680 Vali Loss: 0.0759995 Test Loss: 0.0809578\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0729570\n",
      "\tspeed: 0.0434s/iter; left time: 734.0077s\n",
      "\titers: 200, epoch: 25 | loss: 0.0751325\n",
      "\tspeed: 0.0215s/iter; left time: 361.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0736850 Vali Loss: 0.0759854 Test Loss: 0.0808261\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704323\n",
      "\tspeed: 0.0440s/iter; left time: 735.3478s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739287\n",
      "\tspeed: 0.0216s/iter; left time: 358.1103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0736199 Vali Loss: 0.0759113 Test Loss: 0.0809045\n",
      "Validation loss decreased (0.075934 --> 0.075911).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0719385\n",
      "\tspeed: 0.0445s/iter; left time: 732.8572s\n",
      "\titers: 200, epoch: 27 | loss: 0.0725750\n",
      "\tspeed: 0.0217s/iter; left time: 354.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0735830 Vali Loss: 0.0758279 Test Loss: 0.0809759\n",
      "Validation loss decreased (0.075911 --> 0.075828).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0707296\n",
      "\tspeed: 0.0455s/iter; left time: 739.4164s\n",
      "\titers: 200, epoch: 28 | loss: 0.0734240\n",
      "\tspeed: 0.0217s/iter; left time: 350.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0734927 Vali Loss: 0.0758452 Test Loss: 0.0809245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0731072\n",
      "\tspeed: 0.0449s/iter; left time: 719.7978s\n",
      "\titers: 200, epoch: 29 | loss: 0.0747297\n",
      "\tspeed: 0.0217s/iter; left time: 345.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0734539 Vali Loss: 0.0759566 Test Loss: 0.0809012\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0740424\n",
      "\tspeed: 0.0447s/iter; left time: 706.4403s\n",
      "\titers: 200, epoch: 30 | loss: 0.0736557\n",
      "\tspeed: 0.0217s/iter; left time: 340.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0733408 Vali Loss: 0.0758856 Test Loss: 0.0808438\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0765026\n",
      "\tspeed: 0.0448s/iter; left time: 698.1295s\n",
      "\titers: 200, epoch: 31 | loss: 0.0730270\n",
      "\tspeed: 0.0217s/iter; left time: 336.1496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0733982 Vali Loss: 0.0760393 Test Loss: 0.0810511\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0693656\n",
      "\tspeed: 0.0446s/iter; left time: 684.5233s\n",
      "\titers: 200, epoch: 32 | loss: 0.0756437\n",
      "\tspeed: 0.0216s/iter; left time: 329.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0732387 Vali Loss: 0.0758144 Test Loss: 0.0808302\n",
      "Validation loss decreased (0.075828 --> 0.075814).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0725168\n",
      "\tspeed: 0.0445s/iter; left time: 673.6662s\n",
      "\titers: 200, epoch: 33 | loss: 0.0727527\n",
      "\tspeed: 0.0217s/iter; left time: 326.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0732370 Vali Loss: 0.0758342 Test Loss: 0.0808924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0726183\n",
      "\tspeed: 0.0443s/iter; left time: 660.5687s\n",
      "\titers: 200, epoch: 34 | loss: 0.0718975\n",
      "\tspeed: 0.0215s/iter; left time: 318.6039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0731928 Vali Loss: 0.0758730 Test Loss: 0.0809621\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732121\n",
      "\tspeed: 0.0443s/iter; left time: 649.8964s\n",
      "\titers: 200, epoch: 35 | loss: 0.0792854\n",
      "\tspeed: 0.0215s/iter; left time: 313.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0731534 Vali Loss: 0.0758523 Test Loss: 0.0808746\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0767604\n",
      "\tspeed: 0.0447s/iter; left time: 646.5360s\n",
      "\titers: 200, epoch: 36 | loss: 0.0714889\n",
      "\tspeed: 0.0216s/iter; left time: 310.0072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0731052 Vali Loss: 0.0759114 Test Loss: 0.0809736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0725162\n",
      "\tspeed: 0.0446s/iter; left time: 635.6777s\n",
      "\titers: 200, epoch: 37 | loss: 0.0772842\n",
      "\tspeed: 0.0216s/iter; left time: 304.9747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0730758 Vali Loss: 0.0759069 Test Loss: 0.0809573\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0702892\n",
      "\tspeed: 0.0442s/iter; left time: 619.5411s\n",
      "\titers: 200, epoch: 38 | loss: 0.0715920\n",
      "\tspeed: 0.0216s/iter; left time: 300.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0730808 Vali Loss: 0.0759352 Test Loss: 0.0809955\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0763620\n",
      "\tspeed: 0.0443s/iter; left time: 610.4583s\n",
      "\titers: 200, epoch: 39 | loss: 0.0723274\n",
      "\tspeed: 0.0216s/iter; left time: 295.1773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0730353 Vali Loss: 0.0758699 Test Loss: 0.0809455\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0750282\n",
      "\tspeed: 0.0440s/iter; left time: 596.3260s\n",
      "\titers: 200, epoch: 40 | loss: 0.0713875\n",
      "\tspeed: 0.0215s/iter; left time: 289.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0730155 Vali Loss: 0.0758716 Test Loss: 0.0809301\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0756813\n",
      "\tspeed: 0.0441s/iter; left time: 588.3404s\n",
      "\titers: 200, epoch: 41 | loss: 0.0719113\n",
      "\tspeed: 0.0216s/iter; left time: 285.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0730196 Vali Loss: 0.0758215 Test Loss: 0.0809334\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682350\n",
      "\tspeed: 0.0457s/iter; left time: 599.4794s\n",
      "\titers: 200, epoch: 42 | loss: 0.0718109\n",
      "\tspeed: 0.0217s/iter; left time: 282.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0729887 Vali Loss: 0.0758464 Test Loss: 0.0808992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018875500187277794, rmse:0.13738813996315002, mae:0.0808301791548729, rse:0.5194793939590454\n",
      "Intermediate time for IT and pred_len 96: 00h:09m:19.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1422332\n",
      "\tspeed: 0.0399s/iter; left time: 886.8707s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238884\n",
      "\tspeed: 0.0219s/iter; left time: 483.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.1487401 Vali Loss: 0.1078035 Test Loss: 0.1103905\n",
      "Validation loss decreased (inf --> 0.107803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0940611\n",
      "\tspeed: 0.0454s/iter; left time: 998.2888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0890768\n",
      "\tspeed: 0.0219s/iter; left time: 478.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0993934 Vali Loss: 0.0859923 Test Loss: 0.0905826\n",
      "Validation loss decreased (0.107803 --> 0.085992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0923032\n",
      "\tspeed: 0.0459s/iter; left time: 997.6045s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874902\n",
      "\tspeed: 0.0237s/iter; left time: 513.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0890220 Vali Loss: 0.0842793 Test Loss: 0.0879501\n",
      "Validation loss decreased (0.085992 --> 0.084279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0876270\n",
      "\tspeed: 0.0458s/iter; left time: 985.8983s\n",
      "\titers: 200, epoch: 4 | loss: 0.0905795\n",
      "\tspeed: 0.0219s/iter; left time: 469.1330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0863606 Vali Loss: 0.0836341 Test Loss: 0.0876986\n",
      "Validation loss decreased (0.084279 --> 0.083634).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825929\n",
      "\tspeed: 0.0456s/iter; left time: 972.3481s\n",
      "\titers: 200, epoch: 5 | loss: 0.0831351\n",
      "\tspeed: 0.0220s/iter; left time: 465.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0848012 Vali Loss: 0.0826763 Test Loss: 0.0874410\n",
      "Validation loss decreased (0.083634 --> 0.082676).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816155\n",
      "\tspeed: 0.0463s/iter; left time: 977.2034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0854807\n",
      "\tspeed: 0.0218s/iter; left time: 457.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0836772 Vali Loss: 0.0822454 Test Loss: 0.0871060\n",
      "Validation loss decreased (0.082676 --> 0.082245).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834205\n",
      "\tspeed: 0.0473s/iter; left time: 987.2922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0846652\n",
      "\tspeed: 0.0221s/iter; left time: 458.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827792 Vali Loss: 0.0820543 Test Loss: 0.0869830\n",
      "Validation loss decreased (0.082245 --> 0.082054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0821114\n",
      "\tspeed: 0.0456s/iter; left time: 940.2727s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795568\n",
      "\tspeed: 0.0221s/iter; left time: 453.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0820239 Vali Loss: 0.0822160 Test Loss: 0.0872677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0793278\n",
      "\tspeed: 0.0458s/iter; left time: 935.4193s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779528\n",
      "\tspeed: 0.0220s/iter; left time: 447.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0814570 Vali Loss: 0.0815587 Test Loss: 0.0868244\n",
      "Validation loss decreased (0.082054 --> 0.081559).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0797524\n",
      "\tspeed: 0.0465s/iter; left time: 938.7565s\n",
      "\titers: 200, epoch: 10 | loss: 0.0822584\n",
      "\tspeed: 0.0220s/iter; left time: 442.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0809885 Vali Loss: 0.0817687 Test Loss: 0.0867201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819538\n",
      "\tspeed: 0.0453s/iter; left time: 904.9837s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759394\n",
      "\tspeed: 0.0220s/iter; left time: 437.3079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0805481 Vali Loss: 0.0817018 Test Loss: 0.0869889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0789934\n",
      "\tspeed: 0.0452s/iter; left time: 893.5277s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801707\n",
      "\tspeed: 0.0219s/iter; left time: 430.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0801772 Vali Loss: 0.0817279 Test Loss: 0.0872964\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0786303\n",
      "\tspeed: 0.0449s/iter; left time: 876.7168s\n",
      "\titers: 200, epoch: 13 | loss: 0.0803329\n",
      "\tspeed: 0.0219s/iter; left time: 425.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0798334 Vali Loss: 0.0814555 Test Loss: 0.0870952\n",
      "Validation loss decreased (0.081559 --> 0.081455).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0780716\n",
      "\tspeed: 0.0458s/iter; left time: 884.1649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795619\n",
      "\tspeed: 0.0220s/iter; left time: 421.4865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0794957 Vali Loss: 0.0816452 Test Loss: 0.0867981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0795415\n",
      "\tspeed: 0.0450s/iter; left time: 858.0287s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837863\n",
      "\tspeed: 0.0219s/iter; left time: 414.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0792260 Vali Loss: 0.0814669 Test Loss: 0.0866738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800886\n",
      "\tspeed: 0.0447s/iter; left time: 841.9538s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797749\n",
      "\tspeed: 0.0218s/iter; left time: 409.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0790012 Vali Loss: 0.0815702 Test Loss: 0.0869253\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0799048\n",
      "\tspeed: 0.0444s/iter; left time: 828.0382s\n",
      "\titers: 200, epoch: 17 | loss: 0.0763827\n",
      "\tspeed: 0.0220s/iter; left time: 407.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0787813 Vali Loss: 0.0814374 Test Loss: 0.0867984\n",
      "Validation loss decreased (0.081455 --> 0.081437).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0748992\n",
      "\tspeed: 0.0459s/iter; left time: 844.7253s\n",
      "\titers: 200, epoch: 18 | loss: 0.0801806\n",
      "\tspeed: 0.0220s/iter; left time: 402.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0785796 Vali Loss: 0.0816491 Test Loss: 0.0868996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0780893\n",
      "\tspeed: 0.0453s/iter; left time: 824.0955s\n",
      "\titers: 200, epoch: 19 | loss: 0.0778928\n",
      "\tspeed: 0.0219s/iter; left time: 396.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0783676 Vali Loss: 0.0812692 Test Loss: 0.0866233\n",
      "Validation loss decreased (0.081437 --> 0.081269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0799072\n",
      "\tspeed: 0.0459s/iter; left time: 824.4706s\n",
      "\titers: 200, epoch: 20 | loss: 0.0745044\n",
      "\tspeed: 0.0220s/iter; left time: 393.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0780941 Vali Loss: 0.0815039 Test Loss: 0.0868427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801952\n",
      "\tspeed: 0.0448s/iter; left time: 794.7760s\n",
      "\titers: 200, epoch: 21 | loss: 0.0782417\n",
      "\tspeed: 0.0220s/iter; left time: 388.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0779266 Vali Loss: 0.0813523 Test Loss: 0.0868977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0801301\n",
      "\tspeed: 0.0447s/iter; left time: 782.8674s\n",
      "\titers: 200, epoch: 22 | loss: 0.0788175\n",
      "\tspeed: 0.0219s/iter; left time: 381.9170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0777915 Vali Loss: 0.0812905 Test Loss: 0.0869912\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740311\n",
      "\tspeed: 0.0447s/iter; left time: 773.8720s\n",
      "\titers: 200, epoch: 23 | loss: 0.0786226\n",
      "\tspeed: 0.0220s/iter; left time: 378.5962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0777073 Vali Loss: 0.0813419 Test Loss: 0.0869643\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0794018\n",
      "\tspeed: 0.0445s/iter; left time: 760.4558s\n",
      "\titers: 200, epoch: 24 | loss: 0.0760033\n",
      "\tspeed: 0.0220s/iter; left time: 373.6216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0775662 Vali Loss: 0.0813689 Test Loss: 0.0866420\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0771687\n",
      "\tspeed: 0.0445s/iter; left time: 750.2550s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770259\n",
      "\tspeed: 0.0219s/iter; left time: 367.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0774627 Vali Loss: 0.0812513 Test Loss: 0.0867676\n",
      "Validation loss decreased (0.081269 --> 0.081251).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0801990\n",
      "\tspeed: 0.0474s/iter; left time: 788.5953s\n",
      "\titers: 200, epoch: 26 | loss: 0.0770016\n",
      "\tspeed: 0.0220s/iter; left time: 363.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0772641 Vali Loss: 0.0813442 Test Loss: 0.0867389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0746478\n",
      "\tspeed: 0.0451s/iter; left time: 739.3783s\n",
      "\titers: 200, epoch: 27 | loss: 0.0811946\n",
      "\tspeed: 0.0220s/iter; left time: 358.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0771851 Vali Loss: 0.0813397 Test Loss: 0.0868592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0765276\n",
      "\tspeed: 0.0449s/iter; left time: 726.9303s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778756\n",
      "\tspeed: 0.0222s/iter; left time: 357.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0771561 Vali Loss: 0.0812759 Test Loss: 0.0867207\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0758748\n",
      "\tspeed: 0.0447s/iter; left time: 712.9911s\n",
      "\titers: 200, epoch: 29 | loss: 0.0761895\n",
      "\tspeed: 0.0219s/iter; left time: 347.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0770699 Vali Loss: 0.0811767 Test Loss: 0.0867977\n",
      "Validation loss decreased (0.081251 --> 0.081177).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0772767\n",
      "\tspeed: 0.0451s/iter; left time: 709.5823s\n",
      "\titers: 200, epoch: 30 | loss: 0.0799395\n",
      "\tspeed: 0.0219s/iter; left time: 342.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0770043 Vali Loss: 0.0813326 Test Loss: 0.0865817\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0787377\n",
      "\tspeed: 0.0459s/iter; left time: 711.6382s\n",
      "\titers: 200, epoch: 31 | loss: 0.0790349\n",
      "\tspeed: 0.0219s/iter; left time: 337.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0769014 Vali Loss: 0.0812479 Test Loss: 0.0867099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0753271\n",
      "\tspeed: 0.0443s/iter; left time: 677.0274s\n",
      "\titers: 200, epoch: 32 | loss: 0.0772528\n",
      "\tspeed: 0.0219s/iter; left time: 333.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0768442 Vali Loss: 0.0812564 Test Loss: 0.0866655\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0767389\n",
      "\tspeed: 0.0446s/iter; left time: 672.2992s\n",
      "\titers: 200, epoch: 33 | loss: 0.0774172\n",
      "\tspeed: 0.0219s/iter; left time: 328.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0767227 Vali Loss: 0.0813379 Test Loss: 0.0866511\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754764\n",
      "\tspeed: 0.0442s/iter; left time: 655.3952s\n",
      "\titers: 200, epoch: 34 | loss: 0.0783910\n",
      "\tspeed: 0.0219s/iter; left time: 322.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0767627 Vali Loss: 0.0813302 Test Loss: 0.0867717\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0773165\n",
      "\tspeed: 0.0438s/iter; left time: 639.9556s\n",
      "\titers: 200, epoch: 35 | loss: 0.0745113\n",
      "\tspeed: 0.0219s/iter; left time: 318.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0767981 Vali Loss: 0.0813389 Test Loss: 0.0866733\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0755355\n",
      "\tspeed: 0.0438s/iter; left time: 629.9587s\n",
      "\titers: 200, epoch: 36 | loss: 0.0780581\n",
      "\tspeed: 0.0219s/iter; left time: 312.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0767315 Vali Loss: 0.0813711 Test Loss: 0.0866041\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0764991\n",
      "\tspeed: 0.0449s/iter; left time: 636.6586s\n",
      "\titers: 200, epoch: 37 | loss: 0.0770552\n",
      "\tspeed: 0.0218s/iter; left time: 307.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0767122 Vali Loss: 0.0813273 Test Loss: 0.0865649\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0769197\n",
      "\tspeed: 0.0441s/iter; left time: 614.9343s\n",
      "\titers: 200, epoch: 38 | loss: 0.0761648\n",
      "\tspeed: 0.0220s/iter; left time: 304.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0765907 Vali Loss: 0.0812972 Test Loss: 0.0866962\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0768745\n",
      "\tspeed: 0.0440s/iter; left time: 603.7136s\n",
      "\titers: 200, epoch: 39 | loss: 0.0779365\n",
      "\tspeed: 0.0218s/iter; left time: 297.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0765878 Vali Loss: 0.0812177 Test Loss: 0.0865234\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02091139554977417, rmse:0.14460772275924683, mae:0.08679766952991486, rse:0.5472854971885681\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1444802\n",
      "\tspeed: 0.0241s/iter; left time: 535.4018s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274032\n",
      "\tspeed: 0.0221s/iter; left time: 489.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1514145 Vali Loss: 0.1083492 Test Loss: 0.1111078\n",
      "Validation loss decreased (inf --> 0.108349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0961300\n",
      "\tspeed: 0.0452s/iter; left time: 994.0226s\n",
      "\titers: 200, epoch: 2 | loss: 0.0944361\n",
      "\tspeed: 0.0221s/iter; left time: 483.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0995450 Vali Loss: 0.0859833 Test Loss: 0.0903506\n",
      "Validation loss decreased (0.108349 --> 0.085983).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907044\n",
      "\tspeed: 0.0451s/iter; left time: 981.6929s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892267\n",
      "\tspeed: 0.0219s/iter; left time: 473.2063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0890871 Vali Loss: 0.0844950 Test Loss: 0.0889018\n",
      "Validation loss decreased (0.085983 --> 0.084495).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0917593\n",
      "\tspeed: 0.0441s/iter; left time: 949.8181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0846317\n",
      "\tspeed: 0.0219s/iter; left time: 468.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0866461 Vali Loss: 0.0837718 Test Loss: 0.0880020\n",
      "Validation loss decreased (0.084495 --> 0.083772).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0876566\n",
      "\tspeed: 0.0447s/iter; left time: 952.4333s\n",
      "\titers: 200, epoch: 5 | loss: 0.0873978\n",
      "\tspeed: 0.0219s/iter; left time: 463.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0851161 Vali Loss: 0.0829871 Test Loss: 0.0874617\n",
      "Validation loss decreased (0.083772 --> 0.082987).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838045\n",
      "\tspeed: 0.0454s/iter; left time: 957.7707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822688\n",
      "\tspeed: 0.0219s/iter; left time: 459.2941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0838960 Vali Loss: 0.0824548 Test Loss: 0.0872725\n",
      "Validation loss decreased (0.082987 --> 0.082455).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0808098\n",
      "\tspeed: 0.0438s/iter; left time: 913.7085s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848828\n",
      "\tspeed: 0.0218s/iter; left time: 453.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0829809 Vali Loss: 0.0823142 Test Loss: 0.0876282\n",
      "Validation loss decreased (0.082455 --> 0.082314).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803695\n",
      "\tspeed: 0.0448s/iter; left time: 925.1910s\n",
      "\titers: 200, epoch: 8 | loss: 0.0818768\n",
      "\tspeed: 0.0218s/iter; left time: 448.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0822305 Vali Loss: 0.0820228 Test Loss: 0.0876478\n",
      "Validation loss decreased (0.082314 --> 0.082023).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808091\n",
      "\tspeed: 0.0456s/iter; left time: 930.3121s\n",
      "\titers: 200, epoch: 9 | loss: 0.0799001\n",
      "\tspeed: 0.0219s/iter; left time: 445.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0816215 Vali Loss: 0.0818808 Test Loss: 0.0880365\n",
      "Validation loss decreased (0.082023 --> 0.081881).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0800510\n",
      "\tspeed: 0.0455s/iter; left time: 918.6607s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785952\n",
      "\tspeed: 0.0221s/iter; left time: 444.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0809574 Vali Loss: 0.0814812 Test Loss: 0.0875988\n",
      "Validation loss decreased (0.081881 --> 0.081481).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783685\n",
      "\tspeed: 0.0446s/iter; left time: 891.5125s\n",
      "\titers: 200, epoch: 11 | loss: 0.0788870\n",
      "\tspeed: 0.0219s/iter; left time: 434.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0805099 Vali Loss: 0.0819037 Test Loss: 0.0877739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0827774\n",
      "\tspeed: 0.0436s/iter; left time: 860.1043s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778639\n",
      "\tspeed: 0.0221s/iter; left time: 433.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0800791 Vali Loss: 0.0813280 Test Loss: 0.0874974\n",
      "Validation loss decreased (0.081481 --> 0.081328).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0845484\n",
      "\tspeed: 0.0449s/iter; left time: 876.4750s\n",
      "\titers: 200, epoch: 13 | loss: 0.0799853\n",
      "\tspeed: 0.0219s/iter; left time: 424.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0797862 Vali Loss: 0.0816054 Test Loss: 0.0877575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0744464\n",
      "\tspeed: 0.0436s/iter; left time: 840.9424s\n",
      "\titers: 200, epoch: 14 | loss: 0.0774216\n",
      "\tspeed: 0.0219s/iter; left time: 420.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0794795 Vali Loss: 0.0813056 Test Loss: 0.0879064\n",
      "Validation loss decreased (0.081328 --> 0.081306).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0788057\n",
      "\tspeed: 0.0447s/iter; left time: 852.6139s\n",
      "\titers: 200, epoch: 15 | loss: 0.0765797\n",
      "\tspeed: 0.0218s/iter; left time: 414.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0791673 Vali Loss: 0.0811152 Test Loss: 0.0876386\n",
      "Validation loss decreased (0.081306 --> 0.081115).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0807921\n",
      "\tspeed: 0.0450s/iter; left time: 849.1001s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774815\n",
      "\tspeed: 0.0222s/iter; left time: 416.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0789532 Vali Loss: 0.0814593 Test Loss: 0.0876136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0804251\n",
      "\tspeed: 0.0456s/iter; left time: 848.9204s\n",
      "\titers: 200, epoch: 17 | loss: 0.0788879\n",
      "\tspeed: 0.0222s/iter; left time: 412.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0786518 Vali Loss: 0.0810290 Test Loss: 0.0878293\n",
      "Validation loss decreased (0.081115 --> 0.081029).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0764076\n",
      "\tspeed: 0.0448s/iter; left time: 824.6721s\n",
      "\titers: 200, epoch: 18 | loss: 0.0798518\n",
      "\tspeed: 0.0234s/iter; left time: 428.9303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0784339 Vali Loss: 0.0813855 Test Loss: 0.0877684\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0794611\n",
      "\tspeed: 0.0441s/iter; left time: 802.4188s\n",
      "\titers: 200, epoch: 19 | loss: 0.0837121\n",
      "\tspeed: 0.0219s/iter; left time: 396.3212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0782367 Vali Loss: 0.0811109 Test Loss: 0.0873743\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0762909\n",
      "\tspeed: 0.0444s/iter; left time: 798.4217s\n",
      "\titers: 200, epoch: 20 | loss: 0.0755530\n",
      "\tspeed: 0.0220s/iter; left time: 392.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0780520 Vali Loss: 0.0808757 Test Loss: 0.0875620\n",
      "Validation loss decreased (0.081029 --> 0.080876).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0770825\n",
      "\tspeed: 0.0461s/iter; left time: 817.8213s\n",
      "\titers: 200, epoch: 21 | loss: 0.0790791\n",
      "\tspeed: 0.0221s/iter; left time: 389.9578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0779281 Vali Loss: 0.0809141 Test Loss: 0.0877328\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0814656\n",
      "\tspeed: 0.0444s/iter; left time: 777.7307s\n",
      "\titers: 200, epoch: 22 | loss: 0.0752154\n",
      "\tspeed: 0.0219s/iter; left time: 381.4119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0777684 Vali Loss: 0.0808672 Test Loss: 0.0874537\n",
      "Validation loss decreased (0.080876 --> 0.080867).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0779211\n",
      "\tspeed: 0.0452s/iter; left time: 781.5449s\n",
      "\titers: 200, epoch: 23 | loss: 0.0796038\n",
      "\tspeed: 0.0220s/iter; left time: 378.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0776365 Vali Loss: 0.0809816 Test Loss: 0.0873867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0783439\n",
      "\tspeed: 0.0448s/iter; left time: 765.5439s\n",
      "\titers: 200, epoch: 24 | loss: 0.0807758\n",
      "\tspeed: 0.0219s/iter; left time: 372.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0774527 Vali Loss: 0.0811040 Test Loss: 0.0876076\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785841\n",
      "\tspeed: 0.0441s/iter; left time: 743.5228s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787244\n",
      "\tspeed: 0.0219s/iter; left time: 366.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0773704 Vali Loss: 0.0811864 Test Loss: 0.0875936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0794276\n",
      "\tspeed: 0.0444s/iter; left time: 738.7969s\n",
      "\titers: 200, epoch: 26 | loss: 0.0776701\n",
      "\tspeed: 0.0219s/iter; left time: 362.1007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0773006 Vali Loss: 0.0809925 Test Loss: 0.0875052\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0782279\n",
      "\tspeed: 0.0442s/iter; left time: 725.4448s\n",
      "\titers: 200, epoch: 27 | loss: 0.0763521\n",
      "\tspeed: 0.0219s/iter; left time: 357.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0772246 Vali Loss: 0.0810984 Test Loss: 0.0875920\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0755223\n",
      "\tspeed: 0.0438s/iter; left time: 709.3821s\n",
      "\titers: 200, epoch: 28 | loss: 0.0771596\n",
      "\tspeed: 0.0219s/iter; left time: 351.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0770989 Vali Loss: 0.0811485 Test Loss: 0.0874630\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0731708\n",
      "\tspeed: 0.0437s/iter; left time: 696.9609s\n",
      "\titers: 200, epoch: 29 | loss: 0.0795308\n",
      "\tspeed: 0.0219s/iter; left time: 347.3375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0770529 Vali Loss: 0.0810510 Test Loss: 0.0875364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0786274\n",
      "\tspeed: 0.0446s/iter; left time: 701.9616s\n",
      "\titers: 200, epoch: 30 | loss: 0.0785061\n",
      "\tspeed: 0.0219s/iter; left time: 342.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0769746 Vali Loss: 0.0807405 Test Loss: 0.0872839\n",
      "Validation loss decreased (0.080867 --> 0.080740).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808271\n",
      "\tspeed: 0.0451s/iter; left time: 699.4594s\n",
      "\titers: 200, epoch: 31 | loss: 0.0768587\n",
      "\tspeed: 0.0219s/iter; left time: 337.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0768951 Vali Loss: 0.0808292 Test Loss: 0.0875573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0766787\n",
      "\tspeed: 0.0441s/iter; left time: 674.3648s\n",
      "\titers: 200, epoch: 32 | loss: 0.0756252\n",
      "\tspeed: 0.0219s/iter; left time: 332.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0769027 Vali Loss: 0.0808887 Test Loss: 0.0874944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0792284\n",
      "\tspeed: 0.0452s/iter; left time: 680.9605s\n",
      "\titers: 200, epoch: 33 | loss: 0.0765715\n",
      "\tspeed: 0.0221s/iter; left time: 330.3268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0768116 Vali Loss: 0.0809315 Test Loss: 0.0875360\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0758336\n",
      "\tspeed: 0.0443s/iter; left time: 657.1175s\n",
      "\titers: 200, epoch: 34 | loss: 0.0781302\n",
      "\tspeed: 0.0219s/iter; left time: 322.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0767849 Vali Loss: 0.0809789 Test Loss: 0.0873896\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0783587\n",
      "\tspeed: 0.0449s/iter; left time: 656.8868s\n",
      "\titers: 200, epoch: 35 | loss: 0.0773312\n",
      "\tspeed: 0.0219s/iter; left time: 317.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0767631 Vali Loss: 0.0808629 Test Loss: 0.0875003\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0750958\n",
      "\tspeed: 0.0448s/iter; left time: 645.2777s\n",
      "\titers: 200, epoch: 36 | loss: 0.0749962\n",
      "\tspeed: 0.0219s/iter; left time: 312.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0766440 Vali Loss: 0.0809243 Test Loss: 0.0875456\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0753721\n",
      "\tspeed: 0.0448s/iter; left time: 635.1870s\n",
      "\titers: 200, epoch: 37 | loss: 0.0806005\n",
      "\tspeed: 0.0219s/iter; left time: 307.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0765910 Vali Loss: 0.0810046 Test Loss: 0.0874726\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0762249\n",
      "\tspeed: 0.0452s/iter; left time: 631.2253s\n",
      "\titers: 200, epoch: 38 | loss: 0.0791740\n",
      "\tspeed: 0.0219s/iter; left time: 303.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0765436 Vali Loss: 0.0810213 Test Loss: 0.0875532\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0809940\n",
      "\tspeed: 0.0451s/iter; left time: 619.1145s\n",
      "\titers: 200, epoch: 39 | loss: 0.0743899\n",
      "\tspeed: 0.0219s/iter; left time: 299.0953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0765826 Vali Loss: 0.0808245 Test Loss: 0.0874972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0759105\n",
      "\tspeed: 0.0447s/iter; left time: 603.4081s\n",
      "\titers: 200, epoch: 40 | loss: 0.0807009\n",
      "\tspeed: 0.0222s/iter; left time: 297.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0765790 Vali Loss: 0.0809569 Test Loss: 0.0876428\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020960209891200066, rmse:0.14477641880512238, mae:0.08728384971618652, rse:0.5479239225387573\n",
      "Intermediate time for IT and pred_len 168: 00h:09m:00.38s\n",
      "Intermediate time for IT: 00h:30m:38.90s\n",
      "Total time: 02h:24m:05.06s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.0593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.0804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.0995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0209  0.1447  0.0877\n",
       "        96            0.0376  0.1940  0.1282\n",
       "        168           0.0393  0.1983  0.1340\n",
       "ES      24            0.0098  0.0989  0.0593\n",
       "        96            0.0186  0.1365  0.0865\n",
       "        168           0.0209  0.1445  0.0922\n",
       "FR      24            0.0100  0.0998  0.0548\n",
       "        96            0.0192  0.1384  0.0804\n",
       "        168           0.0215  0.1465  0.0872\n",
       "GB      24            0.0249  0.1577  0.0995\n",
       "        96            0.0417  0.2041  0.1395\n",
       "        168           0.0447  0.2115  0.1468\n",
       "IT      24            0.0101  0.1004  0.0567\n",
       "        96            0.0188  0.1372  0.0808\n",
       "        168           0.0209  0.1447  0.0870"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1332144\n",
      "\tspeed: 0.0739s/iter; left time: 1641.4667s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229960\n",
      "\tspeed: 0.0557s/iter; left time: 1231.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 223 | Train Loss: 0.1358273 Vali Loss: 0.1260563 Test Loss: 0.1311544\n",
      "Validation loss decreased (inf --> 0.126056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0868122\n",
      "\tspeed: 0.0981s/iter; left time: 2155.1823s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820302\n",
      "\tspeed: 0.0557s/iter; left time: 1218.1033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0882056 Vali Loss: 0.0927888 Test Loss: 0.0949692\n",
      "Validation loss decreased (0.126056 --> 0.092789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0753110\n",
      "\tspeed: 0.0970s/iter; left time: 2110.9623s\n",
      "\titers: 200, epoch: 3 | loss: 0.0757236\n",
      "\tspeed: 0.0557s/iter; left time: 1205.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0788444 Vali Loss: 0.0894453 Test Loss: 0.0920496\n",
      "Validation loss decreased (0.092789 --> 0.089445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0791433\n",
      "\tspeed: 0.0980s/iter; left time: 2109.3909s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825152\n",
      "\tspeed: 0.0560s/iter; left time: 1199.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0767609 Vali Loss: 0.0887320 Test Loss: 0.0910566\n",
      "Validation loss decreased (0.089445 --> 0.088732).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760196\n",
      "\tspeed: 0.1003s/iter; left time: 2136.6525s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715352\n",
      "\tspeed: 0.0557s/iter; left time: 1180.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0754450 Vali Loss: 0.0889264 Test Loss: 0.0909010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798182\n",
      "\tspeed: 0.0978s/iter; left time: 2061.9008s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760352\n",
      "\tspeed: 0.0559s/iter; left time: 1172.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0743708 Vali Loss: 0.0882881 Test Loss: 0.0898762\n",
      "Validation loss decreased (0.088732 --> 0.088288).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732908\n",
      "\tspeed: 0.0976s/iter; left time: 2036.5197s\n",
      "\titers: 200, epoch: 7 | loss: 0.0716462\n",
      "\tspeed: 0.0558s/iter; left time: 1157.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0736464 Vali Loss: 0.0883676 Test Loss: 0.0901687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711929\n",
      "\tspeed: 0.0975s/iter; left time: 2012.4290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738796\n",
      "\tspeed: 0.0557s/iter; left time: 1144.0460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0730284 Vali Loss: 0.0872638 Test Loss: 0.0893016\n",
      "Validation loss decreased (0.088288 --> 0.087264).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718604\n",
      "\tspeed: 0.0974s/iter; left time: 1989.0109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724918\n",
      "\tspeed: 0.0557s/iter; left time: 1131.3802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0724477 Vali Loss: 0.0873610 Test Loss: 0.0892784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735393\n",
      "\tspeed: 0.0977s/iter; left time: 1973.5957s\n",
      "\titers: 200, epoch: 10 | loss: 0.0687648\n",
      "\tspeed: 0.0557s/iter; left time: 1119.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0722126 Vali Loss: 0.0868895 Test Loss: 0.0890840\n",
      "Validation loss decreased (0.087264 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0741503\n",
      "\tspeed: 0.0977s/iter; left time: 1950.5542s\n",
      "\titers: 200, epoch: 11 | loss: 0.0751265\n",
      "\tspeed: 0.0556s/iter; left time: 1105.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0719460 Vali Loss: 0.0867828 Test Loss: 0.0886687\n",
      "Validation loss decreased (0.086889 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0688678\n",
      "\tspeed: 0.0969s/iter; left time: 1913.2028s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754033\n",
      "\tspeed: 0.0558s/iter; left time: 1095.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0716845 Vali Loss: 0.0863442 Test Loss: 0.0887282\n",
      "Validation loss decreased (0.086783 --> 0.086344).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0660991\n",
      "\tspeed: 0.0971s/iter; left time: 1896.2582s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696966\n",
      "\tspeed: 0.0557s/iter; left time: 1082.7238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0713887 Vali Loss: 0.0863370 Test Loss: 0.0882716\n",
      "Validation loss decreased (0.086344 --> 0.086337).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0725164\n",
      "\tspeed: 0.0976s/iter; left time: 1884.3073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0659105\n",
      "\tspeed: 0.0556s/iter; left time: 1068.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0712591 Vali Loss: 0.0863522 Test Loss: 0.0883677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713117\n",
      "\tspeed: 0.0970s/iter; left time: 1851.5268s\n",
      "\titers: 200, epoch: 15 | loss: 0.0666008\n",
      "\tspeed: 0.0558s/iter; left time: 1058.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0710470 Vali Loss: 0.0864777 Test Loss: 0.0887146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0738203\n",
      "\tspeed: 0.0974s/iter; left time: 1836.1377s\n",
      "\titers: 200, epoch: 16 | loss: 0.0769220\n",
      "\tspeed: 0.0557s/iter; left time: 1045.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0708745 Vali Loss: 0.0861809 Test Loss: 0.0884529\n",
      "Validation loss decreased (0.086337 --> 0.086181).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0708035\n",
      "\tspeed: 0.0988s/iter; left time: 1841.3885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0764474\n",
      "\tspeed: 0.0557s/iter; left time: 1032.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0707748 Vali Loss: 0.0861680 Test Loss: 0.0882925\n",
      "Validation loss decreased (0.086181 --> 0.086168).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0686066\n",
      "\tspeed: 0.0977s/iter; left time: 1797.7864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0637440\n",
      "\tspeed: 0.0557s/iter; left time: 1019.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0705734 Vali Loss: 0.0859288 Test Loss: 0.0882091\n",
      "Validation loss decreased (0.086168 --> 0.085929).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716321\n",
      "\tspeed: 0.0975s/iter; left time: 1773.7313s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779866\n",
      "\tspeed: 0.0557s/iter; left time: 1007.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.59s\n",
      "Steps: 223 | Train Loss: 0.0705458 Vali Loss: 0.0859715 Test Loss: 0.0881990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0711506\n",
      "\tspeed: 0.1971s/iter; left time: 3541.5114s\n",
      "\titers: 200, epoch: 20 | loss: 0.0688243\n",
      "\tspeed: 0.0586s/iter; left time: 1046.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 223 | Train Loss: 0.0704459 Vali Loss: 0.0860364 Test Loss: 0.0881711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0696923\n",
      "\tspeed: 0.1037s/iter; left time: 1839.7463s\n",
      "\titers: 200, epoch: 21 | loss: 0.0741142\n",
      "\tspeed: 0.1406s/iter; left time: 2479.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:23.64s\n",
      "Steps: 223 | Train Loss: 0.0703798 Vali Loss: 0.0858786 Test Loss: 0.0881454\n",
      "Validation loss decreased (0.085929 --> 0.085879).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712104\n",
      "\tspeed: 0.2403s/iter; left time: 4209.2540s\n",
      "\titers: 200, epoch: 22 | loss: 0.0711397\n",
      "\tspeed: 0.0558s/iter; left time: 971.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 223 | Train Loss: 0.0702365 Vali Loss: 0.0858019 Test Loss: 0.0882561\n",
      "Validation loss decreased (0.085879 --> 0.085802).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0722965\n",
      "\tspeed: 0.0973s/iter; left time: 1682.5152s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714301\n",
      "\tspeed: 0.0556s/iter; left time: 956.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0702496 Vali Loss: 0.0856940 Test Loss: 0.0880869\n",
      "Validation loss decreased (0.085802 --> 0.085694).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0729966\n",
      "\tspeed: 0.0972s/iter; left time: 1659.1227s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680063\n",
      "\tspeed: 0.0557s/iter; left time: 945.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0700992 Vali Loss: 0.0857747 Test Loss: 0.0881663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0697086\n",
      "\tspeed: 0.0964s/iter; left time: 1623.6354s\n",
      "\titers: 200, epoch: 25 | loss: 0.0660151\n",
      "\tspeed: 0.0556s/iter; left time: 932.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0700257 Vali Loss: 0.0856531 Test Loss: 0.0879749\n",
      "Validation loss decreased (0.085694 --> 0.085653).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0688517\n",
      "\tspeed: 0.0974s/iter; left time: 1619.7967s\n",
      "\titers: 200, epoch: 26 | loss: 0.0606614\n",
      "\tspeed: 0.0557s/iter; left time: 920.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0699975 Vali Loss: 0.0857388 Test Loss: 0.0880380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0686153\n",
      "\tspeed: 0.0961s/iter; left time: 1576.8762s\n",
      "\titers: 200, epoch: 27 | loss: 0.0720461\n",
      "\tspeed: 0.0557s/iter; left time: 907.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0699892 Vali Loss: 0.0856320 Test Loss: 0.0880470\n",
      "Validation loss decreased (0.085653 --> 0.085632).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0720013\n",
      "\tspeed: 0.0964s/iter; left time: 1560.2263s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707490\n",
      "\tspeed: 0.0557s/iter; left time: 895.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0699229 Vali Loss: 0.0855001 Test Loss: 0.0879894\n",
      "Validation loss decreased (0.085632 --> 0.085500).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0708807\n",
      "\tspeed: 0.0973s/iter; left time: 1552.7180s\n",
      "\titers: 200, epoch: 29 | loss: 0.0707058\n",
      "\tspeed: 0.0557s/iter; left time: 882.5779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0699270 Vali Loss: 0.0854612 Test Loss: 0.0880216\n",
      "Validation loss decreased (0.085500 --> 0.085461).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0710514\n",
      "\tspeed: 0.0971s/iter; left time: 1528.0552s\n",
      "\titers: 200, epoch: 30 | loss: 0.0662546\n",
      "\tspeed: 0.0557s/iter; left time: 870.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0698292 Vali Loss: 0.0856229 Test Loss: 0.0880136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0734654\n",
      "\tspeed: 0.0966s/iter; left time: 1497.6724s\n",
      "\titers: 200, epoch: 31 | loss: 0.0677515\n",
      "\tspeed: 0.0598s/iter; left time: 921.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.98s\n",
      "Steps: 223 | Train Loss: 0.0698069 Vali Loss: 0.0854874 Test Loss: 0.0878906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712474\n",
      "\tspeed: 0.1011s/iter; left time: 1545.5408s\n",
      "\titers: 200, epoch: 32 | loss: 0.0654372\n",
      "\tspeed: 0.0557s/iter; left time: 846.0904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0697557 Vali Loss: 0.0854843 Test Loss: 0.0879423\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0690423\n",
      "\tspeed: 0.0965s/iter; left time: 1453.1797s\n",
      "\titers: 200, epoch: 33 | loss: 0.0679753\n",
      "\tspeed: 0.0557s/iter; left time: 833.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0696973 Vali Loss: 0.0855460 Test Loss: 0.0879180\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0715394\n",
      "\tspeed: 0.0974s/iter; left time: 1445.0831s\n",
      "\titers: 200, epoch: 34 | loss: 0.0750787\n",
      "\tspeed: 0.0557s/iter; left time: 820.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0697239 Vali Loss: 0.0854108 Test Loss: 0.0879490\n",
      "Validation loss decreased (0.085461 --> 0.085411).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0690634\n",
      "\tspeed: 0.0970s/iter; left time: 1417.6459s\n",
      "\titers: 200, epoch: 35 | loss: 0.0721469\n",
      "\tspeed: 0.0556s/iter; left time: 807.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0696829 Vali Loss: 0.0855239 Test Loss: 0.0879045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0645434\n",
      "\tspeed: 0.0963s/iter; left time: 1386.0281s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615992\n",
      "\tspeed: 0.0557s/iter; left time: 795.6057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0697068 Vali Loss: 0.0854764 Test Loss: 0.0879015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0672771\n",
      "\tspeed: 0.0961s/iter; left time: 1361.8382s\n",
      "\titers: 200, epoch: 37 | loss: 0.0621125\n",
      "\tspeed: 0.0557s/iter; left time: 783.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0696620 Vali Loss: 0.0854599 Test Loss: 0.0879198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0677729\n",
      "\tspeed: 0.0970s/iter; left time: 1353.8420s\n",
      "\titers: 200, epoch: 38 | loss: 0.0694276\n",
      "\tspeed: 0.0557s/iter; left time: 770.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0696719 Vali Loss: 0.0854918 Test Loss: 0.0879481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0696932\n",
      "\tspeed: 0.0971s/iter; left time: 1333.2887s\n",
      "\titers: 200, epoch: 39 | loss: 0.0687645\n",
      "\tspeed: 0.0557s/iter; left time: 758.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0696647 Vali Loss: 0.0855289 Test Loss: 0.0879689\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0642762\n",
      "\tspeed: 0.0973s/iter; left time: 1314.1102s\n",
      "\titers: 200, epoch: 40 | loss: 0.0678461\n",
      "\tspeed: 0.0557s/iter; left time: 746.1651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0696252 Vali Loss: 0.0854736 Test Loss: 0.0878735\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0698427\n",
      "\tspeed: 0.0987s/iter; left time: 1311.2121s\n",
      "\titers: 200, epoch: 41 | loss: 0.0653338\n",
      "\tspeed: 0.0557s/iter; left time: 734.1025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 223 | Train Loss: 0.0696694 Vali Loss: 0.0853362 Test Loss: 0.0879158\n",
      "Validation loss decreased (0.085411 --> 0.085336).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0717271\n",
      "\tspeed: 0.1739s/iter; left time: 2271.2466s\n",
      "\titers: 200, epoch: 42 | loss: 0.0678519\n",
      "\tspeed: 0.0590s/iter; left time: 764.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:20.30s\n",
      "Steps: 223 | Train Loss: 0.0696300 Vali Loss: 0.0855636 Test Loss: 0.0878947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0661314\n",
      "\tspeed: 0.0969s/iter; left time: 1243.8776s\n",
      "\titers: 200, epoch: 43 | loss: 0.0704750\n",
      "\tspeed: 0.0556s/iter; left time: 708.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0695907 Vali Loss: 0.0854893 Test Loss: 0.0878903\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0704460\n",
      "\tspeed: 0.0958s/iter; left time: 1208.1613s\n",
      "\titers: 200, epoch: 44 | loss: 0.0706366\n",
      "\tspeed: 0.0556s/iter; left time: 695.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0696234 Vali Loss: 0.0853781 Test Loss: 0.0879172\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0717367\n",
      "\tspeed: 0.0991s/iter; left time: 1227.6265s\n",
      "\titers: 200, epoch: 45 | loss: 0.0698064\n",
      "\tspeed: 0.0566s/iter; left time: 695.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 223 | Train Loss: 0.0695847 Vali Loss: 0.0853864 Test Loss: 0.0879186\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0661803\n",
      "\tspeed: 0.3822s/iter; left time: 4649.6345s\n",
      "\titers: 200, epoch: 46 | loss: 0.0637130\n",
      "\tspeed: 0.1979s/iter; left time: 2387.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 223 | Train Loss: 0.0695895 Vali Loss: 0.0854397 Test Loss: 0.0879578\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0707999\n",
      "\tspeed: 0.4448s/iter; left time: 5312.2584s\n",
      "\titers: 200, epoch: 47 | loss: 0.0674502\n",
      "\tspeed: 0.2049s/iter; left time: 2426.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:44.92s\n",
      "Steps: 223 | Train Loss: 0.0695607 Vali Loss: 0.0854818 Test Loss: 0.0879332\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0653478\n",
      "\tspeed: 0.4403s/iter; left time: 5159.8858s\n",
      "\titers: 200, epoch: 48 | loss: 0.0760485\n",
      "\tspeed: 0.1901s/iter; left time: 2208.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 223 | Train Loss: 0.0695990 Vali Loss: 0.0855168 Test Loss: 0.0878915\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0666074\n",
      "\tspeed: 0.4195s/iter; left time: 4822.5781s\n",
      "\titers: 200, epoch: 49 | loss: 0.0666795\n",
      "\tspeed: 0.0937s/iter; left time: 1068.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:30.52s\n",
      "Steps: 223 | Train Loss: 0.0695911 Vali Loss: 0.0854137 Test Loss: 0.0878726\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0674558\n",
      "\tspeed: 0.1339s/iter; left time: 1509.6432s\n",
      "\titers: 200, epoch: 50 | loss: 0.0675304\n",
      "\tspeed: 0.0566s/iter; left time: 632.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 223 | Train Loss: 0.0695212 Vali Loss: 0.0853814 Test Loss: 0.0879392\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0730881\n",
      "\tspeed: 0.1021s/iter; left time: 1128.5975s\n",
      "\titers: 200, epoch: 51 | loss: 0.0706381\n",
      "\tspeed: 0.0564s/iter; left time: 617.7231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:12.85s\n",
      "Steps: 223 | Train Loss: 0.0695619 Vali Loss: 0.0853749 Test Loss: 0.0879278\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02084571123123169, rmse:0.14438043534755707, mae:0.08791576325893402, rse:0.5095385909080505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1321949\n",
      "\tspeed: 0.0585s/iter; left time: 1297.8655s\n",
      "\titers: 200, epoch: 1 | loss: 0.1195247\n",
      "\tspeed: 0.0563s/iter; left time: 1244.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 223 | Train Loss: 0.1355204 Vali Loss: 0.1248920 Test Loss: 0.1302046\n",
      "Validation loss decreased (inf --> 0.124892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869159\n",
      "\tspeed: 0.1001s/iter; left time: 2200.7431s\n",
      "\titers: 200, epoch: 2 | loss: 0.0792214\n",
      "\tspeed: 0.0562s/iter; left time: 1230.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 223 | Train Loss: 0.0882127 Vali Loss: 0.0918631 Test Loss: 0.0943182\n",
      "Validation loss decreased (0.124892 --> 0.091863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820515\n",
      "\tspeed: 0.1003s/iter; left time: 2181.7006s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794274\n",
      "\tspeed: 0.0562s/iter; left time: 1216.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 223 | Train Loss: 0.0791551 Vali Loss: 0.0898517 Test Loss: 0.0931835\n",
      "Validation loss decreased (0.091863 --> 0.089852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0748319\n",
      "\tspeed: 0.1004s/iter; left time: 2161.6282s\n",
      "\titers: 200, epoch: 4 | loss: 0.0758545\n",
      "\tspeed: 0.0562s/iter; left time: 1203.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 223 | Train Loss: 0.0770344 Vali Loss: 0.0888502 Test Loss: 0.0912462\n",
      "Validation loss decreased (0.089852 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0794775\n",
      "\tspeed: 0.0996s/iter; left time: 2121.9133s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783038\n",
      "\tspeed: 0.0561s/iter; left time: 1189.6976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 223 | Train Loss: 0.0755707 Vali Loss: 0.0883333 Test Loss: 0.0905530\n",
      "Validation loss decreased (0.088850 --> 0.088333).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737492\n",
      "\tspeed: 0.0998s/iter; left time: 2104.7996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699851\n",
      "\tspeed: 0.0560s/iter; left time: 1175.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 223 | Train Loss: 0.0745040 Vali Loss: 0.0882450 Test Loss: 0.0902655\n",
      "Validation loss decreased (0.088333 --> 0.088245).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0761966\n",
      "\tspeed: 0.0986s/iter; left time: 2056.8633s\n",
      "\titers: 200, epoch: 7 | loss: 0.0732298\n",
      "\tspeed: 0.0559s/iter; left time: 1161.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0737765 Vali Loss: 0.0872415 Test Loss: 0.0893371\n",
      "Validation loss decreased (0.088245 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0738960\n",
      "\tspeed: 0.0981s/iter; left time: 2025.0048s\n",
      "\titers: 200, epoch: 8 | loss: 0.0792185\n",
      "\tspeed: 0.0559s/iter; left time: 1148.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0730418 Vali Loss: 0.0870644 Test Loss: 0.0889776\n",
      "Validation loss decreased (0.087241 --> 0.087064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0699037\n",
      "\tspeed: 0.0981s/iter; left time: 2003.0031s\n",
      "\titers: 200, epoch: 9 | loss: 0.0689672\n",
      "\tspeed: 0.0560s/iter; left time: 1137.1824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 223 | Train Loss: 0.0725071 Vali Loss: 0.0869053 Test Loss: 0.0892861\n",
      "Validation loss decreased (0.087064 --> 0.086905).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692783\n",
      "\tspeed: 0.0987s/iter; left time: 1993.4443s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771821\n",
      "\tspeed: 0.0560s/iter; left time: 1125.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0722507 Vali Loss: 0.0868102 Test Loss: 0.0888723\n",
      "Validation loss decreased (0.086905 --> 0.086810).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0732150\n",
      "\tspeed: 0.0988s/iter; left time: 1973.0183s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711397\n",
      "\tspeed: 0.0560s/iter; left time: 1112.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0718777 Vali Loss: 0.0862361 Test Loss: 0.0886134\n",
      "Validation loss decreased (0.086810 --> 0.086236).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752613\n",
      "\tspeed: 0.0996s/iter; left time: 1965.9867s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696609\n",
      "\tspeed: 0.0560s/iter; left time: 1099.6293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.0715555 Vali Loss: 0.0862368 Test Loss: 0.0885744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0696154\n",
      "\tspeed: 0.0978s/iter; left time: 1910.4225s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712538\n",
      "\tspeed: 0.0559s/iter; left time: 1086.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0713454 Vali Loss: 0.0865776 Test Loss: 0.0886776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710302\n",
      "\tspeed: 0.0976s/iter; left time: 1883.5708s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697807\n",
      "\tspeed: 0.0560s/iter; left time: 1075.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0710154 Vali Loss: 0.0861612 Test Loss: 0.0887227\n",
      "Validation loss decreased (0.086236 --> 0.086161).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721809\n",
      "\tspeed: 0.0984s/iter; left time: 1876.4410s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740700\n",
      "\tspeed: 0.0560s/iter; left time: 1062.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0708765 Vali Loss: 0.0859608 Test Loss: 0.0887293\n",
      "Validation loss decreased (0.086161 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704648\n",
      "\tspeed: 0.0982s/iter; left time: 1852.1776s\n",
      "\titers: 200, epoch: 16 | loss: 0.0707092\n",
      "\tspeed: 0.0560s/iter; left time: 1050.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0707461 Vali Loss: 0.0859768 Test Loss: 0.0884334\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0682754\n",
      "\tspeed: 0.0983s/iter; left time: 1831.9460s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726420\n",
      "\tspeed: 0.0558s/iter; left time: 1033.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 223 | Train Loss: 0.0705416 Vali Loss: 0.0860883 Test Loss: 0.0883619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0666464\n",
      "\tspeed: 0.0985s/iter; left time: 1814.0579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0721241\n",
      "\tspeed: 0.0560s/iter; left time: 1024.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0704308 Vali Loss: 0.0858410 Test Loss: 0.0884350\n",
      "Validation loss decreased (0.085961 --> 0.085841).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720225\n",
      "\tspeed: 0.0998s/iter; left time: 1814.5629s\n",
      "\titers: 200, epoch: 19 | loss: 0.0684079\n",
      "\tspeed: 0.0559s/iter; left time: 1011.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0703177 Vali Loss: 0.0862782 Test Loss: 0.0886609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747698\n",
      "\tspeed: 0.0981s/iter; left time: 1762.9499s\n",
      "\titers: 200, epoch: 20 | loss: 0.0740259\n",
      "\tspeed: 0.0557s/iter; left time: 995.5033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 223 | Train Loss: 0.0702077 Vali Loss: 0.0857407 Test Loss: 0.0881165\n",
      "Validation loss decreased (0.085841 --> 0.085741).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0676428\n",
      "\tspeed: 0.0986s/iter; left time: 1749.5794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731598\n",
      "\tspeed: 0.0557s/iter; left time: 982.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0700955 Vali Loss: 0.0856354 Test Loss: 0.0884902\n",
      "Validation loss decreased (0.085741 --> 0.085635).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0673825\n",
      "\tspeed: 0.0981s/iter; left time: 1718.5668s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733292\n",
      "\tspeed: 0.0559s/iter; left time: 972.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 223 | Train Loss: 0.0700543 Vali Loss: 0.0858868 Test Loss: 0.0882234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0761369\n",
      "\tspeed: 0.0983s/iter; left time: 1699.9604s\n",
      "\titers: 200, epoch: 23 | loss: 0.0708756\n",
      "\tspeed: 0.0558s/iter; left time: 959.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.0699498 Vali Loss: 0.0855788 Test Loss: 0.0882074\n",
      "Validation loss decreased (0.085635 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0689597\n",
      "\tspeed: 0.0981s/iter; left time: 1674.3440s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710519\n",
      "\tspeed: 0.0556s/iter; left time: 944.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0698366 Vali Loss: 0.0856740 Test Loss: 0.0882654\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673283\n",
      "\tspeed: 0.0978s/iter; left time: 1647.4443s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701892\n",
      "\tspeed: 0.0556s/iter; left time: 930.9707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0698020 Vali Loss: 0.0855684 Test Loss: 0.0883306\n",
      "Validation loss decreased (0.085579 --> 0.085568).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654884\n",
      "\tspeed: 0.0986s/iter; left time: 1639.9428s\n",
      "\titers: 200, epoch: 26 | loss: 0.0740729\n",
      "\tspeed: 0.0556s/iter; left time: 918.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0697329 Vali Loss: 0.0856214 Test Loss: 0.0882084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697414\n",
      "\tspeed: 0.0977s/iter; left time: 1603.2724s\n",
      "\titers: 200, epoch: 27 | loss: 0.0663603\n",
      "\tspeed: 0.0556s/iter; left time: 906.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0697158 Vali Loss: 0.0856465 Test Loss: 0.0883860\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0733333\n",
      "\tspeed: 0.0978s/iter; left time: 1581.8238s\n",
      "\titers: 200, epoch: 28 | loss: 0.0680581\n",
      "\tspeed: 0.0557s/iter; left time: 894.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0696312 Vali Loss: 0.0855474 Test Loss: 0.0882996\n",
      "Validation loss decreased (0.085568 --> 0.085547).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0695887\n",
      "\tspeed: 0.0984s/iter; left time: 1570.6086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0727355\n",
      "\tspeed: 0.0556s/iter; left time: 881.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0695944 Vali Loss: 0.0855103 Test Loss: 0.0882742\n",
      "Validation loss decreased (0.085547 --> 0.085510).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0654744\n",
      "\tspeed: 0.0980s/iter; left time: 1541.6680s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713100\n",
      "\tspeed: 0.0556s/iter; left time: 869.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0695733 Vali Loss: 0.0854913 Test Loss: 0.0881864\n",
      "Validation loss decreased (0.085510 --> 0.085491).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699294\n",
      "\tspeed: 0.0995s/iter; left time: 1543.0130s\n",
      "\titers: 200, epoch: 31 | loss: 0.0719529\n",
      "\tspeed: 0.0556s/iter; left time: 856.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694808 Vali Loss: 0.0855194 Test Loss: 0.0882467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0717089\n",
      "\tspeed: 0.0982s/iter; left time: 1501.4923s\n",
      "\titers: 200, epoch: 32 | loss: 0.0716076\n",
      "\tspeed: 0.0556s/iter; left time: 843.8282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0695085 Vali Loss: 0.0855041 Test Loss: 0.0881491\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0678412\n",
      "\tspeed: 0.0976s/iter; left time: 1469.7178s\n",
      "\titers: 200, epoch: 33 | loss: 0.0721972\n",
      "\tspeed: 0.0558s/iter; left time: 834.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694701 Vali Loss: 0.0854765 Test Loss: 0.0881829\n",
      "Validation loss decreased (0.085491 --> 0.085477).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687791\n",
      "\tspeed: 0.0981s/iter; left time: 1455.8451s\n",
      "\titers: 200, epoch: 34 | loss: 0.0698830\n",
      "\tspeed: 0.0557s/iter; left time: 820.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0694615 Vali Loss: 0.0854668 Test Loss: 0.0881900\n",
      "Validation loss decreased (0.085477 --> 0.085467).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0780406\n",
      "\tspeed: 0.0988s/iter; left time: 1444.6798s\n",
      "\titers: 200, epoch: 35 | loss: 0.0692534\n",
      "\tspeed: 0.0557s/iter; left time: 808.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0694168 Vali Loss: 0.0854433 Test Loss: 0.0881925\n",
      "Validation loss decreased (0.085467 --> 0.085443).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702760\n",
      "\tspeed: 0.0983s/iter; left time: 1414.6276s\n",
      "\titers: 200, epoch: 36 | loss: 0.0728263\n",
      "\tspeed: 0.0558s/iter; left time: 797.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0694150 Vali Loss: 0.0854202 Test Loss: 0.0882087\n",
      "Validation loss decreased (0.085443 --> 0.085420).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0724953\n",
      "\tspeed: 0.0993s/iter; left time: 1406.7536s\n",
      "\titers: 200, epoch: 37 | loss: 0.0703829\n",
      "\tspeed: 0.0557s/iter; left time: 783.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0694151 Vali Loss: 0.0854038 Test Loss: 0.0881835\n",
      "Validation loss decreased (0.085420 --> 0.085404).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0660174\n",
      "\tspeed: 0.0988s/iter; left time: 1378.2318s\n",
      "\titers: 200, epoch: 38 | loss: 0.0667294\n",
      "\tspeed: 0.0557s/iter; left time: 771.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0693594 Vali Loss: 0.0854219 Test Loss: 0.0882360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0672446\n",
      "\tspeed: 0.0980s/iter; left time: 1344.5821s\n",
      "\titers: 200, epoch: 39 | loss: 0.0719632\n",
      "\tspeed: 0.0556s/iter; left time: 757.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0694173 Vali Loss: 0.0854895 Test Loss: 0.0882136\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0677967\n",
      "\tspeed: 0.0974s/iter; left time: 1315.8969s\n",
      "\titers: 200, epoch: 40 | loss: 0.0689068\n",
      "\tspeed: 0.0556s/iter; left time: 744.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0693307 Vali Loss: 0.0854681 Test Loss: 0.0881989\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0681659\n",
      "\tspeed: 0.0972s/iter; left time: 1291.0549s\n",
      "\titers: 200, epoch: 41 | loss: 0.0671629\n",
      "\tspeed: 0.0555s/iter; left time: 731.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0692700 Vali Loss: 0.0854146 Test Loss: 0.0881918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682741\n",
      "\tspeed: 0.0978s/iter; left time: 1277.6139s\n",
      "\titers: 200, epoch: 42 | loss: 0.0739376\n",
      "\tspeed: 0.0556s/iter; left time: 719.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0692600 Vali Loss: 0.0854725 Test Loss: 0.0882275\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0713579\n",
      "\tspeed: 0.0973s/iter; left time: 1249.4545s\n",
      "\titers: 200, epoch: 43 | loss: 0.0718290\n",
      "\tspeed: 0.0556s/iter; left time: 708.1053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0693000 Vali Loss: 0.0854612 Test Loss: 0.0882292\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0687260\n",
      "\tspeed: 0.0981s/iter; left time: 1237.7862s\n",
      "\titers: 200, epoch: 44 | loss: 0.0746944\n",
      "\tspeed: 0.0555s/iter; left time: 695.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0693090 Vali Loss: 0.0854083 Test Loss: 0.0882302\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0692354\n",
      "\tspeed: 0.0980s/iter; left time: 1214.4327s\n",
      "\titers: 200, epoch: 45 | loss: 0.0661913\n",
      "\tspeed: 0.0557s/iter; left time: 684.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0692688 Vali Loss: 0.0854105 Test Loss: 0.0882326\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0687669\n",
      "\tspeed: 0.0977s/iter; left time: 1188.5401s\n",
      "\titers: 200, epoch: 46 | loss: 0.0675251\n",
      "\tspeed: 0.0557s/iter; left time: 672.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0692543 Vali Loss: 0.0854415 Test Loss: 0.0882191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0708708\n",
      "\tspeed: 0.0972s/iter; left time: 1160.2913s\n",
      "\titers: 200, epoch: 47 | loss: 0.0699173\n",
      "\tspeed: 0.0556s/iter; left time: 658.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0692846 Vali Loss: 0.0854284 Test Loss: 0.0882030\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02115781232714653, rmse:0.14545725286006927, mae:0.08818355202674866, rse:0.5133388042449951\n",
      "Intermediate time for DE and pred_len 24: 00h:29m:00.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1386770\n",
      "\tspeed: 0.0732s/iter; left time: 1617.9581s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275029\n",
      "\tspeed: 0.0561s/iter; left time: 1234.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 222 | Train Loss: 0.1436589 Vali Loss: 0.1367227 Test Loss: 0.1443707\n",
      "Validation loss decreased (inf --> 0.136723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1119815\n",
      "\tspeed: 0.0975s/iter; left time: 2133.7373s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102261\n",
      "\tspeed: 0.0560s/iter; left time: 1219.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.1122268 Vali Loss: 0.1208071 Test Loss: 0.1275149\n",
      "Validation loss decreased (0.136723 --> 0.120807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020786\n",
      "\tspeed: 0.1001s/iter; left time: 2168.2093s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071238\n",
      "\tspeed: 0.0560s/iter; left time: 1207.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.1050913 Vali Loss: 0.1187858 Test Loss: 0.1260760\n",
      "Validation loss decreased (0.120807 --> 0.118786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993240\n",
      "\tspeed: 0.0982s/iter; left time: 2104.2546s\n",
      "\titers: 200, epoch: 4 | loss: 0.1062713\n",
      "\tspeed: 0.0559s/iter; left time: 1192.9190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 222 | Train Loss: 0.1032697 Vali Loss: 0.1184309 Test Loss: 0.1263589\n",
      "Validation loss decreased (0.118786 --> 0.118431).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1071941\n",
      "\tspeed: 0.0989s/iter; left time: 2097.1131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1011960\n",
      "\tspeed: 0.0561s/iter; left time: 1183.5208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1018686 Vali Loss: 0.1174367 Test Loss: 0.1259556\n",
      "Validation loss decreased (0.118431 --> 0.117437).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0985333\n",
      "\tspeed: 0.0983s/iter; left time: 2062.7188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0995864\n",
      "\tspeed: 0.0561s/iter; left time: 1171.1833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1008020 Vali Loss: 0.1173732 Test Loss: 0.1252204\n",
      "Validation loss decreased (0.117437 --> 0.117373).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983450\n",
      "\tspeed: 0.0993s/iter; left time: 2062.8763s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028825\n",
      "\tspeed: 0.0561s/iter; left time: 1158.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0997352 Vali Loss: 0.1163223 Test Loss: 0.1250026\n",
      "Validation loss decreased (0.117373 --> 0.116322).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0966778\n",
      "\tspeed: 0.1006s/iter; left time: 2067.5907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981909\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0990780 Vali Loss: 0.1164870 Test Loss: 0.1249006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0970541\n",
      "\tspeed: 0.0981s/iter; left time: 1994.2145s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927569\n",
      "\tspeed: 0.0562s/iter; left time: 1136.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0982853 Vali Loss: 0.1163101 Test Loss: 0.1247123\n",
      "Validation loss decreased (0.116322 --> 0.116310).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004419\n",
      "\tspeed: 0.0987s/iter; left time: 1984.2426s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027958\n",
      "\tspeed: 0.0561s/iter; left time: 1122.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0977100 Vali Loss: 0.1168362 Test Loss: 0.1261414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0973103\n",
      "\tspeed: 0.0985s/iter; left time: 1957.3190s\n",
      "\titers: 200, epoch: 11 | loss: 0.0973775\n",
      "\tspeed: 0.0561s/iter; left time: 1109.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0972067 Vali Loss: 0.1165401 Test Loss: 0.1248463\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0943016\n",
      "\tspeed: 0.0979s/iter; left time: 1925.0397s\n",
      "\titers: 200, epoch: 12 | loss: 0.0890948\n",
      "\tspeed: 0.0559s/iter; left time: 1094.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 222 | Train Loss: 0.0967826 Vali Loss: 0.1167771 Test Loss: 0.1255921\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0919507\n",
      "\tspeed: 0.0975s/iter; left time: 1894.2783s\n",
      "\titers: 200, epoch: 13 | loss: 0.0924439\n",
      "\tspeed: 0.0561s/iter; left time: 1084.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0964317 Vali Loss: 0.1169391 Test Loss: 0.1255141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920366\n",
      "\tspeed: 0.0979s/iter; left time: 1881.9140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965247\n",
      "\tspeed: 0.0560s/iter; left time: 1071.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0958845 Vali Loss: 0.1169356 Test Loss: 0.1257542\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0993237\n",
      "\tspeed: 0.0979s/iter; left time: 1858.6467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0994493\n",
      "\tspeed: 0.0560s/iter; left time: 1058.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0956289 Vali Loss: 0.1167035 Test Loss: 0.1253432\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000477\n",
      "\tspeed: 0.0982s/iter; left time: 1843.9902s\n",
      "\titers: 200, epoch: 16 | loss: 0.0847670\n",
      "\tspeed: 0.0560s/iter; left time: 1046.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0952643 Vali Loss: 0.1171782 Test Loss: 0.1261246\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0950092\n",
      "\tspeed: 0.0981s/iter; left time: 1818.7499s\n",
      "\titers: 200, epoch: 17 | loss: 0.0940945\n",
      "\tspeed: 0.0561s/iter; left time: 1034.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0950014 Vali Loss: 0.1169843 Test Loss: 0.1258609\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0952450\n",
      "\tspeed: 0.0970s/iter; left time: 1776.8518s\n",
      "\titers: 200, epoch: 18 | loss: 0.0911217\n",
      "\tspeed: 0.0561s/iter; left time: 1022.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.0946936 Vali Loss: 0.1172174 Test Loss: 0.1259473\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0924156\n",
      "\tspeed: 0.0960s/iter; left time: 1737.5872s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927952\n",
      "\tspeed: 0.0560s/iter; left time: 1008.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 222 | Train Loss: 0.0944330 Vali Loss: 0.1170902 Test Loss: 0.1258976\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0357123464345932, rmse:0.18897710740566254, mae:0.12471231073141098, rse:0.6692061424255371\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1400153\n",
      "\tspeed: 0.0607s/iter; left time: 1340.4608s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283204\n",
      "\tspeed: 0.0560s/iter; left time: 1231.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1451430 Vali Loss: 0.1368039 Test Loss: 0.1443701\n",
      "Validation loss decreased (inf --> 0.136804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1105237\n",
      "\tspeed: 0.0977s/iter; left time: 2136.7989s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087797\n",
      "\tspeed: 0.0560s/iter; left time: 1219.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1123487 Vali Loss: 0.1206258 Test Loss: 0.1276149\n",
      "Validation loss decreased (0.136804 --> 0.120626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1059384\n",
      "\tspeed: 0.0978s/iter; left time: 2118.7439s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022027\n",
      "\tspeed: 0.0562s/iter; left time: 1211.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.1053810 Vali Loss: 0.1195757 Test Loss: 0.1275250\n",
      "Validation loss decreased (0.120626 --> 0.119576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1005405\n",
      "\tspeed: 0.1000s/iter; left time: 2143.8992s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009716\n",
      "\tspeed: 0.0560s/iter; left time: 1194.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1036713 Vali Loss: 0.1178414 Test Loss: 0.1258538\n",
      "Validation loss decreased (0.119576 --> 0.117841).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1006262\n",
      "\tspeed: 0.0984s/iter; left time: 2086.4697s\n",
      "\titers: 200, epoch: 5 | loss: 0.1009720\n",
      "\tspeed: 0.0560s/iter; left time: 1182.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1022844 Vali Loss: 0.1183373 Test Loss: 0.1259439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044686\n",
      "\tspeed: 0.0985s/iter; left time: 2066.9535s\n",
      "\titers: 200, epoch: 6 | loss: 0.1039320\n",
      "\tspeed: 0.0561s/iter; left time: 1172.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1011754 Vali Loss: 0.1172123 Test Loss: 0.1262177\n",
      "Validation loss decreased (0.117841 --> 0.117212).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983822\n",
      "\tspeed: 0.0985s/iter; left time: 2046.7621s\n",
      "\titers: 200, epoch: 7 | loss: 0.0999982\n",
      "\tspeed: 0.0560s/iter; left time: 1156.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.1001580 Vali Loss: 0.1167087 Test Loss: 0.1267239\n",
      "Validation loss decreased (0.117212 --> 0.116709).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0978371\n",
      "\tspeed: 0.0986s/iter; left time: 2026.7079s\n",
      "\titers: 200, epoch: 8 | loss: 0.0960991\n",
      "\tspeed: 0.0560s/iter; left time: 1144.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0993198 Vali Loss: 0.1167437 Test Loss: 0.1256996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030914\n",
      "\tspeed: 0.0971s/iter; left time: 1972.8331s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060393\n",
      "\tspeed: 0.0562s/iter; left time: 1136.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0985208 Vali Loss: 0.1168993 Test Loss: 0.1262533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0944255\n",
      "\tspeed: 0.0968s/iter; left time: 1945.8575s\n",
      "\titers: 200, epoch: 10 | loss: 0.1005896\n",
      "\tspeed: 0.0560s/iter; left time: 1120.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.0978726 Vali Loss: 0.1164778 Test Loss: 0.1254682\n",
      "Validation loss decreased (0.116709 --> 0.116478).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0977786\n",
      "\tspeed: 0.0978s/iter; left time: 1944.9826s\n",
      "\titers: 200, epoch: 11 | loss: 0.1001371\n",
      "\tspeed: 0.0560s/iter; left time: 1107.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0972471 Vali Loss: 0.1168976 Test Loss: 0.1259428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0953204\n",
      "\tspeed: 0.0989s/iter; left time: 1944.8913s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940205\n",
      "\tspeed: 0.0561s/iter; left time: 1096.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0966455 Vali Loss: 0.1169655 Test Loss: 0.1269953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961258\n",
      "\tspeed: 0.0975s/iter; left time: 1895.6554s\n",
      "\titers: 200, epoch: 13 | loss: 0.0972280\n",
      "\tspeed: 0.0560s/iter; left time: 1083.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 222 | Train Loss: 0.0962103 Vali Loss: 0.1170050 Test Loss: 0.1266064\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0952882\n",
      "\tspeed: 0.0973s/iter; left time: 1870.4021s\n",
      "\titers: 200, epoch: 14 | loss: 0.0944683\n",
      "\tspeed: 0.0560s/iter; left time: 1070.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0957853 Vali Loss: 0.1175132 Test Loss: 0.1264056\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0908371\n",
      "\tspeed: 0.0974s/iter; left time: 1849.2390s\n",
      "\titers: 200, epoch: 15 | loss: 0.0950360\n",
      "\tspeed: 0.0560s/iter; left time: 1058.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0954513 Vali Loss: 0.1173833 Test Loss: 0.1263880\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0962350\n",
      "\tspeed: 0.0972s/iter; left time: 1824.7716s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930480\n",
      "\tspeed: 0.0560s/iter; left time: 1045.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 222 | Train Loss: 0.0950452 Vali Loss: 0.1174323 Test Loss: 0.1273650\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0914153\n",
      "\tspeed: 0.0971s/iter; left time: 1801.1286s\n",
      "\titers: 200, epoch: 17 | loss: 0.0968439\n",
      "\tspeed: 0.0560s/iter; left time: 1033.5842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0946228 Vali Loss: 0.1173784 Test Loss: 0.1264199\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0973026\n",
      "\tspeed: 0.0983s/iter; left time: 1801.6330s\n",
      "\titers: 200, epoch: 18 | loss: 0.0956572\n",
      "\tspeed: 0.0560s/iter; left time: 1020.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0943172 Vali Loss: 0.1177413 Test Loss: 0.1269055\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978792\n",
      "\tspeed: 0.0969s/iter; left time: 1754.5040s\n",
      "\titers: 200, epoch: 19 | loss: 0.0975742\n",
      "\tspeed: 0.0560s/iter; left time: 1008.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 222 | Train Loss: 0.0940416 Vali Loss: 0.1174546 Test Loss: 0.1267941\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0935509\n",
      "\tspeed: 0.0974s/iter; left time: 1741.2340s\n",
      "\titers: 200, epoch: 20 | loss: 0.0917177\n",
      "\tspeed: 0.0560s/iter; left time: 996.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0937595 Vali Loss: 0.1178303 Test Loss: 0.1271784\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03607788681983948, rmse:0.18994179368019104, mae:0.1254681944847107, rse:0.6726222634315491\n",
      "Intermediate time for DE and pred_len 96: 00h:10m:12.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1399002\n",
      "\tspeed: 0.0736s/iter; left time: 1627.4941s\n",
      "\titers: 200, epoch: 1 | loss: 0.1310720\n",
      "\tspeed: 0.0563s/iter; left time: 1239.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1455335 Vali Loss: 0.1382271 Test Loss: 0.1469403\n",
      "Validation loss decreased (inf --> 0.138227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1117309\n",
      "\tspeed: 0.1001s/iter; left time: 2189.3365s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123937\n",
      "\tspeed: 0.0562s/iter; left time: 1224.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1173331 Vali Loss: 0.1245262 Test Loss: 0.1328125\n",
      "Validation loss decreased (0.138227 --> 0.124526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142129\n",
      "\tspeed: 0.0987s/iter; left time: 2136.9183s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112960\n",
      "\tspeed: 0.0562s/iter; left time: 1212.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.1107632 Vali Loss: 0.1232793 Test Loss: 0.1330868\n",
      "Validation loss decreased (0.124526 --> 0.123279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1128851\n",
      "\tspeed: 0.0990s/iter; left time: 2121.5691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1049208\n",
      "\tspeed: 0.0564s/iter; left time: 1202.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1088794 Vali Loss: 0.1225181 Test Loss: 0.1325915\n",
      "Validation loss decreased (0.123279 --> 0.122518).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1046247\n",
      "\tspeed: 0.0995s/iter; left time: 2111.0974s\n",
      "\titers: 200, epoch: 5 | loss: 0.1109414\n",
      "\tspeed: 0.0563s/iter; left time: 1187.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1072736 Vali Loss: 0.1221427 Test Loss: 0.1330497\n",
      "Validation loss decreased (0.122518 --> 0.122143).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1038896\n",
      "\tspeed: 0.1006s/iter; left time: 2112.5653s\n",
      "\titers: 200, epoch: 6 | loss: 0.1055614\n",
      "\tspeed: 0.0562s/iter; left time: 1174.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1058474 Vali Loss: 0.1215778 Test Loss: 0.1318558\n",
      "Validation loss decreased (0.122143 --> 0.121578).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041685\n",
      "\tspeed: 0.0989s/iter; left time: 2054.7160s\n",
      "\titers: 200, epoch: 7 | loss: 0.1039714\n",
      "\tspeed: 0.0564s/iter; left time: 1165.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1048099 Vali Loss: 0.1214240 Test Loss: 0.1309484\n",
      "Validation loss decreased (0.121578 --> 0.121424).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1028266\n",
      "\tspeed: 0.1006s/iter; left time: 2067.7900s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051091\n",
      "\tspeed: 0.0563s/iter; left time: 1150.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.1038182 Vali Loss: 0.1214119 Test Loss: 0.1320169\n",
      "Validation loss decreased (0.121424 --> 0.121412).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042578\n",
      "\tspeed: 0.0996s/iter; left time: 2025.2615s\n",
      "\titers: 200, epoch: 9 | loss: 0.1050219\n",
      "\tspeed: 0.0565s/iter; left time: 1143.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1030263 Vali Loss: 0.1220749 Test Loss: 0.1315216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0999491\n",
      "\tspeed: 0.0985s/iter; left time: 1980.2510s\n",
      "\titers: 200, epoch: 10 | loss: 0.1035637\n",
      "\tspeed: 0.0565s/iter; left time: 1131.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1022463 Vali Loss: 0.1222583 Test Loss: 0.1317445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1062949\n",
      "\tspeed: 0.0994s/iter; left time: 1976.7728s\n",
      "\titers: 200, epoch: 11 | loss: 0.1018711\n",
      "\tspeed: 0.0564s/iter; left time: 1116.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1015389 Vali Loss: 0.1223068 Test Loss: 0.1325487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043713\n",
      "\tspeed: 0.0972s/iter; left time: 1910.6977s\n",
      "\titers: 200, epoch: 12 | loss: 0.1038010\n",
      "\tspeed: 0.0563s/iter; left time: 1100.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1009183 Vali Loss: 0.1225692 Test Loss: 0.1322718\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0969497\n",
      "\tspeed: 0.0987s/iter; left time: 1919.2575s\n",
      "\titers: 200, epoch: 13 | loss: 0.1017084\n",
      "\tspeed: 0.0565s/iter; left time: 1093.1834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1002693 Vali Loss: 0.1229654 Test Loss: 0.1329298\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0960272\n",
      "\tspeed: 0.0974s/iter; left time: 1871.2541s\n",
      "\titers: 200, epoch: 14 | loss: 0.0956312\n",
      "\tspeed: 0.0563s/iter; left time: 1075.4648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0997279 Vali Loss: 0.1232132 Test Loss: 0.1330129\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0969483\n",
      "\tspeed: 0.0976s/iter; left time: 1854.4657s\n",
      "\titers: 200, epoch: 15 | loss: 0.0989557\n",
      "\tspeed: 0.0563s/iter; left time: 1063.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0992188 Vali Loss: 0.1234317 Test Loss: 0.1328251\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0992143\n",
      "\tspeed: 0.0978s/iter; left time: 1836.5780s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004101\n",
      "\tspeed: 0.0562s/iter; left time: 1050.1986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0986988 Vali Loss: 0.1237274 Test Loss: 0.1332834\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0983965\n",
      "\tspeed: 0.0975s/iter; left time: 1809.4157s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016725\n",
      "\tspeed: 0.0563s/iter; left time: 1039.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0982776 Vali Loss: 0.1234311 Test Loss: 0.1342439\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1021305\n",
      "\tspeed: 0.0978s/iter; left time: 1791.5198s\n",
      "\titers: 200, epoch: 18 | loss: 0.1000237\n",
      "\tspeed: 0.0563s/iter; left time: 1026.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0979285 Vali Loss: 0.1238799 Test Loss: 0.1341607\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038425009697675705, rmse:0.19602298736572266, mae:0.13201698660850525, rse:0.6943292021751404\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1515820\n",
      "\tspeed: 0.0581s/iter; left time: 1284.1425s\n",
      "\titers: 200, epoch: 1 | loss: 0.1351595\n",
      "\tspeed: 0.0562s/iter; left time: 1236.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 222 | Train Loss: 0.1459106 Vali Loss: 0.1384471 Test Loss: 0.1474545\n",
      "Validation loss decreased (inf --> 0.138447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1206223\n",
      "\tspeed: 0.1032s/iter; left time: 2258.6045s\n",
      "\titers: 200, epoch: 2 | loss: 0.1142049\n",
      "\tspeed: 0.0564s/iter; left time: 1227.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 222 | Train Loss: 0.1174732 Vali Loss: 0.1245720 Test Loss: 0.1331472\n",
      "Validation loss decreased (0.138447 --> 0.124572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1117440\n",
      "\tspeed: 0.1027s/iter; left time: 2223.2753s\n",
      "\titers: 200, epoch: 3 | loss: 0.1069415\n",
      "\tspeed: 0.0563s/iter; left time: 1213.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1109596 Vali Loss: 0.1228000 Test Loss: 0.1327924\n",
      "Validation loss decreased (0.124572 --> 0.122800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1147476\n",
      "\tspeed: 0.1018s/iter; left time: 2182.9928s\n",
      "\titers: 200, epoch: 4 | loss: 0.1086724\n",
      "\tspeed: 0.0565s/iter; left time: 1205.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1091430 Vali Loss: 0.1222963 Test Loss: 0.1323178\n",
      "Validation loss decreased (0.122800 --> 0.122296).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032344\n",
      "\tspeed: 0.0997s/iter; left time: 2114.5639s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114992\n",
      "\tspeed: 0.0565s/iter; left time: 1192.8346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1075674 Vali Loss: 0.1216319 Test Loss: 0.1328520\n",
      "Validation loss decreased (0.122296 --> 0.121632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1055237\n",
      "\tspeed: 0.1015s/iter; left time: 2130.5685s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056632\n",
      "\tspeed: 0.0565s/iter; left time: 1180.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1062136 Vali Loss: 0.1215922 Test Loss: 0.1327853\n",
      "Validation loss decreased (0.121632 --> 0.121592).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061727\n",
      "\tspeed: 0.1000s/iter; left time: 2076.2507s\n",
      "\titers: 200, epoch: 7 | loss: 0.1068689\n",
      "\tspeed: 0.0566s/iter; left time: 1169.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 222 | Train Loss: 0.1049340 Vali Loss: 0.1212201 Test Loss: 0.1333899\n",
      "Validation loss decreased (0.121592 --> 0.121220).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1025914\n",
      "\tspeed: 0.1011s/iter; left time: 2077.9060s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054732\n",
      "\tspeed: 0.0566s/iter; left time: 1157.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 222 | Train Loss: 0.1037226 Vali Loss: 0.1214384 Test Loss: 0.1324994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1038579\n",
      "\tspeed: 0.0990s/iter; left time: 2011.6868s\n",
      "\titers: 200, epoch: 9 | loss: 0.0974196\n",
      "\tspeed: 0.0563s/iter; left time: 1139.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1026216 Vali Loss: 0.1224918 Test Loss: 0.1345142\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996268\n",
      "\tspeed: 0.0987s/iter; left time: 1984.3095s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027106\n",
      "\tspeed: 0.0564s/iter; left time: 1128.9756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 222 | Train Loss: 0.1015664 Vali Loss: 0.1220061 Test Loss: 0.1339394\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0993154\n",
      "\tspeed: 0.0985s/iter; left time: 1958.2135s\n",
      "\titers: 200, epoch: 11 | loss: 0.1040305\n",
      "\tspeed: 0.0564s/iter; left time: 1114.9837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1006644 Vali Loss: 0.1220355 Test Loss: 0.1343870\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1000718\n",
      "\tspeed: 0.0978s/iter; left time: 1923.4137s\n",
      "\titers: 200, epoch: 12 | loss: 0.1012884\n",
      "\tspeed: 0.0562s/iter; left time: 1099.4035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0998381 Vali Loss: 0.1228722 Test Loss: 0.1341205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016827\n",
      "\tspeed: 0.0980s/iter; left time: 1904.5476s\n",
      "\titers: 200, epoch: 13 | loss: 0.0976272\n",
      "\tspeed: 0.0562s/iter; left time: 1086.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0991605 Vali Loss: 0.1230029 Test Loss: 0.1345378\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1022788\n",
      "\tspeed: 0.0974s/iter; left time: 1870.8376s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998285\n",
      "\tspeed: 0.0562s/iter; left time: 1074.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.0985090 Vali Loss: 0.1234400 Test Loss: 0.1346146\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0985817\n",
      "\tspeed: 0.0994s/iter; left time: 1888.7617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0989988\n",
      "\tspeed: 0.0564s/iter; left time: 1065.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 222 | Train Loss: 0.0979335 Vali Loss: 0.1231191 Test Loss: 0.1347603\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990492\n",
      "\tspeed: 0.0994s/iter; left time: 1866.4312s\n",
      "\titers: 200, epoch: 16 | loss: 0.0982786\n",
      "\tspeed: 0.0566s/iter; left time: 1057.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 222 | Train Loss: 0.0974306 Vali Loss: 0.1235838 Test Loss: 0.1353326\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0952108\n",
      "\tspeed: 0.0994s/iter; left time: 1844.3263s\n",
      "\titers: 200, epoch: 17 | loss: 0.0949799\n",
      "\tspeed: 0.0562s/iter; left time: 1037.2817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 222 | Train Loss: 0.0968703 Vali Loss: 0.1237597 Test Loss: 0.1353569\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03871931508183479, rmse:0.1967722475528717, mae:0.1333899199962616, rse:0.6969830989837646\n",
      "Intermediate time for DE and pred_len 168: 00h:09m:17.71s\n",
      "Intermediate time for DE: 00h:48m:30.61s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1190656\n",
      "\tspeed: 0.0736s/iter; left time: 1634.9689s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161422\n",
      "\tspeed: 0.0558s/iter; left time: 1233.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.91s\n",
      "Steps: 223 | Train Loss: 0.1253484 Vali Loss: 0.1194087 Test Loss: 0.1384515\n",
      "Validation loss decreased (inf --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870098\n",
      "\tspeed: 0.0978s/iter; left time: 2148.4085s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820863\n",
      "\tspeed: 0.0558s/iter; left time: 1220.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0858498 Vali Loss: 0.0922656 Test Loss: 0.1037217\n",
      "Validation loss decreased (0.119409 --> 0.092266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0805822\n",
      "\tspeed: 0.0972s/iter; left time: 2115.0916s\n",
      "\titers: 200, epoch: 3 | loss: 0.0783289\n",
      "\tspeed: 0.0558s/iter; left time: 1207.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0789233 Vali Loss: 0.0894624 Test Loss: 0.1028290\n",
      "Validation loss decreased (0.092266 --> 0.089462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815623\n",
      "\tspeed: 0.0970s/iter; left time: 2089.5757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827173\n",
      "\tspeed: 0.0558s/iter; left time: 1196.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0773275 Vali Loss: 0.0896265 Test Loss: 0.1026914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726509\n",
      "\tspeed: 0.0965s/iter; left time: 2056.0343s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737885\n",
      "\tspeed: 0.0557s/iter; left time: 1182.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0762504 Vali Loss: 0.0890852 Test Loss: 0.1016043\n",
      "Validation loss decreased (0.089462 --> 0.089085).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734069\n",
      "\tspeed: 0.0971s/iter; left time: 2046.4637s\n",
      "\titers: 200, epoch: 6 | loss: 0.0775540\n",
      "\tspeed: 0.0558s/iter; left time: 1170.8743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0755329 Vali Loss: 0.0884747 Test Loss: 0.1004770\n",
      "Validation loss decreased (0.089085 --> 0.088475).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754288\n",
      "\tspeed: 0.0979s/iter; left time: 2043.1717s\n",
      "\titers: 200, epoch: 7 | loss: 0.0744961\n",
      "\tspeed: 0.0558s/iter; left time: 1157.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0749985 Vali Loss: 0.0885333 Test Loss: 0.1013064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774653\n",
      "\tspeed: 0.0970s/iter; left time: 2001.8117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739258\n",
      "\tspeed: 0.0557s/iter; left time: 1144.0606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0745286 Vali Loss: 0.0878436 Test Loss: 0.1005928\n",
      "Validation loss decreased (0.088475 --> 0.087844).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736594\n",
      "\tspeed: 0.0970s/iter; left time: 1980.6955s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707307\n",
      "\tspeed: 0.0558s/iter; left time: 1133.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0740644 Vali Loss: 0.0879482 Test Loss: 0.0996325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0720190\n",
      "\tspeed: 0.0973s/iter; left time: 1964.6439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767412\n",
      "\tspeed: 0.0558s/iter; left time: 1121.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0736389 Vali Loss: 0.0878936 Test Loss: 0.1004490\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0787126\n",
      "\tspeed: 0.0964s/iter; left time: 1925.3029s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735841\n",
      "\tspeed: 0.0557s/iter; left time: 1107.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0733615 Vali Loss: 0.0875434 Test Loss: 0.1004866\n",
      "Validation loss decreased (0.087844 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650659\n",
      "\tspeed: 0.0968s/iter; left time: 1910.8100s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782444\n",
      "\tspeed: 0.0556s/iter; left time: 1092.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0731628 Vali Loss: 0.0876492 Test Loss: 0.0996653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0720514\n",
      "\tspeed: 0.0967s/iter; left time: 1887.9786s\n",
      "\titers: 200, epoch: 13 | loss: 0.0745456\n",
      "\tspeed: 0.0558s/iter; left time: 1084.3613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0729101 Vali Loss: 0.0874964 Test Loss: 0.0996864\n",
      "Validation loss decreased (0.087543 --> 0.087496).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719180\n",
      "\tspeed: 0.0982s/iter; left time: 1895.3045s\n",
      "\titers: 200, epoch: 14 | loss: 0.0725956\n",
      "\tspeed: 0.0558s/iter; left time: 1071.4137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0727339 Vali Loss: 0.0876334 Test Loss: 0.0996331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718653\n",
      "\tspeed: 0.0971s/iter; left time: 1852.5220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711401\n",
      "\tspeed: 0.0556s/iter; left time: 1054.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0725731 Vali Loss: 0.0873525 Test Loss: 0.0995370\n",
      "Validation loss decreased (0.087496 --> 0.087353).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709502\n",
      "\tspeed: 0.0977s/iter; left time: 1843.0721s\n",
      "\titers: 200, epoch: 16 | loss: 0.0688956\n",
      "\tspeed: 0.0556s/iter; left time: 1042.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0724521 Vali Loss: 0.0873687 Test Loss: 0.0992573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0763475\n",
      "\tspeed: 0.0968s/iter; left time: 1803.3515s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740564\n",
      "\tspeed: 0.0556s/iter; left time: 1031.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0722744 Vali Loss: 0.0872078 Test Loss: 0.0993596\n",
      "Validation loss decreased (0.087353 --> 0.087208).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710246\n",
      "\tspeed: 0.0976s/iter; left time: 1797.2363s\n",
      "\titers: 200, epoch: 18 | loss: 0.0711855\n",
      "\tspeed: 0.0558s/iter; left time: 1020.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0721521 Vali Loss: 0.0872633 Test Loss: 0.0994425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733631\n",
      "\tspeed: 0.0969s/iter; left time: 1761.6434s\n",
      "\titers: 200, epoch: 19 | loss: 0.0770690\n",
      "\tspeed: 0.0558s/iter; left time: 1008.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0720333 Vali Loss: 0.0873004 Test Loss: 0.0993044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0704630\n",
      "\tspeed: 0.0972s/iter; left time: 1746.3209s\n",
      "\titers: 200, epoch: 20 | loss: 0.0651565\n",
      "\tspeed: 0.0558s/iter; left time: 996.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0719302 Vali Loss: 0.0872917 Test Loss: 0.0991583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0689208\n",
      "\tspeed: 0.0968s/iter; left time: 1717.5031s\n",
      "\titers: 200, epoch: 21 | loss: 0.0757201\n",
      "\tspeed: 0.0557s/iter; left time: 983.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0718589 Vali Loss: 0.0872711 Test Loss: 0.0992796\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0733921\n",
      "\tspeed: 0.0967s/iter; left time: 1694.3010s\n",
      "\titers: 200, epoch: 22 | loss: 0.0708673\n",
      "\tspeed: 0.0558s/iter; left time: 972.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0717552 Vali Loss: 0.0871347 Test Loss: 0.0991715\n",
      "Validation loss decreased (0.087208 --> 0.087135).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0760645\n",
      "\tspeed: 0.0974s/iter; left time: 1684.4248s\n",
      "\titers: 200, epoch: 23 | loss: 0.0667015\n",
      "\tspeed: 0.0557s/iter; left time: 958.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0717327 Vali Loss: 0.0870459 Test Loss: 0.0991245\n",
      "Validation loss decreased (0.087135 --> 0.087046).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0735871\n",
      "\tspeed: 0.0970s/iter; left time: 1655.6581s\n",
      "\titers: 200, epoch: 24 | loss: 0.0728756\n",
      "\tspeed: 0.0558s/iter; left time: 946.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0716163 Vali Loss: 0.0871637 Test Loss: 0.0992907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0732243\n",
      "\tspeed: 0.0970s/iter; left time: 1633.7305s\n",
      "\titers: 200, epoch: 25 | loss: 0.0709287\n",
      "\tspeed: 0.0558s/iter; left time: 934.9185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 223 | Train Loss: 0.0716102 Vali Loss: 0.0873323 Test Loss: 0.0991644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0683563\n",
      "\tspeed: 0.0967s/iter; left time: 1608.1505s\n",
      "\titers: 200, epoch: 26 | loss: 0.0677319\n",
      "\tspeed: 0.0558s/iter; left time: 921.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0715926 Vali Loss: 0.0872675 Test Loss: 0.0991061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0738787\n",
      "\tspeed: 0.0969s/iter; left time: 1589.7199s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742473\n",
      "\tspeed: 0.0558s/iter; left time: 910.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 223 | Train Loss: 0.0714851 Vali Loss: 0.0870536 Test Loss: 0.0990238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0666653\n",
      "\tspeed: 0.1012s/iter; left time: 1637.0762s\n",
      "\titers: 200, epoch: 28 | loss: 0.0767145\n",
      "\tspeed: 0.0584s/iter; left time: 938.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 223 | Train Loss: 0.0714313 Vali Loss: 0.0872936 Test Loss: 0.0991399\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0739312\n",
      "\tspeed: 0.2538s/iter; left time: 4050.4375s\n",
      "\titers: 200, epoch: 29 | loss: 0.0702690\n",
      "\tspeed: 0.1388s/iter; left time: 2201.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:31.52s\n",
      "Steps: 223 | Train Loss: 0.0714035 Vali Loss: 0.0871968 Test Loss: 0.0991477\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0746630\n",
      "\tspeed: 0.2824s/iter; left time: 4442.6480s\n",
      "\titers: 200, epoch: 30 | loss: 0.0762597\n",
      "\tspeed: 0.1269s/iter; left time: 1984.1953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 223 | Train Loss: 0.0713885 Vali Loss: 0.0873346 Test Loss: 0.0991395\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0695903\n",
      "\tspeed: 0.2994s/iter; left time: 4644.7499s\n",
      "\titers: 200, epoch: 31 | loss: 0.0737659\n",
      "\tspeed: 0.1662s/iter; left time: 2561.6537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:31.84s\n",
      "Steps: 223 | Train Loss: 0.0713434 Vali Loss: 0.0871035 Test Loss: 0.0991213\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0750624\n",
      "\tspeed: 0.2879s/iter; left time: 4401.4034s\n",
      "\titers: 200, epoch: 32 | loss: 0.0747816\n",
      "\tspeed: 0.0944s/iter; left time: 1433.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 223 | Train Loss: 0.0713147 Vali Loss: 0.0871615 Test Loss: 0.0991062\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0709687\n",
      "\tspeed: 0.3957s/iter; left time: 5960.8588s\n",
      "\titers: 200, epoch: 33 | loss: 0.0697152\n",
      "\tspeed: 0.1926s/iter; left time: 2882.6352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 223 | Train Loss: 0.0712944 Vali Loss: 0.0871505 Test Loss: 0.0990493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024570560082793236, rmse:0.15674999356269836, mae:0.09912451356649399, rse:0.5407430529594421\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1245341\n",
      "\tspeed: 0.2228s/iter; left time: 4946.5063s\n",
      "\titers: 200, epoch: 1 | loss: 0.1095097\n",
      "\tspeed: 0.2037s/iter; left time: 4501.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 223 | Train Loss: 0.1254445 Vali Loss: 0.1200309 Test Loss: 0.1391877\n",
      "Validation loss decreased (inf --> 0.120031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0840376\n",
      "\tspeed: 0.3435s/iter; left time: 7550.2616s\n",
      "\titers: 200, epoch: 2 | loss: 0.0810726\n",
      "\tspeed: 0.0788s/iter; left time: 1723.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.44s\n",
      "Steps: 223 | Train Loss: 0.0858071 Vali Loss: 0.0911559 Test Loss: 0.1027333\n",
      "Validation loss decreased (0.120031 --> 0.091156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0800171\n",
      "\tspeed: 0.1037s/iter; left time: 2255.2973s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812158\n",
      "\tspeed: 0.0565s/iter; left time: 1222.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 223 | Train Loss: 0.0790698 Vali Loss: 0.0896118 Test Loss: 0.1031010\n",
      "Validation loss decreased (0.091156 --> 0.089612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818189\n",
      "\tspeed: 0.1006s/iter; left time: 2165.9190s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696711\n",
      "\tspeed: 0.0557s/iter; left time: 1193.7008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 223 | Train Loss: 0.0774647 Vali Loss: 0.0894184 Test Loss: 0.1019324\n",
      "Validation loss decreased (0.089612 --> 0.089418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0843827\n",
      "\tspeed: 0.0983s/iter; left time: 2094.6637s\n",
      "\titers: 200, epoch: 5 | loss: 0.0805781\n",
      "\tspeed: 0.0557s/iter; left time: 1180.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 223 | Train Loss: 0.0764215 Vali Loss: 0.0892403 Test Loss: 0.1013356\n",
      "Validation loss decreased (0.089418 --> 0.089240).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0738009\n",
      "\tspeed: 0.0976s/iter; left time: 2057.9585s\n",
      "\titers: 200, epoch: 6 | loss: 0.0750279\n",
      "\tspeed: 0.0555s/iter; left time: 1165.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0756854 Vali Loss: 0.0886191 Test Loss: 0.1014508\n",
      "Validation loss decreased (0.089240 --> 0.088619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0818800\n",
      "\tspeed: 0.0975s/iter; left time: 2034.9174s\n",
      "\titers: 200, epoch: 7 | loss: 0.0787578\n",
      "\tspeed: 0.0556s/iter; left time: 1154.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0751229 Vali Loss: 0.0883886 Test Loss: 0.1005039\n",
      "Validation loss decreased (0.088619 --> 0.088389).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0751207\n",
      "\tspeed: 0.0968s/iter; left time: 1998.4805s\n",
      "\titers: 200, epoch: 8 | loss: 0.0725476\n",
      "\tspeed: 0.0556s/iter; left time: 1141.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0746188 Vali Loss: 0.0880025 Test Loss: 0.1003955\n",
      "Validation loss decreased (0.088389 --> 0.088002).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0723632\n",
      "\tspeed: 0.0971s/iter; left time: 1982.6216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748586\n",
      "\tspeed: 0.0556s/iter; left time: 1130.1861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0741620 Vali Loss: 0.0884281 Test Loss: 0.1003440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684523\n",
      "\tspeed: 0.0966s/iter; left time: 1950.1821s\n",
      "\titers: 200, epoch: 10 | loss: 0.0759455\n",
      "\tspeed: 0.0556s/iter; left time: 1117.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0738323 Vali Loss: 0.0877718 Test Loss: 0.0998402\n",
      "Validation loss decreased (0.088002 --> 0.087772).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773028\n",
      "\tspeed: 0.0974s/iter; left time: 1945.8627s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717021\n",
      "\tspeed: 0.0557s/iter; left time: 1106.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0735408 Vali Loss: 0.0878956 Test Loss: 0.0997441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0727853\n",
      "\tspeed: 0.0970s/iter; left time: 1914.7258s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768436\n",
      "\tspeed: 0.0556s/iter; left time: 1092.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0732213 Vali Loss: 0.0874504 Test Loss: 0.0993545\n",
      "Validation loss decreased (0.087772 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0748568\n",
      "\tspeed: 0.0980s/iter; left time: 1914.2375s\n",
      "\titers: 200, epoch: 13 | loss: 0.0693408\n",
      "\tspeed: 0.0556s/iter; left time: 1080.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0729368 Vali Loss: 0.0872005 Test Loss: 0.0996057\n",
      "Validation loss decreased (0.087450 --> 0.087201).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0723982\n",
      "\tspeed: 0.0974s/iter; left time: 1880.8414s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762133\n",
      "\tspeed: 0.0556s/iter; left time: 1067.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0728184 Vali Loss: 0.0872517 Test Loss: 0.0992832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731171\n",
      "\tspeed: 0.0971s/iter; left time: 1853.1380s\n",
      "\titers: 200, epoch: 15 | loss: 0.0741022\n",
      "\tspeed: 0.0555s/iter; left time: 1053.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0726241 Vali Loss: 0.0870855 Test Loss: 0.0991462\n",
      "Validation loss decreased (0.087201 --> 0.087085).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0750456\n",
      "\tspeed: 0.0963s/iter; left time: 1816.6623s\n",
      "\titers: 200, epoch: 16 | loss: 0.0713072\n",
      "\tspeed: 0.0555s/iter; left time: 1040.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0724411 Vali Loss: 0.0871672 Test Loss: 0.0994019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0668869\n",
      "\tspeed: 0.0966s/iter; left time: 1800.4650s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713389\n",
      "\tspeed: 0.0555s/iter; left time: 1029.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0723312 Vali Loss: 0.0871781 Test Loss: 0.0993513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706983\n",
      "\tspeed: 0.0959s/iter; left time: 1766.2521s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748784\n",
      "\tspeed: 0.0555s/iter; left time: 1016.2035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0721220 Vali Loss: 0.0872997 Test Loss: 0.0990167\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0700274\n",
      "\tspeed: 0.0962s/iter; left time: 1750.2997s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744739\n",
      "\tspeed: 0.0554s/iter; left time: 1002.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0720195 Vali Loss: 0.0869263 Test Loss: 0.0991538\n",
      "Validation loss decreased (0.087085 --> 0.086926).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791809\n",
      "\tspeed: 0.0968s/iter; left time: 1739.6417s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694202\n",
      "\tspeed: 0.0555s/iter; left time: 991.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0719323 Vali Loss: 0.0870747 Test Loss: 0.0990399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0741944\n",
      "\tspeed: 0.0967s/iter; left time: 1715.2873s\n",
      "\titers: 200, epoch: 21 | loss: 0.0745496\n",
      "\tspeed: 0.0555s/iter; left time: 979.4937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0719164 Vali Loss: 0.0870800 Test Loss: 0.0990365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0724013\n",
      "\tspeed: 0.0970s/iter; left time: 1699.3488s\n",
      "\titers: 200, epoch: 22 | loss: 0.0665953\n",
      "\tspeed: 0.0555s/iter; left time: 967.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 223 | Train Loss: 0.0718348 Vali Loss: 0.0870564 Test Loss: 0.0989102\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0713616\n",
      "\tspeed: 0.0960s/iter; left time: 1660.6828s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664531\n",
      "\tspeed: 0.0555s/iter; left time: 954.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0717544 Vali Loss: 0.0869851 Test Loss: 0.0988903\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0733751\n",
      "\tspeed: 0.0972s/iter; left time: 1659.7551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768953\n",
      "\tspeed: 0.0555s/iter; left time: 942.4096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0716118 Vali Loss: 0.0870040 Test Loss: 0.0988361\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0696853\n",
      "\tspeed: 0.0961s/iter; left time: 1618.8960s\n",
      "\titers: 200, epoch: 25 | loss: 0.0754574\n",
      "\tspeed: 0.0556s/iter; left time: 930.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0715513 Vali Loss: 0.0869943 Test Loss: 0.0989808\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0709983\n",
      "\tspeed: 0.0962s/iter; left time: 1599.8028s\n",
      "\titers: 200, epoch: 26 | loss: 0.0676465\n",
      "\tspeed: 0.0555s/iter; left time: 917.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0714881 Vali Loss: 0.0869537 Test Loss: 0.0987807\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0693488\n",
      "\tspeed: 0.0959s/iter; left time: 1573.5555s\n",
      "\titers: 200, epoch: 27 | loss: 0.0711039\n",
      "\tspeed: 0.0555s/iter; left time: 904.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 223 | Train Loss: 0.0713989 Vali Loss: 0.0868826 Test Loss: 0.0987545\n",
      "Validation loss decreased (0.086926 --> 0.086883).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0756186\n",
      "\tspeed: 0.0977s/iter; left time: 1580.8555s\n",
      "\titers: 200, epoch: 28 | loss: 0.0743463\n",
      "\tspeed: 0.0557s/iter; left time: 895.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 223 | Train Loss: 0.0714247 Vali Loss: 0.0867862 Test Loss: 0.0988359\n",
      "Validation loss decreased (0.086883 --> 0.086786).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0710060\n",
      "\tspeed: 0.0968s/iter; left time: 1544.3542s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695662\n",
      "\tspeed: 0.0556s/iter; left time: 882.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0714264 Vali Loss: 0.0868562 Test Loss: 0.0987503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701287\n",
      "\tspeed: 0.0963s/iter; left time: 1515.0535s\n",
      "\titers: 200, epoch: 30 | loss: 0.0757296\n",
      "\tspeed: 0.0555s/iter; left time: 867.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0713372 Vali Loss: 0.0867431 Test Loss: 0.0987461\n",
      "Validation loss decreased (0.086786 --> 0.086743).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0701553\n",
      "\tspeed: 0.0968s/iter; left time: 1502.2116s\n",
      "\titers: 200, epoch: 31 | loss: 0.0727991\n",
      "\tspeed: 0.0557s/iter; left time: 858.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 223 | Train Loss: 0.0712994 Vali Loss: 0.0868837 Test Loss: 0.0987813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0733458\n",
      "\tspeed: 0.0965s/iter; left time: 1474.7947s\n",
      "\titers: 200, epoch: 32 | loss: 0.0694019\n",
      "\tspeed: 0.0556s/iter; left time: 844.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 223 | Train Loss: 0.0713098 Vali Loss: 0.0868881 Test Loss: 0.0988373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0712834\n",
      "\tspeed: 0.0961s/iter; left time: 1448.3921s\n",
      "\titers: 200, epoch: 33 | loss: 0.0688486\n",
      "\tspeed: 0.0555s/iter; left time: 830.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0712188 Vali Loss: 0.0868297 Test Loss: 0.0987804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0690468\n",
      "\tspeed: 0.0959s/iter; left time: 1422.8061s\n",
      "\titers: 200, epoch: 34 | loss: 0.0661724\n",
      "\tspeed: 0.0555s/iter; left time: 818.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 223 | Train Loss: 0.0712138 Vali Loss: 0.0868261 Test Loss: 0.0987904\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0734023\n",
      "\tspeed: 0.0965s/iter; left time: 1410.8276s\n",
      "\titers: 200, epoch: 35 | loss: 0.0691267\n",
      "\tspeed: 0.0554s/iter; left time: 805.0715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711909 Vali Loss: 0.0868607 Test Loss: 0.0987801\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0676273\n",
      "\tspeed: 0.0962s/iter; left time: 1384.2812s\n",
      "\titers: 200, epoch: 36 | loss: 0.0762189\n",
      "\tspeed: 0.0555s/iter; left time: 794.1158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0712222 Vali Loss: 0.0868300 Test Loss: 0.0987861\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0705356\n",
      "\tspeed: 0.0967s/iter; left time: 1370.1689s\n",
      "\titers: 200, epoch: 37 | loss: 0.0708427\n",
      "\tspeed: 0.0555s/iter; left time: 781.1515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711363 Vali Loss: 0.0867921 Test Loss: 0.0988260\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0765347\n",
      "\tspeed: 0.0962s/iter; left time: 1341.3558s\n",
      "\titers: 200, epoch: 38 | loss: 0.0721635\n",
      "\tspeed: 0.0555s/iter; left time: 768.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.0711380 Vali Loss: 0.0868325 Test Loss: 0.0988323\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0716699\n",
      "\tspeed: 0.0969s/iter; left time: 1330.4072s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682490\n",
      "\tspeed: 0.0556s/iter; left time: 757.6486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 223 | Train Loss: 0.0710949 Vali Loss: 0.0868223 Test Loss: 0.0987682\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0706478\n",
      "\tspeed: 0.0961s/iter; left time: 1298.0829s\n",
      "\titers: 200, epoch: 40 | loss: 0.0696950\n",
      "\tspeed: 0.0555s/iter; left time: 743.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 223 | Train Loss: 0.0711050 Vali Loss: 0.0869668 Test Loss: 0.0987652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02454490214586258, rmse:0.15666812658309937, mae:0.09874614328145981, rse:0.5404606461524963\n",
      "Intermediate time for GB and pred_len 24: 00h:22m:41.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1306827\n",
      "\tspeed: 0.0737s/iter; left time: 1627.9731s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177318\n",
      "\tspeed: 0.0562s/iter; left time: 1236.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 222 | Train Loss: 0.1310412 Vali Loss: 0.1288174 Test Loss: 0.1522436\n",
      "Validation loss decreased (inf --> 0.128817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1066177\n",
      "\tspeed: 0.0998s/iter; left time: 2183.2131s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095714\n",
      "\tspeed: 0.0562s/iter; left time: 1224.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1078968 Vali Loss: 0.1167912 Test Loss: 0.1385723\n",
      "Validation loss decreased (0.128817 --> 0.116791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1022676\n",
      "\tspeed: 0.0989s/iter; left time: 2141.9155s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059308\n",
      "\tspeed: 0.0562s/iter; left time: 1211.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1029695 Vali Loss: 0.1158236 Test Loss: 0.1393959\n",
      "Validation loss decreased (0.116791 --> 0.115824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0960328\n",
      "\tspeed: 0.0999s/iter; left time: 2141.3581s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025381\n",
      "\tspeed: 0.0560s/iter; left time: 1194.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1014715 Vali Loss: 0.1154466 Test Loss: 0.1393613\n",
      "Validation loss decreased (0.115824 --> 0.115447).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026418\n",
      "\tspeed: 0.0990s/iter; left time: 2099.4794s\n",
      "\titers: 200, epoch: 5 | loss: 0.1024776\n",
      "\tspeed: 0.0560s/iter; left time: 1181.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1004793 Vali Loss: 0.1146312 Test Loss: 0.1378396\n",
      "Validation loss decreased (0.115447 --> 0.114631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0979286\n",
      "\tspeed: 0.0992s/iter; left time: 2081.7530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994375\n",
      "\tspeed: 0.0561s/iter; left time: 1172.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.68s\n",
      "Steps: 222 | Train Loss: 0.0995605 Vali Loss: 0.1148999 Test Loss: 0.1380830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0970419\n",
      "\tspeed: 0.0987s/iter; left time: 2049.6012s\n",
      "\titers: 200, epoch: 7 | loss: 0.0962363\n",
      "\tspeed: 0.0560s/iter; left time: 1157.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0987005 Vali Loss: 0.1152062 Test Loss: 0.1379218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0996104\n",
      "\tspeed: 0.0982s/iter; left time: 2017.8896s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979448\n",
      "\tspeed: 0.0559s/iter; left time: 1142.7453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 222 | Train Loss: 0.0980342 Vali Loss: 0.1154223 Test Loss: 0.1376054\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0958485\n",
      "\tspeed: 0.0991s/iter; left time: 2014.7033s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965145\n",
      "\tspeed: 0.0615s/iter; left time: 1244.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.21s\n",
      "Steps: 222 | Train Loss: 0.0972717 Vali Loss: 0.1154799 Test Loss: 0.1370620\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954895\n",
      "\tspeed: 0.6275s/iter; left time: 12615.0912s\n",
      "\titers: 200, epoch: 10 | loss: 0.0944765\n",
      "\tspeed: 0.1997s/iter; left time: 3994.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.62s\n",
      "Steps: 222 | Train Loss: 0.0966941 Vali Loss: 0.1156659 Test Loss: 0.1384369\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0955338\n",
      "\tspeed: 0.1835s/iter; left time: 3648.6977s\n",
      "\titers: 200, epoch: 11 | loss: 0.0942479\n",
      "\tspeed: 0.0563s/iter; left time: 1112.7131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 222 | Train Loss: 0.0960870 Vali Loss: 0.1158695 Test Loss: 0.1388598\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0913796\n",
      "\tspeed: 0.0982s/iter; left time: 1930.1414s\n",
      "\titers: 200, epoch: 12 | loss: 0.0934490\n",
      "\tspeed: 0.0567s/iter; left time: 1109.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0955488 Vali Loss: 0.1158540 Test Loss: 0.1386886\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0921230\n",
      "\tspeed: 0.0977s/iter; left time: 1899.7747s\n",
      "\titers: 200, epoch: 13 | loss: 0.0977281\n",
      "\tspeed: 0.0560s/iter; left time: 1083.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 222 | Train Loss: 0.0950370 Vali Loss: 0.1160690 Test Loss: 0.1403026\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0938734\n",
      "\tspeed: 0.0981s/iter; left time: 1885.5387s\n",
      "\titers: 200, epoch: 14 | loss: 0.0945882\n",
      "\tspeed: 0.0561s/iter; left time: 1071.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0945816 Vali Loss: 0.1165808 Test Loss: 0.1402343\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0991733\n",
      "\tspeed: 0.0988s/iter; left time: 1877.2304s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967700\n",
      "\tspeed: 0.0561s/iter; left time: 1059.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0940588 Vali Loss: 0.1163656 Test Loss: 0.1410571\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04015038162469864, rmse:0.20037560164928436, mae:0.13783958554267883, rse:0.6929267048835754\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1303071\n",
      "\tspeed: 0.0615s/iter; left time: 1358.7608s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283034\n",
      "\tspeed: 0.0562s/iter; left time: 1236.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 222 | Train Loss: 0.1310060 Vali Loss: 0.1287630 Test Loss: 0.1517619\n",
      "Validation loss decreased (inf --> 0.128763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1048923\n",
      "\tspeed: 0.0999s/iter; left time: 2185.0535s\n",
      "\titers: 200, epoch: 2 | loss: 0.1013105\n",
      "\tspeed: 0.0560s/iter; left time: 1220.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1080856 Vali Loss: 0.1171368 Test Loss: 0.1385304\n",
      "Validation loss decreased (0.128763 --> 0.117137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1040064\n",
      "\tspeed: 0.0983s/iter; left time: 2128.0664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0998071\n",
      "\tspeed: 0.0560s/iter; left time: 1208.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 222 | Train Loss: 0.1030684 Vali Loss: 0.1154471 Test Loss: 0.1375951\n",
      "Validation loss decreased (0.117137 --> 0.115447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053156\n",
      "\tspeed: 0.3820s/iter; left time: 8187.8691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008415\n",
      "\tspeed: 0.0589s/iter; left time: 1257.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.1016380 Vali Loss: 0.1151421 Test Loss: 0.1379311\n",
      "Validation loss decreased (0.115447 --> 0.115142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0987126\n",
      "\tspeed: 0.0994s/iter; left time: 2107.6234s\n",
      "\titers: 200, epoch: 5 | loss: 0.0972618\n",
      "\tspeed: 0.0691s/iter; left time: 1458.8311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.43s\n",
      "Steps: 222 | Train Loss: 0.1004928 Vali Loss: 0.1147536 Test Loss: 0.1380800\n",
      "Validation loss decreased (0.115142 --> 0.114754).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1012318\n",
      "\tspeed: 0.6444s/iter; left time: 13526.0305s\n",
      "\titers: 200, epoch: 6 | loss: 0.0969684\n",
      "\tspeed: 0.1934s/iter; left time: 4040.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.55s\n",
      "Steps: 222 | Train Loss: 0.0993943 Vali Loss: 0.1148224 Test Loss: 0.1386869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0970156\n",
      "\tspeed: 0.1453s/iter; left time: 3018.6714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0988887\n",
      "\tspeed: 0.0560s/iter; left time: 1158.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 222 | Train Loss: 0.0985187 Vali Loss: 0.1149543 Test Loss: 0.1399635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0929216\n",
      "\tspeed: 0.0985s/iter; left time: 2023.5995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0935230\n",
      "\tspeed: 0.0568s/iter; left time: 1162.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 222 | Train Loss: 0.0974779 Vali Loss: 0.1147359 Test Loss: 0.1398059\n",
      "Validation loss decreased (0.114754 --> 0.114736).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0948713\n",
      "\tspeed: 0.1010s/iter; left time: 2053.3036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0958109\n",
      "\tspeed: 0.0566s/iter; left time: 1144.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 222 | Train Loss: 0.0966486 Vali Loss: 0.1154781 Test Loss: 0.1414918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0992346\n",
      "\tspeed: 0.0998s/iter; left time: 2005.2822s\n",
      "\titers: 200, epoch: 10 | loss: 0.0941390\n",
      "\tspeed: 0.0561s/iter; left time: 1121.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.0958207 Vali Loss: 0.1155172 Test Loss: 0.1409567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0913739\n",
      "\tspeed: 0.0985s/iter; left time: 1958.4105s\n",
      "\titers: 200, epoch: 11 | loss: 0.0964964\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0951955 Vali Loss: 0.1160658 Test Loss: 0.1419416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966781\n",
      "\tspeed: 0.0999s/iter; left time: 1963.4582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0935920\n",
      "\tspeed: 0.0560s/iter; left time: 1095.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 222 | Train Loss: 0.0943973 Vali Loss: 0.1160687 Test Loss: 0.1421239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0959323\n",
      "\tspeed: 0.0984s/iter; left time: 1912.5597s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973188\n",
      "\tspeed: 0.0562s/iter; left time: 1086.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 222 | Train Loss: 0.0938334 Vali Loss: 0.1156196 Test Loss: 0.1408184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0913993\n",
      "\tspeed: 0.1000s/iter; left time: 1921.0940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937971\n",
      "\tspeed: 0.0560s/iter; left time: 1070.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.05s\n",
      "Steps: 222 | Train Loss: 0.0932455 Vali Loss: 0.1158227 Test Loss: 0.1420476\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0968988\n",
      "\tspeed: 0.3754s/iter; left time: 7129.8569s\n",
      "\titers: 200, epoch: 15 | loss: 0.0916217\n",
      "\tspeed: 0.0633s/iter; left time: 1195.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 222 | Train Loss: 0.0927197 Vali Loss: 0.1161066 Test Loss: 0.1418097\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0897948\n",
      "\tspeed: 0.1000s/iter; left time: 1876.2781s\n",
      "\titers: 200, epoch: 16 | loss: 0.0920113\n",
      "\tspeed: 0.0822s/iter; left time: 1534.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.04s\n",
      "Steps: 222 | Train Loss: 0.0922969 Vali Loss: 0.1167289 Test Loss: 0.1427078\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0914260\n",
      "\tspeed: 0.6881s/iter; left time: 12762.8375s\n",
      "\titers: 200, epoch: 17 | loss: 0.0921046\n",
      "\tspeed: 0.1896s/iter; left time: 3498.6136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:44.62s\n",
      "Steps: 222 | Train Loss: 0.0918778 Vali Loss: 0.1167830 Test Loss: 0.1428674\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878626\n",
      "\tspeed: 0.5708s/iter; left time: 10461.8958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0943621\n",
      "\tspeed: 0.0735s/iter; left time: 1339.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:23.58s\n",
      "Steps: 222 | Train Loss: 0.0915997 Vali Loss: 0.1168165 Test Loss: 0.1414241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041960179805755615, rmse:0.20484183728694916, mae:0.1398058831691742, rse:0.708371639251709\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:16.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1260773\n",
      "\tspeed: 0.0773s/iter; left time: 1709.3037s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229722\n",
      "\tspeed: 0.0571s/iter; left time: 1255.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.22s\n",
      "Steps: 222 | Train Loss: 0.1327026 Vali Loss: 0.1309201 Test Loss: 0.1548616\n",
      "Validation loss decreased (inf --> 0.130920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093555\n",
      "\tspeed: 0.1009s/iter; left time: 2206.9556s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087653\n",
      "\tspeed: 0.0565s/iter; left time: 1230.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 222 | Train Loss: 0.1121223 Vali Loss: 0.1213975 Test Loss: 0.1448217\n",
      "Validation loss decreased (0.130920 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089418\n",
      "\tspeed: 0.1006s/iter; left time: 2179.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108851\n",
      "\tspeed: 0.0563s/iter; left time: 1214.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1075883 Vali Loss: 0.1200373 Test Loss: 0.1443896\n",
      "Validation loss decreased (0.121397 --> 0.120037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1100808\n",
      "\tspeed: 0.0998s/iter; left time: 2139.3352s\n",
      "\titers: 200, epoch: 4 | loss: 0.1029688\n",
      "\tspeed: 0.0567s/iter; left time: 1208.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 222 | Train Loss: 0.1060422 Vali Loss: 0.1198486 Test Loss: 0.1441484\n",
      "Validation loss decreased (0.120037 --> 0.119849).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044006\n",
      "\tspeed: 0.0993s/iter; left time: 2105.7861s\n",
      "\titers: 200, epoch: 5 | loss: 0.1066292\n",
      "\tspeed: 0.0564s/iter; left time: 1190.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 222 | Train Loss: 0.1046534 Vali Loss: 0.1206437 Test Loss: 0.1449600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0995353\n",
      "\tspeed: 0.0979s/iter; left time: 2054.9923s\n",
      "\titers: 200, epoch: 6 | loss: 0.1040475\n",
      "\tspeed: 0.0563s/iter; left time: 1176.3104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1034120 Vali Loss: 0.1211787 Test Loss: 0.1452242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1019453\n",
      "\tspeed: 0.0970s/iter; left time: 2014.0747s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026548\n",
      "\tspeed: 0.0563s/iter; left time: 1162.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.1023776 Vali Loss: 0.1218576 Test Loss: 0.1468516\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994126\n",
      "\tspeed: 0.0974s/iter; left time: 2000.8456s\n",
      "\titers: 200, epoch: 8 | loss: 0.0971872\n",
      "\tspeed: 0.0562s/iter; left time: 1148.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1013684 Vali Loss: 0.1218202 Test Loss: 0.1467308\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008324\n",
      "\tspeed: 0.0978s/iter; left time: 1987.1658s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001003\n",
      "\tspeed: 0.0561s/iter; left time: 1135.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.1004547 Vali Loss: 0.1227126 Test Loss: 0.1460044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0981952\n",
      "\tspeed: 0.0970s/iter; left time: 1950.1614s\n",
      "\titers: 200, epoch: 10 | loss: 0.1011151\n",
      "\tspeed: 0.0562s/iter; left time: 1124.2371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0996076 Vali Loss: 0.1219485 Test Loss: 0.1458998\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022985\n",
      "\tspeed: 0.0968s/iter; left time: 1924.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0971800\n",
      "\tspeed: 0.0562s/iter; left time: 1112.3330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.63s\n",
      "Steps: 222 | Train Loss: 0.0987144 Vali Loss: 0.1226570 Test Loss: 0.1463754\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019033\n",
      "\tspeed: 0.0973s/iter; left time: 1912.4186s\n",
      "\titers: 200, epoch: 12 | loss: 0.0964095\n",
      "\tspeed: 0.0562s/iter; left time: 1100.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.0978685 Vali Loss: 0.1225567 Test Loss: 0.1457474\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0953344\n",
      "\tspeed: 0.0966s/iter; left time: 1878.4410s\n",
      "\titers: 200, epoch: 13 | loss: 0.0992721\n",
      "\tspeed: 0.0562s/iter; left time: 1087.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0971082 Vali Loss: 0.1227023 Test Loss: 0.1472565\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0926120\n",
      "\tspeed: 0.0967s/iter; left time: 1858.5787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0951313\n",
      "\tspeed: 0.0562s/iter; left time: 1074.8672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 222 | Train Loss: 0.0964137 Vali Loss: 0.1233526 Test Loss: 0.1470043\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042849574238061905, rmse:0.20700138807296753, mae:0.14414843916893005, rse:0.7177035808563232\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354991\n",
      "\tspeed: 0.0578s/iter; left time: 1278.1000s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270298\n",
      "\tspeed: 0.0562s/iter; left time: 1235.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1335611 Vali Loss: 0.1309445 Test Loss: 0.1545844\n",
      "Validation loss decreased (inf --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1133388\n",
      "\tspeed: 0.0999s/iter; left time: 2186.3013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1125569\n",
      "\tspeed: 0.0562s/iter; left time: 1224.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1122486 Vali Loss: 0.1214251 Test Loss: 0.1446685\n",
      "Validation loss decreased (0.130944 --> 0.121425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1068718\n",
      "\tspeed: 0.0986s/iter; left time: 2135.8821s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110569\n",
      "\tspeed: 0.0562s/iter; left time: 1211.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.1077239 Vali Loss: 0.1201799 Test Loss: 0.1456124\n",
      "Validation loss decreased (0.121425 --> 0.120180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068212\n",
      "\tspeed: 0.0992s/iter; left time: 2126.1356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1060848\n",
      "\tspeed: 0.0562s/iter; left time: 1199.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 222 | Train Loss: 0.1062277 Vali Loss: 0.1203073 Test Loss: 0.1457645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1072107\n",
      "\tspeed: 0.0976s/iter; left time: 2071.3545s\n",
      "\titers: 200, epoch: 5 | loss: 0.1050748\n",
      "\tspeed: 0.0562s/iter; left time: 1187.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1048063 Vali Loss: 0.1204287 Test Loss: 0.1452082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1055551\n",
      "\tspeed: 0.0977s/iter; left time: 2050.0902s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049092\n",
      "\tspeed: 0.0562s/iter; left time: 1174.0853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.1034492 Vali Loss: 0.1209216 Test Loss: 0.1464381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1012986\n",
      "\tspeed: 0.0978s/iter; left time: 2031.0061s\n",
      "\titers: 200, epoch: 7 | loss: 0.0988212\n",
      "\tspeed: 0.0562s/iter; left time: 1161.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1020838 Vali Loss: 0.1218336 Test Loss: 0.1478448\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1025517\n",
      "\tspeed: 0.0974s/iter; left time: 2001.2240s\n",
      "\titers: 200, epoch: 8 | loss: 0.1005487\n",
      "\tspeed: 0.0562s/iter; left time: 1148.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 222 | Train Loss: 0.1008029 Vali Loss: 0.1223594 Test Loss: 0.1472702\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0975043\n",
      "\tspeed: 0.0974s/iter; left time: 1979.6024s\n",
      "\titers: 200, epoch: 9 | loss: 0.0961284\n",
      "\tspeed: 0.0562s/iter; left time: 1137.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0996357 Vali Loss: 0.1229091 Test Loss: 0.1470626\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0974637\n",
      "\tspeed: 0.0974s/iter; left time: 1957.4357s\n",
      "\titers: 200, epoch: 10 | loss: 0.0978937\n",
      "\tspeed: 0.0562s/iter; left time: 1124.2371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0983070 Vali Loss: 0.1235878 Test Loss: 0.1470104\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0942716\n",
      "\tspeed: 0.0973s/iter; left time: 1935.1333s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986272\n",
      "\tspeed: 0.0562s/iter; left time: 1112.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0972591 Vali Loss: 0.1241986 Test Loss: 0.1483821\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0955178\n",
      "\tspeed: 0.0972s/iter; left time: 1911.0378s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003032\n",
      "\tspeed: 0.0562s/iter; left time: 1100.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 222 | Train Loss: 0.0963243 Vali Loss: 0.1242227 Test Loss: 0.1486393\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0958638\n",
      "\tspeed: 0.0974s/iter; left time: 1894.0650s\n",
      "\titers: 200, epoch: 13 | loss: 0.0918685\n",
      "\tspeed: 0.0563s/iter; left time: 1087.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 222 | Train Loss: 0.0954410 Vali Loss: 0.1246279 Test Loss: 0.1481834\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04403311014175415, rmse:0.20984068512916565, mae:0.145612433552742, rse:0.7275477647781372\n",
      "Intermediate time for GB and pred_len 168: 00h:07m:10.11s\n",
      "Intermediate time for GB: 00h:44m:08.61s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1175637\n",
      "\tspeed: 0.0539s/iter; left time: 1197.6987s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060088\n",
      "\tspeed: 0.0349s/iter; left time: 770.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 223 | Train Loss: 0.1258741 Vali Loss: 0.0934121 Test Loss: 0.1067465\n",
      "Validation loss decreased (inf --> 0.093412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0715940\n",
      "\tspeed: 0.0640s/iter; left time: 1405.7288s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685092\n",
      "\tspeed: 0.0349s/iter; left time: 762.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0747378 Vali Loss: 0.0624876 Test Loss: 0.0695573\n",
      "Validation loss decreased (0.093412 --> 0.062488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635684\n",
      "\tspeed: 0.0649s/iter; left time: 1412.1529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0621238\n",
      "\tspeed: 0.0349s/iter; left time: 754.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0643560 Vali Loss: 0.0598924 Test Loss: 0.0667066\n",
      "Validation loss decreased (0.062488 --> 0.059892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0643697\n",
      "\tspeed: 0.0639s/iter; left time: 1376.3862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0598484\n",
      "\tspeed: 0.0349s/iter; left time: 747.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0616906 Vali Loss: 0.0581373 Test Loss: 0.0651106\n",
      "Validation loss decreased (0.059892 --> 0.058137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0595916\n",
      "\tspeed: 0.0639s/iter; left time: 1361.1248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612903\n",
      "\tspeed: 0.0349s/iter; left time: 740.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0598992 Vali Loss: 0.0570621 Test Loss: 0.0634679\n",
      "Validation loss decreased (0.058137 --> 0.057062).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566540\n",
      "\tspeed: 0.0640s/iter; left time: 1350.0472s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576317\n",
      "\tspeed: 0.0348s/iter; left time: 730.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0587601 Vali Loss: 0.0561196 Test Loss: 0.0627356\n",
      "Validation loss decreased (0.057062 --> 0.056120).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0537630\n",
      "\tspeed: 0.0642s/iter; left time: 1338.9650s\n",
      "\titers: 200, epoch: 7 | loss: 0.0569170\n",
      "\tspeed: 0.0348s/iter; left time: 722.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0579201 Vali Loss: 0.0557699 Test Loss: 0.0623582\n",
      "Validation loss decreased (0.056120 --> 0.055770).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542791\n",
      "\tspeed: 0.0642s/iter; left time: 1325.0179s\n",
      "\titers: 200, epoch: 8 | loss: 0.0535772\n",
      "\tspeed: 0.0348s/iter; left time: 715.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0571417 Vali Loss: 0.0554661 Test Loss: 0.0623493\n",
      "Validation loss decreased (0.055770 --> 0.055466).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552964\n",
      "\tspeed: 0.0636s/iter; left time: 1297.8393s\n",
      "\titers: 200, epoch: 9 | loss: 0.0563664\n",
      "\tspeed: 0.0348s/iter; left time: 707.5805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0565837 Vali Loss: 0.0556016 Test Loss: 0.0629203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570711\n",
      "\tspeed: 0.0634s/iter; left time: 1280.1725s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551535\n",
      "\tspeed: 0.0348s/iter; left time: 699.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0560324 Vali Loss: 0.0548921 Test Loss: 0.0620095\n",
      "Validation loss decreased (0.055466 --> 0.054892).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0551980\n",
      "\tspeed: 0.0639s/iter; left time: 1276.4136s\n",
      "\titers: 200, epoch: 11 | loss: 0.0572951\n",
      "\tspeed: 0.0348s/iter; left time: 692.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0556399 Vali Loss: 0.0546968 Test Loss: 0.0617010\n",
      "Validation loss decreased (0.054892 --> 0.054697).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0568327\n",
      "\tspeed: 0.0644s/iter; left time: 1270.9269s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558428\n",
      "\tspeed: 0.0349s/iter; left time: 685.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0552164 Vali Loss: 0.0544590 Test Loss: 0.0614751\n",
      "Validation loss decreased (0.054697 --> 0.054459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0542535\n",
      "\tspeed: 0.0641s/iter; left time: 1251.9684s\n",
      "\titers: 200, epoch: 13 | loss: 0.0545616\n",
      "\tspeed: 0.0348s/iter; left time: 676.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0549488 Vali Loss: 0.0545881 Test Loss: 0.0614434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523805\n",
      "\tspeed: 0.0629s/iter; left time: 1213.4130s\n",
      "\titers: 200, epoch: 14 | loss: 0.0542101\n",
      "\tspeed: 0.0349s/iter; left time: 669.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0546171 Vali Loss: 0.0541874 Test Loss: 0.0611198\n",
      "Validation loss decreased (0.054459 --> 0.054187).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0497755\n",
      "\tspeed: 0.0640s/iter; left time: 1220.7282s\n",
      "\titers: 200, epoch: 15 | loss: 0.0600670\n",
      "\tspeed: 0.0349s/iter; left time: 662.4437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0543438 Vali Loss: 0.0538917 Test Loss: 0.0610247\n",
      "Validation loss decreased (0.054187 --> 0.053892).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0559755\n",
      "\tspeed: 0.0640s/iter; left time: 1206.6236s\n",
      "\titers: 200, epoch: 16 | loss: 0.0507899\n",
      "\tspeed: 0.0348s/iter; left time: 653.3455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0541344 Vali Loss: 0.0536988 Test Loss: 0.0605547\n",
      "Validation loss decreased (0.053892 --> 0.053699).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0569965\n",
      "\tspeed: 0.0658s/iter; left time: 1226.5335s\n",
      "\titers: 200, epoch: 17 | loss: 0.0506428\n",
      "\tspeed: 0.0348s/iter; left time: 644.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0539298 Vali Loss: 0.0534636 Test Loss: 0.0604280\n",
      "Validation loss decreased (0.053699 --> 0.053464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0565841\n",
      "\tspeed: 0.0639s/iter; left time: 1176.2585s\n",
      "\titers: 200, epoch: 18 | loss: 0.0540568\n",
      "\tspeed: 0.0348s/iter; left time: 636.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0537874 Vali Loss: 0.0535432 Test Loss: 0.0605775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0548989\n",
      "\tspeed: 0.0634s/iter; left time: 1153.7619s\n",
      "\titers: 200, epoch: 19 | loss: 0.0527071\n",
      "\tspeed: 0.0347s/iter; left time: 628.4186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0535218 Vali Loss: 0.0535281 Test Loss: 0.0603313\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0550305\n",
      "\tspeed: 0.0634s/iter; left time: 1138.6081s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543642\n",
      "\tspeed: 0.0347s/iter; left time: 620.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0534504 Vali Loss: 0.0532689 Test Loss: 0.0604245\n",
      "Validation loss decreased (0.053464 --> 0.053269).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0523972\n",
      "\tspeed: 0.0642s/iter; left time: 1139.5554s\n",
      "\titers: 200, epoch: 21 | loss: 0.0529216\n",
      "\tspeed: 0.0348s/iter; left time: 614.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0532740 Vali Loss: 0.0531319 Test Loss: 0.0601385\n",
      "Validation loss decreased (0.053269 --> 0.053132).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0521433\n",
      "\tspeed: 0.0634s/iter; left time: 1110.0221s\n",
      "\titers: 200, epoch: 22 | loss: 0.0547027\n",
      "\tspeed: 0.0348s/iter; left time: 605.8963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0532038 Vali Loss: 0.0531704 Test Loss: 0.0603939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0536981\n",
      "\tspeed: 0.0627s/iter; left time: 1084.6706s\n",
      "\titers: 200, epoch: 23 | loss: 0.0563880\n",
      "\tspeed: 0.0348s/iter; left time: 598.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0531312 Vali Loss: 0.0531458 Test Loss: 0.0602351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0546271\n",
      "\tspeed: 0.0633s/iter; left time: 1080.1650s\n",
      "\titers: 200, epoch: 24 | loss: 0.0504135\n",
      "\tspeed: 0.0348s/iter; left time: 590.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0529921 Vali Loss: 0.0530581 Test Loss: 0.0600498\n",
      "Validation loss decreased (0.053132 --> 0.053058).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0553383\n",
      "\tspeed: 0.0641s/iter; left time: 1080.2681s\n",
      "\titers: 200, epoch: 25 | loss: 0.0518673\n",
      "\tspeed: 0.0348s/iter; left time: 582.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0528590 Vali Loss: 0.0530624 Test Loss: 0.0601539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0514446\n",
      "\tspeed: 0.0636s/iter; left time: 1057.3343s\n",
      "\titers: 200, epoch: 26 | loss: 0.0503461\n",
      "\tspeed: 0.0348s/iter; left time: 574.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0528106 Vali Loss: 0.0528923 Test Loss: 0.0600861\n",
      "Validation loss decreased (0.053058 --> 0.052892).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517057\n",
      "\tspeed: 0.0634s/iter; left time: 1039.4872s\n",
      "\titers: 200, epoch: 27 | loss: 0.0537945\n",
      "\tspeed: 0.0348s/iter; left time: 566.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0528068 Vali Loss: 0.0531387 Test Loss: 0.0601630\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0525555\n",
      "\tspeed: 0.0632s/iter; left time: 1022.5375s\n",
      "\titers: 200, epoch: 28 | loss: 0.0549811\n",
      "\tspeed: 0.0348s/iter; left time: 559.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0526904 Vali Loss: 0.0528783 Test Loss: 0.0598450\n",
      "Validation loss decreased (0.052892 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0500230\n",
      "\tspeed: 0.0638s/iter; left time: 1018.3266s\n",
      "\titers: 200, epoch: 29 | loss: 0.0551892\n",
      "\tspeed: 0.0348s/iter; left time: 552.4548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0526697 Vali Loss: 0.0527954 Test Loss: 0.0598333\n",
      "Validation loss decreased (0.052878 --> 0.052795).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0544261\n",
      "\tspeed: 0.0637s/iter; left time: 1001.4913s\n",
      "\titers: 200, epoch: 30 | loss: 0.0517382\n",
      "\tspeed: 0.0348s/iter; left time: 543.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0526079 Vali Loss: 0.0527942 Test Loss: 0.0599940\n",
      "Validation loss decreased (0.052795 --> 0.052794).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509290\n",
      "\tspeed: 0.0648s/iter; left time: 1005.2482s\n",
      "\titers: 200, epoch: 31 | loss: 0.0522115\n",
      "\tspeed: 0.0347s/iter; left time: 535.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0525354 Vali Loss: 0.0528468 Test Loss: 0.0600238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0518514\n",
      "\tspeed: 0.0632s/iter; left time: 966.6202s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561669\n",
      "\tspeed: 0.0348s/iter; left time: 528.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0525267 Vali Loss: 0.0528122 Test Loss: 0.0600026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549385\n",
      "\tspeed: 0.0635s/iter; left time: 956.5434s\n",
      "\titers: 200, epoch: 33 | loss: 0.0550187\n",
      "\tspeed: 0.0347s/iter; left time: 519.9973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0524861 Vali Loss: 0.0527625 Test Loss: 0.0598903\n",
      "Validation loss decreased (0.052794 --> 0.052763).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0545956\n",
      "\tspeed: 0.0640s/iter; left time: 950.3746s\n",
      "\titers: 200, epoch: 34 | loss: 0.0507859\n",
      "\tspeed: 0.0347s/iter; left time: 512.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0524479 Vali Loss: 0.0527562 Test Loss: 0.0599022\n",
      "Validation loss decreased (0.052763 --> 0.052756).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0541387\n",
      "\tspeed: 0.0636s/iter; left time: 929.6086s\n",
      "\titers: 200, epoch: 35 | loss: 0.0549738\n",
      "\tspeed: 0.0348s/iter; left time: 505.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0524044 Vali Loss: 0.0526615 Test Loss: 0.0598362\n",
      "Validation loss decreased (0.052756 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545615\n",
      "\tspeed: 0.0638s/iter; left time: 917.7742s\n",
      "\titers: 200, epoch: 36 | loss: 0.0542032\n",
      "\tspeed: 0.0348s/iter; left time: 497.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0523493 Vali Loss: 0.0526948 Test Loss: 0.0597999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0499858\n",
      "\tspeed: 0.0633s/iter; left time: 897.6538s\n",
      "\titers: 200, epoch: 37 | loss: 0.0523338\n",
      "\tspeed: 0.0348s/iter; left time: 489.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0523323 Vali Loss: 0.0526763 Test Loss: 0.0599144\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0525568\n",
      "\tspeed: 0.0631s/iter; left time: 879.5964s\n",
      "\titers: 200, epoch: 38 | loss: 0.0531557\n",
      "\tspeed: 0.0348s/iter; left time: 481.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523191 Vali Loss: 0.0528053 Test Loss: 0.0598900\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0517309\n",
      "\tspeed: 0.0632s/iter; left time: 867.8943s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516564\n",
      "\tspeed: 0.0348s/iter; left time: 474.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522917 Vali Loss: 0.0527077 Test Loss: 0.0598312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0536129\n",
      "\tspeed: 0.0633s/iter; left time: 855.3285s\n",
      "\titers: 200, epoch: 40 | loss: 0.0507274\n",
      "\tspeed: 0.0347s/iter; left time: 465.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0523048 Vali Loss: 0.0527075 Test Loss: 0.0598177\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530339\n",
      "\tspeed: 0.0636s/iter; left time: 844.5963s\n",
      "\titers: 200, epoch: 41 | loss: 0.0536149\n",
      "\tspeed: 0.0347s/iter; left time: 457.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0523129 Vali Loss: 0.0526658 Test Loss: 0.0599047\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0494002\n",
      "\tspeed: 0.0631s/iter; left time: 824.4909s\n",
      "\titers: 200, epoch: 42 | loss: 0.0515069\n",
      "\tspeed: 0.0347s/iter; left time: 449.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0522722 Vali Loss: 0.0526509 Test Loss: 0.0598522\n",
      "Validation loss decreased (0.052662 --> 0.052651).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0539627\n",
      "\tspeed: 0.0652s/iter; left time: 837.1283s\n",
      "\titers: 200, epoch: 43 | loss: 0.0533281\n",
      "\tspeed: 0.0348s/iter; left time: 442.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0523110 Vali Loss: 0.0525890 Test Loss: 0.0597770\n",
      "Validation loss decreased (0.052651 --> 0.052589).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0521373\n",
      "\tspeed: 0.0636s/iter; left time: 802.5087s\n",
      "\titers: 200, epoch: 44 | loss: 0.0501604\n",
      "\tspeed: 0.0348s/iter; left time: 435.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522199 Vali Loss: 0.0526631 Test Loss: 0.0598244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0566270\n",
      "\tspeed: 0.0637s/iter; left time: 789.3379s\n",
      "\titers: 200, epoch: 45 | loss: 0.0523463\n",
      "\tspeed: 0.0348s/iter; left time: 427.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522631 Vali Loss: 0.0527159 Test Loss: 0.0598033\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0528714\n",
      "\tspeed: 0.0631s/iter; left time: 767.5373s\n",
      "\titers: 200, epoch: 46 | loss: 0.0532004\n",
      "\tspeed: 0.0348s/iter; left time: 419.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522354 Vali Loss: 0.0526221 Test Loss: 0.0598067\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528335\n",
      "\tspeed: 0.0632s/iter; left time: 755.1653s\n",
      "\titers: 200, epoch: 47 | loss: 0.0564661\n",
      "\tspeed: 0.0347s/iter; left time: 411.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523151 Vali Loss: 0.0526697 Test Loss: 0.0597932\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0519690\n",
      "\tspeed: 0.0634s/iter; left time: 743.0612s\n",
      "\titers: 200, epoch: 48 | loss: 0.0549003\n",
      "\tspeed: 0.0348s/iter; left time: 404.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522235 Vali Loss: 0.0526347 Test Loss: 0.0597990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543164\n",
      "\tspeed: 0.0631s/iter; left time: 725.7057s\n",
      "\titers: 200, epoch: 49 | loss: 0.0473209\n",
      "\tspeed: 0.0347s/iter; left time: 395.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522493 Vali Loss: 0.0526192 Test Loss: 0.0598093\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0499371\n",
      "\tspeed: 0.0632s/iter; left time: 712.6842s\n",
      "\titers: 200, epoch: 50 | loss: 0.0519783\n",
      "\tspeed: 0.0348s/iter; left time: 388.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522329 Vali Loss: 0.0526891 Test Loss: 0.0598834\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0568660\n",
      "\tspeed: 0.0631s/iter; left time: 696.8242s\n",
      "\titers: 200, epoch: 51 | loss: 0.0513868\n",
      "\tspeed: 0.0347s/iter; left time: 380.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522060 Vali Loss: 0.0526809 Test Loss: 0.0598164\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0506357\n",
      "\tspeed: 0.0632s/iter; left time: 684.8435s\n",
      "\titers: 200, epoch: 52 | loss: 0.0513345\n",
      "\tspeed: 0.0348s/iter; left time: 373.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0521876 Vali Loss: 0.0526349 Test Loss: 0.0598106\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0541688\n",
      "\tspeed: 0.0632s/iter; left time: 669.7787s\n",
      "\titers: 200, epoch: 53 | loss: 0.0502305\n",
      "\tspeed: 0.0348s/iter; left time: 365.2347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521811 Vali Loss: 0.0526638 Test Loss: 0.0598178\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009866542182862759, rmse:0.09933046996593475, mae:0.05977698788046837, rse:0.29231756925582886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1220326\n",
      "\tspeed: 0.0364s/iter; left time: 808.0457s\n",
      "\titers: 200, epoch: 1 | loss: 0.1029346\n",
      "\tspeed: 0.0348s/iter; left time: 769.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.1259346 Vali Loss: 0.0930124 Test Loss: 0.1065052\n",
      "Validation loss decreased (inf --> 0.093012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0726846\n",
      "\tspeed: 0.0640s/iter; left time: 1406.5569s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688826\n",
      "\tspeed: 0.0348s/iter; left time: 760.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0747757 Vali Loss: 0.0630129 Test Loss: 0.0701470\n",
      "Validation loss decreased (0.093012 --> 0.063013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0630229\n",
      "\tspeed: 0.0638s/iter; left time: 1388.3226s\n",
      "\titers: 200, epoch: 3 | loss: 0.0606441\n",
      "\tspeed: 0.0348s/iter; left time: 752.8131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0643692 Vali Loss: 0.0595219 Test Loss: 0.0660069\n",
      "Validation loss decreased (0.063013 --> 0.059522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0577680\n",
      "\tspeed: 0.0636s/iter; left time: 1369.1470s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634644\n",
      "\tspeed: 0.0348s/iter; left time: 746.0911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0615642 Vali Loss: 0.0584180 Test Loss: 0.0651230\n",
      "Validation loss decreased (0.059522 --> 0.058418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608671\n",
      "\tspeed: 0.0634s/iter; left time: 1350.4796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0647859\n",
      "\tspeed: 0.0348s/iter; left time: 738.8029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0598110 Vali Loss: 0.0573382 Test Loss: 0.0638470\n",
      "Validation loss decreased (0.058418 --> 0.057338).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577245\n",
      "\tspeed: 0.0637s/iter; left time: 1343.0667s\n",
      "\titers: 200, epoch: 6 | loss: 0.0596926\n",
      "\tspeed: 0.0348s/iter; left time: 730.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0586960 Vali Loss: 0.0561589 Test Loss: 0.0628494\n",
      "Validation loss decreased (0.057338 --> 0.056159).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0554998\n",
      "\tspeed: 0.0630s/iter; left time: 1315.0874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0615113\n",
      "\tspeed: 0.0347s/iter; left time: 721.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0577603 Vali Loss: 0.0560129 Test Loss: 0.0629468\n",
      "Validation loss decreased (0.056159 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0617084\n",
      "\tspeed: 0.0634s/iter; left time: 1308.8752s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562230\n",
      "\tspeed: 0.0348s/iter; left time: 715.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0571237 Vali Loss: 0.0552313 Test Loss: 0.0622659\n",
      "Validation loss decreased (0.056013 --> 0.055231).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549473\n",
      "\tspeed: 0.0634s/iter; left time: 1294.6717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0565709\n",
      "\tspeed: 0.0348s/iter; left time: 706.5157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0564831 Vali Loss: 0.0553474 Test Loss: 0.0621103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554801\n",
      "\tspeed: 0.0627s/iter; left time: 1266.8730s\n",
      "\titers: 200, epoch: 10 | loss: 0.0555981\n",
      "\tspeed: 0.0348s/iter; left time: 698.7287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0559145 Vali Loss: 0.0549688 Test Loss: 0.0617780\n",
      "Validation loss decreased (0.055231 --> 0.054969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0557911\n",
      "\tspeed: 0.0641s/iter; left time: 1279.4897s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561363\n",
      "\tspeed: 0.0348s/iter; left time: 691.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0555488 Vali Loss: 0.0545749 Test Loss: 0.0615567\n",
      "Validation loss decreased (0.054969 --> 0.054575).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0546582\n",
      "\tspeed: 0.0646s/iter; left time: 1276.6914s\n",
      "\titers: 200, epoch: 12 | loss: 0.0536586\n",
      "\tspeed: 0.0348s/iter; left time: 683.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0551339 Vali Loss: 0.0539980 Test Loss: 0.0610293\n",
      "Validation loss decreased (0.054575 --> 0.053998).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0567421\n",
      "\tspeed: 0.0655s/iter; left time: 1279.7422s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555143\n",
      "\tspeed: 0.0348s/iter; left time: 675.8562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0547809 Vali Loss: 0.0539634 Test Loss: 0.0609647\n",
      "Validation loss decreased (0.053998 --> 0.053963).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559703\n",
      "\tspeed: 0.0635s/iter; left time: 1226.2728s\n",
      "\titers: 200, epoch: 14 | loss: 0.0540294\n",
      "\tspeed: 0.0348s/iter; left time: 667.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0545201 Vali Loss: 0.0537920 Test Loss: 0.0607807\n",
      "Validation loss decreased (0.053963 --> 0.053792).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571534\n",
      "\tspeed: 0.0633s/iter; left time: 1206.8337s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574851\n",
      "\tspeed: 0.0348s/iter; left time: 659.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0542520 Vali Loss: 0.0537604 Test Loss: 0.0608433\n",
      "Validation loss decreased (0.053792 --> 0.053760).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0579594\n",
      "\tspeed: 0.0634s/iter; left time: 1195.8435s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538236\n",
      "\tspeed: 0.0348s/iter; left time: 652.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0540514 Vali Loss: 0.0534855 Test Loss: 0.0605299\n",
      "Validation loss decreased (0.053760 --> 0.053486).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0563427\n",
      "\tspeed: 0.0634s/iter; left time: 1182.1512s\n",
      "\titers: 200, epoch: 17 | loss: 0.0530981\n",
      "\tspeed: 0.0348s/iter; left time: 644.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0538100 Vali Loss: 0.0537486 Test Loss: 0.0609309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0554305\n",
      "\tspeed: 0.0628s/iter; left time: 1156.8952s\n",
      "\titers: 200, epoch: 18 | loss: 0.0560160\n",
      "\tspeed: 0.0348s/iter; left time: 636.5147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0536474 Vali Loss: 0.0534000 Test Loss: 0.0606266\n",
      "Validation loss decreased (0.053486 --> 0.053400).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525237\n",
      "\tspeed: 0.0636s/iter; left time: 1155.9690s\n",
      "\titers: 200, epoch: 19 | loss: 0.0536887\n",
      "\tspeed: 0.0348s/iter; left time: 629.7454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0534839 Vali Loss: 0.0532571 Test Loss: 0.0605488\n",
      "Validation loss decreased (0.053400 --> 0.053257).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549485\n",
      "\tspeed: 0.0635s/iter; left time: 1141.0508s\n",
      "\titers: 200, epoch: 20 | loss: 0.0514710\n",
      "\tspeed: 0.0348s/iter; left time: 621.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0533952 Vali Loss: 0.0533304 Test Loss: 0.0602945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0535472\n",
      "\tspeed: 0.0630s/iter; left time: 1117.8355s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519489\n",
      "\tspeed: 0.0348s/iter; left time: 613.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0532001 Vali Loss: 0.0531706 Test Loss: 0.0604976\n",
      "Validation loss decreased (0.053257 --> 0.053171).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0557677\n",
      "\tspeed: 0.0635s/iter; left time: 1112.5365s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539617\n",
      "\tspeed: 0.0348s/iter; left time: 605.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0531452 Vali Loss: 0.0529666 Test Loss: 0.0602932\n",
      "Validation loss decreased (0.053171 --> 0.052967).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0514711\n",
      "\tspeed: 0.0632s/iter; left time: 1093.1251s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566470\n",
      "\tspeed: 0.0348s/iter; left time: 599.1830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0530440 Vali Loss: 0.0530361 Test Loss: 0.0602941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492075\n",
      "\tspeed: 0.0631s/iter; left time: 1077.1810s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510157\n",
      "\tspeed: 0.0348s/iter; left time: 590.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0529677 Vali Loss: 0.0528758 Test Loss: 0.0600719\n",
      "Validation loss decreased (0.052967 --> 0.052876).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0576330\n",
      "\tspeed: 0.0633s/iter; left time: 1067.3515s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552283\n",
      "\tspeed: 0.0348s/iter; left time: 582.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0528415 Vali Loss: 0.0529786 Test Loss: 0.0600655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0512867\n",
      "\tspeed: 0.0628s/iter; left time: 1044.1945s\n",
      "\titers: 200, epoch: 26 | loss: 0.0496288\n",
      "\tspeed: 0.0348s/iter; left time: 574.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0527987 Vali Loss: 0.0530332 Test Loss: 0.0601122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0509674\n",
      "\tspeed: 0.0627s/iter; left time: 1028.3703s\n",
      "\titers: 200, epoch: 27 | loss: 0.0484194\n",
      "\tspeed: 0.0348s/iter; left time: 566.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0527392 Vali Loss: 0.0528903 Test Loss: 0.0600539\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0530106\n",
      "\tspeed: 0.0628s/iter; left time: 1016.4508s\n",
      "\titers: 200, epoch: 28 | loss: 0.0531000\n",
      "\tspeed: 0.0348s/iter; left time: 558.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0527272 Vali Loss: 0.0529470 Test Loss: 0.0600106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0491770\n",
      "\tspeed: 0.0630s/iter; left time: 1005.7877s\n",
      "\titers: 200, epoch: 29 | loss: 0.0452469\n",
      "\tspeed: 0.0348s/iter; left time: 552.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0526793 Vali Loss: 0.0528311 Test Loss: 0.0599793\n",
      "Validation loss decreased (0.052876 --> 0.052831).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0550407\n",
      "\tspeed: 0.0633s/iter; left time: 996.5060s\n",
      "\titers: 200, epoch: 30 | loss: 0.0518973\n",
      "\tspeed: 0.0348s/iter; left time: 543.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0526110 Vali Loss: 0.0528266 Test Loss: 0.0600462\n",
      "Validation loss decreased (0.052831 --> 0.052827).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542863\n",
      "\tspeed: 0.0635s/iter; left time: 985.3027s\n",
      "\titers: 200, epoch: 31 | loss: 0.0546150\n",
      "\tspeed: 0.0348s/iter; left time: 535.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0525636 Vali Loss: 0.0527613 Test Loss: 0.0599322\n",
      "Validation loss decreased (0.052827 --> 0.052761).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0539835\n",
      "\tspeed: 0.0635s/iter; left time: 970.0583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0490118\n",
      "\tspeed: 0.0348s/iter; left time: 528.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0524810 Vali Loss: 0.0527825 Test Loss: 0.0599976\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549474\n",
      "\tspeed: 0.0631s/iter; left time: 950.4359s\n",
      "\titers: 200, epoch: 33 | loss: 0.0535856\n",
      "\tspeed: 0.0348s/iter; left time: 520.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0525075 Vali Loss: 0.0527115 Test Loss: 0.0599608\n",
      "Validation loss decreased (0.052761 --> 0.052712).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0556550\n",
      "\tspeed: 0.0647s/iter; left time: 960.1710s\n",
      "\titers: 200, epoch: 34 | loss: 0.0515874\n",
      "\tspeed: 0.0348s/iter; left time: 513.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0524111 Vali Loss: 0.0526704 Test Loss: 0.0598688\n",
      "Validation loss decreased (0.052712 --> 0.052670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0557314\n",
      "\tspeed: 0.0633s/iter; left time: 926.0640s\n",
      "\titers: 200, epoch: 35 | loss: 0.0507834\n",
      "\tspeed: 0.0348s/iter; left time: 505.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0523630 Vali Loss: 0.0527240 Test Loss: 0.0598827\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0512614\n",
      "\tspeed: 0.0629s/iter; left time: 905.4383s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518102\n",
      "\tspeed: 0.0348s/iter; left time: 497.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0524054 Vali Loss: 0.0526994 Test Loss: 0.0598760\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0523046\n",
      "\tspeed: 0.0630s/iter; left time: 893.0770s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508446\n",
      "\tspeed: 0.0348s/iter; left time: 489.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0523582 Vali Loss: 0.0527033 Test Loss: 0.0599662\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0494673\n",
      "\tspeed: 0.0630s/iter; left time: 878.4601s\n",
      "\titers: 200, epoch: 38 | loss: 0.0530426\n",
      "\tspeed: 0.0348s/iter; left time: 481.6451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0523731 Vali Loss: 0.0527296 Test Loss: 0.0598084\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0518862\n",
      "\tspeed: 0.0631s/iter; left time: 866.3405s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517699\n",
      "\tspeed: 0.0348s/iter; left time: 474.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0523550 Vali Loss: 0.0526709 Test Loss: 0.0597897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0523804\n",
      "\tspeed: 0.0629s/iter; left time: 849.3857s\n",
      "\titers: 200, epoch: 40 | loss: 0.0547245\n",
      "\tspeed: 0.0348s/iter; left time: 466.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522779 Vali Loss: 0.0526520 Test Loss: 0.0598167\n",
      "Validation loss decreased (0.052670 --> 0.052652).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0520796\n",
      "\tspeed: 0.0645s/iter; left time: 857.0303s\n",
      "\titers: 200, epoch: 41 | loss: 0.0510751\n",
      "\tspeed: 0.0363s/iter; left time: 477.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0522868 Vali Loss: 0.0526246 Test Loss: 0.0597722\n",
      "Validation loss decreased (0.052652 --> 0.052625).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0512310\n",
      "\tspeed: 0.0635s/iter; left time: 829.0423s\n",
      "\titers: 200, epoch: 42 | loss: 0.0529866\n",
      "\tspeed: 0.0348s/iter; left time: 451.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522490 Vali Loss: 0.0525609 Test Loss: 0.0597641\n",
      "Validation loss decreased (0.052625 --> 0.052561).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0510413\n",
      "\tspeed: 0.0632s/iter; left time: 811.6630s\n",
      "\titers: 200, epoch: 43 | loss: 0.0491077\n",
      "\tspeed: 0.0348s/iter; left time: 443.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522282 Vali Loss: 0.0525843 Test Loss: 0.0597606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0520502\n",
      "\tspeed: 0.0629s/iter; left time: 793.6619s\n",
      "\titers: 200, epoch: 44 | loss: 0.0531535\n",
      "\tspeed: 0.0349s/iter; left time: 436.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0522566 Vali Loss: 0.0526180 Test Loss: 0.0597909\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0503224\n",
      "\tspeed: 0.0635s/iter; left time: 786.1438s\n",
      "\titers: 200, epoch: 45 | loss: 0.0540412\n",
      "\tspeed: 0.0349s/iter; left time: 429.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0522631 Vali Loss: 0.0525658 Test Loss: 0.0597489\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0557683\n",
      "\tspeed: 0.0634s/iter; left time: 771.0397s\n",
      "\titers: 200, epoch: 46 | loss: 0.0500644\n",
      "\tspeed: 0.0349s/iter; left time: 420.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0522589 Vali Loss: 0.0525750 Test Loss: 0.0597478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0505572\n",
      "\tspeed: 0.0631s/iter; left time: 753.5801s\n",
      "\titers: 200, epoch: 47 | loss: 0.0517297\n",
      "\tspeed: 0.0348s/iter; left time: 412.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522229 Vali Loss: 0.0525794 Test Loss: 0.0597371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0519887\n",
      "\tspeed: 0.0631s/iter; left time: 740.0177s\n",
      "\titers: 200, epoch: 48 | loss: 0.0505121\n",
      "\tspeed: 0.0348s/iter; left time: 404.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0522587 Vali Loss: 0.0525739 Test Loss: 0.0597563\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0551468\n",
      "\tspeed: 0.0633s/iter; left time: 727.5549s\n",
      "\titers: 200, epoch: 49 | loss: 0.0543535\n",
      "\tspeed: 0.0349s/iter; left time: 397.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0522053 Vali Loss: 0.0526640 Test Loss: 0.0597686\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0530866\n",
      "\tspeed: 0.0860s/iter; left time: 969.2238s\n",
      "\titers: 200, epoch: 50 | loss: 0.0546758\n",
      "\tspeed: 0.1936s/iter; left time: 2162.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:29.79s\n",
      "Steps: 223 | Train Loss: 0.0521773 Vali Loss: 0.0525721 Test Loss: 0.0597589\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0559117\n",
      "\tspeed: 0.2853s/iter; left time: 3152.6291s\n",
      "\titers: 200, epoch: 51 | loss: 0.0528672\n",
      "\tspeed: 0.0355s/iter; left time: 389.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 223 | Train Loss: 0.0521526 Vali Loss: 0.0525845 Test Loss: 0.0597217\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0560968\n",
      "\tspeed: 0.0648s/iter; left time: 701.4242s\n",
      "\titers: 200, epoch: 52 | loss: 0.0540408\n",
      "\tspeed: 0.0347s/iter; left time: 371.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0521717 Vali Loss: 0.0525350 Test Loss: 0.0597281\n",
      "Validation loss decreased (0.052561 --> 0.052535).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529655\n",
      "\tspeed: 0.0641s/iter; left time: 679.3497s\n",
      "\titers: 200, epoch: 53 | loss: 0.0516334\n",
      "\tspeed: 0.0347s/iter; left time: 364.5613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0522050 Vali Loss: 0.0525881 Test Loss: 0.0597237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0511335\n",
      "\tspeed: 0.0633s/iter; left time: 657.0816s\n",
      "\titers: 200, epoch: 54 | loss: 0.0495469\n",
      "\tspeed: 0.0347s/iter; left time: 356.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522098 Vali Loss: 0.0525827 Test Loss: 0.0597430\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0499042\n",
      "\tspeed: 0.0638s/iter; left time: 647.9299s\n",
      "\titers: 200, epoch: 55 | loss: 0.0543089\n",
      "\tspeed: 0.0347s/iter; left time: 348.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0521472 Vali Loss: 0.0525706 Test Loss: 0.0597533\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0549883\n",
      "\tspeed: 0.0634s/iter; left time: 629.8835s\n",
      "\titers: 200, epoch: 56 | loss: 0.0486927\n",
      "\tspeed: 0.0347s/iter; left time: 341.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0521627 Vali Loss: 0.0525882 Test Loss: 0.0597260\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0517346\n",
      "\tspeed: 0.0640s/iter; left time: 621.6329s\n",
      "\titers: 200, epoch: 57 | loss: 0.0517503\n",
      "\tspeed: 0.0349s/iter; left time: 335.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0521682 Vali Loss: 0.0525590 Test Loss: 0.0597397\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0523834\n",
      "\tspeed: 0.0632s/iter; left time: 600.0961s\n",
      "\titers: 200, epoch: 58 | loss: 0.0494293\n",
      "\tspeed: 0.0346s/iter; left time: 325.1599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521432 Vali Loss: 0.0524969 Test Loss: 0.0597336\n",
      "Validation loss decreased (0.052535 --> 0.052497).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0492647\n",
      "\tspeed: 0.0634s/iter; left time: 587.0846s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519503\n",
      "\tspeed: 0.0346s/iter; left time: 317.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0522087 Vali Loss: 0.0525812 Test Loss: 0.0597525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0497367\n",
      "\tspeed: 0.0630s/iter; left time: 570.0427s\n",
      "\titers: 200, epoch: 60 | loss: 0.0495885\n",
      "\tspeed: 0.0347s/iter; left time: 310.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521029 Vali Loss: 0.0525469 Test Loss: 0.0597159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0560998\n",
      "\tspeed: 0.0628s/iter; left time: 553.6345s\n",
      "\titers: 200, epoch: 61 | loss: 0.0487670\n",
      "\tspeed: 0.0346s/iter; left time: 301.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521652 Vali Loss: 0.0525439 Test Loss: 0.0597304\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0514731\n",
      "\tspeed: 0.0631s/iter; left time: 542.5550s\n",
      "\titers: 200, epoch: 62 | loss: 0.0511709\n",
      "\tspeed: 0.0347s/iter; left time: 294.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521105 Vali Loss: 0.0525647 Test Loss: 0.0597182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0521433\n",
      "\tspeed: 0.0628s/iter; left time: 526.2233s\n",
      "\titers: 200, epoch: 63 | loss: 0.0503324\n",
      "\tspeed: 0.0346s/iter; left time: 286.2273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0521071 Vali Loss: 0.0525776 Test Loss: 0.0597103\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0540591\n",
      "\tspeed: 0.0628s/iter; left time: 512.1828s\n",
      "\titers: 200, epoch: 64 | loss: 0.0516116\n",
      "\tspeed: 0.0346s/iter; left time: 278.9412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0522032 Vali Loss: 0.0525546 Test Loss: 0.0596993\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0474531\n",
      "\tspeed: 0.0630s/iter; left time: 499.7513s\n",
      "\titers: 200, epoch: 65 | loss: 0.0538364\n",
      "\tspeed: 0.0346s/iter; left time: 270.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521677 Vali Loss: 0.0525728 Test Loss: 0.0597150\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0497643\n",
      "\tspeed: 0.0629s/iter; left time: 484.6543s\n",
      "\titers: 200, epoch: 66 | loss: 0.0538237\n",
      "\tspeed: 0.0347s/iter; left time: 263.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521412 Vali Loss: 0.0525373 Test Loss: 0.0597279\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499914\n",
      "\tspeed: 0.0629s/iter; left time: 470.8134s\n",
      "\titers: 200, epoch: 67 | loss: 0.0554513\n",
      "\tspeed: 0.0346s/iter; left time: 255.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0521308 Vali Loss: 0.0525533 Test Loss: 0.0597116\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0493037\n",
      "\tspeed: 0.0634s/iter; left time: 460.3703s\n",
      "\titers: 200, epoch: 68 | loss: 0.0565311\n",
      "\tspeed: 0.0347s/iter; left time: 248.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0521564 Vali Loss: 0.0525395 Test Loss: 0.0596687\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009866722859442234, rmse:0.09933137893676758, mae:0.05973363667726517, rse:0.29232025146484375\n",
      "Intermediate time for ES and pred_len 24: 00h:20m:40.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1260398\n",
      "\tspeed: 0.0530s/iter; left time: 1172.3117s\n",
      "\titers: 200, epoch: 1 | loss: 0.1094058\n",
      "\tspeed: 0.0350s/iter; left time: 770.4190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 222 | Train Loss: 0.1312395 Vali Loss: 0.1025643 Test Loss: 0.1179704\n",
      "Validation loss decreased (inf --> 0.102564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0910940\n",
      "\tspeed: 0.0670s/iter; left time: 1466.3118s\n",
      "\titers: 200, epoch: 2 | loss: 0.0862823\n",
      "\tspeed: 0.0351s/iter; left time: 764.1153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0916984 Vali Loss: 0.0828621 Test Loss: 0.0948578\n",
      "Validation loss decreased (0.102564 --> 0.082862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0830963\n",
      "\tspeed: 0.0658s/iter; left time: 1425.5313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800575\n",
      "\tspeed: 0.0351s/iter; left time: 757.2695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0835440 Vali Loss: 0.0801127 Test Loss: 0.0918577\n",
      "Validation loss decreased (0.082862 --> 0.080113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827469\n",
      "\tspeed: 0.0655s/iter; left time: 1402.9393s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801315\n",
      "\tspeed: 0.0351s/iter; left time: 749.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0810485 Vali Loss: 0.0794556 Test Loss: 0.0912822\n",
      "Validation loss decreased (0.080113 --> 0.079456).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791584\n",
      "\tspeed: 0.0670s/iter; left time: 1421.3492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771858\n",
      "\tspeed: 0.0352s/iter; left time: 743.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0794836 Vali Loss: 0.0775880 Test Loss: 0.0889750\n",
      "Validation loss decreased (0.079456 --> 0.077588).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0784760\n",
      "\tspeed: 0.0650s/iter; left time: 1364.3395s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783841\n",
      "\tspeed: 0.0350s/iter; left time: 732.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0781405 Vali Loss: 0.0771143 Test Loss: 0.0890088\n",
      "Validation loss decreased (0.077588 --> 0.077114).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748558\n",
      "\tspeed: 0.0646s/iter; left time: 1340.6576s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760703\n",
      "\tspeed: 0.0351s/iter; left time: 725.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0771091 Vali Loss: 0.0769558 Test Loss: 0.0889577\n",
      "Validation loss decreased (0.077114 --> 0.076956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0765331\n",
      "\tspeed: 0.0650s/iter; left time: 1335.3036s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739735\n",
      "\tspeed: 0.0351s/iter; left time: 717.8247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0762211 Vali Loss: 0.0766279 Test Loss: 0.0881195\n",
      "Validation loss decreased (0.076956 --> 0.076628).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0740731\n",
      "\tspeed: 0.0655s/iter; left time: 1331.3336s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760542\n",
      "\tspeed: 0.0351s/iter; left time: 710.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0754744 Vali Loss: 0.0768604 Test Loss: 0.0877999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748701\n",
      "\tspeed: 0.0639s/iter; left time: 1284.6550s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732583\n",
      "\tspeed: 0.0351s/iter; left time: 701.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0747732 Vali Loss: 0.0759283 Test Loss: 0.0877505\n",
      "Validation loss decreased (0.076628 --> 0.075928).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744002\n",
      "\tspeed: 0.0644s/iter; left time: 1280.6382s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738547\n",
      "\tspeed: 0.0351s/iter; left time: 695.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0742015 Vali Loss: 0.0763542 Test Loss: 0.0879077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0763251\n",
      "\tspeed: 0.0638s/iter; left time: 1253.8331s\n",
      "\titers: 200, epoch: 12 | loss: 0.0744755\n",
      "\tspeed: 0.0350s/iter; left time: 685.4543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0737041 Vali Loss: 0.0765918 Test Loss: 0.0877662\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757539\n",
      "\tspeed: 0.0648s/iter; left time: 1258.6087s\n",
      "\titers: 200, epoch: 13 | loss: 0.0730051\n",
      "\tspeed: 0.0352s/iter; left time: 680.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0732794 Vali Loss: 0.0768405 Test Loss: 0.0879112\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0759228\n",
      "\tspeed: 0.0649s/iter; left time: 1246.7385s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697216\n",
      "\tspeed: 0.0351s/iter; left time: 670.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0729788 Vali Loss: 0.0768946 Test Loss: 0.0879021\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0712653\n",
      "\tspeed: 0.0642s/iter; left time: 1218.9842s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766184\n",
      "\tspeed: 0.0350s/iter; left time: 661.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 222 | Train Loss: 0.0726127 Vali Loss: 0.0770157 Test Loss: 0.0880994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0742202\n",
      "\tspeed: 0.0650s/iter; left time: 1220.9232s\n",
      "\titers: 200, epoch: 16 | loss: 0.0683738\n",
      "\tspeed: 0.0352s/iter; left time: 657.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0722651 Vali Loss: 0.0772379 Test Loss: 0.0881794\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0698431\n",
      "\tspeed: 0.0646s/iter; left time: 1198.5947s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702294\n",
      "\tspeed: 0.0352s/iter; left time: 650.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0719513 Vali Loss: 0.0765780 Test Loss: 0.0879023\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0715836\n",
      "\tspeed: 0.0643s/iter; left time: 1178.7720s\n",
      "\titers: 200, epoch: 18 | loss: 0.0724372\n",
      "\tspeed: 0.0353s/iter; left time: 643.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0717396 Vali Loss: 0.0768387 Test Loss: 0.0879140\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737238\n",
      "\tspeed: 0.0642s/iter; left time: 1163.0566s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690236\n",
      "\tspeed: 0.0351s/iter; left time: 631.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 222 | Train Loss: 0.0714695 Vali Loss: 0.0772368 Test Loss: 0.0880769\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733092\n",
      "\tspeed: 0.0641s/iter; left time: 1146.9008s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739523\n",
      "\tspeed: 0.0351s/iter; left time: 623.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0713218 Vali Loss: 0.0768432 Test Loss: 0.0879300\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018871869891881943, rmse:0.13737492263317108, mae:0.08775053173303604, rse:0.4035661816596985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1251608\n",
      "\tspeed: 0.0369s/iter; left time: 815.6401s\n",
      "\titers: 200, epoch: 1 | loss: 0.1145597\n",
      "\tspeed: 0.0351s/iter; left time: 772.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.1341426 Vali Loss: 0.1022528 Test Loss: 0.1178219\n",
      "Validation loss decreased (inf --> 0.102253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918480\n",
      "\tspeed: 0.0673s/iter; left time: 1471.8311s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841864\n",
      "\tspeed: 0.0351s/iter; left time: 765.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0917143 Vali Loss: 0.0827933 Test Loss: 0.0951420\n",
      "Validation loss decreased (0.102253 --> 0.082793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802328\n",
      "\tspeed: 0.0659s/iter; left time: 1427.4664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0848325\n",
      "\tspeed: 0.0351s/iter; left time: 756.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0834263 Vali Loss: 0.0801661 Test Loss: 0.0913073\n",
      "Validation loss decreased (0.082793 --> 0.080166).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818230\n",
      "\tspeed: 0.0643s/iter; left time: 1379.0318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802361\n",
      "\tspeed: 0.0351s/iter; left time: 748.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0809871 Vali Loss: 0.0786778 Test Loss: 0.0897193\n",
      "Validation loss decreased (0.080166 --> 0.078678).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772564\n",
      "\tspeed: 0.0652s/iter; left time: 1383.8049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0814229\n",
      "\tspeed: 0.0359s/iter; left time: 757.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0792988 Vali Loss: 0.0778066 Test Loss: 0.0885959\n",
      "Validation loss decreased (0.078678 --> 0.077807).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764081\n",
      "\tspeed: 0.2176s/iter; left time: 4566.7076s\n",
      "\titers: 200, epoch: 6 | loss: 0.0773624\n",
      "\tspeed: 0.1878s/iter; left time: 3923.8099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.55s\n",
      "Steps: 222 | Train Loss: 0.0779447 Vali Loss: 0.0773780 Test Loss: 0.0886872\n",
      "Validation loss decreased (0.077807 --> 0.077378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811512\n",
      "\tspeed: 0.1895s/iter; left time: 3936.2038s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761342\n",
      "\tspeed: 0.0351s/iter; left time: 724.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0769921 Vali Loss: 0.0766341 Test Loss: 0.0885049\n",
      "Validation loss decreased (0.077378 --> 0.076634).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770397\n",
      "\tspeed: 0.0646s/iter; left time: 1328.0639s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767725\n",
      "\tspeed: 0.0351s/iter; left time: 717.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0761878 Vali Loss: 0.0762908 Test Loss: 0.0881954\n",
      "Validation loss decreased (0.076634 --> 0.076291).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769685\n",
      "\tspeed: 0.0649s/iter; left time: 1319.4390s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753919\n",
      "\tspeed: 0.0356s/iter; left time: 720.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0754454 Vali Loss: 0.0759398 Test Loss: 0.0880421\n",
      "Validation loss decreased (0.076291 --> 0.075940).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743246\n",
      "\tspeed: 0.0665s/iter; left time: 1337.4520s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720993\n",
      "\tspeed: 0.0353s/iter; left time: 705.4292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0748660 Vali Loss: 0.0759301 Test Loss: 0.0884588\n",
      "Validation loss decreased (0.075940 --> 0.075930).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720741\n",
      "\tspeed: 0.0656s/iter; left time: 1304.3697s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748360\n",
      "\tspeed: 0.0351s/iter; left time: 695.1580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0743284 Vali Loss: 0.0763421 Test Loss: 0.0880268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726227\n",
      "\tspeed: 0.0646s/iter; left time: 1269.5504s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748167\n",
      "\tspeed: 0.0352s/iter; left time: 688.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0738782 Vali Loss: 0.0759847 Test Loss: 0.0881390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721753\n",
      "\tspeed: 0.0648s/iter; left time: 1258.6577s\n",
      "\titers: 200, epoch: 13 | loss: 0.0772060\n",
      "\tspeed: 0.0352s/iter; left time: 679.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0734766 Vali Loss: 0.0758512 Test Loss: 0.0878312\n",
      "Validation loss decreased (0.075930 --> 0.075851).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715857\n",
      "\tspeed: 0.0655s/iter; left time: 1258.5466s\n",
      "\titers: 200, epoch: 14 | loss: 0.0760631\n",
      "\tspeed: 0.0356s/iter; left time: 680.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0731019 Vali Loss: 0.0763125 Test Loss: 0.0881449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0728902\n",
      "\tspeed: 0.0664s/iter; left time: 1261.9057s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735835\n",
      "\tspeed: 0.0351s/iter; left time: 662.6150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0727445 Vali Loss: 0.0761350 Test Loss: 0.0879413\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0705711\n",
      "\tspeed: 0.0645s/iter; left time: 1210.8984s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673693\n",
      "\tspeed: 0.0351s/iter; left time: 656.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0725134 Vali Loss: 0.0764219 Test Loss: 0.0875670\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732625\n",
      "\tspeed: 0.0653s/iter; left time: 1210.4970s\n",
      "\titers: 200, epoch: 17 | loss: 0.0735754\n",
      "\tspeed: 0.0352s/iter; left time: 649.9066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0722842 Vali Loss: 0.0762213 Test Loss: 0.0875859\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754683\n",
      "\tspeed: 0.0651s/iter; left time: 1193.8060s\n",
      "\titers: 200, epoch: 18 | loss: 0.0736159\n",
      "\tspeed: 0.0352s/iter; left time: 642.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0720724 Vali Loss: 0.0760946 Test Loss: 0.0880375\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718110\n",
      "\tspeed: 0.0659s/iter; left time: 1192.2314s\n",
      "\titers: 200, epoch: 19 | loss: 0.0741730\n",
      "\tspeed: 0.0352s/iter; left time: 633.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0717672 Vali Loss: 0.0764167 Test Loss: 0.0877499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0699607\n",
      "\tspeed: 0.0677s/iter; left time: 1211.3845s\n",
      "\titers: 200, epoch: 20 | loss: 0.0741154\n",
      "\tspeed: 0.1638s/iter; left time: 2913.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 222 | Train Loss: 0.0715612 Vali Loss: 0.0762464 Test Loss: 0.0878026\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0707614\n",
      "\tspeed: 0.0929s/iter; left time: 1639.8626s\n",
      "\titers: 200, epoch: 21 | loss: 0.0679704\n",
      "\tspeed: 0.0365s/iter; left time: 640.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0714182 Vali Loss: 0.0766377 Test Loss: 0.0876773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0744809\n",
      "\tspeed: 0.3808s/iter; left time: 6639.9250s\n",
      "\titers: 200, epoch: 22 | loss: 0.0662124\n",
      "\tspeed: 0.0354s/iter; left time: 614.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 222 | Train Loss: 0.0713353 Vali Loss: 0.0763942 Test Loss: 0.0876612\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0721484\n",
      "\tspeed: 0.0647s/iter; left time: 1113.8564s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740722\n",
      "\tspeed: 0.0352s/iter; left time: 601.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0712046 Vali Loss: 0.0763761 Test Loss: 0.0877781\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019007287919521332, rmse:0.13786691427230835, mae:0.08783120661973953, rse:0.40501153469085693\n",
      "Intermediate time for ES and pred_len 96: 00h:08m:51.89s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1248044\n",
      "\tspeed: 0.0530s/iter; left time: 1170.7224s\n",
      "\titers: 200, epoch: 1 | loss: 0.1121375\n",
      "\tspeed: 0.0354s/iter; left time: 777.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 222 | Train Loss: 0.1329905 Vali Loss: 0.1052874 Test Loss: 0.1202584\n",
      "Validation loss decreased (inf --> 0.105287).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913955\n",
      "\tspeed: 0.0676s/iter; left time: 1479.3802s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897939\n",
      "\tspeed: 0.0354s/iter; left time: 770.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0956577 Vali Loss: 0.0880194 Test Loss: 0.1003802\n",
      "Validation loss decreased (0.105287 --> 0.088019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0912098\n",
      "\tspeed: 0.0658s/iter; left time: 1424.0831s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903715\n",
      "\tspeed: 0.0354s/iter; left time: 762.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0882833 Vali Loss: 0.0853559 Test Loss: 0.0969999\n",
      "Validation loss decreased (0.088019 --> 0.085356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0885219\n",
      "\tspeed: 0.0659s/iter; left time: 1412.1189s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829042\n",
      "\tspeed: 0.0354s/iter; left time: 754.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0855933 Vali Loss: 0.0840832 Test Loss: 0.0959689\n",
      "Validation loss decreased (0.085356 --> 0.084083).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806795\n",
      "\tspeed: 0.0687s/iter; left time: 1457.9011s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851555\n",
      "\tspeed: 0.0354s/iter; left time: 747.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0837458 Vali Loss: 0.0834666 Test Loss: 0.0952264\n",
      "Validation loss decreased (0.084083 --> 0.083467).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0795757\n",
      "\tspeed: 0.0661s/iter; left time: 1386.5759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0825070\n",
      "\tspeed: 0.0354s/iter; left time: 738.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0821476 Vali Loss: 0.0832355 Test Loss: 0.0942999\n",
      "Validation loss decreased (0.083467 --> 0.083235).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832260\n",
      "\tspeed: 0.0666s/iter; left time: 1383.7755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0815057\n",
      "\tspeed: 0.0353s/iter; left time: 730.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0809988 Vali Loss: 0.0836252 Test Loss: 0.0949094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0845280\n",
      "\tspeed: 0.0648s/iter; left time: 1330.4769s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820176\n",
      "\tspeed: 0.0354s/iter; left time: 723.4412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0800716 Vali Loss: 0.0830692 Test Loss: 0.0949128\n",
      "Validation loss decreased (0.083235 --> 0.083069).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779482\n",
      "\tspeed: 0.0692s/iter; left time: 1407.4368s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817634\n",
      "\tspeed: 0.1056s/iter; left time: 2136.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 222 | Train Loss: 0.0792837 Vali Loss: 0.0832909 Test Loss: 0.0947785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0796368\n",
      "\tspeed: 0.0675s/iter; left time: 1356.3240s\n",
      "\titers: 200, epoch: 10 | loss: 0.0779853\n",
      "\tspeed: 0.0526s/iter; left time: 1052.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 222 | Train Loss: 0.0786656 Vali Loss: 0.0832510 Test Loss: 0.0946252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785343\n",
      "\tspeed: 0.6281s/iter; left time: 12486.9896s\n",
      "\titers: 200, epoch: 11 | loss: 0.0724108\n",
      "\tspeed: 0.1509s/iter; left time: 2984.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:36.38s\n",
      "Steps: 222 | Train Loss: 0.0780590 Vali Loss: 0.0837434 Test Loss: 0.0947317\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778789\n",
      "\tspeed: 0.0767s/iter; left time: 1508.4605s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793115\n",
      "\tspeed: 0.0354s/iter; left time: 692.7958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 222 | Train Loss: 0.0776558 Vali Loss: 0.0835496 Test Loss: 0.0946513\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0768540\n",
      "\tspeed: 0.0645s/iter; left time: 1253.1599s\n",
      "\titers: 200, epoch: 13 | loss: 0.0758939\n",
      "\tspeed: 0.0353s/iter; left time: 683.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0771729 Vali Loss: 0.0840376 Test Loss: 0.0947968\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770758\n",
      "\tspeed: 0.0646s/iter; left time: 1240.6503s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722814\n",
      "\tspeed: 0.0353s/iter; left time: 674.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0767453 Vali Loss: 0.0838487 Test Loss: 0.0948405\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0768786\n",
      "\tspeed: 0.0642s/iter; left time: 1220.2160s\n",
      "\titers: 200, epoch: 15 | loss: 0.0742398\n",
      "\tspeed: 0.0353s/iter; left time: 667.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0764734 Vali Loss: 0.0840944 Test Loss: 0.0948674\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0763122\n",
      "\tspeed: 0.0648s/iter; left time: 1216.8669s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735435\n",
      "\tspeed: 0.0354s/iter; left time: 660.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0761429 Vali Loss: 0.0840424 Test Loss: 0.0947928\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0758866\n",
      "\tspeed: 0.0647s/iter; left time: 1199.2048s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786234\n",
      "\tspeed: 0.0354s/iter; left time: 652.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0758693 Vali Loss: 0.0847151 Test Loss: 0.0951496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750566\n",
      "\tspeed: 0.0647s/iter; left time: 1186.6675s\n",
      "\titers: 200, epoch: 18 | loss: 0.0735079\n",
      "\tspeed: 0.0354s/iter; left time: 645.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0756012 Vali Loss: 0.0840558 Test Loss: 0.0955794\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021398372948169708, rmse:0.14628182351589203, mae:0.0949128046631813, rse:0.4297628402709961\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262133\n",
      "\tspeed: 0.0370s/iter; left time: 818.7084s\n",
      "\titers: 200, epoch: 1 | loss: 0.1155465\n",
      "\tspeed: 0.0354s/iter; left time: 778.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.1330362 Vali Loss: 0.1057256 Test Loss: 0.1209119\n",
      "Validation loss decreased (inf --> 0.105726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0969276\n",
      "\tspeed: 0.0782s/iter; left time: 1711.8345s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930786\n",
      "\tspeed: 0.0354s/iter; left time: 769.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0959136 Vali Loss: 0.0881749 Test Loss: 0.1012242\n",
      "Validation loss decreased (0.105726 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903248\n",
      "\tspeed: 0.0657s/iter; left time: 1422.9299s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888213\n",
      "\tspeed: 0.0353s/iter; left time: 761.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0886226 Vali Loss: 0.0859347 Test Loss: 0.0981556\n",
      "Validation loss decreased (0.088175 --> 0.085935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0835429\n",
      "\tspeed: 0.0693s/iter; left time: 1484.7536s\n",
      "\titers: 200, epoch: 4 | loss: 0.0864875\n",
      "\tspeed: 0.0354s/iter; left time: 754.2379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0859898 Vali Loss: 0.0845382 Test Loss: 0.0961444\n",
      "Validation loss decreased (0.085935 --> 0.084538).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793198\n",
      "\tspeed: 0.0675s/iter; left time: 1432.3049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0833651\n",
      "\tspeed: 0.0390s/iter; left time: 824.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 222 | Train Loss: 0.0841185 Vali Loss: 0.0830565 Test Loss: 0.0956405\n",
      "Validation loss decreased (0.084538 --> 0.083056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843879\n",
      "\tspeed: 0.2041s/iter; left time: 4283.3636s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821313\n",
      "\tspeed: 0.0360s/iter; left time: 751.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0827344 Vali Loss: 0.0830209 Test Loss: 0.0961275\n",
      "Validation loss decreased (0.083056 --> 0.083021).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815268\n",
      "\tspeed: 0.4162s/iter; left time: 8645.0667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820298\n",
      "\tspeed: 0.1791s/iter; left time: 3701.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 222 | Train Loss: 0.0815136 Vali Loss: 0.0829712 Test Loss: 0.0942766\n",
      "Validation loss decreased (0.083021 --> 0.082971).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826096\n",
      "\tspeed: 0.2969s/iter; left time: 6100.9579s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799328\n",
      "\tspeed: 0.0360s/iter; left time: 736.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 222 | Train Loss: 0.0804369 Vali Loss: 0.0834113 Test Loss: 0.0943891\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0811863\n",
      "\tspeed: 0.0661s/iter; left time: 1343.7931s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789521\n",
      "\tspeed: 0.0355s/iter; left time: 718.8979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0796194 Vali Loss: 0.0833020 Test Loss: 0.0946176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0792897\n",
      "\tspeed: 0.0654s/iter; left time: 1314.4616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0795097\n",
      "\tspeed: 0.0354s/iter; left time: 708.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0788510 Vali Loss: 0.0848339 Test Loss: 0.0951783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800021\n",
      "\tspeed: 0.0655s/iter; left time: 1302.6337s\n",
      "\titers: 200, epoch: 11 | loss: 0.0780762\n",
      "\tspeed: 0.0354s/iter; left time: 700.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0782232 Vali Loss: 0.0836270 Test Loss: 0.0940536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0789887\n",
      "\tspeed: 0.0661s/iter; left time: 1300.0125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775751\n",
      "\tspeed: 0.0357s/iter; left time: 698.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 222 | Train Loss: 0.0777460 Vali Loss: 0.0836621 Test Loss: 0.0943825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776807\n",
      "\tspeed: 0.0648s/iter; left time: 1260.3107s\n",
      "\titers: 200, epoch: 13 | loss: 0.0753892\n",
      "\tspeed: 0.0354s/iter; left time: 684.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0772821 Vali Loss: 0.0838019 Test Loss: 0.0949747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766929\n",
      "\tspeed: 0.0649s/iter; left time: 1246.8134s\n",
      "\titers: 200, epoch: 14 | loss: 0.0776243\n",
      "\tspeed: 0.0354s/iter; left time: 677.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0768859 Vali Loss: 0.0844462 Test Loss: 0.0948179\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0752913\n",
      "\tspeed: 0.0650s/iter; left time: 1233.6634s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740202\n",
      "\tspeed: 0.0354s/iter; left time: 668.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0764546 Vali Loss: 0.0840741 Test Loss: 0.0945859\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780877\n",
      "\tspeed: 0.0654s/iter; left time: 1226.7383s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740172\n",
      "\tspeed: 0.0354s/iter; left time: 660.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0760855 Vali Loss: 0.0843399 Test Loss: 0.0947543\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0761232\n",
      "\tspeed: 0.0647s/iter; left time: 1200.3612s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759137\n",
      "\tspeed: 0.0354s/iter; left time: 652.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0757693 Vali Loss: 0.0838592 Test Loss: 0.0947815\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02121954783797264, rmse:0.14566931128501892, mae:0.09427657723426819, rse:0.4279633164405823\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:50.20s\n",
      "Intermediate time for ES: 00h:38m:22.14s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0836576\n",
      "\tspeed: 0.0553s/iter; left time: 1228.5774s\n",
      "\titers: 200, epoch: 1 | loss: 0.0827788\n",
      "\tspeed: 0.0347s/iter; left time: 767.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0929252 Vali Loss: 0.0809843 Test Loss: 0.0874676\n",
      "Validation loss decreased (inf --> 0.080984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0541820\n",
      "\tspeed: 0.0640s/iter; left time: 1405.6421s\n",
      "\titers: 200, epoch: 2 | loss: 0.0536694\n",
      "\tspeed: 0.0755s/iter; left time: 1651.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.29s\n",
      "Steps: 223 | Train Loss: 0.0554993 Vali Loss: 0.0584362 Test Loss: 0.0612443\n",
      "Validation loss decreased (0.080984 --> 0.058436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0479808\n",
      "\tspeed: 0.1419s/iter; left time: 3086.3528s\n",
      "\titers: 200, epoch: 3 | loss: 0.0469247\n",
      "\tspeed: 0.0348s/iter; left time: 754.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0488807 Vali Loss: 0.0559211 Test Loss: 0.0599450\n",
      "Validation loss decreased (0.058436 --> 0.055921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495132\n",
      "\tspeed: 0.1465s/iter; left time: 3155.4757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0486777\n",
      "\tspeed: 0.1460s/iter; left time: 3128.0486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.75s\n",
      "Steps: 223 | Train Loss: 0.0471245 Vali Loss: 0.0549650 Test Loss: 0.0586658\n",
      "Validation loss decreased (0.055921 --> 0.054965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461087\n",
      "\tspeed: 0.3328s/iter; left time: 7091.7118s\n",
      "\titers: 200, epoch: 5 | loss: 0.0431552\n",
      "\tspeed: 0.1444s/iter; left time: 3063.2244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.69s\n",
      "Steps: 223 | Train Loss: 0.0459224 Vali Loss: 0.0544292 Test Loss: 0.0579801\n",
      "Validation loss decreased (0.054965 --> 0.054429).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0429516\n",
      "\tspeed: 0.1242s/iter; left time: 2619.4910s\n",
      "\titers: 200, epoch: 6 | loss: 0.0450441\n",
      "\tspeed: 0.0351s/iter; left time: 737.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 223 | Train Loss: 0.0450753 Vali Loss: 0.0534364 Test Loss: 0.0574893\n",
      "Validation loss decreased (0.054429 --> 0.053436).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0427252\n",
      "\tspeed: 0.0642s/iter; left time: 1340.3451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0438986\n",
      "\tspeed: 0.0348s/iter; left time: 722.7895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0443351 Vali Loss: 0.0531485 Test Loss: 0.0569254\n",
      "Validation loss decreased (0.053436 --> 0.053148).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460687\n",
      "\tspeed: 0.0638s/iter; left time: 1316.1113s\n",
      "\titers: 200, epoch: 8 | loss: 0.0425774\n",
      "\tspeed: 0.0348s/iter; left time: 714.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0439071 Vali Loss: 0.0528703 Test Loss: 0.0569165\n",
      "Validation loss decreased (0.053148 --> 0.052870).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0421830\n",
      "\tspeed: 0.0641s/iter; left time: 1308.4582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0437702\n",
      "\tspeed: 0.0348s/iter; left time: 706.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0434690 Vali Loss: 0.0526643 Test Loss: 0.0562686\n",
      "Validation loss decreased (0.052870 --> 0.052664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0450998\n",
      "\tspeed: 0.0646s/iter; left time: 1304.3270s\n",
      "\titers: 200, epoch: 10 | loss: 0.0410023\n",
      "\tspeed: 0.0349s/iter; left time: 700.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0431665 Vali Loss: 0.0526991 Test Loss: 0.0567075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0446551\n",
      "\tspeed: 0.0643s/iter; left time: 1283.4945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0440647\n",
      "\tspeed: 0.0348s/iter; left time: 690.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0428013 Vali Loss: 0.0522881 Test Loss: 0.0562465\n",
      "Validation loss decreased (0.052664 --> 0.052288).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0446330\n",
      "\tspeed: 0.0638s/iter; left time: 1260.3358s\n",
      "\titers: 200, epoch: 12 | loss: 0.0441936\n",
      "\tspeed: 0.0347s/iter; left time: 682.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0425423 Vali Loss: 0.0518824 Test Loss: 0.0558948\n",
      "Validation loss decreased (0.052288 --> 0.051882).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0426764\n",
      "\tspeed: 0.0636s/iter; left time: 1241.3250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0411832\n",
      "\tspeed: 0.0347s/iter; left time: 674.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0423290 Vali Loss: 0.0518348 Test Loss: 0.0561304\n",
      "Validation loss decreased (0.051882 --> 0.051835).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0393404\n",
      "\tspeed: 0.0663s/iter; left time: 1280.1072s\n",
      "\titers: 200, epoch: 14 | loss: 0.0417510\n",
      "\tspeed: 0.0347s/iter; left time: 666.4404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0421292 Vali Loss: 0.0518482 Test Loss: 0.0560844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0428903\n",
      "\tspeed: 0.0640s/iter; left time: 1220.6665s\n",
      "\titers: 200, epoch: 15 | loss: 0.0426096\n",
      "\tspeed: 0.0348s/iter; left time: 659.6620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0419744 Vali Loss: 0.0517020 Test Loss: 0.0557122\n",
      "Validation loss decreased (0.051835 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0406196\n",
      "\tspeed: 0.0650s/iter; left time: 1224.7883s\n",
      "\titers: 200, epoch: 16 | loss: 0.0429875\n",
      "\tspeed: 0.0348s/iter; left time: 652.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0418102 Vali Loss: 0.0516462 Test Loss: 0.0557060\n",
      "Validation loss decreased (0.051702 --> 0.051646).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0435691\n",
      "\tspeed: 0.0640s/iter; left time: 1192.3540s\n",
      "\titers: 200, epoch: 17 | loss: 0.0413735\n",
      "\tspeed: 0.0349s/iter; left time: 647.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0416812 Vali Loss: 0.0513440 Test Loss: 0.0555808\n",
      "Validation loss decreased (0.051646 --> 0.051344).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0442521\n",
      "\tspeed: 0.0658s/iter; left time: 1210.8082s\n",
      "\titers: 200, epoch: 18 | loss: 0.0423577\n",
      "\tspeed: 0.0642s/iter; left time: 1175.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 223 | Train Loss: 0.0415006 Vali Loss: 0.0514995 Test Loss: 0.0556802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0410317\n",
      "\tspeed: 0.1585s/iter; left time: 2882.1213s\n",
      "\titers: 200, epoch: 19 | loss: 0.0432977\n",
      "\tspeed: 0.0363s/iter; left time: 656.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0414593 Vali Loss: 0.0512872 Test Loss: 0.0555878\n",
      "Validation loss decreased (0.051344 --> 0.051287).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0433293\n",
      "\tspeed: 0.0672s/iter; left time: 1207.6452s\n",
      "\titers: 200, epoch: 20 | loss: 0.0413895\n",
      "\tspeed: 0.0352s/iter; left time: 629.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0413562 Vali Loss: 0.0513565 Test Loss: 0.0554658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414682\n",
      "\tspeed: 0.0639s/iter; left time: 1134.4744s\n",
      "\titers: 200, epoch: 21 | loss: 0.0405680\n",
      "\tspeed: 0.0352s/iter; left time: 620.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0412301 Vali Loss: 0.0511387 Test Loss: 0.0554350\n",
      "Validation loss decreased (0.051287 --> 0.051139).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410880\n",
      "\tspeed: 0.0652s/iter; left time: 1141.9281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0437249\n",
      "\tspeed: 0.0351s/iter; left time: 611.8609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0411701 Vali Loss: 0.0511831 Test Loss: 0.0554506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0435361\n",
      "\tspeed: 0.0643s/iter; left time: 1112.1037s\n",
      "\titers: 200, epoch: 23 | loss: 0.0397593\n",
      "\tspeed: 0.0349s/iter; left time: 599.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0410498 Vali Loss: 0.0511003 Test Loss: 0.0554148\n",
      "Validation loss decreased (0.051139 --> 0.051100).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0421156\n",
      "\tspeed: 0.0640s/iter; left time: 1093.1930s\n",
      "\titers: 200, epoch: 24 | loss: 0.0424190\n",
      "\tspeed: 0.0351s/iter; left time: 596.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0409924 Vali Loss: 0.0511058 Test Loss: 0.0553837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0414506\n",
      "\tspeed: 0.0634s/iter; left time: 1068.7081s\n",
      "\titers: 200, epoch: 25 | loss: 0.0393909\n",
      "\tspeed: 0.0352s/iter; left time: 589.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0409429 Vali Loss: 0.0511639 Test Loss: 0.0554420\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0408931\n",
      "\tspeed: 0.0639s/iter; left time: 1062.6643s\n",
      "\titers: 200, epoch: 26 | loss: 0.0393896\n",
      "\tspeed: 0.0353s/iter; left time: 583.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0409068 Vali Loss: 0.0509211 Test Loss: 0.0554087\n",
      "Validation loss decreased (0.051100 --> 0.050921).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0420896\n",
      "\tspeed: 0.0656s/iter; left time: 1075.2783s\n",
      "\titers: 200, epoch: 27 | loss: 0.0398492\n",
      "\tspeed: 0.0352s/iter; left time: 574.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0408039 Vali Loss: 0.0509325 Test Loss: 0.0554289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0403437\n",
      "\tspeed: 0.0642s/iter; left time: 1038.8252s\n",
      "\titers: 200, epoch: 28 | loss: 0.0404508\n",
      "\tspeed: 0.0353s/iter; left time: 567.0769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0407987 Vali Loss: 0.0510672 Test Loss: 0.0553461\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0401933\n",
      "\tspeed: 0.0633s/iter; left time: 1010.2558s\n",
      "\titers: 200, epoch: 29 | loss: 0.0441964\n",
      "\tspeed: 0.0352s/iter; left time: 558.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0407347 Vali Loss: 0.0510270 Test Loss: 0.0553932\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0433453\n",
      "\tspeed: 0.0641s/iter; left time: 1008.9971s\n",
      "\titers: 200, epoch: 30 | loss: 0.0377617\n",
      "\tspeed: 0.0353s/iter; left time: 552.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0407489 Vali Loss: 0.0510796 Test Loss: 0.0552628\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0389959\n",
      "\tspeed: 0.0642s/iter; left time: 995.9266s\n",
      "\titers: 200, epoch: 31 | loss: 0.0391954\n",
      "\tspeed: 0.0351s/iter; left time: 541.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0406471 Vali Loss: 0.0509092 Test Loss: 0.0552722\n",
      "Validation loss decreased (0.050921 --> 0.050909).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0397254\n",
      "\tspeed: 0.0641s/iter; left time: 980.3520s\n",
      "\titers: 200, epoch: 32 | loss: 0.0423798\n",
      "\tspeed: 0.0352s/iter; left time: 535.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0406437 Vali Loss: 0.0510015 Test Loss: 0.0552981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0381529\n",
      "\tspeed: 0.0641s/iter; left time: 965.1537s\n",
      "\titers: 200, epoch: 33 | loss: 0.0393681\n",
      "\tspeed: 0.0351s/iter; left time: 525.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0405906 Vali Loss: 0.0508919 Test Loss: 0.0552640\n",
      "Validation loss decreased (0.050909 --> 0.050892).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0391373\n",
      "\tspeed: 0.0637s/iter; left time: 944.8045s\n",
      "\titers: 200, epoch: 34 | loss: 0.0429796\n",
      "\tspeed: 0.0351s/iter; left time: 517.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0406271 Vali Loss: 0.0509401 Test Loss: 0.0552789\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0393175\n",
      "\tspeed: 0.0638s/iter; left time: 932.6291s\n",
      "\titers: 200, epoch: 35 | loss: 0.0452444\n",
      "\tspeed: 0.0351s/iter; left time: 509.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0405727 Vali Loss: 0.0509840 Test Loss: 0.0553096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0396500\n",
      "\tspeed: 0.0640s/iter; left time: 921.9813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0374432\n",
      "\tspeed: 0.0347s/iter; left time: 496.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0405686 Vali Loss: 0.0508993 Test Loss: 0.0552813\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0382940\n",
      "\tspeed: 0.0635s/iter; left time: 899.3899s\n",
      "\titers: 200, epoch: 37 | loss: 0.0385352\n",
      "\tspeed: 0.0351s/iter; left time: 494.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0405605 Vali Loss: 0.0508825 Test Loss: 0.0552457\n",
      "Validation loss decreased (0.050892 --> 0.050883).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0443772\n",
      "\tspeed: 0.0645s/iter; left time: 900.2980s\n",
      "\titers: 200, epoch: 38 | loss: 0.0408431\n",
      "\tspeed: 0.0351s/iter; left time: 486.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405323 Vali Loss: 0.0508869 Test Loss: 0.0552040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0415697\n",
      "\tspeed: 0.0640s/iter; left time: 878.8649s\n",
      "\titers: 200, epoch: 39 | loss: 0.0401583\n",
      "\tspeed: 0.0352s/iter; left time: 479.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405325 Vali Loss: 0.0508903 Test Loss: 0.0552433\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0401176\n",
      "\tspeed: 0.0641s/iter; left time: 865.6091s\n",
      "\titers: 200, epoch: 40 | loss: 0.0379751\n",
      "\tspeed: 0.0351s/iter; left time: 471.0771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0405105 Vali Loss: 0.0509022 Test Loss: 0.0552413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416584\n",
      "\tspeed: 0.0644s/iter; left time: 855.7865s\n",
      "\titers: 200, epoch: 41 | loss: 0.0421260\n",
      "\tspeed: 0.0351s/iter; left time: 463.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0404700 Vali Loss: 0.0508691 Test Loss: 0.0552322\n",
      "Validation loss decreased (0.050883 --> 0.050869).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0404644\n",
      "\tspeed: 0.0649s/iter; left time: 847.9688s\n",
      "\titers: 200, epoch: 42 | loss: 0.0408125\n",
      "\tspeed: 0.0352s/iter; left time: 456.5434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0404701 Vali Loss: 0.0508088 Test Loss: 0.0552237\n",
      "Validation loss decreased (0.050869 --> 0.050809).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0419943\n",
      "\tspeed: 0.0644s/iter; left time: 826.1812s\n",
      "\titers: 200, epoch: 43 | loss: 0.0436137\n",
      "\tspeed: 0.0352s/iter; left time: 448.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0404592 Vali Loss: 0.0509347 Test Loss: 0.0552353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0376701\n",
      "\tspeed: 0.0633s/iter; left time: 798.2065s\n",
      "\titers: 200, epoch: 44 | loss: 0.0406414\n",
      "\tspeed: 0.0351s/iter; left time: 439.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404487 Vali Loss: 0.0508428 Test Loss: 0.0552090\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0393764\n",
      "\tspeed: 0.0640s/iter; left time: 792.5910s\n",
      "\titers: 200, epoch: 45 | loss: 0.0365028\n",
      "\tspeed: 0.0352s/iter; left time: 432.4115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0404632 Vali Loss: 0.0508255 Test Loss: 0.0552031\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0385800\n",
      "\tspeed: 0.0635s/iter; left time: 772.3172s\n",
      "\titers: 200, epoch: 46 | loss: 0.0384708\n",
      "\tspeed: 0.0351s/iter; left time: 423.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0404808 Vali Loss: 0.0508547 Test Loss: 0.0552096\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0380203\n",
      "\tspeed: 0.0649s/iter; left time: 775.6657s\n",
      "\titers: 200, epoch: 47 | loss: 0.0389383\n",
      "\tspeed: 0.0352s/iter; left time: 417.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0404394 Vali Loss: 0.0508684 Test Loss: 0.0552029\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0392998\n",
      "\tspeed: 0.0636s/iter; left time: 745.6993s\n",
      "\titers: 200, epoch: 48 | loss: 0.0419598\n",
      "\tspeed: 0.0352s/iter; left time: 408.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0404412 Vali Loss: 0.0508178 Test Loss: 0.0552285\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0428239\n",
      "\tspeed: 0.0651s/iter; left time: 748.3714s\n",
      "\titers: 200, epoch: 49 | loss: 0.0397411\n",
      "\tspeed: 0.0352s/iter; left time: 401.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0404602 Vali Loss: 0.0508335 Test Loss: 0.0552242\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0395791\n",
      "\tspeed: 0.0641s/iter; left time: 723.0227s\n",
      "\titers: 200, epoch: 50 | loss: 0.0381157\n",
      "\tspeed: 0.0351s/iter; left time: 392.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0404383 Vali Loss: 0.0508597 Test Loss: 0.0552245\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440048\n",
      "\tspeed: 0.0636s/iter; left time: 703.3596s\n",
      "\titers: 200, epoch: 51 | loss: 0.0397665\n",
      "\tspeed: 0.0352s/iter; left time: 385.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404183 Vali Loss: 0.0508182 Test Loss: 0.0552197\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0443854\n",
      "\tspeed: 0.0631s/iter; left time: 683.4818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0379273\n",
      "\tspeed: 0.0352s/iter; left time: 377.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404342 Vali Loss: 0.0508417 Test Loss: 0.0552029\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010042295791208744, rmse:0.1002112552523613, mae:0.0552237294614315, rse:0.38661226630210876\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0905331\n",
      "\tspeed: 0.0367s/iter; left time: 815.7851s\n",
      "\titers: 200, epoch: 1 | loss: 0.0790937\n",
      "\tspeed: 0.0351s/iter; left time: 776.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0933416 Vali Loss: 0.0811227 Test Loss: 0.0884504\n",
      "Validation loss decreased (inf --> 0.081123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0556278\n",
      "\tspeed: 0.0653s/iter; left time: 1435.0369s\n",
      "\titers: 200, epoch: 2 | loss: 0.0504415\n",
      "\tspeed: 0.0352s/iter; left time: 769.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0557345 Vali Loss: 0.0583004 Test Loss: 0.0612372\n",
      "Validation loss decreased (0.081123 --> 0.058300).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0461911\n",
      "\tspeed: 0.0646s/iter; left time: 1404.6647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0472828\n",
      "\tspeed: 0.0347s/iter; left time: 752.4354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0487746 Vali Loss: 0.0558743 Test Loss: 0.0592142\n",
      "Validation loss decreased (0.058300 --> 0.055874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0482211\n",
      "\tspeed: 0.0657s/iter; left time: 1414.7441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0449718\n",
      "\tspeed: 0.0351s/iter; left time: 751.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0470474 Vali Loss: 0.0544716 Test Loss: 0.0583089\n",
      "Validation loss decreased (0.055874 --> 0.054472).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449317\n",
      "\tspeed: 0.0647s/iter; left time: 1379.2122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0439852\n",
      "\tspeed: 0.0351s/iter; left time: 744.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0458716 Vali Loss: 0.0539440 Test Loss: 0.0576853\n",
      "Validation loss decreased (0.054472 --> 0.053944).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0437656\n",
      "\tspeed: 0.0671s/iter; left time: 1415.3703s\n",
      "\titers: 200, epoch: 6 | loss: 0.0466216\n",
      "\tspeed: 0.0351s/iter; left time: 736.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0449662 Vali Loss: 0.0534553 Test Loss: 0.0572674\n",
      "Validation loss decreased (0.053944 --> 0.053455).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0432135\n",
      "\tspeed: 0.0636s/iter; left time: 1326.0862s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448062\n",
      "\tspeed: 0.0349s/iter; left time: 725.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0443374 Vali Loss: 0.0534272 Test Loss: 0.0571053\n",
      "Validation loss decreased (0.053455 --> 0.053427).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409291\n",
      "\tspeed: 0.0637s/iter; left time: 1315.3355s\n",
      "\titers: 200, epoch: 8 | loss: 0.0430096\n",
      "\tspeed: 0.0351s/iter; left time: 720.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0437858 Vali Loss: 0.0525818 Test Loss: 0.0564486\n",
      "Validation loss decreased (0.053427 --> 0.052582).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0434833\n",
      "\tspeed: 0.0640s/iter; left time: 1307.3049s\n",
      "\titers: 200, epoch: 9 | loss: 0.0431426\n",
      "\tspeed: 0.0347s/iter; left time: 705.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0433379 Vali Loss: 0.0527517 Test Loss: 0.0565157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0436005\n",
      "\tspeed: 0.0650s/iter; left time: 1312.1588s\n",
      "\titers: 200, epoch: 10 | loss: 0.0441317\n",
      "\tspeed: 0.0351s/iter; left time: 704.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0429824 Vali Loss: 0.0525102 Test Loss: 0.0561908\n",
      "Validation loss decreased (0.052582 --> 0.052510).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441469\n",
      "\tspeed: 0.0643s/iter; left time: 1283.2634s\n",
      "\titers: 200, epoch: 11 | loss: 0.0429173\n",
      "\tspeed: 0.0351s/iter; left time: 697.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0427291 Vali Loss: 0.0522521 Test Loss: 0.0560558\n",
      "Validation loss decreased (0.052510 --> 0.052252).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414824\n",
      "\tspeed: 0.0648s/iter; left time: 1280.0183s\n",
      "\titers: 200, epoch: 12 | loss: 0.0416152\n",
      "\tspeed: 0.0351s/iter; left time: 689.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0424671 Vali Loss: 0.0520982 Test Loss: 0.0563322\n",
      "Validation loss decreased (0.052252 --> 0.052098).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0391976\n",
      "\tspeed: 0.0643s/iter; left time: 1256.3365s\n",
      "\titers: 200, epoch: 13 | loss: 0.0431828\n",
      "\tspeed: 0.0351s/iter; left time: 682.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0422042 Vali Loss: 0.0521203 Test Loss: 0.0560514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0414172\n",
      "\tspeed: 0.0635s/iter; left time: 1226.3180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0436923\n",
      "\tspeed: 0.0351s/iter; left time: 674.5539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0420351 Vali Loss: 0.0519225 Test Loss: 0.0560759\n",
      "Validation loss decreased (0.052098 --> 0.051923).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0435061\n",
      "\tspeed: 0.0638s/iter; left time: 1216.5322s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421386\n",
      "\tspeed: 0.0351s/iter; left time: 665.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0418336 Vali Loss: 0.0516601 Test Loss: 0.0557258\n",
      "Validation loss decreased (0.051923 --> 0.051660).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0417260\n",
      "\tspeed: 0.0641s/iter; left time: 1208.7892s\n",
      "\titers: 200, epoch: 16 | loss: 0.0413655\n",
      "\tspeed: 0.0350s/iter; left time: 656.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0416313 Vali Loss: 0.0515719 Test Loss: 0.0557763\n",
      "Validation loss decreased (0.051660 --> 0.051572).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0441681\n",
      "\tspeed: 0.0641s/iter; left time: 1195.2433s\n",
      "\titers: 200, epoch: 17 | loss: 0.0442261\n",
      "\tspeed: 0.0348s/iter; left time: 644.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0415218 Vali Loss: 0.0514898 Test Loss: 0.0556714\n",
      "Validation loss decreased (0.051572 --> 0.051490).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0444827\n",
      "\tspeed: 0.0640s/iter; left time: 1178.9398s\n",
      "\titers: 200, epoch: 18 | loss: 0.0387237\n",
      "\tspeed: 0.0352s/iter; left time: 643.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0414431 Vali Loss: 0.0514083 Test Loss: 0.0557639\n",
      "Validation loss decreased (0.051490 --> 0.051408).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0441746\n",
      "\tspeed: 0.0645s/iter; left time: 1173.3143s\n",
      "\titers: 200, epoch: 19 | loss: 0.0418730\n",
      "\tspeed: 0.0352s/iter; left time: 637.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0412976 Vali Loss: 0.0512842 Test Loss: 0.0555965\n",
      "Validation loss decreased (0.051408 --> 0.051284).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0414115\n",
      "\tspeed: 0.0639s/iter; left time: 1147.5876s\n",
      "\titers: 200, epoch: 20 | loss: 0.0421314\n",
      "\tspeed: 0.0351s/iter; left time: 626.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0411188 Vali Loss: 0.0511608 Test Loss: 0.0555696\n",
      "Validation loss decreased (0.051284 --> 0.051161).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0425900\n",
      "\tspeed: 0.0650s/iter; left time: 1153.4993s\n",
      "\titers: 200, epoch: 21 | loss: 0.0420930\n",
      "\tspeed: 0.0351s/iter; left time: 619.1400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0410380 Vali Loss: 0.0512272 Test Loss: 0.0553351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0425151\n",
      "\tspeed: 0.0645s/iter; left time: 1130.6564s\n",
      "\titers: 200, epoch: 22 | loss: 0.0404247\n",
      "\tspeed: 0.0348s/iter; left time: 607.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0409953 Vali Loss: 0.0513290 Test Loss: 0.0555016\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0388141\n",
      "\tspeed: 0.0642s/iter; left time: 1111.1592s\n",
      "\titers: 200, epoch: 23 | loss: 0.0456665\n",
      "\tspeed: 0.0351s/iter; left time: 603.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0409120 Vali Loss: 0.0512186 Test Loss: 0.0554686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0415782\n",
      "\tspeed: 0.0635s/iter; left time: 1084.5977s\n",
      "\titers: 200, epoch: 24 | loss: 0.0400148\n",
      "\tspeed: 0.0351s/iter; left time: 595.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0408801 Vali Loss: 0.0510632 Test Loss: 0.0552173\n",
      "Validation loss decreased (0.051161 --> 0.051063).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0390060\n",
      "\tspeed: 0.0642s/iter; left time: 1081.8480s\n",
      "\titers: 200, epoch: 25 | loss: 0.0404676\n",
      "\tspeed: 0.0351s/iter; left time: 587.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0407820 Vali Loss: 0.0510935 Test Loss: 0.0554337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0458288\n",
      "\tspeed: 0.0646s/iter; left time: 1074.6319s\n",
      "\titers: 200, epoch: 26 | loss: 0.0387769\n",
      "\tspeed: 0.0348s/iter; left time: 574.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0407251 Vali Loss: 0.0509819 Test Loss: 0.0554200\n",
      "Validation loss decreased (0.051063 --> 0.050982).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0404320\n",
      "\tspeed: 0.0658s/iter; left time: 1078.9898s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413531\n",
      "\tspeed: 0.0350s/iter; left time: 569.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0407241 Vali Loss: 0.0510599 Test Loss: 0.0553351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0404339\n",
      "\tspeed: 0.0638s/iter; left time: 1032.9770s\n",
      "\titers: 200, epoch: 28 | loss: 0.0420386\n",
      "\tspeed: 0.0351s/iter; left time: 564.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0406286 Vali Loss: 0.0510436 Test Loss: 0.0554185\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0406484\n",
      "\tspeed: 0.0636s/iter; left time: 1015.1565s\n",
      "\titers: 200, epoch: 29 | loss: 0.0422703\n",
      "\tspeed: 0.0351s/iter; left time: 557.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0405925 Vali Loss: 0.0509693 Test Loss: 0.0553177\n",
      "Validation loss decreased (0.050982 --> 0.050969).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0401751\n",
      "\tspeed: 0.0644s/iter; left time: 1013.3650s\n",
      "\titers: 200, epoch: 30 | loss: 0.0380990\n",
      "\tspeed: 0.0351s/iter; left time: 548.6465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0405841 Vali Loss: 0.0510028 Test Loss: 0.0553068\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0398719\n",
      "\tspeed: 0.0637s/iter; left time: 988.3468s\n",
      "\titers: 200, epoch: 31 | loss: 0.0389703\n",
      "\tspeed: 0.0351s/iter; left time: 540.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0405483 Vali Loss: 0.0509729 Test Loss: 0.0552955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0416216\n",
      "\tspeed: 0.0632s/iter; left time: 965.4634s\n",
      "\titers: 200, epoch: 32 | loss: 0.0408665\n",
      "\tspeed: 0.0351s/iter; left time: 532.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0404781 Vali Loss: 0.0509606 Test Loss: 0.0552734\n",
      "Validation loss decreased (0.050969 --> 0.050961).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0401581\n",
      "\tspeed: 0.0639s/iter; left time: 963.0300s\n",
      "\titers: 200, epoch: 33 | loss: 0.0444146\n",
      "\tspeed: 0.0351s/iter; left time: 524.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0405358 Vali Loss: 0.0509348 Test Loss: 0.0552480\n",
      "Validation loss decreased (0.050961 --> 0.050935).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0434580\n",
      "\tspeed: 0.0652s/iter; left time: 967.3864s\n",
      "\titers: 200, epoch: 34 | loss: 0.0450271\n",
      "\tspeed: 0.0351s/iter; left time: 517.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404639 Vali Loss: 0.0508491 Test Loss: 0.0552922\n",
      "Validation loss decreased (0.050935 --> 0.050849).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0404810\n",
      "\tspeed: 0.0640s/iter; left time: 935.7007s\n",
      "\titers: 200, epoch: 35 | loss: 0.0394439\n",
      "\tspeed: 0.0351s/iter; left time: 509.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404808 Vali Loss: 0.0508755 Test Loss: 0.0551853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0409779\n",
      "\tspeed: 0.0635s/iter; left time: 914.0628s\n",
      "\titers: 200, epoch: 36 | loss: 0.0380761\n",
      "\tspeed: 0.0351s/iter; left time: 501.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0404602 Vali Loss: 0.0508840 Test Loss: 0.0552284\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0408223\n",
      "\tspeed: 0.0637s/iter; left time: 903.0386s\n",
      "\titers: 200, epoch: 37 | loss: 0.0389406\n",
      "\tspeed: 0.0351s/iter; left time: 494.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0403593 Vali Loss: 0.0509414 Test Loss: 0.0552473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0373138\n",
      "\tspeed: 0.0636s/iter; left time: 886.9634s\n",
      "\titers: 200, epoch: 38 | loss: 0.0389028\n",
      "\tspeed: 0.0351s/iter; left time: 485.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0403862 Vali Loss: 0.0509620 Test Loss: 0.0551982\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0404616\n",
      "\tspeed: 0.0632s/iter; left time: 867.3303s\n",
      "\titers: 200, epoch: 39 | loss: 0.0412011\n",
      "\tspeed: 0.0351s/iter; left time: 478.4572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0403805 Vali Loss: 0.0509299 Test Loss: 0.0552320\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0420976\n",
      "\tspeed: 0.0632s/iter; left time: 853.8060s\n",
      "\titers: 200, epoch: 40 | loss: 0.0417795\n",
      "\tspeed: 0.0351s/iter; left time: 470.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0403735 Vali Loss: 0.0509674 Test Loss: 0.0552053\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0420395\n",
      "\tspeed: 0.0635s/iter; left time: 843.0458s\n",
      "\titers: 200, epoch: 41 | loss: 0.0419803\n",
      "\tspeed: 0.0351s/iter; left time: 462.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0403411 Vali Loss: 0.0508990 Test Loss: 0.0551867\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0386650\n",
      "\tspeed: 0.0631s/iter; left time: 823.5859s\n",
      "\titers: 200, epoch: 42 | loss: 0.0394861\n",
      "\tspeed: 0.0351s/iter; left time: 454.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0403213 Vali Loss: 0.0509176 Test Loss: 0.0551957\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0385314\n",
      "\tspeed: 0.0635s/iter; left time: 814.5643s\n",
      "\titers: 200, epoch: 43 | loss: 0.0429035\n",
      "\tspeed: 0.0351s/iter; left time: 447.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0403033 Vali Loss: 0.0508787 Test Loss: 0.0552006\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0395700\n",
      "\tspeed: 0.0635s/iter; left time: 800.6240s\n",
      "\titers: 200, epoch: 44 | loss: 0.0420449\n",
      "\tspeed: 0.0351s/iter; left time: 438.9876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0403666 Vali Loss: 0.0508539 Test Loss: 0.0551681\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010036074556410313, rmse:0.10018020868301392, mae:0.05529222637414932, rse:0.38649246096611023\n",
      "Intermediate time for FR and pred_len 24: 00h:17m:30.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0945510\n",
      "\tspeed: 0.0573s/iter; left time: 1265.8507s\n",
      "\titers: 200, epoch: 1 | loss: 0.0804860\n",
      "\tspeed: 0.0351s/iter; left time: 772.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 222 | Train Loss: 0.0976736 Vali Loss: 0.0885169 Test Loss: 0.0971670\n",
      "Validation loss decreased (inf --> 0.088517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0725761\n",
      "\tspeed: 0.0659s/iter; left time: 1440.8780s\n",
      "\titers: 200, epoch: 2 | loss: 0.0638014\n",
      "\tspeed: 0.0349s/iter; left time: 760.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0691180 Vali Loss: 0.0740624 Test Loss: 0.0824161\n",
      "Validation loss decreased (0.088517 --> 0.074062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0630231\n",
      "\tspeed: 0.0673s/iter; left time: 1457.6326s\n",
      "\titers: 200, epoch: 3 | loss: 0.0608463\n",
      "\tspeed: 0.0349s/iter; left time: 753.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 222 | Train Loss: 0.0631260 Vali Loss: 0.0725156 Test Loss: 0.0812358\n",
      "Validation loss decreased (0.074062 --> 0.072516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0594296\n",
      "\tspeed: 0.0667s/iter; left time: 1428.9581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622745\n",
      "\tspeed: 0.0355s/iter; left time: 757.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0616088 Vali Loss: 0.0718310 Test Loss: 0.0810862\n",
      "Validation loss decreased (0.072516 --> 0.071831).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637568\n",
      "\tspeed: 0.0682s/iter; left time: 1446.7270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0579425\n",
      "\tspeed: 0.0355s/iter; left time: 748.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0605200 Vali Loss: 0.0706862 Test Loss: 0.0809231\n",
      "Validation loss decreased (0.071831 --> 0.070686).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610347\n",
      "\tspeed: 0.0665s/iter; left time: 1395.1944s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598491\n",
      "\tspeed: 0.0354s/iter; left time: 740.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0597658 Vali Loss: 0.0708580 Test Loss: 0.0803957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572771\n",
      "\tspeed: 0.0661s/iter; left time: 1372.9512s\n",
      "\titers: 200, epoch: 7 | loss: 0.0592725\n",
      "\tspeed: 0.0355s/iter; left time: 733.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0592040 Vali Loss: 0.0703460 Test Loss: 0.0810018\n",
      "Validation loss decreased (0.070686 --> 0.070346).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603465\n",
      "\tspeed: 0.0671s/iter; left time: 1378.0604s\n",
      "\titers: 200, epoch: 8 | loss: 0.0571824\n",
      "\tspeed: 0.0354s/iter; left time: 723.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0587333 Vali Loss: 0.0699967 Test Loss: 0.0808316\n",
      "Validation loss decreased (0.070346 --> 0.069997).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0587291\n",
      "\tspeed: 0.0694s/iter; left time: 1411.4907s\n",
      "\titers: 200, epoch: 9 | loss: 0.0578059\n",
      "\tspeed: 0.0355s/iter; left time: 717.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0582413 Vali Loss: 0.0700071 Test Loss: 0.0808572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0635774\n",
      "\tspeed: 0.0658s/iter; left time: 1322.8441s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593283\n",
      "\tspeed: 0.0354s/iter; left time: 708.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0578581 Vali Loss: 0.0697521 Test Loss: 0.0807573\n",
      "Validation loss decreased (0.069997 --> 0.069752).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0564659\n",
      "\tspeed: 0.0678s/iter; left time: 1348.2090s\n",
      "\titers: 200, epoch: 11 | loss: 0.0573542\n",
      "\tspeed: 0.0354s/iter; left time: 699.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0575417 Vali Loss: 0.0696464 Test Loss: 0.0805303\n",
      "Validation loss decreased (0.069752 --> 0.069646).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0535343\n",
      "\tspeed: 0.0672s/iter; left time: 1321.5389s\n",
      "\titers: 200, epoch: 12 | loss: 0.0554652\n",
      "\tspeed: 0.0353s/iter; left time: 690.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0572956 Vali Loss: 0.0695640 Test Loss: 0.0808186\n",
      "Validation loss decreased (0.069646 --> 0.069564).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570938\n",
      "\tspeed: 0.0678s/iter; left time: 1317.5560s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562633\n",
      "\tspeed: 0.0355s/iter; left time: 686.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0569312 Vali Loss: 0.0693360 Test Loss: 0.0807541\n",
      "Validation loss decreased (0.069564 --> 0.069336).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0537705\n",
      "\tspeed: 0.0687s/iter; left time: 1320.1573s\n",
      "\titers: 200, epoch: 14 | loss: 0.0578052\n",
      "\tspeed: 0.0354s/iter; left time: 676.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0566256 Vali Loss: 0.0694911 Test Loss: 0.0805661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587510\n",
      "\tspeed: 0.0652s/iter; left time: 1237.5370s\n",
      "\titers: 200, epoch: 15 | loss: 0.0568240\n",
      "\tspeed: 0.0354s/iter; left time: 668.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0564097 Vali Loss: 0.0691684 Test Loss: 0.0807191\n",
      "Validation loss decreased (0.069336 --> 0.069168).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0599924\n",
      "\tspeed: 0.0680s/iter; left time: 1275.8116s\n",
      "\titers: 200, epoch: 16 | loss: 0.0536479\n",
      "\tspeed: 0.0354s/iter; left time: 660.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0561433 Vali Loss: 0.0693624 Test Loss: 0.0812679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0548374\n",
      "\tspeed: 0.0655s/iter; left time: 1214.5475s\n",
      "\titers: 200, epoch: 17 | loss: 0.0567769\n",
      "\tspeed: 0.0354s/iter; left time: 653.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0559172 Vali Loss: 0.0695743 Test Loss: 0.0812910\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608710\n",
      "\tspeed: 0.0658s/iter; left time: 1205.4118s\n",
      "\titers: 200, epoch: 18 | loss: 0.0556681\n",
      "\tspeed: 0.0354s/iter; left time: 645.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0557394 Vali Loss: 0.0695313 Test Loss: 0.0813298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0558614\n",
      "\tspeed: 0.0657s/iter; left time: 1189.2892s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570341\n",
      "\tspeed: 0.0354s/iter; left time: 637.6695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0555549 Vali Loss: 0.0694608 Test Loss: 0.0812635\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582343\n",
      "\tspeed: 0.0663s/iter; left time: 1186.0984s\n",
      "\titers: 200, epoch: 20 | loss: 0.0527344\n",
      "\tspeed: 0.0354s/iter; left time: 630.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0553880 Vali Loss: 0.0695730 Test Loss: 0.0817058\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0549253\n",
      "\tspeed: 0.0655s/iter; left time: 1156.4616s\n",
      "\titers: 200, epoch: 21 | loss: 0.0572006\n",
      "\tspeed: 0.0355s/iter; left time: 623.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0552723 Vali Loss: 0.0695640 Test Loss: 0.0813932\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0524042\n",
      "\tspeed: 0.0661s/iter; left time: 1152.6042s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539139\n",
      "\tspeed: 0.0355s/iter; left time: 615.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0551118 Vali Loss: 0.0697175 Test Loss: 0.0816214\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0565736\n",
      "\tspeed: 0.0654s/iter; left time: 1125.5020s\n",
      "\titers: 200, epoch: 23 | loss: 0.0502564\n",
      "\tspeed: 0.0355s/iter; left time: 607.7470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0549755 Vali Loss: 0.0695328 Test Loss: 0.0816044\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0571896\n",
      "\tspeed: 0.0655s/iter; left time: 1113.1195s\n",
      "\titers: 200, epoch: 24 | loss: 0.0563414\n",
      "\tspeed: 0.0355s/iter; left time: 599.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0548804 Vali Loss: 0.0693878 Test Loss: 0.0821570\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0534910\n",
      "\tspeed: 0.0660s/iter; left time: 1106.5047s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567336\n",
      "\tspeed: 0.0354s/iter; left time: 590.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0548006 Vali Loss: 0.0694751 Test Loss: 0.0820147\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01948266476392746, rmse:0.13958030939102173, mae:0.08071916550397873, rse:0.5399338006973267\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0952632\n",
      "\tspeed: 0.0373s/iter; left time: 824.5705s\n",
      "\titers: 200, epoch: 1 | loss: 0.0882251\n",
      "\tspeed: 0.0354s/iter; left time: 778.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0984777 Vali Loss: 0.0887115 Test Loss: 0.0972712\n",
      "Validation loss decreased (inf --> 0.088711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0684055\n",
      "\tspeed: 0.0682s/iter; left time: 1491.7078s\n",
      "\titers: 200, epoch: 2 | loss: 0.0648619\n",
      "\tspeed: 0.0353s/iter; left time: 769.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0695240 Vali Loss: 0.0743351 Test Loss: 0.0826704\n",
      "Validation loss decreased (0.088711 --> 0.074335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636595\n",
      "\tspeed: 0.0668s/iter; left time: 1447.5879s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675047\n",
      "\tspeed: 0.0354s/iter; left time: 762.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0633260 Vali Loss: 0.0723846 Test Loss: 0.0817243\n",
      "Validation loss decreased (0.074335 --> 0.072385).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609815\n",
      "\tspeed: 0.0665s/iter; left time: 1426.3549s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616805\n",
      "\tspeed: 0.0351s/iter; left time: 748.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0616337 Vali Loss: 0.0714362 Test Loss: 0.0802713\n",
      "Validation loss decreased (0.072385 --> 0.071436).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0625119\n",
      "\tspeed: 0.0682s/iter; left time: 1447.5042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612546\n",
      "\tspeed: 0.0354s/iter; left time: 746.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0605159 Vali Loss: 0.0711307 Test Loss: 0.0806584\n",
      "Validation loss decreased (0.071436 --> 0.071131).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579954\n",
      "\tspeed: 0.0666s/iter; left time: 1397.2714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0607083\n",
      "\tspeed: 0.0354s/iter; left time: 739.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0598531 Vali Loss: 0.0707090 Test Loss: 0.0807273\n",
      "Validation loss decreased (0.071131 --> 0.070709).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563586\n",
      "\tspeed: 0.0660s/iter; left time: 1371.2620s\n",
      "\titers: 200, epoch: 7 | loss: 0.0581983\n",
      "\tspeed: 0.0354s/iter; left time: 730.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0591799 Vali Loss: 0.0702574 Test Loss: 0.0805652\n",
      "Validation loss decreased (0.070709 --> 0.070257).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0548895\n",
      "\tspeed: 0.0676s/iter; left time: 1389.8110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0588075\n",
      "\tspeed: 0.0354s/iter; left time: 723.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0587707 Vali Loss: 0.0706747 Test Loss: 0.0802811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0568464\n",
      "\tspeed: 0.0654s/iter; left time: 1329.5698s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626500\n",
      "\tspeed: 0.0351s/iter; left time: 709.1836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0583234 Vali Loss: 0.0702878 Test Loss: 0.0808060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0558727\n",
      "\tspeed: 0.0660s/iter; left time: 1325.8540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0567011\n",
      "\tspeed: 0.0350s/iter; left time: 700.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0579293 Vali Loss: 0.0699047 Test Loss: 0.0802349\n",
      "Validation loss decreased (0.070257 --> 0.069905).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0550953\n",
      "\tspeed: 0.0667s/iter; left time: 1325.3956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0569662\n",
      "\tspeed: 0.0354s/iter; left time: 699.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0576132 Vali Loss: 0.0698486 Test Loss: 0.0809873\n",
      "Validation loss decreased (0.069905 --> 0.069849).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0587837\n",
      "\tspeed: 0.0693s/iter; left time: 1362.3569s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571281\n",
      "\tspeed: 0.0354s/iter; left time: 692.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0572527 Vali Loss: 0.0696938 Test Loss: 0.0804241\n",
      "Validation loss decreased (0.069849 --> 0.069694).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0594783\n",
      "\tspeed: 0.0664s/iter; left time: 1290.7610s\n",
      "\titers: 200, epoch: 13 | loss: 0.0590962\n",
      "\tspeed: 0.0354s/iter; left time: 684.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0569948 Vali Loss: 0.0695417 Test Loss: 0.0802769\n",
      "Validation loss decreased (0.069694 --> 0.069542).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0586970\n",
      "\tspeed: 0.0691s/iter; left time: 1328.1501s\n",
      "\titers: 200, epoch: 14 | loss: 0.0570726\n",
      "\tspeed: 0.0353s/iter; left time: 674.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0567403 Vali Loss: 0.0694959 Test Loss: 0.0799488\n",
      "Validation loss decreased (0.069542 --> 0.069496).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0508721\n",
      "\tspeed: 0.0674s/iter; left time: 1279.5230s\n",
      "\titers: 200, epoch: 15 | loss: 0.0571368\n",
      "\tspeed: 0.0354s/iter; left time: 669.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0564738 Vali Loss: 0.0696391 Test Loss: 0.0806447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578979\n",
      "\tspeed: 0.0655s/iter; left time: 1229.7151s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557072\n",
      "\tspeed: 0.0354s/iter; left time: 661.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0562549 Vali Loss: 0.0693150 Test Loss: 0.0804174\n",
      "Validation loss decreased (0.069496 --> 0.069315).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562159\n",
      "\tspeed: 0.0687s/iter; left time: 1274.4518s\n",
      "\titers: 200, epoch: 17 | loss: 0.0547446\n",
      "\tspeed: 0.0354s/iter; left time: 653.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0560603 Vali Loss: 0.0694241 Test Loss: 0.0808445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0540287\n",
      "\tspeed: 0.0656s/iter; left time: 1202.6489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0579191\n",
      "\tspeed: 0.0354s/iter; left time: 644.7447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0558207 Vali Loss: 0.0693042 Test Loss: 0.0811839\n",
      "Validation loss decreased (0.069315 --> 0.069304).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564311\n",
      "\tspeed: 0.0667s/iter; left time: 1207.6176s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542815\n",
      "\tspeed: 0.0354s/iter; left time: 637.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0556295 Vali Loss: 0.0692249 Test Loss: 0.0809378\n",
      "Validation loss decreased (0.069304 --> 0.069225).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543697\n",
      "\tspeed: 0.0662s/iter; left time: 1184.5198s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536799\n",
      "\tspeed: 0.0355s/iter; left time: 630.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0554733 Vali Loss: 0.0693348 Test Loss: 0.0810664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560020\n",
      "\tspeed: 0.0663s/iter; left time: 1170.3878s\n",
      "\titers: 200, epoch: 21 | loss: 0.0537978\n",
      "\tspeed: 0.0355s/iter; left time: 624.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0553447 Vali Loss: 0.0692935 Test Loss: 0.0814518\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0574112\n",
      "\tspeed: 0.0664s/iter; left time: 1157.2201s\n",
      "\titers: 200, epoch: 22 | loss: 0.0532606\n",
      "\tspeed: 0.0354s/iter; left time: 613.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0551855 Vali Loss: 0.0692805 Test Loss: 0.0813622\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513187\n",
      "\tspeed: 0.0653s/iter; left time: 1124.6813s\n",
      "\titers: 200, epoch: 23 | loss: 0.0571556\n",
      "\tspeed: 0.0354s/iter; left time: 605.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0550499 Vali Loss: 0.0693083 Test Loss: 0.0811403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0542284\n",
      "\tspeed: 0.0653s/iter; left time: 1109.8194s\n",
      "\titers: 200, epoch: 24 | loss: 0.0524075\n",
      "\tspeed: 0.0354s/iter; left time: 597.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0549588 Vali Loss: 0.0693526 Test Loss: 0.0811186\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0529980\n",
      "\tspeed: 0.0654s/iter; left time: 1096.4720s\n",
      "\titers: 200, epoch: 25 | loss: 0.0608104\n",
      "\tspeed: 0.0352s/iter; left time: 587.1956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0548511 Vali Loss: 0.0693528 Test Loss: 0.0813975\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0549603\n",
      "\tspeed: 0.0659s/iter; left time: 1090.3294s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546359\n",
      "\tspeed: 0.0350s/iter; left time: 575.4963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 222 | Train Loss: 0.0547515 Vali Loss: 0.0693082 Test Loss: 0.0813971\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0566669\n",
      "\tspeed: 0.0657s/iter; left time: 1072.5640s\n",
      "\titers: 200, epoch: 27 | loss: 0.0536185\n",
      "\tspeed: 0.0354s/iter; left time: 574.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0546388 Vali Loss: 0.0692286 Test Loss: 0.0812176\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0581224\n",
      "\tspeed: 0.0652s/iter; left time: 1050.6461s\n",
      "\titers: 200, epoch: 28 | loss: 0.0531175\n",
      "\tspeed: 0.0354s/iter; left time: 566.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0545494 Vali Loss: 0.0692481 Test Loss: 0.0811681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0550669\n",
      "\tspeed: 0.0660s/iter; left time: 1048.3709s\n",
      "\titers: 200, epoch: 29 | loss: 0.0559058\n",
      "\tspeed: 0.0353s/iter; left time: 557.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0545274 Vali Loss: 0.0692898 Test Loss: 0.0814695\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019968293607234955, rmse:0.1413092166185379, mae:0.08093781024217606, rse:0.546621561050415\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:21.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0937559\n",
      "\tspeed: 0.0561s/iter; left time: 1239.1318s\n",
      "\titers: 200, epoch: 1 | loss: 0.0854991\n",
      "\tspeed: 0.0355s/iter; left time: 779.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 222 | Train Loss: 0.0996557 Vali Loss: 0.0909250 Test Loss: 0.0982337\n",
      "Validation loss decreased (inf --> 0.090925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0671461\n",
      "\tspeed: 0.0656s/iter; left time: 1434.8695s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668403\n",
      "\tspeed: 0.0355s/iter; left time: 772.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0727891 Vali Loss: 0.0776555 Test Loss: 0.0865498\n",
      "Validation loss decreased (0.090925 --> 0.077656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0663325\n",
      "\tspeed: 0.0668s/iter; left time: 1446.0545s\n",
      "\titers: 200, epoch: 3 | loss: 0.0676556\n",
      "\tspeed: 0.0356s/iter; left time: 766.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0669277 Vali Loss: 0.0760982 Test Loss: 0.0855469\n",
      "Validation loss decreased (0.077656 --> 0.076098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676006\n",
      "\tspeed: 0.0666s/iter; left time: 1428.5333s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629337\n",
      "\tspeed: 0.0357s/iter; left time: 760.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0653958 Vali Loss: 0.0748803 Test Loss: 0.0857829\n",
      "Validation loss decreased (0.076098 --> 0.074880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0611826\n",
      "\tspeed: 0.0730s/iter; left time: 1548.7207s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664870\n",
      "\tspeed: 0.0356s/iter; left time: 751.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0643448 Vali Loss: 0.0745668 Test Loss: 0.0858744\n",
      "Validation loss decreased (0.074880 --> 0.074567).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614737\n",
      "\tspeed: 0.0655s/iter; left time: 1375.5068s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662357\n",
      "\tspeed: 0.0356s/iter; left time: 743.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0634906 Vali Loss: 0.0741564 Test Loss: 0.0861201\n",
      "Validation loss decreased (0.074567 --> 0.074156).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0638003\n",
      "\tspeed: 0.0705s/iter; left time: 1464.1748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668866\n",
      "\tspeed: 0.0356s/iter; left time: 735.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0628535 Vali Loss: 0.0738947 Test Loss: 0.0862584\n",
      "Validation loss decreased (0.074156 --> 0.073895).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640526\n",
      "\tspeed: 0.0671s/iter; left time: 1378.5933s\n",
      "\titers: 200, epoch: 8 | loss: 0.0602180\n",
      "\tspeed: 0.0356s/iter; left time: 727.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0623205 Vali Loss: 0.0736341 Test Loss: 0.0873836\n",
      "Validation loss decreased (0.073895 --> 0.073634).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0597319\n",
      "\tspeed: 0.0677s/iter; left time: 1375.0568s\n",
      "\titers: 200, epoch: 9 | loss: 0.0623516\n",
      "\tspeed: 0.0356s/iter; left time: 719.8003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0617649 Vali Loss: 0.0733476 Test Loss: 0.0872618\n",
      "Validation loss decreased (0.073634 --> 0.073348).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0592745\n",
      "\tspeed: 0.0667s/iter; left time: 1340.9773s\n",
      "\titers: 200, epoch: 10 | loss: 0.0611175\n",
      "\tspeed: 0.0356s/iter; left time: 711.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0613298 Vali Loss: 0.0734085 Test Loss: 0.0880000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628366\n",
      "\tspeed: 0.0668s/iter; left time: 1327.6390s\n",
      "\titers: 200, epoch: 11 | loss: 0.0590079\n",
      "\tspeed: 0.0357s/iter; left time: 705.2565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0608626 Vali Loss: 0.0732229 Test Loss: 0.0884979\n",
      "Validation loss decreased (0.073348 --> 0.073223).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0631045\n",
      "\tspeed: 0.0685s/iter; left time: 1346.3562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0598766\n",
      "\tspeed: 0.0356s/iter; left time: 696.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0604511 Vali Loss: 0.0730404 Test Loss: 0.0892168\n",
      "Validation loss decreased (0.073223 --> 0.073040).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0589007\n",
      "\tspeed: 0.0709s/iter; left time: 1377.8861s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626884\n",
      "\tspeed: 0.0356s/iter; left time: 688.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0600724 Vali Loss: 0.0733249 Test Loss: 0.0880689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554329\n",
      "\tspeed: 0.0646s/iter; left time: 1241.6465s\n",
      "\titers: 200, epoch: 14 | loss: 0.0609844\n",
      "\tspeed: 0.0356s/iter; left time: 680.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0597418 Vali Loss: 0.0732096 Test Loss: 0.0892474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584123\n",
      "\tspeed: 0.0669s/iter; left time: 1270.9218s\n",
      "\titers: 200, epoch: 15 | loss: 0.0562647\n",
      "\tspeed: 0.0356s/iter; left time: 672.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0594256 Vali Loss: 0.0731097 Test Loss: 0.0883574\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0595126\n",
      "\tspeed: 0.0652s/iter; left time: 1223.3511s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591843\n",
      "\tspeed: 0.0356s/iter; left time: 664.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0590443 Vali Loss: 0.0733004 Test Loss: 0.0884439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0588591\n",
      "\tspeed: 0.0654s/iter; left time: 1213.0199s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619928\n",
      "\tspeed: 0.0356s/iter; left time: 656.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0588040 Vali Loss: 0.0732601 Test Loss: 0.0887275\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0623288\n",
      "\tspeed: 0.0658s/iter; left time: 1206.2240s\n",
      "\titers: 200, epoch: 18 | loss: 0.0596518\n",
      "\tspeed: 0.0356s/iter; left time: 647.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0585427 Vali Loss: 0.0734186 Test Loss: 0.0887857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578743\n",
      "\tspeed: 0.0652s/iter; left time: 1180.0319s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603924\n",
      "\tspeed: 0.0356s/iter; left time: 640.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0582407 Vali Loss: 0.0731707 Test Loss: 0.0886741\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0583632\n",
      "\tspeed: 0.0652s/iter; left time: 1166.5112s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561615\n",
      "\tspeed: 0.0356s/iter; left time: 632.5779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0580611 Vali Loss: 0.0733136 Test Loss: 0.0878214\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0573657\n",
      "\tspeed: 0.0665s/iter; left time: 1174.8416s\n",
      "\titers: 200, epoch: 21 | loss: 0.0576622\n",
      "\tspeed: 0.0356s/iter; left time: 625.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0579166 Vali Loss: 0.0733115 Test Loss: 0.0880976\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0600090\n",
      "\tspeed: 0.0652s/iter; left time: 1137.6887s\n",
      "\titers: 200, epoch: 22 | loss: 0.0580474\n",
      "\tspeed: 0.0356s/iter; left time: 617.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0577131 Vali Loss: 0.0735373 Test Loss: 0.0889308\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022798532620072365, rmse:0.15099182724952698, mae:0.08921678364276886, rse:0.5848056674003601\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0909746\n",
      "\tspeed: 0.0377s/iter; left time: 833.2248s\n",
      "\titers: 200, epoch: 1 | loss: 0.0863153\n",
      "\tspeed: 0.0356s/iter; left time: 783.0251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.1003204 Vali Loss: 0.0907418 Test Loss: 0.0980454\n",
      "Validation loss decreased (inf --> 0.090742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0734469\n",
      "\tspeed: 0.0719s/iter; left time: 1572.7107s\n",
      "\titers: 200, epoch: 2 | loss: 0.0706323\n",
      "\tspeed: 0.0356s/iter; left time: 775.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0730947 Vali Loss: 0.0781138 Test Loss: 0.0861697\n",
      "Validation loss decreased (0.090742 --> 0.078114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670260\n",
      "\tspeed: 0.0673s/iter; left time: 1457.4871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0672487\n",
      "\tspeed: 0.0356s/iter; left time: 768.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0671942 Vali Loss: 0.0764739 Test Loss: 0.0861640\n",
      "Validation loss decreased (0.078114 --> 0.076474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0642420\n",
      "\tspeed: 0.0680s/iter; left time: 1458.2017s\n",
      "\titers: 200, epoch: 4 | loss: 0.0681193\n",
      "\tspeed: 0.0356s/iter; left time: 760.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0656319 Vali Loss: 0.0756089 Test Loss: 0.0862310\n",
      "Validation loss decreased (0.076474 --> 0.075609).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0662459\n",
      "\tspeed: 0.0670s/iter; left time: 1420.6034s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619034\n",
      "\tspeed: 0.0356s/iter; left time: 751.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0644669 Vali Loss: 0.0750021 Test Loss: 0.0863676\n",
      "Validation loss decreased (0.075609 --> 0.075002).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0615688\n",
      "\tspeed: 0.0688s/iter; left time: 1443.4137s\n",
      "\titers: 200, epoch: 6 | loss: 0.0642635\n",
      "\tspeed: 0.0356s/iter; left time: 743.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0636490 Vali Loss: 0.0744124 Test Loss: 0.0862947\n",
      "Validation loss decreased (0.075002 --> 0.074412).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0634491\n",
      "\tspeed: 0.0675s/iter; left time: 1401.9660s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646780\n",
      "\tspeed: 0.0356s/iter; left time: 736.2142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0630115 Vali Loss: 0.0743968 Test Loss: 0.0861245\n",
      "Validation loss decreased (0.074412 --> 0.074397).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0609125\n",
      "\tspeed: 0.0680s/iter; left time: 1396.7771s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609732\n",
      "\tspeed: 0.0356s/iter; left time: 728.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0624589 Vali Loss: 0.0742223 Test Loss: 0.0872146\n",
      "Validation loss decreased (0.074397 --> 0.074222).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0626477\n",
      "\tspeed: 0.0745s/iter; left time: 1515.2203s\n",
      "\titers: 200, epoch: 9 | loss: 0.0611828\n",
      "\tspeed: 0.0355s/iter; left time: 718.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0619476 Vali Loss: 0.0739779 Test Loss: 0.0874620\n",
      "Validation loss decreased (0.074222 --> 0.073978).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0587265\n",
      "\tspeed: 0.0668s/iter; left time: 1342.0950s\n",
      "\titers: 200, epoch: 10 | loss: 0.0634449\n",
      "\tspeed: 0.0357s/iter; left time: 714.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0615030 Vali Loss: 0.0735479 Test Loss: 0.0874568\n",
      "Validation loss decreased (0.073978 --> 0.073548).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0611382\n",
      "\tspeed: 0.0682s/iter; left time: 1356.1429s\n",
      "\titers: 200, epoch: 11 | loss: 0.0599037\n",
      "\tspeed: 0.0356s/iter; left time: 704.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0609948 Vali Loss: 0.0734347 Test Loss: 0.0872699\n",
      "Validation loss decreased (0.073548 --> 0.073435).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0662991\n",
      "\tspeed: 0.0685s/iter; left time: 1346.9227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608686\n",
      "\tspeed: 0.0357s/iter; left time: 699.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0606455 Vali Loss: 0.0734493 Test Loss: 0.0879909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596966\n",
      "\tspeed: 0.0657s/iter; left time: 1276.2439s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599534\n",
      "\tspeed: 0.0355s/iter; left time: 686.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0601907 Vali Loss: 0.0735516 Test Loss: 0.0877190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608951\n",
      "\tspeed: 0.0657s/iter; left time: 1262.0944s\n",
      "\titers: 200, epoch: 14 | loss: 0.0583582\n",
      "\tspeed: 0.0355s/iter; left time: 678.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0598597 Vali Loss: 0.0735693 Test Loss: 0.0877809\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0589544\n",
      "\tspeed: 0.0659s/iter; left time: 1251.5029s\n",
      "\titers: 200, epoch: 15 | loss: 0.0602499\n",
      "\tspeed: 0.0356s/iter; left time: 672.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0595246 Vali Loss: 0.0736768 Test Loss: 0.0872724\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0602101\n",
      "\tspeed: 0.0656s/iter; left time: 1230.9355s\n",
      "\titers: 200, epoch: 16 | loss: 0.0599441\n",
      "\tspeed: 0.0356s/iter; left time: 664.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0592592 Vali Loss: 0.0735794 Test Loss: 0.0879726\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604870\n",
      "\tspeed: 0.0660s/iter; left time: 1223.9008s\n",
      "\titers: 200, epoch: 17 | loss: 0.0608909\n",
      "\tspeed: 0.0356s/iter; left time: 656.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0590200 Vali Loss: 0.0737601 Test Loss: 0.0877102\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599590\n",
      "\tspeed: 0.0662s/iter; left time: 1212.8331s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562896\n",
      "\tspeed: 0.0356s/iter; left time: 648.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 222 | Train Loss: 0.0587453 Vali Loss: 0.0735990 Test Loss: 0.0877120\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0577539\n",
      "\tspeed: 0.0667s/iter; left time: 1207.1130s\n",
      "\titers: 200, epoch: 19 | loss: 0.0615933\n",
      "\tspeed: 0.0358s/iter; left time: 644.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0585088 Vali Loss: 0.0736174 Test Loss: 0.0875808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0613166\n",
      "\tspeed: 0.0662s/iter; left time: 1184.7246s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565838\n",
      "\tspeed: 0.0358s/iter; left time: 636.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0583672 Vali Loss: 0.0737815 Test Loss: 0.0879796\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569845\n",
      "\tspeed: 0.0658s/iter; left time: 1161.7737s\n",
      "\titers: 200, epoch: 21 | loss: 0.0580906\n",
      "\tspeed: 0.0356s/iter; left time: 625.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0581812 Vali Loss: 0.0738442 Test Loss: 0.0877143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02144342102110386, rmse:0.1464357227087021, mae:0.08726988732814789, rse:0.5671594142913818\n",
      "Intermediate time for FR and pred_len 168: 00h:07m:33.54s\n",
      "Intermediate time for FR: 00h:34m:26.29s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1215151\n",
      "\tspeed: 0.0584s/iter; left time: 1295.5311s\n",
      "\titers: 200, epoch: 1 | loss: 0.1118875\n",
      "\tspeed: 0.0348s/iter; left time: 769.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 223 | Train Loss: 0.1326542 Vali Loss: 0.0942807 Test Loss: 0.0955525\n",
      "Validation loss decreased (inf --> 0.094281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692392\n",
      "\tspeed: 0.0640s/iter; left time: 1406.0753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668463\n",
      "\tspeed: 0.0348s/iter; left time: 762.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0759663 Vali Loss: 0.0627304 Test Loss: 0.0655534\n",
      "Validation loss decreased (0.094281 --> 0.062730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0653248\n",
      "\tspeed: 0.0646s/iter; left time: 1406.0183s\n",
      "\titers: 200, epoch: 3 | loss: 0.0658268\n",
      "\tspeed: 0.0348s/iter; left time: 753.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0649989 Vali Loss: 0.0598344 Test Loss: 0.0623941\n",
      "Validation loss decreased (0.062730 --> 0.059834).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612408\n",
      "\tspeed: 0.0640s/iter; left time: 1378.4370s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641704\n",
      "\tspeed: 0.0348s/iter; left time: 745.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0622214 Vali Loss: 0.0590931 Test Loss: 0.0612764\n",
      "Validation loss decreased (0.059834 --> 0.059093).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0578229\n",
      "\tspeed: 0.0643s/iter; left time: 1371.0302s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619481\n",
      "\tspeed: 0.0348s/iter; left time: 737.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0607123 Vali Loss: 0.0585121 Test Loss: 0.0608895\n",
      "Validation loss decreased (0.059093 --> 0.058512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601596\n",
      "\tspeed: 0.0650s/iter; left time: 1370.2385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582513\n",
      "\tspeed: 0.0348s/iter; left time: 729.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0596344 Vali Loss: 0.0577123 Test Loss: 0.0601836\n",
      "Validation loss decreased (0.058512 --> 0.057712).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607782\n",
      "\tspeed: 0.0649s/iter; left time: 1354.3299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582576\n",
      "\tspeed: 0.0348s/iter; left time: 721.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0587942 Vali Loss: 0.0578430 Test Loss: 0.0603699\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568957\n",
      "\tspeed: 0.0643s/iter; left time: 1327.7018s\n",
      "\titers: 200, epoch: 8 | loss: 0.0612838\n",
      "\tspeed: 0.0352s/iter; left time: 723.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0581849 Vali Loss: 0.0571036 Test Loss: 0.0594110\n",
      "Validation loss decreased (0.057712 --> 0.057104).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551574\n",
      "\tspeed: 0.0660s/iter; left time: 1348.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544234\n",
      "\tspeed: 0.0351s/iter; left time: 713.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0575606 Vali Loss: 0.0566828 Test Loss: 0.0591373\n",
      "Validation loss decreased (0.057104 --> 0.056683).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0561724\n",
      "\tspeed: 0.0651s/iter; left time: 1315.1278s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550264\n",
      "\tspeed: 0.0348s/iter; left time: 698.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0571180 Vali Loss: 0.0566658 Test Loss: 0.0590203\n",
      "Validation loss decreased (0.056683 --> 0.056666).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0558567\n",
      "\tspeed: 0.0644s/iter; left time: 1286.5022s\n",
      "\titers: 200, epoch: 11 | loss: 0.0551412\n",
      "\tspeed: 0.0348s/iter; left time: 691.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0566924 Vali Loss: 0.0562612 Test Loss: 0.0588131\n",
      "Validation loss decreased (0.056666 --> 0.056261).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0582320\n",
      "\tspeed: 0.0649s/iter; left time: 1281.9793s\n",
      "\titers: 200, epoch: 12 | loss: 0.0552496\n",
      "\tspeed: 0.0348s/iter; left time: 683.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0563733 Vali Loss: 0.0559708 Test Loss: 0.0585530\n",
      "Validation loss decreased (0.056261 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0537563\n",
      "\tspeed: 0.0642s/iter; left time: 1253.5717s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591910\n",
      "\tspeed: 0.0351s/iter; left time: 681.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0560258 Vali Loss: 0.0559113 Test Loss: 0.0584941\n",
      "Validation loss decreased (0.055971 --> 0.055911).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0578019\n",
      "\tspeed: 0.0661s/iter; left time: 1276.2238s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537843\n",
      "\tspeed: 0.0352s/iter; left time: 675.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0557317 Vali Loss: 0.0559744 Test Loss: 0.0587135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582544\n",
      "\tspeed: 0.0650s/iter; left time: 1239.8983s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575671\n",
      "\tspeed: 0.0351s/iter; left time: 666.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0555913 Vali Loss: 0.0556698 Test Loss: 0.0585108\n",
      "Validation loss decreased (0.055911 --> 0.055670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573789\n",
      "\tspeed: 0.0660s/iter; left time: 1244.6433s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597599\n",
      "\tspeed: 0.0350s/iter; left time: 656.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0553490 Vali Loss: 0.0555906 Test Loss: 0.0583118\n",
      "Validation loss decreased (0.055670 --> 0.055591).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0530117\n",
      "\tspeed: 0.0641s/iter; left time: 1193.9584s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540745\n",
      "\tspeed: 0.0348s/iter; left time: 645.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0551468 Vali Loss: 0.0554781 Test Loss: 0.0580857\n",
      "Validation loss decreased (0.055591 --> 0.055478).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0579623\n",
      "\tspeed: 0.0633s/iter; left time: 1164.9885s\n",
      "\titers: 200, epoch: 18 | loss: 0.0557412\n",
      "\tspeed: 0.0348s/iter; left time: 636.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0549865 Vali Loss: 0.0554452 Test Loss: 0.0580464\n",
      "Validation loss decreased (0.055478 --> 0.055445).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0522057\n",
      "\tspeed: 0.0661s/iter; left time: 1202.7089s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545580\n",
      "\tspeed: 0.0351s/iter; left time: 635.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0548027 Vali Loss: 0.0552358 Test Loss: 0.0578113\n",
      "Validation loss decreased (0.055445 --> 0.055236).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0529114\n",
      "\tspeed: 0.0657s/iter; left time: 1179.4980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0570487\n",
      "\tspeed: 0.0351s/iter; left time: 626.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0545887 Vali Loss: 0.0552181 Test Loss: 0.0577855\n",
      "Validation loss decreased (0.055236 --> 0.055218).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0552240\n",
      "\tspeed: 0.0650s/iter; left time: 1153.0202s\n",
      "\titers: 200, epoch: 21 | loss: 0.0546114\n",
      "\tspeed: 0.0348s/iter; left time: 613.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0544541 Vali Loss: 0.0550816 Test Loss: 0.0578460\n",
      "Validation loss decreased (0.055218 --> 0.055082).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533617\n",
      "\tspeed: 0.0654s/iter; left time: 1144.9189s\n",
      "\titers: 200, epoch: 22 | loss: 0.0563828\n",
      "\tspeed: 0.0351s/iter; left time: 611.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0543534 Vali Loss: 0.0550777 Test Loss: 0.0576476\n",
      "Validation loss decreased (0.055082 --> 0.055078).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511991\n",
      "\tspeed: 0.0668s/iter; left time: 1155.7207s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566833\n",
      "\tspeed: 0.0349s/iter; left time: 600.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0543686 Vali Loss: 0.0550093 Test Loss: 0.0577616\n",
      "Validation loss decreased (0.055078 --> 0.055009).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0561067\n",
      "\tspeed: 0.0661s/iter; left time: 1127.7561s\n",
      "\titers: 200, epoch: 24 | loss: 0.0524344\n",
      "\tspeed: 0.0349s/iter; left time: 592.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0541953 Vali Loss: 0.0550054 Test Loss: 0.0576725\n",
      "Validation loss decreased (0.055009 --> 0.055005).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0548554\n",
      "\tspeed: 0.0659s/iter; left time: 1110.4297s\n",
      "\titers: 200, epoch: 25 | loss: 0.0545839\n",
      "\tspeed: 0.0352s/iter; left time: 589.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0541028 Vali Loss: 0.0548294 Test Loss: 0.0576062\n",
      "Validation loss decreased (0.055005 --> 0.054829).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537943\n",
      "\tspeed: 0.0659s/iter; left time: 1095.5692s\n",
      "\titers: 200, epoch: 26 | loss: 0.0544039\n",
      "\tspeed: 0.0352s/iter; left time: 580.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0540807 Vali Loss: 0.0549287 Test Loss: 0.0575237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516824\n",
      "\tspeed: 0.0648s/iter; left time: 1062.6808s\n",
      "\titers: 200, epoch: 27 | loss: 0.0538087\n",
      "\tspeed: 0.0350s/iter; left time: 571.1328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0540239 Vali Loss: 0.0549428 Test Loss: 0.0576405\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0550418\n",
      "\tspeed: 0.0649s/iter; left time: 1049.2804s\n",
      "\titers: 200, epoch: 28 | loss: 0.0557069\n",
      "\tspeed: 0.0352s/iter; left time: 565.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0539656 Vali Loss: 0.0549259 Test Loss: 0.0575492\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525850\n",
      "\tspeed: 0.0658s/iter; left time: 1050.3386s\n",
      "\titers: 200, epoch: 29 | loss: 0.0557783\n",
      "\tspeed: 0.0351s/iter; left time: 556.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0538052 Vali Loss: 0.0548689 Test Loss: 0.0575678\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0511998\n",
      "\tspeed: 0.0653s/iter; left time: 1027.5420s\n",
      "\titers: 200, epoch: 30 | loss: 0.0484094\n",
      "\tspeed: 0.0351s/iter; left time: 548.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0538262 Vali Loss: 0.0548523 Test Loss: 0.0574607\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0547087\n",
      "\tspeed: 0.0654s/iter; left time: 1014.9761s\n",
      "\titers: 200, epoch: 31 | loss: 0.0517584\n",
      "\tspeed: 0.0351s/iter; left time: 541.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0537514 Vali Loss: 0.0547773 Test Loss: 0.0574989\n",
      "Validation loss decreased (0.054829 --> 0.054777).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0566123\n",
      "\tspeed: 0.0666s/iter; left time: 1018.2078s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561727\n",
      "\tspeed: 0.0351s/iter; left time: 532.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0537302 Vali Loss: 0.0546972 Test Loss: 0.0574458\n",
      "Validation loss decreased (0.054777 --> 0.054697).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0504116\n",
      "\tspeed: 0.0664s/iter; left time: 999.7059s\n",
      "\titers: 200, epoch: 33 | loss: 0.0543427\n",
      "\tspeed: 0.0351s/iter; left time: 524.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0537074 Vali Loss: 0.0547021 Test Loss: 0.0574178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0528668\n",
      "\tspeed: 0.0650s/iter; left time: 965.4444s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530927\n",
      "\tspeed: 0.0352s/iter; left time: 518.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0536574 Vali Loss: 0.0547484 Test Loss: 0.0575011\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0500943\n",
      "\tspeed: 0.0648s/iter; left time: 947.6750s\n",
      "\titers: 200, epoch: 35 | loss: 0.0544246\n",
      "\tspeed: 0.0351s/iter; left time: 509.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0536428 Vali Loss: 0.0547106 Test Loss: 0.0574473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0533398\n",
      "\tspeed: 0.0647s/iter; left time: 930.9460s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516305\n",
      "\tspeed: 0.0351s/iter; left time: 502.2065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0535983 Vali Loss: 0.0547135 Test Loss: 0.0573656\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0511870\n",
      "\tspeed: 0.0644s/iter; left time: 912.4765s\n",
      "\titers: 200, epoch: 37 | loss: 0.0523624\n",
      "\tspeed: 0.0352s/iter; left time: 494.9946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0535729 Vali Loss: 0.0547284 Test Loss: 0.0574137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0543733\n",
      "\tspeed: 0.0647s/iter; left time: 902.9269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0522128\n",
      "\tspeed: 0.0351s/iter; left time: 486.0404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0535330 Vali Loss: 0.0547177 Test Loss: 0.0574156\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0500885\n",
      "\tspeed: 0.0655s/iter; left time: 899.1704s\n",
      "\titers: 200, epoch: 39 | loss: 0.0544045\n",
      "\tspeed: 0.0351s/iter; left time: 478.4573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0535079 Vali Loss: 0.0546792 Test Loss: 0.0574100\n",
      "Validation loss decreased (0.054697 --> 0.054679).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0556632\n",
      "\tspeed: 0.0670s/iter; left time: 905.3214s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608936\n",
      "\tspeed: 0.0350s/iter; left time: 468.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0534729 Vali Loss: 0.0546630 Test Loss: 0.0573546\n",
      "Validation loss decreased (0.054679 --> 0.054663).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530188\n",
      "\tspeed: 0.0659s/iter; left time: 875.4849s\n",
      "\titers: 200, epoch: 41 | loss: 0.0543008\n",
      "\tspeed: 0.0348s/iter; left time: 458.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0534663 Vali Loss: 0.0546640 Test Loss: 0.0574067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0527376\n",
      "\tspeed: 0.0639s/iter; left time: 834.7783s\n",
      "\titers: 200, epoch: 42 | loss: 0.0504257\n",
      "\tspeed: 0.0349s/iter; left time: 452.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0535045 Vali Loss: 0.0546867 Test Loss: 0.0574020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0528321\n",
      "\tspeed: 0.0641s/iter; left time: 823.0251s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554217\n",
      "\tspeed: 0.0348s/iter; left time: 442.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0534852 Vali Loss: 0.0545953 Test Loss: 0.0573738\n",
      "Validation loss decreased (0.054663 --> 0.054595).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0516735\n",
      "\tspeed: 0.0659s/iter; left time: 830.8775s\n",
      "\titers: 200, epoch: 44 | loss: 0.0480767\n",
      "\tspeed: 0.0353s/iter; left time: 442.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0534319 Vali Loss: 0.0546308 Test Loss: 0.0573753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0563546\n",
      "\tspeed: 0.0649s/iter; left time: 803.6160s\n",
      "\titers: 200, epoch: 45 | loss: 0.0553964\n",
      "\tspeed: 0.0351s/iter; left time: 431.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0534774 Vali Loss: 0.0546294 Test Loss: 0.0573575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0543456\n",
      "\tspeed: 0.0647s/iter; left time: 787.1173s\n",
      "\titers: 200, epoch: 46 | loss: 0.0519089\n",
      "\tspeed: 0.0351s/iter; left time: 423.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0534381 Vali Loss: 0.0546489 Test Loss: 0.0573632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0561337\n",
      "\tspeed: 0.0652s/iter; left time: 778.7757s\n",
      "\titers: 200, epoch: 47 | loss: 0.0566098\n",
      "\tspeed: 0.0351s/iter; left time: 415.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0534364 Vali Loss: 0.0546397 Test Loss: 0.0573571\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0528050\n",
      "\tspeed: 0.0650s/iter; left time: 762.2341s\n",
      "\titers: 200, epoch: 48 | loss: 0.0533476\n",
      "\tspeed: 0.0351s/iter; left time: 408.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533972 Vali Loss: 0.0546512 Test Loss: 0.0573457\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0541846\n",
      "\tspeed: 0.0641s/iter; left time: 737.5301s\n",
      "\titers: 200, epoch: 49 | loss: 0.0543380\n",
      "\tspeed: 0.0352s/iter; left time: 401.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0534589 Vali Loss: 0.0546227 Test Loss: 0.0573440\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0543175\n",
      "\tspeed: 0.0655s/iter; left time: 738.5563s\n",
      "\titers: 200, epoch: 50 | loss: 0.0555421\n",
      "\tspeed: 0.0351s/iter; left time: 392.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533554 Vali Loss: 0.0546184 Test Loss: 0.0573636\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0542763\n",
      "\tspeed: 0.0648s/iter; left time: 716.4132s\n",
      "\titers: 200, epoch: 51 | loss: 0.0507013\n",
      "\tspeed: 0.0352s/iter; left time: 385.6910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0534446 Vali Loss: 0.0546714 Test Loss: 0.0573693\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0516548\n",
      "\tspeed: 0.0655s/iter; left time: 709.0504s\n",
      "\titers: 200, epoch: 52 | loss: 0.0511236\n",
      "\tspeed: 0.0347s/iter; left time: 372.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0534571 Vali Loss: 0.0545920 Test Loss: 0.0573518\n",
      "Validation loss decreased (0.054595 --> 0.054592).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531069\n",
      "\tspeed: 0.0663s/iter; left time: 703.3966s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519074\n",
      "\tspeed: 0.0352s/iter; left time: 369.6296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533825 Vali Loss: 0.0546071 Test Loss: 0.0573369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0534862\n",
      "\tspeed: 0.0651s/iter; left time: 676.2541s\n",
      "\titers: 200, epoch: 54 | loss: 0.0492625\n",
      "\tspeed: 0.0351s/iter; left time: 361.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533829 Vali Loss: 0.0546410 Test Loss: 0.0573390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0580978\n",
      "\tspeed: 0.0652s/iter; left time: 661.9629s\n",
      "\titers: 200, epoch: 55 | loss: 0.0531033\n",
      "\tspeed: 0.0351s/iter; left time: 353.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533624 Vali Loss: 0.0546159 Test Loss: 0.0573383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0576224\n",
      "\tspeed: 0.0651s/iter; left time: 647.1622s\n",
      "\titers: 200, epoch: 56 | loss: 0.0542574\n",
      "\tspeed: 0.0352s/iter; left time: 346.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0534060 Vali Loss: 0.0545954 Test Loss: 0.0573395\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0483128\n",
      "\tspeed: 0.0654s/iter; left time: 635.4040s\n",
      "\titers: 200, epoch: 57 | loss: 0.0510019\n",
      "\tspeed: 0.0352s/iter; left time: 338.4549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0534189 Vali Loss: 0.0545630 Test Loss: 0.0573416\n",
      "Validation loss decreased (0.054592 --> 0.054563).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0566853\n",
      "\tspeed: 0.0660s/iter; left time: 626.3256s\n",
      "\titers: 200, epoch: 58 | loss: 0.0580699\n",
      "\tspeed: 0.0351s/iter; left time: 329.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533494 Vali Loss: 0.0546348 Test Loss: 0.0573394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0527851\n",
      "\tspeed: 0.0652s/iter; left time: 604.6087s\n",
      "\titers: 200, epoch: 59 | loss: 0.0541783\n",
      "\tspeed: 0.0352s/iter; left time: 322.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533600 Vali Loss: 0.0546001 Test Loss: 0.0573527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0554900\n",
      "\tspeed: 0.0650s/iter; left time: 587.4264s\n",
      "\titers: 200, epoch: 60 | loss: 0.0530581\n",
      "\tspeed: 0.0353s/iter; left time: 315.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0533252 Vali Loss: 0.0545773 Test Loss: 0.0573337\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0569755\n",
      "\tspeed: 0.0648s/iter; left time: 571.7519s\n",
      "\titers: 200, epoch: 61 | loss: 0.0525112\n",
      "\tspeed: 0.0351s/iter; left time: 306.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533005 Vali Loss: 0.0545922 Test Loss: 0.0573551\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0562148\n",
      "\tspeed: 0.0655s/iter; left time: 563.0432s\n",
      "\titers: 200, epoch: 62 | loss: 0.0510816\n",
      "\tspeed: 0.0353s/iter; left time: 299.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0533370 Vali Loss: 0.0546487 Test Loss: 0.0573723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0574854\n",
      "\tspeed: 0.0650s/iter; left time: 544.0078s\n",
      "\titers: 200, epoch: 63 | loss: 0.0529368\n",
      "\tspeed: 0.0351s/iter; left time: 290.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533335 Vali Loss: 0.0545922 Test Loss: 0.0573501\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0557035\n",
      "\tspeed: 0.0655s/iter; left time: 534.1520s\n",
      "\titers: 200, epoch: 64 | loss: 0.0525432\n",
      "\tspeed: 0.0351s/iter; left time: 282.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533528 Vali Loss: 0.0545735 Test Loss: 0.0573364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546455\n",
      "\tspeed: 0.0654s/iter; left time: 518.4721s\n",
      "\titers: 200, epoch: 65 | loss: 0.0553183\n",
      "\tspeed: 0.0353s/iter; left time: 276.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533852 Vali Loss: 0.0546433 Test Loss: 0.0573452\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0561917\n",
      "\tspeed: 0.0655s/iter; left time: 504.8543s\n",
      "\titers: 200, epoch: 66 | loss: 0.0568168\n",
      "\tspeed: 0.0352s/iter; left time: 268.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0533577 Vali Loss: 0.0545441 Test Loss: 0.0573378\n",
      "Validation loss decreased (0.054563 --> 0.054544).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0525508\n",
      "\tspeed: 0.0675s/iter; left time: 505.2784s\n",
      "\titers: 200, epoch: 67 | loss: 0.0557896\n",
      "\tspeed: 0.0351s/iter; left time: 259.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0533420 Vali Loss: 0.0545776 Test Loss: 0.0573440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0541739\n",
      "\tspeed: 0.0664s/iter; left time: 481.9078s\n",
      "\titers: 200, epoch: 68 | loss: 0.0537945\n",
      "\tspeed: 0.0351s/iter; left time: 251.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0534072 Vali Loss: 0.0545726 Test Loss: 0.0573432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0530109\n",
      "\tspeed: 0.0647s/iter; left time: 455.3412s\n",
      "\titers: 200, epoch: 69 | loss: 0.0540929\n",
      "\tspeed: 0.0351s/iter; left time: 243.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0533449 Vali Loss: 0.0545826 Test Loss: 0.0573481\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0518707\n",
      "\tspeed: 0.0642s/iter; left time: 437.7741s\n",
      "\titers: 200, epoch: 70 | loss: 0.0542034\n",
      "\tspeed: 0.0351s/iter; left time: 235.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0533946 Vali Loss: 0.0546405 Test Loss: 0.0573622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0554011\n",
      "\tspeed: 0.0645s/iter; left time: 425.0080s\n",
      "\titers: 200, epoch: 71 | loss: 0.0511646\n",
      "\tspeed: 0.0348s/iter; left time: 225.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0533162 Vali Loss: 0.0545336 Test Loss: 0.0573344\n",
      "Validation loss decreased (0.054544 --> 0.054534).  Saving model ...\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0530440\n",
      "\tspeed: 0.0666s/iter; left time: 423.8380s\n",
      "\titers: 200, epoch: 72 | loss: 0.0569498\n",
      "\tspeed: 0.0352s/iter; left time: 220.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0533984 Vali Loss: 0.0546323 Test Loss: 0.0573371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0569372\n",
      "\tspeed: 0.0652s/iter; left time: 400.6707s\n",
      "\titers: 200, epoch: 73 | loss: 0.0584623\n",
      "\tspeed: 0.0353s/iter; left time: 213.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533600 Vali Loss: 0.0546291 Test Loss: 0.0573471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0547817\n",
      "\tspeed: 0.0651s/iter; left time: 385.7203s\n",
      "\titers: 200, epoch: 74 | loss: 0.0493505\n",
      "\tspeed: 0.0351s/iter; left time: 204.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0533033 Vali Loss: 0.0546224 Test Loss: 0.0573429\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0493547\n",
      "\tspeed: 0.0652s/iter; left time: 371.6734s\n",
      "\titers: 200, epoch: 75 | loss: 0.0555176\n",
      "\tspeed: 0.0351s/iter; left time: 196.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533029 Vali Loss: 0.0546485 Test Loss: 0.0573412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0529091\n",
      "\tspeed: 0.0652s/iter; left time: 356.8269s\n",
      "\titers: 200, epoch: 76 | loss: 0.0509300\n",
      "\tspeed: 0.0351s/iter; left time: 188.5033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0533624 Vali Loss: 0.0545650 Test Loss: 0.0573443\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0607637\n",
      "\tspeed: 0.0649s/iter; left time: 340.9881s\n",
      "\titers: 200, epoch: 77 | loss: 0.0514726\n",
      "\tspeed: 0.0348s/iter; left time: 179.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0534102 Vali Loss: 0.0546305 Test Loss: 0.0573268\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0570907\n",
      "\tspeed: 0.0650s/iter; left time: 327.1195s\n",
      "\titers: 200, epoch: 78 | loss: 0.0551430\n",
      "\tspeed: 0.0348s/iter; left time: 171.3208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0533672 Vali Loss: 0.0546221 Test Loss: 0.0573372\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0489359\n",
      "\tspeed: 0.0640s/iter; left time: 307.8709s\n",
      "\titers: 200, epoch: 79 | loss: 0.0488577\n",
      "\tspeed: 0.0351s/iter; left time: 165.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0533639 Vali Loss: 0.0546596 Test Loss: 0.0573285\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0496042\n",
      "\tspeed: 0.0650s/iter; left time: 298.0569s\n",
      "\titers: 200, epoch: 80 | loss: 0.0566325\n",
      "\tspeed: 0.0352s/iter; left time: 157.9521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0533528 Vali Loss: 0.0546019 Test Loss: 0.0573275\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0518748\n",
      "\tspeed: 0.0649s/iter; left time: 282.9662s\n",
      "\titers: 200, epoch: 81 | loss: 0.0521037\n",
      "\tspeed: 0.0351s/iter; left time: 149.5322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0533605 Vali Loss: 0.0546087 Test Loss: 0.0573167\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010125267319381237, rmse:0.10062438994646072, mae:0.05733437091112137, rse:0.3802099823951721\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1236653\n",
      "\tspeed: 0.0376s/iter; left time: 834.0754s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085836\n",
      "\tspeed: 0.0351s/iter; left time: 775.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1340056 Vali Loss: 0.0942551 Test Loss: 0.0959092\n",
      "Validation loss decreased (inf --> 0.094255).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0773130\n",
      "\tspeed: 0.0653s/iter; left time: 1434.5734s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673379\n",
      "\tspeed: 0.0353s/iter; left time: 771.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0760516 Vali Loss: 0.0626796 Test Loss: 0.0656753\n",
      "Validation loss decreased (0.094255 --> 0.062680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0674818\n",
      "\tspeed: 0.0682s/iter; left time: 1484.1721s\n",
      "\titers: 200, epoch: 3 | loss: 0.0624525\n",
      "\tspeed: 0.0353s/iter; left time: 764.3250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0652883 Vali Loss: 0.0601960 Test Loss: 0.0628172\n",
      "Validation loss decreased (0.062680 --> 0.060196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614427\n",
      "\tspeed: 0.0671s/iter; left time: 1445.3883s\n",
      "\titers: 200, epoch: 4 | loss: 0.0611415\n",
      "\tspeed: 0.0350s/iter; left time: 749.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0625278 Vali Loss: 0.0590170 Test Loss: 0.0610467\n",
      "Validation loss decreased (0.060196 --> 0.059017).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621039\n",
      "\tspeed: 0.0661s/iter; left time: 1409.5724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0640478\n",
      "\tspeed: 0.0352s/iter; left time: 746.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0608943 Vali Loss: 0.0580759 Test Loss: 0.0605287\n",
      "Validation loss decreased (0.059017 --> 0.058076).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599137\n",
      "\tspeed: 0.0658s/iter; left time: 1387.6109s\n",
      "\titers: 200, epoch: 6 | loss: 0.0580266\n",
      "\tspeed: 0.0351s/iter; left time: 735.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0598067 Vali Loss: 0.0580089 Test Loss: 0.0606433\n",
      "Validation loss decreased (0.058076 --> 0.058009).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0658s/iter; left time: 1372.6480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0552828\n",
      "\tspeed: 0.0347s/iter; left time: 719.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0587435 Vali Loss: 0.0578174 Test Loss: 0.0599102\n",
      "Validation loss decreased (0.058009 --> 0.057817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599756\n",
      "\tspeed: 0.0685s/iter; left time: 1414.0659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0566922\n",
      "\tspeed: 0.0351s/iter; left time: 720.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0582020 Vali Loss: 0.0570890 Test Loss: 0.0592180\n",
      "Validation loss decreased (0.057817 --> 0.057089).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0565534\n",
      "\tspeed: 0.0684s/iter; left time: 1397.4800s\n",
      "\titers: 200, epoch: 9 | loss: 0.0553257\n",
      "\tspeed: 0.0513s/iter; left time: 1041.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 223 | Train Loss: 0.0576028 Vali Loss: 0.0568853 Test Loss: 0.0593272\n",
      "Validation loss decreased (0.057089 --> 0.056885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0572889\n",
      "\tspeed: 0.1087s/iter; left time: 2194.5938s\n",
      "\titers: 200, epoch: 10 | loss: 0.0606292\n",
      "\tspeed: 0.0475s/iter; left time: 954.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.99s\n",
      "Steps: 223 | Train Loss: 0.0571892 Vali Loss: 0.0565961 Test Loss: 0.0590728\n",
      "Validation loss decreased (0.056885 --> 0.056596).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582079\n",
      "\tspeed: 0.0726s/iter; left time: 1450.6256s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550425\n",
      "\tspeed: 0.0347s/iter; left time: 689.4622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0567719 Vali Loss: 0.0565161 Test Loss: 0.0591691\n",
      "Validation loss decreased (0.056596 --> 0.056516).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0565605\n",
      "\tspeed: 0.0672s/iter; left time: 1326.7966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558233\n",
      "\tspeed: 0.0427s/iter; left time: 838.2186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 223 | Train Loss: 0.0563979 Vali Loss: 0.0561776 Test Loss: 0.0585629\n",
      "Validation loss decreased (0.056516 --> 0.056178).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540284\n",
      "\tspeed: 0.0687s/iter; left time: 1341.6880s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555557\n",
      "\tspeed: 0.0356s/iter; left time: 691.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0560746 Vali Loss: 0.0561454 Test Loss: 0.0584856\n",
      "Validation loss decreased (0.056178 --> 0.056145).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542161\n",
      "\tspeed: 0.0706s/iter; left time: 1363.3169s\n",
      "\titers: 200, epoch: 14 | loss: 0.0567283\n",
      "\tspeed: 0.0349s/iter; left time: 670.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0558765 Vali Loss: 0.0556245 Test Loss: 0.0582671\n",
      "Validation loss decreased (0.056145 --> 0.055624).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0516504\n",
      "\tspeed: 0.0770s/iter; left time: 1468.6501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539961\n",
      "\tspeed: 0.0351s/iter; left time: 665.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0555634 Vali Loss: 0.0556393 Test Loss: 0.0580658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541912\n",
      "\tspeed: 0.0656s/iter; left time: 1236.3415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0579656\n",
      "\tspeed: 0.0348s/iter; left time: 651.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0554230 Vali Loss: 0.0556770 Test Loss: 0.0582363\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0512342\n",
      "\tspeed: 0.0647s/iter; left time: 1206.3463s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564994\n",
      "\tspeed: 0.0347s/iter; left time: 642.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0551551 Vali Loss: 0.0556197 Test Loss: 0.0580029\n",
      "Validation loss decreased (0.055624 --> 0.055620).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0525832\n",
      "\tspeed: 0.0646s/iter; left time: 1188.7275s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526098\n",
      "\tspeed: 0.0347s/iter; left time: 634.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0549796 Vali Loss: 0.0554065 Test Loss: 0.0579263\n",
      "Validation loss decreased (0.055620 --> 0.055407).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0523012\n",
      "\tspeed: 0.0648s/iter; left time: 1178.7482s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539355\n",
      "\tspeed: 0.0347s/iter; left time: 627.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0548759 Vali Loss: 0.0553395 Test Loss: 0.0578735\n",
      "Validation loss decreased (0.055407 --> 0.055340).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545199\n",
      "\tspeed: 0.0663s/iter; left time: 1191.7170s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550749\n",
      "\tspeed: 0.0347s/iter; left time: 620.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0546577 Vali Loss: 0.0552465 Test Loss: 0.0578412\n",
      "Validation loss decreased (0.055340 --> 0.055246).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0550329\n",
      "\tspeed: 0.0666s/iter; left time: 1181.2350s\n",
      "\titers: 200, epoch: 21 | loss: 0.0578060\n",
      "\tspeed: 0.0353s/iter; left time: 622.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0545746 Vali Loss: 0.0553627 Test Loss: 0.0578596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0537746\n",
      "\tspeed: 0.0686s/iter; left time: 1202.3220s\n",
      "\titers: 200, epoch: 22 | loss: 0.0538387\n",
      "\tspeed: 0.0360s/iter; left time: 627.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0545020 Vali Loss: 0.0551188 Test Loss: 0.0577297\n",
      "Validation loss decreased (0.055246 --> 0.055119).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0544303\n",
      "\tspeed: 0.1279s/iter; left time: 2211.8278s\n",
      "\titers: 200, epoch: 23 | loss: 0.0528518\n",
      "\tspeed: 0.0740s/iter; left time: 1271.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.95s\n",
      "Steps: 223 | Train Loss: 0.0543437 Vali Loss: 0.0548906 Test Loss: 0.0576726\n",
      "Validation loss decreased (0.055119 --> 0.054891).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0523297\n",
      "\tspeed: 0.1661s/iter; left time: 2835.7849s\n",
      "\titers: 200, epoch: 24 | loss: 0.0491816\n",
      "\tspeed: 0.0741s/iter; left time: 1257.3326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:16.93s\n",
      "Steps: 223 | Train Loss: 0.0542616 Vali Loss: 0.0550434 Test Loss: 0.0577392\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573380\n",
      "\tspeed: 0.1635s/iter; left time: 2755.0971s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550361\n",
      "\tspeed: 0.0731s/iter; left time: 1224.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:16.70s\n",
      "Steps: 223 | Train Loss: 0.0541424 Vali Loss: 0.0550252 Test Loss: 0.0575210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0571581\n",
      "\tspeed: 0.1663s/iter; left time: 2765.1225s\n",
      "\titers: 200, epoch: 26 | loss: 0.0503851\n",
      "\tspeed: 0.0724s/iter; left time: 1196.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 223 | Train Loss: 0.0541551 Vali Loss: 0.0548709 Test Loss: 0.0574785\n",
      "Validation loss decreased (0.054891 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0507494\n",
      "\tspeed: 0.1703s/iter; left time: 2793.6248s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532626\n",
      "\tspeed: 0.0744s/iter; left time: 1212.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 223 | Train Loss: 0.0539924 Vali Loss: 0.0549234 Test Loss: 0.0575042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0542392\n",
      "\tspeed: 0.1879s/iter; left time: 3039.4868s\n",
      "\titers: 200, epoch: 28 | loss: 0.0539691\n",
      "\tspeed: 0.0783s/iter; left time: 1258.3340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.64s\n",
      "Steps: 223 | Train Loss: 0.0539487 Vali Loss: 0.0548774 Test Loss: 0.0575267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0521044\n",
      "\tspeed: 0.3136s/iter; left time: 5004.0189s\n",
      "\titers: 200, epoch: 29 | loss: 0.0509934\n",
      "\tspeed: 0.1754s/iter; left time: 2781.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:42.57s\n",
      "Steps: 223 | Train Loss: 0.0539058 Vali Loss: 0.0548742 Test Loss: 0.0573750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0580714\n",
      "\tspeed: 0.2264s/iter; left time: 3561.8815s\n",
      "\titers: 200, epoch: 30 | loss: 0.0515862\n",
      "\tspeed: 0.0814s/iter; left time: 1273.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.93s\n",
      "Steps: 223 | Train Loss: 0.0539120 Vali Loss: 0.0547454 Test Loss: 0.0574369\n",
      "Validation loss decreased (0.054871 --> 0.054745).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0573174\n",
      "\tspeed: 0.1904s/iter; left time: 2953.3819s\n",
      "\titers: 200, epoch: 31 | loss: 0.0589227\n",
      "\tspeed: 0.0822s/iter; left time: 1266.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.89s\n",
      "Steps: 223 | Train Loss: 0.0538397 Vali Loss: 0.0547085 Test Loss: 0.0573836\n",
      "Validation loss decreased (0.054745 --> 0.054708).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0572007\n",
      "\tspeed: 0.1876s/iter; left time: 2867.8048s\n",
      "\titers: 200, epoch: 32 | loss: 0.0529349\n",
      "\tspeed: 0.0807s/iter; left time: 1225.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.60s\n",
      "Steps: 223 | Train Loss: 0.0537666 Vali Loss: 0.0548522 Test Loss: 0.0574574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0535290\n",
      "\tspeed: 0.2115s/iter; left time: 3185.5163s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521026\n",
      "\tspeed: 0.1249s/iter; left time: 1869.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.58s\n",
      "Steps: 223 | Train Loss: 0.0538062 Vali Loss: 0.0548358 Test Loss: 0.0574031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0542147\n",
      "\tspeed: 0.2777s/iter; left time: 4121.8149s\n",
      "\titers: 200, epoch: 34 | loss: 0.0529351\n",
      "\tspeed: 0.1283s/iter; left time: 1891.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:28.99s\n",
      "Steps: 223 | Train Loss: 0.0536756 Vali Loss: 0.0547746 Test Loss: 0.0574166\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0524224\n",
      "\tspeed: 0.3269s/iter; left time: 4779.3293s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521868\n",
      "\tspeed: 0.1556s/iter; left time: 2258.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:34.61s\n",
      "Steps: 223 | Train Loss: 0.0537168 Vali Loss: 0.0546867 Test Loss: 0.0573712\n",
      "Validation loss decreased (0.054708 --> 0.054687).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0547390\n",
      "\tspeed: 0.3498s/iter; left time: 5035.1722s\n",
      "\titers: 200, epoch: 36 | loss: 0.0513252\n",
      "\tspeed: 0.1773s/iter; left time: 2534.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 223 | Train Loss: 0.0536649 Vali Loss: 0.0548329 Test Loss: 0.0573338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0526233\n",
      "\tspeed: 0.4131s/iter; left time: 5855.0527s\n",
      "\titers: 200, epoch: 37 | loss: 0.0532994\n",
      "\tspeed: 0.1768s/iter; left time: 2488.2374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 223 | Train Loss: 0.0536699 Vali Loss: 0.0547430 Test Loss: 0.0573483\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0552216\n",
      "\tspeed: 0.4277s/iter; left time: 5966.7552s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542184\n",
      "\tspeed: 0.1920s/iter; left time: 2659.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:42.05s\n",
      "Steps: 223 | Train Loss: 0.0536600 Vali Loss: 0.0546434 Test Loss: 0.0573275\n",
      "Validation loss decreased (0.054687 --> 0.054643).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0544269\n",
      "\tspeed: 0.4247s/iter; left time: 5829.1753s\n",
      "\titers: 200, epoch: 39 | loss: 0.0550644\n",
      "\tspeed: 0.2114s/iter; left time: 2880.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 223 | Train Loss: 0.0536410 Vali Loss: 0.0547653 Test Loss: 0.0573865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0523039\n",
      "\tspeed: 0.4798s/iter; left time: 6478.7783s\n",
      "\titers: 200, epoch: 40 | loss: 0.0555325\n",
      "\tspeed: 0.2019s/iter; left time: 2706.1862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 223 | Train Loss: 0.0535535 Vali Loss: 0.0547170 Test Loss: 0.0573768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0485696\n",
      "\tspeed: 0.4853s/iter; left time: 6445.8641s\n",
      "\titers: 200, epoch: 41 | loss: 0.0521793\n",
      "\tspeed: 0.1909s/iter; left time: 2515.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:47.15s\n",
      "Steps: 223 | Train Loss: 0.0535917 Vali Loss: 0.0547144 Test Loss: 0.0573494\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0557823\n",
      "\tspeed: 0.4580s/iter; left time: 5981.1233s\n",
      "\titers: 200, epoch: 42 | loss: 0.0514218\n",
      "\tspeed: 0.2059s/iter; left time: 2667.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:45.00s\n",
      "Steps: 223 | Train Loss: 0.0535651 Vali Loss: 0.0547100 Test Loss: 0.0573217\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536297\n",
      "\tspeed: 0.4410s/iter; left time: 5660.0517s\n",
      "\titers: 200, epoch: 43 | loss: 0.0508653\n",
      "\tspeed: 0.1746s/iter; left time: 2223.6951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 223 | Train Loss: 0.0535408 Vali Loss: 0.0545471 Test Loss: 0.0573033\n",
      "Validation loss decreased (0.054643 --> 0.054547).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537778\n",
      "\tspeed: 0.4515s/iter; left time: 5693.6991s\n",
      "\titers: 200, epoch: 44 | loss: 0.0539068\n",
      "\tspeed: 0.1859s/iter; left time: 2325.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 223 | Train Loss: 0.0535216 Vali Loss: 0.0546545 Test Loss: 0.0572622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0526309\n",
      "\tspeed: 0.4266s/iter; left time: 5285.0607s\n",
      "\titers: 200, epoch: 45 | loss: 0.0578126\n",
      "\tspeed: 0.1870s/iter; left time: 2298.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:44.35s\n",
      "Steps: 223 | Train Loss: 0.0534860 Vali Loss: 0.0545956 Test Loss: 0.0573146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0516833\n",
      "\tspeed: 0.4951s/iter; left time: 6023.1268s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523372\n",
      "\tspeed: 0.2050s/iter; left time: 2473.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:47.70s\n",
      "Steps: 223 | Train Loss: 0.0535217 Vali Loss: 0.0546559 Test Loss: 0.0573144\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530197\n",
      "\tspeed: 0.4584s/iter; left time: 5474.1490s\n",
      "\titers: 200, epoch: 47 | loss: 0.0499367\n",
      "\tspeed: 0.2057s/iter; left time: 2436.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 223 | Train Loss: 0.0534722 Vali Loss: 0.0547245 Test Loss: 0.0573141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0524021\n",
      "\tspeed: 0.4370s/iter; left time: 5121.5473s\n",
      "\titers: 200, epoch: 48 | loss: 0.0547925\n",
      "\tspeed: 0.2086s/iter; left time: 2423.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:45.47s\n",
      "Steps: 223 | Train Loss: 0.0535118 Vali Loss: 0.0547139 Test Loss: 0.0573085\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0580956\n",
      "\tspeed: 0.4509s/iter; left time: 5184.5046s\n",
      "\titers: 200, epoch: 49 | loss: 0.0481888\n",
      "\tspeed: 0.2091s/iter; left time: 2382.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 223 | Train Loss: 0.0534437 Vali Loss: 0.0546712 Test Loss: 0.0573046\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0534444\n",
      "\tspeed: 0.3882s/iter; left time: 4376.7753s\n",
      "\titers: 200, epoch: 50 | loss: 0.0551254\n",
      "\tspeed: 0.1342s/iter; left time: 1499.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:32.72s\n",
      "Steps: 223 | Train Loss: 0.0535029 Vali Loss: 0.0545804 Test Loss: 0.0572849\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0532080\n",
      "\tspeed: 0.2621s/iter; left time: 2896.1256s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547003\n",
      "\tspeed: 0.0959s/iter; left time: 1050.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:23.39s\n",
      "Steps: 223 | Train Loss: 0.0535040 Vali Loss: 0.0546792 Test Loss: 0.0572739\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0539353\n",
      "\tspeed: 0.2211s/iter; left time: 2394.0653s\n",
      "\titers: 200, epoch: 52 | loss: 0.0537760\n",
      "\tspeed: 0.0919s/iter; left time: 986.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:21.63s\n",
      "Steps: 223 | Train Loss: 0.0534933 Vali Loss: 0.0546623 Test Loss: 0.0572583\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0524189\n",
      "\tspeed: 0.2059s/iter; left time: 2183.1426s\n",
      "\titers: 200, epoch: 53 | loss: 0.0573189\n",
      "\tspeed: 0.0870s/iter; left time: 913.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:19.95s\n",
      "Steps: 223 | Train Loss: 0.0534749 Vali Loss: 0.0546200 Test Loss: 0.0572883\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010080976411700249, rmse:0.10040406882762909, mae:0.057303305715322495, rse:0.3793775141239166\n",
      "Intermediate time for IT and pred_len 24: 00h:41m:49.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1311399\n",
      "\tspeed: 0.1691s/iter; left time: 3738.3040s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141715\n",
      "\tspeed: 0.1285s/iter; left time: 2827.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 222 | Train Loss: 0.1386955 Vali Loss: 0.1032611 Test Loss: 0.1052448\n",
      "Validation loss decreased (inf --> 0.103261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0856372\n",
      "\tspeed: 0.3564s/iter; left time: 7798.5274s\n",
      "\titers: 200, epoch: 2 | loss: 0.0825728\n",
      "\tspeed: 0.1042s/iter; left time: 2269.2966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.83s\n",
      "Steps: 222 | Train Loss: 0.0933017 Vali Loss: 0.0821070 Test Loss: 0.0853990\n",
      "Validation loss decreased (0.103261 --> 0.082107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840829\n",
      "\tspeed: 0.3542s/iter; left time: 7671.4029s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774338\n",
      "\tspeed: 0.0991s/iter; left time: 2136.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.08s\n",
      "Steps: 222 | Train Loss: 0.0836652 Vali Loss: 0.0801823 Test Loss: 0.0839848\n",
      "Validation loss decreased (0.082107 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0777906\n",
      "\tspeed: 0.3823s/iter; left time: 8194.1118s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808969\n",
      "\tspeed: 0.1163s/iter; left time: 2482.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.82s\n",
      "Steps: 222 | Train Loss: 0.0810691 Vali Loss: 0.0786099 Test Loss: 0.0832172\n",
      "Validation loss decreased (0.080182 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0820504\n",
      "\tspeed: 0.3402s/iter; left time: 7217.5537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0778563\n",
      "\tspeed: 0.1159s/iter; left time: 2446.4149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.97s\n",
      "Steps: 222 | Train Loss: 0.0794057 Vali Loss: 0.0787720 Test Loss: 0.0831368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778250\n",
      "\tspeed: 0.3327s/iter; left time: 6983.2994s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792012\n",
      "\tspeed: 0.1144s/iter; left time: 2390.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.02s\n",
      "Steps: 222 | Train Loss: 0.0783560 Vali Loss: 0.0787365 Test Loss: 0.0827528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0766344\n",
      "\tspeed: 0.3451s/iter; left time: 7168.1667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771671\n",
      "\tspeed: 0.1036s/iter; left time: 2140.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.0773313 Vali Loss: 0.0777745 Test Loss: 0.0821120\n",
      "Validation loss decreased (0.078610 --> 0.077775).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767398\n",
      "\tspeed: 0.3375s/iter; left time: 6935.1741s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759662\n",
      "\tspeed: 0.1116s/iter; left time: 2281.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 222 | Train Loss: 0.0764446 Vali Loss: 0.0786228 Test Loss: 0.0820677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730551\n",
      "\tspeed: 0.3426s/iter; left time: 6963.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0752378\n",
      "\tspeed: 0.1105s/iter; left time: 2234.0419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.50s\n",
      "Steps: 222 | Train Loss: 0.0758786 Vali Loss: 0.0777612 Test Loss: 0.0823828\n",
      "Validation loss decreased (0.077775 --> 0.077761).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0798666\n",
      "\tspeed: 0.3382s/iter; left time: 6799.1711s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749843\n",
      "\tspeed: 0.1098s/iter; left time: 2195.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.35s\n",
      "Steps: 222 | Train Loss: 0.0752808 Vali Loss: 0.0778954 Test Loss: 0.0823552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764299\n",
      "\tspeed: 0.3560s/iter; left time: 7076.8356s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740857\n",
      "\tspeed: 0.1054s/iter; left time: 2084.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:24.96s\n",
      "Steps: 222 | Train Loss: 0.0748124 Vali Loss: 0.0778898 Test Loss: 0.0825079\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0724045\n",
      "\tspeed: 0.3405s/iter; left time: 6694.3039s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746246\n",
      "\tspeed: 0.1063s/iter; left time: 2078.9870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.41s\n",
      "Steps: 222 | Train Loss: 0.0744042 Vali Loss: 0.0778334 Test Loss: 0.0823106\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0746598\n",
      "\tspeed: 0.3462s/iter; left time: 6729.1110s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782185\n",
      "\tspeed: 0.1074s/iter; left time: 2076.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 222 | Train Loss: 0.0740403 Vali Loss: 0.0775864 Test Loss: 0.0823642\n",
      "Validation loss decreased (0.077761 --> 0.077586).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0693135\n",
      "\tspeed: 0.3455s/iter; left time: 6638.4685s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716517\n",
      "\tspeed: 0.1053s/iter; left time: 2012.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 222 | Train Loss: 0.0736158 Vali Loss: 0.0778610 Test Loss: 0.0827634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719399\n",
      "\tspeed: 0.3487s/iter; left time: 6622.2708s\n",
      "\titers: 200, epoch: 15 | loss: 0.0678389\n",
      "\tspeed: 0.1075s/iter; left time: 2030.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 222 | Train Loss: 0.0732489 Vali Loss: 0.0777737 Test Loss: 0.0830149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0743510\n",
      "\tspeed: 0.3548s/iter; left time: 6659.0880s\n",
      "\titers: 200, epoch: 16 | loss: 0.0752960\n",
      "\tspeed: 0.1010s/iter; left time: 1886.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 222 | Train Loss: 0.0729326 Vali Loss: 0.0778201 Test Loss: 0.0826653\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0726962\n",
      "\tspeed: 0.3047s/iter; left time: 5651.1722s\n",
      "\titers: 200, epoch: 17 | loss: 0.0722981\n",
      "\tspeed: 0.0992s/iter; left time: 1830.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 222 | Train Loss: 0.0726651 Vali Loss: 0.0779380 Test Loss: 0.0830403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729924\n",
      "\tspeed: 0.3398s/iter; left time: 6227.3028s\n",
      "\titers: 200, epoch: 18 | loss: 0.0750807\n",
      "\tspeed: 0.1095s/iter; left time: 1996.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:26.56s\n",
      "Steps: 222 | Train Loss: 0.0725138 Vali Loss: 0.0775092 Test Loss: 0.0824644\n",
      "Validation loss decreased (0.077586 --> 0.077509).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725602\n",
      "\tspeed: 0.3671s/iter; left time: 6646.6417s\n",
      "\titers: 200, epoch: 19 | loss: 0.0742136\n",
      "\tspeed: 0.1126s/iter; left time: 2026.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.90s\n",
      "Steps: 222 | Train Loss: 0.0722610 Vali Loss: 0.0777993 Test Loss: 0.0827277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709395\n",
      "\tspeed: 0.3372s/iter; left time: 6029.4661s\n",
      "\titers: 200, epoch: 20 | loss: 0.0712768\n",
      "\tspeed: 0.1099s/iter; left time: 1954.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 222 | Train Loss: 0.0720304 Vali Loss: 0.0776217 Test Loss: 0.0830709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749833\n",
      "\tspeed: 0.3386s/iter; left time: 5979.6552s\n",
      "\titers: 200, epoch: 21 | loss: 0.0723694\n",
      "\tspeed: 0.1125s/iter; left time: 1975.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:25.08s\n",
      "Steps: 222 | Train Loss: 0.0718289 Vali Loss: 0.0777689 Test Loss: 0.0829489\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0728807\n",
      "\tspeed: 0.3430s/iter; left time: 5981.2282s\n",
      "\titers: 200, epoch: 22 | loss: 0.0715724\n",
      "\tspeed: 0.1138s/iter; left time: 1972.5922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 222 | Train Loss: 0.0716578 Vali Loss: 0.0775245 Test Loss: 0.0829920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0736327\n",
      "\tspeed: 0.3422s/iter; left time: 5891.1664s\n",
      "\titers: 200, epoch: 23 | loss: 0.0700886\n",
      "\tspeed: 0.1078s/iter; left time: 1845.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:25.05s\n",
      "Steps: 222 | Train Loss: 0.0715372 Vali Loss: 0.0774438 Test Loss: 0.0829975\n",
      "Validation loss decreased (0.077509 --> 0.077444).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0732769\n",
      "\tspeed: 0.3416s/iter; left time: 5806.1703s\n",
      "\titers: 200, epoch: 24 | loss: 0.0709394\n",
      "\tspeed: 0.1102s/iter; left time: 1861.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 222 | Train Loss: 0.0713622 Vali Loss: 0.0777394 Test Loss: 0.0830288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0692430\n",
      "\tspeed: 0.3341s/iter; left time: 5604.0832s\n",
      "\titers: 200, epoch: 25 | loss: 0.0746632\n",
      "\tspeed: 0.1088s/iter; left time: 1813.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 222 | Train Loss: 0.0712769 Vali Loss: 0.0775630 Test Loss: 0.0829923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0727863\n",
      "\tspeed: 0.3352s/iter; left time: 5547.7592s\n",
      "\titers: 200, epoch: 26 | loss: 0.0689155\n",
      "\tspeed: 0.1044s/iter; left time: 1718.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 222 | Train Loss: 0.0711172 Vali Loss: 0.0776434 Test Loss: 0.0832030\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0752033\n",
      "\tspeed: 0.3557s/iter; left time: 5808.5386s\n",
      "\titers: 200, epoch: 27 | loss: 0.0673548\n",
      "\tspeed: 0.1038s/iter; left time: 1683.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:24.32s\n",
      "Steps: 222 | Train Loss: 0.0710334 Vali Loss: 0.0776247 Test Loss: 0.0831966\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734832\n",
      "\tspeed: 0.3505s/iter; left time: 5644.7200s\n",
      "\titers: 200, epoch: 28 | loss: 0.0692218\n",
      "\tspeed: 0.1076s/iter; left time: 1723.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:24.30s\n",
      "Steps: 222 | Train Loss: 0.0709934 Vali Loss: 0.0776521 Test Loss: 0.0830424\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0723570\n",
      "\tspeed: 0.3472s/iter; left time: 5515.3677s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728116\n",
      "\tspeed: 0.1085s/iter; left time: 1712.1444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 222 | Train Loss: 0.0708610 Vali Loss: 0.0775053 Test Loss: 0.0831043\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0713507\n",
      "\tspeed: 0.3366s/iter; left time: 5271.5541s\n",
      "\titers: 200, epoch: 30 | loss: 0.0729116\n",
      "\tspeed: 0.1111s/iter; left time: 1728.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 222 | Train Loss: 0.0708525 Vali Loss: 0.0777053 Test Loss: 0.0831629\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0749389\n",
      "\tspeed: 0.3201s/iter; left time: 4942.7000s\n",
      "\titers: 200, epoch: 31 | loss: 0.0724649\n",
      "\tspeed: 0.0976s/iter; left time: 1496.7263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 222 | Train Loss: 0.0707049 Vali Loss: 0.0778409 Test Loss: 0.0833423\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0705555\n",
      "\tspeed: 0.2971s/iter; left time: 4521.7761s\n",
      "\titers: 200, epoch: 32 | loss: 0.0722894\n",
      "\tspeed: 0.1003s/iter; left time: 1515.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 222 | Train Loss: 0.0705979 Vali Loss: 0.0777341 Test Loss: 0.0832765\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0708174\n",
      "\tspeed: 0.3026s/iter; left time: 4537.4618s\n",
      "\titers: 200, epoch: 33 | loss: 0.0716869\n",
      "\tspeed: 0.0999s/iter; left time: 1487.6257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.27s\n",
      "Steps: 222 | Train Loss: 0.0705853 Vali Loss: 0.0774142 Test Loss: 0.0832275\n",
      "Validation loss decreased (0.077444 --> 0.077414).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687195\n",
      "\tspeed: 0.3042s/iter; left time: 4495.0039s\n",
      "\titers: 200, epoch: 34 | loss: 0.0715097\n",
      "\tspeed: 0.0980s/iter; left time: 1437.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 222 | Train Loss: 0.0705578 Vali Loss: 0.0776007 Test Loss: 0.0832708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0726959\n",
      "\tspeed: 0.2997s/iter; left time: 4361.7562s\n",
      "\titers: 200, epoch: 35 | loss: 0.0734263\n",
      "\tspeed: 0.0991s/iter; left time: 1432.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 222 | Train Loss: 0.0705173 Vali Loss: 0.0776994 Test Loss: 0.0832131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0730397\n",
      "\tspeed: 0.3074s/iter; left time: 4404.8692s\n",
      "\titers: 200, epoch: 36 | loss: 0.0701893\n",
      "\tspeed: 0.0976s/iter; left time: 1389.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 222 | Train Loss: 0.0704305 Vali Loss: 0.0776818 Test Loss: 0.0833117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0684488\n",
      "\tspeed: 0.2998s/iter; left time: 4230.0076s\n",
      "\titers: 200, epoch: 37 | loss: 0.0706373\n",
      "\tspeed: 0.0987s/iter; left time: 1382.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 222 | Train Loss: 0.0704381 Vali Loss: 0.0776246 Test Loss: 0.0833702\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0681006\n",
      "\tspeed: 0.2962s/iter; left time: 4112.8413s\n",
      "\titers: 200, epoch: 38 | loss: 0.0723561\n",
      "\tspeed: 0.0998s/iter; left time: 1376.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 222 | Train Loss: 0.0703652 Vali Loss: 0.0777585 Test Loss: 0.0832768\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0716680\n",
      "\tspeed: 0.2981s/iter; left time: 4073.8396s\n",
      "\titers: 200, epoch: 39 | loss: 0.0727969\n",
      "\tspeed: 0.0982s/iter; left time: 1332.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 222 | Train Loss: 0.0703907 Vali Loss: 0.0776063 Test Loss: 0.0832168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0663224\n",
      "\tspeed: 0.3013s/iter; left time: 4050.4021s\n",
      "\titers: 200, epoch: 40 | loss: 0.0692386\n",
      "\tspeed: 0.0990s/iter; left time: 1320.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:22.61s\n",
      "Steps: 222 | Train Loss: 0.0703427 Vali Loss: 0.0775947 Test Loss: 0.0833248\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0682518\n",
      "\tspeed: 0.2965s/iter; left time: 3919.5222s\n",
      "\titers: 200, epoch: 41 | loss: 0.0704335\n",
      "\tspeed: 0.0948s/iter; left time: 1243.2475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:21.63s\n",
      "Steps: 222 | Train Loss: 0.0702792 Vali Loss: 0.0776268 Test Loss: 0.0833209\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765378\n",
      "\tspeed: 0.2978s/iter; left time: 3871.5576s\n",
      "\titers: 200, epoch: 42 | loss: 0.0654985\n",
      "\tspeed: 0.0942s/iter; left time: 1214.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:21.71s\n",
      "Steps: 222 | Train Loss: 0.0702523 Vali Loss: 0.0776762 Test Loss: 0.0832865\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0718094\n",
      "\tspeed: 0.2963s/iter; left time: 3785.2200s\n",
      "\titers: 200, epoch: 43 | loss: 0.0723811\n",
      "\tspeed: 0.0982s/iter; left time: 1244.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 222 | Train Loss: 0.0702900 Vali Loss: 0.0777120 Test Loss: 0.0833350\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019661061465740204, rmse:0.14021790027618408, mae:0.08322744071483612, rse:0.5301790237426758\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1307814\n",
      "\tspeed: 0.1003s/iter; left time: 2217.2914s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171321\n",
      "\tspeed: 0.0956s/iter; left time: 2103.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:21.85s\n",
      "Steps: 222 | Train Loss: 0.1395332 Vali Loss: 0.1032470 Test Loss: 0.1049860\n",
      "Validation loss decreased (inf --> 0.103247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916372\n",
      "\tspeed: 0.2953s/iter; left time: 6461.9022s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823959\n",
      "\tspeed: 0.0953s/iter; left time: 2075.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.83s\n",
      "Steps: 222 | Train Loss: 0.0933076 Vali Loss: 0.0824281 Test Loss: 0.0858068\n",
      "Validation loss decreased (0.103247 --> 0.082428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872041\n",
      "\tspeed: 0.2911s/iter; left time: 6304.3783s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788812\n",
      "\tspeed: 0.0976s/iter; left time: 2102.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.08s\n",
      "Steps: 222 | Train Loss: 0.0836500 Vali Loss: 0.0802880 Test Loss: 0.0839654\n",
      "Validation loss decreased (0.082428 --> 0.080288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820672\n",
      "\tspeed: 0.2980s/iter; left time: 6386.7419s\n",
      "\titers: 200, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.0960s/iter; left time: 2047.8672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.85s\n",
      "Steps: 222 | Train Loss: 0.0810862 Vali Loss: 0.0789895 Test Loss: 0.0830211\n",
      "Validation loss decreased (0.080288 --> 0.078989).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760076\n",
      "\tspeed: 0.2990s/iter; left time: 6343.6648s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797620\n",
      "\tspeed: 0.0976s/iter; left time: 2060.0964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 222 | Train Loss: 0.0795027 Vali Loss: 0.0782971 Test Loss: 0.0827075\n",
      "Validation loss decreased (0.078989 --> 0.078297).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0779532\n",
      "\tspeed: 0.2913s/iter; left time: 6114.8252s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816109\n",
      "\tspeed: 0.0953s/iter; left time: 1991.4572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:21.93s\n",
      "Steps: 222 | Train Loss: 0.0784048 Vali Loss: 0.0775458 Test Loss: 0.0820731\n",
      "Validation loss decreased (0.078297 --> 0.077546).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748276\n",
      "\tspeed: 0.2925s/iter; left time: 6075.6091s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819100\n",
      "\tspeed: 0.0936s/iter; left time: 1934.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.68s\n",
      "Steps: 222 | Train Loss: 0.0774822 Vali Loss: 0.0781644 Test Loss: 0.0823445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749587\n",
      "\tspeed: 0.2956s/iter; left time: 6073.0907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749932\n",
      "\tspeed: 0.0982s/iter; left time: 2007.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 222 | Train Loss: 0.0766891 Vali Loss: 0.0772725 Test Loss: 0.0819850\n",
      "Validation loss decreased (0.077546 --> 0.077272).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0743355\n",
      "\tspeed: 0.2922s/iter; left time: 5938.0465s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758577\n",
      "\tspeed: 0.0967s/iter; left time: 1955.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.03s\n",
      "Steps: 222 | Train Loss: 0.0760432 Vali Loss: 0.0781481 Test Loss: 0.0822719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0754635\n",
      "\tspeed: 0.2888s/iter; left time: 5805.8640s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753185\n",
      "\tspeed: 0.0995s/iter; left time: 1990.9896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 222 | Train Loss: 0.0755703 Vali Loss: 0.0779481 Test Loss: 0.0822187\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784725\n",
      "\tspeed: 0.2976s/iter; left time: 5915.8656s\n",
      "\titers: 200, epoch: 11 | loss: 0.0744855\n",
      "\tspeed: 0.0964s/iter; left time: 1907.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.03s\n",
      "Steps: 222 | Train Loss: 0.0750095 Vali Loss: 0.0778305 Test Loss: 0.0819077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705007\n",
      "\tspeed: 0.2777s/iter; left time: 5459.0270s\n",
      "\titers: 200, epoch: 12 | loss: 0.0720747\n",
      "\tspeed: 0.0974s/iter; left time: 1904.9933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.06s\n",
      "Steps: 222 | Train Loss: 0.0745374 Vali Loss: 0.0780981 Test Loss: 0.0819330\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698386\n",
      "\tspeed: 0.2974s/iter; left time: 5780.9542s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727388\n",
      "\tspeed: 0.0962s/iter; left time: 1860.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 222 | Train Loss: 0.0741739 Vali Loss: 0.0778864 Test Loss: 0.0820878\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0789689\n",
      "\tspeed: 0.2803s/iter; left time: 5386.2076s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682087\n",
      "\tspeed: 0.0977s/iter; left time: 1867.6835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 222 | Train Loss: 0.0737458 Vali Loss: 0.0776178 Test Loss: 0.0820219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734283\n",
      "\tspeed: 0.2920s/iter; left time: 5545.9914s\n",
      "\titers: 200, epoch: 15 | loss: 0.0718359\n",
      "\tspeed: 0.0999s/iter; left time: 1887.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 222 | Train Loss: 0.0733381 Vali Loss: 0.0776815 Test Loss: 0.0821751\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0711537\n",
      "\tspeed: 0.2979s/iter; left time: 5592.2039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0715080\n",
      "\tspeed: 0.1002s/iter; left time: 1870.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 222 | Train Loss: 0.0731208 Vali Loss: 0.0775902 Test Loss: 0.0822790\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744190\n",
      "\tspeed: 0.2809s/iter; left time: 5210.4807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702729\n",
      "\tspeed: 0.0994s/iter; left time: 1834.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 222 | Train Loss: 0.0727643 Vali Loss: 0.0776203 Test Loss: 0.0821167\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710593\n",
      "\tspeed: 0.2910s/iter; left time: 5332.4292s\n",
      "\titers: 200, epoch: 18 | loss: 0.0704435\n",
      "\tspeed: 0.0999s/iter; left time: 1820.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 222 | Train Loss: 0.0725734 Vali Loss: 0.0780306 Test Loss: 0.0821137\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01830422878265381, rmse:0.1352931261062622, mae:0.08198496699333191, rse:0.5115578770637512\n",
      "Intermediate time for IT and pred_len 96: 00h:43m:23.82s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1295985\n",
      "\tspeed: 0.1465s/iter; left time: 3237.6315s\n",
      "\titers: 200, epoch: 1 | loss: 0.1180896\n",
      "\tspeed: 0.0983s/iter; left time: 2162.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 222 | Train Loss: 0.1401323 Vali Loss: 0.1051054 Test Loss: 0.1060525\n",
      "Validation loss decreased (inf --> 0.105105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924811\n",
      "\tspeed: 0.3124s/iter; left time: 6835.2263s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879458\n",
      "\tspeed: 0.1004s/iter; left time: 2186.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 222 | Train Loss: 0.0966438 Vali Loss: 0.0867667 Test Loss: 0.0893334\n",
      "Validation loss decreased (0.105105 --> 0.086767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903072\n",
      "\tspeed: 0.3075s/iter; left time: 6659.6450s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883525\n",
      "\tspeed: 0.1024s/iter; left time: 2206.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 222 | Train Loss: 0.0874388 Vali Loss: 0.0843132 Test Loss: 0.0879837\n",
      "Validation loss decreased (0.086767 --> 0.084313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0860730\n",
      "\tspeed: 0.3110s/iter; left time: 6666.9633s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831108\n",
      "\tspeed: 0.1014s/iter; left time: 2162.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 222 | Train Loss: 0.0847376 Vali Loss: 0.0837539 Test Loss: 0.0880465\n",
      "Validation loss decreased (0.084313 --> 0.083754).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0837407\n",
      "\tspeed: 0.3030s/iter; left time: 6427.6945s\n",
      "\titers: 200, epoch: 5 | loss: 0.0845941\n",
      "\tspeed: 0.0998s/iter; left time: 2106.0811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 222 | Train Loss: 0.0829249 Vali Loss: 0.0836297 Test Loss: 0.0880610\n",
      "Validation loss decreased (0.083754 --> 0.083630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783244\n",
      "\tspeed: 0.3130s/iter; left time: 6569.6838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0828781\n",
      "\tspeed: 0.1010s/iter; left time: 2109.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:23.23s\n",
      "Steps: 222 | Train Loss: 0.0816438 Vali Loss: 0.0839534 Test Loss: 0.0884101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834960\n",
      "\tspeed: 0.3080s/iter; left time: 6397.0898s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834978\n",
      "\tspeed: 0.1022s/iter; left time: 2113.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 222 | Train Loss: 0.0806016 Vali Loss: 0.0844958 Test Loss: 0.0885445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0818839\n",
      "\tspeed: 0.3093s/iter; left time: 6354.7046s\n",
      "\titers: 200, epoch: 8 | loss: 0.0781465\n",
      "\tspeed: 0.1028s/iter; left time: 2101.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:23.02s\n",
      "Steps: 222 | Train Loss: 0.0798453 Vali Loss: 0.0841923 Test Loss: 0.0884497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763105\n",
      "\tspeed: 0.3110s/iter; left time: 6320.6427s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815194\n",
      "\tspeed: 0.1017s/iter; left time: 2057.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.26s\n",
      "Steps: 222 | Train Loss: 0.0790506 Vali Loss: 0.0838278 Test Loss: 0.0882513\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0768552\n",
      "\tspeed: 0.3190s/iter; left time: 6412.4627s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751613\n",
      "\tspeed: 0.1010s/iter; left time: 2020.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:23.15s\n",
      "Steps: 222 | Train Loss: 0.0785731 Vali Loss: 0.0852505 Test Loss: 0.0894450\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779051\n",
      "\tspeed: 0.3096s/iter; left time: 6156.0761s\n",
      "\titers: 200, epoch: 11 | loss: 0.0783429\n",
      "\tspeed: 0.1012s/iter; left time: 2002.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 222 | Train Loss: 0.0779830 Vali Loss: 0.0841723 Test Loss: 0.0893404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0793392\n",
      "\tspeed: 0.3183s/iter; left time: 6256.6462s\n",
      "\titers: 200, epoch: 12 | loss: 0.0783407\n",
      "\tspeed: 0.1063s/iter; left time: 2079.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:23.95s\n",
      "Steps: 222 | Train Loss: 0.0775615 Vali Loss: 0.0845753 Test Loss: 0.0896497\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0717627\n",
      "\tspeed: 0.3200s/iter; left time: 6220.8047s\n",
      "\titers: 200, epoch: 13 | loss: 0.0760427\n",
      "\tspeed: 0.1052s/iter; left time: 2035.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.00s\n",
      "Steps: 222 | Train Loss: 0.0771428 Vali Loss: 0.0849008 Test Loss: 0.0896374\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738550\n",
      "\tspeed: 0.3131s/iter; left time: 6015.4938s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723396\n",
      "\tspeed: 0.1023s/iter; left time: 1955.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.37s\n",
      "Steps: 222 | Train Loss: 0.0767282 Vali Loss: 0.0847574 Test Loss: 0.0897097\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0740597\n",
      "\tspeed: 0.3176s/iter; left time: 6031.7120s\n",
      "\titers: 200, epoch: 15 | loss: 0.0726431\n",
      "\tspeed: 0.1038s/iter; left time: 1960.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.49s\n",
      "Steps: 222 | Train Loss: 0.0763989 Vali Loss: 0.0849585 Test Loss: 0.0900345\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01999608241021633, rmse:0.14140750467777252, mae:0.08806101232767105, rse:0.5351738333702087\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1304552\n",
      "\tspeed: 0.1111s/iter; left time: 2456.3137s\n",
      "\titers: 200, epoch: 1 | loss: 0.1230357\n",
      "\tspeed: 0.1008s/iter; left time: 2216.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.68s\n",
      "Steps: 222 | Train Loss: 0.1400045 Vali Loss: 0.1050060 Test Loss: 0.1058844\n",
      "Validation loss decreased (inf --> 0.105006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0944798\n",
      "\tspeed: 0.3307s/iter; left time: 7234.8804s\n",
      "\titers: 200, epoch: 2 | loss: 0.0940326\n",
      "\tspeed: 0.1042s/iter; left time: 2269.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.80s\n",
      "Steps: 222 | Train Loss: 0.0967777 Vali Loss: 0.0866084 Test Loss: 0.0891818\n",
      "Validation loss decreased (0.105006 --> 0.086608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894913\n",
      "\tspeed: 0.3224s/iter; left time: 6982.8506s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858088\n",
      "\tspeed: 0.1092s/iter; left time: 2353.6217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.36s\n",
      "Steps: 222 | Train Loss: 0.0879031 Vali Loss: 0.0848397 Test Loss: 0.0882691\n",
      "Validation loss decreased (0.086608 --> 0.084840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866619\n",
      "\tspeed: 0.3221s/iter; left time: 6903.3660s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828001\n",
      "\tspeed: 0.1054s/iter; left time: 2248.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.07s\n",
      "Steps: 222 | Train Loss: 0.0851090 Vali Loss: 0.0837484 Test Loss: 0.0878012\n",
      "Validation loss decreased (0.084840 --> 0.083748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861621\n",
      "\tspeed: 0.3200s/iter; left time: 6788.4171s\n",
      "\titers: 200, epoch: 5 | loss: 0.0821062\n",
      "\tspeed: 0.1052s/iter; left time: 2220.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:23.97s\n",
      "Steps: 222 | Train Loss: 0.0834075 Vali Loss: 0.0829306 Test Loss: 0.0874454\n",
      "Validation loss decreased (0.083748 --> 0.082931).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808549\n",
      "\tspeed: 0.3190s/iter; left time: 6697.1051s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820382\n",
      "\tspeed: 0.1059s/iter; left time: 2213.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:23.85s\n",
      "Steps: 222 | Train Loss: 0.0819533 Vali Loss: 0.0829529 Test Loss: 0.0878453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0796450\n",
      "\tspeed: 0.3250s/iter; left time: 6749.3430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832715\n",
      "\tspeed: 0.1009s/iter; left time: 2085.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.29s\n",
      "Steps: 222 | Train Loss: 0.0809442 Vali Loss: 0.0825301 Test Loss: 0.0880153\n",
      "Validation loss decreased (0.082931 --> 0.082530).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775254\n",
      "\tspeed: 0.3193s/iter; left time: 6560.8919s\n",
      "\titers: 200, epoch: 8 | loss: 0.0788324\n",
      "\tspeed: 0.1018s/iter; left time: 2081.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:23.35s\n",
      "Steps: 222 | Train Loss: 0.0800502 Vali Loss: 0.0832425 Test Loss: 0.0887176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806981\n",
      "\tspeed: 0.3034s/iter; left time: 6167.0507s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805786\n",
      "\tspeed: 0.1017s/iter; left time: 2056.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.17s\n",
      "Steps: 222 | Train Loss: 0.0792796 Vali Loss: 0.0830872 Test Loss: 0.0887377\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775588\n",
      "\tspeed: 0.3140s/iter; left time: 6313.2120s\n",
      "\titers: 200, epoch: 10 | loss: 0.0809518\n",
      "\tspeed: 0.1087s/iter; left time: 2174.7747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.03s\n",
      "Steps: 222 | Train Loss: 0.0786215 Vali Loss: 0.0832103 Test Loss: 0.0886014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0769939\n",
      "\tspeed: 0.3092s/iter; left time: 6147.3395s\n",
      "\titers: 200, epoch: 11 | loss: 0.0785858\n",
      "\tspeed: 0.1026s/iter; left time: 2029.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.44s\n",
      "Steps: 222 | Train Loss: 0.0780797 Vali Loss: 0.0831849 Test Loss: 0.0888413\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0780162\n",
      "\tspeed: 0.3202s/iter; left time: 6294.6527s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788598\n",
      "\tspeed: 0.1017s/iter; left time: 1989.9683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:23.42s\n",
      "Steps: 222 | Train Loss: 0.0775825 Vali Loss: 0.0833615 Test Loss: 0.0889409\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782921\n",
      "\tspeed: 0.3117s/iter; left time: 6058.5961s\n",
      "\titers: 200, epoch: 13 | loss: 0.0769778\n",
      "\tspeed: 0.1051s/iter; left time: 2033.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:23.88s\n",
      "Steps: 222 | Train Loss: 0.0772040 Vali Loss: 0.0830693 Test Loss: 0.0891442\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791389\n",
      "\tspeed: 0.3194s/iter; left time: 6136.8757s\n",
      "\titers: 200, epoch: 14 | loss: 0.0789384\n",
      "\tspeed: 0.1032s/iter; left time: 1973.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.63s\n",
      "Steps: 222 | Train Loss: 0.0767473 Vali Loss: 0.0832471 Test Loss: 0.0888520\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770241\n",
      "\tspeed: 0.3009s/iter; left time: 5715.4488s\n",
      "\titers: 200, epoch: 15 | loss: 0.0787771\n",
      "\tspeed: 0.1036s/iter; left time: 1957.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.66s\n",
      "Steps: 222 | Train Loss: 0.0764810 Vali Loss: 0.0833797 Test Loss: 0.0892758\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0778514\n",
      "\tspeed: 0.3028s/iter; left time: 5684.6335s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740805\n",
      "\tspeed: 0.1048s/iter; left time: 1955.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:23.80s\n",
      "Steps: 222 | Train Loss: 0.0761760 Vali Loss: 0.0830844 Test Loss: 0.0889327\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792995\n",
      "\tspeed: 0.3109s/iter; left time: 5765.9951s\n",
      "\titers: 200, epoch: 17 | loss: 0.0781442\n",
      "\tspeed: 0.1039s/iter; left time: 1917.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:23.78s\n",
      "Steps: 222 | Train Loss: 0.0758439 Vali Loss: 0.0834271 Test Loss: 0.0892882\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02077891305088997, rmse:0.14414893090724945, mae:0.08801530301570892, rse:0.5455491542816162\n",
      "Intermediate time for IT and pred_len 168: 00h:22m:46.48s\n",
      "Intermediate time for IT: 01h:47m:59.37s\n",
      "Total time: 04h:33m:27.02s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.0989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1449  0.0880\n",
       "        96            0.0359  0.1895  0.1251\n",
       "        168           0.0386  0.1964  0.1327\n",
       "ES      24            0.0099  0.0993  0.0598\n",
       "        96            0.0189  0.1376  0.0878\n",
       "        168           0.0213  0.1460  0.0946\n",
       "FR      24            0.0100  0.1002  0.0553\n",
       "        96            0.0197  0.1404  0.0808\n",
       "        168           0.0221  0.1487  0.0882\n",
       "GB      24            0.0246  0.1567  0.0989\n",
       "        96            0.0411  0.2026  0.1388\n",
       "        168           0.0434  0.2084  0.1449\n",
       "IT      24            0.0101  0.1005  0.0573\n",
       "        96            0.0190  0.1378  0.0826\n",
       "        168           0.0204  0.1428  0.0880"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
