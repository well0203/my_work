{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 168](#3-patchtst-168)\n",
    "- [4. PatchTST 336](#4-patchtst-336)\n",
    "- [5. PatchTST 512](#5-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with input look-back windows =168, 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2193371\n",
      "\tspeed: 0.0714s/iter; left time: 1287.1992s\n",
      "\titers: 200, epoch: 1 | loss: 0.1977215\n",
      "\tspeed: 0.0469s/iter; left time: 840.3139s\n",
      "\titers: 300, epoch: 1 | loss: 0.1884996\n",
      "\tspeed: 0.0462s/iter; left time: 823.0834s\n",
      "\titers: 400, epoch: 1 | loss: 0.1732073\n",
      "\tspeed: 0.0462s/iter; left time: 819.1487s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717234\n",
      "\tspeed: 0.0469s/iter; left time: 825.5600s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616005\n",
      "\tspeed: 0.0463s/iter; left time: 810.7936s\n",
      "\titers: 700, epoch: 1 | loss: 0.1801115\n",
      "\tspeed: 0.0449s/iter; left time: 782.4467s\n",
      "\titers: 800, epoch: 1 | loss: 0.1560573\n",
      "\tspeed: 0.0454s/iter; left time: 786.0068s\n",
      "\titers: 900, epoch: 1 | loss: 0.1495997\n",
      "\tspeed: 0.0432s/iter; left time: 743.1248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 906 | Train Loss: 0.1847156 Vali Loss: 0.1656234 Test Loss: 0.1741142\n",
      "Validation loss decreased (inf --> 0.165623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349597\n",
      "\tspeed: 0.1094s/iter; left time: 1872.9680s\n",
      "\titers: 200, epoch: 2 | loss: 0.1336994\n",
      "\tspeed: 0.0434s/iter; left time: 738.8111s\n",
      "\titers: 300, epoch: 2 | loss: 0.1209916\n",
      "\tspeed: 0.0441s/iter; left time: 746.2628s\n",
      "\titers: 400, epoch: 2 | loss: 0.1125416\n",
      "\tspeed: 0.0437s/iter; left time: 734.8755s\n",
      "\titers: 500, epoch: 2 | loss: 0.1105493\n",
      "\tspeed: 0.0468s/iter; left time: 781.9179s\n",
      "\titers: 600, epoch: 2 | loss: 0.0970625\n",
      "\tspeed: 0.0459s/iter; left time: 763.1726s\n",
      "\titers: 700, epoch: 2 | loss: 0.1116746\n",
      "\tspeed: 0.0454s/iter; left time: 749.6724s\n",
      "\titers: 800, epoch: 2 | loss: 0.1117832\n",
      "\tspeed: 0.0460s/iter; left time: 755.6707s\n",
      "\titers: 900, epoch: 2 | loss: 0.1020986\n",
      "\tspeed: 0.0455s/iter; left time: 741.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.04s\n",
      "Steps: 906 | Train Loss: 0.1192016 Vali Loss: 0.1266201 Test Loss: 0.1359189\n",
      "Validation loss decreased (0.165623 --> 0.126620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1158968\n",
      "\tspeed: 0.1116s/iter; left time: 1809.0700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924040\n",
      "\tspeed: 0.0461s/iter; left time: 742.6047s\n",
      "\titers: 300, epoch: 3 | loss: 0.0899346\n",
      "\tspeed: 0.0459s/iter; left time: 735.5361s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857698\n",
      "\tspeed: 0.0459s/iter; left time: 730.5781s\n",
      "\titers: 500, epoch: 3 | loss: 0.0861939\n",
      "\tspeed: 0.0463s/iter; left time: 731.6099s\n",
      "\titers: 600, epoch: 3 | loss: 0.0858602\n",
      "\tspeed: 0.0458s/iter; left time: 719.1868s\n",
      "\titers: 700, epoch: 3 | loss: 0.0784063\n",
      "\tspeed: 0.0465s/iter; left time: 725.0837s\n",
      "\titers: 800, epoch: 3 | loss: 0.0878744\n",
      "\tspeed: 0.0464s/iter; left time: 718.9662s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808627\n",
      "\tspeed: 0.0462s/iter; left time: 711.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0885531 Vali Loss: 0.1016488 Test Loss: 0.1044472\n",
      "Validation loss decreased (0.126620 --> 0.101649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0792848\n",
      "\tspeed: 0.1104s/iter; left time: 1688.8833s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834116\n",
      "\tspeed: 0.0460s/iter; left time: 699.3593s\n",
      "\titers: 300, epoch: 4 | loss: 0.0808930\n",
      "\tspeed: 0.0458s/iter; left time: 692.4186s\n",
      "\titers: 400, epoch: 4 | loss: 0.0806404\n",
      "\tspeed: 0.0459s/iter; left time: 688.1414s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863321\n",
      "\tspeed: 0.0459s/iter; left time: 683.8630s\n",
      "\titers: 600, epoch: 4 | loss: 0.0819875\n",
      "\tspeed: 0.0453s/iter; left time: 670.6085s\n",
      "\titers: 700, epoch: 4 | loss: 0.0820523\n",
      "\tspeed: 0.0461s/iter; left time: 677.6576s\n",
      "\titers: 800, epoch: 4 | loss: 0.0829418\n",
      "\tspeed: 0.0459s/iter; left time: 670.5115s\n",
      "\titers: 900, epoch: 4 | loss: 0.0640380\n",
      "\tspeed: 0.0460s/iter; left time: 667.5169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.69s\n",
      "Steps: 906 | Train Loss: 0.0792295 Vali Loss: 0.0987642 Test Loss: 0.0995154\n",
      "Validation loss decreased (0.101649 --> 0.098764).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736899\n",
      "\tspeed: 0.1167s/iter; left time: 1679.6907s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741243\n",
      "\tspeed: 0.0506s/iter; left time: 723.5414s\n",
      "\titers: 300, epoch: 5 | loss: 0.0739710\n",
      "\tspeed: 0.0497s/iter; left time: 706.2031s\n",
      "\titers: 400, epoch: 5 | loss: 0.0845009\n",
      "\tspeed: 0.0505s/iter; left time: 712.0110s\n",
      "\titers: 500, epoch: 5 | loss: 0.0734567\n",
      "\tspeed: 0.0497s/iter; left time: 695.1420s\n",
      "\titers: 600, epoch: 5 | loss: 0.0848674\n",
      "\tspeed: 0.0496s/iter; left time: 689.8321s\n",
      "\titers: 700, epoch: 5 | loss: 0.0792132\n",
      "\tspeed: 0.0471s/iter; left time: 649.5918s\n",
      "\titers: 800, epoch: 5 | loss: 0.0796287\n",
      "\tspeed: 0.0507s/iter; left time: 694.5913s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893356\n",
      "\tspeed: 0.0485s/iter; left time: 659.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.25s\n",
      "Steps: 906 | Train Loss: 0.0754891 Vali Loss: 0.0970423 Test Loss: 0.1023288\n",
      "Validation loss decreased (0.098764 --> 0.097042).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770415\n",
      "\tspeed: 0.1176s/iter; left time: 1586.2269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0650214\n",
      "\tspeed: 0.0505s/iter; left time: 676.7536s\n",
      "\titers: 300, epoch: 6 | loss: 0.0709342\n",
      "\tspeed: 0.0504s/iter; left time: 669.6138s\n",
      "\titers: 400, epoch: 6 | loss: 0.0764454\n",
      "\tspeed: 0.0472s/iter; left time: 622.6767s\n",
      "\titers: 500, epoch: 6 | loss: 0.0718121\n",
      "\tspeed: 0.0477s/iter; left time: 624.7120s\n",
      "\titers: 600, epoch: 6 | loss: 0.0657555\n",
      "\tspeed: 0.0479s/iter; left time: 622.6301s\n",
      "\titers: 700, epoch: 6 | loss: 0.0661870\n",
      "\tspeed: 0.0477s/iter; left time: 615.4995s\n",
      "\titers: 800, epoch: 6 | loss: 0.0700175\n",
      "\tspeed: 0.0478s/iter; left time: 611.4614s\n",
      "\titers: 900, epoch: 6 | loss: 0.0714951\n",
      "\tspeed: 0.0478s/iter; left time: 606.2062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.31s\n",
      "Steps: 906 | Train Loss: 0.0722549 Vali Loss: 0.0961112 Test Loss: 0.1040979\n",
      "Validation loss decreased (0.097042 --> 0.096111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0660138\n",
      "\tspeed: 0.1136s/iter; left time: 1429.8950s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665872\n",
      "\tspeed: 0.0474s/iter; left time: 591.6264s\n",
      "\titers: 300, epoch: 7 | loss: 0.0691996\n",
      "\tspeed: 0.0462s/iter; left time: 572.1310s\n",
      "\titers: 400, epoch: 7 | loss: 0.0673207\n",
      "\tspeed: 0.0458s/iter; left time: 562.7136s\n",
      "\titers: 500, epoch: 7 | loss: 0.0736774\n",
      "\tspeed: 0.0457s/iter; left time: 557.0006s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582451\n",
      "\tspeed: 0.0463s/iter; left time: 559.5402s\n",
      "\titers: 700, epoch: 7 | loss: 0.0747162\n",
      "\tspeed: 0.0477s/iter; left time: 571.1265s\n",
      "\titers: 800, epoch: 7 | loss: 0.0575175\n",
      "\tspeed: 0.0456s/iter; left time: 541.5130s\n",
      "\titers: 900, epoch: 7 | loss: 0.0671092\n",
      "\tspeed: 0.0487s/iter; left time: 574.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.57s\n",
      "Steps: 906 | Train Loss: 0.0692671 Vali Loss: 0.0940558 Test Loss: 0.1026407\n",
      "Validation loss decreased (0.096111 --> 0.094056).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0589510\n",
      "\tspeed: 0.1225s/iter; left time: 1430.7593s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728251\n",
      "\tspeed: 0.0504s/iter; left time: 583.9179s\n",
      "\titers: 300, epoch: 8 | loss: 0.0642487\n",
      "\tspeed: 0.0476s/iter; left time: 546.2037s\n",
      "\titers: 400, epoch: 8 | loss: 0.0674729\n",
      "\tspeed: 0.0475s/iter; left time: 540.7638s\n",
      "\titers: 500, epoch: 8 | loss: 0.0671887\n",
      "\tspeed: 0.0475s/iter; left time: 536.1497s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739231\n",
      "\tspeed: 0.0496s/iter; left time: 554.6824s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576856\n",
      "\tspeed: 0.0478s/iter; left time: 529.9790s\n",
      "\titers: 800, epoch: 8 | loss: 0.0614317\n",
      "\tspeed: 0.0480s/iter; left time: 527.0374s\n",
      "\titers: 900, epoch: 8 | loss: 0.0775866\n",
      "\tspeed: 0.0484s/iter; left time: 526.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.35s\n",
      "Steps: 906 | Train Loss: 0.0661331 Vali Loss: 0.0988925 Test Loss: 0.1027935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666226\n",
      "\tspeed: 0.1118s/iter; left time: 1204.6813s\n",
      "\titers: 200, epoch: 9 | loss: 0.0640848\n",
      "\tspeed: 0.0476s/iter; left time: 508.3489s\n",
      "\titers: 300, epoch: 9 | loss: 0.0630905\n",
      "\tspeed: 0.0479s/iter; left time: 505.9449s\n",
      "\titers: 400, epoch: 9 | loss: 0.0661945\n",
      "\tspeed: 0.0476s/iter; left time: 498.7793s\n",
      "\titers: 500, epoch: 9 | loss: 0.0665071\n",
      "\tspeed: 0.0478s/iter; left time: 495.6331s\n",
      "\titers: 600, epoch: 9 | loss: 0.0685818\n",
      "\tspeed: 0.0479s/iter; left time: 492.4401s\n",
      "\titers: 700, epoch: 9 | loss: 0.0656188\n",
      "\tspeed: 0.0474s/iter; left time: 482.3368s\n",
      "\titers: 800, epoch: 9 | loss: 0.0669846\n",
      "\tspeed: 0.0479s/iter; left time: 482.9493s\n",
      "\titers: 900, epoch: 9 | loss: 0.0599250\n",
      "\tspeed: 0.0476s/iter; left time: 474.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 906 | Train Loss: 0.0637068 Vali Loss: 0.0966993 Test Loss: 0.1047861\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632723\n",
      "\tspeed: 0.1101s/iter; left time: 1086.0442s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692926\n",
      "\tspeed: 0.0477s/iter; left time: 466.1071s\n",
      "\titers: 300, epoch: 10 | loss: 0.0645902\n",
      "\tspeed: 0.0480s/iter; left time: 463.7953s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728916\n",
      "\tspeed: 0.0477s/iter; left time: 456.3795s\n",
      "\titers: 500, epoch: 10 | loss: 0.0589608\n",
      "\tspeed: 0.0492s/iter; left time: 465.6830s\n",
      "\titers: 600, epoch: 10 | loss: 0.0589466\n",
      "\tspeed: 0.0470s/iter; left time: 439.7960s\n",
      "\titers: 700, epoch: 10 | loss: 0.0540567\n",
      "\tspeed: 0.0495s/iter; left time: 458.7852s\n",
      "\titers: 800, epoch: 10 | loss: 0.0578213\n",
      "\tspeed: 0.0505s/iter; left time: 462.4800s\n",
      "\titers: 900, epoch: 10 | loss: 0.0561226\n",
      "\tspeed: 0.0483s/iter; left time: 438.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.07s\n",
      "Steps: 906 | Train Loss: 0.0611027 Vali Loss: 0.0954745 Test Loss: 0.1028340\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0608129\n",
      "\tspeed: 0.1144s/iter; left time: 1025.2268s\n",
      "\titers: 200, epoch: 11 | loss: 0.0599368\n",
      "\tspeed: 0.0506s/iter; left time: 448.1623s\n",
      "\titers: 300, epoch: 11 | loss: 0.0558104\n",
      "\tspeed: 0.0503s/iter; left time: 440.2885s\n",
      "\titers: 400, epoch: 11 | loss: 0.0515542\n",
      "\tspeed: 0.0505s/iter; left time: 437.7860s\n",
      "\titers: 500, epoch: 11 | loss: 0.0650875\n",
      "\tspeed: 0.0497s/iter; left time: 425.4352s\n",
      "\titers: 600, epoch: 11 | loss: 0.0647349\n",
      "\tspeed: 0.0491s/iter; left time: 415.7389s\n",
      "\titers: 700, epoch: 11 | loss: 0.0569948\n",
      "\tspeed: 0.0478s/iter; left time: 399.6781s\n",
      "\titers: 800, epoch: 11 | loss: 0.0515813\n",
      "\tspeed: 0.0504s/iter; left time: 416.4456s\n",
      "\titers: 900, epoch: 11 | loss: 0.0487354\n",
      "\tspeed: 0.0495s/iter; left time: 403.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.37s\n",
      "Steps: 906 | Train Loss: 0.0585829 Vali Loss: 0.0957306 Test Loss: 0.1064269\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0584590\n",
      "\tspeed: 0.1124s/iter; left time: 905.5042s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584398\n",
      "\tspeed: 0.0492s/iter; left time: 391.1544s\n",
      "\titers: 300, epoch: 12 | loss: 0.0573530\n",
      "\tspeed: 0.0505s/iter; left time: 396.7801s\n",
      "\titers: 400, epoch: 12 | loss: 0.0605661\n",
      "\tspeed: 0.0467s/iter; left time: 361.8423s\n",
      "\titers: 500, epoch: 12 | loss: 0.0548147\n",
      "\tspeed: 0.0460s/iter; left time: 351.8984s\n",
      "\titers: 600, epoch: 12 | loss: 0.0529713\n",
      "\tspeed: 0.0461s/iter; left time: 348.0106s\n",
      "\titers: 700, epoch: 12 | loss: 0.0574244\n",
      "\tspeed: 0.0458s/iter; left time: 341.5892s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501836\n",
      "\tspeed: 0.0458s/iter; left time: 336.7705s\n",
      "\titers: 900, epoch: 12 | loss: 0.0584249\n",
      "\tspeed: 0.0482s/iter; left time: 349.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 906 | Train Loss: 0.0567967 Vali Loss: 0.0991605 Test Loss: 0.1062757\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02503511682152748, rmse:0.1582248955965042, mae:0.10250058770179749, rse:0.5587754845619202\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2209228\n",
      "\tspeed: 0.0527s/iter; left time: 950.4787s\n",
      "\titers: 200, epoch: 1 | loss: 0.1902164\n",
      "\tspeed: 0.0506s/iter; left time: 907.1320s\n",
      "\titers: 300, epoch: 1 | loss: 0.1861653\n",
      "\tspeed: 0.0493s/iter; left time: 878.7219s\n",
      "\titers: 400, epoch: 1 | loss: 0.1823416\n",
      "\tspeed: 0.0477s/iter; left time: 844.5619s\n",
      "\titers: 500, epoch: 1 | loss: 0.1792150\n",
      "\tspeed: 0.0511s/iter; left time: 900.1851s\n",
      "\titers: 600, epoch: 1 | loss: 0.1767687\n",
      "\tspeed: 0.0497s/iter; left time: 870.1305s\n",
      "\titers: 700, epoch: 1 | loss: 0.1690864\n",
      "\tspeed: 0.0480s/iter; left time: 836.8974s\n",
      "\titers: 800, epoch: 1 | loss: 0.1706984\n",
      "\tspeed: 0.0501s/iter; left time: 868.4686s\n",
      "\titers: 900, epoch: 1 | loss: 0.1513919\n",
      "\tspeed: 0.0495s/iter; left time: 852.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.24s\n",
      "Steps: 906 | Train Loss: 0.1882799 Vali Loss: 0.1665931 Test Loss: 0.1768704\n",
      "Validation loss decreased (inf --> 0.166593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1368255\n",
      "\tspeed: 0.1188s/iter; left time: 2033.1831s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390444\n",
      "\tspeed: 0.0504s/iter; left time: 857.5371s\n",
      "\titers: 300, epoch: 2 | loss: 0.1252545\n",
      "\tspeed: 0.0479s/iter; left time: 810.0550s\n",
      "\titers: 400, epoch: 2 | loss: 0.1175311\n",
      "\tspeed: 0.0480s/iter; left time: 806.2912s\n",
      "\titers: 500, epoch: 2 | loss: 0.1201848\n",
      "\tspeed: 0.0492s/iter; left time: 822.8948s\n",
      "\titers: 600, epoch: 2 | loss: 0.1047623\n",
      "\tspeed: 0.0467s/iter; left time: 775.8895s\n",
      "\titers: 700, epoch: 2 | loss: 0.1203549\n",
      "\tspeed: 0.0481s/iter; left time: 793.9460s\n",
      "\titers: 800, epoch: 2 | loss: 0.0944271\n",
      "\tspeed: 0.0484s/iter; left time: 793.6972s\n",
      "\titers: 900, epoch: 2 | loss: 0.1203178\n",
      "\tspeed: 0.0491s/iter; left time: 800.9743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.33s\n",
      "Steps: 906 | Train Loss: 0.1226015 Vali Loss: 0.1264837 Test Loss: 0.1367266\n",
      "Validation loss decreased (0.166593 --> 0.126484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049845\n",
      "\tspeed: 0.1174s/iter; left time: 1903.4723s\n",
      "\titers: 200, epoch: 3 | loss: 0.1047302\n",
      "\tspeed: 0.0487s/iter; left time: 784.1103s\n",
      "\titers: 300, epoch: 3 | loss: 0.0955707\n",
      "\tspeed: 0.0507s/iter; left time: 812.3723s\n",
      "\titers: 400, epoch: 3 | loss: 0.1100043\n",
      "\tspeed: 0.0479s/iter; left time: 761.5696s\n",
      "\titers: 500, epoch: 3 | loss: 0.1044606\n",
      "\tspeed: 0.0484s/iter; left time: 765.5962s\n",
      "\titers: 600, epoch: 3 | loss: 0.0991454\n",
      "\tspeed: 0.0479s/iter; left time: 751.7801s\n",
      "\titers: 700, epoch: 3 | loss: 0.1010945\n",
      "\tspeed: 0.0476s/iter; left time: 743.2149s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062495\n",
      "\tspeed: 0.0481s/iter; left time: 746.3202s\n",
      "\titers: 900, epoch: 3 | loss: 0.1075993\n",
      "\tspeed: 0.0479s/iter; left time: 737.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.12s\n",
      "Steps: 906 | Train Loss: 0.1036576 Vali Loss: 0.1235929 Test Loss: 0.1351364\n",
      "Validation loss decreased (0.126484 --> 0.123593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985526\n",
      "\tspeed: 0.1157s/iter; left time: 1770.2254s\n",
      "\titers: 200, epoch: 4 | loss: 0.1032197\n",
      "\tspeed: 0.0479s/iter; left time: 727.8057s\n",
      "\titers: 300, epoch: 4 | loss: 0.0960748\n",
      "\tspeed: 0.0477s/iter; left time: 720.0805s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083821\n",
      "\tspeed: 0.0481s/iter; left time: 721.6511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976141\n",
      "\tspeed: 0.0474s/iter; left time: 706.9866s\n",
      "\titers: 600, epoch: 4 | loss: 0.0889361\n",
      "\tspeed: 0.0475s/iter; left time: 703.5839s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876954\n",
      "\tspeed: 0.0470s/iter; left time: 691.4759s\n",
      "\titers: 800, epoch: 4 | loss: 0.0864828\n",
      "\tspeed: 0.0486s/iter; left time: 708.9860s\n",
      "\titers: 900, epoch: 4 | loss: 0.0808749\n",
      "\tspeed: 0.0479s/iter; left time: 695.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.63s\n",
      "Steps: 906 | Train Loss: 0.0955038 Vali Loss: 0.0984326 Test Loss: 0.1020987\n",
      "Validation loss decreased (0.123593 --> 0.098433).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693327\n",
      "\tspeed: 0.1154s/iter; left time: 1661.8658s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791737\n",
      "\tspeed: 0.0475s/iter; left time: 678.6257s\n",
      "\titers: 300, epoch: 5 | loss: 0.0842561\n",
      "\tspeed: 0.0458s/iter; left time: 650.7087s\n",
      "\titers: 400, epoch: 5 | loss: 0.0753921\n",
      "\tspeed: 0.0471s/iter; left time: 663.8060s\n",
      "\titers: 500, epoch: 5 | loss: 0.0805455\n",
      "\tspeed: 0.0471s/iter; left time: 659.2575s\n",
      "\titers: 600, epoch: 5 | loss: 0.0652466\n",
      "\tspeed: 0.0493s/iter; left time: 684.6148s\n",
      "\titers: 700, epoch: 5 | loss: 0.0767411\n",
      "\tspeed: 0.0477s/iter; left time: 657.5715s\n",
      "\titers: 800, epoch: 5 | loss: 0.0734380\n",
      "\tspeed: 0.0491s/iter; left time: 673.1081s\n",
      "\titers: 900, epoch: 5 | loss: 0.0672268\n",
      "\tspeed: 0.0484s/iter; left time: 658.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.57s\n",
      "Steps: 906 | Train Loss: 0.0775636 Vali Loss: 0.0965865 Test Loss: 0.1022946\n",
      "Validation loss decreased (0.098433 --> 0.096587).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776920\n",
      "\tspeed: 0.1146s/iter; left time: 1546.6984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689330\n",
      "\tspeed: 0.0481s/iter; left time: 644.1956s\n",
      "\titers: 300, epoch: 6 | loss: 0.0715801\n",
      "\tspeed: 0.0482s/iter; left time: 640.5671s\n",
      "\titers: 400, epoch: 6 | loss: 0.0735732\n",
      "\tspeed: 0.0452s/iter; left time: 596.8024s\n",
      "\titers: 500, epoch: 6 | loss: 0.0734075\n",
      "\tspeed: 0.0465s/iter; left time: 608.4918s\n",
      "\titers: 600, epoch: 6 | loss: 0.0756910\n",
      "\tspeed: 0.0466s/iter; left time: 605.6275s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700148\n",
      "\tspeed: 0.0481s/iter; left time: 619.8771s\n",
      "\titers: 800, epoch: 6 | loss: 0.0713590\n",
      "\tspeed: 0.0481s/iter; left time: 615.4595s\n",
      "\titers: 900, epoch: 6 | loss: 0.0711626\n",
      "\tspeed: 0.0455s/iter; left time: 578.0040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.02s\n",
      "Steps: 906 | Train Loss: 0.0737180 Vali Loss: 0.0977053 Test Loss: 0.1045457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0707487\n",
      "\tspeed: 0.1092s/iter; left time: 1373.7280s\n",
      "\titers: 200, epoch: 7 | loss: 0.0672919\n",
      "\tspeed: 0.0457s/iter; left time: 570.9540s\n",
      "\titers: 300, epoch: 7 | loss: 0.0736401\n",
      "\tspeed: 0.0461s/iter; left time: 570.3844s\n",
      "\titers: 400, epoch: 7 | loss: 0.0677582\n",
      "\tspeed: 0.0457s/iter; left time: 561.3001s\n",
      "\titers: 500, epoch: 7 | loss: 0.0748733\n",
      "\tspeed: 0.0462s/iter; left time: 562.8405s\n",
      "\titers: 600, epoch: 7 | loss: 0.0729828\n",
      "\tspeed: 0.0462s/iter; left time: 558.1090s\n",
      "\titers: 700, epoch: 7 | loss: 0.0575399\n",
      "\tspeed: 0.0464s/iter; left time: 555.8893s\n",
      "\titers: 800, epoch: 7 | loss: 0.0780056\n",
      "\tspeed: 0.0462s/iter; left time: 549.4186s\n",
      "\titers: 900, epoch: 7 | loss: 0.0625338\n",
      "\tspeed: 0.0455s/iter; left time: 535.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 906 | Train Loss: 0.0701726 Vali Loss: 0.0972105 Test Loss: 0.1042383\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0615204\n",
      "\tspeed: 0.1092s/iter; left time: 1275.3097s\n",
      "\titers: 200, epoch: 8 | loss: 0.0659045\n",
      "\tspeed: 0.0457s/iter; left time: 529.3296s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652609\n",
      "\tspeed: 0.0460s/iter; left time: 528.0945s\n",
      "\titers: 400, epoch: 8 | loss: 0.0691719\n",
      "\tspeed: 0.0461s/iter; left time: 524.5279s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823549\n",
      "\tspeed: 0.0462s/iter; left time: 521.5199s\n",
      "\titers: 600, epoch: 8 | loss: 0.0681711\n",
      "\tspeed: 0.0460s/iter; left time: 513.8483s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681319\n",
      "\tspeed: 0.0457s/iter; left time: 506.4419s\n",
      "\titers: 800, epoch: 8 | loss: 0.0736955\n",
      "\tspeed: 0.0457s/iter; left time: 502.2795s\n",
      "\titers: 900, epoch: 8 | loss: 0.0596028\n",
      "\tspeed: 0.0460s/iter; left time: 500.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 906 | Train Loss: 0.0674239 Vali Loss: 0.0962781 Test Loss: 0.1040185\n",
      "Validation loss decreased (0.096587 --> 0.096278).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0616742\n",
      "\tspeed: 0.1126s/iter; left time: 1212.8309s\n",
      "\titers: 200, epoch: 9 | loss: 0.0522444\n",
      "\tspeed: 0.0451s/iter; left time: 480.9247s\n",
      "\titers: 300, epoch: 9 | loss: 0.0629223\n",
      "\tspeed: 0.0457s/iter; left time: 483.3403s\n",
      "\titers: 400, epoch: 9 | loss: 0.0630886\n",
      "\tspeed: 0.0460s/iter; left time: 482.1895s\n",
      "\titers: 500, epoch: 9 | loss: 0.0573699\n",
      "\tspeed: 0.0460s/iter; left time: 477.1239s\n",
      "\titers: 600, epoch: 9 | loss: 0.0559906\n",
      "\tspeed: 0.0457s/iter; left time: 469.7802s\n",
      "\titers: 700, epoch: 9 | loss: 0.0674314\n",
      "\tspeed: 0.0456s/iter; left time: 464.3792s\n",
      "\titers: 800, epoch: 9 | loss: 0.0620898\n",
      "\tspeed: 0.0464s/iter; left time: 467.1048s\n",
      "\titers: 900, epoch: 9 | loss: 0.0567981\n",
      "\tspeed: 0.0459s/iter; left time: 457.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0646134 Vali Loss: 0.0964188 Test Loss: 0.1026151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548026\n",
      "\tspeed: 0.1089s/iter; left time: 1074.7403s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589220\n",
      "\tspeed: 0.0463s/iter; left time: 452.1062s\n",
      "\titers: 300, epoch: 10 | loss: 0.0606921\n",
      "\tspeed: 0.0463s/iter; left time: 448.0388s\n",
      "\titers: 400, epoch: 10 | loss: 0.0613493\n",
      "\tspeed: 0.0460s/iter; left time: 440.3171s\n",
      "\titers: 500, epoch: 10 | loss: 0.0667166\n",
      "\tspeed: 0.0466s/iter; left time: 440.7466s\n",
      "\titers: 600, epoch: 10 | loss: 0.0655026\n",
      "\tspeed: 0.0460s/iter; left time: 430.7230s\n",
      "\titers: 700, epoch: 10 | loss: 0.0616325\n",
      "\tspeed: 0.0453s/iter; left time: 419.6195s\n",
      "\titers: 800, epoch: 10 | loss: 0.0592780\n",
      "\tspeed: 0.0459s/iter; left time: 420.6660s\n",
      "\titers: 900, epoch: 10 | loss: 0.0651274\n",
      "\tspeed: 0.0449s/iter; left time: 407.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.0621331 Vali Loss: 0.0966932 Test Loss: 0.1082848\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0611093\n",
      "\tspeed: 0.1081s/iter; left time: 968.6472s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578680\n",
      "\tspeed: 0.0470s/iter; left time: 416.3009s\n",
      "\titers: 300, epoch: 11 | loss: 0.0573885\n",
      "\tspeed: 0.0472s/iter; left time: 413.0860s\n",
      "\titers: 400, epoch: 11 | loss: 0.0532788\n",
      "\tspeed: 0.0474s/iter; left time: 410.2725s\n",
      "\titers: 500, epoch: 11 | loss: 0.0575405\n",
      "\tspeed: 0.0493s/iter; left time: 422.3598s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601803\n",
      "\tspeed: 0.0492s/iter; left time: 416.4425s\n",
      "\titers: 700, epoch: 11 | loss: 0.0570868\n",
      "\tspeed: 0.0490s/iter; left time: 409.3627s\n",
      "\titers: 800, epoch: 11 | loss: 0.0665489\n",
      "\tspeed: 0.0494s/iter; left time: 407.8504s\n",
      "\titers: 900, epoch: 11 | loss: 0.0546679\n",
      "\tspeed: 0.0492s/iter; left time: 401.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.86s\n",
      "Steps: 906 | Train Loss: 0.0597120 Vali Loss: 0.0936789 Test Loss: 0.1029847\n",
      "Validation loss decreased (0.096278 --> 0.093679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0630511\n",
      "\tspeed: 0.1138s/iter; left time: 916.7436s\n",
      "\titers: 200, epoch: 12 | loss: 0.0615881\n",
      "\tspeed: 0.0464s/iter; left time: 369.1782s\n",
      "\titers: 300, epoch: 12 | loss: 0.0559201\n",
      "\tspeed: 0.0464s/iter; left time: 364.2414s\n",
      "\titers: 400, epoch: 12 | loss: 0.0519277\n",
      "\tspeed: 0.0466s/iter; left time: 361.7202s\n",
      "\titers: 500, epoch: 12 | loss: 0.0599991\n",
      "\tspeed: 0.0465s/iter; left time: 355.9195s\n",
      "\titers: 600, epoch: 12 | loss: 0.0630212\n",
      "\tspeed: 0.0461s/iter; left time: 348.1366s\n",
      "\titers: 700, epoch: 12 | loss: 0.0543649\n",
      "\tspeed: 0.0466s/iter; left time: 347.3715s\n",
      "\titers: 800, epoch: 12 | loss: 0.0606494\n",
      "\tspeed: 0.0463s/iter; left time: 340.7000s\n",
      "\titers: 900, epoch: 12 | loss: 0.0567524\n",
      "\tspeed: 0.0463s/iter; left time: 336.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 906 | Train Loss: 0.0571922 Vali Loss: 0.0974627 Test Loss: 0.1070443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0593928\n",
      "\tspeed: 0.1106s/iter; left time: 790.7263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506865\n",
      "\tspeed: 0.0457s/iter; left time: 322.1822s\n",
      "\titers: 300, epoch: 13 | loss: 0.0564607\n",
      "\tspeed: 0.0459s/iter; left time: 318.9464s\n",
      "\titers: 400, epoch: 13 | loss: 0.0527917\n",
      "\tspeed: 0.0460s/iter; left time: 315.2981s\n",
      "\titers: 500, epoch: 13 | loss: 0.0548141\n",
      "\tspeed: 0.0457s/iter; left time: 308.2119s\n",
      "\titers: 600, epoch: 13 | loss: 0.0536862\n",
      "\tspeed: 0.0461s/iter; left time: 306.3054s\n",
      "\titers: 700, epoch: 13 | loss: 0.0593105\n",
      "\tspeed: 0.0459s/iter; left time: 300.4360s\n",
      "\titers: 800, epoch: 13 | loss: 0.0583405\n",
      "\tspeed: 0.0463s/iter; left time: 298.4591s\n",
      "\titers: 900, epoch: 13 | loss: 0.0595543\n",
      "\tspeed: 0.0461s/iter; left time: 292.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.90s\n",
      "Steps: 906 | Train Loss: 0.0552700 Vali Loss: 0.0980769 Test Loss: 0.1070963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560386\n",
      "\tspeed: 0.1087s/iter; left time: 678.7218s\n",
      "\titers: 200, epoch: 14 | loss: 0.0519739\n",
      "\tspeed: 0.0459s/iter; left time: 281.9883s\n",
      "\titers: 300, epoch: 14 | loss: 0.0482483\n",
      "\tspeed: 0.0463s/iter; left time: 279.8914s\n",
      "\titers: 400, epoch: 14 | loss: 0.0503040\n",
      "\tspeed: 0.0459s/iter; left time: 273.0089s\n",
      "\titers: 500, epoch: 14 | loss: 0.0518296\n",
      "\tspeed: 0.0460s/iter; left time: 269.0467s\n",
      "\titers: 600, epoch: 14 | loss: 0.0475292\n",
      "\tspeed: 0.0460s/iter; left time: 263.9798s\n",
      "\titers: 700, epoch: 14 | loss: 0.0490515\n",
      "\tspeed: 0.0437s/iter; left time: 246.4102s\n",
      "\titers: 800, epoch: 14 | loss: 0.0554480\n",
      "\tspeed: 0.0461s/iter; left time: 255.3968s\n",
      "\titers: 900, epoch: 14 | loss: 0.0600134\n",
      "\tspeed: 0.0461s/iter; left time: 251.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 906 | Train Loss: 0.0535541 Vali Loss: 0.0998057 Test Loss: 0.1077985\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0498628\n",
      "\tspeed: 0.1094s/iter; left time: 584.0404s\n",
      "\titers: 200, epoch: 15 | loss: 0.0509019\n",
      "\tspeed: 0.0469s/iter; left time: 245.8367s\n",
      "\titers: 300, epoch: 15 | loss: 0.0491260\n",
      "\tspeed: 0.0496s/iter; left time: 254.6633s\n",
      "\titers: 400, epoch: 15 | loss: 0.0523825\n",
      "\tspeed: 0.0494s/iter; left time: 248.8739s\n",
      "\titers: 500, epoch: 15 | loss: 0.0568884\n",
      "\tspeed: 0.0497s/iter; left time: 245.5476s\n",
      "\titers: 600, epoch: 15 | loss: 0.0534033\n",
      "\tspeed: 0.0494s/iter; left time: 239.1020s\n",
      "\titers: 700, epoch: 15 | loss: 0.0473140\n",
      "\tspeed: 0.0497s/iter; left time: 235.5965s\n",
      "\titers: 800, epoch: 15 | loss: 0.0530336\n",
      "\tspeed: 0.0493s/iter; left time: 228.5697s\n",
      "\titers: 900, epoch: 15 | loss: 0.0458356\n",
      "\tspeed: 0.0433s/iter; left time: 196.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 906 | Train Loss: 0.0519952 Vali Loss: 0.0975314 Test Loss: 0.1075522\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0488202\n",
      "\tspeed: 0.1086s/iter; left time: 481.3592s\n",
      "\titers: 200, epoch: 16 | loss: 0.0530199\n",
      "\tspeed: 0.0440s/iter; left time: 190.5993s\n",
      "\titers: 300, epoch: 16 | loss: 0.0499976\n",
      "\tspeed: 0.0437s/iter; left time: 184.9680s\n",
      "\titers: 400, epoch: 16 | loss: 0.0442361\n",
      "\tspeed: 0.0450s/iter; left time: 185.7208s\n",
      "\titers: 500, epoch: 16 | loss: 0.0529236\n",
      "\tspeed: 0.0442s/iter; left time: 177.9981s\n",
      "\titers: 600, epoch: 16 | loss: 0.0488371\n",
      "\tspeed: 0.0441s/iter; left time: 173.2902s\n",
      "\titers: 700, epoch: 16 | loss: 0.0491037\n",
      "\tspeed: 0.0448s/iter; left time: 171.7604s\n",
      "\titers: 800, epoch: 16 | loss: 0.0455605\n",
      "\tspeed: 0.0460s/iter; left time: 171.6779s\n",
      "\titers: 900, epoch: 16 | loss: 0.0486577\n",
      "\tspeed: 0.0458s/iter; left time: 166.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.66s\n",
      "Steps: 906 | Train Loss: 0.0508140 Vali Loss: 0.0993314 Test Loss: 0.1080995\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026359017938375473, rmse:0.16235460340976715, mae:0.10303153097629547, rse:0.5733596682548523\n",
      "Intermediate time for DE and pred_len 24: 00h:23m:11.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2211680\n",
      "\tspeed: 0.0648s/iter; left time: 1165.6347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2124181\n",
      "\tspeed: 0.0504s/iter; left time: 901.9235s\n",
      "\titers: 300, epoch: 1 | loss: 0.2027560\n",
      "\tspeed: 0.0507s/iter; left time: 902.0542s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934510\n",
      "\tspeed: 0.0505s/iter; left time: 893.4285s\n",
      "\titers: 500, epoch: 1 | loss: 0.1852765\n",
      "\tspeed: 0.0504s/iter; left time: 886.4453s\n",
      "\titers: 600, epoch: 1 | loss: 0.1785509\n",
      "\tspeed: 0.0506s/iter; left time: 883.8930s\n",
      "\titers: 700, epoch: 1 | loss: 0.1699531\n",
      "\tspeed: 0.0505s/iter; left time: 877.7730s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744952\n",
      "\tspeed: 0.0505s/iter; left time: 873.0484s\n",
      "\titers: 900, epoch: 1 | loss: 0.1717111\n",
      "\tspeed: 0.0507s/iter; left time: 871.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.45s\n",
      "Steps: 904 | Train Loss: 0.1950607 Vali Loss: 0.1829108 Test Loss: 0.2037840\n",
      "Validation loss decreased (inf --> 0.182911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1621778\n",
      "\tspeed: 0.1254s/iter; left time: 2141.9602s\n",
      "\titers: 200, epoch: 2 | loss: 0.1427496\n",
      "\tspeed: 0.0506s/iter; left time: 859.0954s\n",
      "\titers: 300, epoch: 2 | loss: 0.1401429\n",
      "\tspeed: 0.0505s/iter; left time: 851.4984s\n",
      "\titers: 400, epoch: 2 | loss: 0.1463907\n",
      "\tspeed: 0.0506s/iter; left time: 849.3159s\n",
      "\titers: 500, epoch: 2 | loss: 0.1395933\n",
      "\tspeed: 0.0503s/iter; left time: 838.9343s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227748\n",
      "\tspeed: 0.0505s/iter; left time: 837.4684s\n",
      "\titers: 700, epoch: 2 | loss: 0.1235877\n",
      "\tspeed: 0.0505s/iter; left time: 831.3733s\n",
      "\titers: 800, epoch: 2 | loss: 0.1240215\n",
      "\tspeed: 0.0506s/iter; left time: 828.0348s\n",
      "\titers: 900, epoch: 2 | loss: 0.1336349\n",
      "\tspeed: 0.0508s/iter; left time: 827.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.1377187 Vali Loss: 0.1409242 Test Loss: 0.1577245\n",
      "Validation loss decreased (0.182911 --> 0.140924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216025\n",
      "\tspeed: 0.1306s/iter; left time: 2112.0608s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104100\n",
      "\tspeed: 0.0508s/iter; left time: 815.7676s\n",
      "\titers: 300, epoch: 3 | loss: 0.1143406\n",
      "\tspeed: 0.0509s/iter; left time: 812.6594s\n",
      "\titers: 400, epoch: 3 | loss: 0.1088113\n",
      "\tspeed: 0.0507s/iter; left time: 804.6677s\n",
      "\titers: 500, epoch: 3 | loss: 0.1070392\n",
      "\tspeed: 0.0509s/iter; left time: 803.5037s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047399\n",
      "\tspeed: 0.0506s/iter; left time: 793.8004s\n",
      "\titers: 700, epoch: 3 | loss: 0.1145064\n",
      "\tspeed: 0.0507s/iter; left time: 790.3216s\n",
      "\titers: 800, epoch: 3 | loss: 0.0987913\n",
      "\tspeed: 0.0507s/iter; left time: 784.6588s\n",
      "\titers: 900, epoch: 3 | loss: 0.1122302\n",
      "\tspeed: 0.0507s/iter; left time: 779.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 904 | Train Loss: 0.1095338 Vali Loss: 0.1256561 Test Loss: 0.1422735\n",
      "Validation loss decreased (0.140924 --> 0.125656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153372\n",
      "\tspeed: 0.1259s/iter; left time: 1922.6719s\n",
      "\titers: 200, epoch: 4 | loss: 0.1000890\n",
      "\tspeed: 0.0506s/iter; left time: 766.8459s\n",
      "\titers: 300, epoch: 4 | loss: 0.1141460\n",
      "\tspeed: 0.0506s/iter; left time: 762.1526s\n",
      "\titers: 400, epoch: 4 | loss: 0.0980017\n",
      "\tspeed: 0.0505s/iter; left time: 756.5649s\n",
      "\titers: 500, epoch: 4 | loss: 0.1069045\n",
      "\tspeed: 0.0504s/iter; left time: 749.2749s\n",
      "\titers: 600, epoch: 4 | loss: 0.1010115\n",
      "\tspeed: 0.0504s/iter; left time: 744.9523s\n",
      "\titers: 700, epoch: 4 | loss: 0.1052074\n",
      "\tspeed: 0.0505s/iter; left time: 740.7146s\n",
      "\titers: 800, epoch: 4 | loss: 0.0944677\n",
      "\tspeed: 0.0506s/iter; left time: 736.7107s\n",
      "\titers: 900, epoch: 4 | loss: 0.0917887\n",
      "\tspeed: 0.0502s/iter; left time: 726.9954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.1004663 Vali Loss: 0.1298832 Test Loss: 0.1427613\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909345\n",
      "\tspeed: 0.1222s/iter; left time: 1755.5241s\n",
      "\titers: 200, epoch: 5 | loss: 0.0933988\n",
      "\tspeed: 0.0498s/iter; left time: 710.5553s\n",
      "\titers: 300, epoch: 5 | loss: 0.0942662\n",
      "\tspeed: 0.0497s/iter; left time: 703.4652s\n",
      "\titers: 400, epoch: 5 | loss: 0.1026393\n",
      "\tspeed: 0.0498s/iter; left time: 700.3141s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877419\n",
      "\tspeed: 0.0499s/iter; left time: 697.3258s\n",
      "\titers: 600, epoch: 5 | loss: 0.0984881\n",
      "\tspeed: 0.0499s/iter; left time: 691.5958s\n",
      "\titers: 700, epoch: 5 | loss: 0.0965933\n",
      "\tspeed: 0.0503s/iter; left time: 692.6762s\n",
      "\titers: 800, epoch: 5 | loss: 0.0884743\n",
      "\tspeed: 0.0506s/iter; left time: 691.5599s\n",
      "\titers: 900, epoch: 5 | loss: 0.0875624\n",
      "\tspeed: 0.0507s/iter; left time: 687.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 904 | Train Loss: 0.0937394 Vali Loss: 0.1292347 Test Loss: 0.1464715\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844789\n",
      "\tspeed: 0.1223s/iter; left time: 1645.7527s\n",
      "\titers: 200, epoch: 6 | loss: 0.0831305\n",
      "\tspeed: 0.0504s/iter; left time: 673.0533s\n",
      "\titers: 300, epoch: 6 | loss: 0.0890788\n",
      "\tspeed: 0.0506s/iter; left time: 670.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0890178\n",
      "\tspeed: 0.0505s/iter; left time: 664.6019s\n",
      "\titers: 500, epoch: 6 | loss: 0.0872497\n",
      "\tspeed: 0.0504s/iter; left time: 658.8941s\n",
      "\titers: 600, epoch: 6 | loss: 0.0838243\n",
      "\tspeed: 0.0504s/iter; left time: 653.2431s\n",
      "\titers: 700, epoch: 6 | loss: 0.0790157\n",
      "\tspeed: 0.0506s/iter; left time: 650.2091s\n",
      "\titers: 800, epoch: 6 | loss: 0.0860724\n",
      "\tspeed: 0.0505s/iter; left time: 644.8071s\n",
      "\titers: 900, epoch: 6 | loss: 0.0885994\n",
      "\tspeed: 0.0507s/iter; left time: 642.4027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.0874963 Vali Loss: 0.1259206 Test Loss: 0.1465154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867068\n",
      "\tspeed: 0.1235s/iter; left time: 1551.3603s\n",
      "\titers: 200, epoch: 7 | loss: 0.0808286\n",
      "\tspeed: 0.0505s/iter; left time: 629.6850s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818731\n",
      "\tspeed: 0.0506s/iter; left time: 624.7183s\n",
      "\titers: 400, epoch: 7 | loss: 0.0807535\n",
      "\tspeed: 0.0505s/iter; left time: 619.3385s\n",
      "\titers: 500, epoch: 7 | loss: 0.0798821\n",
      "\tspeed: 0.0504s/iter; left time: 613.2336s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856204\n",
      "\tspeed: 0.0505s/iter; left time: 608.7922s\n",
      "\titers: 700, epoch: 7 | loss: 0.0826759\n",
      "\tspeed: 0.0506s/iter; left time: 604.5178s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764204\n",
      "\tspeed: 0.0509s/iter; left time: 603.1849s\n",
      "\titers: 900, epoch: 7 | loss: 0.0779424\n",
      "\tspeed: 0.0516s/iter; left time: 606.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.0820894 Vali Loss: 0.1282384 Test Loss: 0.1467834\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753770\n",
      "\tspeed: 0.1238s/iter; left time: 1442.5740s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761234\n",
      "\tspeed: 0.0508s/iter; left time: 587.3618s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806233\n",
      "\tspeed: 0.0511s/iter; left time: 584.7093s\n",
      "\titers: 400, epoch: 8 | loss: 0.0802709\n",
      "\tspeed: 0.0508s/iter; left time: 576.8260s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798946\n",
      "\tspeed: 0.0506s/iter; left time: 569.6456s\n",
      "\titers: 600, epoch: 8 | loss: 0.0823787\n",
      "\tspeed: 0.0507s/iter; left time: 565.9418s\n",
      "\titers: 700, epoch: 8 | loss: 0.0790553\n",
      "\tspeed: 0.0505s/iter; left time: 558.3500s\n",
      "\titers: 800, epoch: 8 | loss: 0.0728498\n",
      "\tspeed: 0.0504s/iter; left time: 551.8289s\n",
      "\titers: 900, epoch: 8 | loss: 0.0717074\n",
      "\tspeed: 0.0505s/iter; left time: 548.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0772998 Vali Loss: 0.1293028 Test Loss: 0.1479542\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04122032970190048, rmse:0.2030279040336609, mae:0.14230172336101532, rse:0.7189628481864929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2228246\n",
      "\tspeed: 0.0539s/iter; left time: 970.0559s\n",
      "\titers: 200, epoch: 1 | loss: 0.1975601\n",
      "\tspeed: 0.0515s/iter; left time: 920.7280s\n",
      "\titers: 300, epoch: 1 | loss: 0.1984413\n",
      "\tspeed: 0.0519s/iter; left time: 923.1705s\n",
      "\titers: 400, epoch: 1 | loss: 0.1955372\n",
      "\tspeed: 0.0510s/iter; left time: 902.3944s\n",
      "\titers: 500, epoch: 1 | loss: 0.2015178\n",
      "\tspeed: 0.0507s/iter; left time: 891.0008s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833165\n",
      "\tspeed: 0.0515s/iter; left time: 899.6854s\n",
      "\titers: 700, epoch: 1 | loss: 0.1784639\n",
      "\tspeed: 0.0513s/iter; left time: 892.2272s\n",
      "\titers: 800, epoch: 1 | loss: 0.1788543\n",
      "\tspeed: 0.0511s/iter; left time: 882.4433s\n",
      "\titers: 900, epoch: 1 | loss: 0.1769701\n",
      "\tspeed: 0.0510s/iter; left time: 876.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 904 | Train Loss: 0.1982861 Vali Loss: 0.1791447 Test Loss: 0.1982348\n",
      "Validation loss decreased (inf --> 0.179145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626676\n",
      "\tspeed: 0.1329s/iter; left time: 2269.5882s\n",
      "\titers: 200, epoch: 2 | loss: 0.1418535\n",
      "\tspeed: 0.0505s/iter; left time: 858.1362s\n",
      "\titers: 300, epoch: 2 | loss: 0.1512545\n",
      "\tspeed: 0.0499s/iter; left time: 842.1955s\n",
      "\titers: 400, epoch: 2 | loss: 0.1388979\n",
      "\tspeed: 0.0504s/iter; left time: 845.9797s\n",
      "\titers: 500, epoch: 2 | loss: 0.1387800\n",
      "\tspeed: 0.0505s/iter; left time: 842.1882s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259172\n",
      "\tspeed: 0.0506s/iter; left time: 838.1134s\n",
      "\titers: 700, epoch: 2 | loss: 0.1274560\n",
      "\tspeed: 0.0506s/iter; left time: 833.1670s\n",
      "\titers: 800, epoch: 2 | loss: 0.1289226\n",
      "\tspeed: 0.0503s/iter; left time: 823.2668s\n",
      "\titers: 900, epoch: 2 | loss: 0.1202111\n",
      "\tspeed: 0.0504s/iter; left time: 820.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.1396447 Vali Loss: 0.1410816 Test Loss: 0.1541430\n",
      "Validation loss decreased (0.179145 --> 0.141082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146321\n",
      "\tspeed: 0.1263s/iter; left time: 2041.8913s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086231\n",
      "\tspeed: 0.0510s/iter; left time: 819.1945s\n",
      "\titers: 300, epoch: 3 | loss: 0.1190881\n",
      "\tspeed: 0.0506s/iter; left time: 808.7020s\n",
      "\titers: 400, epoch: 3 | loss: 0.1126139\n",
      "\tspeed: 0.0508s/iter; left time: 806.6522s\n",
      "\titers: 500, epoch: 3 | loss: 0.1115104\n",
      "\tspeed: 0.0507s/iter; left time: 799.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1236731\n",
      "\tspeed: 0.0508s/iter; left time: 796.1503s\n",
      "\titers: 700, epoch: 3 | loss: 0.1179141\n",
      "\tspeed: 0.0507s/iter; left time: 788.9702s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989130\n",
      "\tspeed: 0.0505s/iter; left time: 781.9919s\n",
      "\titers: 900, epoch: 3 | loss: 0.1097365\n",
      "\tspeed: 0.0507s/iter; left time: 779.0321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.1114375 Vali Loss: 0.1281263 Test Loss: 0.1431220\n",
      "Validation loss decreased (0.141082 --> 0.128126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1071102\n",
      "\tspeed: 0.1263s/iter; left time: 1928.5441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969764\n",
      "\tspeed: 0.0501s/iter; left time: 759.9733s\n",
      "\titers: 300, epoch: 4 | loss: 0.1046718\n",
      "\tspeed: 0.0497s/iter; left time: 748.8859s\n",
      "\titers: 400, epoch: 4 | loss: 0.0977541\n",
      "\tspeed: 0.0487s/iter; left time: 729.1974s\n",
      "\titers: 500, epoch: 4 | loss: 0.0945625\n",
      "\tspeed: 0.0481s/iter; left time: 715.8269s\n",
      "\titers: 600, epoch: 4 | loss: 0.0986999\n",
      "\tspeed: 0.0482s/iter; left time: 711.8072s\n",
      "\titers: 700, epoch: 4 | loss: 0.1048499\n",
      "\tspeed: 0.0464s/iter; left time: 680.4869s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994669\n",
      "\tspeed: 0.0460s/iter; left time: 669.8954s\n",
      "\titers: 900, epoch: 4 | loss: 0.0925757\n",
      "\tspeed: 0.0458s/iter; left time: 662.1553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.82s\n",
      "Steps: 904 | Train Loss: 0.1004518 Vali Loss: 0.1291285 Test Loss: 0.1425716\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874742\n",
      "\tspeed: 0.1234s/iter; left time: 1772.0865s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963328\n",
      "\tspeed: 0.0494s/iter; left time: 704.9113s\n",
      "\titers: 300, epoch: 5 | loss: 0.1027813\n",
      "\tspeed: 0.0481s/iter; left time: 681.6077s\n",
      "\titers: 400, epoch: 5 | loss: 0.0895675\n",
      "\tspeed: 0.0478s/iter; left time: 672.6313s\n",
      "\titers: 500, epoch: 5 | loss: 0.0993130\n",
      "\tspeed: 0.0483s/iter; left time: 674.5254s\n",
      "\titers: 600, epoch: 5 | loss: 0.0953645\n",
      "\tspeed: 0.0483s/iter; left time: 669.3154s\n",
      "\titers: 700, epoch: 5 | loss: 0.0892349\n",
      "\tspeed: 0.0480s/iter; left time: 661.2226s\n",
      "\titers: 800, epoch: 5 | loss: 0.0873532\n",
      "\tspeed: 0.0473s/iter; left time: 646.7451s\n",
      "\titers: 900, epoch: 5 | loss: 0.0934440\n",
      "\tspeed: 0.0476s/iter; left time: 645.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.86s\n",
      "Steps: 904 | Train Loss: 0.0931581 Vali Loss: 0.1246601 Test Loss: 0.1443280\n",
      "Validation loss decreased (0.128126 --> 0.124660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961268\n",
      "\tspeed: 0.1241s/iter; left time: 1671.0917s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822272\n",
      "\tspeed: 0.0479s/iter; left time: 639.8865s\n",
      "\titers: 300, epoch: 6 | loss: 0.0832755\n",
      "\tspeed: 0.0491s/iter; left time: 650.9443s\n",
      "\titers: 400, epoch: 6 | loss: 0.0851639\n",
      "\tspeed: 0.0485s/iter; left time: 638.7219s\n",
      "\titers: 500, epoch: 6 | loss: 0.0906663\n",
      "\tspeed: 0.0492s/iter; left time: 642.2392s\n",
      "\titers: 600, epoch: 6 | loss: 0.0864622\n",
      "\tspeed: 0.0490s/iter; left time: 634.4529s\n",
      "\titers: 700, epoch: 6 | loss: 0.0848670\n",
      "\tspeed: 0.0479s/iter; left time: 616.3213s\n",
      "\titers: 800, epoch: 6 | loss: 0.0853517\n",
      "\tspeed: 0.0480s/iter; left time: 612.5557s\n",
      "\titers: 900, epoch: 6 | loss: 0.0898180\n",
      "\tspeed: 0.0475s/iter; left time: 601.2113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.07s\n",
      "Steps: 904 | Train Loss: 0.0864279 Vali Loss: 0.1263104 Test Loss: 0.1436411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830620\n",
      "\tspeed: 0.1228s/iter; left time: 1541.9198s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811775\n",
      "\tspeed: 0.0493s/iter; left time: 614.3111s\n",
      "\titers: 300, epoch: 7 | loss: 0.0790765\n",
      "\tspeed: 0.0501s/iter; left time: 618.8201s\n",
      "\titers: 400, epoch: 7 | loss: 0.0794355\n",
      "\tspeed: 0.0474s/iter; left time: 580.4377s\n",
      "\titers: 500, epoch: 7 | loss: 0.0733461\n",
      "\tspeed: 0.0462s/iter; left time: 562.0339s\n",
      "\titers: 600, epoch: 7 | loss: 0.0799207\n",
      "\tspeed: 0.0473s/iter; left time: 570.7959s\n",
      "\titers: 700, epoch: 7 | loss: 0.0805053\n",
      "\tspeed: 0.0473s/iter; left time: 565.9712s\n",
      "\titers: 800, epoch: 7 | loss: 0.0797424\n",
      "\tspeed: 0.0495s/iter; left time: 586.3928s\n",
      "\titers: 900, epoch: 7 | loss: 0.0868520\n",
      "\tspeed: 0.0490s/iter; left time: 575.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.99s\n",
      "Steps: 904 | Train Loss: 0.0807042 Vali Loss: 0.1286382 Test Loss: 0.1478058\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758880\n",
      "\tspeed: 0.1225s/iter; left time: 1427.6468s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756853\n",
      "\tspeed: 0.0491s/iter; left time: 567.2607s\n",
      "\titers: 300, epoch: 8 | loss: 0.0763412\n",
      "\tspeed: 0.0491s/iter; left time: 562.6049s\n",
      "\titers: 400, epoch: 8 | loss: 0.0878913\n",
      "\tspeed: 0.0484s/iter; left time: 549.1304s\n",
      "\titers: 500, epoch: 8 | loss: 0.0778655\n",
      "\tspeed: 0.0464s/iter; left time: 522.5519s\n",
      "\titers: 600, epoch: 8 | loss: 0.0781955\n",
      "\tspeed: 0.0477s/iter; left time: 531.6148s\n",
      "\titers: 700, epoch: 8 | loss: 0.0686648\n",
      "\tspeed: 0.0472s/iter; left time: 521.6567s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766425\n",
      "\tspeed: 0.0485s/iter; left time: 531.7621s\n",
      "\titers: 900, epoch: 8 | loss: 0.0713768\n",
      "\tspeed: 0.0489s/iter; left time: 530.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.91s\n",
      "Steps: 904 | Train Loss: 0.0758714 Vali Loss: 0.1294556 Test Loss: 0.1475389\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722367\n",
      "\tspeed: 0.1229s/iter; left time: 1320.8477s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719918\n",
      "\tspeed: 0.0495s/iter; left time: 526.7517s\n",
      "\titers: 300, epoch: 9 | loss: 0.0682079\n",
      "\tspeed: 0.0496s/iter; left time: 523.0136s\n",
      "\titers: 400, epoch: 9 | loss: 0.0657540\n",
      "\tspeed: 0.0478s/iter; left time: 499.3316s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733435\n",
      "\tspeed: 0.0439s/iter; left time: 454.2869s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733633\n",
      "\tspeed: 0.0392s/iter; left time: 401.9972s\n",
      "\titers: 700, epoch: 9 | loss: 0.0705372\n",
      "\tspeed: 0.0392s/iter; left time: 397.7362s\n",
      "\titers: 800, epoch: 9 | loss: 0.0677424\n",
      "\tspeed: 0.0406s/iter; left time: 407.6280s\n",
      "\titers: 900, epoch: 9 | loss: 0.0660145\n",
      "\tspeed: 0.0490s/iter; left time: 487.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.16s\n",
      "Steps: 904 | Train Loss: 0.0715858 Vali Loss: 0.1315246 Test Loss: 0.1502602\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692005\n",
      "\tspeed: 0.1231s/iter; left time: 1211.8496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0691886\n",
      "\tspeed: 0.0497s/iter; left time: 484.6451s\n",
      "\titers: 300, epoch: 10 | loss: 0.0687930\n",
      "\tspeed: 0.0496s/iter; left time: 478.5733s\n",
      "\titers: 400, epoch: 10 | loss: 0.0692857\n",
      "\tspeed: 0.0496s/iter; left time: 473.8368s\n",
      "\titers: 500, epoch: 10 | loss: 0.0661787\n",
      "\tspeed: 0.0481s/iter; left time: 453.9018s\n",
      "\titers: 600, epoch: 10 | loss: 0.0713165\n",
      "\tspeed: 0.0485s/iter; left time: 452.8791s\n",
      "\titers: 700, epoch: 10 | loss: 0.0668727\n",
      "\tspeed: 0.0492s/iter; left time: 455.2827s\n",
      "\titers: 800, epoch: 10 | loss: 0.0665657\n",
      "\tspeed: 0.0499s/iter; left time: 456.4630s\n",
      "\titers: 900, epoch: 10 | loss: 0.0688492\n",
      "\tspeed: 0.0500s/iter; left time: 452.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.92s\n",
      "Steps: 904 | Train Loss: 0.0680333 Vali Loss: 0.1297180 Test Loss: 0.1483256\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04413595050573349, rmse:0.21008558571338654, mae:0.14426378905773163, rse:0.7439554929733276\n",
      "Intermediate time for DE and pred_len 96: 00h:15m:54.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2143676\n",
      "\tspeed: 0.0820s/iter; left time: 1471.3804s\n",
      "\titers: 200, epoch: 1 | loss: 0.2117515\n",
      "\tspeed: 0.0541s/iter; left time: 964.8795s\n",
      "\titers: 300, epoch: 1 | loss: 0.1927727\n",
      "\tspeed: 0.0542s/iter; left time: 961.0873s\n",
      "\titers: 400, epoch: 1 | loss: 0.1908412\n",
      "\tspeed: 0.0522s/iter; left time: 921.2835s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840956\n",
      "\tspeed: 0.0499s/iter; left time: 874.5126s\n",
      "\titers: 600, epoch: 1 | loss: 0.1887111\n",
      "\tspeed: 0.0512s/iter; left time: 892.9617s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783495\n",
      "\tspeed: 0.0503s/iter; left time: 873.0014s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741387\n",
      "\tspeed: 0.0520s/iter; left time: 896.5666s\n",
      "\titers: 900, epoch: 1 | loss: 0.1796458\n",
      "\tspeed: 0.0537s/iter; left time: 919.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.96s\n",
      "Steps: 902 | Train Loss: 0.1965990 Vali Loss: 0.1828116 Test Loss: 0.2071697\n",
      "Validation loss decreased (inf --> 0.182812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720107\n",
      "\tspeed: 0.1447s/iter; left time: 2465.7182s\n",
      "\titers: 200, epoch: 2 | loss: 0.1494585\n",
      "\tspeed: 0.0511s/iter; left time: 865.5099s\n",
      "\titers: 300, epoch: 2 | loss: 0.1520132\n",
      "\tspeed: 0.0537s/iter; left time: 903.8573s\n",
      "\titers: 400, epoch: 2 | loss: 0.1517190\n",
      "\tspeed: 0.0529s/iter; left time: 885.2461s\n",
      "\titers: 500, epoch: 2 | loss: 0.1381914\n",
      "\tspeed: 0.0521s/iter; left time: 867.5654s\n",
      "\titers: 600, epoch: 2 | loss: 0.1325774\n",
      "\tspeed: 0.0521s/iter; left time: 862.1610s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320532\n",
      "\tspeed: 0.0505s/iter; left time: 830.5142s\n",
      "\titers: 800, epoch: 2 | loss: 0.1355543\n",
      "\tspeed: 0.0538s/iter; left time: 879.6082s\n",
      "\titers: 900, epoch: 2 | loss: 0.1268250\n",
      "\tspeed: 0.0512s/iter; left time: 831.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.1479768 Vali Loss: 0.1571483 Test Loss: 0.1725036\n",
      "Validation loss decreased (0.182812 --> 0.157148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1298213\n",
      "\tspeed: 0.1461s/iter; left time: 2357.3305s\n",
      "\titers: 200, epoch: 3 | loss: 0.1270678\n",
      "\tspeed: 0.0546s/iter; left time: 875.0936s\n",
      "\titers: 300, epoch: 3 | loss: 0.1299838\n",
      "\tspeed: 0.0535s/iter; left time: 853.0007s\n",
      "\titers: 400, epoch: 3 | loss: 0.1339503\n",
      "\tspeed: 0.0493s/iter; left time: 781.4377s\n",
      "\titers: 500, epoch: 3 | loss: 0.1283429\n",
      "\tspeed: 0.0510s/iter; left time: 802.0874s\n",
      "\titers: 600, epoch: 3 | loss: 0.1257501\n",
      "\tspeed: 0.0504s/iter; left time: 788.4874s\n",
      "\titers: 700, epoch: 3 | loss: 0.1190765\n",
      "\tspeed: 0.0520s/iter; left time: 807.5495s\n",
      "\titers: 800, epoch: 3 | loss: 0.1205630\n",
      "\tspeed: 0.0524s/iter; left time: 809.0160s\n",
      "\titers: 900, epoch: 3 | loss: 0.1183924\n",
      "\tspeed: 0.0528s/iter; left time: 810.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.26s\n",
      "Steps: 902 | Train Loss: 0.1263652 Vali Loss: 0.1494838 Test Loss: 0.1698276\n",
      "Validation loss decreased (0.157148 --> 0.149484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1155508\n",
      "\tspeed: 0.1451s/iter; left time: 2210.5872s\n",
      "\titers: 200, epoch: 4 | loss: 0.1041115\n",
      "\tspeed: 0.0531s/iter; left time: 803.5858s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034060\n",
      "\tspeed: 0.0517s/iter; left time: 776.7251s\n",
      "\titers: 400, epoch: 4 | loss: 0.1053993\n",
      "\tspeed: 0.0525s/iter; left time: 784.4898s\n",
      "\titers: 500, epoch: 4 | loss: 0.1018088\n",
      "\tspeed: 0.0540s/iter; left time: 800.4178s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077380\n",
      "\tspeed: 0.0512s/iter; left time: 754.3121s\n",
      "\titers: 700, epoch: 4 | loss: 0.1009760\n",
      "\tspeed: 0.0532s/iter; left time: 778.8151s\n",
      "\titers: 800, epoch: 4 | loss: 0.1029728\n",
      "\tspeed: 0.0534s/iter; left time: 776.1374s\n",
      "\titers: 900, epoch: 4 | loss: 0.0969269\n",
      "\tspeed: 0.0532s/iter; left time: 767.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.1071249 Vali Loss: 0.1498666 Test Loss: 0.1581961\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0921835\n",
      "\tspeed: 0.1430s/iter; left time: 2049.5515s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946247\n",
      "\tspeed: 0.0525s/iter; left time: 746.5413s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958237\n",
      "\tspeed: 0.0517s/iter; left time: 730.5790s\n",
      "\titers: 400, epoch: 5 | loss: 0.1009195\n",
      "\tspeed: 0.0515s/iter; left time: 723.2145s\n",
      "\titers: 500, epoch: 5 | loss: 0.0915284\n",
      "\tspeed: 0.0509s/iter; left time: 709.7851s\n",
      "\titers: 600, epoch: 5 | loss: 0.0905648\n",
      "\tspeed: 0.0539s/iter; left time: 745.2481s\n",
      "\titers: 700, epoch: 5 | loss: 0.0927724\n",
      "\tspeed: 0.0517s/iter; left time: 709.6732s\n",
      "\titers: 800, epoch: 5 | loss: 0.1016190\n",
      "\tspeed: 0.0519s/iter; left time: 707.5892s\n",
      "\titers: 900, epoch: 5 | loss: 0.0944772\n",
      "\tspeed: 0.0510s/iter; left time: 689.8998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 902 | Train Loss: 0.0974058 Vali Loss: 0.1408406 Test Loss: 0.1551649\n",
      "Validation loss decreased (0.149484 --> 0.140841).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932021\n",
      "\tspeed: 0.1444s/iter; left time: 1939.6463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926236\n",
      "\tspeed: 0.0513s/iter; left time: 683.9999s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907288\n",
      "\tspeed: 0.0514s/iter; left time: 679.4473s\n",
      "\titers: 400, epoch: 6 | loss: 0.0978973\n",
      "\tspeed: 0.0515s/iter; left time: 676.2422s\n",
      "\titers: 500, epoch: 6 | loss: 0.0956134\n",
      "\tspeed: 0.0520s/iter; left time: 677.8161s\n",
      "\titers: 600, epoch: 6 | loss: 0.0908729\n",
      "\tspeed: 0.0534s/iter; left time: 690.1336s\n",
      "\titers: 700, epoch: 6 | loss: 0.0814253\n",
      "\tspeed: 0.0546s/iter; left time: 700.4772s\n",
      "\titers: 800, epoch: 6 | loss: 0.0882680\n",
      "\tspeed: 0.0523s/iter; left time: 665.8617s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903395\n",
      "\tspeed: 0.0508s/iter; left time: 641.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.31s\n",
      "Steps: 902 | Train Loss: 0.0906075 Vali Loss: 0.1435234 Test Loss: 0.1569311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823340\n",
      "\tspeed: 0.1391s/iter; left time: 1742.3315s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836407\n",
      "\tspeed: 0.0529s/iter; left time: 657.3346s\n",
      "\titers: 300, epoch: 7 | loss: 0.0852123\n",
      "\tspeed: 0.0507s/iter; left time: 624.9028s\n",
      "\titers: 400, epoch: 7 | loss: 0.0818945\n",
      "\tspeed: 0.0509s/iter; left time: 623.0208s\n",
      "\titers: 500, epoch: 7 | loss: 0.0864603\n",
      "\tspeed: 0.0505s/iter; left time: 612.8087s\n",
      "\titers: 600, epoch: 7 | loss: 0.0815249\n",
      "\tspeed: 0.0514s/iter; left time: 618.5077s\n",
      "\titers: 700, epoch: 7 | loss: 0.0842814\n",
      "\tspeed: 0.0520s/iter; left time: 620.0365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859686\n",
      "\tspeed: 0.0533s/iter; left time: 630.4007s\n",
      "\titers: 900, epoch: 7 | loss: 0.0876295\n",
      "\tspeed: 0.0501s/iter; left time: 587.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 902 | Train Loss: 0.0842573 Vali Loss: 0.1383368 Test Loss: 0.1558025\n",
      "Validation loss decreased (0.140841 --> 0.138337).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780885\n",
      "\tspeed: 0.1414s/iter; left time: 1643.8187s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838111\n",
      "\tspeed: 0.0547s/iter; left time: 630.7864s\n",
      "\titers: 300, epoch: 8 | loss: 0.0805265\n",
      "\tspeed: 0.0525s/iter; left time: 599.7626s\n",
      "\titers: 400, epoch: 8 | loss: 0.0790132\n",
      "\tspeed: 0.0541s/iter; left time: 612.3716s\n",
      "\titers: 500, epoch: 8 | loss: 0.0785694\n",
      "\tspeed: 0.0533s/iter; left time: 598.6110s\n",
      "\titers: 600, epoch: 8 | loss: 0.0750216\n",
      "\tspeed: 0.0512s/iter; left time: 570.0028s\n",
      "\titers: 700, epoch: 8 | loss: 0.0776697\n",
      "\tspeed: 0.0533s/iter; left time: 587.8262s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769325\n",
      "\tspeed: 0.0520s/iter; left time: 568.6005s\n",
      "\titers: 900, epoch: 8 | loss: 0.0747403\n",
      "\tspeed: 0.0522s/iter; left time: 565.2420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 902 | Train Loss: 0.0794519 Vali Loss: 0.1417993 Test Loss: 0.1582901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711918\n",
      "\tspeed: 0.1426s/iter; left time: 1529.4387s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793033\n",
      "\tspeed: 0.0523s/iter; left time: 556.2177s\n",
      "\titers: 300, epoch: 9 | loss: 0.0817263\n",
      "\tspeed: 0.0510s/iter; left time: 536.9984s\n",
      "\titers: 400, epoch: 9 | loss: 0.0761158\n",
      "\tspeed: 0.0503s/iter; left time: 524.3522s\n",
      "\titers: 500, epoch: 9 | loss: 0.0807231\n",
      "\tspeed: 0.0513s/iter; left time: 529.6941s\n",
      "\titers: 600, epoch: 9 | loss: 0.0731832\n",
      "\tspeed: 0.0530s/iter; left time: 541.7852s\n",
      "\titers: 700, epoch: 9 | loss: 0.0774617\n",
      "\tspeed: 0.0534s/iter; left time: 540.2211s\n",
      "\titers: 800, epoch: 9 | loss: 0.0772811\n",
      "\tspeed: 0.0507s/iter; left time: 508.4414s\n",
      "\titers: 900, epoch: 9 | loss: 0.0736872\n",
      "\tspeed: 0.0511s/iter; left time: 506.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.90s\n",
      "Steps: 902 | Train Loss: 0.0751518 Vali Loss: 0.1422561 Test Loss: 0.1584524\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0668368\n",
      "\tspeed: 0.1405s/iter; left time: 1380.2370s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728021\n",
      "\tspeed: 0.0537s/iter; left time: 522.3645s\n",
      "\titers: 300, epoch: 10 | loss: 0.0750305\n",
      "\tspeed: 0.0516s/iter; left time: 496.2423s\n",
      "\titers: 400, epoch: 10 | loss: 0.0713177\n",
      "\tspeed: 0.0503s/iter; left time: 478.9749s\n",
      "\titers: 500, epoch: 10 | loss: 0.0725282\n",
      "\tspeed: 0.0509s/iter; left time: 479.8414s\n",
      "\titers: 600, epoch: 10 | loss: 0.0728812\n",
      "\tspeed: 0.0520s/iter; left time: 484.8407s\n",
      "\titers: 700, epoch: 10 | loss: 0.0732005\n",
      "\tspeed: 0.0547s/iter; left time: 504.3343s\n",
      "\titers: 800, epoch: 10 | loss: 0.0709999\n",
      "\tspeed: 0.0508s/iter; left time: 463.7888s\n",
      "\titers: 900, epoch: 10 | loss: 0.0734219\n",
      "\tspeed: 0.0518s/iter; left time: 467.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 902 | Train Loss: 0.0715689 Vali Loss: 0.1426778 Test Loss: 0.1605491\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0681446\n",
      "\tspeed: 0.1401s/iter; left time: 1250.2348s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697667\n",
      "\tspeed: 0.0539s/iter; left time: 475.1983s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655064\n",
      "\tspeed: 0.0543s/iter; left time: 473.5026s\n",
      "\titers: 400, epoch: 11 | loss: 0.0666977\n",
      "\tspeed: 0.0539s/iter; left time: 464.6365s\n",
      "\titers: 500, epoch: 11 | loss: 0.0786548\n",
      "\tspeed: 0.0513s/iter; left time: 437.2385s\n",
      "\titers: 600, epoch: 11 | loss: 0.0678788\n",
      "\tspeed: 0.0533s/iter; left time: 448.4274s\n",
      "\titers: 700, epoch: 11 | loss: 0.0705262\n",
      "\tspeed: 0.0522s/iter; left time: 434.7655s\n",
      "\titers: 800, epoch: 11 | loss: 0.0674626\n",
      "\tspeed: 0.0519s/iter; left time: 426.9802s\n",
      "\titers: 900, epoch: 11 | loss: 0.0651507\n",
      "\tspeed: 0.0507s/iter; left time: 411.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0687391 Vali Loss: 0.1402910 Test Loss: 0.1587802\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0653112\n",
      "\tspeed: 0.1421s/iter; left time: 1139.5528s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699357\n",
      "\tspeed: 0.0524s/iter; left time: 415.3268s\n",
      "\titers: 300, epoch: 12 | loss: 0.0649073\n",
      "\tspeed: 0.0514s/iter; left time: 402.1268s\n",
      "\titers: 400, epoch: 12 | loss: 0.0659068\n",
      "\tspeed: 0.0516s/iter; left time: 398.6303s\n",
      "\titers: 500, epoch: 12 | loss: 0.0660025\n",
      "\tspeed: 0.0516s/iter; left time: 393.3168s\n",
      "\titers: 600, epoch: 12 | loss: 0.0685619\n",
      "\tspeed: 0.0531s/iter; left time: 399.5968s\n",
      "\titers: 700, epoch: 12 | loss: 0.0702067\n",
      "\tspeed: 0.0517s/iter; left time: 383.4869s\n",
      "\titers: 800, epoch: 12 | loss: 0.0664895\n",
      "\tspeed: 0.0525s/iter; left time: 384.2946s\n",
      "\titers: 900, epoch: 12 | loss: 0.0690533\n",
      "\tspeed: 0.0515s/iter; left time: 371.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.0663095 Vali Loss: 0.1424346 Test Loss: 0.1606143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.053022854030132294, rmse:0.23026691377162933, mae:0.15602098405361176, rse:0.8157663345336914\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2201324\n",
      "\tspeed: 0.0549s/iter; left time: 985.7384s\n",
      "\titers: 200, epoch: 1 | loss: 0.2001715\n",
      "\tspeed: 0.0508s/iter; left time: 907.0274s\n",
      "\titers: 300, epoch: 1 | loss: 0.1991532\n",
      "\tspeed: 0.0512s/iter; left time: 907.5192s\n",
      "\titers: 400, epoch: 1 | loss: 0.1883941\n",
      "\tspeed: 0.0532s/iter; left time: 937.7628s\n",
      "\titers: 500, epoch: 1 | loss: 0.1873800\n",
      "\tspeed: 0.0524s/iter; left time: 918.5607s\n",
      "\titers: 600, epoch: 1 | loss: 0.1834275\n",
      "\tspeed: 0.0520s/iter; left time: 906.7906s\n",
      "\titers: 700, epoch: 1 | loss: 0.1915931\n",
      "\tspeed: 0.0527s/iter; left time: 913.7041s\n",
      "\titers: 800, epoch: 1 | loss: 0.1855758\n",
      "\tspeed: 0.0512s/iter; left time: 883.2315s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799206\n",
      "\tspeed: 0.0530s/iter; left time: 909.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.32s\n",
      "Steps: 902 | Train Loss: 0.1969401 Vali Loss: 0.1832115 Test Loss: 0.2068883\n",
      "Validation loss decreased (inf --> 0.183212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1596465\n",
      "\tspeed: 0.1500s/iter; left time: 2555.6245s\n",
      "\titers: 200, epoch: 2 | loss: 0.1578218\n",
      "\tspeed: 0.0529s/iter; left time: 895.9734s\n",
      "\titers: 300, epoch: 2 | loss: 0.1497701\n",
      "\tspeed: 0.0527s/iter; left time: 886.7183s\n",
      "\titers: 400, epoch: 2 | loss: 0.1531094\n",
      "\tspeed: 0.0537s/iter; left time: 899.0457s\n",
      "\titers: 500, epoch: 2 | loss: 0.1408316\n",
      "\tspeed: 0.0526s/iter; left time: 874.7931s\n",
      "\titers: 600, epoch: 2 | loss: 0.1419959\n",
      "\tspeed: 0.0514s/iter; left time: 849.4059s\n",
      "\titers: 700, epoch: 2 | loss: 0.1315546\n",
      "\tspeed: 0.0525s/iter; left time: 863.3601s\n",
      "\titers: 800, epoch: 2 | loss: 0.1384183\n",
      "\tspeed: 0.0521s/iter; left time: 850.4561s\n",
      "\titers: 900, epoch: 2 | loss: 0.1377827\n",
      "\tspeed: 0.0547s/iter; left time: 888.2332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.02s\n",
      "Steps: 902 | Train Loss: 0.1480785 Vali Loss: 0.1684496 Test Loss: 0.1873153\n",
      "Validation loss decreased (0.183212 --> 0.168450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1325896\n",
      "\tspeed: 0.1599s/iter; left time: 2580.1987s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413253\n",
      "\tspeed: 0.0502s/iter; left time: 805.2850s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303057\n",
      "\tspeed: 0.0536s/iter; left time: 853.9547s\n",
      "\titers: 400, epoch: 3 | loss: 0.1383175\n",
      "\tspeed: 0.0536s/iter; left time: 849.2935s\n",
      "\titers: 500, epoch: 3 | loss: 0.1243712\n",
      "\tspeed: 0.0523s/iter; left time: 822.8319s\n",
      "\titers: 600, epoch: 3 | loss: 0.1304547\n",
      "\tspeed: 0.0506s/iter; left time: 791.8153s\n",
      "\titers: 700, epoch: 3 | loss: 0.1181477\n",
      "\tspeed: 0.0524s/iter; left time: 814.8231s\n",
      "\titers: 800, epoch: 3 | loss: 0.1223750\n",
      "\tspeed: 0.0523s/iter; left time: 806.8879s\n",
      "\titers: 900, epoch: 3 | loss: 0.1114032\n",
      "\tspeed: 0.0535s/iter; left time: 821.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.48s\n",
      "Steps: 902 | Train Loss: 0.1275883 Vali Loss: 0.1371416 Test Loss: 0.1529757\n",
      "Validation loss decreased (0.168450 --> 0.137142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1154191\n",
      "\tspeed: 0.1555s/iter; left time: 2368.4512s\n",
      "\titers: 200, epoch: 4 | loss: 0.1040316\n",
      "\tspeed: 0.0543s/iter; left time: 822.3829s\n",
      "\titers: 300, epoch: 4 | loss: 0.0999732\n",
      "\tspeed: 0.0532s/iter; left time: 799.2403s\n",
      "\titers: 400, epoch: 4 | loss: 0.1075287\n",
      "\tspeed: 0.0527s/iter; left time: 787.3995s\n",
      "\titers: 500, epoch: 4 | loss: 0.1019707\n",
      "\tspeed: 0.0531s/iter; left time: 788.0533s\n",
      "\titers: 600, epoch: 4 | loss: 0.0993232\n",
      "\tspeed: 0.0512s/iter; left time: 753.8756s\n",
      "\titers: 700, epoch: 4 | loss: 0.1015184\n",
      "\tspeed: 0.0521s/iter; left time: 762.3818s\n",
      "\titers: 800, epoch: 4 | loss: 0.1015958\n",
      "\tspeed: 0.0543s/iter; left time: 789.3634s\n",
      "\titers: 900, epoch: 4 | loss: 0.1020327\n",
      "\tspeed: 0.0534s/iter; left time: 770.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.07s\n",
      "Steps: 902 | Train Loss: 0.1058670 Vali Loss: 0.1376515 Test Loss: 0.1540516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1028747\n",
      "\tspeed: 0.1407s/iter; left time: 2016.4449s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934217\n",
      "\tspeed: 0.0523s/iter; left time: 744.2220s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986301\n",
      "\tspeed: 0.0548s/iter; left time: 774.7619s\n",
      "\titers: 400, epoch: 5 | loss: 0.0986802\n",
      "\tspeed: 0.0525s/iter; left time: 737.0377s\n",
      "\titers: 500, epoch: 5 | loss: 0.0942053\n",
      "\tspeed: 0.0510s/iter; left time: 710.3399s\n",
      "\titers: 600, epoch: 5 | loss: 0.1024459\n",
      "\tspeed: 0.0522s/iter; left time: 722.4331s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918240\n",
      "\tspeed: 0.0500s/iter; left time: 687.0377s\n",
      "\titers: 800, epoch: 5 | loss: 0.0978398\n",
      "\tspeed: 0.0525s/iter; left time: 716.1805s\n",
      "\titers: 900, epoch: 5 | loss: 0.1018387\n",
      "\tspeed: 0.0531s/iter; left time: 718.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.0971580 Vali Loss: 0.1384684 Test Loss: 0.1528751\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0907427\n",
      "\tspeed: 0.1408s/iter; left time: 1891.0171s\n",
      "\titers: 200, epoch: 6 | loss: 0.1008368\n",
      "\tspeed: 0.0523s/iter; left time: 696.6930s\n",
      "\titers: 300, epoch: 6 | loss: 0.0912324\n",
      "\tspeed: 0.0538s/iter; left time: 712.1977s\n",
      "\titers: 400, epoch: 6 | loss: 0.0817516\n",
      "\tspeed: 0.0523s/iter; left time: 686.7482s\n",
      "\titers: 500, epoch: 6 | loss: 0.0888023\n",
      "\tspeed: 0.0527s/iter; left time: 686.2675s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920842\n",
      "\tspeed: 0.0534s/iter; left time: 689.9907s\n",
      "\titers: 700, epoch: 6 | loss: 0.0880135\n",
      "\tspeed: 0.0531s/iter; left time: 681.5950s\n",
      "\titers: 800, epoch: 6 | loss: 0.0896069\n",
      "\tspeed: 0.0533s/iter; left time: 678.5904s\n",
      "\titers: 900, epoch: 6 | loss: 0.0879484\n",
      "\tspeed: 0.0526s/iter; left time: 664.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.86s\n",
      "Steps: 902 | Train Loss: 0.0902217 Vali Loss: 0.1371762 Test Loss: 0.1525187\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811038\n",
      "\tspeed: 0.1415s/iter; left time: 1773.0703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820944\n",
      "\tspeed: 0.0543s/iter; left time: 674.6802s\n",
      "\titers: 300, epoch: 7 | loss: 0.0783249\n",
      "\tspeed: 0.0532s/iter; left time: 655.8493s\n",
      "\titers: 400, epoch: 7 | loss: 0.0892762\n",
      "\tspeed: 0.0524s/iter; left time: 640.3938s\n",
      "\titers: 500, epoch: 7 | loss: 0.0804740\n",
      "\tspeed: 0.0512s/iter; left time: 621.2167s\n",
      "\titers: 600, epoch: 7 | loss: 0.0863952\n",
      "\tspeed: 0.0507s/iter; left time: 609.4150s\n",
      "\titers: 700, epoch: 7 | loss: 0.0759322\n",
      "\tspeed: 0.0515s/iter; left time: 614.6421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0835908\n",
      "\tspeed: 0.0540s/iter; left time: 639.0590s\n",
      "\titers: 900, epoch: 7 | loss: 0.0783999\n",
      "\tspeed: 0.0515s/iter; left time: 603.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.0839978 Vali Loss: 0.1375310 Test Loss: 0.1532999\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0879491\n",
      "\tspeed: 0.1431s/iter; left time: 1663.8212s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793215\n",
      "\tspeed: 0.0533s/iter; left time: 614.3369s\n",
      "\titers: 300, epoch: 8 | loss: 0.0858402\n",
      "\tspeed: 0.0513s/iter; left time: 585.9446s\n",
      "\titers: 400, epoch: 8 | loss: 0.0771001\n",
      "\tspeed: 0.0505s/iter; left time: 572.1057s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798749\n",
      "\tspeed: 0.0512s/iter; left time: 574.7575s\n",
      "\titers: 600, epoch: 8 | loss: 0.0801735\n",
      "\tspeed: 0.0510s/iter; left time: 567.2209s\n",
      "\titers: 700, epoch: 8 | loss: 0.0771784\n",
      "\tspeed: 0.0541s/iter; left time: 596.3842s\n",
      "\titers: 800, epoch: 8 | loss: 0.0812665\n",
      "\tspeed: 0.0542s/iter; left time: 592.2885s\n",
      "\titers: 900, epoch: 8 | loss: 0.0811051\n",
      "\tspeed: 0.0526s/iter; left time: 569.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.37s\n",
      "Steps: 902 | Train Loss: 0.0789480 Vali Loss: 0.1395975 Test Loss: 0.1572920\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04767633229494095, rmse:0.21834909915924072, mae:0.15297505259513855, rse:0.7735451459884644\n",
      "Intermediate time for DE and pred_len 168: 00h:19m:10.24s\n",
      "Intermediate time for DE: 00h:58m:16.29s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2113341\n",
      "\tspeed: 0.0701s/iter; left time: 1262.4581s\n",
      "\titers: 200, epoch: 1 | loss: 0.1939111\n",
      "\tspeed: 0.0412s/iter; left time: 737.6089s\n",
      "\titers: 300, epoch: 1 | loss: 0.1798092\n",
      "\tspeed: 0.0415s/iter; left time: 740.1921s\n",
      "\titers: 400, epoch: 1 | loss: 0.1744348\n",
      "\tspeed: 0.0419s/iter; left time: 741.9444s\n",
      "\titers: 500, epoch: 1 | loss: 0.1593372\n",
      "\tspeed: 0.0389s/iter; left time: 685.9671s\n",
      "\titers: 600, epoch: 1 | loss: 0.1606529\n",
      "\tspeed: 0.0387s/iter; left time: 677.4012s\n",
      "\titers: 700, epoch: 1 | loss: 0.1555635\n",
      "\tspeed: 0.0333s/iter; left time: 579.9983s\n",
      "\titers: 800, epoch: 1 | loss: 0.1435576\n",
      "\tspeed: 0.0390s/iter; left time: 675.5177s\n",
      "\titers: 900, epoch: 1 | loss: 0.1427359\n",
      "\tspeed: 0.0426s/iter; left time: 733.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.1802784 Vali Loss: 0.1541678 Test Loss: 0.1811512\n",
      "Validation loss decreased (inf --> 0.154168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1370904\n",
      "\tspeed: 0.1038s/iter; left time: 1777.0264s\n",
      "\titers: 200, epoch: 2 | loss: 0.1191782\n",
      "\tspeed: 0.0405s/iter; left time: 688.9864s\n",
      "\titers: 300, epoch: 2 | loss: 0.1010349\n",
      "\tspeed: 0.0414s/iter; left time: 700.8579s\n",
      "\titers: 400, epoch: 2 | loss: 0.1107639\n",
      "\tspeed: 0.0402s/iter; left time: 675.4996s\n",
      "\titers: 500, epoch: 2 | loss: 0.1140048\n",
      "\tspeed: 0.0412s/iter; left time: 688.6519s\n",
      "\titers: 600, epoch: 2 | loss: 0.0916289\n",
      "\tspeed: 0.0416s/iter; left time: 690.5227s\n",
      "\titers: 700, epoch: 2 | loss: 0.1156958\n",
      "\tspeed: 0.0393s/iter; left time: 648.4811s\n",
      "\titers: 800, epoch: 2 | loss: 0.1135648\n",
      "\tspeed: 0.0391s/iter; left time: 641.3358s\n",
      "\titers: 900, epoch: 2 | loss: 0.1022947\n",
      "\tspeed: 0.0410s/iter; left time: 669.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.1129938 Vali Loss: 0.1188597 Test Loss: 0.1426858\n",
      "Validation loss decreased (0.154168 --> 0.118860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034873\n",
      "\tspeed: 0.1066s/iter; left time: 1728.4544s\n",
      "\titers: 200, epoch: 3 | loss: 0.1002087\n",
      "\tspeed: 0.0408s/iter; left time: 657.6068s\n",
      "\titers: 300, epoch: 3 | loss: 0.1054211\n",
      "\tspeed: 0.0413s/iter; left time: 660.8803s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004911\n",
      "\tspeed: 0.0403s/iter; left time: 640.7331s\n",
      "\titers: 500, epoch: 3 | loss: 0.1002003\n",
      "\tspeed: 0.0416s/iter; left time: 657.6786s\n",
      "\titers: 600, epoch: 3 | loss: 0.0996972\n",
      "\tspeed: 0.0428s/iter; left time: 671.5825s\n",
      "\titers: 700, epoch: 3 | loss: 0.0997507\n",
      "\tspeed: 0.0431s/iter; left time: 673.3459s\n",
      "\titers: 800, epoch: 3 | loss: 0.0918966\n",
      "\tspeed: 0.0423s/iter; left time: 655.8219s\n",
      "\titers: 900, epoch: 3 | loss: 0.1007679\n",
      "\tspeed: 0.0443s/iter; left time: 682.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.1001998 Vali Loss: 0.1145102 Test Loss: 0.1382046\n",
      "Validation loss decreased (0.118860 --> 0.114510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881878\n",
      "\tspeed: 0.1107s/iter; left time: 1693.5830s\n",
      "\titers: 200, epoch: 4 | loss: 0.1034280\n",
      "\tspeed: 0.0424s/iter; left time: 644.1938s\n",
      "\titers: 300, epoch: 4 | loss: 0.0962766\n",
      "\tspeed: 0.0427s/iter; left time: 644.8530s\n",
      "\titers: 400, epoch: 4 | loss: 0.1010057\n",
      "\tspeed: 0.0409s/iter; left time: 613.6448s\n",
      "\titers: 500, epoch: 4 | loss: 0.1161118\n",
      "\tspeed: 0.0428s/iter; left time: 638.1229s\n",
      "\titers: 600, epoch: 4 | loss: 0.1033959\n",
      "\tspeed: 0.0417s/iter; left time: 617.8816s\n",
      "\titers: 700, epoch: 4 | loss: 0.0912785\n",
      "\tspeed: 0.0405s/iter; left time: 595.4116s\n",
      "\titers: 800, epoch: 4 | loss: 0.0965739\n",
      "\tspeed: 0.0448s/iter; left time: 653.5074s\n",
      "\titers: 900, epoch: 4 | loss: 0.0967808\n",
      "\tspeed: 0.0425s/iter; left time: 616.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 906 | Train Loss: 0.0968959 Vali Loss: 0.1142993 Test Loss: 0.1342016\n",
      "Validation loss decreased (0.114510 --> 0.114299).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1075176\n",
      "\tspeed: 0.1107s/iter; left time: 1594.0732s\n",
      "\titers: 200, epoch: 5 | loss: 0.0871575\n",
      "\tspeed: 0.0442s/iter; left time: 631.5174s\n",
      "\titers: 300, epoch: 5 | loss: 0.0921738\n",
      "\tspeed: 0.0445s/iter; left time: 631.4813s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033385\n",
      "\tspeed: 0.0444s/iter; left time: 626.1897s\n",
      "\titers: 500, epoch: 5 | loss: 0.0857381\n",
      "\tspeed: 0.0444s/iter; left time: 621.2835s\n",
      "\titers: 600, epoch: 5 | loss: 0.0873333\n",
      "\tspeed: 0.0444s/iter; left time: 616.8172s\n",
      "\titers: 700, epoch: 5 | loss: 0.1015887\n",
      "\tspeed: 0.0444s/iter; left time: 612.7377s\n",
      "\titers: 800, epoch: 5 | loss: 0.1003189\n",
      "\tspeed: 0.0423s/iter; left time: 579.9755s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849322\n",
      "\tspeed: 0.0432s/iter; left time: 586.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.12s\n",
      "Steps: 906 | Train Loss: 0.0941614 Vali Loss: 0.1160385 Test Loss: 0.1400663\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0940297\n",
      "\tspeed: 0.1059s/iter; left time: 1429.1392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987860\n",
      "\tspeed: 0.0445s/iter; left time: 595.6223s\n",
      "\titers: 300, epoch: 6 | loss: 0.0889130\n",
      "\tspeed: 0.0446s/iter; left time: 592.4184s\n",
      "\titers: 400, epoch: 6 | loss: 0.0926011\n",
      "\tspeed: 0.0417s/iter; left time: 549.4123s\n",
      "\titers: 500, epoch: 6 | loss: 0.0948536\n",
      "\tspeed: 0.0440s/iter; left time: 575.4568s\n",
      "\titers: 600, epoch: 6 | loss: 0.0864705\n",
      "\tspeed: 0.0425s/iter; left time: 552.6601s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910312\n",
      "\tspeed: 0.0424s/iter; left time: 546.1583s\n",
      "\titers: 800, epoch: 6 | loss: 0.0813692\n",
      "\tspeed: 0.0414s/iter; left time: 529.6876s\n",
      "\titers: 900, epoch: 6 | loss: 0.0944316\n",
      "\tspeed: 0.0414s/iter; left time: 525.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.12s\n",
      "Steps: 906 | Train Loss: 0.0914372 Vali Loss: 0.1205823 Test Loss: 0.1484592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0804197\n",
      "\tspeed: 0.1045s/iter; left time: 1315.6964s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928350\n",
      "\tspeed: 0.0437s/iter; left time: 545.6758s\n",
      "\titers: 300, epoch: 7 | loss: 0.0895849\n",
      "\tspeed: 0.0419s/iter; left time: 518.6997s\n",
      "\titers: 400, epoch: 7 | loss: 0.0982223\n",
      "\tspeed: 0.0418s/iter; left time: 513.5580s\n",
      "\titers: 500, epoch: 7 | loss: 0.0866589\n",
      "\tspeed: 0.0423s/iter; left time: 515.3725s\n",
      "\titers: 600, epoch: 7 | loss: 0.0716318\n",
      "\tspeed: 0.0414s/iter; left time: 499.8829s\n",
      "\titers: 700, epoch: 7 | loss: 0.0926144\n",
      "\tspeed: 0.0419s/iter; left time: 501.9940s\n",
      "\titers: 800, epoch: 7 | loss: 0.0887576\n",
      "\tspeed: 0.0408s/iter; left time: 484.6865s\n",
      "\titers: 900, epoch: 7 | loss: 0.0910463\n",
      "\tspeed: 0.0414s/iter; left time: 487.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 906 | Train Loss: 0.0883436 Vali Loss: 0.1165588 Test Loss: 0.1441727\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863066\n",
      "\tspeed: 0.1025s/iter; left time: 1196.8469s\n",
      "\titers: 200, epoch: 8 | loss: 0.0772502\n",
      "\tspeed: 0.0410s/iter; left time: 474.2303s\n",
      "\titers: 300, epoch: 8 | loss: 0.0882930\n",
      "\tspeed: 0.0394s/iter; left time: 452.6075s\n",
      "\titers: 400, epoch: 8 | loss: 0.0815420\n",
      "\tspeed: 0.0423s/iter; left time: 480.8114s\n",
      "\titers: 500, epoch: 8 | loss: 0.0907906\n",
      "\tspeed: 0.0427s/iter; left time: 481.6264s\n",
      "\titers: 600, epoch: 8 | loss: 0.0891234\n",
      "\tspeed: 0.0442s/iter; left time: 493.6791s\n",
      "\titers: 700, epoch: 8 | loss: 0.0826091\n",
      "\tspeed: 0.0396s/iter; left time: 439.1934s\n",
      "\titers: 800, epoch: 8 | loss: 0.0899871\n",
      "\tspeed: 0.0416s/iter; left time: 457.0302s\n",
      "\titers: 900, epoch: 8 | loss: 0.0860059\n",
      "\tspeed: 0.0405s/iter; left time: 440.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.0858847 Vali Loss: 0.1204836 Test Loss: 0.1483876\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0906029\n",
      "\tspeed: 0.1031s/iter; left time: 1110.9823s\n",
      "\titers: 200, epoch: 9 | loss: 0.0865637\n",
      "\tspeed: 0.0429s/iter; left time: 457.6632s\n",
      "\titers: 300, epoch: 9 | loss: 0.0798166\n",
      "\tspeed: 0.0431s/iter; left time: 456.1773s\n",
      "\titers: 400, epoch: 9 | loss: 0.0883184\n",
      "\tspeed: 0.0441s/iter; left time: 461.4484s\n",
      "\titers: 500, epoch: 9 | loss: 0.0839940\n",
      "\tspeed: 0.0414s/iter; left time: 429.4434s\n",
      "\titers: 600, epoch: 9 | loss: 0.0735761\n",
      "\tspeed: 0.0405s/iter; left time: 415.7908s\n",
      "\titers: 700, epoch: 9 | loss: 0.0817910\n",
      "\tspeed: 0.0436s/iter; left time: 444.0454s\n",
      "\titers: 800, epoch: 9 | loss: 0.0895841\n",
      "\tspeed: 0.0445s/iter; left time: 447.8942s\n",
      "\titers: 900, epoch: 9 | loss: 0.0737404\n",
      "\tspeed: 0.0442s/iter; left time: 440.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.02s\n",
      "Steps: 906 | Train Loss: 0.0833755 Vali Loss: 0.1193913 Test Loss: 0.1506973\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.044055793434381485, rmse:0.20989471673965454, mae:0.13415901362895966, rse:0.7237120866775513\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2428235\n",
      "\tspeed: 0.0445s/iter; left time: 801.2211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2057789\n",
      "\tspeed: 0.0447s/iter; left time: 801.8210s\n",
      "\titers: 300, epoch: 1 | loss: 0.1798792\n",
      "\tspeed: 0.0430s/iter; left time: 766.3847s\n",
      "\titers: 400, epoch: 1 | loss: 0.1719038\n",
      "\tspeed: 0.0432s/iter; left time: 766.0828s\n",
      "\titers: 500, epoch: 1 | loss: 0.1708177\n",
      "\tspeed: 0.0423s/iter; left time: 745.8599s\n",
      "\titers: 600, epoch: 1 | loss: 0.1570417\n",
      "\tspeed: 0.0402s/iter; left time: 703.6126s\n",
      "\titers: 700, epoch: 1 | loss: 0.1589757\n",
      "\tspeed: 0.0405s/iter; left time: 705.9459s\n",
      "\titers: 800, epoch: 1 | loss: 0.1546320\n",
      "\tspeed: 0.0409s/iter; left time: 708.4729s\n",
      "\titers: 900, epoch: 1 | loss: 0.1549362\n",
      "\tspeed: 0.0431s/iter; left time: 742.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 906 | Train Loss: 0.1875353 Vali Loss: 0.1492720 Test Loss: 0.1801390\n",
      "Validation loss decreased (inf --> 0.149272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348393\n",
      "\tspeed: 0.1091s/iter; left time: 1868.0824s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083008\n",
      "\tspeed: 0.0420s/iter; left time: 714.3792s\n",
      "\titers: 300, epoch: 2 | loss: 0.1321781\n",
      "\tspeed: 0.0441s/iter; left time: 745.2249s\n",
      "\titers: 400, epoch: 2 | loss: 0.1061094\n",
      "\tspeed: 0.0429s/iter; left time: 721.9750s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231315\n",
      "\tspeed: 0.0441s/iter; left time: 737.6438s\n",
      "\titers: 600, epoch: 2 | loss: 0.1052596\n",
      "\tspeed: 0.0407s/iter; left time: 676.1413s\n",
      "\titers: 700, epoch: 2 | loss: 0.0950724\n",
      "\tspeed: 0.0410s/iter; left time: 677.7413s\n",
      "\titers: 800, epoch: 2 | loss: 0.0955931\n",
      "\tspeed: 0.0414s/iter; left time: 680.3324s\n",
      "\titers: 900, epoch: 2 | loss: 0.0924762\n",
      "\tspeed: 0.0375s/iter; left time: 611.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 906 | Train Loss: 0.1110337 Vali Loss: 0.1099066 Test Loss: 0.1318764\n",
      "Validation loss decreased (0.149272 --> 0.109907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0923405\n",
      "\tspeed: 0.1100s/iter; left time: 1783.7845s\n",
      "\titers: 200, epoch: 3 | loss: 0.0813107\n",
      "\tspeed: 0.0420s/iter; left time: 677.0576s\n",
      "\titers: 300, epoch: 3 | loss: 0.0849250\n",
      "\tspeed: 0.0414s/iter; left time: 662.2659s\n",
      "\titers: 400, epoch: 3 | loss: 0.0939740\n",
      "\tspeed: 0.0416s/iter; left time: 662.1010s\n",
      "\titers: 500, epoch: 3 | loss: 0.0956512\n",
      "\tspeed: 0.0437s/iter; left time: 690.4079s\n",
      "\titers: 600, epoch: 3 | loss: 0.0800993\n",
      "\tspeed: 0.0404s/iter; left time: 634.7718s\n",
      "\titers: 700, epoch: 3 | loss: 0.0859409\n",
      "\tspeed: 0.0412s/iter; left time: 643.2578s\n",
      "\titers: 800, epoch: 3 | loss: 0.0766279\n",
      "\tspeed: 0.0414s/iter; left time: 641.3931s\n",
      "\titers: 900, epoch: 3 | loss: 0.0780128\n",
      "\tspeed: 0.0424s/iter; left time: 653.6682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 906 | Train Loss: 0.0860765 Vali Loss: 0.0999773 Test Loss: 0.1211452\n",
      "Validation loss decreased (0.109907 --> 0.099977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0768543\n",
      "\tspeed: 0.1074s/iter; left time: 1643.2586s\n",
      "\titers: 200, epoch: 4 | loss: 0.0715280\n",
      "\tspeed: 0.0414s/iter; left time: 628.8105s\n",
      "\titers: 300, epoch: 4 | loss: 0.0677910\n",
      "\tspeed: 0.0416s/iter; left time: 628.0141s\n",
      "\titers: 400, epoch: 4 | loss: 0.0670909\n",
      "\tspeed: 0.0421s/iter; left time: 632.3553s\n",
      "\titers: 500, epoch: 4 | loss: 0.0756935\n",
      "\tspeed: 0.0431s/iter; left time: 642.7114s\n",
      "\titers: 600, epoch: 4 | loss: 0.0924990\n",
      "\tspeed: 0.0431s/iter; left time: 637.7754s\n",
      "\titers: 700, epoch: 4 | loss: 0.0793719\n",
      "\tspeed: 0.0417s/iter; left time: 612.7837s\n",
      "\titers: 800, epoch: 4 | loss: 0.0839831\n",
      "\tspeed: 0.0408s/iter; left time: 595.3371s\n",
      "\titers: 900, epoch: 4 | loss: 0.0862410\n",
      "\tspeed: 0.0419s/iter; left time: 607.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 906 | Train Loss: 0.0813469 Vali Loss: 0.0994681 Test Loss: 0.1163621\n",
      "Validation loss decreased (0.099977 --> 0.099468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788396\n",
      "\tspeed: 0.1082s/iter; left time: 1557.1563s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773479\n",
      "\tspeed: 0.0439s/iter; left time: 628.0851s\n",
      "\titers: 300, epoch: 5 | loss: 0.0841149\n",
      "\tspeed: 0.0434s/iter; left time: 616.1047s\n",
      "\titers: 400, epoch: 5 | loss: 0.0781510\n",
      "\tspeed: 0.0405s/iter; left time: 571.4702s\n",
      "\titers: 500, epoch: 5 | loss: 0.0816887\n",
      "\tspeed: 0.0410s/iter; left time: 574.1494s\n",
      "\titers: 600, epoch: 5 | loss: 0.0724723\n",
      "\tspeed: 0.0413s/iter; left time: 574.4166s\n",
      "\titers: 700, epoch: 5 | loss: 0.0761333\n",
      "\tspeed: 0.0424s/iter; left time: 585.2206s\n",
      "\titers: 800, epoch: 5 | loss: 0.0673740\n",
      "\tspeed: 0.0447s/iter; left time: 612.4852s\n",
      "\titers: 900, epoch: 5 | loss: 0.0788379\n",
      "\tspeed: 0.0436s/iter; left time: 592.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 906 | Train Loss: 0.0774063 Vali Loss: 0.0963497 Test Loss: 0.1142610\n",
      "Validation loss decreased (0.099468 --> 0.096350).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0804996\n",
      "\tspeed: 0.1114s/iter; left time: 1503.3126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841669\n",
      "\tspeed: 0.0413s/iter; left time: 553.5008s\n",
      "\titers: 300, epoch: 6 | loss: 0.0667240\n",
      "\tspeed: 0.0414s/iter; left time: 550.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776014\n",
      "\tspeed: 0.0419s/iter; left time: 552.4822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827275\n",
      "\tspeed: 0.0409s/iter; left time: 535.5406s\n",
      "\titers: 600, epoch: 6 | loss: 0.0766752\n",
      "\tspeed: 0.0433s/iter; left time: 563.0475s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804901\n",
      "\tspeed: 0.0447s/iter; left time: 575.7711s\n",
      "\titers: 800, epoch: 6 | loss: 0.0744671\n",
      "\tspeed: 0.0437s/iter; left time: 559.4921s\n",
      "\titers: 900, epoch: 6 | loss: 0.0781589\n",
      "\tspeed: 0.0445s/iter; left time: 564.1290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.09s\n",
      "Steps: 906 | Train Loss: 0.0746976 Vali Loss: 0.1017625 Test Loss: 0.1222291\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741962\n",
      "\tspeed: 0.1046s/iter; left time: 1316.8960s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620469\n",
      "\tspeed: 0.0436s/iter; left time: 544.0424s\n",
      "\titers: 300, epoch: 7 | loss: 0.0721050\n",
      "\tspeed: 0.0400s/iter; left time: 495.6921s\n",
      "\titers: 400, epoch: 7 | loss: 0.0632480\n",
      "\tspeed: 0.0423s/iter; left time: 519.5903s\n",
      "\titers: 500, epoch: 7 | loss: 0.0664979\n",
      "\tspeed: 0.0421s/iter; left time: 512.6556s\n",
      "\titers: 600, epoch: 7 | loss: 0.0662618\n",
      "\tspeed: 0.0421s/iter; left time: 508.3690s\n",
      "\titers: 700, epoch: 7 | loss: 0.0720267\n",
      "\tspeed: 0.0419s/iter; left time: 501.8393s\n",
      "\titers: 800, epoch: 7 | loss: 0.0630545\n",
      "\tspeed: 0.0404s/iter; left time: 479.9848s\n",
      "\titers: 900, epoch: 7 | loss: 0.0800700\n",
      "\tspeed: 0.0434s/iter; left time: 511.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 906 | Train Loss: 0.0715346 Vali Loss: 0.0970577 Test Loss: 0.1188241\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696932\n",
      "\tspeed: 0.1051s/iter; left time: 1227.3248s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695751\n",
      "\tspeed: 0.0447s/iter; left time: 517.6313s\n",
      "\titers: 300, epoch: 8 | loss: 0.0621481\n",
      "\tspeed: 0.0428s/iter; left time: 491.1447s\n",
      "\titers: 400, epoch: 8 | loss: 0.0656600\n",
      "\tspeed: 0.0424s/iter; left time: 482.9614s\n",
      "\titers: 500, epoch: 8 | loss: 0.0610848\n",
      "\tspeed: 0.0409s/iter; left time: 461.1994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0668859\n",
      "\tspeed: 0.0404s/iter; left time: 452.0429s\n",
      "\titers: 700, epoch: 8 | loss: 0.0636075\n",
      "\tspeed: 0.0407s/iter; left time: 450.4026s\n",
      "\titers: 800, epoch: 8 | loss: 0.0669452\n",
      "\tspeed: 0.0405s/iter; left time: 444.3156s\n",
      "\titers: 900, epoch: 8 | loss: 0.0670184\n",
      "\tspeed: 0.0426s/iter; left time: 463.7058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 906 | Train Loss: 0.0684857 Vali Loss: 0.1010585 Test Loss: 0.1231407\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604522\n",
      "\tspeed: 0.1046s/iter; left time: 1126.7267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733324\n",
      "\tspeed: 0.0413s/iter; left time: 441.2302s\n",
      "\titers: 300, epoch: 9 | loss: 0.0743875\n",
      "\tspeed: 0.0402s/iter; left time: 424.8030s\n",
      "\titers: 400, epoch: 9 | loss: 0.0751797\n",
      "\tspeed: 0.0405s/iter; left time: 424.4039s\n",
      "\titers: 500, epoch: 9 | loss: 0.0547750\n",
      "\tspeed: 0.0409s/iter; left time: 423.8305s\n",
      "\titers: 600, epoch: 9 | loss: 0.0654884\n",
      "\tspeed: 0.0415s/iter; left time: 426.4317s\n",
      "\titers: 700, epoch: 9 | loss: 0.0635630\n",
      "\tspeed: 0.0409s/iter; left time: 416.3660s\n",
      "\titers: 800, epoch: 9 | loss: 0.0642100\n",
      "\tspeed: 0.0409s/iter; left time: 412.0046s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658764\n",
      "\tspeed: 0.0410s/iter; left time: 408.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.36s\n",
      "Steps: 906 | Train Loss: 0.0650878 Vali Loss: 0.0995909 Test Loss: 0.1241297\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591552\n",
      "\tspeed: 0.1033s/iter; left time: 1018.7953s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584013\n",
      "\tspeed: 0.0408s/iter; left time: 398.4046s\n",
      "\titers: 300, epoch: 10 | loss: 0.0595871\n",
      "\tspeed: 0.0398s/iter; left time: 384.3685s\n",
      "\titers: 400, epoch: 10 | loss: 0.0590385\n",
      "\tspeed: 0.0415s/iter; left time: 396.9675s\n",
      "\titers: 500, epoch: 10 | loss: 0.0603983\n",
      "\tspeed: 0.0430s/iter; left time: 407.0963s\n",
      "\titers: 600, epoch: 10 | loss: 0.0631428\n",
      "\tspeed: 0.0430s/iter; left time: 402.5342s\n",
      "\titers: 700, epoch: 10 | loss: 0.0578520\n",
      "\tspeed: 0.0446s/iter; left time: 413.6800s\n",
      "\titers: 800, epoch: 10 | loss: 0.0694408\n",
      "\tspeed: 0.0395s/iter; left time: 362.2236s\n",
      "\titers: 900, epoch: 10 | loss: 0.0650614\n",
      "\tspeed: 0.0397s/iter; left time: 360.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 906 | Train Loss: 0.0625472 Vali Loss: 0.1016852 Test Loss: 0.1267304\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029107721522450447, rmse:0.17060984671115875, mae:0.11423589289188385, rse:0.5882587432861328\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:17.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2255687\n",
      "\tspeed: 0.0760s/iter; left time: 1366.0204s\n",
      "\titers: 200, epoch: 1 | loss: 0.1969440\n",
      "\tspeed: 0.0470s/iter; left time: 840.5014s\n",
      "\titers: 300, epoch: 1 | loss: 0.1951265\n",
      "\tspeed: 0.0474s/iter; left time: 843.4782s\n",
      "\titers: 400, epoch: 1 | loss: 0.1910113\n",
      "\tspeed: 0.0477s/iter; left time: 843.7551s\n",
      "\titers: 500, epoch: 1 | loss: 0.1806086\n",
      "\tspeed: 0.0486s/iter; left time: 854.9877s\n",
      "\titers: 600, epoch: 1 | loss: 0.1724181\n",
      "\tspeed: 0.0467s/iter; left time: 816.8248s\n",
      "\titers: 700, epoch: 1 | loss: 0.1663875\n",
      "\tspeed: 0.0452s/iter; left time: 785.5107s\n",
      "\titers: 800, epoch: 1 | loss: 0.1705200\n",
      "\tspeed: 0.0464s/iter; left time: 802.5584s\n",
      "\titers: 900, epoch: 1 | loss: 0.1639884\n",
      "\tspeed: 0.0477s/iter; left time: 819.0618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.1898295 Vali Loss: 0.1726514 Test Loss: 0.2125144\n",
      "Validation loss decreased (inf --> 0.172651).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1466748\n",
      "\tspeed: 0.1232s/iter; left time: 2104.0705s\n",
      "\titers: 200, epoch: 2 | loss: 0.1372828\n",
      "\tspeed: 0.0454s/iter; left time: 770.4328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1329548\n",
      "\tspeed: 0.0464s/iter; left time: 783.2295s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341645\n",
      "\tspeed: 0.0491s/iter; left time: 823.2519s\n",
      "\titers: 500, epoch: 2 | loss: 0.1367194\n",
      "\tspeed: 0.0497s/iter; left time: 828.0430s\n",
      "\titers: 600, epoch: 2 | loss: 0.1326677\n",
      "\tspeed: 0.0496s/iter; left time: 821.6464s\n",
      "\titers: 700, epoch: 2 | loss: 0.1257785\n",
      "\tspeed: 0.0491s/iter; left time: 808.5336s\n",
      "\titers: 800, epoch: 2 | loss: 0.1244963\n",
      "\tspeed: 0.0449s/iter; left time: 734.5305s\n",
      "\titers: 900, epoch: 2 | loss: 0.1313370\n",
      "\tspeed: 0.0477s/iter; left time: 776.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 904 | Train Loss: 0.1353561 Vali Loss: 0.1446950 Test Loss: 0.1772607\n",
      "Validation loss decreased (0.172651 --> 0.144695).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1177422\n",
      "\tspeed: 0.1245s/iter; left time: 2014.1480s\n",
      "\titers: 200, epoch: 3 | loss: 0.1186227\n",
      "\tspeed: 0.0488s/iter; left time: 783.6847s\n",
      "\titers: 300, epoch: 3 | loss: 0.1157690\n",
      "\tspeed: 0.0471s/iter; left time: 752.5161s\n",
      "\titers: 400, epoch: 3 | loss: 0.1103611\n",
      "\tspeed: 0.0478s/iter; left time: 759.2433s\n",
      "\titers: 500, epoch: 3 | loss: 0.1088090\n",
      "\tspeed: 0.0490s/iter; left time: 772.1911s\n",
      "\titers: 600, epoch: 3 | loss: 0.1162299\n",
      "\tspeed: 0.0488s/iter; left time: 765.0206s\n",
      "\titers: 700, epoch: 3 | loss: 0.1067353\n",
      "\tspeed: 0.0495s/iter; left time: 770.6839s\n",
      "\titers: 800, epoch: 3 | loss: 0.1024203\n",
      "\tspeed: 0.0494s/iter; left time: 763.6034s\n",
      "\titers: 900, epoch: 3 | loss: 0.1095797\n",
      "\tspeed: 0.0477s/iter; left time: 733.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.16s\n",
      "Steps: 904 | Train Loss: 0.1113961 Vali Loss: 0.1269721 Test Loss: 0.1567219\n",
      "Validation loss decreased (0.144695 --> 0.126972).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1150751\n",
      "\tspeed: 0.1260s/iter; left time: 1923.2966s\n",
      "\titers: 200, epoch: 4 | loss: 0.1073310\n",
      "\tspeed: 0.0500s/iter; left time: 758.2552s\n",
      "\titers: 300, epoch: 4 | loss: 0.1104820\n",
      "\tspeed: 0.0475s/iter; left time: 715.5529s\n",
      "\titers: 400, epoch: 4 | loss: 0.1005932\n",
      "\tspeed: 0.0419s/iter; left time: 627.5319s\n",
      "\titers: 500, epoch: 4 | loss: 0.0951388\n",
      "\tspeed: 0.0499s/iter; left time: 741.4723s\n",
      "\titers: 600, epoch: 4 | loss: 0.0997509\n",
      "\tspeed: 0.0493s/iter; left time: 728.4661s\n",
      "\titers: 700, epoch: 4 | loss: 0.0984313\n",
      "\tspeed: 0.0497s/iter; left time: 728.9388s\n",
      "\titers: 800, epoch: 4 | loss: 0.1034888\n",
      "\tspeed: 0.0497s/iter; left time: 724.1530s\n",
      "\titers: 900, epoch: 4 | loss: 0.1050800\n",
      "\tspeed: 0.0439s/iter; left time: 635.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.62s\n",
      "Steps: 904 | Train Loss: 0.1017109 Vali Loss: 0.1283327 Test Loss: 0.1621235\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948988\n",
      "\tspeed: 0.1224s/iter; left time: 1758.2687s\n",
      "\titers: 200, epoch: 5 | loss: 0.0923659\n",
      "\tspeed: 0.0495s/iter; left time: 706.0892s\n",
      "\titers: 300, epoch: 5 | loss: 0.0939323\n",
      "\tspeed: 0.0491s/iter; left time: 694.9450s\n",
      "\titers: 400, epoch: 5 | loss: 0.1048447\n",
      "\tspeed: 0.0456s/iter; left time: 641.6971s\n",
      "\titers: 500, epoch: 5 | loss: 0.0898416\n",
      "\tspeed: 0.0493s/iter; left time: 689.1189s\n",
      "\titers: 600, epoch: 5 | loss: 0.1012730\n",
      "\tspeed: 0.0496s/iter; left time: 687.9547s\n",
      "\titers: 700, epoch: 5 | loss: 0.1037022\n",
      "\tspeed: 0.0499s/iter; left time: 686.8058s\n",
      "\titers: 800, epoch: 5 | loss: 0.1009622\n",
      "\tspeed: 0.0503s/iter; left time: 687.8192s\n",
      "\titers: 900, epoch: 5 | loss: 0.1010886\n",
      "\tspeed: 0.0499s/iter; left time: 676.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.70s\n",
      "Steps: 904 | Train Loss: 0.0953739 Vali Loss: 0.1267609 Test Loss: 0.1637363\n",
      "Validation loss decreased (0.126972 --> 0.126761).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918601\n",
      "\tspeed: 0.1237s/iter; left time: 1664.8794s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857725\n",
      "\tspeed: 0.0489s/iter; left time: 652.8306s\n",
      "\titers: 300, epoch: 6 | loss: 0.0888586\n",
      "\tspeed: 0.0502s/iter; left time: 666.1765s\n",
      "\titers: 400, epoch: 6 | loss: 0.0926645\n",
      "\tspeed: 0.0481s/iter; left time: 633.3903s\n",
      "\titers: 500, epoch: 6 | loss: 0.0844825\n",
      "\tspeed: 0.0465s/iter; left time: 607.8722s\n",
      "\titers: 600, epoch: 6 | loss: 0.0870649\n",
      "\tspeed: 0.0488s/iter; left time: 632.7013s\n",
      "\titers: 700, epoch: 6 | loss: 0.0815338\n",
      "\tspeed: 0.0499s/iter; left time: 641.7445s\n",
      "\titers: 800, epoch: 6 | loss: 0.0904821\n",
      "\tspeed: 0.0467s/iter; left time: 595.5603s\n",
      "\titers: 900, epoch: 6 | loss: 0.0895468\n",
      "\tspeed: 0.0503s/iter; left time: 636.2876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.17s\n",
      "Steps: 904 | Train Loss: 0.0891392 Vali Loss: 0.1326915 Test Loss: 0.1757692\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0813128\n",
      "\tspeed: 0.1216s/iter; left time: 1527.0185s\n",
      "\titers: 200, epoch: 7 | loss: 0.0833745\n",
      "\tspeed: 0.0498s/iter; left time: 619.8049s\n",
      "\titers: 300, epoch: 7 | loss: 0.0761775\n",
      "\tspeed: 0.0500s/iter; left time: 618.4654s\n",
      "\titers: 400, epoch: 7 | loss: 0.0891688\n",
      "\tspeed: 0.0497s/iter; left time: 608.6677s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869506\n",
      "\tspeed: 0.0468s/iter; left time: 568.7626s\n",
      "\titers: 600, epoch: 7 | loss: 0.0887999\n",
      "\tspeed: 0.0495s/iter; left time: 596.4220s\n",
      "\titers: 700, epoch: 7 | loss: 0.0896799\n",
      "\tspeed: 0.0494s/iter; left time: 590.2693s\n",
      "\titers: 800, epoch: 7 | loss: 0.0758964\n",
      "\tspeed: 0.0499s/iter; left time: 592.0330s\n",
      "\titers: 900, epoch: 7 | loss: 0.0829648\n",
      "\tspeed: 0.0497s/iter; left time: 584.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.84s\n",
      "Steps: 904 | Train Loss: 0.0835469 Vali Loss: 0.1329960 Test Loss: 0.1782949\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0797158\n",
      "\tspeed: 0.1201s/iter; left time: 1400.0702s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767336\n",
      "\tspeed: 0.0490s/iter; left time: 566.0544s\n",
      "\titers: 300, epoch: 8 | loss: 0.0795722\n",
      "\tspeed: 0.0498s/iter; left time: 570.3941s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774469\n",
      "\tspeed: 0.0491s/iter; left time: 557.0942s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814914\n",
      "\tspeed: 0.0472s/iter; left time: 531.0827s\n",
      "\titers: 600, epoch: 8 | loss: 0.0761013\n",
      "\tspeed: 0.0470s/iter; left time: 524.5450s\n",
      "\titers: 700, epoch: 8 | loss: 0.0786306\n",
      "\tspeed: 0.0420s/iter; left time: 464.6564s\n",
      "\titers: 800, epoch: 8 | loss: 0.0797036\n",
      "\tspeed: 0.0393s/iter; left time: 430.4928s\n",
      "\titers: 900, epoch: 8 | loss: 0.0819933\n",
      "\tspeed: 0.0393s/iter; left time: 426.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 904 | Train Loss: 0.0788386 Vali Loss: 0.1321585 Test Loss: 0.1784511\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0827697\n",
      "\tspeed: 0.1172s/iter; left time: 1260.1794s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719339\n",
      "\tspeed: 0.0492s/iter; left time: 523.6987s\n",
      "\titers: 300, epoch: 9 | loss: 0.0696444\n",
      "\tspeed: 0.0497s/iter; left time: 523.8967s\n",
      "\titers: 400, epoch: 9 | loss: 0.0856322\n",
      "\tspeed: 0.0502s/iter; left time: 524.6049s\n",
      "\titers: 500, epoch: 9 | loss: 0.0722203\n",
      "\tspeed: 0.0500s/iter; left time: 517.4286s\n",
      "\titers: 600, epoch: 9 | loss: 0.0815830\n",
      "\tspeed: 0.0482s/iter; left time: 493.8630s\n",
      "\titers: 700, epoch: 9 | loss: 0.0667963\n",
      "\tspeed: 0.0498s/iter; left time: 505.2123s\n",
      "\titers: 800, epoch: 9 | loss: 0.0706898\n",
      "\tspeed: 0.0500s/iter; left time: 502.6801s\n",
      "\titers: 900, epoch: 9 | loss: 0.0754192\n",
      "\tspeed: 0.0500s/iter; left time: 497.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 904 | Train Loss: 0.0747280 Vali Loss: 0.1316066 Test Loss: 0.1729603\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0694733\n",
      "\tspeed: 0.1183s/iter; left time: 1165.1138s\n",
      "\titers: 200, epoch: 10 | loss: 0.0695997\n",
      "\tspeed: 0.0495s/iter; left time: 482.0890s\n",
      "\titers: 300, epoch: 10 | loss: 0.0735394\n",
      "\tspeed: 0.0394s/iter; left time: 379.6764s\n",
      "\titers: 400, epoch: 10 | loss: 0.0671492\n",
      "\tspeed: 0.0393s/iter; left time: 375.2100s\n",
      "\titers: 500, epoch: 10 | loss: 0.0740291\n",
      "\tspeed: 0.0431s/iter; left time: 407.5482s\n",
      "\titers: 600, epoch: 10 | loss: 0.0708412\n",
      "\tspeed: 0.0500s/iter; left time: 467.2188s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724577\n",
      "\tspeed: 0.0493s/iter; left time: 455.6526s\n",
      "\titers: 800, epoch: 10 | loss: 0.0702263\n",
      "\tspeed: 0.0454s/iter; left time: 415.4378s\n",
      "\titers: 900, epoch: 10 | loss: 0.0671190\n",
      "\tspeed: 0.0392s/iter; left time: 354.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.60s\n",
      "Steps: 904 | Train Loss: 0.0708816 Vali Loss: 0.1308677 Test Loss: 0.1720753\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.057526689022779465, rmse:0.23984721302986145, mae:0.16363422572612762, rse:0.8294250965118408\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2361504\n",
      "\tspeed: 0.0498s/iter; left time: 895.9571s\n",
      "\titers: 200, epoch: 1 | loss: 0.2048126\n",
      "\tspeed: 0.0461s/iter; left time: 823.9144s\n",
      "\titers: 300, epoch: 1 | loss: 0.1914368\n",
      "\tspeed: 0.0502s/iter; left time: 893.4788s\n",
      "\titers: 400, epoch: 1 | loss: 0.1891696\n",
      "\tspeed: 0.0505s/iter; left time: 892.0573s\n",
      "\titers: 500, epoch: 1 | loss: 0.1742566\n",
      "\tspeed: 0.0491s/iter; left time: 863.8785s\n",
      "\titers: 600, epoch: 1 | loss: 0.1876671\n",
      "\tspeed: 0.0506s/iter; left time: 884.6296s\n",
      "\titers: 700, epoch: 1 | loss: 0.1831172\n",
      "\tspeed: 0.0490s/iter; left time: 851.7845s\n",
      "\titers: 800, epoch: 1 | loss: 0.1632556\n",
      "\tspeed: 0.0423s/iter; left time: 731.4180s\n",
      "\titers: 900, epoch: 1 | loss: 0.1665270\n",
      "\tspeed: 0.0406s/iter; left time: 696.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.1935472 Vali Loss: 0.1648111 Test Loss: 0.2020273\n",
      "Validation loss decreased (inf --> 0.164811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431796\n",
      "\tspeed: 0.1241s/iter; left time: 2118.5508s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429133\n",
      "\tspeed: 0.0474s/iter; left time: 804.9371s\n",
      "\titers: 300, epoch: 2 | loss: 0.1351413\n",
      "\tspeed: 0.0502s/iter; left time: 846.9771s\n",
      "\titers: 400, epoch: 2 | loss: 0.1290429\n",
      "\tspeed: 0.0500s/iter; left time: 839.2104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1320884\n",
      "\tspeed: 0.0489s/iter; left time: 814.8222s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265727\n",
      "\tspeed: 0.0496s/iter; left time: 822.6283s\n",
      "\titers: 700, epoch: 2 | loss: 0.1288902\n",
      "\tspeed: 0.0496s/iter; left time: 816.7460s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242642\n",
      "\tspeed: 0.0458s/iter; left time: 750.2946s\n",
      "\titers: 900, epoch: 2 | loss: 0.1087183\n",
      "\tspeed: 0.0488s/iter; left time: 794.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.43s\n",
      "Steps: 904 | Train Loss: 0.1333465 Vali Loss: 0.1431034 Test Loss: 0.1751640\n",
      "Validation loss decreased (0.164811 --> 0.143103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1197574\n",
      "\tspeed: 0.1241s/iter; left time: 2006.6691s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244095\n",
      "\tspeed: 0.0500s/iter; left time: 803.0443s\n",
      "\titers: 300, epoch: 3 | loss: 0.1182540\n",
      "\tspeed: 0.0483s/iter; left time: 770.7792s\n",
      "\titers: 400, epoch: 3 | loss: 0.1185170\n",
      "\tspeed: 0.0485s/iter; left time: 769.2513s\n",
      "\titers: 500, epoch: 3 | loss: 0.1217805\n",
      "\tspeed: 0.0464s/iter; left time: 731.8833s\n",
      "\titers: 600, epoch: 3 | loss: 0.1079377\n",
      "\tspeed: 0.0502s/iter; left time: 787.3178s\n",
      "\titers: 700, epoch: 3 | loss: 0.1133052\n",
      "\tspeed: 0.0506s/iter; left time: 787.3524s\n",
      "\titers: 800, epoch: 3 | loss: 0.1056479\n",
      "\tspeed: 0.0499s/iter; left time: 771.7006s\n",
      "\titers: 900, epoch: 3 | loss: 0.1042594\n",
      "\tspeed: 0.0498s/iter; left time: 765.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.64s\n",
      "Steps: 904 | Train Loss: 0.1136956 Vali Loss: 0.1303343 Test Loss: 0.1621740\n",
      "Validation loss decreased (0.143103 --> 0.130334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1131616\n",
      "\tspeed: 0.1244s/iter; left time: 1900.2076s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025617\n",
      "\tspeed: 0.0493s/iter; left time: 748.2143s\n",
      "\titers: 300, epoch: 4 | loss: 0.1044936\n",
      "\tspeed: 0.0464s/iter; left time: 699.4243s\n",
      "\titers: 400, epoch: 4 | loss: 0.1040315\n",
      "\tspeed: 0.0480s/iter; left time: 719.1333s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039687\n",
      "\tspeed: 0.0497s/iter; left time: 738.9866s\n",
      "\titers: 600, epoch: 4 | loss: 0.1011319\n",
      "\tspeed: 0.0505s/iter; left time: 745.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0994408\n",
      "\tspeed: 0.0499s/iter; left time: 731.8844s\n",
      "\titers: 800, epoch: 4 | loss: 0.1095860\n",
      "\tspeed: 0.0497s/iter; left time: 723.7528s\n",
      "\titers: 900, epoch: 4 | loss: 0.1097626\n",
      "\tspeed: 0.0484s/iter; left time: 699.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.52s\n",
      "Steps: 904 | Train Loss: 0.1034935 Vali Loss: 0.1326608 Test Loss: 0.1598699\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1011364\n",
      "\tspeed: 0.1215s/iter; left time: 1744.9263s\n",
      "\titers: 200, epoch: 5 | loss: 0.0990633\n",
      "\tspeed: 0.0502s/iter; left time: 716.2142s\n",
      "\titers: 300, epoch: 5 | loss: 0.0947605\n",
      "\tspeed: 0.0501s/iter; left time: 709.5710s\n",
      "\titers: 400, epoch: 5 | loss: 0.0896447\n",
      "\tspeed: 0.0462s/iter; left time: 649.6339s\n",
      "\titers: 500, epoch: 5 | loss: 0.0950052\n",
      "\tspeed: 0.0494s/iter; left time: 689.3587s\n",
      "\titers: 600, epoch: 5 | loss: 0.0931334\n",
      "\tspeed: 0.0480s/iter; left time: 665.7597s\n",
      "\titers: 700, epoch: 5 | loss: 0.1013913\n",
      "\tspeed: 0.0497s/iter; left time: 683.9799s\n",
      "\titers: 800, epoch: 5 | loss: 0.0912395\n",
      "\tspeed: 0.0503s/iter; left time: 686.8013s\n",
      "\titers: 900, epoch: 5 | loss: 0.1009830\n",
      "\tspeed: 0.0500s/iter; left time: 678.3845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 904 | Train Loss: 0.0965961 Vali Loss: 0.1320217 Test Loss: 0.1635417\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990747\n",
      "\tspeed: 0.1224s/iter; left time: 1648.1692s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899862\n",
      "\tspeed: 0.0504s/iter; left time: 673.0483s\n",
      "\titers: 300, epoch: 6 | loss: 0.0861572\n",
      "\tspeed: 0.0501s/iter; left time: 663.8115s\n",
      "\titers: 400, epoch: 6 | loss: 0.0965549\n",
      "\tspeed: 0.0490s/iter; left time: 644.8868s\n",
      "\titers: 500, epoch: 6 | loss: 0.0914424\n",
      "\tspeed: 0.0419s/iter; left time: 547.6008s\n",
      "\titers: 600, epoch: 6 | loss: 0.0866498\n",
      "\tspeed: 0.0394s/iter; left time: 510.1331s\n",
      "\titers: 700, epoch: 6 | loss: 0.0789218\n",
      "\tspeed: 0.0394s/iter; left time: 506.2884s\n",
      "\titers: 800, epoch: 6 | loss: 0.0881015\n",
      "\tspeed: 0.0394s/iter; left time: 503.1789s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933495\n",
      "\tspeed: 0.0394s/iter; left time: 498.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 904 | Train Loss: 0.0900866 Vali Loss: 0.1291286 Test Loss: 0.1623160\n",
      "Validation loss decreased (0.130334 --> 0.129129).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832615\n",
      "\tspeed: 0.1258s/iter; left time: 1579.4167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0875159\n",
      "\tspeed: 0.0500s/iter; left time: 622.3463s\n",
      "\titers: 300, epoch: 7 | loss: 0.0784433\n",
      "\tspeed: 0.0499s/iter; left time: 616.8860s\n",
      "\titers: 400, epoch: 7 | loss: 0.0793963\n",
      "\tspeed: 0.0499s/iter; left time: 612.1079s\n",
      "\titers: 500, epoch: 7 | loss: 0.0825817\n",
      "\tspeed: 0.0492s/iter; left time: 597.9757s\n",
      "\titers: 600, epoch: 7 | loss: 0.0923625\n",
      "\tspeed: 0.0479s/iter; left time: 577.8367s\n",
      "\titers: 700, epoch: 7 | loss: 0.0802216\n",
      "\tspeed: 0.0486s/iter; left time: 580.5910s\n",
      "\titers: 800, epoch: 7 | loss: 0.0863001\n",
      "\tspeed: 0.0476s/iter; left time: 563.8489s\n",
      "\titers: 900, epoch: 7 | loss: 0.0720519\n",
      "\tspeed: 0.0494s/iter; left time: 581.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.70s\n",
      "Steps: 904 | Train Loss: 0.0840416 Vali Loss: 0.1331552 Test Loss: 0.1622402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839713\n",
      "\tspeed: 0.1211s/iter; left time: 1411.4648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806477\n",
      "\tspeed: 0.0497s/iter; left time: 574.1412s\n",
      "\titers: 300, epoch: 8 | loss: 0.0809879\n",
      "\tspeed: 0.0502s/iter; left time: 574.9612s\n",
      "\titers: 400, epoch: 8 | loss: 0.0778002\n",
      "\tspeed: 0.0499s/iter; left time: 566.2249s\n",
      "\titers: 500, epoch: 8 | loss: 0.0738605\n",
      "\tspeed: 0.0489s/iter; left time: 549.8237s\n",
      "\titers: 600, epoch: 8 | loss: 0.0788250\n",
      "\tspeed: 0.0453s/iter; left time: 505.2189s\n",
      "\titers: 700, epoch: 8 | loss: 0.0782335\n",
      "\tspeed: 0.0481s/iter; left time: 531.3415s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746135\n",
      "\tspeed: 0.0502s/iter; left time: 550.1797s\n",
      "\titers: 900, epoch: 8 | loss: 0.0734857\n",
      "\tspeed: 0.0500s/iter; left time: 542.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.51s\n",
      "Steps: 904 | Train Loss: 0.0792389 Vali Loss: 0.1388449 Test Loss: 0.1700458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769500\n",
      "\tspeed: 0.1220s/iter; left time: 1311.1650s\n",
      "\titers: 200, epoch: 9 | loss: 0.0726015\n",
      "\tspeed: 0.0503s/iter; left time: 535.9565s\n",
      "\titers: 300, epoch: 9 | loss: 0.0833335\n",
      "\tspeed: 0.0488s/iter; left time: 514.8115s\n",
      "\titers: 400, epoch: 9 | loss: 0.0767504\n",
      "\tspeed: 0.0495s/iter; left time: 517.1847s\n",
      "\titers: 500, epoch: 9 | loss: 0.0797865\n",
      "\tspeed: 0.0502s/iter; left time: 519.9004s\n",
      "\titers: 600, epoch: 9 | loss: 0.0723531\n",
      "\tspeed: 0.0495s/iter; left time: 507.4686s\n",
      "\titers: 700, epoch: 9 | loss: 0.0742085\n",
      "\tspeed: 0.0470s/iter; left time: 476.5912s\n",
      "\titers: 800, epoch: 9 | loss: 0.0727802\n",
      "\tspeed: 0.0468s/iter; left time: 470.1330s\n",
      "\titers: 900, epoch: 9 | loss: 0.0761377\n",
      "\tspeed: 0.0499s/iter; left time: 496.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.61s\n",
      "Steps: 904 | Train Loss: 0.0747473 Vali Loss: 0.1365098 Test Loss: 0.1709515\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0697394\n",
      "\tspeed: 0.1220s/iter; left time: 1200.8540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0761079\n",
      "\tspeed: 0.0496s/iter; left time: 483.6980s\n",
      "\titers: 300, epoch: 10 | loss: 0.0721913\n",
      "\tspeed: 0.0496s/iter; left time: 478.8330s\n",
      "\titers: 400, epoch: 10 | loss: 0.0689166\n",
      "\tspeed: 0.0489s/iter; left time: 466.3007s\n",
      "\titers: 500, epoch: 10 | loss: 0.0677448\n",
      "\tspeed: 0.0491s/iter; left time: 463.5784s\n",
      "\titers: 600, epoch: 10 | loss: 0.0659904\n",
      "\tspeed: 0.0505s/iter; left time: 472.2652s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724253\n",
      "\tspeed: 0.0503s/iter; left time: 465.3886s\n",
      "\titers: 800, epoch: 10 | loss: 0.0667000\n",
      "\tspeed: 0.0503s/iter; left time: 459.9471s\n",
      "\titers: 900, epoch: 10 | loss: 0.0637502\n",
      "\tspeed: 0.0494s/iter; left time: 447.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.17s\n",
      "Steps: 904 | Train Loss: 0.0710539 Vali Loss: 0.1381611 Test Loss: 0.1748331\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0691393\n",
      "\tspeed: 0.1195s/iter; left time: 1068.0460s\n",
      "\titers: 200, epoch: 11 | loss: 0.0713970\n",
      "\tspeed: 0.0463s/iter; left time: 409.7231s\n",
      "\titers: 300, epoch: 11 | loss: 0.0708896\n",
      "\tspeed: 0.0487s/iter; left time: 426.0248s\n",
      "\titers: 400, epoch: 11 | loss: 0.0681953\n",
      "\tspeed: 0.0493s/iter; left time: 425.5716s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624288\n",
      "\tspeed: 0.0454s/iter; left time: 388.1189s\n",
      "\titers: 600, epoch: 11 | loss: 0.0698107\n",
      "\tspeed: 0.0479s/iter; left time: 403.9841s\n",
      "\titers: 700, epoch: 11 | loss: 0.0659833\n",
      "\tspeed: 0.0501s/iter; left time: 417.5273s\n",
      "\titers: 800, epoch: 11 | loss: 0.0641235\n",
      "\tspeed: 0.0495s/iter; left time: 407.5696s\n",
      "\titers: 900, epoch: 11 | loss: 0.0661707\n",
      "\tspeed: 0.0470s/iter; left time: 382.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.51s\n",
      "Steps: 904 | Train Loss: 0.0677608 Vali Loss: 0.1354970 Test Loss: 0.1686172\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0539480485022068, rmse:0.23226718604564667, mae:0.1623077541589737, rse:0.8032123446464539\n",
      "Intermediate time for GB and pred_len 96: 00h:18m:03.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2130859\n",
      "\tspeed: 0.0801s/iter; left time: 1437.9426s\n",
      "\titers: 200, epoch: 1 | loss: 0.2044703\n",
      "\tspeed: 0.0520s/iter; left time: 928.4471s\n",
      "\titers: 300, epoch: 1 | loss: 0.1846589\n",
      "\tspeed: 0.0526s/iter; left time: 934.0526s\n",
      "\titers: 400, epoch: 1 | loss: 0.1825477\n",
      "\tspeed: 0.0509s/iter; left time: 898.1736s\n",
      "\titers: 500, epoch: 1 | loss: 0.1851541\n",
      "\tspeed: 0.0505s/iter; left time: 885.0862s\n",
      "\titers: 600, epoch: 1 | loss: 0.1808470\n",
      "\tspeed: 0.0508s/iter; left time: 886.7237s\n",
      "\titers: 700, epoch: 1 | loss: 0.1705929\n",
      "\tspeed: 0.0511s/iter; left time: 885.9569s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668541\n",
      "\tspeed: 0.0536s/iter; left time: 923.3948s\n",
      "\titers: 900, epoch: 1 | loss: 0.1636396\n",
      "\tspeed: 0.0521s/iter; left time: 892.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.1903320 Vali Loss: 0.1756451 Test Loss: 0.2138607\n",
      "Validation loss decreased (inf --> 0.175645).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1547550\n",
      "\tspeed: 0.1444s/iter; left time: 2460.4023s\n",
      "\titers: 200, epoch: 2 | loss: 0.1449682\n",
      "\tspeed: 0.0527s/iter; left time: 891.8606s\n",
      "\titers: 300, epoch: 2 | loss: 0.1423143\n",
      "\tspeed: 0.0530s/iter; left time: 892.0081s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334532\n",
      "\tspeed: 0.0510s/iter; left time: 852.9795s\n",
      "\titers: 500, epoch: 2 | loss: 0.1304843\n",
      "\tspeed: 0.0495s/iter; left time: 824.2904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1366739\n",
      "\tspeed: 0.0501s/iter; left time: 828.2109s\n",
      "\titers: 700, epoch: 2 | loss: 0.1369409\n",
      "\tspeed: 0.0528s/iter; left time: 868.6764s\n",
      "\titers: 800, epoch: 2 | loss: 0.1349143\n",
      "\tspeed: 0.0544s/iter; left time: 889.0884s\n",
      "\titers: 900, epoch: 2 | loss: 0.1402102\n",
      "\tspeed: 0.0524s/iter; left time: 851.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.22s\n",
      "Steps: 902 | Train Loss: 0.1414546 Vali Loss: 0.1560951 Test Loss: 0.1947084\n",
      "Validation loss decreased (0.175645 --> 0.156095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1330463\n",
      "\tspeed: 0.1432s/iter; left time: 2310.8407s\n",
      "\titers: 200, epoch: 3 | loss: 0.1262971\n",
      "\tspeed: 0.0532s/iter; left time: 853.7685s\n",
      "\titers: 300, epoch: 3 | loss: 0.1371024\n",
      "\tspeed: 0.0530s/iter; left time: 844.4728s\n",
      "\titers: 400, epoch: 3 | loss: 0.1289511\n",
      "\tspeed: 0.0515s/iter; left time: 815.3481s\n",
      "\titers: 500, epoch: 3 | loss: 0.1287059\n",
      "\tspeed: 0.0514s/iter; left time: 808.8543s\n",
      "\titers: 600, epoch: 3 | loss: 0.1410395\n",
      "\tspeed: 0.0507s/iter; left time: 793.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.1244261\n",
      "\tspeed: 0.0509s/iter; left time: 791.0376s\n",
      "\titers: 800, epoch: 3 | loss: 0.1227208\n",
      "\tspeed: 0.0528s/iter; left time: 815.8293s\n",
      "\titers: 900, epoch: 3 | loss: 0.1195739\n",
      "\tspeed: 0.0517s/iter; left time: 792.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.1292438 Vali Loss: 0.1511649 Test Loss: 0.1915466\n",
      "Validation loss decreased (0.156095 --> 0.151165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1260634\n",
      "\tspeed: 0.1443s/iter; left time: 2198.7220s\n",
      "\titers: 200, epoch: 4 | loss: 0.1137747\n",
      "\tspeed: 0.0531s/iter; left time: 804.1276s\n",
      "\titers: 300, epoch: 4 | loss: 0.1182747\n",
      "\tspeed: 0.0526s/iter; left time: 791.5067s\n",
      "\titers: 400, epoch: 4 | loss: 0.1119198\n",
      "\tspeed: 0.0506s/iter; left time: 755.7425s\n",
      "\titers: 500, epoch: 4 | loss: 0.1041145\n",
      "\tspeed: 0.0526s/iter; left time: 779.9608s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054148\n",
      "\tspeed: 0.0526s/iter; left time: 775.5622s\n",
      "\titers: 700, epoch: 4 | loss: 0.1080971\n",
      "\tspeed: 0.0532s/iter; left time: 778.4536s\n",
      "\titers: 800, epoch: 4 | loss: 0.1017381\n",
      "\tspeed: 0.0557s/iter; left time: 809.0875s\n",
      "\titers: 900, epoch: 4 | loss: 0.0959649\n",
      "\tspeed: 0.0512s/iter; left time: 738.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.74s\n",
      "Steps: 902 | Train Loss: 0.1106928 Vali Loss: 0.1285962 Test Loss: 0.1634130\n",
      "Validation loss decreased (0.151165 --> 0.128596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0952113\n",
      "\tspeed: 0.1457s/iter; left time: 2088.5928s\n",
      "\titers: 200, epoch: 5 | loss: 0.1024759\n",
      "\tspeed: 0.0550s/iter; left time: 782.2679s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958942\n",
      "\tspeed: 0.0531s/iter; left time: 750.0315s\n",
      "\titers: 400, epoch: 5 | loss: 0.0972925\n",
      "\tspeed: 0.0511s/iter; left time: 716.4114s\n",
      "\titers: 500, epoch: 5 | loss: 0.0980621\n",
      "\tspeed: 0.0505s/iter; left time: 703.1414s\n",
      "\titers: 600, epoch: 5 | loss: 0.0946259\n",
      "\tspeed: 0.0513s/iter; left time: 708.9646s\n",
      "\titers: 700, epoch: 5 | loss: 0.0907413\n",
      "\tspeed: 0.0517s/iter; left time: 710.3315s\n",
      "\titers: 800, epoch: 5 | loss: 0.1015313\n",
      "\tspeed: 0.0533s/iter; left time: 727.1556s\n",
      "\titers: 900, epoch: 5 | loss: 0.0984497\n",
      "\tspeed: 0.0519s/iter; left time: 702.5039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.0976338 Vali Loss: 0.1314606 Test Loss: 0.1745053\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0966667\n",
      "\tspeed: 0.1382s/iter; left time: 1856.1035s\n",
      "\titers: 200, epoch: 6 | loss: 0.0976619\n",
      "\tspeed: 0.0517s/iter; left time: 688.6140s\n",
      "\titers: 300, epoch: 6 | loss: 0.0869687\n",
      "\tspeed: 0.0526s/iter; left time: 696.2543s\n",
      "\titers: 400, epoch: 6 | loss: 0.0888621\n",
      "\tspeed: 0.0532s/iter; left time: 698.1760s\n",
      "\titers: 500, epoch: 6 | loss: 0.0968440\n",
      "\tspeed: 0.0504s/iter; left time: 657.1023s\n",
      "\titers: 600, epoch: 6 | loss: 0.0900905\n",
      "\tspeed: 0.0521s/iter; left time: 673.8527s\n",
      "\titers: 700, epoch: 6 | loss: 0.0819179\n",
      "\tspeed: 0.0530s/iter; left time: 680.2167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0874333\n",
      "\tspeed: 0.0541s/iter; left time: 689.0741s\n",
      "\titers: 900, epoch: 6 | loss: 0.0866565\n",
      "\tspeed: 0.0519s/iter; left time: 655.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.0908995 Vali Loss: 0.1360142 Test Loss: 0.1832639\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927695\n",
      "\tspeed: 0.1442s/iter; left time: 1806.6140s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865635\n",
      "\tspeed: 0.0528s/iter; left time: 656.2294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0894563\n",
      "\tspeed: 0.0539s/iter; left time: 664.3774s\n",
      "\titers: 400, epoch: 7 | loss: 0.0827512\n",
      "\tspeed: 0.0519s/iter; left time: 635.2403s\n",
      "\titers: 500, epoch: 7 | loss: 0.0833580\n",
      "\tspeed: 0.0529s/iter; left time: 641.5303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0800363\n",
      "\tspeed: 0.0505s/iter; left time: 607.8582s\n",
      "\titers: 700, epoch: 7 | loss: 0.0868889\n",
      "\tspeed: 0.0513s/iter; left time: 611.4840s\n",
      "\titers: 800, epoch: 7 | loss: 0.0773531\n",
      "\tspeed: 0.0539s/iter; left time: 637.3197s\n",
      "\titers: 900, epoch: 7 | loss: 0.0926475\n",
      "\tspeed: 0.0531s/iter; left time: 622.9517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 902 | Train Loss: 0.0848858 Vali Loss: 0.1352109 Test Loss: 0.1852673\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0755614\n",
      "\tspeed: 0.1423s/iter; left time: 1654.1070s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805938\n",
      "\tspeed: 0.0541s/iter; left time: 623.5909s\n",
      "\titers: 300, epoch: 8 | loss: 0.0836685\n",
      "\tspeed: 0.0548s/iter; left time: 626.1680s\n",
      "\titers: 400, epoch: 8 | loss: 0.0779296\n",
      "\tspeed: 0.0528s/iter; left time: 597.7990s\n",
      "\titers: 500, epoch: 8 | loss: 0.0806055\n",
      "\tspeed: 0.0535s/iter; left time: 601.0736s\n",
      "\titers: 600, epoch: 8 | loss: 0.0807745\n",
      "\tspeed: 0.0514s/iter; left time: 572.0249s\n",
      "\titers: 700, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0503s/iter; left time: 555.0761s\n",
      "\titers: 800, epoch: 8 | loss: 0.0767200\n",
      "\tspeed: 0.0523s/iter; left time: 570.9957s\n",
      "\titers: 900, epoch: 8 | loss: 0.0766900\n",
      "\tspeed: 0.0525s/iter; left time: 568.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0802573 Vali Loss: 0.1368492 Test Loss: 0.1828096\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0760837\n",
      "\tspeed: 0.1425s/iter; left time: 1528.2360s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796131\n",
      "\tspeed: 0.0511s/iter; left time: 542.4394s\n",
      "\titers: 300, epoch: 9 | loss: 0.0798605\n",
      "\tspeed: 0.0527s/iter; left time: 554.6883s\n",
      "\titers: 400, epoch: 9 | loss: 0.0712618\n",
      "\tspeed: 0.0515s/iter; left time: 537.1907s\n",
      "\titers: 500, epoch: 9 | loss: 0.0777337\n",
      "\tspeed: 0.0522s/iter; left time: 539.3689s\n",
      "\titers: 600, epoch: 9 | loss: 0.0738964\n",
      "\tspeed: 0.0515s/iter; left time: 526.6045s\n",
      "\titers: 700, epoch: 9 | loss: 0.0785224\n",
      "\tspeed: 0.0516s/iter; left time: 522.3886s\n",
      "\titers: 800, epoch: 9 | loss: 0.0810030\n",
      "\tspeed: 0.0523s/iter; left time: 524.7185s\n",
      "\titers: 900, epoch: 9 | loss: 0.0730407\n",
      "\tspeed: 0.0526s/iter; left time: 521.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 902 | Train Loss: 0.0763414 Vali Loss: 0.1352318 Test Loss: 0.1789316\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05394035950303078, rmse:0.2322506457567215, mae:0.1633959710597992, rse:0.8051829934120178\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2134379\n",
      "\tspeed: 0.0546s/iter; left time: 980.1405s\n",
      "\titers: 200, epoch: 1 | loss: 0.1971535\n",
      "\tspeed: 0.0527s/iter; left time: 940.0564s\n",
      "\titers: 300, epoch: 1 | loss: 0.1917784\n",
      "\tspeed: 0.0512s/iter; left time: 908.9878s\n",
      "\titers: 400, epoch: 1 | loss: 0.1900738\n",
      "\tspeed: 0.0514s/iter; left time: 906.8844s\n",
      "\titers: 500, epoch: 1 | loss: 0.1847131\n",
      "\tspeed: 0.0529s/iter; left time: 928.6681s\n",
      "\titers: 600, epoch: 1 | loss: 0.1781364\n",
      "\tspeed: 0.0521s/iter; left time: 908.0999s\n",
      "\titers: 700, epoch: 1 | loss: 0.1814755\n",
      "\tspeed: 0.0552s/iter; left time: 957.7139s\n",
      "\titers: 800, epoch: 1 | loss: 0.1737877\n",
      "\tspeed: 0.0519s/iter; left time: 894.5888s\n",
      "\titers: 900, epoch: 1 | loss: 0.1653976\n",
      "\tspeed: 0.0524s/iter; left time: 898.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.63s\n",
      "Steps: 902 | Train Loss: 0.1889060 Vali Loss: 0.1745365 Test Loss: 0.2131111\n",
      "Validation loss decreased (inf --> 0.174537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1515991\n",
      "\tspeed: 0.1439s/iter; left time: 2452.6231s\n",
      "\titers: 200, epoch: 2 | loss: 0.1437050\n",
      "\tspeed: 0.0534s/iter; left time: 904.9235s\n",
      "\titers: 300, epoch: 2 | loss: 0.1358945\n",
      "\tspeed: 0.0518s/iter; left time: 871.8788s\n",
      "\titers: 400, epoch: 2 | loss: 0.1331195\n",
      "\tspeed: 0.0515s/iter; left time: 861.6693s\n",
      "\titers: 500, epoch: 2 | loss: 0.1422927\n",
      "\tspeed: 0.0517s/iter; left time: 860.2230s\n",
      "\titers: 600, epoch: 2 | loss: 0.1329440\n",
      "\tspeed: 0.0531s/iter; left time: 878.1795s\n",
      "\titers: 700, epoch: 2 | loss: 0.1398292\n",
      "\tspeed: 0.0526s/iter; left time: 865.2574s\n",
      "\titers: 800, epoch: 2 | loss: 0.1418460\n",
      "\tspeed: 0.0518s/iter; left time: 845.8023s\n",
      "\titers: 900, epoch: 2 | loss: 0.1426569\n",
      "\tspeed: 0.0515s/iter; left time: 836.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.1400078 Vali Loss: 0.1543211 Test Loss: 0.1984515\n",
      "Validation loss decreased (0.174537 --> 0.154321).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1326267\n",
      "\tspeed: 0.1486s/iter; left time: 2397.9671s\n",
      "\titers: 200, epoch: 3 | loss: 0.1332973\n",
      "\tspeed: 0.0537s/iter; left time: 860.7941s\n",
      "\titers: 300, epoch: 3 | loss: 0.1251836\n",
      "\tspeed: 0.0516s/iter; left time: 821.8738s\n",
      "\titers: 400, epoch: 3 | loss: 0.1309564\n",
      "\tspeed: 0.0518s/iter; left time: 820.7354s\n",
      "\titers: 500, epoch: 3 | loss: 0.1188614\n",
      "\tspeed: 0.0529s/iter; left time: 832.2934s\n",
      "\titers: 600, epoch: 3 | loss: 0.1249987\n",
      "\tspeed: 0.0535s/iter; left time: 836.6307s\n",
      "\titers: 700, epoch: 3 | loss: 0.1272221\n",
      "\tspeed: 0.0503s/iter; left time: 780.8602s\n",
      "\titers: 800, epoch: 3 | loss: 0.1237295\n",
      "\tspeed: 0.0508s/iter; left time: 784.1184s\n",
      "\titers: 900, epoch: 3 | loss: 0.1169028\n",
      "\tspeed: 0.0511s/iter; left time: 783.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.59s\n",
      "Steps: 902 | Train Loss: 0.1270497 Vali Loss: 0.1489277 Test Loss: 0.1829660\n",
      "Validation loss decreased (0.154321 --> 0.148928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1184739\n",
      "\tspeed: 0.1450s/iter; left time: 2209.5418s\n",
      "\titers: 200, epoch: 4 | loss: 0.1167085\n",
      "\tspeed: 0.0522s/iter; left time: 789.6788s\n",
      "\titers: 300, epoch: 4 | loss: 0.1232799\n",
      "\tspeed: 0.0517s/iter; left time: 777.2280s\n",
      "\titers: 400, epoch: 4 | loss: 0.1110598\n",
      "\tspeed: 0.0509s/iter; left time: 759.5673s\n",
      "\titers: 500, epoch: 4 | loss: 0.1131461\n",
      "\tspeed: 0.0519s/iter; left time: 769.6613s\n",
      "\titers: 600, epoch: 4 | loss: 0.1031046\n",
      "\tspeed: 0.0548s/iter; left time: 808.0670s\n",
      "\titers: 700, epoch: 4 | loss: 0.1132229\n",
      "\tspeed: 0.0516s/iter; left time: 755.0190s\n",
      "\titers: 800, epoch: 4 | loss: 0.1058731\n",
      "\tspeed: 0.0514s/iter; left time: 746.6952s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973919\n",
      "\tspeed: 0.0518s/iter; left time: 748.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.1107167 Vali Loss: 0.1337407 Test Loss: 0.1688370\n",
      "Validation loss decreased (0.148928 --> 0.133741).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0961302\n",
      "\tspeed: 0.1466s/iter; left time: 2101.8889s\n",
      "\titers: 200, epoch: 5 | loss: 0.1058981\n",
      "\tspeed: 0.0514s/iter; left time: 731.8937s\n",
      "\titers: 300, epoch: 5 | loss: 0.1043737\n",
      "\tspeed: 0.0524s/iter; left time: 740.5619s\n",
      "\titers: 400, epoch: 5 | loss: 0.1017848\n",
      "\tspeed: 0.0523s/iter; left time: 734.0867s\n",
      "\titers: 500, epoch: 5 | loss: 0.0923788\n",
      "\tspeed: 0.0538s/iter; left time: 749.2453s\n",
      "\titers: 600, epoch: 5 | loss: 0.1001138\n",
      "\tspeed: 0.0535s/iter; left time: 740.2166s\n",
      "\titers: 700, epoch: 5 | loss: 0.0901133\n",
      "\tspeed: 0.0512s/iter; left time: 703.3624s\n",
      "\titers: 800, epoch: 5 | loss: 0.0911202\n",
      "\tspeed: 0.0514s/iter; left time: 701.3377s\n",
      "\titers: 900, epoch: 5 | loss: 0.0951924\n",
      "\tspeed: 0.0517s/iter; left time: 699.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.0978547 Vali Loss: 0.1347397 Test Loss: 0.1750676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916292\n",
      "\tspeed: 0.1457s/iter; left time: 1956.8987s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926998\n",
      "\tspeed: 0.0522s/iter; left time: 695.8473s\n",
      "\titers: 300, epoch: 6 | loss: 0.0945397\n",
      "\tspeed: 0.0524s/iter; left time: 693.5252s\n",
      "\titers: 400, epoch: 6 | loss: 0.0976250\n",
      "\tspeed: 0.0514s/iter; left time: 674.3577s\n",
      "\titers: 500, epoch: 6 | loss: 0.0917374\n",
      "\tspeed: 0.0538s/iter; left time: 701.1080s\n",
      "\titers: 600, epoch: 6 | loss: 0.0943440\n",
      "\tspeed: 0.0524s/iter; left time: 677.6103s\n",
      "\titers: 700, epoch: 6 | loss: 0.0875346\n",
      "\tspeed: 0.0520s/iter; left time: 667.8072s\n",
      "\titers: 800, epoch: 6 | loss: 0.0911442\n",
      "\tspeed: 0.0513s/iter; left time: 652.8994s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831802\n",
      "\tspeed: 0.0508s/iter; left time: 641.1983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.34s\n",
      "Steps: 902 | Train Loss: 0.0912941 Vali Loss: 0.1359846 Test Loss: 0.1837453\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0986938\n",
      "\tspeed: 0.1442s/iter; left time: 1807.2877s\n",
      "\titers: 200, epoch: 7 | loss: 0.0869653\n",
      "\tspeed: 0.0535s/iter; left time: 664.7790s\n",
      "\titers: 300, epoch: 7 | loss: 0.0861455\n",
      "\tspeed: 0.0514s/iter; left time: 633.2277s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878249\n",
      "\tspeed: 0.0509s/iter; left time: 622.1452s\n",
      "\titers: 500, epoch: 7 | loss: 0.0846415\n",
      "\tspeed: 0.0542s/iter; left time: 656.9875s\n",
      "\titers: 600, epoch: 7 | loss: 0.0866977\n",
      "\tspeed: 0.0527s/iter; left time: 634.2609s\n",
      "\titers: 700, epoch: 7 | loss: 0.0845247\n",
      "\tspeed: 0.0520s/iter; left time: 620.5286s\n",
      "\titers: 800, epoch: 7 | loss: 0.0829732\n",
      "\tspeed: 0.0514s/iter; left time: 607.7360s\n",
      "\titers: 900, epoch: 7 | loss: 0.0763239\n",
      "\tspeed: 0.0524s/iter; left time: 614.7106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.0856306 Vali Loss: 0.1405071 Test Loss: 0.1843889\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805372\n",
      "\tspeed: 0.1447s/iter; left time: 1682.0709s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753312\n",
      "\tspeed: 0.0508s/iter; left time: 586.1102s\n",
      "\titers: 300, epoch: 8 | loss: 0.0841432\n",
      "\tspeed: 0.0520s/iter; left time: 594.2269s\n",
      "\titers: 400, epoch: 8 | loss: 0.0836814\n",
      "\tspeed: 0.0528s/iter; left time: 597.5900s\n",
      "\titers: 500, epoch: 8 | loss: 0.0760510\n",
      "\tspeed: 0.0547s/iter; left time: 614.1696s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825711\n",
      "\tspeed: 0.0522s/iter; left time: 580.4889s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778928\n",
      "\tspeed: 0.0532s/iter; left time: 586.9057s\n",
      "\titers: 800, epoch: 8 | loss: 0.0787227\n",
      "\tspeed: 0.0529s/iter; left time: 577.7233s\n",
      "\titers: 900, epoch: 8 | loss: 0.0812062\n",
      "\tspeed: 0.0520s/iter; left time: 563.0336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.72s\n",
      "Steps: 902 | Train Loss: 0.0805182 Vali Loss: 0.1401425 Test Loss: 0.1808053\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0783460\n",
      "\tspeed: 0.1457s/iter; left time: 1562.9836s\n",
      "\titers: 200, epoch: 9 | loss: 0.0771335\n",
      "\tspeed: 0.0519s/iter; left time: 551.4203s\n",
      "\titers: 300, epoch: 9 | loss: 0.0708805\n",
      "\tspeed: 0.0522s/iter; left time: 549.4704s\n",
      "\titers: 400, epoch: 9 | loss: 0.0755136\n",
      "\tspeed: 0.0517s/iter; left time: 538.7829s\n",
      "\titers: 500, epoch: 9 | loss: 0.0766300\n",
      "\tspeed: 0.0525s/iter; left time: 542.4813s\n",
      "\titers: 600, epoch: 9 | loss: 0.0769121\n",
      "\tspeed: 0.0524s/iter; left time: 535.4238s\n",
      "\titers: 700, epoch: 9 | loss: 0.0734445\n",
      "\tspeed: 0.0515s/iter; left time: 521.3565s\n",
      "\titers: 800, epoch: 9 | loss: 0.0742932\n",
      "\tspeed: 0.0528s/iter; left time: 529.1895s\n",
      "\titers: 900, epoch: 9 | loss: 0.0711582\n",
      "\tspeed: 0.0516s/iter; left time: 511.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.0761055 Vali Loss: 0.1382257 Test Loss: 0.1815997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.060001105070114136, rmse:0.24495123326778412, mae:0.1687474101781845, rse:0.8492143154144287\n",
      "Intermediate time for GB and pred_len 168: 00h:17m:13.10s\n",
      "Intermediate time for GB: 00h:49m:34.57s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2225701\n",
      "\tspeed: 0.0727s/iter; left time: 1310.9185s\n",
      "\titers: 200, epoch: 1 | loss: 0.2311551\n",
      "\tspeed: 0.0439s/iter; left time: 786.6421s\n",
      "\titers: 300, epoch: 1 | loss: 0.1908760\n",
      "\tspeed: 0.0430s/iter; left time: 765.7375s\n",
      "\titers: 400, epoch: 1 | loss: 0.1898048\n",
      "\tspeed: 0.0438s/iter; left time: 776.0223s\n",
      "\titers: 500, epoch: 1 | loss: 0.1737094\n",
      "\tspeed: 0.0443s/iter; left time: 779.9809s\n",
      "\titers: 600, epoch: 1 | loss: 0.1705023\n",
      "\tspeed: 0.0436s/iter; left time: 764.7088s\n",
      "\titers: 700, epoch: 1 | loss: 0.1603696\n",
      "\tspeed: 0.0446s/iter; left time: 777.7191s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485734\n",
      "\tspeed: 0.0437s/iter; left time: 756.6431s\n",
      "\titers: 900, epoch: 1 | loss: 0.1428652\n",
      "\tspeed: 0.0332s/iter; left time: 571.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.38s\n",
      "Steps: 906 | Train Loss: 0.1848827 Vali Loss: 0.1115890 Test Loss: 0.1317366\n",
      "Validation loss decreased (inf --> 0.111589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1037941\n",
      "\tspeed: 0.1152s/iter; left time: 1971.9039s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033034\n",
      "\tspeed: 0.0438s/iter; left time: 745.8017s\n",
      "\titers: 300, epoch: 2 | loss: 0.0906658\n",
      "\tspeed: 0.0445s/iter; left time: 751.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.0915393\n",
      "\tspeed: 0.0437s/iter; left time: 735.1874s\n",
      "\titers: 500, epoch: 2 | loss: 0.0821387\n",
      "\tspeed: 0.0404s/iter; left time: 676.1150s\n",
      "\titers: 600, epoch: 2 | loss: 0.0891824\n",
      "\tspeed: 0.0419s/iter; left time: 696.6666s\n",
      "\titers: 700, epoch: 2 | loss: 0.0815542\n",
      "\tspeed: 0.0436s/iter; left time: 720.7095s\n",
      "\titers: 800, epoch: 2 | loss: 0.0823997\n",
      "\tspeed: 0.0445s/iter; left time: 730.3242s\n",
      "\titers: 900, epoch: 2 | loss: 0.0749999\n",
      "\tspeed: 0.0444s/iter; left time: 724.8776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 906 | Train Loss: 0.0931591 Vali Loss: 0.0782987 Test Loss: 0.1036240\n",
      "Validation loss decreased (0.111589 --> 0.078299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846602\n",
      "\tspeed: 0.1074s/iter; left time: 1740.3452s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805954\n",
      "\tspeed: 0.0402s/iter; left time: 647.2998s\n",
      "\titers: 300, epoch: 3 | loss: 0.0780625\n",
      "\tspeed: 0.0367s/iter; left time: 587.7092s\n",
      "\titers: 400, epoch: 3 | loss: 0.0678523\n",
      "\tspeed: 0.0447s/iter; left time: 711.1884s\n",
      "\titers: 500, epoch: 3 | loss: 0.0754667\n",
      "\tspeed: 0.0446s/iter; left time: 705.7935s\n",
      "\titers: 600, epoch: 3 | loss: 0.0654097\n",
      "\tspeed: 0.0436s/iter; left time: 684.1337s\n",
      "\titers: 700, epoch: 3 | loss: 0.0704309\n",
      "\tspeed: 0.0427s/iter; left time: 666.1056s\n",
      "\titers: 800, epoch: 3 | loss: 0.0754049\n",
      "\tspeed: 0.0441s/iter; left time: 684.0873s\n",
      "\titers: 900, epoch: 3 | loss: 0.0711015\n",
      "\tspeed: 0.0414s/iter; left time: 638.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 906 | Train Loss: 0.0721747 Vali Loss: 0.0701697 Test Loss: 0.0977866\n",
      "Validation loss decreased (0.078299 --> 0.070170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676409\n",
      "\tspeed: 0.1091s/iter; left time: 1670.0650s\n",
      "\titers: 200, epoch: 4 | loss: 0.0728024\n",
      "\tspeed: 0.0423s/iter; left time: 643.2116s\n",
      "\titers: 300, epoch: 4 | loss: 0.0679015\n",
      "\tspeed: 0.0448s/iter; left time: 676.8852s\n",
      "\titers: 400, epoch: 4 | loss: 0.0694085\n",
      "\tspeed: 0.0426s/iter; left time: 638.4820s\n",
      "\titers: 500, epoch: 4 | loss: 0.0613866\n",
      "\tspeed: 0.0415s/iter; left time: 618.9653s\n",
      "\titers: 600, epoch: 4 | loss: 0.0619529\n",
      "\tspeed: 0.0421s/iter; left time: 623.3358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0728609\n",
      "\tspeed: 0.0424s/iter; left time: 623.2545s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630194\n",
      "\tspeed: 0.0436s/iter; left time: 636.1329s\n",
      "\titers: 900, epoch: 4 | loss: 0.0703440\n",
      "\tspeed: 0.0443s/iter; left time: 642.0026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.26s\n",
      "Steps: 906 | Train Loss: 0.0664020 Vali Loss: 0.0661063 Test Loss: 0.0966524\n",
      "Validation loss decreased (0.070170 --> 0.066106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0660200\n",
      "\tspeed: 0.1053s/iter; left time: 1515.7127s\n",
      "\titers: 200, epoch: 5 | loss: 0.0623797\n",
      "\tspeed: 0.0418s/iter; left time: 597.9801s\n",
      "\titers: 300, epoch: 5 | loss: 0.0559764\n",
      "\tspeed: 0.0424s/iter; left time: 602.5398s\n",
      "\titers: 400, epoch: 5 | loss: 0.0630376\n",
      "\tspeed: 0.0425s/iter; left time: 599.2109s\n",
      "\titers: 500, epoch: 5 | loss: 0.0590218\n",
      "\tspeed: 0.0433s/iter; left time: 605.6838s\n",
      "\titers: 600, epoch: 5 | loss: 0.0610482\n",
      "\tspeed: 0.0339s/iter; left time: 470.5150s\n",
      "\titers: 700, epoch: 5 | loss: 0.0674176\n",
      "\tspeed: 0.0351s/iter; left time: 484.3692s\n",
      "\titers: 800, epoch: 5 | loss: 0.0588276\n",
      "\tspeed: 0.0338s/iter; left time: 463.3978s\n",
      "\titers: 900, epoch: 5 | loss: 0.0639992\n",
      "\tspeed: 0.0337s/iter; left time: 458.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:35.15s\n",
      "Steps: 906 | Train Loss: 0.0626899 Vali Loss: 0.0615744 Test Loss: 0.0916710\n",
      "Validation loss decreased (0.066106 --> 0.061574).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637254\n",
      "\tspeed: 0.1109s/iter; left time: 1495.9127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539645\n",
      "\tspeed: 0.0452s/iter; left time: 604.9319s\n",
      "\titers: 300, epoch: 6 | loss: 0.0630191\n",
      "\tspeed: 0.0418s/iter; left time: 556.1302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0613206\n",
      "\tspeed: 0.0450s/iter; left time: 593.1957s\n",
      "\titers: 500, epoch: 6 | loss: 0.0591853\n",
      "\tspeed: 0.0443s/iter; left time: 579.8375s\n",
      "\titers: 600, epoch: 6 | loss: 0.0613972\n",
      "\tspeed: 0.0436s/iter; left time: 566.2449s\n",
      "\titers: 700, epoch: 6 | loss: 0.0573764\n",
      "\tspeed: 0.0419s/iter; left time: 539.7953s\n",
      "\titers: 800, epoch: 6 | loss: 0.0631472\n",
      "\tspeed: 0.0444s/iter; left time: 567.6297s\n",
      "\titers: 900, epoch: 6 | loss: 0.0627898\n",
      "\tspeed: 0.0434s/iter; left time: 550.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 906 | Train Loss: 0.0592335 Vali Loss: 0.0626371 Test Loss: 0.0960112\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577794\n",
      "\tspeed: 0.1036s/iter; left time: 1303.2274s\n",
      "\titers: 200, epoch: 7 | loss: 0.0618888\n",
      "\tspeed: 0.0433s/iter; left time: 540.1234s\n",
      "\titers: 300, epoch: 7 | loss: 0.0594594\n",
      "\tspeed: 0.0445s/iter; left time: 551.1106s\n",
      "\titers: 400, epoch: 7 | loss: 0.0554541\n",
      "\tspeed: 0.0424s/iter; left time: 520.5314s\n",
      "\titers: 500, epoch: 7 | loss: 0.0584475\n",
      "\tspeed: 0.0428s/iter; left time: 520.9703s\n",
      "\titers: 600, epoch: 7 | loss: 0.0496468\n",
      "\tspeed: 0.0449s/iter; left time: 542.7406s\n",
      "\titers: 700, epoch: 7 | loss: 0.0529550\n",
      "\tspeed: 0.0450s/iter; left time: 539.8121s\n",
      "\titers: 800, epoch: 7 | loss: 0.0549940\n",
      "\tspeed: 0.0430s/iter; left time: 511.3768s\n",
      "\titers: 900, epoch: 7 | loss: 0.0590899\n",
      "\tspeed: 0.0440s/iter; left time: 519.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 906 | Train Loss: 0.0570599 Vali Loss: 0.0583242 Test Loss: 0.0939164\n",
      "Validation loss decreased (0.061574 --> 0.058324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0526088\n",
      "\tspeed: 0.1114s/iter; left time: 1301.2578s\n",
      "\titers: 200, epoch: 8 | loss: 0.0522844\n",
      "\tspeed: 0.0437s/iter; left time: 506.5009s\n",
      "\titers: 300, epoch: 8 | loss: 0.0492625\n",
      "\tspeed: 0.0443s/iter; left time: 508.7455s\n",
      "\titers: 400, epoch: 8 | loss: 0.0537116\n",
      "\tspeed: 0.0441s/iter; left time: 502.1380s\n",
      "\titers: 500, epoch: 8 | loss: 0.0549990\n",
      "\tspeed: 0.0442s/iter; left time: 499.0563s\n",
      "\titers: 600, epoch: 8 | loss: 0.0550420\n",
      "\tspeed: 0.0441s/iter; left time: 492.5384s\n",
      "\titers: 700, epoch: 8 | loss: 0.0603805\n",
      "\tspeed: 0.0423s/iter; left time: 468.2148s\n",
      "\titers: 800, epoch: 8 | loss: 0.0563873\n",
      "\tspeed: 0.0432s/iter; left time: 473.8128s\n",
      "\titers: 900, epoch: 8 | loss: 0.0567774\n",
      "\tspeed: 0.0441s/iter; left time: 480.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.0550604 Vali Loss: 0.0584201 Test Loss: 0.1015700\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0514966\n",
      "\tspeed: 0.1069s/iter; left time: 1151.7819s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532569\n",
      "\tspeed: 0.0438s/iter; left time: 467.8942s\n",
      "\titers: 300, epoch: 9 | loss: 0.0562458\n",
      "\tspeed: 0.0438s/iter; left time: 463.4605s\n",
      "\titers: 400, epoch: 9 | loss: 0.0574775\n",
      "\tspeed: 0.0411s/iter; left time: 429.9765s\n",
      "\titers: 500, epoch: 9 | loss: 0.0569222\n",
      "\tspeed: 0.0432s/iter; left time: 447.8125s\n",
      "\titers: 600, epoch: 9 | loss: 0.0562265\n",
      "\tspeed: 0.0443s/iter; left time: 454.7354s\n",
      "\titers: 700, epoch: 9 | loss: 0.0513619\n",
      "\tspeed: 0.0445s/iter; left time: 452.5811s\n",
      "\titers: 800, epoch: 9 | loss: 0.0531737\n",
      "\tspeed: 0.0445s/iter; left time: 448.1868s\n",
      "\titers: 900, epoch: 9 | loss: 0.0442144\n",
      "\tspeed: 0.0437s/iter; left time: 435.8113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.80s\n",
      "Steps: 906 | Train Loss: 0.0536022 Vali Loss: 0.0577300 Test Loss: 0.0931803\n",
      "Validation loss decreased (0.058324 --> 0.057730).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0552977\n",
      "\tspeed: 0.1108s/iter; left time: 1092.7721s\n",
      "\titers: 200, epoch: 10 | loss: 0.0540405\n",
      "\tspeed: 0.0439s/iter; left time: 429.2381s\n",
      "\titers: 300, epoch: 10 | loss: 0.0559633\n",
      "\tspeed: 0.0442s/iter; left time: 427.1885s\n",
      "\titers: 400, epoch: 10 | loss: 0.0634846\n",
      "\tspeed: 0.0411s/iter; left time: 392.7908s\n",
      "\titers: 500, epoch: 10 | loss: 0.0543671\n",
      "\tspeed: 0.0368s/iter; left time: 348.4556s\n",
      "\titers: 600, epoch: 10 | loss: 0.0492467\n",
      "\tspeed: 0.0451s/iter; left time: 422.2585s\n",
      "\titers: 700, epoch: 10 | loss: 0.0576616\n",
      "\tspeed: 0.0446s/iter; left time: 413.7546s\n",
      "\titers: 800, epoch: 10 | loss: 0.0450681\n",
      "\tspeed: 0.0445s/iter; left time: 408.3804s\n",
      "\titers: 900, epoch: 10 | loss: 0.0514902\n",
      "\tspeed: 0.0445s/iter; left time: 403.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.36s\n",
      "Steps: 906 | Train Loss: 0.0522438 Vali Loss: 0.0580221 Test Loss: 0.0941721\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514877\n",
      "\tspeed: 0.1046s/iter; left time: 937.0919s\n",
      "\titers: 200, epoch: 11 | loss: 0.0466050\n",
      "\tspeed: 0.0414s/iter; left time: 366.9040s\n",
      "\titers: 300, epoch: 11 | loss: 0.0494588\n",
      "\tspeed: 0.0443s/iter; left time: 387.8879s\n",
      "\titers: 400, epoch: 11 | loss: 0.0483637\n",
      "\tspeed: 0.0434s/iter; left time: 375.5540s\n",
      "\titers: 500, epoch: 11 | loss: 0.0525916\n",
      "\tspeed: 0.0412s/iter; left time: 352.3961s\n",
      "\titers: 600, epoch: 11 | loss: 0.0529519\n",
      "\tspeed: 0.0445s/iter; left time: 376.4178s\n",
      "\titers: 700, epoch: 11 | loss: 0.0522642\n",
      "\tspeed: 0.0391s/iter; left time: 326.8741s\n",
      "\titers: 800, epoch: 11 | loss: 0.0520713\n",
      "\tspeed: 0.0401s/iter; left time: 330.9780s\n",
      "\titers: 900, epoch: 11 | loss: 0.0516929\n",
      "\tspeed: 0.0432s/iter; left time: 352.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.0511752 Vali Loss: 0.0579007 Test Loss: 0.0985341\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0533170\n",
      "\tspeed: 0.1059s/iter; left time: 853.2523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521227\n",
      "\tspeed: 0.0443s/iter; left time: 352.4597s\n",
      "\titers: 300, epoch: 12 | loss: 0.0496030\n",
      "\tspeed: 0.0444s/iter; left time: 348.7598s\n",
      "\titers: 400, epoch: 12 | loss: 0.0584046\n",
      "\tspeed: 0.0436s/iter; left time: 338.0204s\n",
      "\titers: 500, epoch: 12 | loss: 0.0521255\n",
      "\tspeed: 0.0445s/iter; left time: 340.4598s\n",
      "\titers: 600, epoch: 12 | loss: 0.0469644\n",
      "\tspeed: 0.0442s/iter; left time: 333.6560s\n",
      "\titers: 700, epoch: 12 | loss: 0.0461116\n",
      "\tspeed: 0.0440s/iter; left time: 327.6579s\n",
      "\titers: 800, epoch: 12 | loss: 0.0504953\n",
      "\tspeed: 0.0437s/iter; left time: 321.6752s\n",
      "\titers: 900, epoch: 12 | loss: 0.0466300\n",
      "\tspeed: 0.0442s/iter; left time: 320.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 906 | Train Loss: 0.0499998 Vali Loss: 0.0585769 Test Loss: 0.1037559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465140\n",
      "\tspeed: 0.1053s/iter; left time: 752.7390s\n",
      "\titers: 200, epoch: 13 | loss: 0.0493444\n",
      "\tspeed: 0.0443s/iter; left time: 312.5628s\n",
      "\titers: 300, epoch: 13 | loss: 0.0551908\n",
      "\tspeed: 0.0439s/iter; left time: 305.3742s\n",
      "\titers: 400, epoch: 13 | loss: 0.0452325\n",
      "\tspeed: 0.0444s/iter; left time: 304.4194s\n",
      "\titers: 500, epoch: 13 | loss: 0.0501908\n",
      "\tspeed: 0.0439s/iter; left time: 296.1353s\n",
      "\titers: 600, epoch: 13 | loss: 0.0472432\n",
      "\tspeed: 0.0439s/iter; left time: 291.8602s\n",
      "\titers: 700, epoch: 13 | loss: 0.0494244\n",
      "\tspeed: 0.0435s/iter; left time: 284.6929s\n",
      "\titers: 800, epoch: 13 | loss: 0.0481905\n",
      "\tspeed: 0.0447s/iter; left time: 288.1406s\n",
      "\titers: 900, epoch: 13 | loss: 0.0470515\n",
      "\tspeed: 0.0438s/iter; left time: 277.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 906 | Train Loss: 0.0489971 Vali Loss: 0.0568892 Test Loss: 0.0995678\n",
      "Validation loss decreased (0.057730 --> 0.056889).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0508224\n",
      "\tspeed: 0.1092s/iter; left time: 681.6769s\n",
      "\titers: 200, epoch: 14 | loss: 0.0500584\n",
      "\tspeed: 0.0430s/iter; left time: 264.2501s\n",
      "\titers: 300, epoch: 14 | loss: 0.0461346\n",
      "\tspeed: 0.0414s/iter; left time: 250.2527s\n",
      "\titers: 400, epoch: 14 | loss: 0.0485840\n",
      "\tspeed: 0.0433s/iter; left time: 257.4673s\n",
      "\titers: 500, epoch: 14 | loss: 0.0415537\n",
      "\tspeed: 0.0433s/iter; left time: 253.0303s\n",
      "\titers: 600, epoch: 14 | loss: 0.0460557\n",
      "\tspeed: 0.0431s/iter; left time: 247.4043s\n",
      "\titers: 700, epoch: 14 | loss: 0.0503677\n",
      "\tspeed: 0.0441s/iter; left time: 248.7186s\n",
      "\titers: 800, epoch: 14 | loss: 0.0574076\n",
      "\tspeed: 0.0427s/iter; left time: 236.4133s\n",
      "\titers: 900, epoch: 14 | loss: 0.0483416\n",
      "\tspeed: 0.0430s/iter; left time: 233.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.17s\n",
      "Steps: 906 | Train Loss: 0.0481233 Vali Loss: 0.0570113 Test Loss: 0.1011703\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0470948\n",
      "\tspeed: 0.1063s/iter; left time: 567.2351s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453737\n",
      "\tspeed: 0.0436s/iter; left time: 228.2719s\n",
      "\titers: 300, epoch: 15 | loss: 0.0432208\n",
      "\tspeed: 0.0441s/iter; left time: 226.3564s\n",
      "\titers: 400, epoch: 15 | loss: 0.0495395\n",
      "\tspeed: 0.0437s/iter; left time: 220.2631s\n",
      "\titers: 500, epoch: 15 | loss: 0.0489155\n",
      "\tspeed: 0.0412s/iter; left time: 203.2721s\n",
      "\titers: 600, epoch: 15 | loss: 0.0499997\n",
      "\tspeed: 0.0424s/iter; left time: 205.0388s\n",
      "\titers: 700, epoch: 15 | loss: 0.0444094\n",
      "\tspeed: 0.0412s/iter; left time: 195.1046s\n",
      "\titers: 800, epoch: 15 | loss: 0.0409945\n",
      "\tspeed: 0.0439s/iter; left time: 203.7290s\n",
      "\titers: 900, epoch: 15 | loss: 0.0468104\n",
      "\tspeed: 0.0418s/iter; left time: 189.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.06s\n",
      "Steps: 906 | Train Loss: 0.0473649 Vali Loss: 0.0571158 Test Loss: 0.1002323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541349\n",
      "\tspeed: 0.1065s/iter; left time: 471.6943s\n",
      "\titers: 200, epoch: 16 | loss: 0.0523621\n",
      "\tspeed: 0.0447s/iter; left time: 193.6216s\n",
      "\titers: 300, epoch: 16 | loss: 0.0414441\n",
      "\tspeed: 0.0435s/iter; left time: 184.1119s\n",
      "\titers: 400, epoch: 16 | loss: 0.0472221\n",
      "\tspeed: 0.0443s/iter; left time: 183.0606s\n",
      "\titers: 500, epoch: 16 | loss: 0.0470437\n",
      "\tspeed: 0.0445s/iter; left time: 179.2041s\n",
      "\titers: 600, epoch: 16 | loss: 0.0411740\n",
      "\tspeed: 0.0409s/iter; left time: 160.6773s\n",
      "\titers: 700, epoch: 16 | loss: 0.0513565\n",
      "\tspeed: 0.0421s/iter; left time: 161.1572s\n",
      "\titers: 800, epoch: 16 | loss: 0.0425249\n",
      "\tspeed: 0.0416s/iter; left time: 155.3568s\n",
      "\titers: 900, epoch: 16 | loss: 0.0494811\n",
      "\tspeed: 0.0416s/iter; left time: 151.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.20s\n",
      "Steps: 906 | Train Loss: 0.0464900 Vali Loss: 0.0573784 Test Loss: 0.1039492\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0428713\n",
      "\tspeed: 0.1056s/iter; left time: 372.2612s\n",
      "\titers: 200, epoch: 17 | loss: 0.0463484\n",
      "\tspeed: 0.0429s/iter; left time: 146.9456s\n",
      "\titers: 300, epoch: 17 | loss: 0.0401853\n",
      "\tspeed: 0.0403s/iter; left time: 133.9143s\n",
      "\titers: 400, epoch: 17 | loss: 0.0488955\n",
      "\tspeed: 0.0422s/iter; left time: 136.2322s\n",
      "\titers: 500, epoch: 17 | loss: 0.0493908\n",
      "\tspeed: 0.0446s/iter; left time: 139.3483s\n",
      "\titers: 600, epoch: 17 | loss: 0.0440601\n",
      "\tspeed: 0.0445s/iter; left time: 134.5869s\n",
      "\titers: 700, epoch: 17 | loss: 0.0442597\n",
      "\tspeed: 0.0448s/iter; left time: 130.9255s\n",
      "\titers: 800, epoch: 17 | loss: 0.0541522\n",
      "\tspeed: 0.0436s/iter; left time: 123.0634s\n",
      "\titers: 900, epoch: 17 | loss: 0.0446799\n",
      "\tspeed: 0.0437s/iter; left time: 118.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.51s\n",
      "Steps: 906 | Train Loss: 0.0457837 Vali Loss: 0.0572614 Test Loss: 0.1043900\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0476238\n",
      "\tspeed: 0.0962s/iter; left time: 251.9674s\n",
      "\titers: 200, epoch: 18 | loss: 0.0440719\n",
      "\tspeed: 0.0380s/iter; left time: 95.6193s\n",
      "\titers: 300, epoch: 18 | loss: 0.0421719\n",
      "\tspeed: 0.0439s/iter; left time: 106.1420s\n",
      "\titers: 400, epoch: 18 | loss: 0.0431837\n",
      "\tspeed: 0.0422s/iter; left time: 97.9044s\n",
      "\titers: 500, epoch: 18 | loss: 0.0495908\n",
      "\tspeed: 0.0430s/iter; left time: 95.3876s\n",
      "\titers: 600, epoch: 18 | loss: 0.0416300\n",
      "\tspeed: 0.0436s/iter; left time: 92.3151s\n",
      "\titers: 700, epoch: 18 | loss: 0.0489602\n",
      "\tspeed: 0.0443s/iter; left time: 89.4259s\n",
      "\titers: 800, epoch: 18 | loss: 0.0421391\n",
      "\tspeed: 0.0429s/iter; left time: 82.3183s\n",
      "\titers: 900, epoch: 18 | loss: 0.0424431\n",
      "\tspeed: 0.0433s/iter; left time: 78.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.0453538 Vali Loss: 0.0578796 Test Loss: 0.1050055\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028536172583699226, rmse:0.16892653703689575, mae:0.09957146644592285, rse:0.4963572025299072\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2313316\n",
      "\tspeed: 0.0443s/iter; left time: 798.8098s\n",
      "\titers: 200, epoch: 1 | loss: 0.2083366\n",
      "\tspeed: 0.0444s/iter; left time: 796.5518s\n",
      "\titers: 300, epoch: 1 | loss: 0.2007164\n",
      "\tspeed: 0.0444s/iter; left time: 792.1386s\n",
      "\titers: 400, epoch: 1 | loss: 0.1766935\n",
      "\tspeed: 0.0438s/iter; left time: 776.5220s\n",
      "\titers: 500, epoch: 1 | loss: 0.1663704\n",
      "\tspeed: 0.0439s/iter; left time: 773.8722s\n",
      "\titers: 600, epoch: 1 | loss: 0.1537390\n",
      "\tspeed: 0.0354s/iter; left time: 619.4099s\n",
      "\titers: 700, epoch: 1 | loss: 0.1531670\n",
      "\tspeed: 0.0386s/iter; left time: 672.2683s\n",
      "\titers: 800, epoch: 1 | loss: 0.1397817\n",
      "\tspeed: 0.0386s/iter; left time: 667.7462s\n",
      "\titers: 900, epoch: 1 | loss: 0.1367912\n",
      "\tspeed: 0.0409s/iter; left time: 704.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1826177 Vali Loss: 0.1168092 Test Loss: 0.1326445\n",
      "Validation loss decreased (inf --> 0.116809).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1116118\n",
      "\tspeed: 0.1068s/iter; left time: 1827.2371s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123900\n",
      "\tspeed: 0.0402s/iter; left time: 684.4131s\n",
      "\titers: 300, epoch: 2 | loss: 0.0865321\n",
      "\tspeed: 0.0449s/iter; left time: 758.9397s\n",
      "\titers: 400, epoch: 2 | loss: 0.0858704\n",
      "\tspeed: 0.0452s/iter; left time: 759.6655s\n",
      "\titers: 500, epoch: 2 | loss: 0.0826757\n",
      "\tspeed: 0.0451s/iter; left time: 754.2646s\n",
      "\titers: 600, epoch: 2 | loss: 0.0818717\n",
      "\tspeed: 0.0445s/iter; left time: 740.0103s\n",
      "\titers: 700, epoch: 2 | loss: 0.0779352\n",
      "\tspeed: 0.0439s/iter; left time: 725.2402s\n",
      "\titers: 800, epoch: 2 | loss: 0.0921536\n",
      "\tspeed: 0.0425s/iter; left time: 697.0326s\n",
      "\titers: 900, epoch: 2 | loss: 0.0730876\n",
      "\tspeed: 0.0405s/iter; left time: 661.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.25s\n",
      "Steps: 906 | Train Loss: 0.0939332 Vali Loss: 0.0757749 Test Loss: 0.0978310\n",
      "Validation loss decreased (0.116809 --> 0.075775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0707570\n",
      "\tspeed: 0.1104s/iter; left time: 1789.0318s\n",
      "\titers: 200, epoch: 3 | loss: 0.0873234\n",
      "\tspeed: 0.0441s/iter; left time: 710.5997s\n",
      "\titers: 300, epoch: 3 | loss: 0.0727585\n",
      "\tspeed: 0.0412s/iter; left time: 659.4728s\n",
      "\titers: 400, epoch: 3 | loss: 0.0726301\n",
      "\tspeed: 0.0416s/iter; left time: 661.2546s\n",
      "\titers: 500, epoch: 3 | loss: 0.0729856\n",
      "\tspeed: 0.0416s/iter; left time: 658.1341s\n",
      "\titers: 600, epoch: 3 | loss: 0.0740381\n",
      "\tspeed: 0.0422s/iter; left time: 663.0867s\n",
      "\titers: 700, epoch: 3 | loss: 0.0687820\n",
      "\tspeed: 0.0410s/iter; left time: 639.3882s\n",
      "\titers: 800, epoch: 3 | loss: 0.0763161\n",
      "\tspeed: 0.0418s/iter; left time: 647.7640s\n",
      "\titers: 900, epoch: 3 | loss: 0.0734477\n",
      "\tspeed: 0.0412s/iter; left time: 635.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 906 | Train Loss: 0.0723015 Vali Loss: 0.0702711 Test Loss: 0.0914330\n",
      "Validation loss decreased (0.075775 --> 0.070271).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619542\n",
      "\tspeed: 0.1129s/iter; left time: 1727.7937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0599128\n",
      "\tspeed: 0.0436s/iter; left time: 663.2738s\n",
      "\titers: 300, epoch: 4 | loss: 0.0723603\n",
      "\tspeed: 0.0445s/iter; left time: 671.9057s\n",
      "\titers: 400, epoch: 4 | loss: 0.0708914\n",
      "\tspeed: 0.0450s/iter; left time: 675.0391s\n",
      "\titers: 500, epoch: 4 | loss: 0.0703685\n",
      "\tspeed: 0.0426s/iter; left time: 635.3699s\n",
      "\titers: 600, epoch: 4 | loss: 0.0644621\n",
      "\tspeed: 0.0410s/iter; left time: 607.2016s\n",
      "\titers: 700, epoch: 4 | loss: 0.0626157\n",
      "\tspeed: 0.0449s/iter; left time: 659.7139s\n",
      "\titers: 800, epoch: 4 | loss: 0.0553676\n",
      "\tspeed: 0.0458s/iter; left time: 669.4363s\n",
      "\titers: 900, epoch: 4 | loss: 0.0617898\n",
      "\tspeed: 0.0445s/iter; left time: 645.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.0659040 Vali Loss: 0.0740883 Test Loss: 0.0980233\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598068\n",
      "\tspeed: 0.1086s/iter; left time: 1563.6838s\n",
      "\titers: 200, epoch: 5 | loss: 0.0649589\n",
      "\tspeed: 0.0444s/iter; left time: 634.5112s\n",
      "\titers: 300, epoch: 5 | loss: 0.0586884\n",
      "\tspeed: 0.0445s/iter; left time: 632.1882s\n",
      "\titers: 400, epoch: 5 | loss: 0.0771512\n",
      "\tspeed: 0.0405s/iter; left time: 571.2332s\n",
      "\titers: 500, epoch: 5 | loss: 0.0645529\n",
      "\tspeed: 0.0369s/iter; left time: 516.0967s\n",
      "\titers: 600, epoch: 5 | loss: 0.0685468\n",
      "\tspeed: 0.0448s/iter; left time: 623.0498s\n",
      "\titers: 700, epoch: 5 | loss: 0.0685796\n",
      "\tspeed: 0.0456s/iter; left time: 629.0955s\n",
      "\titers: 800, epoch: 5 | loss: 0.0585045\n",
      "\tspeed: 0.0443s/iter; left time: 606.3994s\n",
      "\titers: 900, epoch: 5 | loss: 0.0589975\n",
      "\tspeed: 0.0381s/iter; left time: 518.3554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 906 | Train Loss: 0.0619781 Vali Loss: 0.0643090 Test Loss: 0.0918030\n",
      "Validation loss decreased (0.070271 --> 0.064309).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0677534\n",
      "\tspeed: 0.1137s/iter; left time: 1533.6194s\n",
      "\titers: 200, epoch: 6 | loss: 0.0530176\n",
      "\tspeed: 0.0456s/iter; left time: 610.4104s\n",
      "\titers: 300, epoch: 6 | loss: 0.0548486\n",
      "\tspeed: 0.0456s/iter; left time: 605.8501s\n",
      "\titers: 400, epoch: 6 | loss: 0.0547553\n",
      "\tspeed: 0.0463s/iter; left time: 611.4028s\n",
      "\titers: 500, epoch: 6 | loss: 0.0612377\n",
      "\tspeed: 0.0450s/iter; left time: 589.1144s\n",
      "\titers: 600, epoch: 6 | loss: 0.0533771\n",
      "\tspeed: 0.0443s/iter; left time: 576.0056s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555436\n",
      "\tspeed: 0.0425s/iter; left time: 547.8653s\n",
      "\titers: 800, epoch: 6 | loss: 0.0503458\n",
      "\tspeed: 0.0425s/iter; left time: 543.2555s\n",
      "\titers: 900, epoch: 6 | loss: 0.0532720\n",
      "\tspeed: 0.0434s/iter; left time: 551.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.56s\n",
      "Steps: 906 | Train Loss: 0.0591056 Vali Loss: 0.0622354 Test Loss: 0.0924892\n",
      "Validation loss decreased (0.064309 --> 0.062235).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528733\n",
      "\tspeed: 0.1125s/iter; left time: 1415.3072s\n",
      "\titers: 200, epoch: 7 | loss: 0.0529910\n",
      "\tspeed: 0.0446s/iter; left time: 556.4089s\n",
      "\titers: 300, epoch: 7 | loss: 0.0598943\n",
      "\tspeed: 0.0438s/iter; left time: 542.9925s\n",
      "\titers: 400, epoch: 7 | loss: 0.0604081\n",
      "\tspeed: 0.0433s/iter; left time: 531.8548s\n",
      "\titers: 500, epoch: 7 | loss: 0.0523877\n",
      "\tspeed: 0.0442s/iter; left time: 538.9786s\n",
      "\titers: 600, epoch: 7 | loss: 0.0515208\n",
      "\tspeed: 0.0426s/iter; left time: 514.7054s\n",
      "\titers: 700, epoch: 7 | loss: 0.0524358\n",
      "\tspeed: 0.0420s/iter; left time: 502.8734s\n",
      "\titers: 800, epoch: 7 | loss: 0.0512721\n",
      "\tspeed: 0.0439s/iter; left time: 521.8643s\n",
      "\titers: 900, epoch: 7 | loss: 0.0596220\n",
      "\tspeed: 0.0430s/iter; left time: 506.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.65s\n",
      "Steps: 906 | Train Loss: 0.0569564 Vali Loss: 0.0586430 Test Loss: 0.0882417\n",
      "Validation loss decreased (0.062235 --> 0.058643).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0517399\n",
      "\tspeed: 0.1236s/iter; left time: 1443.9657s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589598\n",
      "\tspeed: 0.0444s/iter; left time: 514.2482s\n",
      "\titers: 300, epoch: 8 | loss: 0.0577127\n",
      "\tspeed: 0.0414s/iter; left time: 474.9538s\n",
      "\titers: 400, epoch: 8 | loss: 0.0532096\n",
      "\tspeed: 0.0430s/iter; left time: 489.5803s\n",
      "\titers: 500, epoch: 8 | loss: 0.0528615\n",
      "\tspeed: 0.0449s/iter; left time: 506.1521s\n",
      "\titers: 600, epoch: 8 | loss: 0.0566781\n",
      "\tspeed: 0.0429s/iter; left time: 479.3895s\n",
      "\titers: 700, epoch: 8 | loss: 0.0528790\n",
      "\tspeed: 0.0443s/iter; left time: 490.4175s\n",
      "\titers: 800, epoch: 8 | loss: 0.0491190\n",
      "\tspeed: 0.0362s/iter; left time: 397.1890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0502336\n",
      "\tspeed: 0.0435s/iter; left time: 472.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.86s\n",
      "Steps: 906 | Train Loss: 0.0550019 Vali Loss: 0.0594650 Test Loss: 0.0909620\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0540753\n",
      "\tspeed: 0.0977s/iter; left time: 1052.1611s\n",
      "\titers: 200, epoch: 9 | loss: 0.0531044\n",
      "\tspeed: 0.0337s/iter; left time: 359.7026s\n",
      "\titers: 300, epoch: 9 | loss: 0.0522201\n",
      "\tspeed: 0.0383s/iter; left time: 404.8255s\n",
      "\titers: 400, epoch: 9 | loss: 0.0586018\n",
      "\tspeed: 0.0455s/iter; left time: 476.4605s\n",
      "\titers: 500, epoch: 9 | loss: 0.0518451\n",
      "\tspeed: 0.0428s/iter; left time: 443.8353s\n",
      "\titers: 600, epoch: 9 | loss: 0.0535643\n",
      "\tspeed: 0.0420s/iter; left time: 431.5549s\n",
      "\titers: 700, epoch: 9 | loss: 0.0501714\n",
      "\tspeed: 0.0424s/iter; left time: 431.6363s\n",
      "\titers: 800, epoch: 9 | loss: 0.0548880\n",
      "\tspeed: 0.0429s/iter; left time: 432.4512s\n",
      "\titers: 900, epoch: 9 | loss: 0.0576162\n",
      "\tspeed: 0.0409s/iter; left time: 407.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.79s\n",
      "Steps: 906 | Train Loss: 0.0536402 Vali Loss: 0.0601242 Test Loss: 0.0902880\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0518997\n",
      "\tspeed: 0.1075s/iter; left time: 1060.5678s\n",
      "\titers: 200, epoch: 10 | loss: 0.0513844\n",
      "\tspeed: 0.0431s/iter; left time: 420.5070s\n",
      "\titers: 300, epoch: 10 | loss: 0.0480083\n",
      "\tspeed: 0.0439s/iter; left time: 424.2366s\n",
      "\titers: 400, epoch: 10 | loss: 0.0492702\n",
      "\tspeed: 0.0433s/iter; left time: 414.0125s\n",
      "\titers: 500, epoch: 10 | loss: 0.0519252\n",
      "\tspeed: 0.0435s/iter; left time: 411.8603s\n",
      "\titers: 600, epoch: 10 | loss: 0.0542450\n",
      "\tspeed: 0.0427s/iter; left time: 399.5325s\n",
      "\titers: 700, epoch: 10 | loss: 0.0535993\n",
      "\tspeed: 0.0419s/iter; left time: 388.2285s\n",
      "\titers: 800, epoch: 10 | loss: 0.0548232\n",
      "\tspeed: 0.0405s/iter; left time: 371.5101s\n",
      "\titers: 900, epoch: 10 | loss: 0.0558516\n",
      "\tspeed: 0.0425s/iter; left time: 385.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.00s\n",
      "Steps: 906 | Train Loss: 0.0521639 Vali Loss: 0.0586735 Test Loss: 0.0904036\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0520976\n",
      "\tspeed: 0.1082s/iter; left time: 969.6206s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546211\n",
      "\tspeed: 0.0438s/iter; left time: 387.6893s\n",
      "\titers: 300, epoch: 11 | loss: 0.0537416\n",
      "\tspeed: 0.0452s/iter; left time: 395.9296s\n",
      "\titers: 400, epoch: 11 | loss: 0.0576245\n",
      "\tspeed: 0.0439s/iter; left time: 380.5025s\n",
      "\titers: 500, epoch: 11 | loss: 0.0557026\n",
      "\tspeed: 0.0430s/iter; left time: 368.5508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0542328\n",
      "\tspeed: 0.0425s/iter; left time: 359.4589s\n",
      "\titers: 700, epoch: 11 | loss: 0.0465595\n",
      "\tspeed: 0.0424s/iter; left time: 354.6454s\n",
      "\titers: 800, epoch: 11 | loss: 0.0529933\n",
      "\tspeed: 0.0426s/iter; left time: 351.6369s\n",
      "\titers: 900, epoch: 11 | loss: 0.0521689\n",
      "\tspeed: 0.0431s/iter; left time: 352.0106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.64s\n",
      "Steps: 906 | Train Loss: 0.0511675 Vali Loss: 0.0598988 Test Loss: 0.0922994\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0543974\n",
      "\tspeed: 0.1079s/iter; left time: 869.1142s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558931\n",
      "\tspeed: 0.0439s/iter; left time: 349.4350s\n",
      "\titers: 300, epoch: 12 | loss: 0.0536673\n",
      "\tspeed: 0.0418s/iter; left time: 328.6495s\n",
      "\titers: 400, epoch: 12 | loss: 0.0493185\n",
      "\tspeed: 0.0395s/iter; left time: 306.6525s\n",
      "\titers: 500, epoch: 12 | loss: 0.0480766\n",
      "\tspeed: 0.0454s/iter; left time: 347.6258s\n",
      "\titers: 600, epoch: 12 | loss: 0.0496297\n",
      "\tspeed: 0.0390s/iter; left time: 294.4691s\n",
      "\titers: 700, epoch: 12 | loss: 0.0478737\n",
      "\tspeed: 0.0359s/iter; left time: 267.5886s\n",
      "\titers: 800, epoch: 12 | loss: 0.0538624\n",
      "\tspeed: 0.0367s/iter; left time: 269.8622s\n",
      "\titers: 900, epoch: 12 | loss: 0.0532948\n",
      "\tspeed: 0.0437s/iter; left time: 316.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0501974 Vali Loss: 0.0584733 Test Loss: 0.0908385\n",
      "Validation loss decreased (0.058643 --> 0.058473).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0446094\n",
      "\tspeed: 0.1131s/iter; left time: 808.5172s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457311\n",
      "\tspeed: 0.0427s/iter; left time: 301.0601s\n",
      "\titers: 300, epoch: 13 | loss: 0.0506537\n",
      "\tspeed: 0.0439s/iter; left time: 305.4049s\n",
      "\titers: 400, epoch: 13 | loss: 0.0511733\n",
      "\tspeed: 0.0442s/iter; left time: 302.9935s\n",
      "\titers: 500, epoch: 13 | loss: 0.0539472\n",
      "\tspeed: 0.0427s/iter; left time: 288.3194s\n",
      "\titers: 600, epoch: 13 | loss: 0.0441267\n",
      "\tspeed: 0.0428s/iter; left time: 284.5521s\n",
      "\titers: 700, epoch: 13 | loss: 0.0492516\n",
      "\tspeed: 0.0415s/iter; left time: 271.6041s\n",
      "\titers: 800, epoch: 13 | loss: 0.0561598\n",
      "\tspeed: 0.0421s/iter; left time: 271.8197s\n",
      "\titers: 900, epoch: 13 | loss: 0.0472484\n",
      "\tspeed: 0.0429s/iter; left time: 272.4937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.07s\n",
      "Steps: 906 | Train Loss: 0.0491326 Vali Loss: 0.0594089 Test Loss: 0.0963262\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530333\n",
      "\tspeed: 0.1069s/iter; left time: 667.6597s\n",
      "\titers: 200, epoch: 14 | loss: 0.0487412\n",
      "\tspeed: 0.0420s/iter; left time: 258.1694s\n",
      "\titers: 300, epoch: 14 | loss: 0.0453941\n",
      "\tspeed: 0.0417s/iter; left time: 252.0604s\n",
      "\titers: 400, epoch: 14 | loss: 0.0444784\n",
      "\tspeed: 0.0425s/iter; left time: 252.3848s\n",
      "\titers: 500, epoch: 14 | loss: 0.0439628\n",
      "\tspeed: 0.0417s/iter; left time: 243.8408s\n",
      "\titers: 600, epoch: 14 | loss: 0.0476262\n",
      "\tspeed: 0.0443s/iter; left time: 254.2760s\n",
      "\titers: 700, epoch: 14 | loss: 0.0483886\n",
      "\tspeed: 0.0433s/iter; left time: 244.3192s\n",
      "\titers: 800, epoch: 14 | loss: 0.0529764\n",
      "\tspeed: 0.0427s/iter; left time: 236.8726s\n",
      "\titers: 900, epoch: 14 | loss: 0.0472643\n",
      "\tspeed: 0.0402s/iter; left time: 218.5852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 906 | Train Loss: 0.0482440 Vali Loss: 0.0596548 Test Loss: 0.0971809\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0510043\n",
      "\tspeed: 0.1068s/iter; left time: 570.2174s\n",
      "\titers: 200, epoch: 15 | loss: 0.0419200\n",
      "\tspeed: 0.0436s/iter; left time: 228.5415s\n",
      "\titers: 300, epoch: 15 | loss: 0.0468224\n",
      "\tspeed: 0.0453s/iter; left time: 232.8411s\n",
      "\titers: 400, epoch: 15 | loss: 0.0428927\n",
      "\tspeed: 0.0424s/iter; left time: 213.5581s\n",
      "\titers: 500, epoch: 15 | loss: 0.0499197\n",
      "\tspeed: 0.0423s/iter; left time: 208.6248s\n",
      "\titers: 600, epoch: 15 | loss: 0.0496863\n",
      "\tspeed: 0.0454s/iter; left time: 219.5392s\n",
      "\titers: 700, epoch: 15 | loss: 0.0491264\n",
      "\tspeed: 0.0446s/iter; left time: 211.1205s\n",
      "\titers: 800, epoch: 15 | loss: 0.0506055\n",
      "\tspeed: 0.0435s/iter; left time: 201.9092s\n",
      "\titers: 900, epoch: 15 | loss: 0.0496673\n",
      "\tspeed: 0.0442s/iter; left time: 200.6103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.96s\n",
      "Steps: 906 | Train Loss: 0.0474373 Vali Loss: 0.0577796 Test Loss: 0.0971414\n",
      "Validation loss decreased (0.058473 --> 0.057780).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0438764\n",
      "\tspeed: 0.1129s/iter; left time: 500.1458s\n",
      "\titers: 200, epoch: 16 | loss: 0.0438639\n",
      "\tspeed: 0.0432s/iter; left time: 187.0524s\n",
      "\titers: 300, epoch: 16 | loss: 0.0494521\n",
      "\tspeed: 0.0438s/iter; left time: 185.1173s\n",
      "\titers: 400, epoch: 16 | loss: 0.0448913\n",
      "\tspeed: 0.0420s/iter; left time: 173.6705s\n",
      "\titers: 500, epoch: 16 | loss: 0.0451118\n",
      "\tspeed: 0.0422s/iter; left time: 170.1019s\n",
      "\titers: 600, epoch: 16 | loss: 0.0447474\n",
      "\tspeed: 0.0421s/iter; left time: 165.4212s\n",
      "\titers: 700, epoch: 16 | loss: 0.0474475\n",
      "\tspeed: 0.0425s/iter; left time: 162.9229s\n",
      "\titers: 800, epoch: 16 | loss: 0.0469913\n",
      "\tspeed: 0.0420s/iter; left time: 156.6235s\n",
      "\titers: 900, epoch: 16 | loss: 0.0424623\n",
      "\tspeed: 0.0447s/iter; left time: 162.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.02s\n",
      "Steps: 906 | Train Loss: 0.0466344 Vali Loss: 0.0593383 Test Loss: 0.0970664\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0495520\n",
      "\tspeed: 0.1067s/iter; left time: 375.9424s\n",
      "\titers: 200, epoch: 17 | loss: 0.0392627\n",
      "\tspeed: 0.0402s/iter; left time: 137.6641s\n",
      "\titers: 300, epoch: 17 | loss: 0.0440726\n",
      "\tspeed: 0.0432s/iter; left time: 143.6500s\n",
      "\titers: 400, epoch: 17 | loss: 0.0480871\n",
      "\tspeed: 0.0445s/iter; left time: 143.5580s\n",
      "\titers: 500, epoch: 17 | loss: 0.0463579\n",
      "\tspeed: 0.0449s/iter; left time: 140.3851s\n",
      "\titers: 600, epoch: 17 | loss: 0.0517737\n",
      "\tspeed: 0.0447s/iter; left time: 135.2138s\n",
      "\titers: 700, epoch: 17 | loss: 0.0455615\n",
      "\tspeed: 0.0437s/iter; left time: 127.8104s\n",
      "\titers: 800, epoch: 17 | loss: 0.0434252\n",
      "\tspeed: 0.0444s/iter; left time: 125.5193s\n",
      "\titers: 900, epoch: 17 | loss: 0.0463968\n",
      "\tspeed: 0.0449s/iter; left time: 122.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.85s\n",
      "Steps: 906 | Train Loss: 0.0458945 Vali Loss: 0.0584379 Test Loss: 0.0950533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0485099\n",
      "\tspeed: 0.1074s/iter; left time: 281.2153s\n",
      "\titers: 200, epoch: 18 | loss: 0.0528042\n",
      "\tspeed: 0.0427s/iter; left time: 107.6323s\n",
      "\titers: 300, epoch: 18 | loss: 0.0441985\n",
      "\tspeed: 0.0432s/iter; left time: 104.4056s\n",
      "\titers: 400, epoch: 18 | loss: 0.0439317\n",
      "\tspeed: 0.0430s/iter; left time: 99.8201s\n",
      "\titers: 500, epoch: 18 | loss: 0.0448917\n",
      "\tspeed: 0.0428s/iter; left time: 94.8984s\n",
      "\titers: 600, epoch: 18 | loss: 0.0403514\n",
      "\tspeed: 0.0423s/iter; left time: 89.6848s\n",
      "\titers: 700, epoch: 18 | loss: 0.0424764\n",
      "\tspeed: 0.0413s/iter; left time: 83.4820s\n",
      "\titers: 800, epoch: 18 | loss: 0.0437762\n",
      "\tspeed: 0.0437s/iter; left time: 83.8336s\n",
      "\titers: 900, epoch: 18 | loss: 0.0481154\n",
      "\tspeed: 0.0411s/iter; left time: 74.7502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 906 | Train Loss: 0.0453132 Vali Loss: 0.0576576 Test Loss: 0.0957833\n",
      "Validation loss decreased (0.057780 --> 0.057658).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525963\n",
      "\tspeed: 0.1144s/iter; left time: 195.9725s\n",
      "\titers: 200, epoch: 19 | loss: 0.0475755\n",
      "\tspeed: 0.0437s/iter; left time: 70.5220s\n",
      "\titers: 300, epoch: 19 | loss: 0.0504941\n",
      "\tspeed: 0.0452s/iter; left time: 68.4124s\n",
      "\titers: 400, epoch: 19 | loss: 0.0391003\n",
      "\tspeed: 0.0451s/iter; left time: 63.7487s\n",
      "\titers: 500, epoch: 19 | loss: 0.0436999\n",
      "\tspeed: 0.0435s/iter; left time: 57.1626s\n",
      "\titers: 600, epoch: 19 | loss: 0.0416488\n",
      "\tspeed: 0.0434s/iter; left time: 52.6032s\n",
      "\titers: 700, epoch: 19 | loss: 0.0458390\n",
      "\tspeed: 0.0448s/iter; left time: 49.8677s\n",
      "\titers: 800, epoch: 19 | loss: 0.0466240\n",
      "\tspeed: 0.0436s/iter; left time: 44.1246s\n",
      "\titers: 900, epoch: 19 | loss: 0.0424584\n",
      "\tspeed: 0.0448s/iter; left time: 40.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 906 | Train Loss: 0.0446740 Vali Loss: 0.0614819 Test Loss: 0.1065742\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0435882\n",
      "\tspeed: 0.1066s/iter; left time: 86.0427s\n",
      "\titers: 200, epoch: 20 | loss: 0.0435573\n",
      "\tspeed: 0.0434s/iter; left time: 30.6982s\n",
      "\titers: 300, epoch: 20 | loss: 0.0418303\n",
      "\tspeed: 0.0439s/iter; left time: 26.6183s\n",
      "\titers: 400, epoch: 20 | loss: 0.0441725\n",
      "\tspeed: 0.0450s/iter; left time: 22.8326s\n",
      "\titers: 500, epoch: 20 | loss: 0.0432206\n",
      "\tspeed: 0.0442s/iter; left time: 17.9906s\n",
      "\titers: 600, epoch: 20 | loss: 0.0425618\n",
      "\tspeed: 0.0452s/iter; left time: 13.8630s\n",
      "\titers: 700, epoch: 20 | loss: 0.0430357\n",
      "\tspeed: 0.0438s/iter; left time: 9.0677s\n",
      "\titers: 800, epoch: 20 | loss: 0.0425836\n",
      "\tspeed: 0.0454s/iter; left time: 4.8576s\n",
      "\titers: 900, epoch: 20 | loss: 0.0451035\n",
      "\tspeed: 0.0437s/iter; left time: 0.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:40.24s\n",
      "Steps: 906 | Train Loss: 0.0442419 Vali Loss: 0.0586618 Test Loss: 0.0996176\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024789901450276375, rmse:0.15744809806346893, mae:0.09591271728277206, rse:0.46263009309768677\n",
      "Intermediate time for ES and pred_len 24: 00h:28m:53.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2384515\n",
      "\tspeed: 0.0755s/iter; left time: 1357.3714s\n",
      "\titers: 200, epoch: 1 | loss: 0.2146414\n",
      "\tspeed: 0.0450s/iter; left time: 805.1458s\n",
      "\titers: 300, epoch: 1 | loss: 0.2180060\n",
      "\tspeed: 0.0479s/iter; left time: 851.3699s\n",
      "\titers: 400, epoch: 1 | loss: 0.2053107\n",
      "\tspeed: 0.0487s/iter; left time: 860.2883s\n",
      "\titers: 500, epoch: 1 | loss: 0.1972545\n",
      "\tspeed: 0.0493s/iter; left time: 867.6185s\n",
      "\titers: 600, epoch: 1 | loss: 0.1857185\n",
      "\tspeed: 0.0492s/iter; left time: 860.0796s\n",
      "\titers: 700, epoch: 1 | loss: 0.1904936\n",
      "\tspeed: 0.0462s/iter; left time: 802.1456s\n",
      "\titers: 800, epoch: 1 | loss: 0.1748629\n",
      "\tspeed: 0.0469s/iter; left time: 810.8537s\n",
      "\titers: 900, epoch: 1 | loss: 0.1777007\n",
      "\tspeed: 0.0487s/iter; left time: 837.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 904 | Train Loss: 0.2054805 Vali Loss: 0.1695710 Test Loss: 0.2078795\n",
      "Validation loss decreased (inf --> 0.169571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453836\n",
      "\tspeed: 0.1268s/iter; left time: 2165.3349s\n",
      "\titers: 200, epoch: 2 | loss: 0.1358089\n",
      "\tspeed: 0.0493s/iter; left time: 836.4676s\n",
      "\titers: 300, epoch: 2 | loss: 0.1296715\n",
      "\tspeed: 0.0475s/iter; left time: 802.3977s\n",
      "\titers: 400, epoch: 2 | loss: 0.1144006\n",
      "\tspeed: 0.0476s/iter; left time: 797.8862s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037235\n",
      "\tspeed: 0.0481s/iter; left time: 802.9475s\n",
      "\titers: 600, epoch: 2 | loss: 0.1101244\n",
      "\tspeed: 0.0471s/iter; left time: 780.4448s\n",
      "\titers: 700, epoch: 2 | loss: 0.0999445\n",
      "\tspeed: 0.0465s/iter; left time: 766.4905s\n",
      "\titers: 800, epoch: 2 | loss: 0.0935427\n",
      "\tspeed: 0.0426s/iter; left time: 697.7491s\n",
      "\titers: 900, epoch: 2 | loss: 0.0998164\n",
      "\tspeed: 0.0472s/iter; left time: 768.8985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.1199355 Vali Loss: 0.0985261 Test Loss: 0.1282562\n",
      "Validation loss decreased (0.169571 --> 0.098526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954515\n",
      "\tspeed: 0.1243s/iter; left time: 2009.5040s\n",
      "\titers: 200, epoch: 3 | loss: 0.0912124\n",
      "\tspeed: 0.0482s/iter; left time: 774.2395s\n",
      "\titers: 300, epoch: 3 | loss: 0.0960256\n",
      "\tspeed: 0.0451s/iter; left time: 720.6675s\n",
      "\titers: 400, epoch: 3 | loss: 0.0962705\n",
      "\tspeed: 0.0487s/iter; left time: 773.1858s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870261\n",
      "\tspeed: 0.0473s/iter; left time: 746.7124s\n",
      "\titers: 600, epoch: 3 | loss: 0.0912619\n",
      "\tspeed: 0.0471s/iter; left time: 738.9021s\n",
      "\titers: 700, epoch: 3 | loss: 0.0945015\n",
      "\tspeed: 0.0482s/iter; left time: 750.6099s\n",
      "\titers: 800, epoch: 3 | loss: 0.0904101\n",
      "\tspeed: 0.0474s/iter; left time: 734.0817s\n",
      "\titers: 900, epoch: 3 | loss: 0.0849228\n",
      "\tspeed: 0.0459s/iter; left time: 705.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.0920878 Vali Loss: 0.0895598 Test Loss: 0.1295949\n",
      "Validation loss decreased (0.098526 --> 0.089560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842967\n",
      "\tspeed: 0.1262s/iter; left time: 1926.6401s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829929\n",
      "\tspeed: 0.0458s/iter; left time: 694.3825s\n",
      "\titers: 300, epoch: 4 | loss: 0.0879289\n",
      "\tspeed: 0.0486s/iter; left time: 732.9298s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827095\n",
      "\tspeed: 0.0437s/iter; left time: 654.4887s\n",
      "\titers: 500, epoch: 4 | loss: 0.0913868\n",
      "\tspeed: 0.0462s/iter; left time: 686.5412s\n",
      "\titers: 600, epoch: 4 | loss: 0.0841849\n",
      "\tspeed: 0.0395s/iter; left time: 582.7696s\n",
      "\titers: 700, epoch: 4 | loss: 0.0793578\n",
      "\tspeed: 0.0395s/iter; left time: 578.7119s\n",
      "\titers: 800, epoch: 4 | loss: 0.0784055\n",
      "\tspeed: 0.0394s/iter; left time: 573.7781s\n",
      "\titers: 900, epoch: 4 | loss: 0.0885338\n",
      "\tspeed: 0.0396s/iter; left time: 572.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.42s\n",
      "Steps: 904 | Train Loss: 0.0862932 Vali Loss: 0.0881228 Test Loss: 0.1295835\n",
      "Validation loss decreased (0.089560 --> 0.088123).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0864483\n",
      "\tspeed: 0.1246s/iter; left time: 1789.4260s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811242\n",
      "\tspeed: 0.0477s/iter; left time: 681.1017s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844520\n",
      "\tspeed: 0.0492s/iter; left time: 697.5070s\n",
      "\titers: 400, epoch: 5 | loss: 0.0801701\n",
      "\tspeed: 0.0497s/iter; left time: 699.4853s\n",
      "\titers: 500, epoch: 5 | loss: 0.0795058\n",
      "\tspeed: 0.0447s/iter; left time: 624.6874s\n",
      "\titers: 600, epoch: 5 | loss: 0.0792065\n",
      "\tspeed: 0.0460s/iter; left time: 637.8333s\n",
      "\titers: 700, epoch: 5 | loss: 0.0809612\n",
      "\tspeed: 0.0486s/iter; left time: 669.5296s\n",
      "\titers: 800, epoch: 5 | loss: 0.0837107\n",
      "\tspeed: 0.0408s/iter; left time: 556.9969s\n",
      "\titers: 900, epoch: 5 | loss: 0.0820203\n",
      "\tspeed: 0.0393s/iter; left time: 532.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 904 | Train Loss: 0.0817486 Vali Loss: 0.0859961 Test Loss: 0.1347349\n",
      "Validation loss decreased (0.088123 --> 0.085996).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0823008\n",
      "\tspeed: 0.1355s/iter; left time: 1823.9726s\n",
      "\titers: 200, epoch: 6 | loss: 0.0809554\n",
      "\tspeed: 0.0482s/iter; left time: 643.9127s\n",
      "\titers: 300, epoch: 6 | loss: 0.0802722\n",
      "\tspeed: 0.0482s/iter; left time: 639.5823s\n",
      "\titers: 400, epoch: 6 | loss: 0.0778541\n",
      "\tspeed: 0.0451s/iter; left time: 593.9421s\n",
      "\titers: 500, epoch: 6 | loss: 0.0792405\n",
      "\tspeed: 0.0395s/iter; left time: 515.3884s\n",
      "\titers: 600, epoch: 6 | loss: 0.0772906\n",
      "\tspeed: 0.0405s/iter; left time: 524.7475s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781953\n",
      "\tspeed: 0.0448s/iter; left time: 575.9904s\n",
      "\titers: 800, epoch: 6 | loss: 0.0805445\n",
      "\tspeed: 0.0466s/iter; left time: 595.1949s\n",
      "\titers: 900, epoch: 6 | loss: 0.0751942\n",
      "\tspeed: 0.0455s/iter; left time: 575.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.98s\n",
      "Steps: 904 | Train Loss: 0.0782990 Vali Loss: 0.0867788 Test Loss: 0.1433721\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756937\n",
      "\tspeed: 0.1192s/iter; left time: 1496.2755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0780173\n",
      "\tspeed: 0.0473s/iter; left time: 589.0204s\n",
      "\titers: 300, epoch: 7 | loss: 0.0782186\n",
      "\tspeed: 0.0461s/iter; left time: 569.3580s\n",
      "\titers: 400, epoch: 7 | loss: 0.0780234\n",
      "\tspeed: 0.0494s/iter; left time: 605.4380s\n",
      "\titers: 500, epoch: 7 | loss: 0.0733429\n",
      "\tspeed: 0.0497s/iter; left time: 604.7322s\n",
      "\titers: 600, epoch: 7 | loss: 0.0655437\n",
      "\tspeed: 0.0467s/iter; left time: 563.6244s\n",
      "\titers: 700, epoch: 7 | loss: 0.0745077\n",
      "\tspeed: 0.0454s/iter; left time: 542.5678s\n",
      "\titers: 800, epoch: 7 | loss: 0.0771893\n",
      "\tspeed: 0.0444s/iter; left time: 526.2926s\n",
      "\titers: 900, epoch: 7 | loss: 0.0747498\n",
      "\tspeed: 0.0488s/iter; left time: 574.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.04s\n",
      "Steps: 904 | Train Loss: 0.0750828 Vali Loss: 0.0865508 Test Loss: 0.1437815\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0779755\n",
      "\tspeed: 0.1184s/iter; left time: 1379.1875s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732990\n",
      "\tspeed: 0.0487s/iter; left time: 562.9374s\n",
      "\titers: 300, epoch: 8 | loss: 0.0715991\n",
      "\tspeed: 0.0461s/iter; left time: 527.4743s\n",
      "\titers: 400, epoch: 8 | loss: 0.0711120\n",
      "\tspeed: 0.0475s/iter; left time: 539.0710s\n",
      "\titers: 500, epoch: 8 | loss: 0.0711963\n",
      "\tspeed: 0.0470s/iter; left time: 528.7458s\n",
      "\titers: 600, epoch: 8 | loss: 0.0720228\n",
      "\tspeed: 0.0488s/iter; left time: 543.8609s\n",
      "\titers: 700, epoch: 8 | loss: 0.0637291\n",
      "\tspeed: 0.0483s/iter; left time: 534.1236s\n",
      "\titers: 800, epoch: 8 | loss: 0.0720645\n",
      "\tspeed: 0.0468s/iter; left time: 512.2591s\n",
      "\titers: 900, epoch: 8 | loss: 0.0679686\n",
      "\tspeed: 0.0459s/iter; left time: 498.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0717168 Vali Loss: 0.0864078 Test Loss: 0.1496538\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685663\n",
      "\tspeed: 0.1174s/iter; left time: 1261.8858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717570\n",
      "\tspeed: 0.0485s/iter; left time: 516.6176s\n",
      "\titers: 300, epoch: 9 | loss: 0.0695549\n",
      "\tspeed: 0.0476s/iter; left time: 501.6224s\n",
      "\titers: 400, epoch: 9 | loss: 0.0646989\n",
      "\tspeed: 0.0437s/iter; left time: 456.6713s\n",
      "\titers: 500, epoch: 9 | loss: 0.0739497\n",
      "\tspeed: 0.0463s/iter; left time: 478.8910s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717835\n",
      "\tspeed: 0.0474s/iter; left time: 485.9519s\n",
      "\titers: 700, epoch: 9 | loss: 0.0680621\n",
      "\tspeed: 0.0490s/iter; left time: 497.0983s\n",
      "\titers: 800, epoch: 9 | loss: 0.0682900\n",
      "\tspeed: 0.0492s/iter; left time: 494.7125s\n",
      "\titers: 900, epoch: 9 | loss: 0.0699611\n",
      "\tspeed: 0.0483s/iter; left time: 480.8239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.0691861 Vali Loss: 0.0879675 Test Loss: 0.1634988\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669832\n",
      "\tspeed: 0.1221s/iter; left time: 1202.3295s\n",
      "\titers: 200, epoch: 10 | loss: 0.0653438\n",
      "\tspeed: 0.0483s/iter; left time: 470.2072s\n",
      "\titers: 300, epoch: 10 | loss: 0.0653087\n",
      "\tspeed: 0.0454s/iter; left time: 438.3002s\n",
      "\titers: 400, epoch: 10 | loss: 0.0681388\n",
      "\tspeed: 0.0458s/iter; left time: 436.9722s\n",
      "\titers: 500, epoch: 10 | loss: 0.0653993\n",
      "\tspeed: 0.0474s/iter; left time: 447.6120s\n",
      "\titers: 600, epoch: 10 | loss: 0.0670908\n",
      "\tspeed: 0.0473s/iter; left time: 441.5982s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699330\n",
      "\tspeed: 0.0449s/iter; left time: 414.8412s\n",
      "\titers: 800, epoch: 10 | loss: 0.0599767\n",
      "\tspeed: 0.0473s/iter; left time: 432.6973s\n",
      "\titers: 900, epoch: 10 | loss: 0.0634191\n",
      "\tspeed: 0.0481s/iter; left time: 435.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.0664865 Vali Loss: 0.0859074 Test Loss: 0.1562858\n",
      "Validation loss decreased (0.085996 --> 0.085907).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657937\n",
      "\tspeed: 0.1283s/iter; left time: 1146.9509s\n",
      "\titers: 200, epoch: 11 | loss: 0.0644366\n",
      "\tspeed: 0.0497s/iter; left time: 439.1246s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647984\n",
      "\tspeed: 0.0504s/iter; left time: 440.3506s\n",
      "\titers: 400, epoch: 11 | loss: 0.0712598\n",
      "\tspeed: 0.0504s/iter; left time: 435.4275s\n",
      "\titers: 500, epoch: 11 | loss: 0.0661000\n",
      "\tspeed: 0.0480s/iter; left time: 409.7563s\n",
      "\titers: 600, epoch: 11 | loss: 0.0673678\n",
      "\tspeed: 0.0489s/iter; left time: 412.8401s\n",
      "\titers: 700, epoch: 11 | loss: 0.0654028\n",
      "\tspeed: 0.0471s/iter; left time: 392.8196s\n",
      "\titers: 800, epoch: 11 | loss: 0.0609792\n",
      "\tspeed: 0.0482s/iter; left time: 396.8505s\n",
      "\titers: 900, epoch: 11 | loss: 0.0600154\n",
      "\tspeed: 0.0423s/iter; left time: 344.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.82s\n",
      "Steps: 904 | Train Loss: 0.0644636 Vali Loss: 0.0866142 Test Loss: 0.1615575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583775\n",
      "\tspeed: 0.1204s/iter; left time: 967.7340s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650353\n",
      "\tspeed: 0.0505s/iter; left time: 400.7761s\n",
      "\titers: 300, epoch: 12 | loss: 0.0610544\n",
      "\tspeed: 0.0496s/iter; left time: 388.4153s\n",
      "\titers: 400, epoch: 12 | loss: 0.0564006\n",
      "\tspeed: 0.0481s/iter; left time: 372.0864s\n",
      "\titers: 500, epoch: 12 | loss: 0.0640808\n",
      "\tspeed: 0.0493s/iter; left time: 376.1323s\n",
      "\titers: 600, epoch: 12 | loss: 0.0569968\n",
      "\tspeed: 0.0485s/iter; left time: 365.4635s\n",
      "\titers: 700, epoch: 12 | loss: 0.0635740\n",
      "\tspeed: 0.0481s/iter; left time: 357.8909s\n",
      "\titers: 800, epoch: 12 | loss: 0.0614182\n",
      "\tspeed: 0.0479s/iter; left time: 351.5626s\n",
      "\titers: 900, epoch: 12 | loss: 0.0595840\n",
      "\tspeed: 0.0465s/iter; left time: 336.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 904 | Train Loss: 0.0623148 Vali Loss: 0.0865320 Test Loss: 0.1586662\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0612977\n",
      "\tspeed: 0.1180s/iter; left time: 841.9289s\n",
      "\titers: 200, epoch: 13 | loss: 0.0587642\n",
      "\tspeed: 0.0479s/iter; left time: 336.9320s\n",
      "\titers: 300, epoch: 13 | loss: 0.0563776\n",
      "\tspeed: 0.0487s/iter; left time: 337.8501s\n",
      "\titers: 400, epoch: 13 | loss: 0.0562836\n",
      "\tspeed: 0.0428s/iter; left time: 292.3383s\n",
      "\titers: 500, epoch: 13 | loss: 0.0634416\n",
      "\tspeed: 0.0477s/iter; left time: 320.9856s\n",
      "\titers: 600, epoch: 13 | loss: 0.0640421\n",
      "\tspeed: 0.0471s/iter; left time: 312.0883s\n",
      "\titers: 700, epoch: 13 | loss: 0.0602080\n",
      "\tspeed: 0.0476s/iter; left time: 310.6758s\n",
      "\titers: 800, epoch: 13 | loss: 0.0640807\n",
      "\tspeed: 0.0480s/iter; left time: 308.8975s\n",
      "\titers: 900, epoch: 13 | loss: 0.0604606\n",
      "\tspeed: 0.0470s/iter; left time: 297.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.79s\n",
      "Steps: 904 | Train Loss: 0.0603249 Vali Loss: 0.0876123 Test Loss: 0.1657297\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0609293\n",
      "\tspeed: 0.1219s/iter; left time: 759.5451s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600787\n",
      "\tspeed: 0.0500s/iter; left time: 306.4939s\n",
      "\titers: 300, epoch: 14 | loss: 0.0579149\n",
      "\tspeed: 0.0495s/iter; left time: 298.2846s\n",
      "\titers: 400, epoch: 14 | loss: 0.0552511\n",
      "\tspeed: 0.0483s/iter; left time: 286.3759s\n",
      "\titers: 500, epoch: 14 | loss: 0.0606611\n",
      "\tspeed: 0.0468s/iter; left time: 272.5752s\n",
      "\titers: 600, epoch: 14 | loss: 0.0585283\n",
      "\tspeed: 0.0475s/iter; left time: 272.0598s\n",
      "\titers: 700, epoch: 14 | loss: 0.0589618\n",
      "\tspeed: 0.0483s/iter; left time: 271.7281s\n",
      "\titers: 800, epoch: 14 | loss: 0.0589674\n",
      "\tspeed: 0.0461s/iter; left time: 254.7387s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592620\n",
      "\tspeed: 0.0471s/iter; left time: 255.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:43.80s\n",
      "Steps: 904 | Train Loss: 0.0586510 Vali Loss: 0.0880812 Test Loss: 0.1672379\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0616658\n",
      "\tspeed: 0.1191s/iter; left time: 634.1412s\n",
      "\titers: 200, epoch: 15 | loss: 0.0599181\n",
      "\tspeed: 0.0488s/iter; left time: 254.9005s\n",
      "\titers: 300, epoch: 15 | loss: 0.0558654\n",
      "\tspeed: 0.0466s/iter; left time: 238.9213s\n",
      "\titers: 400, epoch: 15 | loss: 0.0597988\n",
      "\tspeed: 0.0474s/iter; left time: 237.9652s\n",
      "\titers: 500, epoch: 15 | loss: 0.0576043\n",
      "\tspeed: 0.0451s/iter; left time: 222.1081s\n",
      "\titers: 600, epoch: 15 | loss: 0.0592206\n",
      "\tspeed: 0.0479s/iter; left time: 231.2219s\n",
      "\titers: 700, epoch: 15 | loss: 0.0582772\n",
      "\tspeed: 0.0463s/iter; left time: 218.8288s\n",
      "\titers: 800, epoch: 15 | loss: 0.0593535\n",
      "\tspeed: 0.0487s/iter; left time: 225.1337s\n",
      "\titers: 900, epoch: 15 | loss: 0.0618834\n",
      "\tspeed: 0.0499s/iter; left time: 225.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.0570594 Vali Loss: 0.0870935 Test Loss: 0.1662657\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0621136911213398, rmse:0.2492261826992035, mae:0.1562231183052063, rse:0.7321515083312988\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2404172\n",
      "\tspeed: 0.0508s/iter; left time: 913.9292s\n",
      "\titers: 200, epoch: 1 | loss: 0.2201424\n",
      "\tspeed: 0.0500s/iter; left time: 893.3608s\n",
      "\titers: 300, epoch: 1 | loss: 0.2063731\n",
      "\tspeed: 0.0475s/iter; left time: 845.1072s\n",
      "\titers: 400, epoch: 1 | loss: 0.2057976\n",
      "\tspeed: 0.0489s/iter; left time: 864.5590s\n",
      "\titers: 500, epoch: 1 | loss: 0.2004143\n",
      "\tspeed: 0.0443s/iter; left time: 778.8122s\n",
      "\titers: 600, epoch: 1 | loss: 0.2004972\n",
      "\tspeed: 0.0475s/iter; left time: 830.1881s\n",
      "\titers: 700, epoch: 1 | loss: 0.1928217\n",
      "\tspeed: 0.0473s/iter; left time: 822.9813s\n",
      "\titers: 800, epoch: 1 | loss: 0.1905690\n",
      "\tspeed: 0.0477s/iter; left time: 825.0824s\n",
      "\titers: 900, epoch: 1 | loss: 0.1725994\n",
      "\tspeed: 0.0492s/iter; left time: 844.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.59s\n",
      "Steps: 904 | Train Loss: 0.2077810 Vali Loss: 0.1732043 Test Loss: 0.2144032\n",
      "Validation loss decreased (inf --> 0.173204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501734\n",
      "\tspeed: 0.1329s/iter; left time: 2268.8013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1352457\n",
      "\tspeed: 0.0497s/iter; left time: 843.4716s\n",
      "\titers: 300, epoch: 2 | loss: 0.1314882\n",
      "\tspeed: 0.0483s/iter; left time: 815.3808s\n",
      "\titers: 400, epoch: 2 | loss: 0.1208705\n",
      "\tspeed: 0.0478s/iter; left time: 801.2522s\n",
      "\titers: 500, epoch: 2 | loss: 0.1158073\n",
      "\tspeed: 0.0495s/iter; left time: 825.0634s\n",
      "\titers: 600, epoch: 2 | loss: 0.1148969\n",
      "\tspeed: 0.0457s/iter; left time: 757.8738s\n",
      "\titers: 700, epoch: 2 | loss: 0.0997682\n",
      "\tspeed: 0.0474s/iter; left time: 780.2948s\n",
      "\titers: 800, epoch: 2 | loss: 0.1034051\n",
      "\tspeed: 0.0504s/iter; left time: 824.7030s\n",
      "\titers: 900, epoch: 2 | loss: 0.0903369\n",
      "\tspeed: 0.0496s/iter; left time: 807.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.29s\n",
      "Steps: 904 | Train Loss: 0.1209288 Vali Loss: 0.0963794 Test Loss: 0.1371179\n",
      "Validation loss decreased (0.173204 --> 0.096379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0935780\n",
      "\tspeed: 0.1246s/iter; left time: 2015.7357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927026\n",
      "\tspeed: 0.0456s/iter; left time: 733.2501s\n",
      "\titers: 300, epoch: 3 | loss: 0.1050145\n",
      "\tspeed: 0.0483s/iter; left time: 771.1490s\n",
      "\titers: 400, epoch: 3 | loss: 0.0948645\n",
      "\tspeed: 0.0491s/iter; left time: 779.8359s\n",
      "\titers: 500, epoch: 3 | loss: 0.0827705\n",
      "\tspeed: 0.0498s/iter; left time: 785.2940s\n",
      "\titers: 600, epoch: 3 | loss: 0.0837813\n",
      "\tspeed: 0.0500s/iter; left time: 783.8900s\n",
      "\titers: 700, epoch: 3 | loss: 0.0890595\n",
      "\tspeed: 0.0450s/iter; left time: 700.7420s\n",
      "\titers: 800, epoch: 3 | loss: 0.0927761\n",
      "\tspeed: 0.0471s/iter; left time: 728.5241s\n",
      "\titers: 900, epoch: 3 | loss: 0.0832633\n",
      "\tspeed: 0.0483s/iter; left time: 742.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.69s\n",
      "Steps: 904 | Train Loss: 0.0918153 Vali Loss: 0.0892233 Test Loss: 0.1335807\n",
      "Validation loss decreased (0.096379 --> 0.089223).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0909086\n",
      "\tspeed: 0.1321s/iter; left time: 2016.5528s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835494\n",
      "\tspeed: 0.0475s/iter; left time: 719.9020s\n",
      "\titers: 300, epoch: 4 | loss: 0.0839262\n",
      "\tspeed: 0.0461s/iter; left time: 695.2990s\n",
      "\titers: 400, epoch: 4 | loss: 0.0796652\n",
      "\tspeed: 0.0498s/iter; left time: 744.9434s\n",
      "\titers: 500, epoch: 4 | loss: 0.0784578\n",
      "\tspeed: 0.0496s/iter; left time: 737.6688s\n",
      "\titers: 600, epoch: 4 | loss: 0.0873888\n",
      "\tspeed: 0.0484s/iter; left time: 715.3901s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838238\n",
      "\tspeed: 0.0466s/iter; left time: 683.0229s\n",
      "\titers: 800, epoch: 4 | loss: 0.0810640\n",
      "\tspeed: 0.0448s/iter; left time: 652.5258s\n",
      "\titers: 900, epoch: 4 | loss: 0.0828189\n",
      "\tspeed: 0.0458s/iter; left time: 662.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.0853449 Vali Loss: 0.0901499 Test Loss: 0.1362802\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844502\n",
      "\tspeed: 0.1213s/iter; left time: 1742.0014s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893857\n",
      "\tspeed: 0.0490s/iter; left time: 698.6678s\n",
      "\titers: 300, epoch: 5 | loss: 0.0784553\n",
      "\tspeed: 0.0453s/iter; left time: 641.0197s\n",
      "\titers: 400, epoch: 5 | loss: 0.0792715\n",
      "\tspeed: 0.0484s/iter; left time: 680.5353s\n",
      "\titers: 500, epoch: 5 | loss: 0.0742564\n",
      "\tspeed: 0.0474s/iter; left time: 662.1011s\n",
      "\titers: 600, epoch: 5 | loss: 0.0751548\n",
      "\tspeed: 0.0501s/iter; left time: 693.9776s\n",
      "\titers: 700, epoch: 5 | loss: 0.0851703\n",
      "\tspeed: 0.0410s/iter; left time: 564.2893s\n",
      "\titers: 800, epoch: 5 | loss: 0.0861519\n",
      "\tspeed: 0.0397s/iter; left time: 543.1437s\n",
      "\titers: 900, epoch: 5 | loss: 0.0877003\n",
      "\tspeed: 0.0428s/iter; left time: 580.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.0810769 Vali Loss: 0.0892295 Test Loss: 0.1417478\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809330\n",
      "\tspeed: 0.1186s/iter; left time: 1596.8832s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795789\n",
      "\tspeed: 0.0495s/iter; left time: 660.7492s\n",
      "\titers: 300, epoch: 6 | loss: 0.0735987\n",
      "\tspeed: 0.0505s/iter; left time: 669.4897s\n",
      "\titers: 400, epoch: 6 | loss: 0.0762497\n",
      "\tspeed: 0.0465s/iter; left time: 611.6702s\n",
      "\titers: 500, epoch: 6 | loss: 0.0729858\n",
      "\tspeed: 0.0456s/iter; left time: 596.0373s\n",
      "\titers: 600, epoch: 6 | loss: 0.0770677\n",
      "\tspeed: 0.0473s/iter; left time: 613.5428s\n",
      "\titers: 700, epoch: 6 | loss: 0.0758942\n",
      "\tspeed: 0.0501s/iter; left time: 644.3161s\n",
      "\titers: 800, epoch: 6 | loss: 0.0780751\n",
      "\tspeed: 0.0503s/iter; left time: 641.8302s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726726\n",
      "\tspeed: 0.0497s/iter; left time: 629.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.01s\n",
      "Steps: 904 | Train Loss: 0.0771611 Vali Loss: 0.0849141 Test Loss: 0.1407367\n",
      "Validation loss decreased (0.089223 --> 0.084914).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0729787\n",
      "\tspeed: 0.1238s/iter; left time: 1554.0443s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727771\n",
      "\tspeed: 0.0474s/iter; left time: 591.0820s\n",
      "\titers: 300, epoch: 7 | loss: 0.0745202\n",
      "\tspeed: 0.0481s/iter; left time: 594.6845s\n",
      "\titers: 400, epoch: 7 | loss: 0.0725877\n",
      "\tspeed: 0.0472s/iter; left time: 578.6928s\n",
      "\titers: 500, epoch: 7 | loss: 0.0691659\n",
      "\tspeed: 0.0467s/iter; left time: 567.4676s\n",
      "\titers: 600, epoch: 7 | loss: 0.0758437\n",
      "\tspeed: 0.0482s/iter; left time: 581.7008s\n",
      "\titers: 700, epoch: 7 | loss: 0.0709473\n",
      "\tspeed: 0.0444s/iter; left time: 531.4752s\n",
      "\titers: 800, epoch: 7 | loss: 0.0694657\n",
      "\tspeed: 0.0500s/iter; left time: 592.6362s\n",
      "\titers: 900, epoch: 7 | loss: 0.0726918\n",
      "\tspeed: 0.0505s/iter; left time: 594.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.64s\n",
      "Steps: 904 | Train Loss: 0.0737538 Vali Loss: 0.0846094 Test Loss: 0.1517563\n",
      "Validation loss decreased (0.084914 --> 0.084609).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781815\n",
      "\tspeed: 0.1233s/iter; left time: 1437.1645s\n",
      "\titers: 200, epoch: 8 | loss: 0.0669782\n",
      "\tspeed: 0.0504s/iter; left time: 582.3222s\n",
      "\titers: 300, epoch: 8 | loss: 0.0750756\n",
      "\tspeed: 0.0468s/iter; left time: 536.3345s\n",
      "\titers: 400, epoch: 8 | loss: 0.0724268\n",
      "\tspeed: 0.0439s/iter; left time: 498.6732s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750967\n",
      "\tspeed: 0.0450s/iter; left time: 505.9207s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727142\n",
      "\tspeed: 0.0468s/iter; left time: 521.5234s\n",
      "\titers: 700, epoch: 8 | loss: 0.0646042\n",
      "\tspeed: 0.0450s/iter; left time: 497.8523s\n",
      "\titers: 800, epoch: 8 | loss: 0.0693420\n",
      "\tspeed: 0.0460s/iter; left time: 503.6784s\n",
      "\titers: 900, epoch: 8 | loss: 0.0620706\n",
      "\tspeed: 0.0454s/iter; left time: 493.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.07s\n",
      "Steps: 904 | Train Loss: 0.0709016 Vali Loss: 0.0847298 Test Loss: 0.1540082\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0625846\n",
      "\tspeed: 0.1172s/iter; left time: 1259.7979s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698348\n",
      "\tspeed: 0.0455s/iter; left time: 484.1328s\n",
      "\titers: 300, epoch: 9 | loss: 0.0620178\n",
      "\tspeed: 0.0457s/iter; left time: 481.6099s\n",
      "\titers: 400, epoch: 9 | loss: 0.0690884\n",
      "\tspeed: 0.0448s/iter; left time: 467.9445s\n",
      "\titers: 500, epoch: 9 | loss: 0.0693989\n",
      "\tspeed: 0.0459s/iter; left time: 474.9093s\n",
      "\titers: 600, epoch: 9 | loss: 0.0746084\n",
      "\tspeed: 0.0454s/iter; left time: 465.4534s\n",
      "\titers: 700, epoch: 9 | loss: 0.0681551\n",
      "\tspeed: 0.0453s/iter; left time: 460.0933s\n",
      "\titers: 800, epoch: 9 | loss: 0.0686809\n",
      "\tspeed: 0.0398s/iter; left time: 399.6938s\n",
      "\titers: 900, epoch: 9 | loss: 0.0648397\n",
      "\tspeed: 0.0433s/iter; left time: 431.2835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.52s\n",
      "Steps: 904 | Train Loss: 0.0681101 Vali Loss: 0.0869950 Test Loss: 0.1493889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710971\n",
      "\tspeed: 0.1160s/iter; left time: 1142.0457s\n",
      "\titers: 200, epoch: 10 | loss: 0.0607016\n",
      "\tspeed: 0.0465s/iter; left time: 453.6124s\n",
      "\titers: 300, epoch: 10 | loss: 0.0663983\n",
      "\tspeed: 0.0467s/iter; left time: 449.9981s\n",
      "\titers: 400, epoch: 10 | loss: 0.0653817\n",
      "\tspeed: 0.0447s/iter; left time: 426.2831s\n",
      "\titers: 500, epoch: 10 | loss: 0.0647618\n",
      "\tspeed: 0.0442s/iter; left time: 417.4412s\n",
      "\titers: 600, epoch: 10 | loss: 0.0653631\n",
      "\tspeed: 0.0458s/iter; left time: 427.6832s\n",
      "\titers: 700, epoch: 10 | loss: 0.0635928\n",
      "\tspeed: 0.0459s/iter; left time: 424.1940s\n",
      "\titers: 800, epoch: 10 | loss: 0.0676852\n",
      "\tspeed: 0.0459s/iter; left time: 419.4088s\n",
      "\titers: 900, epoch: 10 | loss: 0.0719308\n",
      "\tspeed: 0.0475s/iter; left time: 429.7810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 904 | Train Loss: 0.0651464 Vali Loss: 0.0863084 Test Loss: 0.1573102\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622910\n",
      "\tspeed: 0.1207s/iter; left time: 1079.2014s\n",
      "\titers: 200, epoch: 11 | loss: 0.0615052\n",
      "\tspeed: 0.0456s/iter; left time: 403.4911s\n",
      "\titers: 300, epoch: 11 | loss: 0.0616270\n",
      "\tspeed: 0.0452s/iter; left time: 394.9188s\n",
      "\titers: 400, epoch: 11 | loss: 0.0629679\n",
      "\tspeed: 0.0413s/iter; left time: 357.0123s\n",
      "\titers: 500, epoch: 11 | loss: 0.0645794\n",
      "\tspeed: 0.0405s/iter; left time: 345.6662s\n",
      "\titers: 600, epoch: 11 | loss: 0.0598391\n",
      "\tspeed: 0.0454s/iter; left time: 383.6152s\n",
      "\titers: 700, epoch: 11 | loss: 0.0596024\n",
      "\tspeed: 0.0470s/iter; left time: 391.7359s\n",
      "\titers: 800, epoch: 11 | loss: 0.0642787\n",
      "\tspeed: 0.0483s/iter; left time: 397.8913s\n",
      "\titers: 900, epoch: 11 | loss: 0.0582848\n",
      "\tspeed: 0.0461s/iter; left time: 375.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.25s\n",
      "Steps: 904 | Train Loss: 0.0629357 Vali Loss: 0.0862783 Test Loss: 0.1557319\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594919\n",
      "\tspeed: 0.1184s/iter; left time: 951.8482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594223\n",
      "\tspeed: 0.0448s/iter; left time: 355.9143s\n",
      "\titers: 300, epoch: 12 | loss: 0.0616208\n",
      "\tspeed: 0.0469s/iter; left time: 367.9016s\n",
      "\titers: 400, epoch: 12 | loss: 0.0625487\n",
      "\tspeed: 0.0469s/iter; left time: 362.6668s\n",
      "\titers: 500, epoch: 12 | loss: 0.0591396\n",
      "\tspeed: 0.0444s/iter; left time: 339.0964s\n",
      "\titers: 600, epoch: 12 | loss: 0.0629145\n",
      "\tspeed: 0.0453s/iter; left time: 341.5741s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644609\n",
      "\tspeed: 0.0478s/iter; left time: 355.7781s\n",
      "\titers: 800, epoch: 12 | loss: 0.0662911\n",
      "\tspeed: 0.0499s/iter; left time: 366.0103s\n",
      "\titers: 900, epoch: 12 | loss: 0.0599037\n",
      "\tspeed: 0.0466s/iter; left time: 337.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 904 | Train Loss: 0.0606856 Vali Loss: 0.0858058 Test Loss: 0.1528269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05941867083311081, rmse:0.24375945329666138, mae:0.15178018808364868, rse:0.7160918712615967\n",
      "Intermediate time for ES and pred_len 96: 00h:22m:42.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2494293\n",
      "\tspeed: 0.0790s/iter; left time: 1417.6897s\n",
      "\titers: 200, epoch: 1 | loss: 0.2181168\n",
      "\tspeed: 0.0529s/iter; left time: 943.1981s\n",
      "\titers: 300, epoch: 1 | loss: 0.2107528\n",
      "\tspeed: 0.0510s/iter; left time: 904.6344s\n",
      "\titers: 400, epoch: 1 | loss: 0.2044485\n",
      "\tspeed: 0.0520s/iter; left time: 917.1043s\n",
      "\titers: 500, epoch: 1 | loss: 0.1976297\n",
      "\tspeed: 0.0502s/iter; left time: 880.4663s\n",
      "\titers: 600, epoch: 1 | loss: 0.1977707\n",
      "\tspeed: 0.0521s/iter; left time: 908.0073s\n",
      "\titers: 700, epoch: 1 | loss: 0.1934083\n",
      "\tspeed: 0.0551s/iter; left time: 955.8418s\n",
      "\titers: 800, epoch: 1 | loss: 0.1834540\n",
      "\tspeed: 0.0545s/iter; left time: 940.1561s\n",
      "\titers: 900, epoch: 1 | loss: 0.1815212\n",
      "\tspeed: 0.0531s/iter; left time: 909.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.2080731 Vali Loss: 0.1811913 Test Loss: 0.2210122\n",
      "Validation loss decreased (inf --> 0.181191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645532\n",
      "\tspeed: 0.1426s/iter; left time: 2430.1129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1557363\n",
      "\tspeed: 0.0522s/iter; left time: 883.4765s\n",
      "\titers: 300, epoch: 2 | loss: 0.1507612\n",
      "\tspeed: 0.0512s/iter; left time: 862.5728s\n",
      "\titers: 400, epoch: 2 | loss: 0.1327350\n",
      "\tspeed: 0.0512s/iter; left time: 857.6313s\n",
      "\titers: 500, epoch: 2 | loss: 0.1191086\n",
      "\tspeed: 0.0503s/iter; left time: 837.0511s\n",
      "\titers: 600, epoch: 2 | loss: 0.1147511\n",
      "\tspeed: 0.0518s/iter; left time: 856.4008s\n",
      "\titers: 700, epoch: 2 | loss: 0.1073123\n",
      "\tspeed: 0.0517s/iter; left time: 850.6455s\n",
      "\titers: 800, epoch: 2 | loss: 0.1038416\n",
      "\tspeed: 0.0514s/iter; left time: 839.6568s\n",
      "\titers: 900, epoch: 2 | loss: 0.0993121\n",
      "\tspeed: 0.0532s/iter; left time: 863.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.69s\n",
      "Steps: 902 | Train Loss: 0.1322833 Vali Loss: 0.1038791 Test Loss: 0.1466250\n",
      "Validation loss decreased (0.181191 --> 0.103879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1026798\n",
      "\tspeed: 0.1504s/iter; left time: 2426.6763s\n",
      "\titers: 200, epoch: 3 | loss: 0.0970726\n",
      "\tspeed: 0.0525s/iter; left time: 841.8991s\n",
      "\titers: 300, epoch: 3 | loss: 0.0917688\n",
      "\tspeed: 0.0514s/iter; left time: 819.9162s\n",
      "\titers: 400, epoch: 3 | loss: 0.0928012\n",
      "\tspeed: 0.0531s/iter; left time: 841.5559s\n",
      "\titers: 500, epoch: 3 | loss: 0.0957348\n",
      "\tspeed: 0.0522s/iter; left time: 821.3519s\n",
      "\titers: 600, epoch: 3 | loss: 0.1012272\n",
      "\tspeed: 0.0534s/iter; left time: 834.7320s\n",
      "\titers: 700, epoch: 3 | loss: 0.0967861\n",
      "\tspeed: 0.0529s/iter; left time: 821.2245s\n",
      "\titers: 800, epoch: 3 | loss: 0.0937926\n",
      "\tspeed: 0.0534s/iter; left time: 824.6520s\n",
      "\titers: 900, epoch: 3 | loss: 0.0936729\n",
      "\tspeed: 0.0522s/iter; left time: 801.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.0974400 Vali Loss: 0.0987192 Test Loss: 0.1403093\n",
      "Validation loss decreased (0.103879 --> 0.098719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0929292\n",
      "\tspeed: 0.1488s/iter; left time: 2266.4498s\n",
      "\titers: 200, epoch: 4 | loss: 0.0965619\n",
      "\tspeed: 0.0545s/iter; left time: 825.5336s\n",
      "\titers: 300, epoch: 4 | loss: 0.0898032\n",
      "\tspeed: 0.0524s/iter; left time: 788.0433s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937172\n",
      "\tspeed: 0.0534s/iter; left time: 797.4721s\n",
      "\titers: 500, epoch: 4 | loss: 0.0906779\n",
      "\tspeed: 0.0514s/iter; left time: 762.4537s\n",
      "\titers: 600, epoch: 4 | loss: 0.0879486\n",
      "\tspeed: 0.0524s/iter; left time: 772.0911s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877434\n",
      "\tspeed: 0.0526s/iter; left time: 769.7305s\n",
      "\titers: 800, epoch: 4 | loss: 0.0960336\n",
      "\tspeed: 0.0529s/iter; left time: 768.7060s\n",
      "\titers: 900, epoch: 4 | loss: 0.0904689\n",
      "\tspeed: 0.0516s/iter; left time: 744.6675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 902 | Train Loss: 0.0913474 Vali Loss: 0.0929738 Test Loss: 0.1350355\n",
      "Validation loss decreased (0.098719 --> 0.092974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862888\n",
      "\tspeed: 0.1511s/iter; left time: 2165.2130s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853113\n",
      "\tspeed: 0.0511s/iter; left time: 727.3395s\n",
      "\titers: 300, epoch: 5 | loss: 0.0885890\n",
      "\tspeed: 0.0517s/iter; left time: 731.1419s\n",
      "\titers: 400, epoch: 5 | loss: 0.0850736\n",
      "\tspeed: 0.0519s/iter; left time: 728.7964s\n",
      "\titers: 500, epoch: 5 | loss: 0.0858059\n",
      "\tspeed: 0.0524s/iter; left time: 729.9799s\n",
      "\titers: 600, epoch: 5 | loss: 0.0846744\n",
      "\tspeed: 0.0512s/iter; left time: 707.6701s\n",
      "\titers: 700, epoch: 5 | loss: 0.0864810\n",
      "\tspeed: 0.0521s/iter; left time: 715.2550s\n",
      "\titers: 800, epoch: 5 | loss: 0.0868695\n",
      "\tspeed: 0.0525s/iter; left time: 715.1709s\n",
      "\titers: 900, epoch: 5 | loss: 0.0815381\n",
      "\tspeed: 0.0511s/iter; left time: 691.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 902 | Train Loss: 0.0866137 Vali Loss: 0.0950143 Test Loss: 0.1459457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0885002\n",
      "\tspeed: 0.1449s/iter; left time: 1946.3835s\n",
      "\titers: 200, epoch: 6 | loss: 0.0887537\n",
      "\tspeed: 0.0533s/iter; left time: 710.1734s\n",
      "\titers: 300, epoch: 6 | loss: 0.0861426\n",
      "\tspeed: 0.0537s/iter; left time: 710.5378s\n",
      "\titers: 400, epoch: 6 | loss: 0.0801997\n",
      "\tspeed: 0.0547s/iter; left time: 717.9256s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807461\n",
      "\tspeed: 0.0547s/iter; left time: 712.1461s\n",
      "\titers: 600, epoch: 6 | loss: 0.0818900\n",
      "\tspeed: 0.0542s/iter; left time: 701.1401s\n",
      "\titers: 700, epoch: 6 | loss: 0.0835803\n",
      "\tspeed: 0.0537s/iter; left time: 688.4465s\n",
      "\titers: 800, epoch: 6 | loss: 0.0846795\n",
      "\tspeed: 0.0515s/iter; left time: 655.2319s\n",
      "\titers: 900, epoch: 6 | loss: 0.0825628\n",
      "\tspeed: 0.0530s/iter; left time: 668.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.0825070 Vali Loss: 0.0925536 Test Loss: 0.1536084\n",
      "Validation loss decreased (0.092974 --> 0.092554).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785005\n",
      "\tspeed: 0.1469s/iter; left time: 1840.4137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756859\n",
      "\tspeed: 0.0545s/iter; left time: 677.7375s\n",
      "\titers: 300, epoch: 7 | loss: 0.0790050\n",
      "\tspeed: 0.0526s/iter; left time: 647.9304s\n",
      "\titers: 400, epoch: 7 | loss: 0.0765400\n",
      "\tspeed: 0.0532s/iter; left time: 650.0600s\n",
      "\titers: 500, epoch: 7 | loss: 0.0782865\n",
      "\tspeed: 0.0583s/iter; left time: 707.2088s\n",
      "\titers: 600, epoch: 7 | loss: 0.0761877\n",
      "\tspeed: 0.0555s/iter; left time: 667.4252s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772740\n",
      "\tspeed: 0.0558s/iter; left time: 665.3745s\n",
      "\titers: 800, epoch: 7 | loss: 0.0769790\n",
      "\tspeed: 0.0545s/iter; left time: 644.1345s\n",
      "\titers: 900, epoch: 7 | loss: 0.0764078\n",
      "\tspeed: 0.0549s/iter; left time: 643.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.52s\n",
      "Steps: 902 | Train Loss: 0.0786847 Vali Loss: 0.0959039 Test Loss: 0.1605772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771067\n",
      "\tspeed: 0.1438s/iter; left time: 1672.5169s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762483\n",
      "\tspeed: 0.0549s/iter; left time: 633.2333s\n",
      "\titers: 300, epoch: 8 | loss: 0.0753533\n",
      "\tspeed: 0.0553s/iter; left time: 631.6388s\n",
      "\titers: 400, epoch: 8 | loss: 0.0804044\n",
      "\tspeed: 0.0548s/iter; left time: 620.5940s\n",
      "\titers: 500, epoch: 8 | loss: 0.0772283\n",
      "\tspeed: 0.0555s/iter; left time: 623.1537s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727716\n",
      "\tspeed: 0.0544s/iter; left time: 605.8202s\n",
      "\titers: 700, epoch: 8 | loss: 0.0719767\n",
      "\tspeed: 0.0533s/iter; left time: 587.3938s\n",
      "\titers: 800, epoch: 8 | loss: 0.0737946\n",
      "\tspeed: 0.0533s/iter; left time: 581.8642s\n",
      "\titers: 900, epoch: 8 | loss: 0.0697558\n",
      "\tspeed: 0.0539s/iter; left time: 583.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.34s\n",
      "Steps: 902 | Train Loss: 0.0752117 Vali Loss: 0.0952677 Test Loss: 0.1705816\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0707476\n",
      "\tspeed: 0.1490s/iter; left time: 1598.4772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711046\n",
      "\tspeed: 0.0528s/iter; left time: 560.7472s\n",
      "\titers: 300, epoch: 9 | loss: 0.0731578\n",
      "\tspeed: 0.0540s/iter; left time: 568.1655s\n",
      "\titers: 400, epoch: 9 | loss: 0.0743887\n",
      "\tspeed: 0.0551s/iter; left time: 573.9173s\n",
      "\titers: 500, epoch: 9 | loss: 0.0720469\n",
      "\tspeed: 0.0533s/iter; left time: 550.5864s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696812\n",
      "\tspeed: 0.0532s/iter; left time: 543.5740s\n",
      "\titers: 700, epoch: 9 | loss: 0.0712176\n",
      "\tspeed: 0.0526s/iter; left time: 532.9702s\n",
      "\titers: 800, epoch: 9 | loss: 0.0743244\n",
      "\tspeed: 0.0534s/iter; left time: 535.5993s\n",
      "\titers: 900, epoch: 9 | loss: 0.0718729\n",
      "\tspeed: 0.0524s/iter; left time: 519.8514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.0719530 Vali Loss: 0.0969985 Test Loss: 0.1797135\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0683066\n",
      "\tspeed: 0.1437s/iter; left time: 1412.0437s\n",
      "\titers: 200, epoch: 10 | loss: 0.0716422\n",
      "\tspeed: 0.0526s/iter; left time: 511.4677s\n",
      "\titers: 300, epoch: 10 | loss: 0.0723626\n",
      "\tspeed: 0.0526s/iter; left time: 505.9720s\n",
      "\titers: 400, epoch: 10 | loss: 0.0699641\n",
      "\tspeed: 0.0539s/iter; left time: 513.3518s\n",
      "\titers: 500, epoch: 10 | loss: 0.0695303\n",
      "\tspeed: 0.0527s/iter; left time: 496.9047s\n",
      "\titers: 600, epoch: 10 | loss: 0.0675861\n",
      "\tspeed: 0.0536s/iter; left time: 500.0521s\n",
      "\titers: 700, epoch: 10 | loss: 0.0694537\n",
      "\tspeed: 0.0525s/iter; left time: 484.4969s\n",
      "\titers: 800, epoch: 10 | loss: 0.0755490\n",
      "\tspeed: 0.0534s/iter; left time: 486.8669s\n",
      "\titers: 900, epoch: 10 | loss: 0.0642353\n",
      "\tspeed: 0.0537s/iter; left time: 484.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.0689081 Vali Loss: 0.0958964 Test Loss: 0.1808414\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0662207\n",
      "\tspeed: 0.1443s/iter; left time: 1287.4279s\n",
      "\titers: 200, epoch: 11 | loss: 0.0688213\n",
      "\tspeed: 0.0524s/iter; left time: 462.1533s\n",
      "\titers: 300, epoch: 11 | loss: 0.0666703\n",
      "\tspeed: 0.0524s/iter; left time: 456.9465s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667215\n",
      "\tspeed: 0.0536s/iter; left time: 462.2141s\n",
      "\titers: 500, epoch: 11 | loss: 0.0642328\n",
      "\tspeed: 0.0520s/iter; left time: 442.7801s\n",
      "\titers: 600, epoch: 11 | loss: 0.0628756\n",
      "\tspeed: 0.0537s/iter; left time: 451.8185s\n",
      "\titers: 700, epoch: 11 | loss: 0.0666778\n",
      "\tspeed: 0.0536s/iter; left time: 446.3034s\n",
      "\titers: 800, epoch: 11 | loss: 0.0637921\n",
      "\tspeed: 0.0533s/iter; left time: 438.4866s\n",
      "\titers: 900, epoch: 11 | loss: 0.0647936\n",
      "\tspeed: 0.0533s/iter; left time: 433.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.23s\n",
      "Steps: 902 | Train Loss: 0.0661303 Vali Loss: 0.0938816 Test Loss: 0.1753303\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.059251438826322556, rmse:0.2434161901473999, mae:0.15362679958343506, rse:0.7149913311004639\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2349210\n",
      "\tspeed: 0.0544s/iter; left time: 976.2651s\n",
      "\titers: 200, epoch: 1 | loss: 0.2279838\n",
      "\tspeed: 0.0528s/iter; left time: 942.7319s\n",
      "\titers: 300, epoch: 1 | loss: 0.2191480\n",
      "\tspeed: 0.0532s/iter; left time: 943.7385s\n",
      "\titers: 400, epoch: 1 | loss: 0.2087048\n",
      "\tspeed: 0.0523s/iter; left time: 923.2847s\n",
      "\titers: 500, epoch: 1 | loss: 0.1916923\n",
      "\tspeed: 0.0523s/iter; left time: 916.7012s\n",
      "\titers: 600, epoch: 1 | loss: 0.1907430\n",
      "\tspeed: 0.0521s/iter; left time: 908.5827s\n",
      "\titers: 700, epoch: 1 | loss: 0.1920722\n",
      "\tspeed: 0.0524s/iter; left time: 907.8864s\n",
      "\titers: 800, epoch: 1 | loss: 0.1773725\n",
      "\tspeed: 0.0521s/iter; left time: 897.7489s\n",
      "\titers: 900, epoch: 1 | loss: 0.1780178\n",
      "\tspeed: 0.0522s/iter; left time: 895.1848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.56s\n",
      "Steps: 902 | Train Loss: 0.2070508 Vali Loss: 0.1749768 Test Loss: 0.2157735\n",
      "Validation loss decreased (inf --> 0.174977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1617161\n",
      "\tspeed: 0.1497s/iter; left time: 2550.5091s\n",
      "\titers: 200, epoch: 2 | loss: 0.1568196\n",
      "\tspeed: 0.0528s/iter; left time: 895.1930s\n",
      "\titers: 300, epoch: 2 | loss: 0.1507764\n",
      "\tspeed: 0.0525s/iter; left time: 883.5483s\n",
      "\titers: 400, epoch: 2 | loss: 0.1362563\n",
      "\tspeed: 0.0526s/iter; left time: 880.5542s\n",
      "\titers: 500, epoch: 2 | loss: 0.1151469\n",
      "\tspeed: 0.0531s/iter; left time: 882.8529s\n",
      "\titers: 600, epoch: 2 | loss: 0.1056248\n",
      "\tspeed: 0.0533s/iter; left time: 881.2900s\n",
      "\titers: 700, epoch: 2 | loss: 0.1037987\n",
      "\tspeed: 0.0535s/iter; left time: 879.3878s\n",
      "\titers: 800, epoch: 2 | loss: 0.1028209\n",
      "\tspeed: 0.0516s/iter; left time: 842.9393s\n",
      "\titers: 900, epoch: 2 | loss: 0.1003323\n",
      "\tspeed: 0.0520s/iter; left time: 843.6963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.80s\n",
      "Steps: 902 | Train Loss: 0.1284606 Vali Loss: 0.1045906 Test Loss: 0.1474278\n",
      "Validation loss decreased (0.174977 --> 0.104591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1005617\n",
      "\tspeed: 0.1443s/iter; left time: 2328.3111s\n",
      "\titers: 200, epoch: 3 | loss: 0.1018791\n",
      "\tspeed: 0.0519s/iter; left time: 832.1961s\n",
      "\titers: 300, epoch: 3 | loss: 0.0966349\n",
      "\tspeed: 0.0514s/iter; left time: 819.3177s\n",
      "\titers: 400, epoch: 3 | loss: 0.0967483\n",
      "\tspeed: 0.0513s/iter; left time: 812.2297s\n",
      "\titers: 500, epoch: 3 | loss: 0.0928284\n",
      "\tspeed: 0.0504s/iter; left time: 792.6062s\n",
      "\titers: 600, epoch: 3 | loss: 0.0995029\n",
      "\tspeed: 0.0536s/iter; left time: 838.8403s\n",
      "\titers: 700, epoch: 3 | loss: 0.0985659\n",
      "\tspeed: 0.0531s/iter; left time: 825.2069s\n",
      "\titers: 800, epoch: 3 | loss: 0.0971092\n",
      "\tspeed: 0.0518s/iter; left time: 799.3335s\n",
      "\titers: 900, epoch: 3 | loss: 0.0919120\n",
      "\tspeed: 0.0525s/iter; left time: 805.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.0970943 Vali Loss: 0.0964301 Test Loss: 0.1427914\n",
      "Validation loss decreased (0.104591 --> 0.096430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0905354\n",
      "\tspeed: 0.1455s/iter; left time: 2217.4364s\n",
      "\titers: 200, epoch: 4 | loss: 0.0956672\n",
      "\tspeed: 0.0529s/iter; left time: 800.5287s\n",
      "\titers: 300, epoch: 4 | loss: 0.0939741\n",
      "\tspeed: 0.0531s/iter; left time: 798.5403s\n",
      "\titers: 400, epoch: 4 | loss: 0.0921513\n",
      "\tspeed: 0.0530s/iter; left time: 790.8765s\n",
      "\titers: 500, epoch: 4 | loss: 0.0914307\n",
      "\tspeed: 0.0515s/iter; left time: 764.4590s\n",
      "\titers: 600, epoch: 4 | loss: 0.0860426\n",
      "\tspeed: 0.0527s/iter; left time: 775.9998s\n",
      "\titers: 700, epoch: 4 | loss: 0.0933233\n",
      "\tspeed: 0.0501s/iter; left time: 732.9929s\n",
      "\titers: 800, epoch: 4 | loss: 0.0861083\n",
      "\tspeed: 0.0516s/iter; left time: 750.1494s\n",
      "\titers: 900, epoch: 4 | loss: 0.0898743\n",
      "\tspeed: 0.0515s/iter; left time: 742.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.0903123 Vali Loss: 0.0957017 Test Loss: 0.1425941\n",
      "Validation loss decreased (0.096430 --> 0.095702).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0847614\n",
      "\tspeed: 0.1452s/iter; left time: 2081.1395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937782\n",
      "\tspeed: 0.0506s/iter; left time: 720.4432s\n",
      "\titers: 300, epoch: 5 | loss: 0.0876471\n",
      "\tspeed: 0.0536s/iter; left time: 757.9856s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887670\n",
      "\tspeed: 0.0520s/iter; left time: 730.1675s\n",
      "\titers: 500, epoch: 5 | loss: 0.0893669\n",
      "\tspeed: 0.0515s/iter; left time: 717.0674s\n",
      "\titers: 600, epoch: 5 | loss: 0.0840157\n",
      "\tspeed: 0.0524s/iter; left time: 725.5151s\n",
      "\titers: 700, epoch: 5 | loss: 0.0800300\n",
      "\tspeed: 0.0516s/iter; left time: 708.5058s\n",
      "\titers: 800, epoch: 5 | loss: 0.0872025\n",
      "\tspeed: 0.0524s/iter; left time: 714.4685s\n",
      "\titers: 900, epoch: 5 | loss: 0.0851304\n",
      "\tspeed: 0.0513s/iter; left time: 694.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.20s\n",
      "Steps: 902 | Train Loss: 0.0854653 Vali Loss: 0.0925818 Test Loss: 0.1454035\n",
      "Validation loss decreased (0.095702 --> 0.092582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808024\n",
      "\tspeed: 0.1489s/iter; left time: 1999.5463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0885766\n",
      "\tspeed: 0.0520s/iter; left time: 693.4472s\n",
      "\titers: 300, epoch: 6 | loss: 0.0827625\n",
      "\tspeed: 0.0521s/iter; left time: 689.2404s\n",
      "\titers: 400, epoch: 6 | loss: 0.0804902\n",
      "\tspeed: 0.0522s/iter; left time: 685.3654s\n",
      "\titers: 500, epoch: 6 | loss: 0.0835528\n",
      "\tspeed: 0.0518s/iter; left time: 675.4753s\n",
      "\titers: 600, epoch: 6 | loss: 0.0793270\n",
      "\tspeed: 0.0535s/iter; left time: 692.0030s\n",
      "\titers: 700, epoch: 6 | loss: 0.0842770\n",
      "\tspeed: 0.0524s/iter; left time: 672.9244s\n",
      "\titers: 800, epoch: 6 | loss: 0.0834730\n",
      "\tspeed: 0.0538s/iter; left time: 684.7118s\n",
      "\titers: 900, epoch: 6 | loss: 0.0774157\n",
      "\tspeed: 0.0540s/iter; left time: 682.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.81s\n",
      "Steps: 902 | Train Loss: 0.0813975 Vali Loss: 0.0921341 Test Loss: 0.1452484\n",
      "Validation loss decreased (0.092582 --> 0.092134).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779524\n",
      "\tspeed: 0.1479s/iter; left time: 1853.2045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771557\n",
      "\tspeed: 0.0518s/iter; left time: 643.8084s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816080\n",
      "\tspeed: 0.0545s/iter; left time: 671.5264s\n",
      "\titers: 400, epoch: 7 | loss: 0.0794977\n",
      "\tspeed: 0.0528s/iter; left time: 645.3208s\n",
      "\titers: 500, epoch: 7 | loss: 0.0854444\n",
      "\tspeed: 0.0541s/iter; left time: 656.7240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0777031\n",
      "\tspeed: 0.0539s/iter; left time: 647.8878s\n",
      "\titers: 700, epoch: 7 | loss: 0.0810900\n",
      "\tspeed: 0.0544s/iter; left time: 648.9561s\n",
      "\titers: 800, epoch: 7 | loss: 0.0756242\n",
      "\tspeed: 0.0522s/iter; left time: 616.9586s\n",
      "\titers: 900, epoch: 7 | loss: 0.0795688\n",
      "\tspeed: 0.0531s/iter; left time: 622.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.0777726 Vali Loss: 0.0932417 Test Loss: 0.1590466\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0717619\n",
      "\tspeed: 0.1476s/iter; left time: 1715.7293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806814\n",
      "\tspeed: 0.0541s/iter; left time: 623.4765s\n",
      "\titers: 300, epoch: 8 | loss: 0.0720096\n",
      "\tspeed: 0.0544s/iter; left time: 621.9014s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708151\n",
      "\tspeed: 0.0538s/iter; left time: 609.6725s\n",
      "\titers: 500, epoch: 8 | loss: 0.0770770\n",
      "\tspeed: 0.0540s/iter; left time: 605.8227s\n",
      "\titers: 600, epoch: 8 | loss: 0.0690221\n",
      "\tspeed: 0.0536s/iter; left time: 595.8697s\n",
      "\titers: 700, epoch: 8 | loss: 0.0720180\n",
      "\tspeed: 0.0541s/iter; left time: 596.6386s\n",
      "\titers: 800, epoch: 8 | loss: 0.0740105\n",
      "\tspeed: 0.0537s/iter; left time: 586.3305s\n",
      "\titers: 900, epoch: 8 | loss: 0.0766453\n",
      "\tspeed: 0.0540s/iter; left time: 584.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.0742275 Vali Loss: 0.0959616 Test Loss: 0.1693050\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726401\n",
      "\tspeed: 0.1448s/iter; left time: 1552.8867s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666279\n",
      "\tspeed: 0.0539s/iter; left time: 572.4371s\n",
      "\titers: 300, epoch: 9 | loss: 0.0707830\n",
      "\tspeed: 0.0531s/iter; left time: 558.9579s\n",
      "\titers: 400, epoch: 9 | loss: 0.0732539\n",
      "\tspeed: 0.0532s/iter; left time: 555.0676s\n",
      "\titers: 500, epoch: 9 | loss: 0.0725338\n",
      "\tspeed: 0.0519s/iter; left time: 536.2630s\n",
      "\titers: 600, epoch: 9 | loss: 0.0685830\n",
      "\tspeed: 0.0524s/iter; left time: 535.4196s\n",
      "\titers: 700, epoch: 9 | loss: 0.0691205\n",
      "\tspeed: 0.0513s/iter; left time: 519.7935s\n",
      "\titers: 800, epoch: 9 | loss: 0.0638777\n",
      "\tspeed: 0.0522s/iter; left time: 523.2924s\n",
      "\titers: 900, epoch: 9 | loss: 0.0657238\n",
      "\tspeed: 0.0528s/iter; left time: 523.8445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.71s\n",
      "Steps: 902 | Train Loss: 0.0708883 Vali Loss: 0.0933904 Test Loss: 0.1672392\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0691511\n",
      "\tspeed: 0.1458s/iter; left time: 1431.8984s\n",
      "\titers: 200, epoch: 10 | loss: 0.0717913\n",
      "\tspeed: 0.0517s/iter; left time: 502.4328s\n",
      "\titers: 300, epoch: 10 | loss: 0.0665604\n",
      "\tspeed: 0.0538s/iter; left time: 518.0027s\n",
      "\titers: 400, epoch: 10 | loss: 0.0681423\n",
      "\tspeed: 0.0538s/iter; left time: 512.1897s\n",
      "\titers: 500, epoch: 10 | loss: 0.0683971\n",
      "\tspeed: 0.0535s/iter; left time: 504.1959s\n",
      "\titers: 600, epoch: 10 | loss: 0.0674540\n",
      "\tspeed: 0.0518s/iter; left time: 482.7737s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714129\n",
      "\tspeed: 0.0535s/iter; left time: 493.2585s\n",
      "\titers: 800, epoch: 10 | loss: 0.0681712\n",
      "\tspeed: 0.0541s/iter; left time: 493.4230s\n",
      "\titers: 900, epoch: 10 | loss: 0.0643739\n",
      "\tspeed: 0.0521s/iter; left time: 470.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.14s\n",
      "Steps: 902 | Train Loss: 0.0681751 Vali Loss: 0.0937885 Test Loss: 0.1629257\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0640436\n",
      "\tspeed: 0.1466s/iter; left time: 1307.8026s\n",
      "\titers: 200, epoch: 11 | loss: 0.0631882\n",
      "\tspeed: 0.0529s/iter; left time: 466.7173s\n",
      "\titers: 300, epoch: 11 | loss: 0.0633764\n",
      "\tspeed: 0.0515s/iter; left time: 449.3352s\n",
      "\titers: 400, epoch: 11 | loss: 0.0611668\n",
      "\tspeed: 0.0525s/iter; left time: 452.3608s\n",
      "\titers: 500, epoch: 11 | loss: 0.0607350\n",
      "\tspeed: 0.0520s/iter; left time: 443.2550s\n",
      "\titers: 600, epoch: 11 | loss: 0.0656816\n",
      "\tspeed: 0.0530s/iter; left time: 446.6461s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642508\n",
      "\tspeed: 0.0519s/iter; left time: 431.8194s\n",
      "\titers: 800, epoch: 11 | loss: 0.0654244\n",
      "\tspeed: 0.0521s/iter; left time: 428.1195s\n",
      "\titers: 900, epoch: 11 | loss: 0.0648274\n",
      "\tspeed: 0.0529s/iter; left time: 429.7854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.79s\n",
      "Steps: 902 | Train Loss: 0.0653278 Vali Loss: 0.0973051 Test Loss: 0.1744384\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05074656754732132, rmse:0.22526998817920685, mae:0.14528633654117584, rse:0.6616901159286499\n",
      "Intermediate time for ES and pred_len 168: 00h:21m:13.79s\n",
      "Intermediate time for ES: 01h:12m:50.45s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1739433\n",
      "\tspeed: 0.0545s/iter; left time: 981.9162s\n",
      "\titers: 200, epoch: 1 | loss: 0.1698646\n",
      "\tspeed: 0.0410s/iter; left time: 734.9585s\n",
      "\titers: 300, epoch: 1 | loss: 0.1628093\n",
      "\tspeed: 0.0389s/iter; left time: 692.9846s\n",
      "\titers: 400, epoch: 1 | loss: 0.1506268\n",
      "\tspeed: 0.0381s/iter; left time: 674.8135s\n",
      "\titers: 500, epoch: 1 | loss: 0.1512203\n",
      "\tspeed: 0.0383s/iter; left time: 675.3318s\n",
      "\titers: 600, epoch: 1 | loss: 0.1498979\n",
      "\tspeed: 0.0394s/iter; left time: 690.5871s\n",
      "\titers: 700, epoch: 1 | loss: 0.1457416\n",
      "\tspeed: 0.0391s/iter; left time: 681.4140s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485578\n",
      "\tspeed: 0.0377s/iter; left time: 652.7581s\n",
      "\titers: 900, epoch: 1 | loss: 0.1391965\n",
      "\tspeed: 0.0382s/iter; left time: 657.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.00s\n",
      "Steps: 906 | Train Loss: 0.1572056 Vali Loss: 0.1463180 Test Loss: 0.1671409\n",
      "Validation loss decreased (inf --> 0.146318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182796\n",
      "\tspeed: 0.1090s/iter; left time: 1865.3764s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924962\n",
      "\tspeed: 0.0388s/iter; left time: 659.4949s\n",
      "\titers: 300, epoch: 2 | loss: 0.0810476\n",
      "\tspeed: 0.0374s/iter; left time: 632.1690s\n",
      "\titers: 400, epoch: 2 | loss: 0.0683360\n",
      "\tspeed: 0.0394s/iter; left time: 662.9679s\n",
      "\titers: 500, epoch: 2 | loss: 0.0648645\n",
      "\tspeed: 0.0387s/iter; left time: 646.9797s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752140\n",
      "\tspeed: 0.0379s/iter; left time: 629.7756s\n",
      "\titers: 700, epoch: 2 | loss: 0.0643508\n",
      "\tspeed: 0.0387s/iter; left time: 638.3899s\n",
      "\titers: 800, epoch: 2 | loss: 0.0680291\n",
      "\tspeed: 0.0389s/iter; left time: 638.2195s\n",
      "\titers: 900, epoch: 2 | loss: 0.0632531\n",
      "\tspeed: 0.0391s/iter; left time: 638.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.59s\n",
      "Steps: 906 | Train Loss: 0.0802678 Vali Loss: 0.0658131 Test Loss: 0.0756742\n",
      "Validation loss decreased (0.146318 --> 0.065813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0590658\n",
      "\tspeed: 0.1098s/iter; left time: 1779.5694s\n",
      "\titers: 200, epoch: 3 | loss: 0.0515479\n",
      "\tspeed: 0.0396s/iter; left time: 638.3218s\n",
      "\titers: 300, epoch: 3 | loss: 0.0599568\n",
      "\tspeed: 0.0365s/iter; left time: 583.9626s\n",
      "\titers: 400, epoch: 3 | loss: 0.0562826\n",
      "\tspeed: 0.0400s/iter; left time: 636.0786s\n",
      "\titers: 500, epoch: 3 | loss: 0.0613825\n",
      "\tspeed: 0.0382s/iter; left time: 603.6933s\n",
      "\titers: 600, epoch: 3 | loss: 0.0567336\n",
      "\tspeed: 0.0402s/iter; left time: 630.9852s\n",
      "\titers: 700, epoch: 3 | loss: 0.0552840\n",
      "\tspeed: 0.0390s/iter; left time: 608.4750s\n",
      "\titers: 800, epoch: 3 | loss: 0.0479929\n",
      "\tspeed: 0.0403s/iter; left time: 624.8499s\n",
      "\titers: 900, epoch: 3 | loss: 0.0459714\n",
      "\tspeed: 0.0391s/iter; left time: 601.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.68s\n",
      "Steps: 906 | Train Loss: 0.0553792 Vali Loss: 0.0635076 Test Loss: 0.0724751\n",
      "Validation loss decreased (0.065813 --> 0.063508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0503195\n",
      "\tspeed: 0.1085s/iter; left time: 1660.2666s\n",
      "\titers: 200, epoch: 4 | loss: 0.0478199\n",
      "\tspeed: 0.0394s/iter; left time: 599.5076s\n",
      "\titers: 300, epoch: 4 | loss: 0.0544001\n",
      "\tspeed: 0.0395s/iter; left time: 595.9972s\n",
      "\titers: 400, epoch: 4 | loss: 0.0519251\n",
      "\tspeed: 0.0366s/iter; left time: 549.3323s\n",
      "\titers: 500, epoch: 4 | loss: 0.0462065\n",
      "\tspeed: 0.0374s/iter; left time: 556.7468s\n",
      "\titers: 600, epoch: 4 | loss: 0.0428687\n",
      "\tspeed: 0.0396s/iter; left time: 586.4738s\n",
      "\titers: 700, epoch: 4 | loss: 0.0567114\n",
      "\tspeed: 0.0381s/iter; left time: 560.3176s\n",
      "\titers: 800, epoch: 4 | loss: 0.0539834\n",
      "\tspeed: 0.0379s/iter; left time: 553.6395s\n",
      "\titers: 900, epoch: 4 | loss: 0.0465132\n",
      "\tspeed: 0.0393s/iter; left time: 570.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.43s\n",
      "Steps: 906 | Train Loss: 0.0516731 Vali Loss: 0.0619425 Test Loss: 0.0685361\n",
      "Validation loss decreased (0.063508 --> 0.061942).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0494203\n",
      "\tspeed: 0.1117s/iter; left time: 1608.0445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0499139\n",
      "\tspeed: 0.0395s/iter; left time: 564.7785s\n",
      "\titers: 300, epoch: 5 | loss: 0.0500820\n",
      "\tspeed: 0.0391s/iter; left time: 555.3451s\n",
      "\titers: 400, epoch: 5 | loss: 0.0480923\n",
      "\tspeed: 0.0401s/iter; left time: 565.4548s\n",
      "\titers: 500, epoch: 5 | loss: 0.0483339\n",
      "\tspeed: 0.0403s/iter; left time: 563.6466s\n",
      "\titers: 600, epoch: 5 | loss: 0.0575161\n",
      "\tspeed: 0.0395s/iter; left time: 549.1202s\n",
      "\titers: 700, epoch: 5 | loss: 0.0527869\n",
      "\tspeed: 0.0402s/iter; left time: 554.5915s\n",
      "\titers: 800, epoch: 5 | loss: 0.0443416\n",
      "\tspeed: 0.0439s/iter; left time: 601.7954s\n",
      "\titers: 900, epoch: 5 | loss: 0.0465798\n",
      "\tspeed: 0.0444s/iter; left time: 604.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.49s\n",
      "Steps: 906 | Train Loss: 0.0490737 Vali Loss: 0.0608070 Test Loss: 0.0667752\n",
      "Validation loss decreased (0.061942 --> 0.060807).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0477781\n",
      "\tspeed: 0.1185s/iter; left time: 1598.3768s\n",
      "\titers: 200, epoch: 6 | loss: 0.0399382\n",
      "\tspeed: 0.0426s/iter; left time: 569.9910s\n",
      "\titers: 300, epoch: 6 | loss: 0.0452826\n",
      "\tspeed: 0.0408s/iter; left time: 541.8222s\n",
      "\titers: 400, epoch: 6 | loss: 0.0539995\n",
      "\tspeed: 0.0428s/iter; left time: 564.8477s\n",
      "\titers: 500, epoch: 6 | loss: 0.0418926\n",
      "\tspeed: 0.0406s/iter; left time: 532.1151s\n",
      "\titers: 600, epoch: 6 | loss: 0.0522295\n",
      "\tspeed: 0.0413s/iter; left time: 536.6030s\n",
      "\titers: 700, epoch: 6 | loss: 0.0463074\n",
      "\tspeed: 0.0396s/iter; left time: 510.0412s\n",
      "\titers: 800, epoch: 6 | loss: 0.0447749\n",
      "\tspeed: 0.0382s/iter; left time: 488.5759s\n",
      "\titers: 900, epoch: 6 | loss: 0.0478271\n",
      "\tspeed: 0.0404s/iter; left time: 512.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.45s\n",
      "Steps: 906 | Train Loss: 0.0473443 Vali Loss: 0.0609044 Test Loss: 0.0686819\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0404355\n",
      "\tspeed: 0.1047s/iter; left time: 1318.0163s\n",
      "\titers: 200, epoch: 7 | loss: 0.0545798\n",
      "\tspeed: 0.0433s/iter; left time: 540.6449s\n",
      "\titers: 300, epoch: 7 | loss: 0.0438270\n",
      "\tspeed: 0.0452s/iter; left time: 559.7783s\n",
      "\titers: 400, epoch: 7 | loss: 0.0470609\n",
      "\tspeed: 0.0431s/iter; left time: 529.7680s\n",
      "\titers: 500, epoch: 7 | loss: 0.0418809\n",
      "\tspeed: 0.0441s/iter; left time: 537.3889s\n",
      "\titers: 600, epoch: 7 | loss: 0.0415065\n",
      "\tspeed: 0.0410s/iter; left time: 495.7367s\n",
      "\titers: 700, epoch: 7 | loss: 0.0461207\n",
      "\tspeed: 0.0391s/iter; left time: 469.0107s\n",
      "\titers: 800, epoch: 7 | loss: 0.0440742\n",
      "\tspeed: 0.0400s/iter; left time: 475.7026s\n",
      "\titers: 900, epoch: 7 | loss: 0.0388834\n",
      "\tspeed: 0.0400s/iter; left time: 471.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.0455381 Vali Loss: 0.0588701 Test Loss: 0.0653362\n",
      "Validation loss decreased (0.060807 --> 0.058870).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0394117\n",
      "\tspeed: 0.1090s/iter; left time: 1272.7909s\n",
      "\titers: 200, epoch: 8 | loss: 0.0441284\n",
      "\tspeed: 0.0427s/iter; left time: 494.3665s\n",
      "\titers: 300, epoch: 8 | loss: 0.0406993\n",
      "\tspeed: 0.0436s/iter; left time: 500.9457s\n",
      "\titers: 400, epoch: 8 | loss: 0.0489252\n",
      "\tspeed: 0.0410s/iter; left time: 466.1972s\n",
      "\titers: 500, epoch: 8 | loss: 0.0420747\n",
      "\tspeed: 0.0411s/iter; left time: 463.9701s\n",
      "\titers: 600, epoch: 8 | loss: 0.0420048\n",
      "\tspeed: 0.0386s/iter; left time: 431.9772s\n",
      "\titers: 700, epoch: 8 | loss: 0.0441453\n",
      "\tspeed: 0.0394s/iter; left time: 436.1680s\n",
      "\titers: 800, epoch: 8 | loss: 0.0445756\n",
      "\tspeed: 0.0386s/iter; left time: 423.6749s\n",
      "\titers: 900, epoch: 8 | loss: 0.0459655\n",
      "\tspeed: 0.0396s/iter; left time: 430.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.0444504 Vali Loss: 0.0598973 Test Loss: 0.0679733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0412332\n",
      "\tspeed: 0.1013s/iter; left time: 1091.5147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0436754\n",
      "\tspeed: 0.0383s/iter; left time: 408.3242s\n",
      "\titers: 300, epoch: 9 | loss: 0.0464150\n",
      "\tspeed: 0.0384s/iter; left time: 405.9599s\n",
      "\titers: 400, epoch: 9 | loss: 0.0429204\n",
      "\tspeed: 0.0388s/iter; left time: 406.6853s\n",
      "\titers: 500, epoch: 9 | loss: 0.0452812\n",
      "\tspeed: 0.0330s/iter; left time: 342.6839s\n",
      "\titers: 600, epoch: 9 | loss: 0.0380351\n",
      "\tspeed: 0.0411s/iter; left time: 421.8096s\n",
      "\titers: 700, epoch: 9 | loss: 0.0369139\n",
      "\tspeed: 0.0403s/iter; left time: 409.7010s\n",
      "\titers: 800, epoch: 9 | loss: 0.0397433\n",
      "\tspeed: 0.0425s/iter; left time: 428.2902s\n",
      "\titers: 900, epoch: 9 | loss: 0.0355174\n",
      "\tspeed: 0.0420s/iter; left time: 418.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:35.85s\n",
      "Steps: 906 | Train Loss: 0.0431518 Vali Loss: 0.0585733 Test Loss: 0.0657527\n",
      "Validation loss decreased (0.058870 --> 0.058573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0438814\n",
      "\tspeed: 0.1108s/iter; left time: 1092.8122s\n",
      "\titers: 200, epoch: 10 | loss: 0.0401150\n",
      "\tspeed: 0.0430s/iter; left time: 420.4002s\n",
      "\titers: 300, epoch: 10 | loss: 0.0440580\n",
      "\tspeed: 0.0427s/iter; left time: 412.3520s\n",
      "\titers: 400, epoch: 10 | loss: 0.0475025\n",
      "\tspeed: 0.0434s/iter; left time: 415.6676s\n",
      "\titers: 500, epoch: 10 | loss: 0.0337716\n",
      "\tspeed: 0.0422s/iter; left time: 399.0959s\n",
      "\titers: 600, epoch: 10 | loss: 0.0398108\n",
      "\tspeed: 0.0439s/iter; left time: 410.9621s\n",
      "\titers: 700, epoch: 10 | loss: 0.0447894\n",
      "\tspeed: 0.0397s/iter; left time: 367.9111s\n",
      "\titers: 800, epoch: 10 | loss: 0.0408278\n",
      "\tspeed: 0.0393s/iter; left time: 360.0389s\n",
      "\titers: 900, epoch: 10 | loss: 0.0431183\n",
      "\tspeed: 0.0405s/iter; left time: 367.1176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.0416804 Vali Loss: 0.0569647 Test Loss: 0.0654366\n",
      "Validation loss decreased (0.058573 --> 0.056965).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0437250\n",
      "\tspeed: 0.1081s/iter; left time: 968.6066s\n",
      "\titers: 200, epoch: 11 | loss: 0.0444618\n",
      "\tspeed: 0.0423s/iter; left time: 374.4090s\n",
      "\titers: 300, epoch: 11 | loss: 0.0372252\n",
      "\tspeed: 0.0405s/iter; left time: 355.1405s\n",
      "\titers: 400, epoch: 11 | loss: 0.0400675\n",
      "\tspeed: 0.0410s/iter; left time: 354.8291s\n",
      "\titers: 500, epoch: 11 | loss: 0.0479926\n",
      "\tspeed: 0.0386s/iter; left time: 330.6914s\n",
      "\titers: 600, epoch: 11 | loss: 0.0441770\n",
      "\tspeed: 0.0396s/iter; left time: 334.8742s\n",
      "\titers: 700, epoch: 11 | loss: 0.0421550\n",
      "\tspeed: 0.0411s/iter; left time: 343.9627s\n",
      "\titers: 800, epoch: 11 | loss: 0.0402640\n",
      "\tspeed: 0.0392s/iter; left time: 323.9813s\n",
      "\titers: 900, epoch: 11 | loss: 0.0424030\n",
      "\tspeed: 0.0407s/iter; left time: 331.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.02s\n",
      "Steps: 906 | Train Loss: 0.0402147 Vali Loss: 0.0575275 Test Loss: 0.0661826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0367234\n",
      "\tspeed: 0.1064s/iter; left time: 856.9594s\n",
      "\titers: 200, epoch: 12 | loss: 0.0441120\n",
      "\tspeed: 0.0445s/iter; left time: 353.6076s\n",
      "\titers: 300, epoch: 12 | loss: 0.0377974\n",
      "\tspeed: 0.0424s/iter; left time: 332.7427s\n",
      "\titers: 400, epoch: 12 | loss: 0.0402544\n",
      "\tspeed: 0.0402s/iter; left time: 311.9148s\n",
      "\titers: 500, epoch: 12 | loss: 0.0366363\n",
      "\tspeed: 0.0444s/iter; left time: 339.6338s\n",
      "\titers: 600, epoch: 12 | loss: 0.0380469\n",
      "\tspeed: 0.0409s/iter; left time: 308.6835s\n",
      "\titers: 700, epoch: 12 | loss: 0.0380596\n",
      "\tspeed: 0.0389s/iter; left time: 289.9684s\n",
      "\titers: 800, epoch: 12 | loss: 0.0357173\n",
      "\tspeed: 0.0386s/iter; left time: 284.0102s\n",
      "\titers: 900, epoch: 12 | loss: 0.0374893\n",
      "\tspeed: 0.0377s/iter; left time: 273.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.56s\n",
      "Steps: 906 | Train Loss: 0.0390284 Vali Loss: 0.0570473 Test Loss: 0.0645510\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0410800\n",
      "\tspeed: 0.1058s/iter; left time: 756.0804s\n",
      "\titers: 200, epoch: 13 | loss: 0.0377162\n",
      "\tspeed: 0.0452s/iter; left time: 318.6452s\n",
      "\titers: 300, epoch: 13 | loss: 0.0337014\n",
      "\tspeed: 0.0417s/iter; left time: 289.5847s\n",
      "\titers: 400, epoch: 13 | loss: 0.0352647\n",
      "\tspeed: 0.0380s/iter; left time: 260.0731s\n",
      "\titers: 500, epoch: 13 | loss: 0.0410597\n",
      "\tspeed: 0.0370s/iter; left time: 249.5504s\n",
      "\titers: 600, epoch: 13 | loss: 0.0352836\n",
      "\tspeed: 0.0385s/iter; left time: 255.7908s\n",
      "\titers: 700, epoch: 13 | loss: 0.0384835\n",
      "\tspeed: 0.0382s/iter; left time: 250.3786s\n",
      "\titers: 800, epoch: 13 | loss: 0.0338243\n",
      "\tspeed: 0.0407s/iter; left time: 262.1869s\n",
      "\titers: 900, epoch: 13 | loss: 0.0383945\n",
      "\tspeed: 0.0420s/iter; left time: 266.7598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:36.87s\n",
      "Steps: 906 | Train Loss: 0.0381592 Vali Loss: 0.0571874 Test Loss: 0.0657793\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0388397\n",
      "\tspeed: 0.1030s/iter; left time: 642.9936s\n",
      "\titers: 200, epoch: 14 | loss: 0.0342924\n",
      "\tspeed: 0.0370s/iter; left time: 227.1508s\n",
      "\titers: 300, epoch: 14 | loss: 0.0353495\n",
      "\tspeed: 0.0407s/iter; left time: 245.7718s\n",
      "\titers: 400, epoch: 14 | loss: 0.0359039\n",
      "\tspeed: 0.0384s/iter; left time: 228.2510s\n",
      "\titers: 500, epoch: 14 | loss: 0.0381349\n",
      "\tspeed: 0.0396s/iter; left time: 231.1223s\n",
      "\titers: 600, epoch: 14 | loss: 0.0381662\n",
      "\tspeed: 0.0387s/iter; left time: 222.1007s\n",
      "\titers: 700, epoch: 14 | loss: 0.0357963\n",
      "\tspeed: 0.0374s/iter; left time: 210.9807s\n",
      "\titers: 800, epoch: 14 | loss: 0.0473406\n",
      "\tspeed: 0.0394s/iter; left time: 218.3380s\n",
      "\titers: 900, epoch: 14 | loss: 0.0343527\n",
      "\tspeed: 0.0386s/iter; left time: 209.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:35.37s\n",
      "Steps: 906 | Train Loss: 0.0372811 Vali Loss: 0.0566014 Test Loss: 0.0641220\n",
      "Validation loss decreased (0.056965 --> 0.056601).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0387673\n",
      "\tspeed: 0.1109s/iter; left time: 591.7178s\n",
      "\titers: 200, epoch: 15 | loss: 0.0376668\n",
      "\tspeed: 0.0431s/iter; left time: 225.5859s\n",
      "\titers: 300, epoch: 15 | loss: 0.0340129\n",
      "\tspeed: 0.0405s/iter; left time: 208.0257s\n",
      "\titers: 400, epoch: 15 | loss: 0.0356156\n",
      "\tspeed: 0.0420s/iter; left time: 211.3633s\n",
      "\titers: 500, epoch: 15 | loss: 0.0341311\n",
      "\tspeed: 0.0432s/iter; left time: 213.2384s\n",
      "\titers: 600, epoch: 15 | loss: 0.0390709\n",
      "\tspeed: 0.0416s/iter; left time: 200.9851s\n",
      "\titers: 700, epoch: 15 | loss: 0.0334687\n",
      "\tspeed: 0.0383s/iter; left time: 181.4522s\n",
      "\titers: 800, epoch: 15 | loss: 0.0408071\n",
      "\tspeed: 0.0377s/iter; left time: 174.5888s\n",
      "\titers: 900, epoch: 15 | loss: 0.0364410\n",
      "\tspeed: 0.0388s/iter; left time: 176.1881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 906 | Train Loss: 0.0367306 Vali Loss: 0.0574687 Test Loss: 0.0659029\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0368593\n",
      "\tspeed: 0.1024s/iter; left time: 453.8384s\n",
      "\titers: 200, epoch: 16 | loss: 0.0431039\n",
      "\tspeed: 0.0426s/iter; left time: 184.6693s\n",
      "\titers: 300, epoch: 16 | loss: 0.0384472\n",
      "\tspeed: 0.0413s/iter; left time: 174.8084s\n",
      "\titers: 400, epoch: 16 | loss: 0.0352341\n",
      "\tspeed: 0.0405s/iter; left time: 167.1825s\n",
      "\titers: 500, epoch: 16 | loss: 0.0311277\n",
      "\tspeed: 0.0396s/iter; left time: 159.5497s\n",
      "\titers: 600, epoch: 16 | loss: 0.0366535\n",
      "\tspeed: 0.0382s/iter; left time: 150.3405s\n",
      "\titers: 700, epoch: 16 | loss: 0.0330081\n",
      "\tspeed: 0.0388s/iter; left time: 148.7461s\n",
      "\titers: 800, epoch: 16 | loss: 0.0367885\n",
      "\tspeed: 0.0380s/iter; left time: 141.8650s\n",
      "\titers: 900, epoch: 16 | loss: 0.0353695\n",
      "\tspeed: 0.0392s/iter; left time: 142.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:36.24s\n",
      "Steps: 906 | Train Loss: 0.0359501 Vali Loss: 0.0579413 Test Loss: 0.0662559\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387607\n",
      "\tspeed: 0.1062s/iter; left time: 374.2456s\n",
      "\titers: 200, epoch: 17 | loss: 0.0358092\n",
      "\tspeed: 0.0427s/iter; left time: 146.1709s\n",
      "\titers: 300, epoch: 17 | loss: 0.0380436\n",
      "\tspeed: 0.0437s/iter; left time: 145.3790s\n",
      "\titers: 400, epoch: 17 | loss: 0.0352150\n",
      "\tspeed: 0.0388s/iter; left time: 125.1843s\n",
      "\titers: 500, epoch: 17 | loss: 0.0336286\n",
      "\tspeed: 0.0429s/iter; left time: 134.1436s\n",
      "\titers: 600, epoch: 17 | loss: 0.0328397\n",
      "\tspeed: 0.0384s/iter; left time: 116.1102s\n",
      "\titers: 700, epoch: 17 | loss: 0.0385101\n",
      "\tspeed: 0.0389s/iter; left time: 113.6682s\n",
      "\titers: 800, epoch: 17 | loss: 0.0363401\n",
      "\tspeed: 0.0403s/iter; left time: 113.7904s\n",
      "\titers: 900, epoch: 17 | loss: 0.0418978\n",
      "\tspeed: 0.0378s/iter; left time: 103.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:37.15s\n",
      "Steps: 906 | Train Loss: 0.0353823 Vali Loss: 0.0571683 Test Loss: 0.0651751\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0348546\n",
      "\tspeed: 0.1039s/iter; left time: 272.0614s\n",
      "\titers: 200, epoch: 18 | loss: 0.0355422\n",
      "\tspeed: 0.0398s/iter; left time: 100.3225s\n",
      "\titers: 300, epoch: 18 | loss: 0.0365842\n",
      "\tspeed: 0.0393s/iter; left time: 95.0118s\n",
      "\titers: 400, epoch: 18 | loss: 0.0375368\n",
      "\tspeed: 0.0382s/iter; left time: 88.6326s\n",
      "\titers: 500, epoch: 18 | loss: 0.0391709\n",
      "\tspeed: 0.0382s/iter; left time: 84.8221s\n",
      "\titers: 600, epoch: 18 | loss: 0.0359639\n",
      "\tspeed: 0.0398s/iter; left time: 84.2761s\n",
      "\titers: 700, epoch: 18 | loss: 0.0451567\n",
      "\tspeed: 0.0408s/iter; left time: 82.3707s\n",
      "\titers: 800, epoch: 18 | loss: 0.0332086\n",
      "\tspeed: 0.0404s/iter; left time: 77.5710s\n",
      "\titers: 900, epoch: 18 | loss: 0.0385903\n",
      "\tspeed: 0.0449s/iter; left time: 81.5982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.0347825 Vali Loss: 0.0575072 Test Loss: 0.0649085\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0343457\n",
      "\tspeed: 0.1052s/iter; left time: 180.1607s\n",
      "\titers: 200, epoch: 19 | loss: 0.0324227\n",
      "\tspeed: 0.0433s/iter; left time: 69.9122s\n",
      "\titers: 300, epoch: 19 | loss: 0.0352254\n",
      "\tspeed: 0.0439s/iter; left time: 66.3869s\n",
      "\titers: 400, epoch: 19 | loss: 0.0333225\n",
      "\tspeed: 0.0432s/iter; left time: 61.0403s\n",
      "\titers: 500, epoch: 19 | loss: 0.0341113\n",
      "\tspeed: 0.0421s/iter; left time: 55.3331s\n",
      "\titers: 600, epoch: 19 | loss: 0.0351807\n",
      "\tspeed: 0.0391s/iter; left time: 47.4665s\n",
      "\titers: 700, epoch: 19 | loss: 0.0348938\n",
      "\tspeed: 0.0410s/iter; left time: 45.6869s\n",
      "\titers: 800, epoch: 19 | loss: 0.0338098\n",
      "\tspeed: 0.0423s/iter; left time: 42.8148s\n",
      "\titers: 900, epoch: 19 | loss: 0.0356139\n",
      "\tspeed: 0.0420s/iter; left time: 38.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 906 | Train Loss: 0.0342754 Vali Loss: 0.0572752 Test Loss: 0.0656079\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012767552398145199, rmse:0.11299359798431396, mae:0.06396614760160446, rse:0.4360218048095703\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1801156\n",
      "\tspeed: 0.0427s/iter; left time: 768.8814s\n",
      "\titers: 200, epoch: 1 | loss: 0.1693918\n",
      "\tspeed: 0.0386s/iter; left time: 692.0285s\n",
      "\titers: 300, epoch: 1 | loss: 0.1592212\n",
      "\tspeed: 0.0393s/iter; left time: 699.5794s\n",
      "\titers: 400, epoch: 1 | loss: 0.1620753\n",
      "\tspeed: 0.0397s/iter; left time: 704.2397s\n",
      "\titers: 500, epoch: 1 | loss: 0.1458250\n",
      "\tspeed: 0.0378s/iter; left time: 665.9755s\n",
      "\titers: 600, epoch: 1 | loss: 0.1475012\n",
      "\tspeed: 0.0393s/iter; left time: 688.5811s\n",
      "\titers: 700, epoch: 1 | loss: 0.1419826\n",
      "\tspeed: 0.0395s/iter; left time: 688.5086s\n",
      "\titers: 800, epoch: 1 | loss: 0.1336648\n",
      "\tspeed: 0.0394s/iter; left time: 682.4325s\n",
      "\titers: 900, epoch: 1 | loss: 0.1408745\n",
      "\tspeed: 0.0396s/iter; left time: 681.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:35.90s\n",
      "Steps: 906 | Train Loss: 0.1612176 Vali Loss: 0.1463322 Test Loss: 0.1673547\n",
      "Validation loss decreased (inf --> 0.146332).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303828\n",
      "\tspeed: 0.1067s/iter; left time: 1826.6675s\n",
      "\titers: 200, epoch: 2 | loss: 0.1161620\n",
      "\tspeed: 0.0390s/iter; left time: 664.2655s\n",
      "\titers: 300, epoch: 2 | loss: 0.1155948\n",
      "\tspeed: 0.0401s/iter; left time: 678.8689s\n",
      "\titers: 400, epoch: 2 | loss: 0.1075312\n",
      "\tspeed: 0.0375s/iter; left time: 631.3561s\n",
      "\titers: 500, epoch: 2 | loss: 0.1108859\n",
      "\tspeed: 0.0401s/iter; left time: 670.5023s\n",
      "\titers: 600, epoch: 2 | loss: 0.1101993\n",
      "\tspeed: 0.0425s/iter; left time: 706.7913s\n",
      "\titers: 700, epoch: 2 | loss: 0.0986314\n",
      "\tspeed: 0.0412s/iter; left time: 679.6471s\n",
      "\titers: 800, epoch: 2 | loss: 0.0980658\n",
      "\tspeed: 0.0392s/iter; left time: 643.0957s\n",
      "\titers: 900, epoch: 2 | loss: 0.0954762\n",
      "\tspeed: 0.0389s/iter; left time: 634.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.24s\n",
      "Steps: 906 | Train Loss: 0.1117984 Vali Loss: 0.1216852 Test Loss: 0.1423893\n",
      "Validation loss decreased (0.146332 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071936\n",
      "\tspeed: 0.1059s/iter; left time: 1716.4609s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877124\n",
      "\tspeed: 0.0393s/iter; left time: 632.9512s\n",
      "\titers: 300, epoch: 3 | loss: 0.0951138\n",
      "\tspeed: 0.0414s/iter; left time: 662.3681s\n",
      "\titers: 400, epoch: 3 | loss: 0.1052210\n",
      "\tspeed: 0.0402s/iter; left time: 639.4561s\n",
      "\titers: 500, epoch: 3 | loss: 0.0915232\n",
      "\tspeed: 0.0403s/iter; left time: 636.4539s\n",
      "\titers: 600, epoch: 3 | loss: 0.0950945\n",
      "\tspeed: 0.0394s/iter; left time: 618.9040s\n",
      "\titers: 700, epoch: 3 | loss: 0.0965930\n",
      "\tspeed: 0.0393s/iter; left time: 613.5258s\n",
      "\titers: 800, epoch: 3 | loss: 0.0935806\n",
      "\tspeed: 0.0404s/iter; left time: 626.1080s\n",
      "\titers: 900, epoch: 3 | loss: 0.0903433\n",
      "\tspeed: 0.0395s/iter; left time: 608.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.47s\n",
      "Steps: 906 | Train Loss: 0.0975487 Vali Loss: 0.1222855 Test Loss: 0.1466359\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915177\n",
      "\tspeed: 0.1033s/iter; left time: 1581.4359s\n",
      "\titers: 200, epoch: 4 | loss: 0.0943076\n",
      "\tspeed: 0.0383s/iter; left time: 581.8604s\n",
      "\titers: 300, epoch: 4 | loss: 0.0961792\n",
      "\tspeed: 0.0373s/iter; left time: 563.5931s\n",
      "\titers: 400, epoch: 4 | loss: 0.0892987\n",
      "\tspeed: 0.0383s/iter; left time: 574.0083s\n",
      "\titers: 500, epoch: 4 | loss: 0.0983917\n",
      "\tspeed: 0.0404s/iter; left time: 601.4747s\n",
      "\titers: 600, epoch: 4 | loss: 0.0893438\n",
      "\tspeed: 0.0406s/iter; left time: 601.1224s\n",
      "\titers: 700, epoch: 4 | loss: 0.0890017\n",
      "\tspeed: 0.0380s/iter; left time: 558.9892s\n",
      "\titers: 800, epoch: 4 | loss: 0.0899160\n",
      "\tspeed: 0.0377s/iter; left time: 549.8158s\n",
      "\titers: 900, epoch: 4 | loss: 0.0873288\n",
      "\tspeed: 0.0408s/iter; left time: 591.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.59s\n",
      "Steps: 906 | Train Loss: 0.0929393 Vali Loss: 0.1178700 Test Loss: 0.1405447\n",
      "Validation loss decreased (0.121685 --> 0.117870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608060\n",
      "\tspeed: 0.1087s/iter; left time: 1564.3689s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597439\n",
      "\tspeed: 0.0412s/iter; left time: 589.1831s\n",
      "\titers: 300, epoch: 5 | loss: 0.0522412\n",
      "\tspeed: 0.0407s/iter; left time: 578.3249s\n",
      "\titers: 400, epoch: 5 | loss: 0.0543010\n",
      "\tspeed: 0.0408s/iter; left time: 575.4843s\n",
      "\titers: 500, epoch: 5 | loss: 0.0510247\n",
      "\tspeed: 0.0390s/iter; left time: 546.3922s\n",
      "\titers: 600, epoch: 5 | loss: 0.0480882\n",
      "\tspeed: 0.0422s/iter; left time: 586.7257s\n",
      "\titers: 700, epoch: 5 | loss: 0.0547104\n",
      "\tspeed: 0.0460s/iter; left time: 634.2739s\n",
      "\titers: 800, epoch: 5 | loss: 0.0395380\n",
      "\tspeed: 0.0459s/iter; left time: 628.2696s\n",
      "\titers: 900, epoch: 5 | loss: 0.0498560\n",
      "\tspeed: 0.0459s/iter; left time: 624.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 906 | Train Loss: 0.0547073 Vali Loss: 0.0645226 Test Loss: 0.0707614\n",
      "Validation loss decreased (0.117870 --> 0.064523).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568447\n",
      "\tspeed: 0.1123s/iter; left time: 1515.5677s\n",
      "\titers: 200, epoch: 6 | loss: 0.0532049\n",
      "\tspeed: 0.0458s/iter; left time: 613.4933s\n",
      "\titers: 300, epoch: 6 | loss: 0.0566209\n",
      "\tspeed: 0.0373s/iter; left time: 495.8130s\n",
      "\titers: 400, epoch: 6 | loss: 0.0460761\n",
      "\tspeed: 0.0328s/iter; left time: 433.2224s\n",
      "\titers: 500, epoch: 6 | loss: 0.0461107\n",
      "\tspeed: 0.0329s/iter; left time: 430.2425s\n",
      "\titers: 600, epoch: 6 | loss: 0.0416425\n",
      "\tspeed: 0.0329s/iter; left time: 426.8793s\n",
      "\titers: 700, epoch: 6 | loss: 0.0520144\n",
      "\tspeed: 0.0329s/iter; left time: 423.8004s\n",
      "\titers: 800, epoch: 6 | loss: 0.0474252\n",
      "\tspeed: 0.0329s/iter; left time: 420.2952s\n",
      "\titers: 900, epoch: 6 | loss: 0.0456907\n",
      "\tspeed: 0.0329s/iter; left time: 417.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 906 | Train Loss: 0.0484333 Vali Loss: 0.0617828 Test Loss: 0.0678977\n",
      "Validation loss decreased (0.064523 --> 0.061783).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0537158\n",
      "\tspeed: 0.1121s/iter; left time: 1410.6652s\n",
      "\titers: 200, epoch: 7 | loss: 0.0511137\n",
      "\tspeed: 0.0463s/iter; left time: 578.2386s\n",
      "\titers: 300, epoch: 7 | loss: 0.0435230\n",
      "\tspeed: 0.0462s/iter; left time: 571.8435s\n",
      "\titers: 400, epoch: 7 | loss: 0.0451123\n",
      "\tspeed: 0.0462s/iter; left time: 567.9675s\n",
      "\titers: 500, epoch: 7 | loss: 0.0537385\n",
      "\tspeed: 0.0460s/iter; left time: 559.9919s\n",
      "\titers: 600, epoch: 7 | loss: 0.0416286\n",
      "\tspeed: 0.0462s/iter; left time: 558.7961s\n",
      "\titers: 700, epoch: 7 | loss: 0.0466046\n",
      "\tspeed: 0.0463s/iter; left time: 555.0269s\n",
      "\titers: 800, epoch: 7 | loss: 0.0462235\n",
      "\tspeed: 0.0459s/iter; left time: 545.3901s\n",
      "\titers: 900, epoch: 7 | loss: 0.0409817\n",
      "\tspeed: 0.0463s/iter; left time: 545.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.11s\n",
      "Steps: 906 | Train Loss: 0.0464273 Vali Loss: 0.0605569 Test Loss: 0.0668078\n",
      "Validation loss decreased (0.061783 --> 0.060557).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0487131\n",
      "\tspeed: 0.1120s/iter; left time: 1308.6315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0413706\n",
      "\tspeed: 0.0460s/iter; left time: 532.4259s\n",
      "\titers: 300, epoch: 8 | loss: 0.0469885\n",
      "\tspeed: 0.0462s/iter; left time: 530.3601s\n",
      "\titers: 400, epoch: 8 | loss: 0.0439744\n",
      "\tspeed: 0.0462s/iter; left time: 525.5379s\n",
      "\titers: 500, epoch: 8 | loss: 0.0461223\n",
      "\tspeed: 0.0459s/iter; left time: 518.2190s\n",
      "\titers: 600, epoch: 8 | loss: 0.0443447\n",
      "\tspeed: 0.0462s/iter; left time: 516.8941s\n",
      "\titers: 700, epoch: 8 | loss: 0.0442688\n",
      "\tspeed: 0.0459s/iter; left time: 508.2221s\n",
      "\titers: 800, epoch: 8 | loss: 0.0440482\n",
      "\tspeed: 0.0457s/iter; left time: 501.3841s\n",
      "\titers: 900, epoch: 8 | loss: 0.0466514\n",
      "\tspeed: 0.0457s/iter; left time: 496.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.94s\n",
      "Steps: 906 | Train Loss: 0.0448513 Vali Loss: 0.0610837 Test Loss: 0.0678426\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0493816\n",
      "\tspeed: 0.1089s/iter; left time: 1173.3104s\n",
      "\titers: 200, epoch: 9 | loss: 0.0397221\n",
      "\tspeed: 0.0387s/iter; left time: 413.5162s\n",
      "\titers: 300, epoch: 9 | loss: 0.0432034\n",
      "\tspeed: 0.0329s/iter; left time: 347.3873s\n",
      "\titers: 400, epoch: 9 | loss: 0.0397232\n",
      "\tspeed: 0.0329s/iter; left time: 344.1216s\n",
      "\titers: 500, epoch: 9 | loss: 0.0407601\n",
      "\tspeed: 0.0329s/iter; left time: 341.1713s\n",
      "\titers: 600, epoch: 9 | loss: 0.0382149\n",
      "\tspeed: 0.0329s/iter; left time: 337.5988s\n",
      "\titers: 700, epoch: 9 | loss: 0.0399199\n",
      "\tspeed: 0.0329s/iter; left time: 334.2977s\n",
      "\titers: 800, epoch: 9 | loss: 0.0448039\n",
      "\tspeed: 0.0328s/iter; left time: 330.8010s\n",
      "\titers: 900, epoch: 9 | loss: 0.0397257\n",
      "\tspeed: 0.0328s/iter; left time: 327.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0435285 Vali Loss: 0.0585313 Test Loss: 0.0650581\n",
      "Validation loss decreased (0.060557 --> 0.058531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0426823\n",
      "\tspeed: 0.1114s/iter; left time: 1099.3591s\n",
      "\titers: 200, epoch: 10 | loss: 0.0409605\n",
      "\tspeed: 0.0460s/iter; left time: 449.2869s\n",
      "\titers: 300, epoch: 10 | loss: 0.0423930\n",
      "\tspeed: 0.0463s/iter; left time: 447.3325s\n",
      "\titers: 400, epoch: 10 | loss: 0.0425085\n",
      "\tspeed: 0.0463s/iter; left time: 442.4766s\n",
      "\titers: 500, epoch: 10 | loss: 0.0413204\n",
      "\tspeed: 0.0467s/iter; left time: 442.0727s\n",
      "\titers: 600, epoch: 10 | loss: 0.0463774\n",
      "\tspeed: 0.0462s/iter; left time: 432.8123s\n",
      "\titers: 700, epoch: 10 | loss: 0.0379347\n",
      "\tspeed: 0.0462s/iter; left time: 427.9731s\n",
      "\titers: 800, epoch: 10 | loss: 0.0455473\n",
      "\tspeed: 0.0463s/iter; left time: 424.0721s\n",
      "\titers: 900, epoch: 10 | loss: 0.0484285\n",
      "\tspeed: 0.0463s/iter; left time: 419.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 906 | Train Loss: 0.0419678 Vali Loss: 0.0583743 Test Loss: 0.0650106\n",
      "Validation loss decreased (0.058531 --> 0.058374).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417961\n",
      "\tspeed: 0.1136s/iter; left time: 1017.8757s\n",
      "\titers: 200, epoch: 11 | loss: 0.0406378\n",
      "\tspeed: 0.0461s/iter; left time: 408.1779s\n",
      "\titers: 300, epoch: 11 | loss: 0.0437176\n",
      "\tspeed: 0.0459s/iter; left time: 402.4304s\n",
      "\titers: 400, epoch: 11 | loss: 0.0392322\n",
      "\tspeed: 0.0458s/iter; left time: 396.2638s\n",
      "\titers: 500, epoch: 11 | loss: 0.0369425\n",
      "\tspeed: 0.0458s/iter; left time: 391.8981s\n",
      "\titers: 600, epoch: 11 | loss: 0.0395975\n",
      "\tspeed: 0.0459s/iter; left time: 388.4843s\n",
      "\titers: 700, epoch: 11 | loss: 0.0426910\n",
      "\tspeed: 0.0457s/iter; left time: 381.8703s\n",
      "\titers: 800, epoch: 11 | loss: 0.0414411\n",
      "\tspeed: 0.0458s/iter; left time: 378.4104s\n",
      "\titers: 900, epoch: 11 | loss: 0.0433159\n",
      "\tspeed: 0.0458s/iter; left time: 374.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0407944 Vali Loss: 0.0585528 Test Loss: 0.0678896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0353869\n",
      "\tspeed: 0.1093s/iter; left time: 880.0215s\n",
      "\titers: 200, epoch: 12 | loss: 0.0369177\n",
      "\tspeed: 0.0460s/iter; left time: 365.7609s\n",
      "\titers: 300, epoch: 12 | loss: 0.0402261\n",
      "\tspeed: 0.0458s/iter; left time: 360.0506s\n",
      "\titers: 400, epoch: 12 | loss: 0.0403699\n",
      "\tspeed: 0.0459s/iter; left time: 356.2830s\n",
      "\titers: 500, epoch: 12 | loss: 0.0416523\n",
      "\tspeed: 0.0457s/iter; left time: 349.8637s\n",
      "\titers: 600, epoch: 12 | loss: 0.0359642\n",
      "\tspeed: 0.0458s/iter; left time: 345.7162s\n",
      "\titers: 700, epoch: 12 | loss: 0.0365096\n",
      "\tspeed: 0.0457s/iter; left time: 340.7711s\n",
      "\titers: 800, epoch: 12 | loss: 0.0419170\n",
      "\tspeed: 0.0457s/iter; left time: 336.2889s\n",
      "\titers: 900, epoch: 12 | loss: 0.0427586\n",
      "\tspeed: 0.0458s/iter; left time: 332.6305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.0394729 Vali Loss: 0.0576715 Test Loss: 0.0654075\n",
      "Validation loss decreased (0.058374 --> 0.057672).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0382381\n",
      "\tspeed: 0.1126s/iter; left time: 805.0593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0408555\n",
      "\tspeed: 0.0460s/iter; left time: 324.3473s\n",
      "\titers: 300, epoch: 13 | loss: 0.0425836\n",
      "\tspeed: 0.0460s/iter; left time: 319.6341s\n",
      "\titers: 400, epoch: 13 | loss: 0.0404076\n",
      "\tspeed: 0.0459s/iter; left time: 314.1939s\n",
      "\titers: 500, epoch: 13 | loss: 0.0379511\n",
      "\tspeed: 0.0462s/iter; left time: 312.0545s\n",
      "\titers: 600, epoch: 13 | loss: 0.0329018\n",
      "\tspeed: 0.0461s/iter; left time: 306.8388s\n",
      "\titers: 700, epoch: 13 | loss: 0.0368670\n",
      "\tspeed: 0.0460s/iter; left time: 301.5050s\n",
      "\titers: 800, epoch: 13 | loss: 0.0375282\n",
      "\tspeed: 0.0365s/iter; left time: 235.1578s\n",
      "\titers: 900, epoch: 13 | loss: 0.0373945\n",
      "\tspeed: 0.0329s/iter; left time: 208.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.59s\n",
      "Steps: 906 | Train Loss: 0.0381429 Vali Loss: 0.0585803 Test Loss: 0.0667337\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0455244\n",
      "\tspeed: 0.1074s/iter; left time: 670.5787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0310949\n",
      "\tspeed: 0.0458s/iter; left time: 281.4525s\n",
      "\titers: 300, epoch: 14 | loss: 0.0321337\n",
      "\tspeed: 0.0454s/iter; left time: 274.2140s\n",
      "\titers: 400, epoch: 14 | loss: 0.0348212\n",
      "\tspeed: 0.0461s/iter; left time: 273.8428s\n",
      "\titers: 500, epoch: 14 | loss: 0.0381810\n",
      "\tspeed: 0.0462s/iter; left time: 269.6948s\n",
      "\titers: 600, epoch: 14 | loss: 0.0381188\n",
      "\tspeed: 0.0462s/iter; left time: 265.3836s\n",
      "\titers: 700, epoch: 14 | loss: 0.0382425\n",
      "\tspeed: 0.0460s/iter; left time: 259.7676s\n",
      "\titers: 800, epoch: 14 | loss: 0.0361690\n",
      "\tspeed: 0.0460s/iter; left time: 254.8896s\n",
      "\titers: 900, epoch: 14 | loss: 0.0385786\n",
      "\tspeed: 0.0460s/iter; left time: 250.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.0372778 Vali Loss: 0.0601808 Test Loss: 0.0676199\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0363024\n",
      "\tspeed: 0.1115s/iter; left time: 595.1988s\n",
      "\titers: 200, epoch: 15 | loss: 0.0342614\n",
      "\tspeed: 0.0470s/iter; left time: 246.1229s\n",
      "\titers: 300, epoch: 15 | loss: 0.0361045\n",
      "\tspeed: 0.0460s/iter; left time: 236.1380s\n",
      "\titers: 400, epoch: 15 | loss: 0.0331206\n",
      "\tspeed: 0.0458s/iter; left time: 230.8463s\n",
      "\titers: 500, epoch: 15 | loss: 0.0400858\n",
      "\tspeed: 0.0462s/iter; left time: 228.1404s\n",
      "\titers: 600, epoch: 15 | loss: 0.0305633\n",
      "\tspeed: 0.0461s/iter; left time: 222.8591s\n",
      "\titers: 700, epoch: 15 | loss: 0.0351738\n",
      "\tspeed: 0.0459s/iter; left time: 217.4909s\n",
      "\titers: 800, epoch: 15 | loss: 0.0380954\n",
      "\tspeed: 0.0460s/iter; left time: 213.1632s\n",
      "\titers: 900, epoch: 15 | loss: 0.0319528\n",
      "\tspeed: 0.0458s/iter; left time: 207.5697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.30s\n",
      "Steps: 906 | Train Loss: 0.0363847 Vali Loss: 0.0583235 Test Loss: 0.0649400\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0376110\n",
      "\tspeed: 0.1090s/iter; left time: 482.9346s\n",
      "\titers: 200, epoch: 16 | loss: 0.0324695\n",
      "\tspeed: 0.0459s/iter; left time: 198.8669s\n",
      "\titers: 300, epoch: 16 | loss: 0.0349067\n",
      "\tspeed: 0.0460s/iter; left time: 194.6242s\n",
      "\titers: 400, epoch: 16 | loss: 0.0405893\n",
      "\tspeed: 0.0462s/iter; left time: 190.7526s\n",
      "\titers: 500, epoch: 16 | loss: 0.0344875\n",
      "\tspeed: 0.0462s/iter; left time: 186.0671s\n",
      "\titers: 600, epoch: 16 | loss: 0.0346076\n",
      "\tspeed: 0.0459s/iter; left time: 180.3261s\n",
      "\titers: 700, epoch: 16 | loss: 0.0311003\n",
      "\tspeed: 0.0460s/iter; left time: 176.0471s\n",
      "\titers: 800, epoch: 16 | loss: 0.0379062\n",
      "\tspeed: 0.0461s/iter; left time: 171.9251s\n",
      "\titers: 900, epoch: 16 | loss: 0.0341136\n",
      "\tspeed: 0.0458s/iter; left time: 166.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:41.92s\n",
      "Steps: 906 | Train Loss: 0.0357149 Vali Loss: 0.0598772 Test Loss: 0.0668659\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0357666\n",
      "\tspeed: 0.1090s/iter; left time: 384.3938s\n",
      "\titers: 200, epoch: 17 | loss: 0.0370329\n",
      "\tspeed: 0.0464s/iter; left time: 159.0520s\n",
      "\titers: 300, epoch: 17 | loss: 0.0373027\n",
      "\tspeed: 0.0463s/iter; left time: 153.8677s\n",
      "\titers: 400, epoch: 17 | loss: 0.0400641\n",
      "\tspeed: 0.0461s/iter; left time: 148.7384s\n",
      "\titers: 500, epoch: 17 | loss: 0.0296947\n",
      "\tspeed: 0.0459s/iter; left time: 143.3042s\n",
      "\titers: 600, epoch: 17 | loss: 0.0346400\n",
      "\tspeed: 0.0463s/iter; left time: 140.0409s\n",
      "\titers: 700, epoch: 17 | loss: 0.0376296\n",
      "\tspeed: 0.0458s/iter; left time: 133.9604s\n",
      "\titers: 800, epoch: 17 | loss: 0.0341742\n",
      "\tspeed: 0.0461s/iter; left time: 130.1758s\n",
      "\titers: 900, epoch: 17 | loss: 0.0311247\n",
      "\tspeed: 0.0460s/iter; left time: 125.3007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 906 | Train Loss: 0.0350217 Vali Loss: 0.0584925 Test Loss: 0.0648316\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01316201314330101, rmse:0.11472582072019577, mae:0.06538578867912292, rse:0.4427061080932617\n",
      "Intermediate time for FR and pred_len 24: 00h:26m:36.09s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1911445\n",
      "\tspeed: 0.0803s/iter; left time: 1444.4125s\n",
      "\titers: 200, epoch: 1 | loss: 0.1656685\n",
      "\tspeed: 0.0506s/iter; left time: 903.9182s\n",
      "\titers: 300, epoch: 1 | loss: 0.1671335\n",
      "\tspeed: 0.0507s/iter; left time: 901.1391s\n",
      "\titers: 400, epoch: 1 | loss: 0.1556050\n",
      "\tspeed: 0.0507s/iter; left time: 895.5628s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509407\n",
      "\tspeed: 0.0508s/iter; left time: 892.8131s\n",
      "\titers: 600, epoch: 1 | loss: 0.1473168\n",
      "\tspeed: 0.0505s/iter; left time: 882.8836s\n",
      "\titers: 700, epoch: 1 | loss: 0.1520337\n",
      "\tspeed: 0.0505s/iter; left time: 877.1535s\n",
      "\titers: 800, epoch: 1 | loss: 0.1436543\n",
      "\tspeed: 0.0506s/iter; left time: 874.5963s\n",
      "\titers: 900, epoch: 1 | loss: 0.1419926\n",
      "\tspeed: 0.0504s/iter; left time: 865.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.54s\n",
      "Steps: 904 | Train Loss: 0.1621126 Vali Loss: 0.1570459 Test Loss: 0.1830849\n",
      "Validation loss decreased (inf --> 0.157046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1269499\n",
      "\tspeed: 0.1279s/iter; left time: 2184.4936s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186103\n",
      "\tspeed: 0.0509s/iter; left time: 863.3141s\n",
      "\titers: 300, epoch: 2 | loss: 0.1039269\n",
      "\tspeed: 0.0506s/iter; left time: 854.5644s\n",
      "\titers: 400, epoch: 2 | loss: 0.1115946\n",
      "\tspeed: 0.0506s/iter; left time: 849.1524s\n",
      "\titers: 500, epoch: 2 | loss: 0.1037187\n",
      "\tspeed: 0.0504s/iter; left time: 840.2825s\n",
      "\titers: 600, epoch: 2 | loss: 0.1041693\n",
      "\tspeed: 0.0505s/iter; left time: 837.7539s\n",
      "\titers: 700, epoch: 2 | loss: 0.0979861\n",
      "\tspeed: 0.0507s/iter; left time: 835.9437s\n",
      "\titers: 800, epoch: 2 | loss: 0.0868282\n",
      "\tspeed: 0.0505s/iter; left time: 827.6650s\n",
      "\titers: 900, epoch: 2 | loss: 0.0910813\n",
      "\tspeed: 0.0506s/iter; left time: 822.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.1090979 Vali Loss: 0.1060935 Test Loss: 0.1198013\n",
      "Validation loss decreased (0.157046 --> 0.106094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890009\n",
      "\tspeed: 0.1259s/iter; left time: 2036.3522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865769\n",
      "\tspeed: 0.0507s/iter; left time: 814.4020s\n",
      "\titers: 300, epoch: 3 | loss: 0.0859727\n",
      "\tspeed: 0.0507s/iter; left time: 809.8494s\n",
      "\titers: 400, epoch: 3 | loss: 0.0802479\n",
      "\tspeed: 0.0506s/iter; left time: 803.6390s\n",
      "\titers: 500, epoch: 3 | loss: 0.0837094\n",
      "\tspeed: 0.0506s/iter; left time: 797.6185s\n",
      "\titers: 600, epoch: 3 | loss: 0.0759933\n",
      "\tspeed: 0.0504s/iter; left time: 790.4098s\n",
      "\titers: 700, epoch: 3 | loss: 0.0734874\n",
      "\tspeed: 0.0505s/iter; left time: 786.8602s\n",
      "\titers: 800, epoch: 3 | loss: 0.0764690\n",
      "\tspeed: 0.0507s/iter; left time: 783.9287s\n",
      "\titers: 900, epoch: 3 | loss: 0.0716284\n",
      "\tspeed: 0.0504s/iter; left time: 775.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0818074 Vali Loss: 0.0865899 Test Loss: 0.0993657\n",
      "Validation loss decreased (0.106094 --> 0.086590).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621516\n",
      "\tspeed: 0.1291s/iter; left time: 1970.8591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0672046\n",
      "\tspeed: 0.0505s/iter; left time: 765.3299s\n",
      "\titers: 300, epoch: 4 | loss: 0.0658672\n",
      "\tspeed: 0.0505s/iter; left time: 760.3700s\n",
      "\titers: 400, epoch: 4 | loss: 0.0698871\n",
      "\tspeed: 0.0505s/iter; left time: 756.4381s\n",
      "\titers: 500, epoch: 4 | loss: 0.0635847\n",
      "\tspeed: 0.0499s/iter; left time: 742.1211s\n",
      "\titers: 600, epoch: 4 | loss: 0.0619379\n",
      "\tspeed: 0.0501s/iter; left time: 739.4574s\n",
      "\titers: 700, epoch: 4 | loss: 0.0643404\n",
      "\tspeed: 0.0502s/iter; left time: 736.6118s\n",
      "\titers: 800, epoch: 4 | loss: 0.0603288\n",
      "\tspeed: 0.0505s/iter; left time: 736.1262s\n",
      "\titers: 900, epoch: 4 | loss: 0.0631917\n",
      "\tspeed: 0.0505s/iter; left time: 731.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 904 | Train Loss: 0.0672327 Vali Loss: 0.0836879 Test Loss: 0.0913545\n",
      "Validation loss decreased (0.086590 --> 0.083688).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656674\n",
      "\tspeed: 0.1275s/iter; left time: 1831.1807s\n",
      "\titers: 200, epoch: 5 | loss: 0.0633681\n",
      "\tspeed: 0.0506s/iter; left time: 721.1608s\n",
      "\titers: 300, epoch: 5 | loss: 0.0669293\n",
      "\tspeed: 0.0504s/iter; left time: 714.4979s\n",
      "\titers: 400, epoch: 5 | loss: 0.0591970\n",
      "\tspeed: 0.0506s/iter; left time: 711.3966s\n",
      "\titers: 500, epoch: 5 | loss: 0.0588198\n",
      "\tspeed: 0.0507s/iter; left time: 708.2805s\n",
      "\titers: 600, epoch: 5 | loss: 0.0630945\n",
      "\tspeed: 0.0505s/iter; left time: 700.7015s\n",
      "\titers: 700, epoch: 5 | loss: 0.0599165\n",
      "\tspeed: 0.0506s/iter; left time: 696.6852s\n",
      "\titers: 800, epoch: 5 | loss: 0.0645712\n",
      "\tspeed: 0.0505s/iter; left time: 690.1315s\n",
      "\titers: 900, epoch: 5 | loss: 0.0631721\n",
      "\tspeed: 0.0505s/iter; left time: 685.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0622755 Vali Loss: 0.0825124 Test Loss: 0.0918160\n",
      "Validation loss decreased (0.083688 --> 0.082512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566855\n",
      "\tspeed: 0.1254s/iter; left time: 1688.2624s\n",
      "\titers: 200, epoch: 6 | loss: 0.0580016\n",
      "\tspeed: 0.0506s/iter; left time: 675.6191s\n",
      "\titers: 300, epoch: 6 | loss: 0.0588441\n",
      "\tspeed: 0.0506s/iter; left time: 670.6982s\n",
      "\titers: 400, epoch: 6 | loss: 0.0573844\n",
      "\tspeed: 0.0503s/iter; left time: 661.5452s\n",
      "\titers: 500, epoch: 6 | loss: 0.0531953\n",
      "\tspeed: 0.0505s/iter; left time: 659.5892s\n",
      "\titers: 600, epoch: 6 | loss: 0.0570009\n",
      "\tspeed: 0.0505s/iter; left time: 654.6813s\n",
      "\titers: 700, epoch: 6 | loss: 0.0556639\n",
      "\tspeed: 0.0505s/iter; left time: 649.8086s\n",
      "\titers: 800, epoch: 6 | loss: 0.0532397\n",
      "\tspeed: 0.0505s/iter; left time: 644.3521s\n",
      "\titers: 900, epoch: 6 | loss: 0.0591764\n",
      "\tspeed: 0.0506s/iter; left time: 640.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0585346 Vali Loss: 0.0808577 Test Loss: 0.0923948\n",
      "Validation loss decreased (0.082512 --> 0.080858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534672\n",
      "\tspeed: 0.1284s/iter; left time: 1612.9152s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589887\n",
      "\tspeed: 0.0503s/iter; left time: 626.9591s\n",
      "\titers: 300, epoch: 7 | loss: 0.0536293\n",
      "\tspeed: 0.0506s/iter; left time: 625.8570s\n",
      "\titers: 400, epoch: 7 | loss: 0.0519964\n",
      "\tspeed: 0.0506s/iter; left time: 619.9827s\n",
      "\titers: 500, epoch: 7 | loss: 0.0530630\n",
      "\tspeed: 0.0505s/iter; left time: 614.4477s\n",
      "\titers: 600, epoch: 7 | loss: 0.0474895\n",
      "\tspeed: 0.0506s/iter; left time: 609.8932s\n",
      "\titers: 700, epoch: 7 | loss: 0.0552770\n",
      "\tspeed: 0.0507s/iter; left time: 605.8597s\n",
      "\titers: 800, epoch: 7 | loss: 0.0558303\n",
      "\tspeed: 0.0506s/iter; left time: 599.3791s\n",
      "\titers: 900, epoch: 7 | loss: 0.0549571\n",
      "\tspeed: 0.0507s/iter; left time: 595.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0557393 Vali Loss: 0.0816498 Test Loss: 0.0896462\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563578\n",
      "\tspeed: 0.1224s/iter; left time: 1426.8218s\n",
      "\titers: 200, epoch: 8 | loss: 0.0544026\n",
      "\tspeed: 0.0506s/iter; left time: 584.4998s\n",
      "\titers: 300, epoch: 8 | loss: 0.0539047\n",
      "\tspeed: 0.0505s/iter; left time: 578.1390s\n",
      "\titers: 400, epoch: 8 | loss: 0.0478208\n",
      "\tspeed: 0.0506s/iter; left time: 574.0311s\n",
      "\titers: 500, epoch: 8 | loss: 0.0498325\n",
      "\tspeed: 0.0506s/iter; left time: 569.8196s\n",
      "\titers: 600, epoch: 8 | loss: 0.0514959\n",
      "\tspeed: 0.0506s/iter; left time: 564.0083s\n",
      "\titers: 700, epoch: 8 | loss: 0.0493322\n",
      "\tspeed: 0.0506s/iter; left time: 559.2727s\n",
      "\titers: 800, epoch: 8 | loss: 0.0527163\n",
      "\tspeed: 0.0505s/iter; left time: 552.8934s\n",
      "\titers: 900, epoch: 8 | loss: 0.0476547\n",
      "\tspeed: 0.0507s/iter; left time: 550.6008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0534399 Vali Loss: 0.0823979 Test Loss: 0.0926677\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0487081\n",
      "\tspeed: 0.1220s/iter; left time: 1311.6567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0489254\n",
      "\tspeed: 0.0501s/iter; left time: 533.6282s\n",
      "\titers: 300, epoch: 9 | loss: 0.0504238\n",
      "\tspeed: 0.0503s/iter; left time: 530.8977s\n",
      "\titers: 400, epoch: 9 | loss: 0.0451382\n",
      "\tspeed: 0.0506s/iter; left time: 528.4643s\n",
      "\titers: 500, epoch: 9 | loss: 0.0497325\n",
      "\tspeed: 0.0506s/iter; left time: 524.1462s\n",
      "\titers: 600, epoch: 9 | loss: 0.0512080\n",
      "\tspeed: 0.0505s/iter; left time: 517.9714s\n",
      "\titers: 700, epoch: 9 | loss: 0.0522259\n",
      "\tspeed: 0.0505s/iter; left time: 512.7486s\n",
      "\titers: 800, epoch: 9 | loss: 0.0505538\n",
      "\tspeed: 0.0506s/iter; left time: 508.0177s\n",
      "\titers: 900, epoch: 9 | loss: 0.0517188\n",
      "\tspeed: 0.0506s/iter; left time: 502.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 904 | Train Loss: 0.0510219 Vali Loss: 0.0819406 Test Loss: 0.0904427\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0461655\n",
      "\tspeed: 0.1233s/iter; left time: 1214.0317s\n",
      "\titers: 200, epoch: 10 | loss: 0.0465046\n",
      "\tspeed: 0.0508s/iter; left time: 495.1710s\n",
      "\titers: 300, epoch: 10 | loss: 0.0463841\n",
      "\tspeed: 0.0505s/iter; left time: 487.4539s\n",
      "\titers: 400, epoch: 10 | loss: 0.0464293\n",
      "\tspeed: 0.0505s/iter; left time: 481.6041s\n",
      "\titers: 500, epoch: 10 | loss: 0.0465597\n",
      "\tspeed: 0.0507s/iter; left time: 479.1735s\n",
      "\titers: 600, epoch: 10 | loss: 0.0523428\n",
      "\tspeed: 0.0505s/iter; left time: 472.2004s\n",
      "\titers: 700, epoch: 10 | loss: 0.0491336\n",
      "\tspeed: 0.0505s/iter; left time: 466.9916s\n",
      "\titers: 800, epoch: 10 | loss: 0.0531798\n",
      "\tspeed: 0.0504s/iter; left time: 460.6456s\n",
      "\titers: 900, epoch: 10 | loss: 0.0509942\n",
      "\tspeed: 0.0503s/iter; left time: 454.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0489800 Vali Loss: 0.0816964 Test Loss: 0.0916990\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0457875\n",
      "\tspeed: 0.1222s/iter; left time: 1092.9783s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482542\n",
      "\tspeed: 0.0506s/iter; left time: 447.1186s\n",
      "\titers: 300, epoch: 11 | loss: 0.0474747\n",
      "\tspeed: 0.0505s/iter; left time: 441.6749s\n",
      "\titers: 400, epoch: 11 | loss: 0.0486984\n",
      "\tspeed: 0.0506s/iter; left time: 437.1095s\n",
      "\titers: 500, epoch: 11 | loss: 0.0492964\n",
      "\tspeed: 0.0506s/iter; left time: 431.9607s\n",
      "\titers: 600, epoch: 11 | loss: 0.0460422\n",
      "\tspeed: 0.0506s/iter; left time: 426.7474s\n",
      "\titers: 700, epoch: 11 | loss: 0.0455612\n",
      "\tspeed: 0.0505s/iter; left time: 421.1809s\n",
      "\titers: 800, epoch: 11 | loss: 0.0474474\n",
      "\tspeed: 0.0507s/iter; left time: 417.4114s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470046\n",
      "\tspeed: 0.0506s/iter; left time: 412.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0473390 Vali Loss: 0.0814191 Test Loss: 0.0897584\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023155687376856804, rmse:0.15216992795467377, mae:0.0923483744263649, rse:0.5886337161064148\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1992797\n",
      "\tspeed: 0.0530s/iter; left time: 953.8579s\n",
      "\titers: 200, epoch: 1 | loss: 0.1617417\n",
      "\tspeed: 0.0510s/iter; left time: 911.5704s\n",
      "\titers: 300, epoch: 1 | loss: 0.1604739\n",
      "\tspeed: 0.0507s/iter; left time: 900.9498s\n",
      "\titers: 400, epoch: 1 | loss: 0.1667275\n",
      "\tspeed: 0.0507s/iter; left time: 896.0491s\n",
      "\titers: 500, epoch: 1 | loss: 0.1528316\n",
      "\tspeed: 0.0506s/iter; left time: 888.8939s\n",
      "\titers: 600, epoch: 1 | loss: 0.1504665\n",
      "\tspeed: 0.0506s/iter; left time: 885.0096s\n",
      "\titers: 700, epoch: 1 | loss: 0.1398170\n",
      "\tspeed: 0.0507s/iter; left time: 881.9486s\n",
      "\titers: 800, epoch: 1 | loss: 0.1525903\n",
      "\tspeed: 0.0505s/iter; left time: 873.2741s\n",
      "\titers: 900, epoch: 1 | loss: 0.1397681\n",
      "\tspeed: 0.0508s/iter; left time: 872.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.1611014 Vali Loss: 0.1487986 Test Loss: 0.1742257\n",
      "Validation loss decreased (inf --> 0.148799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1291680\n",
      "\tspeed: 0.1317s/iter; left time: 2248.6499s\n",
      "\titers: 200, epoch: 2 | loss: 0.1218417\n",
      "\tspeed: 0.0512s/iter; left time: 868.6402s\n",
      "\titers: 300, epoch: 2 | loss: 0.1178188\n",
      "\tspeed: 0.0509s/iter; left time: 859.3650s\n",
      "\titers: 400, epoch: 2 | loss: 0.1215334\n",
      "\tspeed: 0.0508s/iter; left time: 852.6427s\n",
      "\titers: 500, epoch: 2 | loss: 0.1175609\n",
      "\tspeed: 0.0506s/iter; left time: 844.0629s\n",
      "\titers: 600, epoch: 2 | loss: 0.1084198\n",
      "\tspeed: 0.0506s/iter; left time: 838.7657s\n",
      "\titers: 700, epoch: 2 | loss: 0.1001606\n",
      "\tspeed: 0.0508s/iter; left time: 837.3330s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075935\n",
      "\tspeed: 0.0508s/iter; left time: 831.3252s\n",
      "\titers: 900, epoch: 2 | loss: 0.1030391\n",
      "\tspeed: 0.0507s/iter; left time: 825.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.24s\n",
      "Steps: 904 | Train Loss: 0.1155119 Vali Loss: 0.1259977 Test Loss: 0.1459249\n",
      "Validation loss decreased (0.148799 --> 0.125998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1066775\n",
      "\tspeed: 0.1282s/iter; left time: 2073.4635s\n",
      "\titers: 200, epoch: 3 | loss: 0.0974142\n",
      "\tspeed: 0.0505s/iter; left time: 812.1775s\n",
      "\titers: 300, epoch: 3 | loss: 0.0965906\n",
      "\tspeed: 0.0505s/iter; left time: 806.1987s\n",
      "\titers: 400, epoch: 3 | loss: 0.0946485\n",
      "\tspeed: 0.0505s/iter; left time: 801.4112s\n",
      "\titers: 500, epoch: 3 | loss: 0.0919983\n",
      "\tspeed: 0.0505s/iter; left time: 797.2381s\n",
      "\titers: 600, epoch: 3 | loss: 0.0809823\n",
      "\tspeed: 0.0502s/iter; left time: 787.2122s\n",
      "\titers: 700, epoch: 3 | loss: 0.0901392\n",
      "\tspeed: 0.0502s/iter; left time: 782.0813s\n",
      "\titers: 800, epoch: 3 | loss: 0.0719470\n",
      "\tspeed: 0.0503s/iter; left time: 777.8872s\n",
      "\titers: 900, epoch: 3 | loss: 0.0709015\n",
      "\tspeed: 0.0502s/iter; left time: 771.8865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 904 | Train Loss: 0.0926840 Vali Loss: 0.0885343 Test Loss: 0.1007292\n",
      "Validation loss decreased (0.125998 --> 0.088534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647133\n",
      "\tspeed: 0.1280s/iter; left time: 1955.1853s\n",
      "\titers: 200, epoch: 4 | loss: 0.0759917\n",
      "\tspeed: 0.0506s/iter; left time: 767.9724s\n",
      "\titers: 300, epoch: 4 | loss: 0.0750118\n",
      "\tspeed: 0.0500s/iter; left time: 753.6366s\n",
      "\titers: 400, epoch: 4 | loss: 0.0646950\n",
      "\tspeed: 0.0506s/iter; left time: 757.2492s\n",
      "\titers: 500, epoch: 4 | loss: 0.0636472\n",
      "\tspeed: 0.0506s/iter; left time: 752.4170s\n",
      "\titers: 600, epoch: 4 | loss: 0.0703337\n",
      "\tspeed: 0.0505s/iter; left time: 746.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0662696\n",
      "\tspeed: 0.0508s/iter; left time: 744.5638s\n",
      "\titers: 800, epoch: 4 | loss: 0.0660502\n",
      "\tspeed: 0.0509s/iter; left time: 741.0855s\n",
      "\titers: 900, epoch: 4 | loss: 0.0649790\n",
      "\tspeed: 0.0509s/iter; left time: 736.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 904 | Train Loss: 0.0686160 Vali Loss: 0.0839365 Test Loss: 0.0947516\n",
      "Validation loss decreased (0.088534 --> 0.083936).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616051\n",
      "\tspeed: 0.1298s/iter; left time: 1864.1785s\n",
      "\titers: 200, epoch: 5 | loss: 0.0659879\n",
      "\tspeed: 0.0505s/iter; left time: 720.6512s\n",
      "\titers: 300, epoch: 5 | loss: 0.0706296\n",
      "\tspeed: 0.0506s/iter; left time: 716.1843s\n",
      "\titers: 400, epoch: 5 | loss: 0.0663615\n",
      "\tspeed: 0.0506s/iter; left time: 712.2961s\n",
      "\titers: 500, epoch: 5 | loss: 0.0614187\n",
      "\tspeed: 0.0502s/iter; left time: 700.3798s\n",
      "\titers: 600, epoch: 5 | loss: 0.0616514\n",
      "\tspeed: 0.0506s/iter; left time: 700.9022s\n",
      "\titers: 700, epoch: 5 | loss: 0.0729438\n",
      "\tspeed: 0.0504s/iter; left time: 694.2268s\n",
      "\titers: 800, epoch: 5 | loss: 0.0523489\n",
      "\tspeed: 0.0507s/iter; left time: 692.1435s\n",
      "\titers: 900, epoch: 5 | loss: 0.0600485\n",
      "\tspeed: 0.0507s/iter; left time: 687.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0630417 Vali Loss: 0.0807501 Test Loss: 0.0890914\n",
      "Validation loss decreased (0.083936 --> 0.080750).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614960\n",
      "\tspeed: 0.1272s/iter; left time: 1711.6171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571879\n",
      "\tspeed: 0.0505s/iter; left time: 675.1414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0620920\n",
      "\tspeed: 0.0505s/iter; left time: 669.8691s\n",
      "\titers: 400, epoch: 6 | loss: 0.0574742\n",
      "\tspeed: 0.0505s/iter; left time: 664.5494s\n",
      "\titers: 500, epoch: 6 | loss: 0.0606673\n",
      "\tspeed: 0.0506s/iter; left time: 660.7471s\n",
      "\titers: 600, epoch: 6 | loss: 0.0583962\n",
      "\tspeed: 0.0506s/iter; left time: 656.2011s\n",
      "\titers: 700, epoch: 6 | loss: 0.0587346\n",
      "\tspeed: 0.0505s/iter; left time: 649.1816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0582970\n",
      "\tspeed: 0.0505s/iter; left time: 644.5022s\n",
      "\titers: 900, epoch: 6 | loss: 0.0548476\n",
      "\tspeed: 0.0506s/iter; left time: 640.1337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0592987 Vali Loss: 0.0836388 Test Loss: 0.0921502\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0547832\n",
      "\tspeed: 0.1229s/iter; left time: 1543.0266s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547374\n",
      "\tspeed: 0.0506s/iter; left time: 629.7259s\n",
      "\titers: 300, epoch: 7 | loss: 0.0591234\n",
      "\tspeed: 0.0506s/iter; left time: 625.8370s\n",
      "\titers: 400, epoch: 7 | loss: 0.0566430\n",
      "\tspeed: 0.0505s/iter; left time: 619.3298s\n",
      "\titers: 500, epoch: 7 | loss: 0.0529336\n",
      "\tspeed: 0.0505s/iter; left time: 614.5125s\n",
      "\titers: 600, epoch: 7 | loss: 0.0527418\n",
      "\tspeed: 0.0501s/iter; left time: 604.4278s\n",
      "\titers: 700, epoch: 7 | loss: 0.0545850\n",
      "\tspeed: 0.0505s/iter; left time: 604.1396s\n",
      "\titers: 800, epoch: 7 | loss: 0.0537773\n",
      "\tspeed: 0.0506s/iter; left time: 599.4206s\n",
      "\titers: 900, epoch: 7 | loss: 0.0556343\n",
      "\tspeed: 0.0507s/iter; left time: 595.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0562589 Vali Loss: 0.0830783 Test Loss: 0.0920738\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540548\n",
      "\tspeed: 0.1224s/iter; left time: 1426.2162s\n",
      "\titers: 200, epoch: 8 | loss: 0.0540662\n",
      "\tspeed: 0.0505s/iter; left time: 583.7681s\n",
      "\titers: 300, epoch: 8 | loss: 0.0517248\n",
      "\tspeed: 0.0504s/iter; left time: 577.8036s\n",
      "\titers: 400, epoch: 8 | loss: 0.0503701\n",
      "\tspeed: 0.0504s/iter; left time: 572.2432s\n",
      "\titers: 500, epoch: 8 | loss: 0.0568538\n",
      "\tspeed: 0.0505s/iter; left time: 568.1375s\n",
      "\titers: 600, epoch: 8 | loss: 0.0514664\n",
      "\tspeed: 0.0505s/iter; left time: 563.4341s\n",
      "\titers: 700, epoch: 8 | loss: 0.0525621\n",
      "\tspeed: 0.0505s/iter; left time: 558.7093s\n",
      "\titers: 800, epoch: 8 | loss: 0.0539060\n",
      "\tspeed: 0.0504s/iter; left time: 552.2348s\n",
      "\titers: 900, epoch: 8 | loss: 0.0534104\n",
      "\tspeed: 0.0505s/iter; left time: 548.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.0536997 Vali Loss: 0.0821512 Test Loss: 0.0878213\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554801\n",
      "\tspeed: 0.1224s/iter; left time: 1315.1962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525909\n",
      "\tspeed: 0.0507s/iter; left time: 539.5220s\n",
      "\titers: 300, epoch: 9 | loss: 0.0503607\n",
      "\tspeed: 0.0504s/iter; left time: 531.8914s\n",
      "\titers: 400, epoch: 9 | loss: 0.0517837\n",
      "\tspeed: 0.0505s/iter; left time: 527.7686s\n",
      "\titers: 500, epoch: 9 | loss: 0.0491131\n",
      "\tspeed: 0.0505s/iter; left time: 522.8078s\n",
      "\titers: 600, epoch: 9 | loss: 0.0495254\n",
      "\tspeed: 0.0506s/iter; left time: 518.2128s\n",
      "\titers: 700, epoch: 9 | loss: 0.0511253\n",
      "\tspeed: 0.0502s/iter; left time: 509.9266s\n",
      "\titers: 800, epoch: 9 | loss: 0.0498807\n",
      "\tspeed: 0.0506s/iter; left time: 508.3025s\n",
      "\titers: 900, epoch: 9 | loss: 0.0514518\n",
      "\tspeed: 0.0504s/iter; left time: 501.8074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.0514246 Vali Loss: 0.0811186 Test Loss: 0.0901066\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0488571\n",
      "\tspeed: 0.1219s/iter; left time: 1199.6386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0466229\n",
      "\tspeed: 0.0505s/iter; left time: 492.5093s\n",
      "\titers: 300, epoch: 10 | loss: 0.0452690\n",
      "\tspeed: 0.0505s/iter; left time: 487.0796s\n",
      "\titers: 400, epoch: 10 | loss: 0.0498474\n",
      "\tspeed: 0.0505s/iter; left time: 482.2005s\n",
      "\titers: 500, epoch: 10 | loss: 0.0495107\n",
      "\tspeed: 0.0505s/iter; left time: 477.0538s\n",
      "\titers: 600, epoch: 10 | loss: 0.0493437\n",
      "\tspeed: 0.0505s/iter; left time: 471.6458s\n",
      "\titers: 700, epoch: 10 | loss: 0.0476745\n",
      "\tspeed: 0.0506s/iter; left time: 467.4354s\n",
      "\titers: 800, epoch: 10 | loss: 0.0496488\n",
      "\tspeed: 0.0506s/iter; left time: 462.3024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0473083\n",
      "\tspeed: 0.0507s/iter; left time: 458.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0493435 Vali Loss: 0.0829276 Test Loss: 0.0909194\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02133835293352604, rmse:0.1460765302181244, mae:0.08909517526626587, rse:0.5650628209114075\n",
      "Intermediate time for FR and pred_len 96: 00h:18m:52.36s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1899857\n",
      "\tspeed: 0.0780s/iter; left time: 1399.5346s\n",
      "\titers: 200, epoch: 1 | loss: 0.1676250\n",
      "\tspeed: 0.0529s/iter; left time: 943.2363s\n",
      "\titers: 300, epoch: 1 | loss: 0.1593906\n",
      "\tspeed: 0.0521s/iter; left time: 923.6046s\n",
      "\titers: 400, epoch: 1 | loss: 0.1584194\n",
      "\tspeed: 0.0519s/iter; left time: 916.4201s\n",
      "\titers: 500, epoch: 1 | loss: 0.1616855\n",
      "\tspeed: 0.0523s/iter; left time: 917.4955s\n",
      "\titers: 600, epoch: 1 | loss: 0.1559882\n",
      "\tspeed: 0.0545s/iter; left time: 951.1120s\n",
      "\titers: 700, epoch: 1 | loss: 0.1501905\n",
      "\tspeed: 0.0538s/iter; left time: 932.6300s\n",
      "\titers: 800, epoch: 1 | loss: 0.1467984\n",
      "\tspeed: 0.0469s/iter; left time: 808.2247s\n",
      "\titers: 900, epoch: 1 | loss: 0.1486980\n",
      "\tspeed: 0.0516s/iter; left time: 883.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.1628964 Vali Loss: 0.1598981 Test Loss: 0.1863369\n",
      "Validation loss decreased (inf --> 0.159898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1357078\n",
      "\tspeed: 0.1468s/iter; left time: 2501.8069s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157170\n",
      "\tspeed: 0.0531s/iter; left time: 899.6214s\n",
      "\titers: 300, epoch: 2 | loss: 0.1116724\n",
      "\tspeed: 0.0526s/iter; left time: 885.2919s\n",
      "\titers: 400, epoch: 2 | loss: 0.1103282\n",
      "\tspeed: 0.0529s/iter; left time: 885.2732s\n",
      "\titers: 500, epoch: 2 | loss: 0.1188741\n",
      "\tspeed: 0.0530s/iter; left time: 882.0979s\n",
      "\titers: 600, epoch: 2 | loss: 0.1104626\n",
      "\tspeed: 0.0537s/iter; left time: 887.8432s\n",
      "\titers: 700, epoch: 2 | loss: 0.1123905\n",
      "\tspeed: 0.0572s/iter; left time: 939.8803s\n",
      "\titers: 800, epoch: 2 | loss: 0.1013852\n",
      "\tspeed: 0.0593s/iter; left time: 968.4194s\n",
      "\titers: 900, epoch: 2 | loss: 0.1009232\n",
      "\tspeed: 0.0561s/iter; left time: 911.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.78s\n",
      "Steps: 902 | Train Loss: 0.1158511 Vali Loss: 0.1261606 Test Loss: 0.1455380\n",
      "Validation loss decreased (0.159898 --> 0.126161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033958\n",
      "\tspeed: 0.1482s/iter; left time: 2390.7982s\n",
      "\titers: 200, epoch: 3 | loss: 0.1038508\n",
      "\tspeed: 0.0545s/iter; left time: 874.7325s\n",
      "\titers: 300, epoch: 3 | loss: 0.0945433\n",
      "\tspeed: 0.0562s/iter; left time: 896.2881s\n",
      "\titers: 400, epoch: 3 | loss: 0.0930621\n",
      "\tspeed: 0.0578s/iter; left time: 915.4324s\n",
      "\titers: 500, epoch: 3 | loss: 0.0925619\n",
      "\tspeed: 0.0578s/iter; left time: 910.2046s\n",
      "\titers: 600, epoch: 3 | loss: 0.0950229\n",
      "\tspeed: 0.0590s/iter; left time: 922.9946s\n",
      "\titers: 700, epoch: 3 | loss: 0.0878589\n",
      "\tspeed: 0.0600s/iter; left time: 932.7960s\n",
      "\titers: 800, epoch: 3 | loss: 0.0876500\n",
      "\tspeed: 0.0601s/iter; left time: 928.3239s\n",
      "\titers: 900, epoch: 3 | loss: 0.0900771\n",
      "\tspeed: 0.0597s/iter; left time: 914.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 902 | Train Loss: 0.0953644 Vali Loss: 0.1116854 Test Loss: 0.1285899\n",
      "Validation loss decreased (0.126161 --> 0.111685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870865\n",
      "\tspeed: 0.1507s/iter; left time: 2296.6213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811079\n",
      "\tspeed: 0.0583s/iter; left time: 881.7404s\n",
      "\titers: 300, epoch: 4 | loss: 0.0708244\n",
      "\tspeed: 0.0602s/iter; left time: 904.4932s\n",
      "\titers: 400, epoch: 4 | loss: 0.0783814\n",
      "\tspeed: 0.0605s/iter; left time: 903.9875s\n",
      "\titers: 500, epoch: 4 | loss: 0.0716911\n",
      "\tspeed: 0.0606s/iter; left time: 898.7375s\n",
      "\titers: 600, epoch: 4 | loss: 0.0728482\n",
      "\tspeed: 0.0607s/iter; left time: 893.9505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0684563\n",
      "\tspeed: 0.0601s/iter; left time: 880.1466s\n",
      "\titers: 800, epoch: 4 | loss: 0.0699331\n",
      "\tspeed: 0.0594s/iter; left time: 863.9287s\n",
      "\titers: 900, epoch: 4 | loss: 0.0653397\n",
      "\tspeed: 0.0548s/iter; left time: 791.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.71s\n",
      "Steps: 902 | Train Loss: 0.0746272 Vali Loss: 0.0860982 Test Loss: 0.0967193\n",
      "Validation loss decreased (0.111685 --> 0.086098).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0695566\n",
      "\tspeed: 0.1597s/iter; left time: 2288.6017s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643279\n",
      "\tspeed: 0.0595s/iter; left time: 846.8195s\n",
      "\titers: 300, epoch: 5 | loss: 0.0624109\n",
      "\tspeed: 0.0584s/iter; left time: 825.5700s\n",
      "\titers: 400, epoch: 5 | loss: 0.0653408\n",
      "\tspeed: 0.0580s/iter; left time: 813.2557s\n",
      "\titers: 500, epoch: 5 | loss: 0.0686386\n",
      "\tspeed: 0.0585s/iter; left time: 815.2293s\n",
      "\titers: 600, epoch: 5 | loss: 0.0697915\n",
      "\tspeed: 0.0608s/iter; left time: 840.9991s\n",
      "\titers: 700, epoch: 5 | loss: 0.0662466\n",
      "\tspeed: 0.0592s/iter; left time: 813.3030s\n",
      "\titers: 800, epoch: 5 | loss: 0.0670046\n",
      "\tspeed: 0.0545s/iter; left time: 742.7302s\n",
      "\titers: 900, epoch: 5 | loss: 0.0620230\n",
      "\tspeed: 0.0531s/iter; left time: 719.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:52.57s\n",
      "Steps: 902 | Train Loss: 0.0664477 Vali Loss: 0.0898873 Test Loss: 0.1025955\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616981\n",
      "\tspeed: 0.1447s/iter; left time: 1942.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742534\n",
      "\tspeed: 0.0596s/iter; left time: 794.3587s\n",
      "\titers: 300, epoch: 6 | loss: 0.0670259\n",
      "\tspeed: 0.0595s/iter; left time: 787.7372s\n",
      "\titers: 400, epoch: 6 | loss: 0.0620175\n",
      "\tspeed: 0.0595s/iter; left time: 781.8633s\n",
      "\titers: 500, epoch: 6 | loss: 0.0606017\n",
      "\tspeed: 0.0601s/iter; left time: 783.2031s\n",
      "\titers: 600, epoch: 6 | loss: 0.0605927\n",
      "\tspeed: 0.0595s/iter; left time: 769.3462s\n",
      "\titers: 700, epoch: 6 | loss: 0.0613156\n",
      "\tspeed: 0.0595s/iter; left time: 764.0355s\n",
      "\titers: 800, epoch: 6 | loss: 0.0661772\n",
      "\tspeed: 0.0558s/iter; left time: 710.9861s\n",
      "\titers: 900, epoch: 6 | loss: 0.0633410\n",
      "\tspeed: 0.0597s/iter; left time: 753.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.53s\n",
      "Steps: 902 | Train Loss: 0.0628621 Vali Loss: 0.0865787 Test Loss: 0.0994628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611387\n",
      "\tspeed: 0.1485s/iter; left time: 1861.1484s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607835\n",
      "\tspeed: 0.0579s/iter; left time: 720.1694s\n",
      "\titers: 300, epoch: 7 | loss: 0.0577639\n",
      "\tspeed: 0.0606s/iter; left time: 747.6325s\n",
      "\titers: 400, epoch: 7 | loss: 0.0605740\n",
      "\tspeed: 0.0609s/iter; left time: 744.4022s\n",
      "\titers: 500, epoch: 7 | loss: 0.0584024\n",
      "\tspeed: 0.0598s/iter; left time: 725.2008s\n",
      "\titers: 600, epoch: 7 | loss: 0.0664984\n",
      "\tspeed: 0.0587s/iter; left time: 705.6565s\n",
      "\titers: 700, epoch: 7 | loss: 0.0554081\n",
      "\tspeed: 0.0574s/iter; left time: 684.9186s\n",
      "\titers: 800, epoch: 7 | loss: 0.0564103\n",
      "\tspeed: 0.0573s/iter; left time: 677.6168s\n",
      "\titers: 900, epoch: 7 | loss: 0.0537747\n",
      "\tspeed: 0.0576s/iter; left time: 675.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:53.57s\n",
      "Steps: 902 | Train Loss: 0.0598913 Vali Loss: 0.0868521 Test Loss: 0.0966919\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0600452\n",
      "\tspeed: 0.1452s/iter; left time: 1688.2860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561281\n",
      "\tspeed: 0.0589s/iter; left time: 678.6754s\n",
      "\titers: 300, epoch: 8 | loss: 0.0555709\n",
      "\tspeed: 0.0609s/iter; left time: 696.1066s\n",
      "\titers: 400, epoch: 8 | loss: 0.0520003\n",
      "\tspeed: 0.0574s/iter; left time: 650.4371s\n",
      "\titers: 500, epoch: 8 | loss: 0.0566507\n",
      "\tspeed: 0.0581s/iter; left time: 652.5850s\n",
      "\titers: 600, epoch: 8 | loss: 0.0556884\n",
      "\tspeed: 0.0594s/iter; left time: 661.2419s\n",
      "\titers: 700, epoch: 8 | loss: 0.0591233\n",
      "\tspeed: 0.0579s/iter; left time: 638.6652s\n",
      "\titers: 800, epoch: 8 | loss: 0.0589403\n",
      "\tspeed: 0.0560s/iter; left time: 611.9083s\n",
      "\titers: 900, epoch: 8 | loss: 0.0540469\n",
      "\tspeed: 0.0530s/iter; left time: 573.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.31s\n",
      "Steps: 902 | Train Loss: 0.0569611 Vali Loss: 0.0868621 Test Loss: 0.0964759\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0561222\n",
      "\tspeed: 0.1449s/iter; left time: 1553.7256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579822\n",
      "\tspeed: 0.0588s/iter; left time: 624.8300s\n",
      "\titers: 300, epoch: 9 | loss: 0.0579146\n",
      "\tspeed: 0.0576s/iter; left time: 606.3907s\n",
      "\titers: 400, epoch: 9 | loss: 0.0504256\n",
      "\tspeed: 0.0577s/iter; left time: 601.1613s\n",
      "\titers: 500, epoch: 9 | loss: 0.0551281\n",
      "\tspeed: 0.0576s/iter; left time: 594.6160s\n",
      "\titers: 600, epoch: 9 | loss: 0.0562751\n",
      "\tspeed: 0.0585s/iter; left time: 597.6538s\n",
      "\titers: 700, epoch: 9 | loss: 0.0516972\n",
      "\tspeed: 0.0575s/iter; left time: 581.8894s\n",
      "\titers: 800, epoch: 9 | loss: 0.0570556\n",
      "\tspeed: 0.0599s/iter; left time: 600.7258s\n",
      "\titers: 900, epoch: 9 | loss: 0.0492881\n",
      "\tspeed: 0.0598s/iter; left time: 593.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:52.99s\n",
      "Steps: 902 | Train Loss: 0.0544857 Vali Loss: 0.0874148 Test Loss: 0.0987635\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024115122854709625, rmse:0.15529043972492218, mae:0.09677531570196152, rse:0.6014295220375061\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1785302\n",
      "\tspeed: 0.0635s/iter; left time: 1138.7576s\n",
      "\titers: 200, epoch: 1 | loss: 0.1742498\n",
      "\tspeed: 0.0614s/iter; left time: 1095.3331s\n",
      "\titers: 300, epoch: 1 | loss: 0.1729709\n",
      "\tspeed: 0.0599s/iter; left time: 1062.3939s\n",
      "\titers: 400, epoch: 1 | loss: 0.1655923\n",
      "\tspeed: 0.0582s/iter; left time: 1026.4602s\n",
      "\titers: 500, epoch: 1 | loss: 0.1546990\n",
      "\tspeed: 0.0577s/iter; left time: 1011.3089s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575718\n",
      "\tspeed: 0.0603s/iter; left time: 1052.4058s\n",
      "\titers: 700, epoch: 1 | loss: 0.1496958\n",
      "\tspeed: 0.0600s/iter; left time: 1041.0537s\n",
      "\titers: 800, epoch: 1 | loss: 0.1440132\n",
      "\tspeed: 0.0607s/iter; left time: 1047.0268s\n",
      "\titers: 900, epoch: 1 | loss: 0.1425814\n",
      "\tspeed: 0.0603s/iter; left time: 1033.6411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.40s\n",
      "Steps: 902 | Train Loss: 0.1641949 Vali Loss: 0.1581948 Test Loss: 0.1846315\n",
      "Validation loss decreased (inf --> 0.158195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314752\n",
      "\tspeed: 0.1529s/iter; left time: 2604.5366s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302168\n",
      "\tspeed: 0.0598s/iter; left time: 1013.7875s\n",
      "\titers: 300, epoch: 2 | loss: 0.1227156\n",
      "\tspeed: 0.0597s/iter; left time: 1006.0754s\n",
      "\titers: 400, epoch: 2 | loss: 0.1190880\n",
      "\tspeed: 0.0604s/iter; left time: 1011.0847s\n",
      "\titers: 500, epoch: 2 | loss: 0.0990525\n",
      "\tspeed: 0.0606s/iter; left time: 1008.7808s\n",
      "\titers: 600, epoch: 2 | loss: 0.1053740\n",
      "\tspeed: 0.0606s/iter; left time: 1002.4939s\n",
      "\titers: 700, epoch: 2 | loss: 0.0962143\n",
      "\tspeed: 0.0557s/iter; left time: 915.1166s\n",
      "\titers: 800, epoch: 2 | loss: 0.0986449\n",
      "\tspeed: 0.0579s/iter; left time: 946.0718s\n",
      "\titers: 900, epoch: 2 | loss: 0.1000924\n",
      "\tspeed: 0.0609s/iter; left time: 989.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.11s\n",
      "Steps: 902 | Train Loss: 0.1131171 Vali Loss: 0.1164894 Test Loss: 0.1345251\n",
      "Validation loss decreased (0.158195 --> 0.116489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1004082\n",
      "\tspeed: 0.1523s/iter; left time: 2457.6542s\n",
      "\titers: 200, epoch: 3 | loss: 0.0904731\n",
      "\tspeed: 0.0583s/iter; left time: 934.9128s\n",
      "\titers: 300, epoch: 3 | loss: 0.0904409\n",
      "\tspeed: 0.0584s/iter; left time: 930.1719s\n",
      "\titers: 400, epoch: 3 | loss: 0.0877866\n",
      "\tspeed: 0.0581s/iter; left time: 920.6820s\n",
      "\titers: 500, epoch: 3 | loss: 0.0891124\n",
      "\tspeed: 0.0598s/iter; left time: 940.5747s\n",
      "\titers: 600, epoch: 3 | loss: 0.0888252\n",
      "\tspeed: 0.0595s/iter; left time: 930.5944s\n",
      "\titers: 700, epoch: 3 | loss: 0.0889246\n",
      "\tspeed: 0.0575s/iter; left time: 893.5442s\n",
      "\titers: 800, epoch: 3 | loss: 0.0875869\n",
      "\tspeed: 0.0575s/iter; left time: 886.9235s\n",
      "\titers: 900, epoch: 3 | loss: 0.0879779\n",
      "\tspeed: 0.0579s/iter; left time: 888.4143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.95s\n",
      "Steps: 902 | Train Loss: 0.0916435 Vali Loss: 0.1094298 Test Loss: 0.1251870\n",
      "Validation loss decreased (0.116489 --> 0.109430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0813007\n",
      "\tspeed: 0.1541s/iter; left time: 2347.9719s\n",
      "\titers: 200, epoch: 4 | loss: 0.0870459\n",
      "\tspeed: 0.0603s/iter; left time: 912.5594s\n",
      "\titers: 300, epoch: 4 | loss: 0.0785663\n",
      "\tspeed: 0.0601s/iter; left time: 903.9126s\n",
      "\titers: 400, epoch: 4 | loss: 0.0740290\n",
      "\tspeed: 0.0602s/iter; left time: 899.2363s\n",
      "\titers: 500, epoch: 4 | loss: 0.0707856\n",
      "\tspeed: 0.0602s/iter; left time: 893.2220s\n",
      "\titers: 600, epoch: 4 | loss: 0.0676506\n",
      "\tspeed: 0.0554s/iter; left time: 815.7501s\n",
      "\titers: 700, epoch: 4 | loss: 0.0746882\n",
      "\tspeed: 0.0549s/iter; left time: 803.8527s\n",
      "\titers: 800, epoch: 4 | loss: 0.0669481\n",
      "\tspeed: 0.0547s/iter; left time: 794.8761s\n",
      "\titers: 900, epoch: 4 | loss: 0.0653036\n",
      "\tspeed: 0.0602s/iter; left time: 869.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.19s\n",
      "Steps: 902 | Train Loss: 0.0758402 Vali Loss: 0.0875886 Test Loss: 0.0993864\n",
      "Validation loss decreased (0.109430 --> 0.087589).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722621\n",
      "\tspeed: 0.1510s/iter; left time: 2164.7217s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759351\n",
      "\tspeed: 0.0572s/iter; left time: 814.0176s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662302\n",
      "\tspeed: 0.0551s/iter; left time: 778.5665s\n",
      "\titers: 400, epoch: 5 | loss: 0.0686782\n",
      "\tspeed: 0.0544s/iter; left time: 763.2730s\n",
      "\titers: 500, epoch: 5 | loss: 0.0718346\n",
      "\tspeed: 0.0539s/iter; left time: 751.3672s\n",
      "\titers: 600, epoch: 5 | loss: 0.0629920\n",
      "\tspeed: 0.0525s/iter; left time: 726.4640s\n",
      "\titers: 700, epoch: 5 | loss: 0.0704636\n",
      "\tspeed: 0.0539s/iter; left time: 740.5741s\n",
      "\titers: 800, epoch: 5 | loss: 0.0650801\n",
      "\tspeed: 0.0561s/iter; left time: 765.0776s\n",
      "\titers: 900, epoch: 5 | loss: 0.0662815\n",
      "\tspeed: 0.0568s/iter; left time: 768.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.39s\n",
      "Steps: 902 | Train Loss: 0.0671744 Vali Loss: 0.0864926 Test Loss: 0.0974499\n",
      "Validation loss decreased (0.087589 --> 0.086493).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0632755\n",
      "\tspeed: 0.1613s/iter; left time: 2166.8490s\n",
      "\titers: 200, epoch: 6 | loss: 0.0704076\n",
      "\tspeed: 0.0521s/iter; left time: 694.5483s\n",
      "\titers: 300, epoch: 6 | loss: 0.0638798\n",
      "\tspeed: 0.0568s/iter; left time: 751.5413s\n",
      "\titers: 400, epoch: 6 | loss: 0.0719318\n",
      "\tspeed: 0.0539s/iter; left time: 708.3267s\n",
      "\titers: 500, epoch: 6 | loss: 0.0646495\n",
      "\tspeed: 0.0537s/iter; left time: 700.1309s\n",
      "\titers: 600, epoch: 6 | loss: 0.0630737\n",
      "\tspeed: 0.0527s/iter; left time: 680.8240s\n",
      "\titers: 700, epoch: 6 | loss: 0.0621607\n",
      "\tspeed: 0.0528s/iter; left time: 676.9724s\n",
      "\titers: 800, epoch: 6 | loss: 0.0637690\n",
      "\tspeed: 0.0556s/iter; left time: 707.3471s\n",
      "\titers: 900, epoch: 6 | loss: 0.0659249\n",
      "\tspeed: 0.0570s/iter; left time: 719.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.64s\n",
      "Steps: 902 | Train Loss: 0.0638288 Vali Loss: 0.0890451 Test Loss: 0.0982523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608656\n",
      "\tspeed: 0.1494s/iter; left time: 1871.3064s\n",
      "\titers: 200, epoch: 7 | loss: 0.0660629\n",
      "\tspeed: 0.0542s/iter; left time: 673.0992s\n",
      "\titers: 300, epoch: 7 | loss: 0.0593757\n",
      "\tspeed: 0.0547s/iter; left time: 673.9836s\n",
      "\titers: 400, epoch: 7 | loss: 0.0624351\n",
      "\tspeed: 0.0580s/iter; left time: 709.3627s\n",
      "\titers: 500, epoch: 7 | loss: 0.0612352\n",
      "\tspeed: 0.0542s/iter; left time: 657.6281s\n",
      "\titers: 600, epoch: 7 | loss: 0.0603471\n",
      "\tspeed: 0.0559s/iter; left time: 672.6033s\n",
      "\titers: 700, epoch: 7 | loss: 0.0572254\n",
      "\tspeed: 0.0544s/iter; left time: 649.4253s\n",
      "\titers: 800, epoch: 7 | loss: 0.0634374\n",
      "\tspeed: 0.0559s/iter; left time: 661.4510s\n",
      "\titers: 900, epoch: 7 | loss: 0.0577613\n",
      "\tspeed: 0.0560s/iter; left time: 656.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.04s\n",
      "Steps: 902 | Train Loss: 0.0610705 Vali Loss: 0.0890353 Test Loss: 0.0984212\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568304\n",
      "\tspeed: 0.1530s/iter; left time: 1779.2663s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629917\n",
      "\tspeed: 0.0533s/iter; left time: 614.7875s\n",
      "\titers: 300, epoch: 8 | loss: 0.0604713\n",
      "\tspeed: 0.0573s/iter; left time: 654.6461s\n",
      "\titers: 400, epoch: 8 | loss: 0.0546912\n",
      "\tspeed: 0.0599s/iter; left time: 678.1914s\n",
      "\titers: 500, epoch: 8 | loss: 0.0576465\n",
      "\tspeed: 0.0536s/iter; left time: 601.8852s\n",
      "\titers: 600, epoch: 8 | loss: 0.0579468\n",
      "\tspeed: 0.0560s/iter; left time: 622.6592s\n",
      "\titers: 700, epoch: 8 | loss: 0.0640215\n",
      "\tspeed: 0.0584s/iter; left time: 644.0706s\n",
      "\titers: 800, epoch: 8 | loss: 0.0588516\n",
      "\tspeed: 0.0579s/iter; left time: 633.1668s\n",
      "\titers: 900, epoch: 8 | loss: 0.0581271\n",
      "\tspeed: 0.0597s/iter; left time: 646.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.42s\n",
      "Steps: 902 | Train Loss: 0.0581456 Vali Loss: 0.0892812 Test Loss: 0.1002643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0557753\n",
      "\tspeed: 0.1540s/iter; left time: 1651.5160s\n",
      "\titers: 200, epoch: 9 | loss: 0.0565634\n",
      "\tspeed: 0.0549s/iter; left time: 583.5711s\n",
      "\titers: 300, epoch: 9 | loss: 0.0615852\n",
      "\tspeed: 0.0533s/iter; left time: 561.2829s\n",
      "\titers: 400, epoch: 9 | loss: 0.0576182\n",
      "\tspeed: 0.0538s/iter; left time: 560.9104s\n",
      "\titers: 500, epoch: 9 | loss: 0.0538350\n",
      "\tspeed: 0.0599s/iter; left time: 618.6423s\n",
      "\titers: 600, epoch: 9 | loss: 0.0555872\n",
      "\tspeed: 0.0548s/iter; left time: 560.2040s\n",
      "\titers: 700, epoch: 9 | loss: 0.0574964\n",
      "\tspeed: 0.0563s/iter; left time: 569.7864s\n",
      "\titers: 800, epoch: 9 | loss: 0.0590935\n",
      "\tspeed: 0.0544s/iter; left time: 545.4058s\n",
      "\titers: 900, epoch: 9 | loss: 0.0515767\n",
      "\tspeed: 0.0555s/iter; left time: 551.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.18s\n",
      "Steps: 902 | Train Loss: 0.0557337 Vali Loss: 0.0892858 Test Loss: 0.1004070\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0550226\n",
      "\tspeed: 0.1545s/iter; left time: 1518.0811s\n",
      "\titers: 200, epoch: 10 | loss: 0.0531268\n",
      "\tspeed: 0.0610s/iter; left time: 593.5321s\n",
      "\titers: 300, epoch: 10 | loss: 0.0561566\n",
      "\tspeed: 0.0571s/iter; left time: 549.1860s\n",
      "\titers: 400, epoch: 10 | loss: 0.0495613\n",
      "\tspeed: 0.0566s/iter; left time: 539.3311s\n",
      "\titers: 500, epoch: 10 | loss: 0.0518721\n",
      "\tspeed: 0.0539s/iter; left time: 508.2590s\n",
      "\titers: 600, epoch: 10 | loss: 0.0532236\n",
      "\tspeed: 0.0568s/iter; left time: 529.8027s\n",
      "\titers: 700, epoch: 10 | loss: 0.0585488\n",
      "\tspeed: 0.0594s/iter; left time: 547.4720s\n",
      "\titers: 800, epoch: 10 | loss: 0.0552348\n",
      "\tspeed: 0.0569s/iter; left time: 519.3443s\n",
      "\titers: 900, epoch: 10 | loss: 0.0491405\n",
      "\tspeed: 0.0610s/iter; left time: 550.4105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:52.70s\n",
      "Steps: 902 | Train Loss: 0.0535494 Vali Loss: 0.0900601 Test Loss: 0.1045570\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02373029664158821, rmse:0.1540464162826538, mae:0.09749884158372879, rse:0.5966114401817322\n",
      "Intermediate time for FR and pred_len 168: 00h:19m:38.78s\n",
      "Intermediate time for FR: 01h:05m:07.23s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2307948\n",
      "\tspeed: 0.0721s/iter; left time: 1299.0824s\n",
      "\titers: 200, epoch: 1 | loss: 0.2170307\n",
      "\tspeed: 0.0469s/iter; left time: 840.8232s\n",
      "\titers: 300, epoch: 1 | loss: 0.1993549\n",
      "\tspeed: 0.0477s/iter; left time: 849.8236s\n",
      "\titers: 400, epoch: 1 | loss: 0.1917663\n",
      "\tspeed: 0.0475s/iter; left time: 841.9351s\n",
      "\titers: 500, epoch: 1 | loss: 0.1806835\n",
      "\tspeed: 0.0476s/iter; left time: 838.1656s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889363\n",
      "\tspeed: 0.0459s/iter; left time: 805.0661s\n",
      "\titers: 700, epoch: 1 | loss: 0.1678230\n",
      "\tspeed: 0.0464s/iter; left time: 809.0737s\n",
      "\titers: 800, epoch: 1 | loss: 0.1737418\n",
      "\tspeed: 0.0464s/iter; left time: 803.9748s\n",
      "\titers: 900, epoch: 1 | loss: 0.1780356\n",
      "\tspeed: 0.0461s/iter; left time: 794.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 906 | Train Loss: 0.1945321 Vali Loss: 0.1552572 Test Loss: 0.1695632\n",
      "Validation loss decreased (inf --> 0.155257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1274221\n",
      "\tspeed: 0.1163s/iter; left time: 1989.7082s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033664\n",
      "\tspeed: 0.0454s/iter; left time: 772.8905s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016906\n",
      "\tspeed: 0.0460s/iter; left time: 777.9083s\n",
      "\titers: 400, epoch: 2 | loss: 0.0928045\n",
      "\tspeed: 0.0405s/iter; left time: 680.1879s\n",
      "\titers: 500, epoch: 2 | loss: 0.0867835\n",
      "\tspeed: 0.0410s/iter; left time: 685.5672s\n",
      "\titers: 600, epoch: 2 | loss: 0.0947664\n",
      "\tspeed: 0.0457s/iter; left time: 759.2955s\n",
      "\titers: 700, epoch: 2 | loss: 0.0804106\n",
      "\tspeed: 0.0380s/iter; left time: 627.3463s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738746\n",
      "\tspeed: 0.0425s/iter; left time: 697.5514s\n",
      "\titers: 900, epoch: 2 | loss: 0.0749059\n",
      "\tspeed: 0.0445s/iter; left time: 726.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.47s\n",
      "Steps: 906 | Train Loss: 0.0942970 Vali Loss: 0.0736937 Test Loss: 0.0768138\n",
      "Validation loss decreased (0.155257 --> 0.073694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0687655\n",
      "\tspeed: 0.1155s/iter; left time: 1872.4141s\n",
      "\titers: 200, epoch: 3 | loss: 0.0704586\n",
      "\tspeed: 0.0445s/iter; left time: 716.1992s\n",
      "\titers: 300, epoch: 3 | loss: 0.0724156\n",
      "\tspeed: 0.0458s/iter; left time: 733.4158s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637848\n",
      "\tspeed: 0.0452s/iter; left time: 719.8114s\n",
      "\titers: 500, epoch: 3 | loss: 0.0650237\n",
      "\tspeed: 0.0462s/iter; left time: 730.1273s\n",
      "\titers: 600, epoch: 3 | loss: 0.0696827\n",
      "\tspeed: 0.0458s/iter; left time: 719.7048s\n",
      "\titers: 700, epoch: 3 | loss: 0.0704158\n",
      "\tspeed: 0.0458s/iter; left time: 715.3496s\n",
      "\titers: 800, epoch: 3 | loss: 0.0765548\n",
      "\tspeed: 0.0464s/iter; left time: 718.8555s\n",
      "\titers: 900, epoch: 3 | loss: 0.0625168\n",
      "\tspeed: 0.0461s/iter; left time: 709.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.0707018 Vali Loss: 0.0683638 Test Loss: 0.0725142\n",
      "Validation loss decreased (0.073694 --> 0.068364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0740591\n",
      "\tspeed: 0.1281s/iter; left time: 1960.5387s\n",
      "\titers: 200, epoch: 4 | loss: 0.0657040\n",
      "\tspeed: 0.0457s/iter; left time: 695.1284s\n",
      "\titers: 300, epoch: 4 | loss: 0.0651752\n",
      "\tspeed: 0.0457s/iter; left time: 689.4549s\n",
      "\titers: 400, epoch: 4 | loss: 0.0705427\n",
      "\tspeed: 0.0438s/iter; left time: 656.9906s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684307\n",
      "\tspeed: 0.0454s/iter; left time: 675.8787s\n",
      "\titers: 600, epoch: 4 | loss: 0.0605410\n",
      "\tspeed: 0.0455s/iter; left time: 673.7403s\n",
      "\titers: 700, epoch: 4 | loss: 0.0608732\n",
      "\tspeed: 0.0459s/iter; left time: 675.0490s\n",
      "\titers: 800, epoch: 4 | loss: 0.0677149\n",
      "\tspeed: 0.0463s/iter; left time: 676.7305s\n",
      "\titers: 900, epoch: 4 | loss: 0.0673072\n",
      "\tspeed: 0.0461s/iter; left time: 667.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 906 | Train Loss: 0.0663268 Vali Loss: 0.0629338 Test Loss: 0.0677571\n",
      "Validation loss decreased (0.068364 --> 0.062934).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582587\n",
      "\tspeed: 0.1164s/iter; left time: 1675.2684s\n",
      "\titers: 200, epoch: 5 | loss: 0.0729717\n",
      "\tspeed: 0.0462s/iter; left time: 660.8183s\n",
      "\titers: 300, epoch: 5 | loss: 0.0581469\n",
      "\tspeed: 0.0461s/iter; left time: 653.7912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0582043\n",
      "\tspeed: 0.0457s/iter; left time: 644.3940s\n",
      "\titers: 500, epoch: 5 | loss: 0.0630305\n",
      "\tspeed: 0.0455s/iter; left time: 636.3713s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587564\n",
      "\tspeed: 0.0440s/iter; left time: 611.6765s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723579\n",
      "\tspeed: 0.0460s/iter; left time: 635.1060s\n",
      "\titers: 800, epoch: 5 | loss: 0.0508928\n",
      "\tspeed: 0.0343s/iter; left time: 469.5837s\n",
      "\titers: 900, epoch: 5 | loss: 0.0608719\n",
      "\tspeed: 0.0384s/iter; left time: 521.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 906 | Train Loss: 0.0611652 Vali Loss: 0.0615305 Test Loss: 0.0664691\n",
      "Validation loss decreased (0.062934 --> 0.061531).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599097\n",
      "\tspeed: 0.1150s/iter; left time: 1551.8573s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599032\n",
      "\tspeed: 0.0461s/iter; left time: 617.0158s\n",
      "\titers: 300, epoch: 6 | loss: 0.0679143\n",
      "\tspeed: 0.0453s/iter; left time: 602.4755s\n",
      "\titers: 400, epoch: 6 | loss: 0.0566240\n",
      "\tspeed: 0.0458s/iter; left time: 603.7310s\n",
      "\titers: 500, epoch: 6 | loss: 0.0485979\n",
      "\tspeed: 0.0456s/iter; left time: 596.6031s\n",
      "\titers: 600, epoch: 6 | loss: 0.0569954\n",
      "\tspeed: 0.0463s/iter; left time: 601.3462s\n",
      "\titers: 700, epoch: 6 | loss: 0.0567324\n",
      "\tspeed: 0.0462s/iter; left time: 595.5850s\n",
      "\titers: 800, epoch: 6 | loss: 0.0569716\n",
      "\tspeed: 0.0456s/iter; left time: 583.1985s\n",
      "\titers: 900, epoch: 6 | loss: 0.0572487\n",
      "\tspeed: 0.0454s/iter; left time: 575.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 906 | Train Loss: 0.0585703 Vali Loss: 0.0593522 Test Loss: 0.0649830\n",
      "Validation loss decreased (0.061531 --> 0.059352).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0521329\n",
      "\tspeed: 0.1140s/iter; left time: 1434.8173s\n",
      "\titers: 200, epoch: 7 | loss: 0.0602825\n",
      "\tspeed: 0.0398s/iter; left time: 496.8121s\n",
      "\titers: 300, epoch: 7 | loss: 0.0526658\n",
      "\tspeed: 0.0403s/iter; left time: 499.5965s\n",
      "\titers: 400, epoch: 7 | loss: 0.0597318\n",
      "\tspeed: 0.0452s/iter; left time: 555.1043s\n",
      "\titers: 500, epoch: 7 | loss: 0.0559797\n",
      "\tspeed: 0.0447s/iter; left time: 545.0116s\n",
      "\titers: 600, epoch: 7 | loss: 0.0527933\n",
      "\tspeed: 0.0442s/iter; left time: 534.4707s\n",
      "\titers: 700, epoch: 7 | loss: 0.0564267\n",
      "\tspeed: 0.0450s/iter; left time: 539.3642s\n",
      "\titers: 800, epoch: 7 | loss: 0.0623623\n",
      "\tspeed: 0.0455s/iter; left time: 541.1146s\n",
      "\titers: 900, epoch: 7 | loss: 0.0521361\n",
      "\tspeed: 0.0458s/iter; left time: 539.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 906 | Train Loss: 0.0565267 Vali Loss: 0.0588676 Test Loss: 0.0644704\n",
      "Validation loss decreased (0.059352 --> 0.058868).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0495059\n",
      "\tspeed: 0.1170s/iter; left time: 1366.3918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0503293\n",
      "\tspeed: 0.0455s/iter; left time: 526.9212s\n",
      "\titers: 300, epoch: 8 | loss: 0.0528705\n",
      "\tspeed: 0.0460s/iter; left time: 527.5471s\n",
      "\titers: 400, epoch: 8 | loss: 0.0570818\n",
      "\tspeed: 0.0454s/iter; left time: 516.5250s\n",
      "\titers: 500, epoch: 8 | loss: 0.0514506\n",
      "\tspeed: 0.0456s/iter; left time: 513.8822s\n",
      "\titers: 600, epoch: 8 | loss: 0.0580141\n",
      "\tspeed: 0.0460s/iter; left time: 513.7563s\n",
      "\titers: 700, epoch: 8 | loss: 0.0505321\n",
      "\tspeed: 0.0455s/iter; left time: 504.5194s\n",
      "\titers: 800, epoch: 8 | loss: 0.0571655\n",
      "\tspeed: 0.0459s/iter; left time: 503.8342s\n",
      "\titers: 900, epoch: 8 | loss: 0.0527277\n",
      "\tspeed: 0.0460s/iter; left time: 500.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.0548148 Vali Loss: 0.0589675 Test Loss: 0.0645328\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0492653\n",
      "\tspeed: 0.1035s/iter; left time: 1115.5191s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525350\n",
      "\tspeed: 0.0405s/iter; left time: 431.7273s\n",
      "\titers: 300, epoch: 9 | loss: 0.0607874\n",
      "\tspeed: 0.0344s/iter; left time: 364.1603s\n",
      "\titers: 400, epoch: 9 | loss: 0.0506876\n",
      "\tspeed: 0.0344s/iter; left time: 360.1093s\n",
      "\titers: 500, epoch: 9 | loss: 0.0526138\n",
      "\tspeed: 0.0345s/iter; left time: 358.1490s\n",
      "\titers: 600, epoch: 9 | loss: 0.0575149\n",
      "\tspeed: 0.0347s/iter; left time: 356.8773s\n",
      "\titers: 700, epoch: 9 | loss: 0.0521966\n",
      "\tspeed: 0.0439s/iter; left time: 446.8943s\n",
      "\titers: 800, epoch: 9 | loss: 0.0507446\n",
      "\tspeed: 0.0443s/iter; left time: 446.4457s\n",
      "\titers: 900, epoch: 9 | loss: 0.0499900\n",
      "\tspeed: 0.0344s/iter; left time: 343.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:34.45s\n",
      "Steps: 906 | Train Loss: 0.0529426 Vali Loss: 0.0582318 Test Loss: 0.0637104\n",
      "Validation loss decreased (0.058868 --> 0.058232).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0533132\n",
      "\tspeed: 0.1155s/iter; left time: 1139.9241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0526193\n",
      "\tspeed: 0.0455s/iter; left time: 444.7213s\n",
      "\titers: 300, epoch: 10 | loss: 0.0531725\n",
      "\tspeed: 0.0455s/iter; left time: 440.2593s\n",
      "\titers: 400, epoch: 10 | loss: 0.0492657\n",
      "\tspeed: 0.0462s/iter; left time: 441.9885s\n",
      "\titers: 500, epoch: 10 | loss: 0.0447725\n",
      "\tspeed: 0.0461s/iter; left time: 436.0313s\n",
      "\titers: 600, epoch: 10 | loss: 0.0552568\n",
      "\tspeed: 0.0460s/iter; left time: 430.5452s\n",
      "\titers: 700, epoch: 10 | loss: 0.0507572\n",
      "\tspeed: 0.0461s/iter; left time: 427.1633s\n",
      "\titers: 800, epoch: 10 | loss: 0.0558165\n",
      "\tspeed: 0.0460s/iter; left time: 422.1070s\n",
      "\titers: 900, epoch: 10 | loss: 0.0490795\n",
      "\tspeed: 0.0461s/iter; left time: 417.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.89s\n",
      "Steps: 906 | Train Loss: 0.0516530 Vali Loss: 0.0562525 Test Loss: 0.0636979\n",
      "Validation loss decreased (0.058232 --> 0.056252).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0508998\n",
      "\tspeed: 0.1178s/iter; left time: 1055.4424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481778\n",
      "\tspeed: 0.0459s/iter; left time: 406.6955s\n",
      "\titers: 300, epoch: 11 | loss: 0.0519176\n",
      "\tspeed: 0.0461s/iter; left time: 403.6090s\n",
      "\titers: 400, epoch: 11 | loss: 0.0494691\n",
      "\tspeed: 0.0457s/iter; left time: 395.6066s\n",
      "\titers: 500, epoch: 11 | loss: 0.0515038\n",
      "\tspeed: 0.0462s/iter; left time: 395.8119s\n",
      "\titers: 600, epoch: 11 | loss: 0.0554365\n",
      "\tspeed: 0.0450s/iter; left time: 380.7408s\n",
      "\titers: 700, epoch: 11 | loss: 0.0472331\n",
      "\tspeed: 0.0455s/iter; left time: 380.6264s\n",
      "\titers: 800, epoch: 11 | loss: 0.0520767\n",
      "\tspeed: 0.0463s/iter; left time: 382.3994s\n",
      "\titers: 900, epoch: 11 | loss: 0.0424463\n",
      "\tspeed: 0.0460s/iter; left time: 375.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 906 | Train Loss: 0.0502541 Vali Loss: 0.0577327 Test Loss: 0.0642007\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454566\n",
      "\tspeed: 0.1106s/iter; left time: 891.0652s\n",
      "\titers: 200, epoch: 12 | loss: 0.0528943\n",
      "\tspeed: 0.0457s/iter; left time: 363.4229s\n",
      "\titers: 300, epoch: 12 | loss: 0.0458079\n",
      "\tspeed: 0.0461s/iter; left time: 361.9115s\n",
      "\titers: 400, epoch: 12 | loss: 0.0522390\n",
      "\tspeed: 0.0463s/iter; left time: 358.7723s\n",
      "\titers: 500, epoch: 12 | loss: 0.0539040\n",
      "\tspeed: 0.0465s/iter; left time: 356.0043s\n",
      "\titers: 600, epoch: 12 | loss: 0.0494072\n",
      "\tspeed: 0.0463s/iter; left time: 349.7081s\n",
      "\titers: 700, epoch: 12 | loss: 0.0449162\n",
      "\tspeed: 0.0426s/iter; left time: 317.6995s\n",
      "\titers: 800, epoch: 12 | loss: 0.0487760\n",
      "\tspeed: 0.0401s/iter; left time: 294.8353s\n",
      "\titers: 900, epoch: 12 | loss: 0.0489900\n",
      "\tspeed: 0.0441s/iter; left time: 319.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.84s\n",
      "Steps: 906 | Train Loss: 0.0491409 Vali Loss: 0.0570933 Test Loss: 0.0650408\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0444334\n",
      "\tspeed: 0.1098s/iter; left time: 784.7336s\n",
      "\titers: 200, epoch: 13 | loss: 0.0502308\n",
      "\tspeed: 0.0468s/iter; left time: 329.6964s\n",
      "\titers: 300, epoch: 13 | loss: 0.0439510\n",
      "\tspeed: 0.0457s/iter; left time: 317.7920s\n",
      "\titers: 400, epoch: 13 | loss: 0.0540998\n",
      "\tspeed: 0.0461s/iter; left time: 315.9764s\n",
      "\titers: 500, epoch: 13 | loss: 0.0414450\n",
      "\tspeed: 0.0450s/iter; left time: 303.5217s\n",
      "\titers: 600, epoch: 13 | loss: 0.0479760\n",
      "\tspeed: 0.0464s/iter; left time: 308.2690s\n",
      "\titers: 700, epoch: 13 | loss: 0.0474711\n",
      "\tspeed: 0.0457s/iter; left time: 299.5120s\n",
      "\titers: 800, epoch: 13 | loss: 0.0518570\n",
      "\tspeed: 0.0453s/iter; left time: 292.3641s\n",
      "\titers: 900, epoch: 13 | loss: 0.0531900\n",
      "\tspeed: 0.0459s/iter; left time: 291.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 906 | Train Loss: 0.0481198 Vali Loss: 0.0574941 Test Loss: 0.0645238\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0513889\n",
      "\tspeed: 0.1071s/iter; left time: 668.7431s\n",
      "\titers: 200, epoch: 14 | loss: 0.0478791\n",
      "\tspeed: 0.0463s/iter; left time: 284.4605s\n",
      "\titers: 300, epoch: 14 | loss: 0.0410728\n",
      "\tspeed: 0.0460s/iter; left time: 278.1191s\n",
      "\titers: 400, epoch: 14 | loss: 0.0400066\n",
      "\tspeed: 0.0461s/iter; left time: 273.6772s\n",
      "\titers: 500, epoch: 14 | loss: 0.0507554\n",
      "\tspeed: 0.0453s/iter; left time: 264.8484s\n",
      "\titers: 600, epoch: 14 | loss: 0.0465095\n",
      "\tspeed: 0.0459s/iter; left time: 263.3496s\n",
      "\titers: 700, epoch: 14 | loss: 0.0421395\n",
      "\tspeed: 0.0453s/iter; left time: 255.5417s\n",
      "\titers: 800, epoch: 14 | loss: 0.0522231\n",
      "\tspeed: 0.0462s/iter; left time: 255.9529s\n",
      "\titers: 900, epoch: 14 | loss: 0.0404586\n",
      "\tspeed: 0.0461s/iter; left time: 251.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 906 | Train Loss: 0.0469094 Vali Loss: 0.0568367 Test Loss: 0.0650876\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453801\n",
      "\tspeed: 0.1099s/iter; left time: 586.4157s\n",
      "\titers: 200, epoch: 15 | loss: 0.0439583\n",
      "\tspeed: 0.0454s/iter; left time: 237.5691s\n",
      "\titers: 300, epoch: 15 | loss: 0.0447786\n",
      "\tspeed: 0.0464s/iter; left time: 238.2008s\n",
      "\titers: 400, epoch: 15 | loss: 0.0476598\n",
      "\tspeed: 0.0463s/iter; left time: 233.0282s\n",
      "\titers: 500, epoch: 15 | loss: 0.0495078\n",
      "\tspeed: 0.0456s/iter; left time: 225.2822s\n",
      "\titers: 600, epoch: 15 | loss: 0.0445326\n",
      "\tspeed: 0.0461s/iter; left time: 223.1705s\n",
      "\titers: 700, epoch: 15 | loss: 0.0462682\n",
      "\tspeed: 0.0460s/iter; left time: 217.8345s\n",
      "\titers: 800, epoch: 15 | loss: 0.0402244\n",
      "\tspeed: 0.0458s/iter; left time: 212.4315s\n",
      "\titers: 900, epoch: 15 | loss: 0.0464951\n",
      "\tspeed: 0.0462s/iter; left time: 209.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 906 | Train Loss: 0.0460613 Vali Loss: 0.0586359 Test Loss: 0.0665492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011864868924021721, rmse:0.10892597585916519, mae:0.06381679326295853, rse:0.41163885593414307\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2109626\n",
      "\tspeed: 0.0482s/iter; left time: 868.1846s\n",
      "\titers: 200, epoch: 1 | loss: 0.2091217\n",
      "\tspeed: 0.0468s/iter; left time: 839.0923s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961004\n",
      "\tspeed: 0.0464s/iter; left time: 826.8452s\n",
      "\titers: 400, epoch: 1 | loss: 0.1901211\n",
      "\tspeed: 0.0464s/iter; left time: 821.9869s\n",
      "\titers: 500, epoch: 1 | loss: 0.1885638\n",
      "\tspeed: 0.0455s/iter; left time: 802.3692s\n",
      "\titers: 600, epoch: 1 | loss: 0.1874101\n",
      "\tspeed: 0.0462s/iter; left time: 809.0309s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783781\n",
      "\tspeed: 0.0465s/iter; left time: 810.8653s\n",
      "\titers: 800, epoch: 1 | loss: 0.1743317\n",
      "\tspeed: 0.0464s/iter; left time: 804.4761s\n",
      "\titers: 900, epoch: 1 | loss: 0.1757907\n",
      "\tspeed: 0.0462s/iter; left time: 795.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 906 | Train Loss: 0.1959116 Vali Loss: 0.1546778 Test Loss: 0.1709039\n",
      "Validation loss decreased (inf --> 0.154678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1281275\n",
      "\tspeed: 0.1177s/iter; left time: 2015.1886s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132162\n",
      "\tspeed: 0.0459s/iter; left time: 781.4092s\n",
      "\titers: 300, epoch: 2 | loss: 0.0984158\n",
      "\tspeed: 0.0462s/iter; left time: 781.5899s\n",
      "\titers: 400, epoch: 2 | loss: 0.0888975\n",
      "\tspeed: 0.0471s/iter; left time: 792.2074s\n",
      "\titers: 500, epoch: 2 | loss: 0.0904843\n",
      "\tspeed: 0.0465s/iter; left time: 777.4221s\n",
      "\titers: 600, epoch: 2 | loss: 0.0857565\n",
      "\tspeed: 0.0460s/iter; left time: 765.0775s\n",
      "\titers: 700, epoch: 2 | loss: 0.0794186\n",
      "\tspeed: 0.0461s/iter; left time: 761.2701s\n",
      "\titers: 800, epoch: 2 | loss: 0.0741243\n",
      "\tspeed: 0.0463s/iter; left time: 760.6779s\n",
      "\titers: 900, epoch: 2 | loss: 0.0768472\n",
      "\tspeed: 0.0460s/iter; left time: 750.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 906 | Train Loss: 0.0952127 Vali Loss: 0.0730349 Test Loss: 0.0759419\n",
      "Validation loss decreased (0.154678 --> 0.073035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0723839\n",
      "\tspeed: 0.1196s/iter; left time: 1939.0873s\n",
      "\titers: 200, epoch: 3 | loss: 0.0767555\n",
      "\tspeed: 0.0462s/iter; left time: 743.7280s\n",
      "\titers: 300, epoch: 3 | loss: 0.0778952\n",
      "\tspeed: 0.0461s/iter; left time: 738.3189s\n",
      "\titers: 400, epoch: 3 | loss: 0.0873912\n",
      "\tspeed: 0.0457s/iter; left time: 727.7648s\n",
      "\titers: 500, epoch: 3 | loss: 0.0722778\n",
      "\tspeed: 0.0456s/iter; left time: 720.4852s\n",
      "\titers: 600, epoch: 3 | loss: 0.0687346\n",
      "\tspeed: 0.0461s/iter; left time: 724.3926s\n",
      "\titers: 700, epoch: 3 | loss: 0.0765534\n",
      "\tspeed: 0.0459s/iter; left time: 717.2048s\n",
      "\titers: 800, epoch: 3 | loss: 0.0741475\n",
      "\tspeed: 0.0469s/iter; left time: 727.3288s\n",
      "\titers: 900, epoch: 3 | loss: 0.0682636\n",
      "\tspeed: 0.0463s/iter; left time: 712.8698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.11s\n",
      "Steps: 906 | Train Loss: 0.0705030 Vali Loss: 0.0653467 Test Loss: 0.0696557\n",
      "Validation loss decreased (0.073035 --> 0.065347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729796\n",
      "\tspeed: 0.1183s/iter; left time: 1810.1404s\n",
      "\titers: 200, epoch: 4 | loss: 0.0689848\n",
      "\tspeed: 0.0461s/iter; left time: 700.7664s\n",
      "\titers: 300, epoch: 4 | loss: 0.0671700\n",
      "\tspeed: 0.0463s/iter; left time: 699.0460s\n",
      "\titers: 400, epoch: 4 | loss: 0.0754131\n",
      "\tspeed: 0.0467s/iter; left time: 700.6095s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684203\n",
      "\tspeed: 0.0466s/iter; left time: 694.9005s\n",
      "\titers: 600, epoch: 4 | loss: 0.0608075\n",
      "\tspeed: 0.0463s/iter; left time: 685.4812s\n",
      "\titers: 700, epoch: 4 | loss: 0.0621233\n",
      "\tspeed: 0.0462s/iter; left time: 679.6706s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630564\n",
      "\tspeed: 0.0463s/iter; left time: 675.4794s\n",
      "\titers: 900, epoch: 4 | loss: 0.0627514\n",
      "\tspeed: 0.0463s/iter; left time: 671.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.30s\n",
      "Steps: 906 | Train Loss: 0.0659813 Vali Loss: 0.0651102 Test Loss: 0.0704118\n",
      "Validation loss decreased (0.065347 --> 0.065110).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0640047\n",
      "\tspeed: 0.1177s/iter; left time: 1693.9603s\n",
      "\titers: 200, epoch: 5 | loss: 0.0673053\n",
      "\tspeed: 0.0379s/iter; left time: 542.1728s\n",
      "\titers: 300, epoch: 5 | loss: 0.0616328\n",
      "\tspeed: 0.0344s/iter; left time: 488.4527s\n",
      "\titers: 400, epoch: 5 | loss: 0.0629819\n",
      "\tspeed: 0.0345s/iter; left time: 485.7056s\n",
      "\titers: 500, epoch: 5 | loss: 0.0518201\n",
      "\tspeed: 0.0379s/iter; left time: 530.8547s\n",
      "\titers: 600, epoch: 5 | loss: 0.0555115\n",
      "\tspeed: 0.0462s/iter; left time: 641.8705s\n",
      "\titers: 700, epoch: 5 | loss: 0.0688249\n",
      "\tspeed: 0.0456s/iter; left time: 629.5041s\n",
      "\titers: 800, epoch: 5 | loss: 0.0569780\n",
      "\tspeed: 0.0458s/iter; left time: 627.5672s\n",
      "\titers: 900, epoch: 5 | loss: 0.0626754\n",
      "\tspeed: 0.0466s/iter; left time: 633.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 906 | Train Loss: 0.0617045 Vali Loss: 0.0598438 Test Loss: 0.0665010\n",
      "Validation loss decreased (0.065110 --> 0.059844).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614690\n",
      "\tspeed: 0.1155s/iter; left time: 1558.7684s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638781\n",
      "\tspeed: 0.0464s/iter; left time: 620.7160s\n",
      "\titers: 300, epoch: 6 | loss: 0.0556555\n",
      "\tspeed: 0.0464s/iter; left time: 617.2711s\n",
      "\titers: 400, epoch: 6 | loss: 0.0609595\n",
      "\tspeed: 0.0457s/iter; left time: 602.3026s\n",
      "\titers: 500, epoch: 6 | loss: 0.0524145\n",
      "\tspeed: 0.0460s/iter; left time: 602.3152s\n",
      "\titers: 600, epoch: 6 | loss: 0.0607218\n",
      "\tspeed: 0.0463s/iter; left time: 600.8714s\n",
      "\titers: 700, epoch: 6 | loss: 0.0563587\n",
      "\tspeed: 0.0471s/iter; left time: 607.5614s\n",
      "\titers: 800, epoch: 6 | loss: 0.0591731\n",
      "\tspeed: 0.0460s/iter; left time: 588.7391s\n",
      "\titers: 900, epoch: 6 | loss: 0.0635162\n",
      "\tspeed: 0.0455s/iter; left time: 576.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 906 | Train Loss: 0.0581259 Vali Loss: 0.0593193 Test Loss: 0.0652329\n",
      "Validation loss decreased (0.059844 --> 0.059319).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563043\n",
      "\tspeed: 0.1158s/iter; left time: 1457.0997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620157\n",
      "\tspeed: 0.0456s/iter; left time: 569.1329s\n",
      "\titers: 300, epoch: 7 | loss: 0.0573500\n",
      "\tspeed: 0.0462s/iter; left time: 572.3171s\n",
      "\titers: 400, epoch: 7 | loss: 0.0539220\n",
      "\tspeed: 0.0458s/iter; left time: 562.7614s\n",
      "\titers: 500, epoch: 7 | loss: 0.0572008\n",
      "\tspeed: 0.0464s/iter; left time: 565.8965s\n",
      "\titers: 600, epoch: 7 | loss: 0.0531926\n",
      "\tspeed: 0.0460s/iter; left time: 555.3117s\n",
      "\titers: 700, epoch: 7 | loss: 0.0566674\n",
      "\tspeed: 0.0454s/iter; left time: 544.2876s\n",
      "\titers: 800, epoch: 7 | loss: 0.0561290\n",
      "\tspeed: 0.0461s/iter; left time: 547.9887s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559161\n",
      "\tspeed: 0.0461s/iter; left time: 543.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0564226 Vali Loss: 0.0584143 Test Loss: 0.0647861\n",
      "Validation loss decreased (0.059319 --> 0.058414).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0462566\n",
      "\tspeed: 0.1223s/iter; left time: 1428.3189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0597787\n",
      "\tspeed: 0.0460s/iter; left time: 532.2432s\n",
      "\titers: 300, epoch: 8 | loss: 0.0561780\n",
      "\tspeed: 0.0461s/iter; left time: 529.7547s\n",
      "\titers: 400, epoch: 8 | loss: 0.0555837\n",
      "\tspeed: 0.0461s/iter; left time: 524.1064s\n",
      "\titers: 500, epoch: 8 | loss: 0.0476322\n",
      "\tspeed: 0.0462s/iter; left time: 520.6140s\n",
      "\titers: 600, epoch: 8 | loss: 0.0541930\n",
      "\tspeed: 0.0461s/iter; left time: 515.4133s\n",
      "\titers: 700, epoch: 8 | loss: 0.0557520\n",
      "\tspeed: 0.0464s/iter; left time: 514.5157s\n",
      "\titers: 800, epoch: 8 | loss: 0.0503330\n",
      "\tspeed: 0.0462s/iter; left time: 507.6674s\n",
      "\titers: 900, epoch: 8 | loss: 0.0532688\n",
      "\tspeed: 0.0454s/iter; left time: 493.4389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.08s\n",
      "Steps: 906 | Train Loss: 0.0540635 Vali Loss: 0.0587974 Test Loss: 0.0668096\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0499691\n",
      "\tspeed: 0.1113s/iter; left time: 1198.5113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0512514\n",
      "\tspeed: 0.0459s/iter; left time: 490.0760s\n",
      "\titers: 300, epoch: 9 | loss: 0.0525538\n",
      "\tspeed: 0.0454s/iter; left time: 480.4917s\n",
      "\titers: 400, epoch: 9 | loss: 0.0486190\n",
      "\tspeed: 0.0460s/iter; left time: 481.8090s\n",
      "\titers: 500, epoch: 9 | loss: 0.0457945\n",
      "\tspeed: 0.0463s/iter; left time: 480.1252s\n",
      "\titers: 600, epoch: 9 | loss: 0.0426274\n",
      "\tspeed: 0.0462s/iter; left time: 474.2997s\n",
      "\titers: 700, epoch: 9 | loss: 0.0513264\n",
      "\tspeed: 0.0462s/iter; left time: 469.7447s\n",
      "\titers: 800, epoch: 9 | loss: 0.0450985\n",
      "\tspeed: 0.0462s/iter; left time: 465.8018s\n",
      "\titers: 900, epoch: 9 | loss: 0.0614643\n",
      "\tspeed: 0.0460s/iter; left time: 458.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.98s\n",
      "Steps: 906 | Train Loss: 0.0523870 Vali Loss: 0.0582359 Test Loss: 0.0673847\n",
      "Validation loss decreased (0.058414 --> 0.058236).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0525341\n",
      "\tspeed: 0.1190s/iter; left time: 1173.7879s\n",
      "\titers: 200, epoch: 10 | loss: 0.0492574\n",
      "\tspeed: 0.0469s/iter; left time: 457.6191s\n",
      "\titers: 300, epoch: 10 | loss: 0.0516225\n",
      "\tspeed: 0.0457s/iter; left time: 441.7144s\n",
      "\titers: 400, epoch: 10 | loss: 0.0542395\n",
      "\tspeed: 0.0463s/iter; left time: 442.7613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0526795\n",
      "\tspeed: 0.0462s/iter; left time: 437.0248s\n",
      "\titers: 600, epoch: 10 | loss: 0.0583520\n",
      "\tspeed: 0.0458s/iter; left time: 429.0140s\n",
      "\titers: 700, epoch: 10 | loss: 0.0519676\n",
      "\tspeed: 0.0452s/iter; left time: 418.9620s\n",
      "\titers: 800, epoch: 10 | loss: 0.0471216\n",
      "\tspeed: 0.0465s/iter; left time: 426.5380s\n",
      "\titers: 900, epoch: 10 | loss: 0.0532540\n",
      "\tspeed: 0.0443s/iter; left time: 401.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 906 | Train Loss: 0.0509804 Vali Loss: 0.0577439 Test Loss: 0.0654377\n",
      "Validation loss decreased (0.058236 --> 0.057744).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0532611\n",
      "\tspeed: 0.1141s/iter; left time: 1022.1168s\n",
      "\titers: 200, epoch: 11 | loss: 0.0440280\n",
      "\tspeed: 0.0461s/iter; left time: 408.7278s\n",
      "\titers: 300, epoch: 11 | loss: 0.0471814\n",
      "\tspeed: 0.0457s/iter; left time: 400.6578s\n",
      "\titers: 400, epoch: 11 | loss: 0.0457120\n",
      "\tspeed: 0.0455s/iter; left time: 393.8755s\n",
      "\titers: 500, epoch: 11 | loss: 0.0555467\n",
      "\tspeed: 0.0467s/iter; left time: 400.1266s\n",
      "\titers: 600, epoch: 11 | loss: 0.0511844\n",
      "\tspeed: 0.0466s/iter; left time: 394.2059s\n",
      "\titers: 700, epoch: 11 | loss: 0.0495706\n",
      "\tspeed: 0.0462s/iter; left time: 386.1215s\n",
      "\titers: 800, epoch: 11 | loss: 0.0451784\n",
      "\tspeed: 0.0461s/iter; left time: 380.7636s\n",
      "\titers: 900, epoch: 11 | loss: 0.0467793\n",
      "\tspeed: 0.0457s/iter; left time: 372.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 906 | Train Loss: 0.0497706 Vali Loss: 0.0569061 Test Loss: 0.0654467\n",
      "Validation loss decreased (0.057744 --> 0.056906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0482793\n",
      "\tspeed: 0.1185s/iter; left time: 954.5477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0434402\n",
      "\tspeed: 0.0469s/iter; left time: 373.0319s\n",
      "\titers: 300, epoch: 12 | loss: 0.0461225\n",
      "\tspeed: 0.0468s/iter; left time: 367.4067s\n",
      "\titers: 400, epoch: 12 | loss: 0.0501549\n",
      "\tspeed: 0.0464s/iter; left time: 359.7950s\n",
      "\titers: 500, epoch: 12 | loss: 0.0471101\n",
      "\tspeed: 0.0463s/iter; left time: 354.0828s\n",
      "\titers: 600, epoch: 12 | loss: 0.0460915\n",
      "\tspeed: 0.0465s/iter; left time: 351.2298s\n",
      "\titers: 700, epoch: 12 | loss: 0.0523421\n",
      "\tspeed: 0.0463s/iter; left time: 344.8894s\n",
      "\titers: 800, epoch: 12 | loss: 0.0561501\n",
      "\tspeed: 0.0463s/iter; left time: 340.8723s\n",
      "\titers: 900, epoch: 12 | loss: 0.0543579\n",
      "\tspeed: 0.0455s/iter; left time: 330.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.21s\n",
      "Steps: 906 | Train Loss: 0.0484071 Vali Loss: 0.0569519 Test Loss: 0.0658272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0523379\n",
      "\tspeed: 0.1142s/iter; left time: 816.6506s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463685\n",
      "\tspeed: 0.0469s/iter; left time: 330.3022s\n",
      "\titers: 300, epoch: 13 | loss: 0.0489728\n",
      "\tspeed: 0.0464s/iter; left time: 322.1361s\n",
      "\titers: 400, epoch: 13 | loss: 0.0463173\n",
      "\tspeed: 0.0466s/iter; left time: 319.2036s\n",
      "\titers: 500, epoch: 13 | loss: 0.0386495\n",
      "\tspeed: 0.0458s/iter; left time: 309.1874s\n",
      "\titers: 600, epoch: 13 | loss: 0.0483736\n",
      "\tspeed: 0.0458s/iter; left time: 304.3405s\n",
      "\titers: 700, epoch: 13 | loss: 0.0490400\n",
      "\tspeed: 0.0469s/iter; left time: 307.3407s\n",
      "\titers: 800, epoch: 13 | loss: 0.0517511\n",
      "\tspeed: 0.0468s/iter; left time: 302.1140s\n",
      "\titers: 900, epoch: 13 | loss: 0.0434999\n",
      "\tspeed: 0.0462s/iter; left time: 293.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.35s\n",
      "Steps: 906 | Train Loss: 0.0473505 Vali Loss: 0.0584924 Test Loss: 0.0682402\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0435317\n",
      "\tspeed: 0.1116s/iter; left time: 696.5768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0482684\n",
      "\tspeed: 0.0464s/iter; left time: 285.1611s\n",
      "\titers: 300, epoch: 14 | loss: 0.0464913\n",
      "\tspeed: 0.0466s/iter; left time: 281.6895s\n",
      "\titers: 400, epoch: 14 | loss: 0.0499952\n",
      "\tspeed: 0.0468s/iter; left time: 278.0407s\n",
      "\titers: 500, epoch: 14 | loss: 0.0423364\n",
      "\tspeed: 0.0467s/iter; left time: 272.6370s\n",
      "\titers: 600, epoch: 14 | loss: 0.0485045\n",
      "\tspeed: 0.0466s/iter; left time: 267.4313s\n",
      "\titers: 700, epoch: 14 | loss: 0.0436609\n",
      "\tspeed: 0.0464s/iter; left time: 261.8734s\n",
      "\titers: 800, epoch: 14 | loss: 0.0463641\n",
      "\tspeed: 0.0458s/iter; left time: 253.9245s\n",
      "\titers: 900, epoch: 14 | loss: 0.0399385\n",
      "\tspeed: 0.0464s/iter; left time: 252.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 906 | Train Loss: 0.0461858 Vali Loss: 0.0589781 Test Loss: 0.0686759\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0490868\n",
      "\tspeed: 0.1110s/iter; left time: 592.6486s\n",
      "\titers: 200, epoch: 15 | loss: 0.0424480\n",
      "\tspeed: 0.0471s/iter; left time: 246.8748s\n",
      "\titers: 300, epoch: 15 | loss: 0.0455182\n",
      "\tspeed: 0.0463s/iter; left time: 238.0161s\n",
      "\titers: 400, epoch: 15 | loss: 0.0462314\n",
      "\tspeed: 0.0462s/iter; left time: 232.5880s\n",
      "\titers: 500, epoch: 15 | loss: 0.0469817\n",
      "\tspeed: 0.0468s/iter; left time: 230.9556s\n",
      "\titers: 600, epoch: 15 | loss: 0.0399142\n",
      "\tspeed: 0.0461s/iter; left time: 223.0448s\n",
      "\titers: 700, epoch: 15 | loss: 0.0407262\n",
      "\tspeed: 0.0463s/iter; left time: 219.5031s\n",
      "\titers: 800, epoch: 15 | loss: 0.0469630\n",
      "\tspeed: 0.0464s/iter; left time: 215.1864s\n",
      "\titers: 900, epoch: 15 | loss: 0.0500793\n",
      "\tspeed: 0.0466s/iter; left time: 211.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.27s\n",
      "Steps: 906 | Train Loss: 0.0451721 Vali Loss: 0.0591949 Test Loss: 0.0692948\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0441049\n",
      "\tspeed: 0.1129s/iter; left time: 500.4201s\n",
      "\titers: 200, epoch: 16 | loss: 0.0419718\n",
      "\tspeed: 0.0465s/iter; left time: 201.4254s\n",
      "\titers: 300, epoch: 16 | loss: 0.0411529\n",
      "\tspeed: 0.0460s/iter; left time: 194.4386s\n",
      "\titers: 400, epoch: 16 | loss: 0.0435567\n",
      "\tspeed: 0.0456s/iter; left time: 188.5222s\n",
      "\titers: 500, epoch: 16 | loss: 0.0501134\n",
      "\tspeed: 0.0465s/iter; left time: 187.3870s\n",
      "\titers: 600, epoch: 16 | loss: 0.0526159\n",
      "\tspeed: 0.0455s/iter; left time: 178.9287s\n",
      "\titers: 700, epoch: 16 | loss: 0.0420197\n",
      "\tspeed: 0.0465s/iter; left time: 178.1328s\n",
      "\titers: 800, epoch: 16 | loss: 0.0490651\n",
      "\tspeed: 0.0466s/iter; left time: 174.0283s\n",
      "\titers: 900, epoch: 16 | loss: 0.0443328\n",
      "\tspeed: 0.0462s/iter; left time: 167.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:42.15s\n",
      "Steps: 906 | Train Loss: 0.0442571 Vali Loss: 0.0580243 Test Loss: 0.0665946\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012446870096027851, rmse:0.11156554520130157, mae:0.06534929573535919, rse:0.42161399126052856\n",
      "Intermediate time for IT and pred_len 24: 00h:24m:59.30s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2346102\n",
      "\tspeed: 0.0836s/iter; left time: 1502.8908s\n",
      "\titers: 200, epoch: 1 | loss: 0.2142702\n",
      "\tspeed: 0.0516s/iter; left time: 922.4463s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006122\n",
      "\tspeed: 0.0517s/iter; left time: 920.0968s\n",
      "\titers: 400, epoch: 1 | loss: 0.1997358\n",
      "\tspeed: 0.0522s/iter; left time: 923.4960s\n",
      "\titers: 500, epoch: 1 | loss: 0.2005629\n",
      "\tspeed: 0.0521s/iter; left time: 915.8504s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911706\n",
      "\tspeed: 0.0523s/iter; left time: 913.6639s\n",
      "\titers: 700, epoch: 1 | loss: 0.1871520\n",
      "\tspeed: 0.0516s/iter; left time: 897.4617s\n",
      "\titers: 800, epoch: 1 | loss: 0.1799988\n",
      "\tspeed: 0.0511s/iter; left time: 883.6368s\n",
      "\titers: 900, epoch: 1 | loss: 0.1866743\n",
      "\tspeed: 0.0519s/iter; left time: 891.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 904 | Train Loss: 0.2045585 Vali Loss: 0.1690600 Test Loss: 0.1870416\n",
      "Validation loss decreased (inf --> 0.169060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1703862\n",
      "\tspeed: 0.1369s/iter; left time: 2338.2148s\n",
      "\titers: 200, epoch: 2 | loss: 0.1623032\n",
      "\tspeed: 0.0521s/iter; left time: 883.7392s\n",
      "\titers: 300, epoch: 2 | loss: 0.1603419\n",
      "\tspeed: 0.0511s/iter; left time: 862.0315s\n",
      "\titers: 400, epoch: 2 | loss: 0.1485215\n",
      "\tspeed: 0.0513s/iter; left time: 860.0053s\n",
      "\titers: 500, epoch: 2 | loss: 0.1340641\n",
      "\tspeed: 0.0515s/iter; left time: 858.2297s\n",
      "\titers: 600, epoch: 2 | loss: 0.1223895\n",
      "\tspeed: 0.0516s/iter; left time: 855.4102s\n",
      "\titers: 700, epoch: 2 | loss: 0.1190573\n",
      "\tspeed: 0.0519s/iter; left time: 855.0865s\n",
      "\titers: 800, epoch: 2 | loss: 0.1006235\n",
      "\tspeed: 0.0515s/iter; left time: 844.0052s\n",
      "\titers: 900, epoch: 2 | loss: 0.0964359\n",
      "\tspeed: 0.0522s/iter; left time: 849.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.03s\n",
      "Steps: 904 | Train Loss: 0.1381357 Vali Loss: 0.0926630 Test Loss: 0.1002443\n",
      "Validation loss decreased (0.169060 --> 0.092663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0936791\n",
      "\tspeed: 0.1349s/iter; left time: 2181.6572s\n",
      "\titers: 200, epoch: 3 | loss: 0.0933003\n",
      "\tspeed: 0.0514s/iter; left time: 826.0103s\n",
      "\titers: 300, epoch: 3 | loss: 0.0929585\n",
      "\tspeed: 0.0514s/iter; left time: 820.8665s\n",
      "\titers: 400, epoch: 3 | loss: 0.0903624\n",
      "\tspeed: 0.0512s/iter; left time: 811.9754s\n",
      "\titers: 500, epoch: 3 | loss: 0.0857177\n",
      "\tspeed: 0.0508s/iter; left time: 801.2431s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911927\n",
      "\tspeed: 0.0507s/iter; left time: 793.8521s\n",
      "\titers: 700, epoch: 3 | loss: 0.0836361\n",
      "\tspeed: 0.0507s/iter; left time: 789.0365s\n",
      "\titers: 800, epoch: 3 | loss: 0.0931301\n",
      "\tspeed: 0.0506s/iter; left time: 782.9603s\n",
      "\titers: 900, epoch: 3 | loss: 0.0813277\n",
      "\tspeed: 0.0516s/iter; left time: 793.7182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.45s\n",
      "Steps: 904 | Train Loss: 0.0911522 Vali Loss: 0.0849023 Test Loss: 0.0922207\n",
      "Validation loss decreased (0.092663 --> 0.084902).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807011\n",
      "\tspeed: 0.1354s/iter; left time: 2066.9483s\n",
      "\titers: 200, epoch: 4 | loss: 0.0884485\n",
      "\tspeed: 0.0514s/iter; left time: 779.3313s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868657\n",
      "\tspeed: 0.0513s/iter; left time: 772.6133s\n",
      "\titers: 400, epoch: 4 | loss: 0.0818226\n",
      "\tspeed: 0.0513s/iter; left time: 767.3603s\n",
      "\titers: 500, epoch: 4 | loss: 0.0801383\n",
      "\tspeed: 0.0425s/iter; left time: 631.6506s\n",
      "\titers: 600, epoch: 4 | loss: 0.0800255\n",
      "\tspeed: 0.0500s/iter; left time: 737.8013s\n",
      "\titers: 700, epoch: 4 | loss: 0.0881254\n",
      "\tspeed: 0.0506s/iter; left time: 741.8925s\n",
      "\titers: 800, epoch: 4 | loss: 0.0750352\n",
      "\tspeed: 0.0520s/iter; left time: 757.3101s\n",
      "\titers: 900, epoch: 4 | loss: 0.0815959\n",
      "\tspeed: 0.0510s/iter; left time: 737.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 904 | Train Loss: 0.0842349 Vali Loss: 0.0822077 Test Loss: 0.0902671\n",
      "Validation loss decreased (0.084902 --> 0.082208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0822577\n",
      "\tspeed: 0.1347s/iter; left time: 1934.4378s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750880\n",
      "\tspeed: 0.0511s/iter; left time: 729.4213s\n",
      "\titers: 300, epoch: 5 | loss: 0.0845693\n",
      "\tspeed: 0.0509s/iter; left time: 720.7970s\n",
      "\titers: 400, epoch: 5 | loss: 0.0796774\n",
      "\tspeed: 0.0508s/iter; left time: 714.2798s\n",
      "\titers: 500, epoch: 5 | loss: 0.0784429\n",
      "\tspeed: 0.0515s/iter; left time: 718.6015s\n",
      "\titers: 600, epoch: 5 | loss: 0.0817848\n",
      "\tspeed: 0.0516s/iter; left time: 715.7869s\n",
      "\titers: 700, epoch: 5 | loss: 0.0782104\n",
      "\tspeed: 0.0507s/iter; left time: 697.8374s\n",
      "\titers: 800, epoch: 5 | loss: 0.0815488\n",
      "\tspeed: 0.0509s/iter; left time: 696.1949s\n",
      "\titers: 900, epoch: 5 | loss: 0.0798884\n",
      "\tspeed: 0.0510s/iter; left time: 691.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.53s\n",
      "Steps: 904 | Train Loss: 0.0794317 Vali Loss: 0.0809435 Test Loss: 0.0928860\n",
      "Validation loss decreased (0.082208 --> 0.080944).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0826950\n",
      "\tspeed: 0.1363s/iter; left time: 1834.1771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800711\n",
      "\tspeed: 0.0511s/iter; left time: 682.2562s\n",
      "\titers: 300, epoch: 6 | loss: 0.0783440\n",
      "\tspeed: 0.0526s/iter; left time: 697.7276s\n",
      "\titers: 400, epoch: 6 | loss: 0.0761599\n",
      "\tspeed: 0.0518s/iter; left time: 682.3269s\n",
      "\titers: 500, epoch: 6 | loss: 0.0720684\n",
      "\tspeed: 0.0513s/iter; left time: 670.1307s\n",
      "\titers: 600, epoch: 6 | loss: 0.0718406\n",
      "\tspeed: 0.0518s/iter; left time: 671.1483s\n",
      "\titers: 700, epoch: 6 | loss: 0.0753348\n",
      "\tspeed: 0.0516s/iter; left time: 663.7398s\n",
      "\titers: 800, epoch: 6 | loss: 0.0779216\n",
      "\tspeed: 0.0518s/iter; left time: 660.4063s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721837\n",
      "\tspeed: 0.0520s/iter; left time: 658.6227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.07s\n",
      "Steps: 904 | Train Loss: 0.0759032 Vali Loss: 0.0800776 Test Loss: 0.0901867\n",
      "Validation loss decreased (0.080944 --> 0.080078).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718432\n",
      "\tspeed: 0.1356s/iter; left time: 1702.2105s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773734\n",
      "\tspeed: 0.0518s/iter; left time: 645.6036s\n",
      "\titers: 300, epoch: 7 | loss: 0.0754037\n",
      "\tspeed: 0.0519s/iter; left time: 640.9338s\n",
      "\titers: 400, epoch: 7 | loss: 0.0701126\n",
      "\tspeed: 0.0514s/iter; left time: 630.1589s\n",
      "\titers: 500, epoch: 7 | loss: 0.0724805\n",
      "\tspeed: 0.0519s/iter; left time: 631.1501s\n",
      "\titers: 600, epoch: 7 | loss: 0.0637182\n",
      "\tspeed: 0.0429s/iter; left time: 517.6763s\n",
      "\titers: 700, epoch: 7 | loss: 0.0746906\n",
      "\tspeed: 0.0515s/iter; left time: 615.2225s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649625\n",
      "\tspeed: 0.0523s/iter; left time: 619.7528s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737293\n",
      "\tspeed: 0.0520s/iter; left time: 611.3888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.32s\n",
      "Steps: 904 | Train Loss: 0.0727564 Vali Loss: 0.0798132 Test Loss: 0.0905188\n",
      "Validation loss decreased (0.080078 --> 0.079813).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0764455\n",
      "\tspeed: 0.1345s/iter; left time: 1566.7566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762972\n",
      "\tspeed: 0.0518s/iter; left time: 598.1163s\n",
      "\titers: 300, epoch: 8 | loss: 0.0672638\n",
      "\tspeed: 0.0523s/iter; left time: 599.2583s\n",
      "\titers: 400, epoch: 8 | loss: 0.0701525\n",
      "\tspeed: 0.0523s/iter; left time: 593.7732s\n",
      "\titers: 500, epoch: 8 | loss: 0.0662000\n",
      "\tspeed: 0.0518s/iter; left time: 583.1192s\n",
      "\titers: 600, epoch: 8 | loss: 0.0694611\n",
      "\tspeed: 0.0517s/iter; left time: 576.2167s\n",
      "\titers: 700, epoch: 8 | loss: 0.0673127\n",
      "\tspeed: 0.0512s/iter; left time: 565.6331s\n",
      "\titers: 800, epoch: 8 | loss: 0.0704161\n",
      "\tspeed: 0.0514s/iter; left time: 562.6129s\n",
      "\titers: 900, epoch: 8 | loss: 0.0656521\n",
      "\tspeed: 0.0520s/iter; left time: 564.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 904 | Train Loss: 0.0696523 Vali Loss: 0.0797702 Test Loss: 0.0920613\n",
      "Validation loss decreased (0.079813 --> 0.079770).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0708809\n",
      "\tspeed: 0.1356s/iter; left time: 1457.7393s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683321\n",
      "\tspeed: 0.0502s/iter; left time: 534.9658s\n",
      "\titers: 300, epoch: 9 | loss: 0.0658918\n",
      "\tspeed: 0.0506s/iter; left time: 533.4506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0622855\n",
      "\tspeed: 0.0513s/iter; left time: 535.9716s\n",
      "\titers: 500, epoch: 9 | loss: 0.0712728\n",
      "\tspeed: 0.0511s/iter; left time: 529.0159s\n",
      "\titers: 600, epoch: 9 | loss: 0.0650618\n",
      "\tspeed: 0.0516s/iter; left time: 529.2829s\n",
      "\titers: 700, epoch: 9 | loss: 0.0621875\n",
      "\tspeed: 0.0516s/iter; left time: 523.5251s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671298\n",
      "\tspeed: 0.0508s/iter; left time: 510.2567s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658551\n",
      "\tspeed: 0.0521s/iter; left time: 517.8696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.56s\n",
      "Steps: 904 | Train Loss: 0.0671600 Vali Loss: 0.0818805 Test Loss: 0.0926254\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747117\n",
      "\tspeed: 0.1276s/iter; left time: 1255.7397s\n",
      "\titers: 200, epoch: 10 | loss: 0.0629282\n",
      "\tspeed: 0.0505s/iter; left time: 492.0581s\n",
      "\titers: 300, epoch: 10 | loss: 0.0615253\n",
      "\tspeed: 0.0502s/iter; left time: 484.5621s\n",
      "\titers: 400, epoch: 10 | loss: 0.0587503\n",
      "\tspeed: 0.0503s/iter; left time: 480.2918s\n",
      "\titers: 500, epoch: 10 | loss: 0.0707426\n",
      "\tspeed: 0.0507s/iter; left time: 478.8487s\n",
      "\titers: 600, epoch: 10 | loss: 0.0628930\n",
      "\tspeed: 0.0503s/iter; left time: 469.8034s\n",
      "\titers: 700, epoch: 10 | loss: 0.0636662\n",
      "\tspeed: 0.0508s/iter; left time: 469.9010s\n",
      "\titers: 800, epoch: 10 | loss: 0.0666468\n",
      "\tspeed: 0.0510s/iter; left time: 466.1574s\n",
      "\titers: 900, epoch: 10 | loss: 0.0652690\n",
      "\tspeed: 0.0506s/iter; left time: 457.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 904 | Train Loss: 0.0645158 Vali Loss: 0.0811130 Test Loss: 0.0931069\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0621498\n",
      "\tspeed: 0.1293s/iter; left time: 1156.0421s\n",
      "\titers: 200, epoch: 11 | loss: 0.0671997\n",
      "\tspeed: 0.0508s/iter; left time: 449.2967s\n",
      "\titers: 300, epoch: 11 | loss: 0.0566427\n",
      "\tspeed: 0.0511s/iter; left time: 446.7690s\n",
      "\titers: 400, epoch: 11 | loss: 0.0663417\n",
      "\tspeed: 0.0419s/iter; left time: 362.4651s\n",
      "\titers: 500, epoch: 11 | loss: 0.0570788\n",
      "\tspeed: 0.0407s/iter; left time: 347.8551s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601416\n",
      "\tspeed: 0.0515s/iter; left time: 434.6945s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623477\n",
      "\tspeed: 0.0517s/iter; left time: 430.8542s\n",
      "\titers: 800, epoch: 11 | loss: 0.0638136\n",
      "\tspeed: 0.0515s/iter; left time: 424.6432s\n",
      "\titers: 900, epoch: 11 | loss: 0.0633517\n",
      "\tspeed: 0.0515s/iter; left time: 419.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:44.77s\n",
      "Steps: 904 | Train Loss: 0.0621482 Vali Loss: 0.0833270 Test Loss: 0.0941476\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0597172\n",
      "\tspeed: 0.1209s/iter; left time: 971.7136s\n",
      "\titers: 200, epoch: 12 | loss: 0.0604670\n",
      "\tspeed: 0.0507s/iter; left time: 402.7161s\n",
      "\titers: 300, epoch: 12 | loss: 0.0571212\n",
      "\tspeed: 0.0506s/iter; left time: 396.2428s\n",
      "\titers: 400, epoch: 12 | loss: 0.0534001\n",
      "\tspeed: 0.0507s/iter; left time: 391.9751s\n",
      "\titers: 500, epoch: 12 | loss: 0.0627694\n",
      "\tspeed: 0.0508s/iter; left time: 388.0855s\n",
      "\titers: 600, epoch: 12 | loss: 0.0579445\n",
      "\tspeed: 0.0502s/iter; left time: 378.1049s\n",
      "\titers: 700, epoch: 12 | loss: 0.0641891\n",
      "\tspeed: 0.0497s/iter; left time: 369.2897s\n",
      "\titers: 800, epoch: 12 | loss: 0.0589688\n",
      "\tspeed: 0.0469s/iter; left time: 343.9118s\n",
      "\titers: 900, epoch: 12 | loss: 0.0612988\n",
      "\tspeed: 0.0417s/iter; left time: 302.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:44.01s\n",
      "Steps: 904 | Train Loss: 0.0602438 Vali Loss: 0.0849022 Test Loss: 0.0967499\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595376\n",
      "\tspeed: 0.1253s/iter; left time: 894.1169s\n",
      "\titers: 200, epoch: 13 | loss: 0.0561075\n",
      "\tspeed: 0.0405s/iter; left time: 284.5548s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545213\n",
      "\tspeed: 0.0463s/iter; left time: 320.6786s\n",
      "\titers: 400, epoch: 13 | loss: 0.0562269\n",
      "\tspeed: 0.0492s/iter; left time: 336.1617s\n",
      "\titers: 500, epoch: 13 | loss: 0.0604830\n",
      "\tspeed: 0.0500s/iter; left time: 336.9627s\n",
      "\titers: 600, epoch: 13 | loss: 0.0584102\n",
      "\tspeed: 0.0507s/iter; left time: 336.2902s\n",
      "\titers: 700, epoch: 13 | loss: 0.0524922\n",
      "\tspeed: 0.0505s/iter; left time: 330.0890s\n",
      "\titers: 800, epoch: 13 | loss: 0.0580739\n",
      "\tspeed: 0.0506s/iter; left time: 325.5880s\n",
      "\titers: 900, epoch: 13 | loss: 0.0583791\n",
      "\tspeed: 0.0494s/iter; left time: 312.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:44.18s\n",
      "Steps: 904 | Train Loss: 0.0583602 Vali Loss: 0.0844376 Test Loss: 0.0959828\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022557392716407776, rmse:0.15019118785858154, mae:0.09195020794868469, rse:0.5678890943527222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2311379\n",
      "\tspeed: 0.0546s/iter; left time: 981.7248s\n",
      "\titers: 200, epoch: 1 | loss: 0.2107387\n",
      "\tspeed: 0.0509s/iter; left time: 910.8108s\n",
      "\titers: 300, epoch: 1 | loss: 0.2088801\n",
      "\tspeed: 0.0511s/iter; left time: 908.0146s\n",
      "\titers: 400, epoch: 1 | loss: 0.2078077\n",
      "\tspeed: 0.0508s/iter; left time: 897.5353s\n",
      "\titers: 500, epoch: 1 | loss: 0.1975893\n",
      "\tspeed: 0.0509s/iter; left time: 894.0043s\n",
      "\titers: 600, epoch: 1 | loss: 0.1970696\n",
      "\tspeed: 0.0512s/iter; left time: 894.3397s\n",
      "\titers: 700, epoch: 1 | loss: 0.1888131\n",
      "\tspeed: 0.0510s/iter; left time: 887.1098s\n",
      "\titers: 800, epoch: 1 | loss: 0.1775232\n",
      "\tspeed: 0.0485s/iter; left time: 838.1275s\n",
      "\titers: 900, epoch: 1 | loss: 0.1805059\n",
      "\tspeed: 0.0495s/iter; left time: 849.6922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 904 | Train Loss: 0.2048719 Vali Loss: 0.1682425 Test Loss: 0.1862899\n",
      "Validation loss decreased (inf --> 0.168242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651758\n",
      "\tspeed: 0.1375s/iter; left time: 2347.3201s\n",
      "\titers: 200, epoch: 2 | loss: 0.1582526\n",
      "\tspeed: 0.0493s/iter; left time: 837.3827s\n",
      "\titers: 300, epoch: 2 | loss: 0.1334995\n",
      "\tspeed: 0.0504s/iter; left time: 851.4271s\n",
      "\titers: 400, epoch: 2 | loss: 0.1281435\n",
      "\tspeed: 0.0497s/iter; left time: 833.5652s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120991\n",
      "\tspeed: 0.0508s/iter; left time: 847.1016s\n",
      "\titers: 600, epoch: 2 | loss: 0.1063993\n",
      "\tspeed: 0.0502s/iter; left time: 832.0409s\n",
      "\titers: 700, epoch: 2 | loss: 0.1050140\n",
      "\tspeed: 0.0504s/iter; left time: 830.9362s\n",
      "\titers: 800, epoch: 2 | loss: 0.0939684\n",
      "\tspeed: 0.0507s/iter; left time: 829.6744s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027621\n",
      "\tspeed: 0.0506s/iter; left time: 823.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.1279720 Vali Loss: 0.0910116 Test Loss: 0.0978945\n",
      "Validation loss decreased (0.168242 --> 0.091012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874250\n",
      "\tspeed: 0.1345s/iter; left time: 2176.0240s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910681\n",
      "\tspeed: 0.0508s/iter; left time: 816.9962s\n",
      "\titers: 300, epoch: 3 | loss: 0.0960952\n",
      "\tspeed: 0.0507s/iter; left time: 810.2590s\n",
      "\titers: 400, epoch: 3 | loss: 0.1049342\n",
      "\tspeed: 0.0506s/iter; left time: 803.1317s\n",
      "\titers: 500, epoch: 3 | loss: 0.0909262\n",
      "\tspeed: 0.0509s/iter; left time: 802.7038s\n",
      "\titers: 600, epoch: 3 | loss: 0.0906060\n",
      "\tspeed: 0.0511s/iter; left time: 801.1169s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950601\n",
      "\tspeed: 0.0512s/iter; left time: 796.6056s\n",
      "\titers: 800, epoch: 3 | loss: 0.0871191\n",
      "\tspeed: 0.0504s/iter; left time: 780.2036s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931305\n",
      "\tspeed: 0.0502s/iter; left time: 772.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 904 | Train Loss: 0.0898878 Vali Loss: 0.0846631 Test Loss: 0.0933970\n",
      "Validation loss decreased (0.091012 --> 0.084663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790232\n",
      "\tspeed: 0.1300s/iter; left time: 1984.2621s\n",
      "\titers: 200, epoch: 4 | loss: 0.0902696\n",
      "\tspeed: 0.0507s/iter; left time: 768.3812s\n",
      "\titers: 300, epoch: 4 | loss: 0.0840954\n",
      "\tspeed: 0.0512s/iter; left time: 772.0275s\n",
      "\titers: 400, epoch: 4 | loss: 0.0806407\n",
      "\tspeed: 0.0505s/iter; left time: 755.6915s\n",
      "\titers: 500, epoch: 4 | loss: 0.0832484\n",
      "\tspeed: 0.0508s/iter; left time: 754.7856s\n",
      "\titers: 600, epoch: 4 | loss: 0.0873472\n",
      "\tspeed: 0.0510s/iter; left time: 753.1995s\n",
      "\titers: 700, epoch: 4 | loss: 0.0760519\n",
      "\tspeed: 0.0504s/iter; left time: 739.0469s\n",
      "\titers: 800, epoch: 4 | loss: 0.0904471\n",
      "\tspeed: 0.0505s/iter; left time: 736.2101s\n",
      "\titers: 900, epoch: 4 | loss: 0.0777563\n",
      "\tspeed: 0.0506s/iter; left time: 731.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0834705 Vali Loss: 0.0841414 Test Loss: 0.0939747\n",
      "Validation loss decreased (0.084663 --> 0.084141).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765879\n",
      "\tspeed: 0.1395s/iter; left time: 2003.2269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0705418\n",
      "\tspeed: 0.0506s/iter; left time: 722.3502s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873328\n",
      "\tspeed: 0.0507s/iter; left time: 717.7206s\n",
      "\titers: 400, epoch: 5 | loss: 0.0743462\n",
      "\tspeed: 0.0507s/iter; left time: 713.3268s\n",
      "\titers: 500, epoch: 5 | loss: 0.0757773\n",
      "\tspeed: 0.0504s/iter; left time: 703.1470s\n",
      "\titers: 600, epoch: 5 | loss: 0.0745896\n",
      "\tspeed: 0.0512s/iter; left time: 709.6763s\n",
      "\titers: 700, epoch: 5 | loss: 0.0764779\n",
      "\tspeed: 0.0507s/iter; left time: 697.4324s\n",
      "\titers: 800, epoch: 5 | loss: 0.0801189\n",
      "\tspeed: 0.0510s/iter; left time: 697.1266s\n",
      "\titers: 900, epoch: 5 | loss: 0.0745504\n",
      "\tspeed: 0.0505s/iter; left time: 684.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 904 | Train Loss: 0.0786197 Vali Loss: 0.0797811 Test Loss: 0.0875647\n",
      "Validation loss decreased (0.084141 --> 0.079781).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734403\n",
      "\tspeed: 0.1299s/iter; left time: 1748.5187s\n",
      "\titers: 200, epoch: 6 | loss: 0.0697036\n",
      "\tspeed: 0.0509s/iter; left time: 680.2679s\n",
      "\titers: 300, epoch: 6 | loss: 0.0720066\n",
      "\tspeed: 0.0509s/iter; left time: 674.8543s\n",
      "\titers: 400, epoch: 6 | loss: 0.0713798\n",
      "\tspeed: 0.0506s/iter; left time: 666.0969s\n",
      "\titers: 500, epoch: 6 | loss: 0.0751987\n",
      "\tspeed: 0.0508s/iter; left time: 663.5413s\n",
      "\titers: 600, epoch: 6 | loss: 0.0796741\n",
      "\tspeed: 0.0507s/iter; left time: 656.8715s\n",
      "\titers: 700, epoch: 6 | loss: 0.0704738\n",
      "\tspeed: 0.0505s/iter; left time: 649.4056s\n",
      "\titers: 800, epoch: 6 | loss: 0.0697082\n",
      "\tspeed: 0.0505s/iter; left time: 644.1371s\n",
      "\titers: 900, epoch: 6 | loss: 0.0710281\n",
      "\tspeed: 0.0509s/iter; left time: 644.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 904 | Train Loss: 0.0752827 Vali Loss: 0.0798891 Test Loss: 0.0936438\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0728502\n",
      "\tspeed: 0.1271s/iter; left time: 1596.0199s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820544\n",
      "\tspeed: 0.0508s/iter; left time: 633.1571s\n",
      "\titers: 300, epoch: 7 | loss: 0.0752040\n",
      "\tspeed: 0.0507s/iter; left time: 627.0224s\n",
      "\titers: 400, epoch: 7 | loss: 0.0719560\n",
      "\tspeed: 0.0508s/iter; left time: 622.9942s\n",
      "\titers: 500, epoch: 7 | loss: 0.0690600\n",
      "\tspeed: 0.0508s/iter; left time: 617.4039s\n",
      "\titers: 600, epoch: 7 | loss: 0.0686415\n",
      "\tspeed: 0.0514s/iter; left time: 620.3161s\n",
      "\titers: 700, epoch: 7 | loss: 0.0770732\n",
      "\tspeed: 0.0510s/iter; left time: 609.6197s\n",
      "\titers: 800, epoch: 7 | loss: 0.0647433\n",
      "\tspeed: 0.0510s/iter; left time: 604.5009s\n",
      "\titers: 900, epoch: 7 | loss: 0.0698012\n",
      "\tspeed: 0.0508s/iter; left time: 597.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 904 | Train Loss: 0.0721934 Vali Loss: 0.0802166 Test Loss: 0.0900334\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724484\n",
      "\tspeed: 0.1272s/iter; left time: 1482.3053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720747\n",
      "\tspeed: 0.0510s/iter; left time: 588.9821s\n",
      "\titers: 300, epoch: 8 | loss: 0.0671920\n",
      "\tspeed: 0.0514s/iter; left time: 588.5194s\n",
      "\titers: 400, epoch: 8 | loss: 0.0658102\n",
      "\tspeed: 0.0514s/iter; left time: 583.2008s\n",
      "\titers: 500, epoch: 8 | loss: 0.0691405\n",
      "\tspeed: 0.0512s/iter; left time: 576.1455s\n",
      "\titers: 600, epoch: 8 | loss: 0.0673880\n",
      "\tspeed: 0.0511s/iter; left time: 569.3840s\n",
      "\titers: 700, epoch: 8 | loss: 0.0676256\n",
      "\tspeed: 0.0508s/iter; left time: 561.2340s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773491\n",
      "\tspeed: 0.0502s/iter; left time: 549.6558s\n",
      "\titers: 900, epoch: 8 | loss: 0.0705851\n",
      "\tspeed: 0.0511s/iter; left time: 554.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.42s\n",
      "Steps: 904 | Train Loss: 0.0695177 Vali Loss: 0.0807144 Test Loss: 0.0903425\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667911\n",
      "\tspeed: 0.1272s/iter; left time: 1367.4071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0619899\n",
      "\tspeed: 0.0508s/iter; left time: 541.3632s\n",
      "\titers: 300, epoch: 9 | loss: 0.0688059\n",
      "\tspeed: 0.0508s/iter; left time: 536.2018s\n",
      "\titers: 400, epoch: 9 | loss: 0.0649368\n",
      "\tspeed: 0.0512s/iter; left time: 535.1446s\n",
      "\titers: 500, epoch: 9 | loss: 0.0658120\n",
      "\tspeed: 0.0507s/iter; left time: 525.0996s\n",
      "\titers: 600, epoch: 9 | loss: 0.0716825\n",
      "\tspeed: 0.0511s/iter; left time: 523.9275s\n",
      "\titers: 700, epoch: 9 | loss: 0.0709795\n",
      "\tspeed: 0.0506s/iter; left time: 513.7640s\n",
      "\titers: 800, epoch: 9 | loss: 0.0706118\n",
      "\tspeed: 0.0509s/iter; left time: 511.0694s\n",
      "\titers: 900, epoch: 9 | loss: 0.0659611\n",
      "\tspeed: 0.0509s/iter; left time: 506.2774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.31s\n",
      "Steps: 904 | Train Loss: 0.0666192 Vali Loss: 0.0834932 Test Loss: 0.0930626\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0744382\n",
      "\tspeed: 0.1273s/iter; left time: 1253.5433s\n",
      "\titers: 200, epoch: 10 | loss: 0.0630922\n",
      "\tspeed: 0.0510s/iter; left time: 497.1416s\n",
      "\titers: 300, epoch: 10 | loss: 0.0629388\n",
      "\tspeed: 0.0512s/iter; left time: 493.8345s\n",
      "\titers: 400, epoch: 10 | loss: 0.0620162\n",
      "\tspeed: 0.0508s/iter; left time: 484.9797s\n",
      "\titers: 500, epoch: 10 | loss: 0.0673733\n",
      "\tspeed: 0.0507s/iter; left time: 478.4284s\n",
      "\titers: 600, epoch: 10 | loss: 0.0673278\n",
      "\tspeed: 0.0502s/iter; left time: 468.7234s\n",
      "\titers: 700, epoch: 10 | loss: 0.0655921\n",
      "\tspeed: 0.0507s/iter; left time: 469.1414s\n",
      "\titers: 800, epoch: 10 | loss: 0.0597681\n",
      "\tspeed: 0.0508s/iter; left time: 464.1896s\n",
      "\titers: 900, epoch: 10 | loss: 0.0618950\n",
      "\tspeed: 0.0511s/iter; left time: 462.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 904 | Train Loss: 0.0642936 Vali Loss: 0.0834238 Test Loss: 0.0920974\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01962193101644516, rmse:0.14007830619812012, mae:0.08756327629089355, rse:0.5296511650085449\n",
      "Intermediate time for IT and pred_len 96: 00h:20m:55.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2406804\n",
      "\tspeed: 0.0817s/iter; left time: 1466.4552s\n",
      "\titers: 200, epoch: 1 | loss: 0.2127664\n",
      "\tspeed: 0.0526s/iter; left time: 938.9026s\n",
      "\titers: 300, epoch: 1 | loss: 0.2112524\n",
      "\tspeed: 0.0553s/iter; left time: 980.2543s\n",
      "\titers: 400, epoch: 1 | loss: 0.2002598\n",
      "\tspeed: 0.0530s/iter; left time: 934.7168s\n",
      "\titers: 500, epoch: 1 | loss: 0.2001060\n",
      "\tspeed: 0.0555s/iter; left time: 973.0592s\n",
      "\titers: 600, epoch: 1 | loss: 0.1987666\n",
      "\tspeed: 0.0551s/iter; left time: 961.5511s\n",
      "\titers: 700, epoch: 1 | loss: 0.1934598\n",
      "\tspeed: 0.0514s/iter; left time: 890.5093s\n",
      "\titers: 800, epoch: 1 | loss: 0.1944774\n",
      "\tspeed: 0.0507s/iter; left time: 874.6885s\n",
      "\titers: 900, epoch: 1 | loss: 0.1917253\n",
      "\tspeed: 0.0575s/iter; left time: 986.1786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.51s\n",
      "Steps: 902 | Train Loss: 0.2068505 Vali Loss: 0.1744625 Test Loss: 0.1911217\n",
      "Validation loss decreased (inf --> 0.174462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1737314\n",
      "\tspeed: 0.1531s/iter; left time: 2608.8091s\n",
      "\titers: 200, epoch: 2 | loss: 0.1589169\n",
      "\tspeed: 0.0549s/iter; left time: 930.0960s\n",
      "\titers: 300, epoch: 2 | loss: 0.1499351\n",
      "\tspeed: 0.0539s/iter; left time: 907.9172s\n",
      "\titers: 400, epoch: 2 | loss: 0.1438678\n",
      "\tspeed: 0.0514s/iter; left time: 859.6686s\n",
      "\titers: 500, epoch: 2 | loss: 0.1360246\n",
      "\tspeed: 0.0531s/iter; left time: 884.3623s\n",
      "\titers: 600, epoch: 2 | loss: 0.1343525\n",
      "\tspeed: 0.0524s/iter; left time: 866.9065s\n",
      "\titers: 700, epoch: 2 | loss: 0.1210604\n",
      "\tspeed: 0.0551s/iter; left time: 905.8356s\n",
      "\titers: 800, epoch: 2 | loss: 0.1088701\n",
      "\tspeed: 0.0542s/iter; left time: 885.7647s\n",
      "\titers: 900, epoch: 2 | loss: 0.1029986\n",
      "\tspeed: 0.0538s/iter; left time: 874.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.44s\n",
      "Steps: 902 | Train Loss: 0.1416033 Vali Loss: 0.1001055 Test Loss: 0.1089795\n",
      "Validation loss decreased (0.174462 --> 0.100105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053182\n",
      "\tspeed: 0.1566s/iter; left time: 2526.5100s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986656\n",
      "\tspeed: 0.0557s/iter; left time: 893.6372s\n",
      "\titers: 300, epoch: 3 | loss: 0.0984584\n",
      "\tspeed: 0.0541s/iter; left time: 862.0154s\n",
      "\titers: 400, epoch: 3 | loss: 0.0897405\n",
      "\tspeed: 0.0534s/iter; left time: 846.0256s\n",
      "\titers: 500, epoch: 3 | loss: 0.0952346\n",
      "\tspeed: 0.0555s/iter; left time: 873.6718s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963142\n",
      "\tspeed: 0.0544s/iter; left time: 851.3430s\n",
      "\titers: 700, epoch: 3 | loss: 0.0938548\n",
      "\tspeed: 0.0558s/iter; left time: 866.6090s\n",
      "\titers: 800, epoch: 3 | loss: 0.0881569\n",
      "\tspeed: 0.0536s/iter; left time: 827.9615s\n",
      "\titers: 900, epoch: 3 | loss: 0.0945525\n",
      "\tspeed: 0.0533s/iter; left time: 817.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.64s\n",
      "Steps: 902 | Train Loss: 0.0963866 Vali Loss: 0.0898182 Test Loss: 0.0998336\n",
      "Validation loss decreased (0.100105 --> 0.089818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0923409\n",
      "\tspeed: 0.1560s/iter; left time: 2375.9268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0874340\n",
      "\tspeed: 0.0516s/iter; left time: 781.4488s\n",
      "\titers: 300, epoch: 4 | loss: 0.0880191\n",
      "\tspeed: 0.0558s/iter; left time: 838.4748s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910763\n",
      "\tspeed: 0.0547s/iter; left time: 816.7020s\n",
      "\titers: 500, epoch: 4 | loss: 0.0871311\n",
      "\tspeed: 0.0556s/iter; left time: 825.3986s\n",
      "\titers: 600, epoch: 4 | loss: 0.0879892\n",
      "\tspeed: 0.0542s/iter; left time: 798.7329s\n",
      "\titers: 700, epoch: 4 | loss: 0.0853011\n",
      "\tspeed: 0.0548s/iter; left time: 802.0985s\n",
      "\titers: 800, epoch: 4 | loss: 0.0927186\n",
      "\tspeed: 0.0535s/iter; left time: 778.1233s\n",
      "\titers: 900, epoch: 4 | loss: 0.0857175\n",
      "\tspeed: 0.0561s/iter; left time: 810.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.63s\n",
      "Steps: 902 | Train Loss: 0.0889699 Vali Loss: 0.0872253 Test Loss: 0.0956871\n",
      "Validation loss decreased (0.089818 --> 0.087225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871143\n",
      "\tspeed: 0.1543s/iter; left time: 2211.2691s\n",
      "\titers: 200, epoch: 5 | loss: 0.0825435\n",
      "\tspeed: 0.0561s/iter; left time: 798.1456s\n",
      "\titers: 300, epoch: 5 | loss: 0.0854570\n",
      "\tspeed: 0.0548s/iter; left time: 774.9912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0884355\n",
      "\tspeed: 0.0553s/iter; left time: 776.3258s\n",
      "\titers: 500, epoch: 5 | loss: 0.0823852\n",
      "\tspeed: 0.0532s/iter; left time: 741.8953s\n",
      "\titers: 600, epoch: 5 | loss: 0.0858922\n",
      "\tspeed: 0.0570s/iter; left time: 788.3054s\n",
      "\titers: 700, epoch: 5 | loss: 0.0828293\n",
      "\tspeed: 0.0539s/iter; left time: 740.3683s\n",
      "\titers: 800, epoch: 5 | loss: 0.0816355\n",
      "\tspeed: 0.0548s/iter; left time: 746.9673s\n",
      "\titers: 900, epoch: 5 | loss: 0.0854966\n",
      "\tspeed: 0.0541s/iter; left time: 732.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.77s\n",
      "Steps: 902 | Train Loss: 0.0841458 Vali Loss: 0.0860987 Test Loss: 0.0951558\n",
      "Validation loss decreased (0.087225 --> 0.086099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0852132\n",
      "\tspeed: 0.1585s/iter; left time: 2129.1258s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888999\n",
      "\tspeed: 0.0537s/iter; left time: 715.7748s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834618\n",
      "\tspeed: 0.0535s/iter; left time: 708.3328s\n",
      "\titers: 400, epoch: 6 | loss: 0.0814066\n",
      "\tspeed: 0.0537s/iter; left time: 705.3339s\n",
      "\titers: 500, epoch: 6 | loss: 0.0789409\n",
      "\tspeed: 0.0542s/iter; left time: 706.3558s\n",
      "\titers: 600, epoch: 6 | loss: 0.0791459\n",
      "\tspeed: 0.0557s/iter; left time: 720.5780s\n",
      "\titers: 700, epoch: 6 | loss: 0.0796230\n",
      "\tspeed: 0.0511s/iter; left time: 656.2595s\n",
      "\titers: 800, epoch: 6 | loss: 0.0840694\n",
      "\tspeed: 0.0539s/iter; left time: 686.6397s\n",
      "\titers: 900, epoch: 6 | loss: 0.0776450\n",
      "\tspeed: 0.0566s/iter; left time: 714.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.47s\n",
      "Steps: 902 | Train Loss: 0.0804640 Vali Loss: 0.0859904 Test Loss: 0.0942083\n",
      "Validation loss decreased (0.086099 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0850125\n",
      "\tspeed: 0.1578s/iter; left time: 1977.6337s\n",
      "\titers: 200, epoch: 7 | loss: 0.0780817\n",
      "\tspeed: 0.0527s/iter; left time: 654.6849s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797425\n",
      "\tspeed: 0.0543s/iter; left time: 669.0924s\n",
      "\titers: 400, epoch: 7 | loss: 0.0827978\n",
      "\tspeed: 0.0556s/iter; left time: 680.1023s\n",
      "\titers: 500, epoch: 7 | loss: 0.0696051\n",
      "\tspeed: 0.0547s/iter; left time: 663.6758s\n",
      "\titers: 600, epoch: 7 | loss: 0.0784860\n",
      "\tspeed: 0.0541s/iter; left time: 650.9320s\n",
      "\titers: 700, epoch: 7 | loss: 0.0744822\n",
      "\tspeed: 0.0533s/iter; left time: 635.3568s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776769\n",
      "\tspeed: 0.0540s/iter; left time: 638.4604s\n",
      "\titers: 900, epoch: 7 | loss: 0.0753103\n",
      "\tspeed: 0.0535s/iter; left time: 627.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.11s\n",
      "Steps: 902 | Train Loss: 0.0767612 Vali Loss: 0.0869188 Test Loss: 0.0973250\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0760540\n",
      "\tspeed: 0.1513s/iter; left time: 1759.4278s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714573\n",
      "\tspeed: 0.0550s/iter; left time: 633.9818s\n",
      "\titers: 300, epoch: 8 | loss: 0.0771488\n",
      "\tspeed: 0.0542s/iter; left time: 619.4444s\n",
      "\titers: 400, epoch: 8 | loss: 0.0733557\n",
      "\tspeed: 0.0535s/iter; left time: 605.5521s\n",
      "\titers: 500, epoch: 8 | loss: 0.0753683\n",
      "\tspeed: 0.0549s/iter; left time: 616.2810s\n",
      "\titers: 600, epoch: 8 | loss: 0.0709704\n",
      "\tspeed: 0.0549s/iter; left time: 610.9294s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778525\n",
      "\tspeed: 0.0536s/iter; left time: 590.6503s\n",
      "\titers: 800, epoch: 8 | loss: 0.0728218\n",
      "\tspeed: 0.0539s/iter; left time: 589.2615s\n",
      "\titers: 900, epoch: 8 | loss: 0.0678858\n",
      "\tspeed: 0.0553s/iter; left time: 598.5270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.17s\n",
      "Steps: 902 | Train Loss: 0.0731265 Vali Loss: 0.0867562 Test Loss: 0.0984258\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0668934\n",
      "\tspeed: 0.1501s/iter; left time: 1610.2491s\n",
      "\titers: 200, epoch: 9 | loss: 0.0693415\n",
      "\tspeed: 0.0529s/iter; left time: 561.7101s\n",
      "\titers: 300, epoch: 9 | loss: 0.0720601\n",
      "\tspeed: 0.0552s/iter; left time: 581.3386s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665089\n",
      "\tspeed: 0.0568s/iter; left time: 591.7464s\n",
      "\titers: 500, epoch: 9 | loss: 0.0702857\n",
      "\tspeed: 0.0554s/iter; left time: 571.5155s\n",
      "\titers: 600, epoch: 9 | loss: 0.0722413\n",
      "\tspeed: 0.0547s/iter; left time: 558.9576s\n",
      "\titers: 700, epoch: 9 | loss: 0.0672538\n",
      "\tspeed: 0.0557s/iter; left time: 563.7864s\n",
      "\titers: 800, epoch: 9 | loss: 0.0681854\n",
      "\tspeed: 0.0561s/iter; left time: 562.3897s\n",
      "\titers: 900, epoch: 9 | loss: 0.0679674\n",
      "\tspeed: 0.0543s/iter; left time: 538.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.91s\n",
      "Steps: 902 | Train Loss: 0.0695120 Vali Loss: 0.0878431 Test Loss: 0.0970462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669751\n",
      "\tspeed: 0.1569s/iter; left time: 1541.1966s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686549\n",
      "\tspeed: 0.0549s/iter; left time: 533.9789s\n",
      "\titers: 300, epoch: 10 | loss: 0.0665885\n",
      "\tspeed: 0.0558s/iter; left time: 536.5697s\n",
      "\titers: 400, epoch: 10 | loss: 0.0687989\n",
      "\tspeed: 0.0546s/iter; left time: 519.6203s\n",
      "\titers: 500, epoch: 10 | loss: 0.0638649\n",
      "\tspeed: 0.0546s/iter; left time: 514.3068s\n",
      "\titers: 600, epoch: 10 | loss: 0.0652834\n",
      "\tspeed: 0.0588s/iter; left time: 548.0039s\n",
      "\titers: 700, epoch: 10 | loss: 0.0634052\n",
      "\tspeed: 0.0558s/iter; left time: 514.4173s\n",
      "\titers: 800, epoch: 10 | loss: 0.0706556\n",
      "\tspeed: 0.0543s/iter; left time: 495.7766s\n",
      "\titers: 900, epoch: 10 | loss: 0.0622955\n",
      "\tspeed: 0.0545s/iter; left time: 491.9339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.27s\n",
      "Steps: 902 | Train Loss: 0.0662096 Vali Loss: 0.0881258 Test Loss: 0.0997533\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642025\n",
      "\tspeed: 0.1530s/iter; left time: 1364.8534s\n",
      "\titers: 200, epoch: 11 | loss: 0.0620056\n",
      "\tspeed: 0.0575s/iter; left time: 507.0875s\n",
      "\titers: 300, epoch: 11 | loss: 0.0635489\n",
      "\tspeed: 0.0551s/iter; left time: 480.7605s\n",
      "\titers: 400, epoch: 11 | loss: 0.0652145\n",
      "\tspeed: 0.0548s/iter; left time: 472.3013s\n",
      "\titers: 500, epoch: 11 | loss: 0.0608407\n",
      "\tspeed: 0.0540s/iter; left time: 459.8280s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624363\n",
      "\tspeed: 0.0554s/iter; left time: 466.5403s\n",
      "\titers: 700, epoch: 11 | loss: 0.0605113\n",
      "\tspeed: 0.0556s/iter; left time: 462.3131s\n",
      "\titers: 800, epoch: 11 | loss: 0.0605089\n",
      "\tspeed: 0.0525s/iter; left time: 431.7932s\n",
      "\titers: 900, epoch: 11 | loss: 0.0593132\n",
      "\tspeed: 0.0587s/iter; left time: 476.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.29s\n",
      "Steps: 902 | Train Loss: 0.0631221 Vali Loss: 0.0902975 Test Loss: 0.0980740\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02240457385778427, rmse:0.14968156814575195, mae:0.09415119886398315, rse:0.5663532018661499\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2267673\n",
      "\tspeed: 0.0583s/iter; left time: 1045.9809s\n",
      "\titers: 200, epoch: 1 | loss: 0.2210553\n",
      "\tspeed: 0.0550s/iter; left time: 980.5110s\n",
      "\titers: 300, epoch: 1 | loss: 0.2116144\n",
      "\tspeed: 0.0556s/iter; left time: 986.0592s\n",
      "\titers: 400, epoch: 1 | loss: 0.2097916\n",
      "\tspeed: 0.0557s/iter; left time: 982.4223s\n",
      "\titers: 500, epoch: 1 | loss: 0.1997766\n",
      "\tspeed: 0.0551s/iter; left time: 967.0799s\n",
      "\titers: 600, epoch: 1 | loss: 0.1958111\n",
      "\tspeed: 0.0559s/iter; left time: 974.1841s\n",
      "\titers: 700, epoch: 1 | loss: 0.1964175\n",
      "\tspeed: 0.0568s/iter; left time: 984.5643s\n",
      "\titers: 800, epoch: 1 | loss: 0.1797141\n",
      "\tspeed: 0.0559s/iter; left time: 962.9982s\n",
      "\titers: 900, epoch: 1 | loss: 0.1917520\n",
      "\tspeed: 0.0550s/iter; left time: 943.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.51s\n",
      "Steps: 902 | Train Loss: 0.2058786 Vali Loss: 0.1700873 Test Loss: 0.1877915\n",
      "Validation loss decreased (inf --> 0.170087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1742273\n",
      "\tspeed: 0.1688s/iter; left time: 2876.9281s\n",
      "\titers: 200, epoch: 2 | loss: 0.1734163\n",
      "\tspeed: 0.0570s/iter; left time: 965.2957s\n",
      "\titers: 300, epoch: 2 | loss: 0.1682757\n",
      "\tspeed: 0.0567s/iter; left time: 954.7038s\n",
      "\titers: 400, epoch: 2 | loss: 0.1633339\n",
      "\tspeed: 0.0580s/iter; left time: 971.3836s\n",
      "\titers: 500, epoch: 2 | loss: 0.1598000\n",
      "\tspeed: 0.0570s/iter; left time: 948.1086s\n",
      "\titers: 600, epoch: 2 | loss: 0.1490487\n",
      "\tspeed: 0.0556s/iter; left time: 919.7467s\n",
      "\titers: 700, epoch: 2 | loss: 0.1348605\n",
      "\tspeed: 0.0615s/iter; left time: 1010.6949s\n",
      "\titers: 800, epoch: 2 | loss: 0.1170168\n",
      "\tspeed: 0.0601s/iter; left time: 982.5901s\n",
      "\titers: 900, epoch: 2 | loss: 0.1081366\n",
      "\tspeed: 0.0569s/iter; left time: 923.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:52.47s\n",
      "Steps: 902 | Train Loss: 0.1525863 Vali Loss: 0.1007635 Test Loss: 0.1088220\n",
      "Validation loss decreased (0.170087 --> 0.100763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1067860\n",
      "\tspeed: 0.1679s/iter; left time: 2709.6611s\n",
      "\titers: 200, epoch: 3 | loss: 0.1000163\n",
      "\tspeed: 0.0568s/iter; left time: 910.7521s\n",
      "\titers: 300, epoch: 3 | loss: 0.0990415\n",
      "\tspeed: 0.0554s/iter; left time: 883.6522s\n",
      "\titers: 400, epoch: 3 | loss: 0.1030617\n",
      "\tspeed: 0.0540s/iter; left time: 855.8820s\n",
      "\titers: 500, epoch: 3 | loss: 0.0993092\n",
      "\tspeed: 0.0666s/iter; left time: 1047.7999s\n",
      "\titers: 600, epoch: 3 | loss: 0.0939378\n",
      "\tspeed: 0.0559s/iter; left time: 874.0815s\n",
      "\titers: 700, epoch: 3 | loss: 0.0941445\n",
      "\tspeed: 0.0564s/iter; left time: 876.9514s\n",
      "\titers: 800, epoch: 3 | loss: 0.0921857\n",
      "\tspeed: 0.0558s/iter; left time: 860.7323s\n",
      "\titers: 900, epoch: 3 | loss: 0.0946364\n",
      "\tspeed: 0.0561s/iter; left time: 860.7192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.88s\n",
      "Steps: 902 | Train Loss: 0.0968587 Vali Loss: 0.0869811 Test Loss: 0.0956921\n",
      "Validation loss decreased (0.100763 --> 0.086981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0898372\n",
      "\tspeed: 0.1603s/iter; left time: 2442.8469s\n",
      "\titers: 200, epoch: 4 | loss: 0.0991435\n",
      "\tspeed: 0.0600s/iter; left time: 908.3866s\n",
      "\titers: 300, epoch: 4 | loss: 0.0840835\n",
      "\tspeed: 0.0570s/iter; left time: 857.6776s\n",
      "\titers: 400, epoch: 4 | loss: 0.0929531\n",
      "\tspeed: 0.0567s/iter; left time: 847.3360s\n",
      "\titers: 500, epoch: 4 | loss: 0.0892102\n",
      "\tspeed: 0.0589s/iter; left time: 873.8471s\n",
      "\titers: 600, epoch: 4 | loss: 0.0850115\n",
      "\tspeed: 0.0579s/iter; left time: 852.8185s\n",
      "\titers: 700, epoch: 4 | loss: 0.0912520\n",
      "\tspeed: 0.0579s/iter; left time: 847.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.0880117\n",
      "\tspeed: 0.0586s/iter; left time: 851.4412s\n",
      "\titers: 900, epoch: 4 | loss: 0.0846420\n",
      "\tspeed: 0.0597s/iter; left time: 862.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 902 | Train Loss: 0.0884787 Vali Loss: 0.0848812 Test Loss: 0.0973621\n",
      "Validation loss decreased (0.086981 --> 0.084881).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0810058\n",
      "\tspeed: 0.1752s/iter; left time: 2510.9140s\n",
      "\titers: 200, epoch: 5 | loss: 0.0882122\n",
      "\tspeed: 0.0558s/iter; left time: 793.5904s\n",
      "\titers: 300, epoch: 5 | loss: 0.0831145\n",
      "\tspeed: 0.0617s/iter; left time: 872.6356s\n",
      "\titers: 400, epoch: 5 | loss: 0.0829300\n",
      "\tspeed: 0.0590s/iter; left time: 827.8140s\n",
      "\titers: 500, epoch: 5 | loss: 0.0805245\n",
      "\tspeed: 0.0577s/iter; left time: 803.3644s\n",
      "\titers: 600, epoch: 5 | loss: 0.0844140\n",
      "\tspeed: 0.0566s/iter; left time: 783.0987s\n",
      "\titers: 700, epoch: 5 | loss: 0.0788835\n",
      "\tspeed: 0.0549s/iter; left time: 753.8863s\n",
      "\titers: 800, epoch: 5 | loss: 0.0826269\n",
      "\tspeed: 0.0625s/iter; left time: 851.4778s\n",
      "\titers: 900, epoch: 5 | loss: 0.0806869\n",
      "\tspeed: 0.0567s/iter; left time: 767.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:52.90s\n",
      "Steps: 902 | Train Loss: 0.0836713 Vali Loss: 0.0863794 Test Loss: 0.0963056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0811056\n",
      "\tspeed: 0.1616s/iter; left time: 2170.4834s\n",
      "\titers: 200, epoch: 6 | loss: 0.0835971\n",
      "\tspeed: 0.0552s/iter; left time: 736.3368s\n",
      "\titers: 300, epoch: 6 | loss: 0.0877080\n",
      "\tspeed: 0.0561s/iter; left time: 741.9850s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781132\n",
      "\tspeed: 0.0559s/iter; left time: 734.1611s\n",
      "\titers: 500, epoch: 6 | loss: 0.0830950\n",
      "\tspeed: 0.0504s/iter; left time: 656.7932s\n",
      "\titers: 600, epoch: 6 | loss: 0.0777409\n",
      "\tspeed: 0.0541s/iter; left time: 699.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.0786194\n",
      "\tspeed: 0.0597s/iter; left time: 766.0671s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790971\n",
      "\tspeed: 0.0533s/iter; left time: 678.1970s\n",
      "\titers: 900, epoch: 6 | loss: 0.0779720\n",
      "\tspeed: 0.0552s/iter; left time: 697.5122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.19s\n",
      "Steps: 902 | Train Loss: 0.0798447 Vali Loss: 0.0831233 Test Loss: 0.0931060\n",
      "Validation loss decreased (0.084881 --> 0.083123).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769085\n",
      "\tspeed: 0.1622s/iter; left time: 2032.7722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753283\n",
      "\tspeed: 0.0577s/iter; left time: 716.9315s\n",
      "\titers: 300, epoch: 7 | loss: 0.0888861\n",
      "\tspeed: 0.0562s/iter; left time: 692.8608s\n",
      "\titers: 400, epoch: 7 | loss: 0.0752653\n",
      "\tspeed: 0.0551s/iter; left time: 673.7293s\n",
      "\titers: 500, epoch: 7 | loss: 0.0852774\n",
      "\tspeed: 0.0562s/iter; left time: 681.6918s\n",
      "\titers: 600, epoch: 7 | loss: 0.0713650\n",
      "\tspeed: 0.0561s/iter; left time: 674.3091s\n",
      "\titers: 700, epoch: 7 | loss: 0.0733699\n",
      "\tspeed: 0.0551s/iter; left time: 657.5945s\n",
      "\titers: 800, epoch: 7 | loss: 0.0775007\n",
      "\tspeed: 0.0546s/iter; left time: 646.1685s\n",
      "\titers: 900, epoch: 7 | loss: 0.0741364\n",
      "\tspeed: 0.0596s/iter; left time: 698.5567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.28s\n",
      "Steps: 902 | Train Loss: 0.0764814 Vali Loss: 0.0855528 Test Loss: 0.0939845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789248\n",
      "\tspeed: 0.1542s/iter; left time: 1792.6305s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775377\n",
      "\tspeed: 0.0560s/iter; left time: 646.0597s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762293\n",
      "\tspeed: 0.0552s/iter; left time: 630.3400s\n",
      "\titers: 400, epoch: 8 | loss: 0.0747236\n",
      "\tspeed: 0.0546s/iter; left time: 618.3556s\n",
      "\titers: 500, epoch: 8 | loss: 0.0730445\n",
      "\tspeed: 0.0604s/iter; left time: 678.0439s\n",
      "\titers: 600, epoch: 8 | loss: 0.0738466\n",
      "\tspeed: 0.0559s/iter; left time: 621.7854s\n",
      "\titers: 700, epoch: 8 | loss: 0.0768590\n",
      "\tspeed: 0.0553s/iter; left time: 609.9158s\n",
      "\titers: 800, epoch: 8 | loss: 0.0759818\n",
      "\tspeed: 0.0561s/iter; left time: 612.5215s\n",
      "\titers: 900, epoch: 8 | loss: 0.0694436\n",
      "\tspeed: 0.0542s/iter; left time: 586.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.75s\n",
      "Steps: 902 | Train Loss: 0.0734237 Vali Loss: 0.0894040 Test Loss: 0.0991596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0683368\n",
      "\tspeed: 0.1553s/iter; left time: 1666.0632s\n",
      "\titers: 200, epoch: 9 | loss: 0.0713612\n",
      "\tspeed: 0.0561s/iter; left time: 596.3141s\n",
      "\titers: 300, epoch: 9 | loss: 0.0733693\n",
      "\tspeed: 0.0557s/iter; left time: 586.4202s\n",
      "\titers: 400, epoch: 9 | loss: 0.0686704\n",
      "\tspeed: 0.0563s/iter; left time: 586.7292s\n",
      "\titers: 500, epoch: 9 | loss: 0.0714800\n",
      "\tspeed: 0.0552s/iter; left time: 570.2415s\n",
      "\titers: 600, epoch: 9 | loss: 0.0691100\n",
      "\tspeed: 0.0573s/iter; left time: 586.2351s\n",
      "\titers: 700, epoch: 9 | loss: 0.0644889\n",
      "\tspeed: 0.0552s/iter; left time: 559.2290s\n",
      "\titers: 800, epoch: 9 | loss: 0.0633002\n",
      "\tspeed: 0.0602s/iter; left time: 603.5210s\n",
      "\titers: 900, epoch: 9 | loss: 0.0722990\n",
      "\tspeed: 0.0576s/iter; left time: 571.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:51.77s\n",
      "Steps: 902 | Train Loss: 0.0704051 Vali Loss: 0.0860073 Test Loss: 0.0975743\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682998\n",
      "\tspeed: 0.1545s/iter; left time: 1517.8492s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692387\n",
      "\tspeed: 0.0545s/iter; left time: 530.2173s\n",
      "\titers: 300, epoch: 10 | loss: 0.0657472\n",
      "\tspeed: 0.0551s/iter; left time: 529.9181s\n",
      "\titers: 400, epoch: 10 | loss: 0.0671159\n",
      "\tspeed: 0.0610s/iter; left time: 580.7138s\n",
      "\titers: 500, epoch: 10 | loss: 0.0671956\n",
      "\tspeed: 0.0555s/iter; left time: 522.5556s\n",
      "\titers: 600, epoch: 10 | loss: 0.0691979\n",
      "\tspeed: 0.0543s/iter; left time: 505.8060s\n",
      "\titers: 700, epoch: 10 | loss: 0.0719837\n",
      "\tspeed: 0.0556s/iter; left time: 512.7235s\n",
      "\titers: 800, epoch: 10 | loss: 0.0659146\n",
      "\tspeed: 0.0551s/iter; left time: 502.5871s\n",
      "\titers: 900, epoch: 10 | loss: 0.0624403\n",
      "\tspeed: 0.0553s/iter; left time: 499.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.56s\n",
      "Steps: 902 | Train Loss: 0.0673667 Vali Loss: 0.0881326 Test Loss: 0.0972519\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0659390\n",
      "\tspeed: 0.1599s/iter; left time: 1426.1146s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711790\n",
      "\tspeed: 0.0541s/iter; left time: 477.5863s\n",
      "\titers: 300, epoch: 11 | loss: 0.0636270\n",
      "\tspeed: 0.0564s/iter; left time: 491.4331s\n",
      "\titers: 400, epoch: 11 | loss: 0.0594921\n",
      "\tspeed: 0.0559s/iter; left time: 482.3355s\n",
      "\titers: 500, epoch: 11 | loss: 0.0676920\n",
      "\tspeed: 0.0546s/iter; left time: 465.1431s\n",
      "\titers: 600, epoch: 11 | loss: 0.0632904\n",
      "\tspeed: 0.0554s/iter; left time: 466.3358s\n",
      "\titers: 700, epoch: 11 | loss: 0.0643619\n",
      "\tspeed: 0.0544s/iter; left time: 452.7133s\n",
      "\titers: 800, epoch: 11 | loss: 0.0635986\n",
      "\tspeed: 0.0591s/iter; left time: 485.7729s\n",
      "\titers: 900, epoch: 11 | loss: 0.0704689\n",
      "\tspeed: 0.0558s/iter; left time: 453.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.82s\n",
      "Steps: 902 | Train Loss: 0.0645314 Vali Loss: 0.0900577 Test Loss: 0.0986329\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0215200986713171, rmse:0.1466972976922989, mae:0.09315669536590576, rse:0.5550615191459656\n",
      "Intermediate time for IT and pred_len 168: 00h:22m:28.46s\n",
      "Intermediate time for IT: 01h:08m:23.33s\n",
      "Total time: 05h:14m:11.86s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 168\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values.\n",
    "\n",
    "Again, we separated all look-back windows into different cells, to settle up training on remote servers. Here is first with look-back 168 time steps, the next will be 336 and finally 512. In the following 3 parts all arguments are the same except seq_lem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1494096\n",
      "\tspeed: 0.0331s/iter; left time: 744.9698s\n",
      "\titers: 200, epoch: 1 | loss: 0.1323591\n",
      "\tspeed: 0.0147s/iter; left time: 328.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.1472841 Vali Loss: 0.1347737 Test Loss: 0.1428933\n",
      "Validation loss decreased (inf --> 0.134774).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0845640\n",
      "\tspeed: 0.0317s/iter; left time: 707.1836s\n",
      "\titers: 200, epoch: 2 | loss: 0.0840180\n",
      "\tspeed: 0.0150s/iter; left time: 332.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0913177 Vali Loss: 0.0952576 Test Loss: 0.0964126\n",
      "Validation loss decreased (0.134774 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0810556\n",
      "\tspeed: 0.0328s/iter; left time: 722.6901s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814877\n",
      "\tspeed: 0.0148s/iter; left time: 324.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0810284 Vali Loss: 0.0909402 Test Loss: 0.0929232\n",
      "Validation loss decreased (0.095258 --> 0.090940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0829395\n",
      "\tspeed: 0.0319s/iter; left time: 695.7021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0787051\n",
      "\tspeed: 0.0149s/iter; left time: 323.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0783240 Vali Loss: 0.0893383 Test Loss: 0.0917443\n",
      "Validation loss decreased (0.090940 --> 0.089338).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827021\n",
      "\tspeed: 0.0338s/iter; left time: 729.2611s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717351\n",
      "\tspeed: 0.0164s/iter; left time: 353.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0768973 Vali Loss: 0.0892281 Test Loss: 0.0911057\n",
      "Validation loss decreased (0.089338 --> 0.089228).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0709572\n",
      "\tspeed: 0.0362s/iter; left time: 772.7199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760926\n",
      "\tspeed: 0.0156s/iter; left time: 332.2332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0759201 Vali Loss: 0.0882277 Test Loss: 0.0904895\n",
      "Validation loss decreased (0.089228 --> 0.088228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0784024\n",
      "\tspeed: 0.0324s/iter; left time: 684.1842s\n",
      "\titers: 200, epoch: 7 | loss: 0.0754921\n",
      "\tspeed: 0.0147s/iter; left time: 308.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0752275 Vali Loss: 0.0879289 Test Loss: 0.0902016\n",
      "Validation loss decreased (0.088228 --> 0.087929).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0699481\n",
      "\tspeed: 0.0351s/iter; left time: 734.4453s\n",
      "\titers: 200, epoch: 8 | loss: 0.0718761\n",
      "\tspeed: 0.0194s/iter; left time: 403.5384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 226 | Train Loss: 0.0747946 Vali Loss: 0.0874789 Test Loss: 0.0901015\n",
      "Validation loss decreased (0.087929 --> 0.087479).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0716389\n",
      "\tspeed: 0.0366s/iter; left time: 756.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681881\n",
      "\tspeed: 0.0168s/iter; left time: 346.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0742107 Vali Loss: 0.0872496 Test Loss: 0.0898178\n",
      "Validation loss decreased (0.087479 --> 0.087250).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0767106\n",
      "\tspeed: 0.0373s/iter; left time: 762.6762s\n",
      "\titers: 200, epoch: 10 | loss: 0.0742374\n",
      "\tspeed: 0.0165s/iter; left time: 335.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0739115 Vali Loss: 0.0874932 Test Loss: 0.0897692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768209\n",
      "\tspeed: 0.0303s/iter; left time: 613.9543s\n",
      "\titers: 200, epoch: 11 | loss: 0.0725960\n",
      "\tspeed: 0.0147s/iter; left time: 296.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0735395 Vali Loss: 0.0871070 Test Loss: 0.0896325\n",
      "Validation loss decreased (0.087250 --> 0.087107).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0729355\n",
      "\tspeed: 0.0305s/iter; left time: 609.9880s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778641\n",
      "\tspeed: 0.0168s/iter; left time: 334.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0733159 Vali Loss: 0.0867546 Test Loss: 0.0893783\n",
      "Validation loss decreased (0.087107 --> 0.086755).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0724195\n",
      "\tspeed: 0.0381s/iter; left time: 754.7910s\n",
      "\titers: 200, epoch: 13 | loss: 0.0691778\n",
      "\tspeed: 0.0212s/iter; left time: 417.5995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0731571 Vali Loss: 0.0866443 Test Loss: 0.0890993\n",
      "Validation loss decreased (0.086755 --> 0.086644).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0730425\n",
      "\tspeed: 0.0346s/iter; left time: 677.1500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0773089\n",
      "\tspeed: 0.0215s/iter; left time: 417.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0728669 Vali Loss: 0.0865124 Test Loss: 0.0889917\n",
      "Validation loss decreased (0.086644 --> 0.086512).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731445\n",
      "\tspeed: 0.0332s/iter; left time: 642.2836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0727954\n",
      "\tspeed: 0.0147s/iter; left time: 282.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0726974 Vali Loss: 0.0864326 Test Loss: 0.0889845\n",
      "Validation loss decreased (0.086512 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736746\n",
      "\tspeed: 0.0366s/iter; left time: 698.8203s\n",
      "\titers: 200, epoch: 16 | loss: 0.0759136\n",
      "\tspeed: 0.0147s/iter; left time: 279.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0725172 Vali Loss: 0.0862788 Test Loss: 0.0887207\n",
      "Validation loss decreased (0.086433 --> 0.086279).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0719921\n",
      "\tspeed: 0.0363s/iter; left time: 685.1361s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726950\n",
      "\tspeed: 0.0223s/iter; left time: 418.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0723900 Vali Loss: 0.0861436 Test Loss: 0.0887920\n",
      "Validation loss decreased (0.086279 --> 0.086144).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0689621\n",
      "\tspeed: 0.0343s/iter; left time: 639.8221s\n",
      "\titers: 200, epoch: 18 | loss: 0.0707179\n",
      "\tspeed: 0.0177s/iter; left time: 328.2012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0722318 Vali Loss: 0.0861794 Test Loss: 0.0886752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0785493\n",
      "\tspeed: 0.0353s/iter; left time: 651.0269s\n",
      "\titers: 200, epoch: 19 | loss: 0.0726154\n",
      "\tspeed: 0.0188s/iter; left time: 343.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0721604 Vali Loss: 0.0861406 Test Loss: 0.0886920\n",
      "Validation loss decreased (0.086144 --> 0.086141).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0758487\n",
      "\tspeed: 0.0340s/iter; left time: 619.1498s\n",
      "\titers: 200, epoch: 20 | loss: 0.0768337\n",
      "\tspeed: 0.0183s/iter; left time: 330.6882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0720731 Vali Loss: 0.0858387 Test Loss: 0.0885592\n",
      "Validation loss decreased (0.086141 --> 0.085839).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0714005\n",
      "\tspeed: 0.0359s/iter; left time: 645.3804s\n",
      "\titers: 200, epoch: 21 | loss: 0.0685546\n",
      "\tspeed: 0.0177s/iter; left time: 315.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0719999 Vali Loss: 0.0860083 Test Loss: 0.0886675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0693834\n",
      "\tspeed: 0.0356s/iter; left time: 632.1671s\n",
      "\titers: 200, epoch: 22 | loss: 0.0721585\n",
      "\tspeed: 0.0210s/iter; left time: 370.9165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0718582 Vali Loss: 0.0861149 Test Loss: 0.0887164\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0723435\n",
      "\tspeed: 0.0356s/iter; left time: 623.4974s\n",
      "\titers: 200, epoch: 23 | loss: 0.0708623\n",
      "\tspeed: 0.0192s/iter; left time: 334.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 226 | Train Loss: 0.0718138 Vali Loss: 0.0859426 Test Loss: 0.0885447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0673030\n",
      "\tspeed: 0.0337s/iter; left time: 583.4311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0738681\n",
      "\tspeed: 0.0150s/iter; left time: 258.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0717829 Vali Loss: 0.0858032 Test Loss: 0.0884723\n",
      "Validation loss decreased (0.085839 --> 0.085803).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0704683\n",
      "\tspeed: 0.0400s/iter; left time: 683.7744s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714896\n",
      "\tspeed: 0.0186s/iter; left time: 315.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0717126 Vali Loss: 0.0859911 Test Loss: 0.0884950\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0681589\n",
      "\tspeed: 0.0359s/iter; left time: 604.9268s\n",
      "\titers: 200, epoch: 26 | loss: 0.0726249\n",
      "\tspeed: 0.0169s/iter; left time: 283.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0717103 Vali Loss: 0.0859508 Test Loss: 0.0884369\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0782910\n",
      "\tspeed: 0.0368s/iter; left time: 611.0635s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724409\n",
      "\tspeed: 0.0184s/iter; left time: 303.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0716138 Vali Loss: 0.0858983 Test Loss: 0.0884526\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0694560\n",
      "\tspeed: 0.0310s/iter; left time: 508.5377s\n",
      "\titers: 200, epoch: 28 | loss: 0.0677827\n",
      "\tspeed: 0.0149s/iter; left time: 242.8831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0715209 Vali Loss: 0.0858228 Test Loss: 0.0884682\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0740452\n",
      "\tspeed: 0.0342s/iter; left time: 553.5682s\n",
      "\titers: 200, epoch: 29 | loss: 0.0732080\n",
      "\tspeed: 0.0156s/iter; left time: 250.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0715645 Vali Loss: 0.0857859 Test Loss: 0.0884036\n",
      "Validation loss decreased (0.085803 --> 0.085786).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0713792\n",
      "\tspeed: 0.0326s/iter; left time: 519.2028s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688472\n",
      "\tspeed: 0.0167s/iter; left time: 264.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0715175 Vali Loss: 0.0857581 Test Loss: 0.0884080\n",
      "Validation loss decreased (0.085786 --> 0.085758).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0746582\n",
      "\tspeed: 0.0346s/iter; left time: 544.3058s\n",
      "\titers: 200, epoch: 31 | loss: 0.0794997\n",
      "\tspeed: 0.0177s/iter; left time: 276.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0715177 Vali Loss: 0.0857334 Test Loss: 0.0884154\n",
      "Validation loss decreased (0.085758 --> 0.085733).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0719389\n",
      "\tspeed: 0.0366s/iter; left time: 567.0978s\n",
      "\titers: 200, epoch: 32 | loss: 0.0694298\n",
      "\tspeed: 0.0176s/iter; left time: 270.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0714295 Vali Loss: 0.0856955 Test Loss: 0.0884091\n",
      "Validation loss decreased (0.085733 --> 0.085696).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731141\n",
      "\tspeed: 0.0374s/iter; left time: 570.6708s\n",
      "\titers: 200, epoch: 33 | loss: 0.0715551\n",
      "\tspeed: 0.0174s/iter; left time: 263.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0714486 Vali Loss: 0.0857436 Test Loss: 0.0884355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0685063\n",
      "\tspeed: 0.0328s/iter; left time: 492.9971s\n",
      "\titers: 200, epoch: 34 | loss: 0.0719461\n",
      "\tspeed: 0.0161s/iter; left time: 240.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0714117 Vali Loss: 0.0857003 Test Loss: 0.0883715\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0678761\n",
      "\tspeed: 0.0316s/iter; left time: 468.1568s\n",
      "\titers: 200, epoch: 35 | loss: 0.0704411\n",
      "\tspeed: 0.0148s/iter; left time: 217.1721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0714024 Vali Loss: 0.0857247 Test Loss: 0.0883413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0765597\n",
      "\tspeed: 0.0361s/iter; left time: 527.0034s\n",
      "\titers: 200, epoch: 36 | loss: 0.0729911\n",
      "\tspeed: 0.0206s/iter; left time: 299.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 226 | Train Loss: 0.0713982 Vali Loss: 0.0857187 Test Loss: 0.0883920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0711310\n",
      "\tspeed: 0.0373s/iter; left time: 536.0037s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783857\n",
      "\tspeed: 0.0174s/iter; left time: 247.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0713893 Vali Loss: 0.0857170 Test Loss: 0.0883451\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0746590\n",
      "\tspeed: 0.0377s/iter; left time: 533.1887s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706815\n",
      "\tspeed: 0.0203s/iter; left time: 284.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 226 | Train Loss: 0.0713295 Vali Loss: 0.0857492 Test Loss: 0.0883414\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0762485\n",
      "\tspeed: 0.0415s/iter; left time: 578.0144s\n",
      "\titers: 200, epoch: 39 | loss: 0.0727055\n",
      "\tspeed: 0.0211s/iter; left time: 291.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 226 | Train Loss: 0.0713518 Vali Loss: 0.0857587 Test Loss: 0.0883479\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0698914\n",
      "\tspeed: 0.0356s/iter; left time: 487.4345s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677442\n",
      "\tspeed: 0.0159s/iter; left time: 216.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0713394 Vali Loss: 0.0856901 Test Loss: 0.0883288\n",
      "Validation loss decreased (0.085696 --> 0.085690).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0728084\n",
      "\tspeed: 0.0330s/iter; left time: 444.6270s\n",
      "\titers: 200, epoch: 41 | loss: 0.0761702\n",
      "\tspeed: 0.0179s/iter; left time: 239.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0713025 Vali Loss: 0.0855827 Test Loss: 0.0883383\n",
      "Validation loss decreased (0.085690 --> 0.085583).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0713209\n",
      "\tspeed: 0.0338s/iter; left time: 447.3594s\n",
      "\titers: 200, epoch: 42 | loss: 0.0679729\n",
      "\tspeed: 0.0182s/iter; left time: 238.8916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0712892 Vali Loss: 0.0856312 Test Loss: 0.0883043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0712263\n",
      "\tspeed: 0.0329s/iter; left time: 427.8249s\n",
      "\titers: 200, epoch: 43 | loss: 0.0721410\n",
      "\tspeed: 0.0149s/iter; left time: 192.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0713039 Vali Loss: 0.0856211 Test Loss: 0.0883403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0702652\n",
      "\tspeed: 0.0383s/iter; left time: 489.9326s\n",
      "\titers: 200, epoch: 44 | loss: 0.0679031\n",
      "\tspeed: 0.0174s/iter; left time: 221.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0712658 Vali Loss: 0.0857103 Test Loss: 0.0883354\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0719044\n",
      "\tspeed: 0.0338s/iter; left time: 424.8848s\n",
      "\titers: 200, epoch: 45 | loss: 0.0728759\n",
      "\tspeed: 0.0153s/iter; left time: 190.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0712951 Vali Loss: 0.0857546 Test Loss: 0.0883350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0705679\n",
      "\tspeed: 0.0340s/iter; left time: 419.5287s\n",
      "\titers: 200, epoch: 46 | loss: 0.0715705\n",
      "\tspeed: 0.0180s/iter; left time: 219.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0713185 Vali Loss: 0.0855664 Test Loss: 0.0883432\n",
      "Validation loss decreased (0.085583 --> 0.085566).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0704627\n",
      "\tspeed: 0.0324s/iter; left time: 392.7287s\n",
      "\titers: 200, epoch: 47 | loss: 0.0729561\n",
      "\tspeed: 0.0157s/iter; left time: 189.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0712942 Vali Loss: 0.0856717 Test Loss: 0.0883280\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0682058\n",
      "\tspeed: 0.0331s/iter; left time: 392.8261s\n",
      "\titers: 200, epoch: 48 | loss: 0.0693166\n",
      "\tspeed: 0.0148s/iter; left time: 174.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0713058 Vali Loss: 0.0856410 Test Loss: 0.0883086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660363\n",
      "\tspeed: 0.0330s/iter; left time: 384.3493s\n",
      "\titers: 200, epoch: 49 | loss: 0.0697123\n",
      "\tspeed: 0.0171s/iter; left time: 197.6317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0712463 Vali Loss: 0.0855903 Test Loss: 0.0883189\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0686551\n",
      "\tspeed: 0.0378s/iter; left time: 431.8369s\n",
      "\titers: 200, epoch: 50 | loss: 0.0664038\n",
      "\tspeed: 0.0197s/iter; left time: 222.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0712557 Vali Loss: 0.0855734 Test Loss: 0.0883155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0744726\n",
      "\tspeed: 0.0354s/iter; left time: 397.0690s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737909\n",
      "\tspeed: 0.0161s/iter; left time: 178.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0712689 Vali Loss: 0.0856441 Test Loss: 0.0883205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0756705\n",
      "\tspeed: 0.0318s/iter; left time: 348.8220s\n",
      "\titers: 200, epoch: 52 | loss: 0.0705133\n",
      "\tspeed: 0.0175s/iter; left time: 189.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0712694 Vali Loss: 0.0855412 Test Loss: 0.0883130\n",
      "Validation loss decreased (0.085566 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0720955\n",
      "\tspeed: 0.0342s/iter; left time: 367.8885s\n",
      "\titers: 200, epoch: 53 | loss: 0.0706849\n",
      "\tspeed: 0.0180s/iter; left time: 191.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.0712541 Vali Loss: 0.0856194 Test Loss: 0.0883148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0678672\n",
      "\tspeed: 0.0344s/iter; left time: 361.9226s\n",
      "\titers: 200, epoch: 54 | loss: 0.0734708\n",
      "\tspeed: 0.0161s/iter; left time: 167.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0712836 Vali Loss: 0.0856949 Test Loss: 0.0883241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0711872\n",
      "\tspeed: 0.0388s/iter; left time: 399.7837s\n",
      "\titers: 200, epoch: 55 | loss: 0.0728162\n",
      "\tspeed: 0.0148s/iter; left time: 150.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0712821 Vali Loss: 0.0857205 Test Loss: 0.0883147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0777686\n",
      "\tspeed: 0.0349s/iter; left time: 351.9102s\n",
      "\titers: 200, epoch: 56 | loss: 0.0725330\n",
      "\tspeed: 0.0160s/iter; left time: 159.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0712508 Vali Loss: 0.0856761 Test Loss: 0.0883089\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0710412\n",
      "\tspeed: 0.0361s/iter; left time: 355.3465s\n",
      "\titers: 200, epoch: 57 | loss: 0.0677898\n",
      "\tspeed: 0.0177s/iter; left time: 172.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0712242 Vali Loss: 0.0856294 Test Loss: 0.0883095\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0743255\n",
      "\tspeed: 0.0362s/iter; left time: 348.6598s\n",
      "\titers: 200, epoch: 58 | loss: 0.0715804\n",
      "\tspeed: 0.0191s/iter; left time: 181.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0712374 Vali Loss: 0.0856550 Test Loss: 0.0883076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0697248\n",
      "\tspeed: 0.0340s/iter; left time: 319.7715s\n",
      "\titers: 200, epoch: 59 | loss: 0.0690377\n",
      "\tspeed: 0.0154s/iter; left time: 143.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0712509 Vali Loss: 0.0857698 Test Loss: 0.0883156\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0771950\n",
      "\tspeed: 0.0342s/iter; left time: 313.7151s\n",
      "\titers: 200, epoch: 60 | loss: 0.0674402\n",
      "\tspeed: 0.0153s/iter; left time: 139.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0712430 Vali Loss: 0.0856275 Test Loss: 0.0883090\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0728195\n",
      "\tspeed: 0.0363s/iter; left time: 324.6634s\n",
      "\titers: 200, epoch: 61 | loss: 0.0771895\n",
      "\tspeed: 0.0157s/iter; left time: 138.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0712464 Vali Loss: 0.0856176 Test Loss: 0.0883221\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0706645\n",
      "\tspeed: 0.0355s/iter; left time: 309.0578s\n",
      "\titers: 200, epoch: 62 | loss: 0.0693574\n",
      "\tspeed: 0.0176s/iter; left time: 151.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0712369 Vali Loss: 0.0855623 Test Loss: 0.0883131\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021246246993541718, rmse:0.1457609236240387, mae:0.08831298351287842, rse:0.5144104957580566\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1518033\n",
      "\tspeed: 0.0192s/iter; left time: 431.8547s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270512\n",
      "\tspeed: 0.0201s/iter; left time: 449.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.1498720 Vali Loss: 0.1357662 Test Loss: 0.1440873\n",
      "Validation loss decreased (inf --> 0.135766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853987\n",
      "\tspeed: 0.0352s/iter; left time: 784.5516s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901837\n",
      "\tspeed: 0.0148s/iter; left time: 328.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0911641 Vali Loss: 0.0949860 Test Loss: 0.0961873\n",
      "Validation loss decreased (0.135766 --> 0.094986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799221\n",
      "\tspeed: 0.0335s/iter; left time: 737.8098s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794998\n",
      "\tspeed: 0.0157s/iter; left time: 344.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0814267 Vali Loss: 0.0915384 Test Loss: 0.0932980\n",
      "Validation loss decreased (0.094986 --> 0.091538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764318\n",
      "\tspeed: 0.0368s/iter; left time: 802.1689s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785906\n",
      "\tspeed: 0.0218s/iter; left time: 474.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 226 | Train Loss: 0.0787459 Vali Loss: 0.0898482 Test Loss: 0.0917731\n",
      "Validation loss decreased (0.091538 --> 0.089848).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0741054\n",
      "\tspeed: 0.0383s/iter; left time: 826.3129s\n",
      "\titers: 200, epoch: 5 | loss: 0.0753271\n",
      "\tspeed: 0.0187s/iter; left time: 401.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0770410 Vali Loss: 0.0887867 Test Loss: 0.0908344\n",
      "Validation loss decreased (0.089848 --> 0.088787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765578\n",
      "\tspeed: 0.0346s/iter; left time: 740.2349s\n",
      "\titers: 200, epoch: 6 | loss: 0.0733192\n",
      "\tspeed: 0.0162s/iter; left time: 344.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0760022 Vali Loss: 0.0880748 Test Loss: 0.0903927\n",
      "Validation loss decreased (0.088787 --> 0.088075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0709637\n",
      "\tspeed: 0.0361s/iter; left time: 763.8951s\n",
      "\titers: 200, epoch: 7 | loss: 0.0734636\n",
      "\tspeed: 0.0163s/iter; left time: 343.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0751434 Vali Loss: 0.0871895 Test Loss: 0.0901067\n",
      "Validation loss decreased (0.088075 --> 0.087190).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0773387\n",
      "\tspeed: 0.0366s/iter; left time: 764.6073s\n",
      "\titers: 200, epoch: 8 | loss: 0.0676913\n",
      "\tspeed: 0.0155s/iter; left time: 321.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0746788 Vali Loss: 0.0872169 Test Loss: 0.0898075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763129\n",
      "\tspeed: 0.0374s/iter; left time: 774.4037s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725481\n",
      "\tspeed: 0.0195s/iter; left time: 402.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0741238 Vali Loss: 0.0871174 Test Loss: 0.0893675\n",
      "Validation loss decreased (0.087190 --> 0.087117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748332\n",
      "\tspeed: 0.0366s/iter; left time: 750.1061s\n",
      "\titers: 200, epoch: 10 | loss: 0.0738588\n",
      "\tspeed: 0.0206s/iter; left time: 419.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0737441 Vali Loss: 0.0869346 Test Loss: 0.0891188\n",
      "Validation loss decreased (0.087117 --> 0.086935).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0711018\n",
      "\tspeed: 0.0379s/iter; left time: 767.1253s\n",
      "\titers: 200, epoch: 11 | loss: 0.0700966\n",
      "\tspeed: 0.0190s/iter; left time: 383.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0733540 Vali Loss: 0.0866789 Test Loss: 0.0892408\n",
      "Validation loss decreased (0.086935 --> 0.086679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0763421\n",
      "\tspeed: 0.0405s/iter; left time: 811.2465s\n",
      "\titers: 200, epoch: 12 | loss: 0.0745435\n",
      "\tspeed: 0.0196s/iter; left time: 390.4372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0731190 Vali Loss: 0.0863019 Test Loss: 0.0886837\n",
      "Validation loss decreased (0.086679 --> 0.086302).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0725760\n",
      "\tspeed: 0.0373s/iter; left time: 738.0649s\n",
      "\titers: 200, epoch: 13 | loss: 0.0694761\n",
      "\tspeed: 0.0202s/iter; left time: 396.9208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0728449 Vali Loss: 0.0860798 Test Loss: 0.0886771\n",
      "Validation loss decreased (0.086302 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0713402\n",
      "\tspeed: 0.0395s/iter; left time: 772.6691s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717091\n",
      "\tspeed: 0.0197s/iter; left time: 383.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0726764 Vali Loss: 0.0860854 Test Loss: 0.0887915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696020\n",
      "\tspeed: 0.0379s/iter; left time: 732.7090s\n",
      "\titers: 200, epoch: 15 | loss: 0.0707006\n",
      "\tspeed: 0.0182s/iter; left time: 349.7996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0724796 Vali Loss: 0.0859697 Test Loss: 0.0885499\n",
      "Validation loss decreased (0.086080 --> 0.085970).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0702264\n",
      "\tspeed: 0.0326s/iter; left time: 623.5638s\n",
      "\titers: 200, epoch: 16 | loss: 0.0770680\n",
      "\tspeed: 0.0148s/iter; left time: 280.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0723478 Vali Loss: 0.0859928 Test Loss: 0.0885237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0693218\n",
      "\tspeed: 0.0366s/iter; left time: 690.8188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0685964\n",
      "\tspeed: 0.0195s/iter; left time: 366.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0721852 Vali Loss: 0.0858721 Test Loss: 0.0885176\n",
      "Validation loss decreased (0.085970 --> 0.085872).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0763035\n",
      "\tspeed: 0.0348s/iter; left time: 649.1754s\n",
      "\titers: 200, epoch: 18 | loss: 0.0726792\n",
      "\tspeed: 0.0228s/iter; left time: 422.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0720626 Vali Loss: 0.0858251 Test Loss: 0.0883971\n",
      "Validation loss decreased (0.085872 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737270\n",
      "\tspeed: 0.0377s/iter; left time: 694.0765s\n",
      "\titers: 200, epoch: 19 | loss: 0.0792900\n",
      "\tspeed: 0.0209s/iter; left time: 382.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0719951 Vali Loss: 0.0858679 Test Loss: 0.0884198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0684844\n",
      "\tspeed: 0.0388s/iter; left time: 707.1272s\n",
      "\titers: 200, epoch: 20 | loss: 0.0707226\n",
      "\tspeed: 0.0201s/iter; left time: 363.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0718766 Vali Loss: 0.0856740 Test Loss: 0.0883149\n",
      "Validation loss decreased (0.085825 --> 0.085674).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0758472\n",
      "\tspeed: 0.0385s/iter; left time: 691.6377s\n",
      "\titers: 200, epoch: 21 | loss: 0.0754508\n",
      "\tspeed: 0.0201s/iter; left time: 358.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0717989 Vali Loss: 0.0857483 Test Loss: 0.0882967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0715936\n",
      "\tspeed: 0.0376s/iter; left time: 667.4035s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681770\n",
      "\tspeed: 0.0188s/iter; left time: 332.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0716900 Vali Loss: 0.0857370 Test Loss: 0.0882843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729675\n",
      "\tspeed: 0.0385s/iter; left time: 675.1515s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740432\n",
      "\tspeed: 0.0212s/iter; left time: 369.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0716362 Vali Loss: 0.0854434 Test Loss: 0.0882942\n",
      "Validation loss decreased (0.085674 --> 0.085443).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0722094\n",
      "\tspeed: 0.0392s/iter; left time: 677.9869s\n",
      "\titers: 200, epoch: 24 | loss: 0.0706832\n",
      "\tspeed: 0.0174s/iter; left time: 300.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0715837 Vali Loss: 0.0857568 Test Loss: 0.0883134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0648718\n",
      "\tspeed: 0.0408s/iter; left time: 697.0089s\n",
      "\titers: 200, epoch: 25 | loss: 0.0725351\n",
      "\tspeed: 0.0172s/iter; left time: 292.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0714995 Vali Loss: 0.0852995 Test Loss: 0.0881621\n",
      "Validation loss decreased (0.085443 --> 0.085299).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812834\n",
      "\tspeed: 0.0387s/iter; left time: 651.7739s\n",
      "\titers: 200, epoch: 26 | loss: 0.0664594\n",
      "\tspeed: 0.0191s/iter; left time: 319.1942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0714836 Vali Loss: 0.0853780 Test Loss: 0.0881366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742876\n",
      "\tspeed: 0.0400s/iter; left time: 665.4394s\n",
      "\titers: 200, epoch: 27 | loss: 0.0732438\n",
      "\tspeed: 0.0220s/iter; left time: 363.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 226 | Train Loss: 0.0714202 Vali Loss: 0.0854149 Test Loss: 0.0881234\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0714915\n",
      "\tspeed: 0.0348s/iter; left time: 570.5468s\n",
      "\titers: 200, epoch: 28 | loss: 0.0735736\n",
      "\tspeed: 0.0179s/iter; left time: 291.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0713732 Vali Loss: 0.0854846 Test Loss: 0.0881038\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0754490\n",
      "\tspeed: 0.0375s/iter; left time: 606.1918s\n",
      "\titers: 200, epoch: 29 | loss: 0.0688223\n",
      "\tspeed: 0.0199s/iter; left time: 319.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0714346 Vali Loss: 0.0855115 Test Loss: 0.0881206\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0691710\n",
      "\tspeed: 0.0383s/iter; left time: 610.5563s\n",
      "\titers: 200, epoch: 30 | loss: 0.0732817\n",
      "\tspeed: 0.0162s/iter; left time: 257.2781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0713558 Vali Loss: 0.0852352 Test Loss: 0.0881770\n",
      "Validation loss decreased (0.085299 --> 0.085235).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0723415\n",
      "\tspeed: 0.0368s/iter; left time: 578.3818s\n",
      "\titers: 200, epoch: 31 | loss: 0.0698793\n",
      "\tspeed: 0.0148s/iter; left time: 230.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0713109 Vali Loss: 0.0855413 Test Loss: 0.0881131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0731405\n",
      "\tspeed: 0.0358s/iter; left time: 555.4050s\n",
      "\titers: 200, epoch: 32 | loss: 0.0700180\n",
      "\tspeed: 0.0193s/iter; left time: 296.7149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0713076 Vali Loss: 0.0853621 Test Loss: 0.0880926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0645976\n",
      "\tspeed: 0.0334s/iter; left time: 510.1503s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736442\n",
      "\tspeed: 0.0157s/iter; left time: 237.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0712606 Vali Loss: 0.0855004 Test Loss: 0.0881196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0698599\n",
      "\tspeed: 0.0326s/iter; left time: 490.4366s\n",
      "\titers: 200, epoch: 34 | loss: 0.0672192\n",
      "\tspeed: 0.0148s/iter; left time: 220.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0712565 Vali Loss: 0.0854266 Test Loss: 0.0881393\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0714119\n",
      "\tspeed: 0.0380s/iter; left time: 562.3737s\n",
      "\titers: 200, epoch: 35 | loss: 0.0745585\n",
      "\tspeed: 0.0156s/iter; left time: 229.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0712457 Vali Loss: 0.0854704 Test Loss: 0.0881282\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0699492\n",
      "\tspeed: 0.0375s/iter; left time: 547.7401s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743586\n",
      "\tspeed: 0.0177s/iter; left time: 256.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 226 | Train Loss: 0.0712100 Vali Loss: 0.0852717 Test Loss: 0.0881152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0690385\n",
      "\tspeed: 0.0323s/iter; left time: 463.5959s\n",
      "\titers: 200, epoch: 37 | loss: 0.0691354\n",
      "\tspeed: 0.0149s/iter; left time: 212.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0712000 Vali Loss: 0.0853180 Test Loss: 0.0880658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0746413\n",
      "\tspeed: 0.0389s/iter; left time: 549.4572s\n",
      "\titers: 200, epoch: 38 | loss: 0.0729299\n",
      "\tspeed: 0.0178s/iter; left time: 249.7368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0711829 Vali Loss: 0.0853320 Test Loss: 0.0880678\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0674538\n",
      "\tspeed: 0.0330s/iter; left time: 459.7032s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696075\n",
      "\tspeed: 0.0149s/iter; left time: 205.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0711302 Vali Loss: 0.0852830 Test Loss: 0.0880550\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0697548\n",
      "\tspeed: 0.0374s/iter; left time: 511.2212s\n",
      "\titers: 200, epoch: 40 | loss: 0.0723081\n",
      "\tspeed: 0.0164s/iter; left time: 222.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0711335 Vali Loss: 0.0852903 Test Loss: 0.0880491\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02114878036081791, rmse:0.1454261988401413, mae:0.08817699551582336, rse:0.5132291913032532\n",
      "Intermediate time for DE and pred_len 24: 00h:09m:10.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1546121\n",
      "\tspeed: 0.0416s/iter; left time: 932.4142s\n",
      "\titers: 200, epoch: 1 | loss: 0.1400235\n",
      "\tspeed: 0.0154s/iter; left time: 344.2735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.1571345 Vali Loss: 0.1484944 Test Loss: 0.1616077\n",
      "Validation loss decreased (inf --> 0.148494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1196035\n",
      "\tspeed: 0.0355s/iter; left time: 787.1608s\n",
      "\titers: 200, epoch: 2 | loss: 0.1128855\n",
      "\tspeed: 0.0196s/iter; left time: 433.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1181649 Vali Loss: 0.1238543 Test Loss: 0.1332652\n",
      "Validation loss decreased (0.148494 --> 0.123854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108415\n",
      "\tspeed: 0.0346s/iter; left time: 759.2518s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081765\n",
      "\tspeed: 0.0182s/iter; left time: 398.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1086654 Vali Loss: 0.1214263 Test Loss: 0.1309388\n",
      "Validation loss decreased (0.123854 --> 0.121426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058460\n",
      "\tspeed: 0.0362s/iter; left time: 787.2354s\n",
      "\titers: 200, epoch: 4 | loss: 0.1017606\n",
      "\tspeed: 0.0165s/iter; left time: 357.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.1063051 Vali Loss: 0.1204320 Test Loss: 0.1294891\n",
      "Validation loss decreased (0.121426 --> 0.120432).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1031780\n",
      "\tspeed: 0.0335s/iter; left time: 720.3490s\n",
      "\titers: 200, epoch: 5 | loss: 0.1077288\n",
      "\tspeed: 0.0182s/iter; left time: 388.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1049562 Vali Loss: 0.1202408 Test Loss: 0.1285590\n",
      "Validation loss decreased (0.120432 --> 0.120241).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112841\n",
      "\tspeed: 0.0347s/iter; left time: 737.7303s\n",
      "\titers: 200, epoch: 6 | loss: 0.1057750\n",
      "\tspeed: 0.0166s/iter; left time: 351.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1040261 Vali Loss: 0.1198119 Test Loss: 0.1283519\n",
      "Validation loss decreased (0.120241 --> 0.119812).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015058\n",
      "\tspeed: 0.0369s/iter; left time: 777.0897s\n",
      "\titers: 200, epoch: 7 | loss: 0.1056823\n",
      "\tspeed: 0.0174s/iter; left time: 365.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1032991 Vali Loss: 0.1199166 Test Loss: 0.1284418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1041890\n",
      "\tspeed: 0.0343s/iter; left time: 714.1693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076229\n",
      "\tspeed: 0.0151s/iter; left time: 313.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.1027025 Vali Loss: 0.1198784 Test Loss: 0.1279660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1025044\n",
      "\tspeed: 0.0346s/iter; left time: 712.8094s\n",
      "\titers: 200, epoch: 9 | loss: 0.0994158\n",
      "\tspeed: 0.0150s/iter; left time: 307.2104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.1022336 Vali Loss: 0.1190886 Test Loss: 0.1272537\n",
      "Validation loss decreased (0.119812 --> 0.119089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1005756\n",
      "\tspeed: 0.0383s/iter; left time: 781.2921s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013288\n",
      "\tspeed: 0.0189s/iter; left time: 384.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.1017910 Vali Loss: 0.1191306 Test Loss: 0.1268866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1017002\n",
      "\tspeed: 0.0400s/iter; left time: 805.5786s\n",
      "\titers: 200, epoch: 11 | loss: 0.1038562\n",
      "\tspeed: 0.0225s/iter; left time: 451.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.1014321 Vali Loss: 0.1187267 Test Loss: 0.1270149\n",
      "Validation loss decreased (0.119089 --> 0.118727).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0990154\n",
      "\tspeed: 0.0380s/iter; left time: 756.3343s\n",
      "\titers: 200, epoch: 12 | loss: 0.1071175\n",
      "\tspeed: 0.0178s/iter; left time: 353.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1010969 Vali Loss: 0.1191120 Test Loss: 0.1271684\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1041970\n",
      "\tspeed: 0.0338s/iter; left time: 666.3408s\n",
      "\titers: 200, epoch: 13 | loss: 0.1016034\n",
      "\tspeed: 0.0164s/iter; left time: 322.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.1008338 Vali Loss: 0.1195352 Test Loss: 0.1274527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013781\n",
      "\tspeed: 0.0362s/iter; left time: 705.5291s\n",
      "\titers: 200, epoch: 14 | loss: 0.1037347\n",
      "\tspeed: 0.0171s/iter; left time: 330.4930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.1006502 Vali Loss: 0.1190295 Test Loss: 0.1268910\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0992426\n",
      "\tspeed: 0.0345s/iter; left time: 664.9427s\n",
      "\titers: 200, epoch: 15 | loss: 0.0969416\n",
      "\tspeed: 0.0149s/iter; left time: 286.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.1003572 Vali Loss: 0.1189620 Test Loss: 0.1268336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1013089\n",
      "\tspeed: 0.0349s/iter; left time: 664.2710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0990523\n",
      "\tspeed: 0.0203s/iter; left time: 383.4438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1001020 Vali Loss: 0.1187779 Test Loss: 0.1264221\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0997604\n",
      "\tspeed: 0.0361s/iter; left time: 678.8091s\n",
      "\titers: 200, epoch: 17 | loss: 0.1042790\n",
      "\tspeed: 0.0152s/iter; left time: 284.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1000534 Vali Loss: 0.1187418 Test Loss: 0.1266497\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1057856\n",
      "\tspeed: 0.0356s/iter; left time: 661.7073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0973422\n",
      "\tspeed: 0.0154s/iter; left time: 284.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0998120 Vali Loss: 0.1185887 Test Loss: 0.1265640\n",
      "Validation loss decreased (0.118727 --> 0.118589).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0994233\n",
      "\tspeed: 0.0348s/iter; left time: 639.0015s\n",
      "\titers: 200, epoch: 19 | loss: 0.0999866\n",
      "\tspeed: 0.0154s/iter; left time: 281.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0997114 Vali Loss: 0.1188520 Test Loss: 0.1263896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0996900\n",
      "\tspeed: 0.0352s/iter; left time: 638.2583s\n",
      "\titers: 200, epoch: 20 | loss: 0.1031228\n",
      "\tspeed: 0.0178s/iter; left time: 320.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0995866 Vali Loss: 0.1189126 Test Loss: 0.1265392\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0999166\n",
      "\tspeed: 0.0333s/iter; left time: 595.9401s\n",
      "\titers: 200, epoch: 21 | loss: 0.0971584\n",
      "\tspeed: 0.0166s/iter; left time: 296.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0994200 Vali Loss: 0.1187942 Test Loss: 0.1265447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0989321\n",
      "\tspeed: 0.0332s/iter; left time: 587.4503s\n",
      "\titers: 200, epoch: 22 | loss: 0.1030317\n",
      "\tspeed: 0.0149s/iter; left time: 262.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0993532 Vali Loss: 0.1184512 Test Loss: 0.1264205\n",
      "Validation loss decreased (0.118589 --> 0.118451).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1053485\n",
      "\tspeed: 0.0363s/iter; left time: 633.2806s\n",
      "\titers: 200, epoch: 23 | loss: 0.0915438\n",
      "\tspeed: 0.0190s/iter; left time: 328.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0992047 Vali Loss: 0.1188719 Test Loss: 0.1264960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1002571\n",
      "\tspeed: 0.0362s/iter; left time: 623.0431s\n",
      "\titers: 200, epoch: 24 | loss: 0.1038216\n",
      "\tspeed: 0.0164s/iter; left time: 280.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0991893 Vali Loss: 0.1185893 Test Loss: 0.1262891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0964289\n",
      "\tspeed: 0.0358s/iter; left time: 609.1420s\n",
      "\titers: 200, epoch: 25 | loss: 0.0961830\n",
      "\tspeed: 0.0160s/iter; left time: 270.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0990750 Vali Loss: 0.1187493 Test Loss: 0.1265117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1029489\n",
      "\tspeed: 0.0334s/iter; left time: 559.5250s\n",
      "\titers: 200, epoch: 26 | loss: 0.0984642\n",
      "\tspeed: 0.0149s/iter; left time: 249.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0990308 Vali Loss: 0.1184566 Test Loss: 0.1263237\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0963094\n",
      "\tspeed: 0.0343s/iter; left time: 568.2647s\n",
      "\titers: 200, epoch: 27 | loss: 0.0988014\n",
      "\tspeed: 0.0176s/iter; left time: 289.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0990124 Vali Loss: 0.1186175 Test Loss: 0.1265397\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0955154\n",
      "\tspeed: 0.0352s/iter; left time: 575.1701s\n",
      "\titers: 200, epoch: 28 | loss: 0.0994291\n",
      "\tspeed: 0.0150s/iter; left time: 243.4683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0988817 Vali Loss: 0.1186398 Test Loss: 0.1264903\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1008465\n",
      "\tspeed: 0.0376s/iter; left time: 605.1781s\n",
      "\titers: 200, epoch: 29 | loss: 0.0950760\n",
      "\tspeed: 0.0151s/iter; left time: 241.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0988331 Vali Loss: 0.1185322 Test Loss: 0.1264422\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0931816\n",
      "\tspeed: 0.0350s/iter; left time: 555.9447s\n",
      "\titers: 200, epoch: 30 | loss: 0.1001480\n",
      "\tspeed: 0.0149s/iter; left time: 234.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0989152 Vali Loss: 0.1184158 Test Loss: 0.1263546\n",
      "Validation loss decreased (0.118451 --> 0.118416).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0959047\n",
      "\tspeed: 0.0365s/iter; left time: 570.9919s\n",
      "\titers: 200, epoch: 31 | loss: 0.1010143\n",
      "\tspeed: 0.0189s/iter; left time: 293.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0988581 Vali Loss: 0.1183319 Test Loss: 0.1263200\n",
      "Validation loss decreased (0.118416 --> 0.118332).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0970245\n",
      "\tspeed: 0.0376s/iter; left time: 580.4557s\n",
      "\titers: 200, epoch: 32 | loss: 0.0988358\n",
      "\tspeed: 0.0166s/iter; left time: 254.0047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0988036 Vali Loss: 0.1183956 Test Loss: 0.1264224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1012524\n",
      "\tspeed: 0.0394s/iter; left time: 599.4984s\n",
      "\titers: 200, epoch: 33 | loss: 0.0987937\n",
      "\tspeed: 0.0205s/iter; left time: 310.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0987398 Vali Loss: 0.1182987 Test Loss: 0.1263141\n",
      "Validation loss decreased (0.118332 --> 0.118299).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0985900\n",
      "\tspeed: 0.0374s/iter; left time: 560.4650s\n",
      "\titers: 200, epoch: 34 | loss: 0.0935382\n",
      "\tspeed: 0.0157s/iter; left time: 234.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0987068 Vali Loss: 0.1183450 Test Loss: 0.1263458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0970084\n",
      "\tspeed: 0.0353s/iter; left time: 521.2234s\n",
      "\titers: 200, epoch: 35 | loss: 0.0927501\n",
      "\tspeed: 0.0208s/iter; left time: 304.0132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0986973 Vali Loss: 0.1186062 Test Loss: 0.1265274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0998640\n",
      "\tspeed: 0.0407s/iter; left time: 591.0085s\n",
      "\titers: 200, epoch: 36 | loss: 0.1007608\n",
      "\tspeed: 0.0220s/iter; left time: 317.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0986956 Vali Loss: 0.1184913 Test Loss: 0.1264177\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1017523\n",
      "\tspeed: 0.0404s/iter; left time: 577.5350s\n",
      "\titers: 200, epoch: 37 | loss: 0.0997659\n",
      "\tspeed: 0.0201s/iter; left time: 284.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.0985954 Vali Loss: 0.1184251 Test Loss: 0.1263238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0956129\n",
      "\tspeed: 0.0353s/iter; left time: 497.2797s\n",
      "\titers: 200, epoch: 38 | loss: 0.0992918\n",
      "\tspeed: 0.0156s/iter; left time: 217.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0986035 Vali Loss: 0.1185189 Test Loss: 0.1264063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0935376\n",
      "\tspeed: 0.0381s/iter; left time: 527.6382s\n",
      "\titers: 200, epoch: 39 | loss: 0.0947464\n",
      "\tspeed: 0.0203s/iter; left time: 278.7095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0986035 Vali Loss: 0.1185026 Test Loss: 0.1264198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0979223\n",
      "\tspeed: 0.0352s/iter; left time: 479.1197s\n",
      "\titers: 200, epoch: 40 | loss: 0.0945299\n",
      "\tspeed: 0.0198s/iter; left time: 267.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0986283 Vali Loss: 0.1184659 Test Loss: 0.1264053\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0983004\n",
      "\tspeed: 0.0403s/iter; left time: 540.3695s\n",
      "\titers: 200, epoch: 41 | loss: 0.0979814\n",
      "\tspeed: 0.0201s/iter; left time: 267.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.0985964 Vali Loss: 0.1184100 Test Loss: 0.1263391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1028368\n",
      "\tspeed: 0.0382s/iter; left time: 502.9143s\n",
      "\titers: 200, epoch: 42 | loss: 0.0956750\n",
      "\tspeed: 0.0187s/iter; left time: 244.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0985760 Vali Loss: 0.1185045 Test Loss: 0.1263552\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0966641\n",
      "\tspeed: 0.0369s/iter; left time: 478.1689s\n",
      "\titers: 200, epoch: 43 | loss: 0.0967524\n",
      "\tspeed: 0.0153s/iter; left time: 197.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0985568 Vali Loss: 0.1185039 Test Loss: 0.1264004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03725607320666313, rmse:0.19301831722259521, mae:0.12631411850452423, rse:0.6835169196128845\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1594719\n",
      "\tspeed: 0.0203s/iter; left time: 454.8996s\n",
      "\titers: 200, epoch: 1 | loss: 0.1446275\n",
      "\tspeed: 0.0205s/iter; left time: 456.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1578681 Vali Loss: 0.1489479 Test Loss: 0.1620588\n",
      "Validation loss decreased (inf --> 0.148948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1165081\n",
      "\tspeed: 0.0368s/iter; left time: 815.4234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102197\n",
      "\tspeed: 0.0175s/iter; left time: 385.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1184436 Vali Loss: 0.1239039 Test Loss: 0.1334199\n",
      "Validation loss decreased (0.148948 --> 0.123904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1065054\n",
      "\tspeed: 0.0375s/iter; left time: 822.0836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0987603\n",
      "\tspeed: 0.0150s/iter; left time: 327.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.1088305 Vali Loss: 0.1219295 Test Loss: 0.1310768\n",
      "Validation loss decreased (0.123904 --> 0.121929).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1059293\n",
      "\tspeed: 0.0430s/iter; left time: 934.3116s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097753\n",
      "\tspeed: 0.0207s/iter; left time: 446.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.1064283 Vali Loss: 0.1208800 Test Loss: 0.1299682\n",
      "Validation loss decreased (0.121929 --> 0.120880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106490\n",
      "\tspeed: 0.0440s/iter; left time: 945.2451s\n",
      "\titers: 200, epoch: 5 | loss: 0.1115315\n",
      "\tspeed: 0.0198s/iter; left time: 423.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.1050829 Vali Loss: 0.1201282 Test Loss: 0.1288217\n",
      "Validation loss decreased (0.120880 --> 0.120128).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1070387\n",
      "\tspeed: 0.0368s/iter; left time: 783.4612s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977164\n",
      "\tspeed: 0.0164s/iter; left time: 346.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.1041735 Vali Loss: 0.1211485 Test Loss: 0.1292872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014085\n",
      "\tspeed: 0.0330s/iter; left time: 695.6314s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047801\n",
      "\tspeed: 0.0152s/iter; left time: 317.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1035143 Vali Loss: 0.1195752 Test Loss: 0.1277059\n",
      "Validation loss decreased (0.120128 --> 0.119575).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1013614\n",
      "\tspeed: 0.0390s/iter; left time: 811.3228s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080542\n",
      "\tspeed: 0.0195s/iter; left time: 405.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 225 | Train Loss: 0.1029324 Vali Loss: 0.1196418 Test Loss: 0.1277450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1005211\n",
      "\tspeed: 0.0362s/iter; left time: 745.8069s\n",
      "\titers: 200, epoch: 9 | loss: 0.0996397\n",
      "\tspeed: 0.0171s/iter; left time: 349.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1024450 Vali Loss: 0.1194940 Test Loss: 0.1271717\n",
      "Validation loss decreased (0.119575 --> 0.119494).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033988\n",
      "\tspeed: 0.0405s/iter; left time: 825.6661s\n",
      "\titers: 200, epoch: 10 | loss: 0.1075299\n",
      "\tspeed: 0.0211s/iter; left time: 428.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.1019535 Vali Loss: 0.1189011 Test Loss: 0.1265846\n",
      "Validation loss decreased (0.119494 --> 0.118901).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1029874\n",
      "\tspeed: 0.0421s/iter; left time: 849.3110s\n",
      "\titers: 200, epoch: 11 | loss: 0.0994294\n",
      "\tspeed: 0.0199s/iter; left time: 398.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.1015970 Vali Loss: 0.1188431 Test Loss: 0.1266741\n",
      "Validation loss decreased (0.118901 --> 0.118843).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1002504\n",
      "\tspeed: 0.0386s/iter; left time: 769.3879s\n",
      "\titers: 200, epoch: 12 | loss: 0.0984752\n",
      "\tspeed: 0.0210s/iter; left time: 415.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1012771 Vali Loss: 0.1190146 Test Loss: 0.1266688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0951208\n",
      "\tspeed: 0.0397s/iter; left time: 781.4904s\n",
      "\titers: 200, epoch: 13 | loss: 0.1013440\n",
      "\tspeed: 0.0207s/iter; left time: 405.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1009379 Vali Loss: 0.1190206 Test Loss: 0.1263876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1019207\n",
      "\tspeed: 0.0394s/iter; left time: 767.8853s\n",
      "\titers: 200, epoch: 14 | loss: 0.1002271\n",
      "\tspeed: 0.0193s/iter; left time: 373.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1006495 Vali Loss: 0.1190553 Test Loss: 0.1264120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0994094\n",
      "\tspeed: 0.0393s/iter; left time: 756.3436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0971790\n",
      "\tspeed: 0.0179s/iter; left time: 342.5074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.1004595 Vali Loss: 0.1186343 Test Loss: 0.1265867\n",
      "Validation loss decreased (0.118843 --> 0.118634).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1021780\n",
      "\tspeed: 0.0393s/iter; left time: 747.8991s\n",
      "\titers: 200, epoch: 16 | loss: 0.1010583\n",
      "\tspeed: 0.0175s/iter; left time: 331.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.1002135 Vali Loss: 0.1187289 Test Loss: 0.1263449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0969147\n",
      "\tspeed: 0.0383s/iter; left time: 720.5074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0948327\n",
      "\tspeed: 0.0190s/iter; left time: 354.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0999837 Vali Loss: 0.1188469 Test Loss: 0.1263028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0999236\n",
      "\tspeed: 0.0408s/iter; left time: 757.3810s\n",
      "\titers: 200, epoch: 18 | loss: 0.1040796\n",
      "\tspeed: 0.0207s/iter; left time: 382.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0998135 Vali Loss: 0.1189184 Test Loss: 0.1264344\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1023207\n",
      "\tspeed: 0.0381s/iter; left time: 700.0582s\n",
      "\titers: 200, epoch: 19 | loss: 0.0959595\n",
      "\tspeed: 0.0178s/iter; left time: 324.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0996949 Vali Loss: 0.1189701 Test Loss: 0.1262245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1043485\n",
      "\tspeed: 0.0417s/iter; left time: 756.0298s\n",
      "\titers: 200, epoch: 20 | loss: 0.1012136\n",
      "\tspeed: 0.0221s/iter; left time: 397.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0996269 Vali Loss: 0.1188949 Test Loss: 0.1261493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1007755\n",
      "\tspeed: 0.0402s/iter; left time: 719.6723s\n",
      "\titers: 200, epoch: 21 | loss: 0.0938013\n",
      "\tspeed: 0.0220s/iter; left time: 391.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0994555 Vali Loss: 0.1189866 Test Loss: 0.1263751\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0992515\n",
      "\tspeed: 0.0428s/iter; left time: 757.0956s\n",
      "\titers: 200, epoch: 22 | loss: 0.0981303\n",
      "\tspeed: 0.0226s/iter; left time: 396.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 225 | Train Loss: 0.0994021 Vali Loss: 0.1189413 Test Loss: 0.1262374\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1014347\n",
      "\tspeed: 0.0444s/iter; left time: 774.2949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0944737\n",
      "\tspeed: 0.0205s/iter; left time: 355.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 225 | Train Loss: 0.0993091 Vali Loss: 0.1188072 Test Loss: 0.1261979\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1021972\n",
      "\tspeed: 0.0403s/iter; left time: 693.4551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0987332\n",
      "\tspeed: 0.0200s/iter; left time: 341.7360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0991928 Vali Loss: 0.1189013 Test Loss: 0.1264363\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1018750\n",
      "\tspeed: 0.0399s/iter; left time: 677.8940s\n",
      "\titers: 200, epoch: 25 | loss: 0.0972224\n",
      "\tspeed: 0.0192s/iter; left time: 323.9625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0991676 Vali Loss: 0.1189413 Test Loss: 0.1262479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03709335997700691, rmse:0.19259636104106903, mae:0.1265867054462433, rse:0.6820226311683655\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:29.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1597681\n",
      "\tspeed: 0.0421s/iter; left time: 943.7567s\n",
      "\titers: 200, epoch: 1 | loss: 0.1394441\n",
      "\tspeed: 0.0154s/iter; left time: 343.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1611064 Vali Loss: 0.1516039 Test Loss: 0.1655859\n",
      "Validation loss decreased (inf --> 0.151604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1293734\n",
      "\tspeed: 0.0379s/iter; left time: 840.5527s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188756\n",
      "\tspeed: 0.0184s/iter; left time: 406.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1250985 Vali Loss: 0.1289203 Test Loss: 0.1402800\n",
      "Validation loss decreased (0.151604 --> 0.128920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1157258\n",
      "\tspeed: 0.0392s/iter; left time: 860.6975s\n",
      "\titers: 200, epoch: 3 | loss: 0.1150265\n",
      "\tspeed: 0.0159s/iter; left time: 347.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.1154583 Vali Loss: 0.1264038 Test Loss: 0.1374858\n",
      "Validation loss decreased (0.128920 --> 0.126404).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1165608\n",
      "\tspeed: 0.0366s/iter; left time: 794.8849s\n",
      "\titers: 200, epoch: 4 | loss: 0.1122621\n",
      "\tspeed: 0.0181s/iter; left time: 390.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1130506 Vali Loss: 0.1259780 Test Loss: 0.1365361\n",
      "Validation loss decreased (0.126404 --> 0.125978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1151247\n",
      "\tspeed: 0.0390s/iter; left time: 839.4699s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071975\n",
      "\tspeed: 0.0179s/iter; left time: 382.5318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1116234 Vali Loss: 0.1258907 Test Loss: 0.1366494\n",
      "Validation loss decreased (0.125978 --> 0.125891).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089182\n",
      "\tspeed: 0.0355s/iter; left time: 756.0827s\n",
      "\titers: 200, epoch: 6 | loss: 0.1135221\n",
      "\tspeed: 0.0168s/iter; left time: 356.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.1107035 Vali Loss: 0.1255296 Test Loss: 0.1358035\n",
      "Validation loss decreased (0.125891 --> 0.125530).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1117654\n",
      "\tspeed: 0.0397s/iter; left time: 836.1848s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075306\n",
      "\tspeed: 0.0192s/iter; left time: 402.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1099964 Vali Loss: 0.1253670 Test Loss: 0.1351608\n",
      "Validation loss decreased (0.125530 --> 0.125367).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1033830\n",
      "\tspeed: 0.0366s/iter; left time: 762.8314s\n",
      "\titers: 200, epoch: 8 | loss: 0.1089234\n",
      "\tspeed: 0.0152s/iter; left time: 314.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.1094158 Vali Loss: 0.1254329 Test Loss: 0.1354677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1109020\n",
      "\tspeed: 0.0346s/iter; left time: 713.4664s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085580\n",
      "\tspeed: 0.0153s/iter; left time: 314.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1089027 Vali Loss: 0.1248833 Test Loss: 0.1352038\n",
      "Validation loss decreased (0.125367 --> 0.124883).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067005\n",
      "\tspeed: 0.0356s/iter; left time: 725.6138s\n",
      "\titers: 200, epoch: 10 | loss: 0.1039695\n",
      "\tspeed: 0.0151s/iter; left time: 307.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1085350 Vali Loss: 0.1246719 Test Loss: 0.1349904\n",
      "Validation loss decreased (0.124883 --> 0.124672).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1060302\n",
      "\tspeed: 0.0401s/iter; left time: 807.2325s\n",
      "\titers: 200, epoch: 11 | loss: 0.1044329\n",
      "\tspeed: 0.0174s/iter; left time: 348.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.1080497 Vali Loss: 0.1248863 Test Loss: 0.1353544\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1098358\n",
      "\tspeed: 0.0364s/iter; left time: 724.6957s\n",
      "\titers: 200, epoch: 12 | loss: 0.1077055\n",
      "\tspeed: 0.0151s/iter; left time: 300.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1078033 Vali Loss: 0.1247643 Test Loss: 0.1351484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1063721\n",
      "\tspeed: 0.0377s/iter; left time: 743.4401s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019878\n",
      "\tspeed: 0.0190s/iter; left time: 372.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1074929 Vali Loss: 0.1244314 Test Loss: 0.1348955\n",
      "Validation loss decreased (0.124672 --> 0.124431).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1112889\n",
      "\tspeed: 0.0405s/iter; left time: 788.4218s\n",
      "\titers: 200, epoch: 14 | loss: 0.1100490\n",
      "\tspeed: 0.0160s/iter; left time: 309.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.1072949 Vali Loss: 0.1246140 Test Loss: 0.1347168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1048008\n",
      "\tspeed: 0.0356s/iter; left time: 686.2853s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065564\n",
      "\tspeed: 0.0168s/iter; left time: 321.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.1069529 Vali Loss: 0.1243602 Test Loss: 0.1350712\n",
      "Validation loss decreased (0.124431 --> 0.124360).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1137868\n",
      "\tspeed: 0.0366s/iter; left time: 696.4361s\n",
      "\titers: 200, epoch: 16 | loss: 0.1119398\n",
      "\tspeed: 0.0190s/iter; left time: 358.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.1068381 Vali Loss: 0.1244992 Test Loss: 0.1346245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1088810\n",
      "\tspeed: 0.0338s/iter; left time: 634.5856s\n",
      "\titers: 200, epoch: 17 | loss: 0.1117870\n",
      "\tspeed: 0.0153s/iter; left time: 286.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.1066407 Vali Loss: 0.1241617 Test Loss: 0.1347925\n",
      "Validation loss decreased (0.124360 --> 0.124162).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1037163\n",
      "\tspeed: 0.0382s/iter; left time: 710.1916s\n",
      "\titers: 200, epoch: 18 | loss: 0.1055945\n",
      "\tspeed: 0.0151s/iter; left time: 279.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1065037 Vali Loss: 0.1244145 Test Loss: 0.1348231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1053035\n",
      "\tspeed: 0.0340s/iter; left time: 624.7087s\n",
      "\titers: 200, epoch: 19 | loss: 0.1099117\n",
      "\tspeed: 0.0151s/iter; left time: 275.6109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.1063549 Vali Loss: 0.1242019 Test Loss: 0.1347113\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073127\n",
      "\tspeed: 0.0361s/iter; left time: 654.6316s\n",
      "\titers: 200, epoch: 20 | loss: 0.1123709\n",
      "\tspeed: 0.0172s/iter; left time: 309.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.1063023 Vali Loss: 0.1241778 Test Loss: 0.1349964\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1037868\n",
      "\tspeed: 0.0403s/iter; left time: 721.5322s\n",
      "\titers: 200, epoch: 21 | loss: 0.1039041\n",
      "\tspeed: 0.0181s/iter; left time: 323.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.1061470 Vali Loss: 0.1238399 Test Loss: 0.1348939\n",
      "Validation loss decreased (0.124162 --> 0.123840).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1074208\n",
      "\tspeed: 0.0352s/iter; left time: 622.4051s\n",
      "\titers: 200, epoch: 22 | loss: 0.1065059\n",
      "\tspeed: 0.0153s/iter; left time: 268.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.1060402 Vali Loss: 0.1240012 Test Loss: 0.1350031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1067464\n",
      "\tspeed: 0.0396s/iter; left time: 690.8393s\n",
      "\titers: 200, epoch: 23 | loss: 0.0995105\n",
      "\tspeed: 0.0173s/iter; left time: 300.5072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.1059790 Vali Loss: 0.1240508 Test Loss: 0.1347556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1051342\n",
      "\tspeed: 0.0373s/iter; left time: 643.2248s\n",
      "\titers: 200, epoch: 24 | loss: 0.1061060\n",
      "\tspeed: 0.0180s/iter; left time: 307.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.1058389 Vali Loss: 0.1241084 Test Loss: 0.1347512\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1040247\n",
      "\tspeed: 0.0346s/iter; left time: 587.8989s\n",
      "\titers: 200, epoch: 25 | loss: 0.1066597\n",
      "\tspeed: 0.0158s/iter; left time: 267.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.1057603 Vali Loss: 0.1238703 Test Loss: 0.1346270\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1043022\n",
      "\tspeed: 0.0344s/iter; left time: 576.4309s\n",
      "\titers: 200, epoch: 26 | loss: 0.1011586\n",
      "\tspeed: 0.0165s/iter; left time: 275.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.1057232 Vali Loss: 0.1242573 Test Loss: 0.1348052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1044532\n",
      "\tspeed: 0.0364s/iter; left time: 602.3999s\n",
      "\titers: 200, epoch: 27 | loss: 0.1077922\n",
      "\tspeed: 0.0170s/iter; left time: 279.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1056584 Vali Loss: 0.1239977 Test Loss: 0.1347191\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1062665\n",
      "\tspeed: 0.0378s/iter; left time: 617.5555s\n",
      "\titers: 200, epoch: 28 | loss: 0.1054133\n",
      "\tspeed: 0.0202s/iter; left time: 327.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.1055746 Vali Loss: 0.1241290 Test Loss: 0.1347836\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1068603\n",
      "\tspeed: 0.0393s/iter; left time: 633.2472s\n",
      "\titers: 200, epoch: 29 | loss: 0.1053896\n",
      "\tspeed: 0.0175s/iter; left time: 279.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1055822 Vali Loss: 0.1239924 Test Loss: 0.1348849\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1037724\n",
      "\tspeed: 0.0382s/iter; left time: 606.1204s\n",
      "\titers: 200, epoch: 30 | loss: 0.1117676\n",
      "\tspeed: 0.0187s/iter; left time: 294.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.1054864 Vali Loss: 0.1239919 Test Loss: 0.1348824\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1049670\n",
      "\tspeed: 0.0378s/iter; left time: 591.6000s\n",
      "\titers: 200, epoch: 31 | loss: 0.1072682\n",
      "\tspeed: 0.0175s/iter; left time: 271.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.1054962 Vali Loss: 0.1241026 Test Loss: 0.1347783\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04131152108311653, rmse:0.20325236022472382, mae:0.13489389419555664, rse:0.719936192035675\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1629653\n",
      "\tspeed: 0.0174s/iter; left time: 390.6402s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467177\n",
      "\tspeed: 0.0153s/iter; left time: 341.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.1603462 Vali Loss: 0.1508472 Test Loss: 0.1646355\n",
      "Validation loss decreased (inf --> 0.150847).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1300881\n",
      "\tspeed: 0.0398s/iter; left time: 881.5142s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143041\n",
      "\tspeed: 0.0183s/iter; left time: 403.2012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.1242376 Vali Loss: 0.1294085 Test Loss: 0.1407559\n",
      "Validation loss decreased (0.150847 --> 0.129408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1186319\n",
      "\tspeed: 0.0381s/iter; left time: 836.7470s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203104\n",
      "\tspeed: 0.0162s/iter; left time: 354.0128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.1154474 Vali Loss: 0.1263371 Test Loss: 0.1371361\n",
      "Validation loss decreased (0.129408 --> 0.126337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1122255\n",
      "\tspeed: 0.0392s/iter; left time: 850.7349s\n",
      "\titers: 200, epoch: 4 | loss: 0.1088989\n",
      "\tspeed: 0.0171s/iter; left time: 369.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1131376 Vali Loss: 0.1253243 Test Loss: 0.1361789\n",
      "Validation loss decreased (0.126337 --> 0.125324).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1083760\n",
      "\tspeed: 0.0381s/iter; left time: 819.0103s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178844\n",
      "\tspeed: 0.0205s/iter; left time: 438.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.1117257 Vali Loss: 0.1248998 Test Loss: 0.1352501\n",
      "Validation loss decreased (0.125324 --> 0.124900).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139530\n",
      "\tspeed: 0.0383s/iter; left time: 813.9864s\n",
      "\titers: 200, epoch: 6 | loss: 0.1064244\n",
      "\tspeed: 0.0166s/iter; left time: 351.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1107475 Vali Loss: 0.1244106 Test Loss: 0.1347651\n",
      "Validation loss decreased (0.124900 --> 0.124411).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1151732\n",
      "\tspeed: 0.0393s/iter; left time: 826.2979s\n",
      "\titers: 200, epoch: 7 | loss: 0.1072712\n",
      "\tspeed: 0.0187s/iter; left time: 392.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1100969 Vali Loss: 0.1244932 Test Loss: 0.1351271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1128722\n",
      "\tspeed: 0.0398s/iter; left time: 829.2852s\n",
      "\titers: 200, epoch: 8 | loss: 0.1057848\n",
      "\tspeed: 0.0178s/iter; left time: 369.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.1094682 Vali Loss: 0.1239749 Test Loss: 0.1349620\n",
      "Validation loss decreased (0.124411 --> 0.123975).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1162132\n",
      "\tspeed: 0.0348s/iter; left time: 717.1068s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069723\n",
      "\tspeed: 0.0151s/iter; left time: 309.5633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1089953 Vali Loss: 0.1242746 Test Loss: 0.1343836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1074245\n",
      "\tspeed: 0.0359s/iter; left time: 730.6829s\n",
      "\titers: 200, epoch: 10 | loss: 0.1146695\n",
      "\tspeed: 0.0169s/iter; left time: 342.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.1085315 Vali Loss: 0.1246715 Test Loss: 0.1342424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1077108\n",
      "\tspeed: 0.0390s/iter; left time: 785.0145s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067131\n",
      "\tspeed: 0.0204s/iter; left time: 408.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 225 | Train Loss: 0.1081504 Vali Loss: 0.1237239 Test Loss: 0.1338762\n",
      "Validation loss decreased (0.123975 --> 0.123724).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066032\n",
      "\tspeed: 0.0405s/iter; left time: 806.9693s\n",
      "\titers: 200, epoch: 12 | loss: 0.1069852\n",
      "\tspeed: 0.0188s/iter; left time: 372.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.1077525 Vali Loss: 0.1240567 Test Loss: 0.1340794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1074472\n",
      "\tspeed: 0.0397s/iter; left time: 781.6063s\n",
      "\titers: 200, epoch: 13 | loss: 0.1039106\n",
      "\tspeed: 0.0193s/iter; left time: 377.6317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.1074885 Vali Loss: 0.1241955 Test Loss: 0.1341534\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1025117\n",
      "\tspeed: 0.0398s/iter; left time: 774.9892s\n",
      "\titers: 200, epoch: 14 | loss: 0.1067264\n",
      "\tspeed: 0.0196s/iter; left time: 380.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1072166 Vali Loss: 0.1242939 Test Loss: 0.1342657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1097217\n",
      "\tspeed: 0.0397s/iter; left time: 765.1856s\n",
      "\titers: 200, epoch: 15 | loss: 0.1035928\n",
      "\tspeed: 0.0197s/iter; left time: 376.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1069498 Vali Loss: 0.1239720 Test Loss: 0.1343582\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067876\n",
      "\tspeed: 0.0413s/iter; left time: 786.6408s\n",
      "\titers: 200, epoch: 16 | loss: 0.1109241\n",
      "\tspeed: 0.0182s/iter; left time: 345.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.1067773 Vali Loss: 0.1238592 Test Loss: 0.1337989\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1054149\n",
      "\tspeed: 0.0402s/iter; left time: 756.4454s\n",
      "\titers: 200, epoch: 17 | loss: 0.1046284\n",
      "\tspeed: 0.0204s/iter; left time: 380.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.1066017 Vali Loss: 0.1241902 Test Loss: 0.1340709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1064189\n",
      "\tspeed: 0.0413s/iter; left time: 766.7903s\n",
      "\titers: 200, epoch: 18 | loss: 0.1059560\n",
      "\tspeed: 0.0199s/iter; left time: 367.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1064438 Vali Loss: 0.1239474 Test Loss: 0.1339504\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1021350\n",
      "\tspeed: 0.0418s/iter; left time: 766.4911s\n",
      "\titers: 200, epoch: 19 | loss: 0.1146571\n",
      "\tspeed: 0.0191s/iter; left time: 348.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1062876 Vali Loss: 0.1241477 Test Loss: 0.1338608\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1086384\n",
      "\tspeed: 0.0393s/iter; left time: 712.8210s\n",
      "\titers: 200, epoch: 20 | loss: 0.1046049\n",
      "\tspeed: 0.0210s/iter; left time: 377.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.1061432 Vali Loss: 0.1240658 Test Loss: 0.1340669\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1032892\n",
      "\tspeed: 0.0414s/iter; left time: 741.2086s\n",
      "\titers: 200, epoch: 21 | loss: 0.1053182\n",
      "\tspeed: 0.0173s/iter; left time: 308.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.1060186 Vali Loss: 0.1244103 Test Loss: 0.1343777\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04032425582408905, rmse:0.20080900192260742, mae:0.13387621939182281, rse:0.7112816572189331\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:01.35s\n",
      "Intermediate time for DE: 00h:20m:42.10s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1348012\n",
      "\tspeed: 0.0432s/iter; left time: 971.5674s\n",
      "\titers: 200, epoch: 1 | loss: 0.1199800\n",
      "\tspeed: 0.0147s/iter; left time: 330.1381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.1358073 Vali Loss: 0.1256861 Test Loss: 0.1465730\n",
      "Validation loss decreased (inf --> 0.125686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0842726\n",
      "\tspeed: 0.0326s/iter; left time: 725.8451s\n",
      "\titers: 200, epoch: 2 | loss: 0.0801193\n",
      "\tspeed: 0.0165s/iter; left time: 366.0726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0878881 Vali Loss: 0.0922427 Test Loss: 0.1037492\n",
      "Validation loss decreased (0.125686 --> 0.092243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0849407\n",
      "\tspeed: 0.0333s/iter; left time: 735.1307s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829507\n",
      "\tspeed: 0.0208s/iter; left time: 455.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0802817 Vali Loss: 0.0916280 Test Loss: 0.1027605\n",
      "Validation loss decreased (0.092243 --> 0.091628).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0824983\n",
      "\tspeed: 0.0341s/iter; left time: 744.3155s\n",
      "\titers: 200, epoch: 4 | loss: 0.0778295\n",
      "\tspeed: 0.0148s/iter; left time: 322.3088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0787315 Vali Loss: 0.0912857 Test Loss: 0.1020525\n",
      "Validation loss decreased (0.091628 --> 0.091286).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0771139\n",
      "\tspeed: 0.0323s/iter; left time: 696.5428s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828588\n",
      "\tspeed: 0.0150s/iter; left time: 323.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0778978 Vali Loss: 0.0906263 Test Loss: 0.1016233\n",
      "Validation loss decreased (0.091286 --> 0.090626).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730026\n",
      "\tspeed: 0.0334s/iter; left time: 714.6117s\n",
      "\titers: 200, epoch: 6 | loss: 0.0768275\n",
      "\tspeed: 0.0152s/iter; left time: 324.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0771877 Vali Loss: 0.0897547 Test Loss: 0.1013267\n",
      "Validation loss decreased (0.090626 --> 0.089755).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764931\n",
      "\tspeed: 0.0334s/iter; left time: 705.6211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729029\n",
      "\tspeed: 0.0151s/iter; left time: 317.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0767380 Vali Loss: 0.0894999 Test Loss: 0.1012439\n",
      "Validation loss decreased (0.089755 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740525\n",
      "\tspeed: 0.0340s/iter; left time: 711.5861s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767735\n",
      "\tspeed: 0.0153s/iter; left time: 319.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0764164 Vali Loss: 0.0896466 Test Loss: 0.1009590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774673\n",
      "\tspeed: 0.0337s/iter; left time: 697.6230s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760660\n",
      "\tspeed: 0.0161s/iter; left time: 330.7182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0760536 Vali Loss: 0.0890659 Test Loss: 0.1009193\n",
      "Validation loss decreased (0.089500 --> 0.089066).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0732044\n",
      "\tspeed: 0.0340s/iter; left time: 694.9415s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767341\n",
      "\tspeed: 0.0172s/iter; left time: 349.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0757877 Vali Loss: 0.0891886 Test Loss: 0.1009441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0825395\n",
      "\tspeed: 0.0343s/iter; left time: 694.4001s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761485\n",
      "\tspeed: 0.0157s/iter; left time: 317.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0755504 Vali Loss: 0.0890318 Test Loss: 0.1007226\n",
      "Validation loss decreased (0.089066 --> 0.089032).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0742803\n",
      "\tspeed: 0.0315s/iter; left time: 629.9250s\n",
      "\titers: 200, epoch: 12 | loss: 0.0833599\n",
      "\tspeed: 0.0147s/iter; left time: 293.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0753169 Vali Loss: 0.0888209 Test Loss: 0.1007950\n",
      "Validation loss decreased (0.089032 --> 0.088821).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688437\n",
      "\tspeed: 0.0332s/iter; left time: 656.0625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757275\n",
      "\tspeed: 0.0163s/iter; left time: 321.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0752007 Vali Loss: 0.0886280 Test Loss: 0.1005576\n",
      "Validation loss decreased (0.088821 --> 0.088628).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754868\n",
      "\tspeed: 0.0337s/iter; left time: 658.6997s\n",
      "\titers: 200, epoch: 14 | loss: 0.0743996\n",
      "\tspeed: 0.0151s/iter; left time: 293.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0750082 Vali Loss: 0.0888044 Test Loss: 0.1005008\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776850\n",
      "\tspeed: 0.0347s/iter; left time: 670.9982s\n",
      "\titers: 200, epoch: 15 | loss: 0.0746924\n",
      "\tspeed: 0.0162s/iter; left time: 310.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0748108 Vali Loss: 0.0884927 Test Loss: 0.1003191\n",
      "Validation loss decreased (0.088628 --> 0.088493).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0747475\n",
      "\tspeed: 0.0347s/iter; left time: 663.5982s\n",
      "\titers: 200, epoch: 16 | loss: 0.0749063\n",
      "\tspeed: 0.0154s/iter; left time: 292.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0747405 Vali Loss: 0.0885689 Test Loss: 0.1004213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733430\n",
      "\tspeed: 0.0335s/iter; left time: 632.4483s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734850\n",
      "\tspeed: 0.0151s/iter; left time: 284.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0746306 Vali Loss: 0.0886222 Test Loss: 0.1004618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729925\n",
      "\tspeed: 0.0397s/iter; left time: 740.4525s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748200\n",
      "\tspeed: 0.0215s/iter; left time: 398.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 226 | Train Loss: 0.0745408 Vali Loss: 0.0885219 Test Loss: 0.1001322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0740487\n",
      "\tspeed: 0.0393s/iter; left time: 724.6756s\n",
      "\titers: 200, epoch: 19 | loss: 0.0761470\n",
      "\tspeed: 0.0199s/iter; left time: 364.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0743890 Vali Loss: 0.0884069 Test Loss: 0.1004253\n",
      "Validation loss decreased (0.088493 --> 0.088407).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804507\n",
      "\tspeed: 0.0347s/iter; left time: 632.2010s\n",
      "\titers: 200, epoch: 20 | loss: 0.0757066\n",
      "\tspeed: 0.0176s/iter; left time: 318.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0743674 Vali Loss: 0.0885054 Test Loss: 0.1000969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0756700\n",
      "\tspeed: 0.0364s/iter; left time: 654.9323s\n",
      "\titers: 200, epoch: 21 | loss: 0.0785028\n",
      "\tspeed: 0.0168s/iter; left time: 301.1972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0743069 Vali Loss: 0.0886169 Test Loss: 0.1004365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0687134\n",
      "\tspeed: 0.0375s/iter; left time: 665.8023s\n",
      "\titers: 200, epoch: 22 | loss: 0.0773262\n",
      "\tspeed: 0.0215s/iter; left time: 378.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 226 | Train Loss: 0.0742749 Vali Loss: 0.0883453 Test Loss: 0.1002563\n",
      "Validation loss decreased (0.088407 --> 0.088345).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0707392\n",
      "\tspeed: 0.0365s/iter; left time: 639.1904s\n",
      "\titers: 200, epoch: 23 | loss: 0.0712351\n",
      "\tspeed: 0.0173s/iter; left time: 301.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0741822 Vali Loss: 0.0882935 Test Loss: 0.1002856\n",
      "Validation loss decreased (0.088345 --> 0.088293).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0738477\n",
      "\tspeed: 0.0387s/iter; left time: 668.9220s\n",
      "\titers: 200, epoch: 24 | loss: 0.0728533\n",
      "\tspeed: 0.0195s/iter; left time: 335.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0740945 Vali Loss: 0.0883293 Test Loss: 0.1002986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0715703\n",
      "\tspeed: 0.0371s/iter; left time: 633.0545s\n",
      "\titers: 200, epoch: 25 | loss: 0.0675489\n",
      "\tspeed: 0.0195s/iter; left time: 331.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0740816 Vali Loss: 0.0881852 Test Loss: 0.1001899\n",
      "Validation loss decreased (0.088293 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0774840\n",
      "\tspeed: 0.0330s/iter; left time: 555.7904s\n",
      "\titers: 200, epoch: 26 | loss: 0.0691603\n",
      "\tspeed: 0.0156s/iter; left time: 260.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0740570 Vali Loss: 0.0882801 Test Loss: 0.1002105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0784263\n",
      "\tspeed: 0.0337s/iter; left time: 560.2220s\n",
      "\titers: 200, epoch: 27 | loss: 0.0770142\n",
      "\tspeed: 0.0158s/iter; left time: 261.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0740176 Vali Loss: 0.0882419 Test Loss: 0.1001402\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708968\n",
      "\tspeed: 0.0385s/iter; left time: 630.6580s\n",
      "\titers: 200, epoch: 28 | loss: 0.0749423\n",
      "\tspeed: 0.0202s/iter; left time: 329.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0739662 Vali Loss: 0.0882251 Test Loss: 0.1001193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744236\n",
      "\tspeed: 0.0379s/iter; left time: 613.4823s\n",
      "\titers: 200, epoch: 29 | loss: 0.0747024\n",
      "\tspeed: 0.0193s/iter; left time: 309.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0739222 Vali Loss: 0.0881882 Test Loss: 0.1000275\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0714746\n",
      "\tspeed: 0.0341s/iter; left time: 544.5706s\n",
      "\titers: 200, epoch: 30 | loss: 0.0766074\n",
      "\tspeed: 0.0169s/iter; left time: 268.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0739116 Vali Loss: 0.0882050 Test Loss: 0.1001214\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0727411\n",
      "\tspeed: 0.0325s/iter; left time: 510.4227s\n",
      "\titers: 200, epoch: 31 | loss: 0.0782608\n",
      "\tspeed: 0.0148s/iter; left time: 231.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0738956 Vali Loss: 0.0881337 Test Loss: 0.1001574\n",
      "Validation loss decreased (0.088185 --> 0.088134).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0693213\n",
      "\tspeed: 0.0345s/iter; left time: 535.1526s\n",
      "\titers: 200, epoch: 32 | loss: 0.0733726\n",
      "\tspeed: 0.0147s/iter; left time: 227.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0739038 Vali Loss: 0.0881182 Test Loss: 0.1001412\n",
      "Validation loss decreased (0.088134 --> 0.088118).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0727043\n",
      "\tspeed: 0.0332s/iter; left time: 507.4772s\n",
      "\titers: 200, epoch: 33 | loss: 0.0756064\n",
      "\tspeed: 0.0149s/iter; left time: 226.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0738486 Vali Loss: 0.0881378 Test Loss: 0.1001345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697464\n",
      "\tspeed: 0.0327s/iter; left time: 491.7849s\n",
      "\titers: 200, epoch: 34 | loss: 0.0767846\n",
      "\tspeed: 0.0152s/iter; left time: 227.8124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0738271 Vali Loss: 0.0880433 Test Loss: 0.1000919\n",
      "Validation loss decreased (0.088118 --> 0.088043).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0740372\n",
      "\tspeed: 0.0324s/iter; left time: 480.5610s\n",
      "\titers: 200, epoch: 35 | loss: 0.0748931\n",
      "\tspeed: 0.0150s/iter; left time: 221.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0737723 Vali Loss: 0.0881123 Test Loss: 0.1001010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0736170\n",
      "\tspeed: 0.0352s/iter; left time: 514.2756s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743167\n",
      "\tspeed: 0.0152s/iter; left time: 220.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0738238 Vali Loss: 0.0880142 Test Loss: 0.1001303\n",
      "Validation loss decreased (0.088043 --> 0.088014).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0735850\n",
      "\tspeed: 0.0364s/iter; left time: 522.8827s\n",
      "\titers: 200, epoch: 37 | loss: 0.0743387\n",
      "\tspeed: 0.0150s/iter; left time: 214.1146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 226 | Train Loss: 0.0738114 Vali Loss: 0.0880951 Test Loss: 0.1000949\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0743272\n",
      "\tspeed: 0.0326s/iter; left time: 460.5040s\n",
      "\titers: 200, epoch: 38 | loss: 0.0732567\n",
      "\tspeed: 0.0148s/iter; left time: 207.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0737474 Vali Loss: 0.0880771 Test Loss: 0.1000663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0693054\n",
      "\tspeed: 0.0360s/iter; left time: 500.4227s\n",
      "\titers: 200, epoch: 39 | loss: 0.0733643\n",
      "\tspeed: 0.0176s/iter; left time: 243.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0738039 Vali Loss: 0.0882132 Test Loss: 0.1000884\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0703399\n",
      "\tspeed: 0.0381s/iter; left time: 521.7610s\n",
      "\titers: 200, epoch: 40 | loss: 0.0768747\n",
      "\tspeed: 0.0187s/iter; left time: 254.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0737794 Vali Loss: 0.0880865 Test Loss: 0.1000977\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0724354\n",
      "\tspeed: 0.0356s/iter; left time: 479.7915s\n",
      "\titers: 200, epoch: 41 | loss: 0.0733097\n",
      "\tspeed: 0.0160s/iter; left time: 213.7762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0737165 Vali Loss: 0.0880635 Test Loss: 0.1001283\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0742350\n",
      "\tspeed: 0.0364s/iter; left time: 481.8759s\n",
      "\titers: 200, epoch: 42 | loss: 0.0694430\n",
      "\tspeed: 0.0147s/iter; left time: 192.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0737438 Vali Loss: 0.0880835 Test Loss: 0.1000885\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779440\n",
      "\tspeed: 0.0332s/iter; left time: 431.7426s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749396\n",
      "\tspeed: 0.0147s/iter; left time: 189.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0737518 Vali Loss: 0.0880366 Test Loss: 0.1000987\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0714604\n",
      "\tspeed: 0.0332s/iter; left time: 424.0469s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757622\n",
      "\tspeed: 0.0148s/iter; left time: 188.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0737035 Vali Loss: 0.0881269 Test Loss: 0.1000961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0767419\n",
      "\tspeed: 0.0358s/iter; left time: 449.1202s\n",
      "\titers: 200, epoch: 45 | loss: 0.0718795\n",
      "\tspeed: 0.0192s/iter; left time: 239.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0737914 Vali Loss: 0.0881576 Test Loss: 0.1000799\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0765565\n",
      "\tspeed: 0.0342s/iter; left time: 422.1977s\n",
      "\titers: 200, epoch: 46 | loss: 0.0712216\n",
      "\tspeed: 0.0148s/iter; left time: 181.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0736830 Vali Loss: 0.0880687 Test Loss: 0.1001025\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025458605960011482, rmse:0.1595575362443924, mae:0.1001303642988205, rse:0.5504282712936401\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1299379\n",
      "\tspeed: 0.0211s/iter; left time: 475.0637s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275410\n",
      "\tspeed: 0.0149s/iter; left time: 334.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.1308100 Vali Loss: 0.1222478 Test Loss: 0.1417705\n",
      "Validation loss decreased (inf --> 0.122248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0886318\n",
      "\tspeed: 0.0346s/iter; left time: 769.9040s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795489\n",
      "\tspeed: 0.0147s/iter; left time: 326.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0874953 Vali Loss: 0.0923675 Test Loss: 0.1036771\n",
      "Validation loss decreased (0.122248 --> 0.092367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0793882\n",
      "\tspeed: 0.0359s/iter; left time: 791.0130s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739622\n",
      "\tspeed: 0.0155s/iter; left time: 341.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0803336 Vali Loss: 0.0912035 Test Loss: 0.1025618\n",
      "Validation loss decreased (0.092367 --> 0.091204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770089\n",
      "\tspeed: 0.0349s/iter; left time: 762.1679s\n",
      "\titers: 200, epoch: 4 | loss: 0.0781828\n",
      "\tspeed: 0.0168s/iter; left time: 365.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0788796 Vali Loss: 0.0909087 Test Loss: 0.1021345\n",
      "Validation loss decreased (0.091204 --> 0.090909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836506\n",
      "\tspeed: 0.0358s/iter; left time: 772.5072s\n",
      "\titers: 200, epoch: 5 | loss: 0.0713013\n",
      "\tspeed: 0.0164s/iter; left time: 351.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0779398 Vali Loss: 0.0901915 Test Loss: 0.1018874\n",
      "Validation loss decreased (0.090909 --> 0.090192).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814649\n",
      "\tspeed: 0.0365s/iter; left time: 779.4728s\n",
      "\titers: 200, epoch: 6 | loss: 0.0717318\n",
      "\tspeed: 0.0152s/iter; left time: 323.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0774009 Vali Loss: 0.0898792 Test Loss: 0.1014808\n",
      "Validation loss decreased (0.090192 --> 0.089879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731443\n",
      "\tspeed: 0.0381s/iter; left time: 806.6344s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849989\n",
      "\tspeed: 0.0211s/iter; left time: 445.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0768103 Vali Loss: 0.0896169 Test Loss: 0.1012145\n",
      "Validation loss decreased (0.089879 --> 0.089617).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767947\n",
      "\tspeed: 0.0367s/iter; left time: 766.7318s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805392\n",
      "\tspeed: 0.0162s/iter; left time: 337.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.0764402 Vali Loss: 0.0894719 Test Loss: 0.1012099\n",
      "Validation loss decreased (0.089617 --> 0.089472).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0757468\n",
      "\tspeed: 0.0379s/iter; left time: 783.9103s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773815\n",
      "\tspeed: 0.0207s/iter; left time: 425.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0761080 Vali Loss: 0.0896265 Test Loss: 0.1009124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0765713\n",
      "\tspeed: 0.0390s/iter; left time: 798.4415s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686516\n",
      "\tspeed: 0.0203s/iter; left time: 414.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0758771 Vali Loss: 0.0890902 Test Loss: 0.1008138\n",
      "Validation loss decreased (0.089472 --> 0.089090).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744935\n",
      "\tspeed: 0.0357s/iter; left time: 722.1835s\n",
      "\titers: 200, epoch: 11 | loss: 0.0698684\n",
      "\tspeed: 0.0150s/iter; left time: 302.8401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0755856 Vali Loss: 0.0890289 Test Loss: 0.1007839\n",
      "Validation loss decreased (0.089090 --> 0.089029).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0681625\n",
      "\tspeed: 0.0353s/iter; left time: 705.6890s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767795\n",
      "\tspeed: 0.0165s/iter; left time: 328.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0753697 Vali Loss: 0.0887901 Test Loss: 0.1009245\n",
      "Validation loss decreased (0.089029 --> 0.088790).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727203\n",
      "\tspeed: 0.0346s/iter; left time: 685.5272s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751047\n",
      "\tspeed: 0.0151s/iter; left time: 298.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0752134 Vali Loss: 0.0887878 Test Loss: 0.1005532\n",
      "Validation loss decreased (0.088790 --> 0.088788).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0849499\n",
      "\tspeed: 0.0327s/iter; left time: 640.0149s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722159\n",
      "\tspeed: 0.0147s/iter; left time: 286.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0749800 Vali Loss: 0.0888784 Test Loss: 0.1003572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731766\n",
      "\tspeed: 0.0316s/iter; left time: 611.8467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0795646\n",
      "\tspeed: 0.0148s/iter; left time: 285.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0748853 Vali Loss: 0.0886995 Test Loss: 0.1003053\n",
      "Validation loss decreased (0.088788 --> 0.088700).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0797883\n",
      "\tspeed: 0.0378s/iter; left time: 722.9744s\n",
      "\titers: 200, epoch: 16 | loss: 0.0785311\n",
      "\tspeed: 0.0166s/iter; left time: 315.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0747140 Vali Loss: 0.0885486 Test Loss: 0.1003760\n",
      "Validation loss decreased (0.088700 --> 0.088549).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766100\n",
      "\tspeed: 0.0390s/iter; left time: 735.8959s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713198\n",
      "\tspeed: 0.0155s/iter; left time: 290.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0745887 Vali Loss: 0.0883946 Test Loss: 0.1003597\n",
      "Validation loss decreased (0.088549 --> 0.088395).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0718078\n",
      "\tspeed: 0.0355s/iter; left time: 661.6344s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747818\n",
      "\tspeed: 0.0149s/iter; left time: 277.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 226 | Train Loss: 0.0745034 Vali Loss: 0.0884246 Test Loss: 0.1004869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0739261\n",
      "\tspeed: 0.0328s/iter; left time: 604.6951s\n",
      "\titers: 200, epoch: 19 | loss: 0.0768519\n",
      "\tspeed: 0.0148s/iter; left time: 270.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0743887 Vali Loss: 0.0882176 Test Loss: 0.1004880\n",
      "Validation loss decreased (0.088395 --> 0.088218).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724575\n",
      "\tspeed: 0.0351s/iter; left time: 639.6548s\n",
      "\titers: 200, epoch: 20 | loss: 0.0703330\n",
      "\tspeed: 0.0179s/iter; left time: 323.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0742888 Vali Loss: 0.0882550 Test Loss: 0.1003058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749832\n",
      "\tspeed: 0.0358s/iter; left time: 644.2972s\n",
      "\titers: 200, epoch: 21 | loss: 0.0722545\n",
      "\tspeed: 0.0168s/iter; left time: 300.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0742666 Vali Loss: 0.0883987 Test Loss: 0.1002589\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0743824\n",
      "\tspeed: 0.0380s/iter; left time: 675.0969s\n",
      "\titers: 200, epoch: 22 | loss: 0.0727077\n",
      "\tspeed: 0.0164s/iter; left time: 288.8293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0741849 Vali Loss: 0.0884717 Test Loss: 0.1003307\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725270\n",
      "\tspeed: 0.0364s/iter; left time: 638.3954s\n",
      "\titers: 200, epoch: 23 | loss: 0.0761230\n",
      "\tspeed: 0.0156s/iter; left time: 271.9287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0741284 Vali Loss: 0.0883142 Test Loss: 0.1002705\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0769574\n",
      "\tspeed: 0.0338s/iter; left time: 585.1179s\n",
      "\titers: 200, epoch: 24 | loss: 0.0711329\n",
      "\tspeed: 0.0149s/iter; left time: 255.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0740526 Vali Loss: 0.0882026 Test Loss: 0.1002394\n",
      "Validation loss decreased (0.088218 --> 0.088203).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785076\n",
      "\tspeed: 0.0363s/iter; left time: 619.5563s\n",
      "\titers: 200, epoch: 25 | loss: 0.0712431\n",
      "\tspeed: 0.0181s/iter; left time: 307.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0740483 Vali Loss: 0.0882465 Test Loss: 0.1003153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0716059\n",
      "\tspeed: 0.0335s/iter; left time: 564.3508s\n",
      "\titers: 200, epoch: 26 | loss: 0.0759152\n",
      "\tspeed: 0.0150s/iter; left time: 251.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0739681 Vali Loss: 0.0882726 Test Loss: 0.1000976\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0750724\n",
      "\tspeed: 0.0315s/iter; left time: 524.4293s\n",
      "\titers: 200, epoch: 27 | loss: 0.0754104\n",
      "\tspeed: 0.0148s/iter; left time: 243.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0739455 Vali Loss: 0.0881110 Test Loss: 0.1002562\n",
      "Validation loss decreased (0.088203 --> 0.088111).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0758224\n",
      "\tspeed: 0.0345s/iter; left time: 565.3009s\n",
      "\titers: 200, epoch: 28 | loss: 0.0766049\n",
      "\tspeed: 0.0178s/iter; left time: 289.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0739173 Vali Loss: 0.0882354 Test Loss: 0.1001683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0708620\n",
      "\tspeed: 0.0402s/iter; left time: 649.9362s\n",
      "\titers: 200, epoch: 29 | loss: 0.0762078\n",
      "\tspeed: 0.0217s/iter; left time: 349.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 226 | Train Loss: 0.0739167 Vali Loss: 0.0882121 Test Loss: 0.1001651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0749271\n",
      "\tspeed: 0.0420s/iter; left time: 670.2582s\n",
      "\titers: 200, epoch: 30 | loss: 0.0734478\n",
      "\tspeed: 0.0223s/iter; left time: 353.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 226 | Train Loss: 0.0738925 Vali Loss: 0.0882489 Test Loss: 0.1001061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0736174\n",
      "\tspeed: 0.0342s/iter; left time: 537.5242s\n",
      "\titers: 200, epoch: 31 | loss: 0.0758822\n",
      "\tspeed: 0.0151s/iter; left time: 235.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0738126 Vali Loss: 0.0881726 Test Loss: 0.1001027\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0762339\n",
      "\tspeed: 0.0348s/iter; left time: 539.2509s\n",
      "\titers: 200, epoch: 32 | loss: 0.0719958\n",
      "\tspeed: 0.0150s/iter; left time: 231.2703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.0738045 Vali Loss: 0.0881914 Test Loss: 0.1000991\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0720251\n",
      "\tspeed: 0.0324s/iter; left time: 494.9373s\n",
      "\titers: 200, epoch: 33 | loss: 0.0768513\n",
      "\tspeed: 0.0149s/iter; left time: 225.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0738133 Vali Loss: 0.0880187 Test Loss: 0.1001144\n",
      "Validation loss decreased (0.088111 --> 0.088019).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0787433\n",
      "\tspeed: 0.0383s/iter; left time: 576.7804s\n",
      "\titers: 200, epoch: 34 | loss: 0.0745010\n",
      "\tspeed: 0.0196s/iter; left time: 293.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0737879 Vali Loss: 0.0880583 Test Loss: 0.1001430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0743883\n",
      "\tspeed: 0.0329s/iter; left time: 488.0103s\n",
      "\titers: 200, epoch: 35 | loss: 0.0735667\n",
      "\tspeed: 0.0164s/iter; left time: 241.0911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0737276 Vali Loss: 0.0881054 Test Loss: 0.1001485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0694856\n",
      "\tspeed: 0.0350s/iter; left time: 509.9782s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743685\n",
      "\tspeed: 0.0155s/iter; left time: 224.3093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0737488 Vali Loss: 0.0881350 Test Loss: 0.1001791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0712377\n",
      "\tspeed: 0.0356s/iter; left time: 510.7199s\n",
      "\titers: 200, epoch: 37 | loss: 0.0748500\n",
      "\tspeed: 0.0184s/iter; left time: 262.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0737391 Vali Loss: 0.0880918 Test Loss: 0.1001669\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0725543\n",
      "\tspeed: 0.0372s/iter; left time: 525.7316s\n",
      "\titers: 200, epoch: 38 | loss: 0.0687990\n",
      "\tspeed: 0.0157s/iter; left time: 220.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0737394 Vali Loss: 0.0881696 Test Loss: 0.1001650\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0725478\n",
      "\tspeed: 0.0346s/iter; left time: 480.8865s\n",
      "\titers: 200, epoch: 39 | loss: 0.0692375\n",
      "\tspeed: 0.0193s/iter; left time: 266.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0736793 Vali Loss: 0.0880255 Test Loss: 0.1001555\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0699850\n",
      "\tspeed: 0.0391s/iter; left time: 535.3959s\n",
      "\titers: 200, epoch: 40 | loss: 0.0763473\n",
      "\tspeed: 0.0185s/iter; left time: 251.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0736832 Vali Loss: 0.0882237 Test Loss: 0.1001549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0755943\n",
      "\tspeed: 0.0406s/iter; left time: 546.5201s\n",
      "\titers: 200, epoch: 41 | loss: 0.0742840\n",
      "\tspeed: 0.0224s/iter; left time: 299.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 226 | Train Loss: 0.0736210 Vali Loss: 0.0880303 Test Loss: 0.1001531\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0724656\n",
      "\tspeed: 0.0352s/iter; left time: 466.5144s\n",
      "\titers: 200, epoch: 42 | loss: 0.0697383\n",
      "\tspeed: 0.0166s/iter; left time: 218.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0736599 Vali Loss: 0.0880839 Test Loss: 0.1001138\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0706227\n",
      "\tspeed: 0.0346s/iter; left time: 450.6407s\n",
      "\titers: 200, epoch: 43 | loss: 0.0782978\n",
      "\tspeed: 0.0196s/iter; left time: 252.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0736657 Vali Loss: 0.0880406 Test Loss: 0.1001322\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025257881730794907, rmse:0.1589272916316986, mae:0.10011441260576248, rse:0.5482540726661682\n",
      "Intermediate time for GB and pred_len 24: 00h:07m:55.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1432486\n",
      "\tspeed: 0.0433s/iter; left time: 969.2891s\n",
      "\titers: 200, epoch: 1 | loss: 0.1336714\n",
      "\tspeed: 0.0149s/iter; left time: 332.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1440825 Vali Loss: 0.1380730 Test Loss: 0.1636122\n",
      "Validation loss decreased (inf --> 0.138073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100838\n",
      "\tspeed: 0.0342s/iter; left time: 757.4684s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123376\n",
      "\tspeed: 0.0150s/iter; left time: 330.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1121373 Vali Loss: 0.1199572 Test Loss: 0.1431091\n",
      "Validation loss decreased (0.138073 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1075862\n",
      "\tspeed: 0.0347s/iter; left time: 760.6842s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033198\n",
      "\tspeed: 0.0152s/iter; left time: 331.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.1063111 Vali Loss: 0.1183126 Test Loss: 0.1420789\n",
      "Validation loss decreased (0.119957 --> 0.118313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1024592\n",
      "\tspeed: 0.0350s/iter; left time: 760.0231s\n",
      "\titers: 200, epoch: 4 | loss: 0.1038170\n",
      "\tspeed: 0.0190s/iter; left time: 410.6695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.1047231 Vali Loss: 0.1184994 Test Loss: 0.1432469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1062332\n",
      "\tspeed: 0.0384s/iter; left time: 825.9961s\n",
      "\titers: 200, epoch: 5 | loss: 0.1022250\n",
      "\tspeed: 0.0228s/iter; left time: 488.7446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.1038286 Vali Loss: 0.1181398 Test Loss: 0.1429648\n",
      "Validation loss decreased (0.118313 --> 0.118140).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1065187\n",
      "\tspeed: 0.0390s/iter; left time: 829.3336s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032488\n",
      "\tspeed: 0.0190s/iter; left time: 402.3874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1031733 Vali Loss: 0.1179559 Test Loss: 0.1427092\n",
      "Validation loss decreased (0.118140 --> 0.117956).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0992134\n",
      "\tspeed: 0.0424s/iter; left time: 892.8995s\n",
      "\titers: 200, epoch: 7 | loss: 0.1032226\n",
      "\tspeed: 0.0194s/iter; left time: 406.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.1026534 Vali Loss: 0.1179666 Test Loss: 0.1436215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001497\n",
      "\tspeed: 0.0335s/iter; left time: 697.4606s\n",
      "\titers: 200, epoch: 8 | loss: 0.1063705\n",
      "\tspeed: 0.0153s/iter; left time: 316.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.1021949 Vali Loss: 0.1178256 Test Loss: 0.1436705\n",
      "Validation loss decreased (0.117956 --> 0.117826).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1031673\n",
      "\tspeed: 0.0388s/iter; left time: 798.3675s\n",
      "\titers: 200, epoch: 9 | loss: 0.1014487\n",
      "\tspeed: 0.0200s/iter; left time: 409.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.1017360 Vali Loss: 0.1180316 Test Loss: 0.1442261\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037467\n",
      "\tspeed: 0.0386s/iter; left time: 786.9086s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027923\n",
      "\tspeed: 0.0177s/iter; left time: 358.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.1014511 Vali Loss: 0.1187993 Test Loss: 0.1454186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0971863\n",
      "\tspeed: 0.0350s/iter; left time: 706.0033s\n",
      "\titers: 200, epoch: 11 | loss: 0.1066962\n",
      "\tspeed: 0.0170s/iter; left time: 341.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1011792 Vali Loss: 0.1179904 Test Loss: 0.1447006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0974395\n",
      "\tspeed: 0.0364s/iter; left time: 724.5687s\n",
      "\titers: 200, epoch: 12 | loss: 0.1026871\n",
      "\tspeed: 0.0169s/iter; left time: 335.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1009035 Vali Loss: 0.1181274 Test Loss: 0.1444180\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988215\n",
      "\tspeed: 0.0365s/iter; left time: 720.0462s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990030\n",
      "\tspeed: 0.0156s/iter; left time: 304.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.1006301 Vali Loss: 0.1185747 Test Loss: 0.1452403\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1004764\n",
      "\tspeed: 0.0347s/iter; left time: 676.3641s\n",
      "\titers: 200, epoch: 14 | loss: 0.1026148\n",
      "\tspeed: 0.0189s/iter; left time: 365.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1004318 Vali Loss: 0.1184490 Test Loss: 0.1451024\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0977727\n",
      "\tspeed: 0.0344s/iter; left time: 661.6612s\n",
      "\titers: 200, epoch: 15 | loss: 0.0959741\n",
      "\tspeed: 0.0161s/iter; left time: 308.3490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1002692 Vali Loss: 0.1184843 Test Loss: 0.1451076\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0966277\n",
      "\tspeed: 0.0356s/iter; left time: 677.4609s\n",
      "\titers: 200, epoch: 16 | loss: 0.1025084\n",
      "\tspeed: 0.0174s/iter; left time: 328.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1000582 Vali Loss: 0.1184273 Test Loss: 0.1450801\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0983456\n",
      "\tspeed: 0.0350s/iter; left time: 657.3731s\n",
      "\titers: 200, epoch: 17 | loss: 0.0992725\n",
      "\tspeed: 0.0163s/iter; left time: 305.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0997954 Vali Loss: 0.1189902 Test Loss: 0.1460390\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034021\n",
      "\tspeed: 0.0345s/iter; left time: 641.1145s\n",
      "\titers: 200, epoch: 18 | loss: 0.0961946\n",
      "\tspeed: 0.0170s/iter; left time: 314.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0996697 Vali Loss: 0.1185702 Test Loss: 0.1454241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04502221569418907, rmse:0.2121843844652176, mae:0.1436704397201538, rse:0.7337632179260254\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1483310\n",
      "\tspeed: 0.0171s/iter; left time: 383.6728s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308554\n",
      "\tspeed: 0.0152s/iter; left time: 339.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.1445622 Vali Loss: 0.1381677 Test Loss: 0.1637920\n",
      "Validation loss decreased (inf --> 0.138168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1130186\n",
      "\tspeed: 0.0359s/iter; left time: 795.3798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083098\n",
      "\tspeed: 0.0169s/iter; left time: 372.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1122220 Vali Loss: 0.1197145 Test Loss: 0.1430694\n",
      "Validation loss decreased (0.138168 --> 0.119714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1004686\n",
      "\tspeed: 0.0382s/iter; left time: 839.2659s\n",
      "\titers: 200, epoch: 3 | loss: 0.1058460\n",
      "\tspeed: 0.0174s/iter; left time: 381.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1065320 Vali Loss: 0.1191321 Test Loss: 0.1431164\n",
      "Validation loss decreased (0.119714 --> 0.119132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1067420\n",
      "\tspeed: 0.0366s/iter; left time: 796.1413s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052855\n",
      "\tspeed: 0.0173s/iter; left time: 373.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1051883 Vali Loss: 0.1185206 Test Loss: 0.1429021\n",
      "Validation loss decreased (0.119132 --> 0.118521).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1020963\n",
      "\tspeed: 0.0382s/iter; left time: 821.7015s\n",
      "\titers: 200, epoch: 5 | loss: 0.1061885\n",
      "\tspeed: 0.0175s/iter; left time: 373.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1042266 Vali Loss: 0.1179224 Test Loss: 0.1425153\n",
      "Validation loss decreased (0.118521 --> 0.117922).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1019426\n",
      "\tspeed: 0.0389s/iter; left time: 826.5984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987578\n",
      "\tspeed: 0.0173s/iter; left time: 365.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.1034838 Vali Loss: 0.1178515 Test Loss: 0.1430858\n",
      "Validation loss decreased (0.117922 --> 0.117851).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1048590\n",
      "\tspeed: 0.0416s/iter; left time: 876.0780s\n",
      "\titers: 200, epoch: 7 | loss: 0.1034662\n",
      "\tspeed: 0.0181s/iter; left time: 379.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.1028714 Vali Loss: 0.1178046 Test Loss: 0.1434703\n",
      "Validation loss decreased (0.117851 --> 0.117805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960290\n",
      "\tspeed: 0.0379s/iter; left time: 790.2719s\n",
      "\titers: 200, epoch: 8 | loss: 0.0993760\n",
      "\tspeed: 0.0191s/iter; left time: 395.6642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.1023618 Vali Loss: 0.1179817 Test Loss: 0.1439923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982805\n",
      "\tspeed: 0.0392s/iter; left time: 806.9582s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009188\n",
      "\tspeed: 0.0190s/iter; left time: 390.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.1019138 Vali Loss: 0.1181148 Test Loss: 0.1445342\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027546\n",
      "\tspeed: 0.0385s/iter; left time: 785.1390s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985924\n",
      "\tspeed: 0.0171s/iter; left time: 345.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1015597 Vali Loss: 0.1182591 Test Loss: 0.1449339\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0938201\n",
      "\tspeed: 0.0379s/iter; left time: 763.8042s\n",
      "\titers: 200, epoch: 11 | loss: 0.1016373\n",
      "\tspeed: 0.0160s/iter; left time: 321.7632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1012948 Vali Loss: 0.1179792 Test Loss: 0.1446447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1054280\n",
      "\tspeed: 0.0389s/iter; left time: 775.5564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0961260\n",
      "\tspeed: 0.0179s/iter; left time: 355.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.1010108 Vali Loss: 0.1181633 Test Loss: 0.1451541\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1007230\n",
      "\tspeed: 0.0356s/iter; left time: 702.2664s\n",
      "\titers: 200, epoch: 13 | loss: 0.1053447\n",
      "\tspeed: 0.0166s/iter; left time: 325.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1008488 Vali Loss: 0.1179375 Test Loss: 0.1453492\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0957747\n",
      "\tspeed: 0.0369s/iter; left time: 718.0869s\n",
      "\titers: 200, epoch: 14 | loss: 0.1026282\n",
      "\tspeed: 0.0170s/iter; left time: 329.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1005955 Vali Loss: 0.1181584 Test Loss: 0.1455183\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1030927\n",
      "\tspeed: 0.0383s/iter; left time: 737.1703s\n",
      "\titers: 200, epoch: 15 | loss: 0.1035435\n",
      "\tspeed: 0.0158s/iter; left time: 303.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.1004362 Vali Loss: 0.1177396 Test Loss: 0.1446944\n",
      "Validation loss decreased (0.117805 --> 0.117740).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1024171\n",
      "\tspeed: 0.0353s/iter; left time: 671.1995s\n",
      "\titers: 200, epoch: 16 | loss: 0.1014723\n",
      "\tspeed: 0.0152s/iter; left time: 287.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1002407 Vali Loss: 0.1181168 Test Loss: 0.1451479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0950730\n",
      "\tspeed: 0.0347s/iter; left time: 652.9884s\n",
      "\titers: 200, epoch: 17 | loss: 0.1007550\n",
      "\tspeed: 0.0180s/iter; left time: 337.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1001653 Vali Loss: 0.1176875 Test Loss: 0.1446122\n",
      "Validation loss decreased (0.117740 --> 0.117687).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1016255\n",
      "\tspeed: 0.0367s/iter; left time: 682.6580s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003857\n",
      "\tspeed: 0.0153s/iter; left time: 281.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0999799 Vali Loss: 0.1176812 Test Loss: 0.1449458\n",
      "Validation loss decreased (0.117687 --> 0.117681).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0989775\n",
      "\tspeed: 0.0395s/iter; left time: 725.5833s\n",
      "\titers: 200, epoch: 19 | loss: 0.0949207\n",
      "\tspeed: 0.0160s/iter; left time: 292.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0998343 Vali Loss: 0.1181190 Test Loss: 0.1450148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1017841\n",
      "\tspeed: 0.0383s/iter; left time: 694.4167s\n",
      "\titers: 200, epoch: 20 | loss: 0.0993757\n",
      "\tspeed: 0.0170s/iter; left time: 306.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0997756 Vali Loss: 0.1178565 Test Loss: 0.1450385\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0974881\n",
      "\tspeed: 0.0428s/iter; left time: 765.9095s\n",
      "\titers: 200, epoch: 21 | loss: 0.1050698\n",
      "\tspeed: 0.0217s/iter; left time: 386.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0997030 Vali Loss: 0.1181531 Test Loss: 0.1456380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0996484\n",
      "\tspeed: 0.0409s/iter; left time: 722.2175s\n",
      "\titers: 200, epoch: 22 | loss: 0.1009263\n",
      "\tspeed: 0.0186s/iter; left time: 326.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0995709 Vali Loss: 0.1181348 Test Loss: 0.1454638\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0936366\n",
      "\tspeed: 0.0403s/iter; left time: 703.4896s\n",
      "\titers: 200, epoch: 23 | loss: 0.1032682\n",
      "\tspeed: 0.0183s/iter; left time: 317.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0995458 Vali Loss: 0.1179884 Test Loss: 0.1451582\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0968743\n",
      "\tspeed: 0.0390s/iter; left time: 671.3012s\n",
      "\titers: 200, epoch: 24 | loss: 0.1019463\n",
      "\tspeed: 0.0163s/iter; left time: 279.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0994681 Vali Loss: 0.1181457 Test Loss: 0.1455523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1061921\n",
      "\tspeed: 0.0398s/iter; left time: 677.3985s\n",
      "\titers: 200, epoch: 25 | loss: 0.0970668\n",
      "\tspeed: 0.0199s/iter; left time: 336.2067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0994505 Vali Loss: 0.1180443 Test Loss: 0.1453885\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1002892\n",
      "\tspeed: 0.0412s/iter; left time: 691.8628s\n",
      "\titers: 200, epoch: 26 | loss: 0.0993644\n",
      "\tspeed: 0.0192s/iter; left time: 320.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0993534 Vali Loss: 0.1181938 Test Loss: 0.1455262\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0944799\n",
      "\tspeed: 0.0407s/iter; left time: 673.0061s\n",
      "\titers: 200, epoch: 27 | loss: 0.0981926\n",
      "\tspeed: 0.0189s/iter; left time: 311.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0992863 Vali Loss: 0.1181367 Test Loss: 0.1452989\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0966076\n",
      "\tspeed: 0.0408s/iter; left time: 665.8369s\n",
      "\titers: 200, epoch: 28 | loss: 0.0948356\n",
      "\tspeed: 0.0220s/iter; left time: 356.5191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0992611 Vali Loss: 0.1181604 Test Loss: 0.1453564\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04601024091243744, rmse:0.21449998021125793, mae:0.1449458748102188, rse:0.7417708039283752\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:25.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1499535\n",
      "\tspeed: 0.0401s/iter; left time: 897.4073s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275760\n",
      "\tspeed: 0.0152s/iter; left time: 339.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1469418 Vali Loss: 0.1418786 Test Loss: 0.1676975\n",
      "Validation loss decreased (inf --> 0.141879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1141674\n",
      "\tspeed: 0.0351s/iter; left time: 778.8829s\n",
      "\titers: 200, epoch: 2 | loss: 0.1113455\n",
      "\tspeed: 0.0186s/iter; left time: 409.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1173277 Vali Loss: 0.1255487 Test Loss: 0.1495915\n",
      "Validation loss decreased (0.141879 --> 0.125549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092727\n",
      "\tspeed: 0.0367s/iter; left time: 805.8922s\n",
      "\titers: 200, epoch: 3 | loss: 0.1134550\n",
      "\tspeed: 0.0179s/iter; left time: 390.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1115658 Vali Loss: 0.1249689 Test Loss: 0.1503542\n",
      "Validation loss decreased (0.125549 --> 0.124969).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144803\n",
      "\tspeed: 0.0372s/iter; left time: 807.4042s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094217\n",
      "\tspeed: 0.0161s/iter; left time: 347.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.1099271 Vali Loss: 0.1243636 Test Loss: 0.1502110\n",
      "Validation loss decreased (0.124969 --> 0.124364).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1082388\n",
      "\tspeed: 0.0361s/iter; left time: 776.3311s\n",
      "\titers: 200, epoch: 5 | loss: 0.1077586\n",
      "\tspeed: 0.0164s/iter; left time: 351.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.1089903 Vali Loss: 0.1241797 Test Loss: 0.1502208\n",
      "Validation loss decreased (0.124364 --> 0.124180).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1081436\n",
      "\tspeed: 0.0350s/iter; left time: 744.8605s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119499\n",
      "\tspeed: 0.0157s/iter; left time: 332.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.1083248 Vali Loss: 0.1238742 Test Loss: 0.1504022\n",
      "Validation loss decreased (0.124180 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1111545\n",
      "\tspeed: 0.0391s/iter; left time: 822.6812s\n",
      "\titers: 200, epoch: 7 | loss: 0.1063496\n",
      "\tspeed: 0.0197s/iter; left time: 412.3867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.1078107 Vali Loss: 0.1247523 Test Loss: 0.1519305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016383\n",
      "\tspeed: 0.0358s/iter; left time: 746.1562s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076421\n",
      "\tspeed: 0.0163s/iter; left time: 336.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1074174 Vali Loss: 0.1238740 Test Loss: 0.1508317\n",
      "Validation loss decreased (0.123874 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1057409\n",
      "\tspeed: 0.0407s/iter; left time: 839.0853s\n",
      "\titers: 200, epoch: 9 | loss: 0.1076946\n",
      "\tspeed: 0.0168s/iter; left time: 343.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1070738 Vali Loss: 0.1239253 Test Loss: 0.1512166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1064644\n",
      "\tspeed: 0.0368s/iter; left time: 750.1468s\n",
      "\titers: 200, epoch: 10 | loss: 0.1061676\n",
      "\tspeed: 0.0233s/iter; left time: 472.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.1067472 Vali Loss: 0.1239237 Test Loss: 0.1517738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1069961\n",
      "\tspeed: 0.0412s/iter; left time: 830.6942s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058313\n",
      "\tspeed: 0.0187s/iter; left time: 375.9255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1063631 Vali Loss: 0.1238796 Test Loss: 0.1516500\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1059460\n",
      "\tspeed: 0.0358s/iter; left time: 713.4968s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064634\n",
      "\tspeed: 0.0157s/iter; left time: 311.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.1060945 Vali Loss: 0.1240394 Test Loss: 0.1517687\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032645\n",
      "\tspeed: 0.0358s/iter; left time: 704.3413s\n",
      "\titers: 200, epoch: 13 | loss: 0.1023014\n",
      "\tspeed: 0.0198s/iter; left time: 387.3759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1058933 Vali Loss: 0.1241398 Test Loss: 0.1517029\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1068519\n",
      "\tspeed: 0.0363s/iter; left time: 706.8059s\n",
      "\titers: 200, epoch: 14 | loss: 0.1030616\n",
      "\tspeed: 0.0191s/iter; left time: 369.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.1056087 Vali Loss: 0.1243978 Test Loss: 0.1522958\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037581\n",
      "\tspeed: 0.0354s/iter; left time: 680.9908s\n",
      "\titers: 200, epoch: 15 | loss: 0.1031120\n",
      "\tspeed: 0.0151s/iter; left time: 289.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.1054437 Vali Loss: 0.1244598 Test Loss: 0.1526321\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1081312\n",
      "\tspeed: 0.0348s/iter; left time: 661.3441s\n",
      "\titers: 200, epoch: 16 | loss: 0.1071312\n",
      "\tspeed: 0.0156s/iter; left time: 294.7698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1052283 Vali Loss: 0.1243807 Test Loss: 0.1525210\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1078316\n",
      "\tspeed: 0.0349s/iter; left time: 656.4600s\n",
      "\titers: 200, epoch: 17 | loss: 0.1053726\n",
      "\tspeed: 0.0176s/iter; left time: 329.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1050940 Vali Loss: 0.1245384 Test Loss: 0.1528213\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1060644\n",
      "\tspeed: 0.0423s/iter; left time: 786.3323s\n",
      "\titers: 200, epoch: 18 | loss: 0.1060730\n",
      "\tspeed: 0.0174s/iter; left time: 321.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.1049388 Vali Loss: 0.1245682 Test Loss: 0.1526806\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048577629029750824, rmse:0.22040332853794098, mae:0.1508316695690155, rse:0.7641699910163879\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1486480\n",
      "\tspeed: 0.0205s/iter; left time: 458.7998s\n",
      "\titers: 200, epoch: 1 | loss: 0.1346984\n",
      "\tspeed: 0.0177s/iter; left time: 394.6057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1462936 Vali Loss: 0.1413484 Test Loss: 0.1671238\n",
      "Validation loss decreased (inf --> 0.141348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1223506\n",
      "\tspeed: 0.0409s/iter; left time: 907.1932s\n",
      "\titers: 200, epoch: 2 | loss: 0.1111667\n",
      "\tspeed: 0.0190s/iter; left time: 419.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.1173274 Vali Loss: 0.1256820 Test Loss: 0.1498371\n",
      "Validation loss decreased (0.141348 --> 0.125682).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108388\n",
      "\tspeed: 0.0367s/iter; left time: 805.4347s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082366\n",
      "\tspeed: 0.0165s/iter; left time: 361.4048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.1116993 Vali Loss: 0.1249393 Test Loss: 0.1492249\n",
      "Validation loss decreased (0.125682 --> 0.124939).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090657\n",
      "\tspeed: 0.0378s/iter; left time: 820.9635s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095768\n",
      "\tspeed: 0.0192s/iter; left time: 415.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.1101767 Vali Loss: 0.1239666 Test Loss: 0.1496069\n",
      "Validation loss decreased (0.124939 --> 0.123967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1122283\n",
      "\tspeed: 0.0367s/iter; left time: 788.3670s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103199\n",
      "\tspeed: 0.0160s/iter; left time: 343.1005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.1091507 Vali Loss: 0.1240546 Test Loss: 0.1494649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116899\n",
      "\tspeed: 0.0360s/iter; left time: 766.3005s\n",
      "\titers: 200, epoch: 6 | loss: 0.1087078\n",
      "\tspeed: 0.0194s/iter; left time: 410.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1084126 Vali Loss: 0.1242108 Test Loss: 0.1503803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1052423\n",
      "\tspeed: 0.0364s/iter; left time: 766.0071s\n",
      "\titers: 200, epoch: 7 | loss: 0.1058420\n",
      "\tspeed: 0.0151s/iter; left time: 316.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1078158 Vali Loss: 0.1241233 Test Loss: 0.1499704\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1088142\n",
      "\tspeed: 0.0420s/iter; left time: 874.5691s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080927\n",
      "\tspeed: 0.0239s/iter; left time: 494.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.1073037 Vali Loss: 0.1240906 Test Loss: 0.1502237\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1084523\n",
      "\tspeed: 0.0389s/iter; left time: 801.1094s\n",
      "\titers: 200, epoch: 9 | loss: 0.1062123\n",
      "\tspeed: 0.0177s/iter; left time: 363.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.1069074 Vali Loss: 0.1238233 Test Loss: 0.1508131\n",
      "Validation loss decreased (0.123967 --> 0.123823).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033939\n",
      "\tspeed: 0.0372s/iter; left time: 758.7269s\n",
      "\titers: 200, epoch: 10 | loss: 0.1022663\n",
      "\tspeed: 0.0152s/iter; left time: 307.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1065447 Vali Loss: 0.1237250 Test Loss: 0.1507618\n",
      "Validation loss decreased (0.123823 --> 0.123725).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1049054\n",
      "\tspeed: 0.0390s/iter; left time: 786.1605s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089206\n",
      "\tspeed: 0.0157s/iter; left time: 314.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.1062916 Vali Loss: 0.1240461 Test Loss: 0.1506609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1051058\n",
      "\tspeed: 0.0399s/iter; left time: 796.0054s\n",
      "\titers: 200, epoch: 12 | loss: 0.1044658\n",
      "\tspeed: 0.0183s/iter; left time: 362.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.1060037 Vali Loss: 0.1238396 Test Loss: 0.1518371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1060486\n",
      "\tspeed: 0.0357s/iter; left time: 703.7851s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043409\n",
      "\tspeed: 0.0164s/iter; left time: 320.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.1057808 Vali Loss: 0.1241505 Test Loss: 0.1515134\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1095880\n",
      "\tspeed: 0.0367s/iter; left time: 713.9725s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056166\n",
      "\tspeed: 0.0157s/iter; left time: 303.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.1055283 Vali Loss: 0.1239597 Test Loss: 0.1517490\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1075236\n",
      "\tspeed: 0.0366s/iter; left time: 705.3965s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062559\n",
      "\tspeed: 0.0166s/iter; left time: 318.1343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.1053117 Vali Loss: 0.1241924 Test Loss: 0.1519936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1069865\n",
      "\tspeed: 0.0389s/iter; left time: 740.6799s\n",
      "\titers: 200, epoch: 16 | loss: 0.1052222\n",
      "\tspeed: 0.0201s/iter; left time: 380.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.1051655 Vali Loss: 0.1241199 Test Loss: 0.1524266\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1054700\n",
      "\tspeed: 0.0390s/iter; left time: 732.6092s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039295\n",
      "\tspeed: 0.0177s/iter; left time: 330.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.1049739 Vali Loss: 0.1241205 Test Loss: 0.1521003\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1029889\n",
      "\tspeed: 0.0363s/iter; left time: 673.9203s\n",
      "\titers: 200, epoch: 18 | loss: 0.1077079\n",
      "\tspeed: 0.0168s/iter; left time: 309.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1048550 Vali Loss: 0.1240906 Test Loss: 0.1522658\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1090901\n",
      "\tspeed: 0.0406s/iter; left time: 744.7466s\n",
      "\titers: 200, epoch: 19 | loss: 0.1001188\n",
      "\tspeed: 0.0177s/iter; left time: 323.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.1047448 Vali Loss: 0.1239998 Test Loss: 0.1522070\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1083529\n",
      "\tspeed: 0.0390s/iter; left time: 706.6121s\n",
      "\titers: 200, epoch: 20 | loss: 0.1003313\n",
      "\tspeed: 0.0151s/iter; left time: 272.4803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1046049 Vali Loss: 0.1242627 Test Loss: 0.1523417\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0486115999519825, rmse:0.22048038244247437, mae:0.15076184272766113, rse:0.7644371390342712\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:41.15s\n",
      "Intermediate time for GB: 00h:16m:02.70s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1451550\n",
      "\tspeed: 0.0395s/iter; left time: 888.7457s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177439\n",
      "\tspeed: 0.0135s/iter; left time: 301.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.1467837 Vali Loss: 0.1082984 Test Loss: 0.1226880\n",
      "Validation loss decreased (inf --> 0.108298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765975\n",
      "\tspeed: 0.0305s/iter; left time: 680.4632s\n",
      "\titers: 200, epoch: 2 | loss: 0.0669800\n",
      "\tspeed: 0.0169s/iter; left time: 373.9560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0798699 Vali Loss: 0.0656852 Test Loss: 0.0723652\n",
      "Validation loss decreased (0.108298 --> 0.065685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679572\n",
      "\tspeed: 0.0377s/iter; left time: 830.4263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0667502\n",
      "\tspeed: 0.0229s/iter; left time: 502.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 226 | Train Loss: 0.0679510 Vali Loss: 0.0617661 Test Loss: 0.0682334\n",
      "Validation loss decreased (0.065685 --> 0.061766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0635966\n",
      "\tspeed: 0.0350s/iter; left time: 763.2318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0613056\n",
      "\tspeed: 0.0183s/iter; left time: 397.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0647878 Vali Loss: 0.0594496 Test Loss: 0.0655302\n",
      "Validation loss decreased (0.061766 --> 0.059450).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0638050\n",
      "\tspeed: 0.0370s/iter; left time: 798.5349s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621530\n",
      "\tspeed: 0.0200s/iter; left time: 429.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0625533 Vali Loss: 0.0581501 Test Loss: 0.0642101\n",
      "Validation loss decreased (0.059450 --> 0.058150).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599403\n",
      "\tspeed: 0.0373s/iter; left time: 797.2017s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587380\n",
      "\tspeed: 0.0200s/iter; left time: 426.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0610643 Vali Loss: 0.0572503 Test Loss: 0.0633823\n",
      "Validation loss decreased (0.058150 --> 0.057250).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577566\n",
      "\tspeed: 0.0398s/iter; left time: 840.9181s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595189\n",
      "\tspeed: 0.0215s/iter; left time: 452.3899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 226 | Train Loss: 0.0599456 Vali Loss: 0.0565520 Test Loss: 0.0626068\n",
      "Validation loss decreased (0.057250 --> 0.056552).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583735\n",
      "\tspeed: 0.0344s/iter; left time: 719.6524s\n",
      "\titers: 200, epoch: 8 | loss: 0.0600804\n",
      "\tspeed: 0.0155s/iter; left time: 323.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0591601 Vali Loss: 0.0560919 Test Loss: 0.0620987\n",
      "Validation loss decreased (0.056552 --> 0.056092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0583554\n",
      "\tspeed: 0.0353s/iter; left time: 730.4459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0625408\n",
      "\tspeed: 0.0158s/iter; left time: 324.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0584560 Vali Loss: 0.0557185 Test Loss: 0.0616777\n",
      "Validation loss decreased (0.056092 --> 0.055719).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586190\n",
      "\tspeed: 0.0380s/iter; left time: 778.4299s\n",
      "\titers: 200, epoch: 10 | loss: 0.0579860\n",
      "\tspeed: 0.0197s/iter; left time: 401.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 226 | Train Loss: 0.0579441 Vali Loss: 0.0553816 Test Loss: 0.0612375\n",
      "Validation loss decreased (0.055719 --> 0.055382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0550162\n",
      "\tspeed: 0.0354s/iter; left time: 717.1668s\n",
      "\titers: 200, epoch: 11 | loss: 0.0574639\n",
      "\tspeed: 0.0172s/iter; left time: 346.2872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 226 | Train Loss: 0.0574571 Vali Loss: 0.0549510 Test Loss: 0.0610811\n",
      "Validation loss decreased (0.055382 --> 0.054951).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0580048\n",
      "\tspeed: 0.0352s/iter; left time: 703.7974s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585291\n",
      "\tspeed: 0.0173s/iter; left time: 345.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0570274 Vali Loss: 0.0547696 Test Loss: 0.0606912\n",
      "Validation loss decreased (0.054951 --> 0.054770).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0554573\n",
      "\tspeed: 0.0340s/iter; left time: 673.3766s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591582\n",
      "\tspeed: 0.0172s/iter; left time: 337.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0566880 Vali Loss: 0.0546194 Test Loss: 0.0605852\n",
      "Validation loss decreased (0.054770 --> 0.054619).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542542\n",
      "\tspeed: 0.0369s/iter; left time: 721.0404s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572352\n",
      "\tspeed: 0.0199s/iter; left time: 386.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 226 | Train Loss: 0.0564119 Vali Loss: 0.0544218 Test Loss: 0.0603917\n",
      "Validation loss decreased (0.054619 --> 0.054422).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0540660\n",
      "\tspeed: 0.0353s/iter; left time: 681.8516s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574466\n",
      "\tspeed: 0.0172s/iter; left time: 330.8605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0561427 Vali Loss: 0.0542233 Test Loss: 0.0602162\n",
      "Validation loss decreased (0.054422 --> 0.054223).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569734\n",
      "\tspeed: 0.0354s/iter; left time: 676.9982s\n",
      "\titers: 200, epoch: 16 | loss: 0.0520816\n",
      "\tspeed: 0.0170s/iter; left time: 322.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0559051 Vali Loss: 0.0542752 Test Loss: 0.0600648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0512955\n",
      "\tspeed: 0.0350s/iter; left time: 661.3820s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539228\n",
      "\tspeed: 0.0192s/iter; left time: 361.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0556844 Vali Loss: 0.0540120 Test Loss: 0.0600547\n",
      "Validation loss decreased (0.054223 --> 0.054012).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542477\n",
      "\tspeed: 0.0356s/iter; left time: 663.8737s\n",
      "\titers: 200, epoch: 18 | loss: 0.0539086\n",
      "\tspeed: 0.0175s/iter; left time: 324.7138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0555654 Vali Loss: 0.0539356 Test Loss: 0.0599224\n",
      "Validation loss decreased (0.054012 --> 0.053936).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0571002\n",
      "\tspeed: 0.0365s/iter; left time: 673.3697s\n",
      "\titers: 200, epoch: 19 | loss: 0.0550000\n",
      "\tspeed: 0.0195s/iter; left time: 357.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0553925 Vali Loss: 0.0537290 Test Loss: 0.0598146\n",
      "Validation loss decreased (0.053936 --> 0.053729).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542098\n",
      "\tspeed: 0.0336s/iter; left time: 612.3132s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565600\n",
      "\tspeed: 0.0149s/iter; left time: 269.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0552582 Vali Loss: 0.0536194 Test Loss: 0.0596348\n",
      "Validation loss decreased (0.053729 --> 0.053619).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0570835\n",
      "\tspeed: 0.0300s/iter; left time: 538.8699s\n",
      "\titers: 200, epoch: 21 | loss: 0.0525154\n",
      "\tspeed: 0.0174s/iter; left time: 310.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0551466 Vali Loss: 0.0537754 Test Loss: 0.0597416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0550864\n",
      "\tspeed: 0.0319s/iter; left time: 566.1580s\n",
      "\titers: 200, epoch: 22 | loss: 0.0529542\n",
      "\tspeed: 0.0151s/iter; left time: 266.4800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0550331 Vali Loss: 0.0535485 Test Loss: 0.0595939\n",
      "Validation loss decreased (0.053619 --> 0.053548).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570377\n",
      "\tspeed: 0.0327s/iter; left time: 573.6363s\n",
      "\titers: 200, epoch: 23 | loss: 0.0554462\n",
      "\tspeed: 0.0192s/iter; left time: 334.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0549571 Vali Loss: 0.0536868 Test Loss: 0.0597135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0528872\n",
      "\tspeed: 0.0315s/iter; left time: 544.7078s\n",
      "\titers: 200, epoch: 24 | loss: 0.0580698\n",
      "\tspeed: 0.0167s/iter; left time: 287.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0548983 Vali Loss: 0.0533693 Test Loss: 0.0593940\n",
      "Validation loss decreased (0.053548 --> 0.053369).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0536186\n",
      "\tspeed: 0.0309s/iter; left time: 527.9620s\n",
      "\titers: 200, epoch: 25 | loss: 0.0545483\n",
      "\tspeed: 0.0130s/iter; left time: 220.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0548395 Vali Loss: 0.0534591 Test Loss: 0.0594047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0536943\n",
      "\tspeed: 0.0284s/iter; left time: 479.1360s\n",
      "\titers: 200, epoch: 26 | loss: 0.0547102\n",
      "\tspeed: 0.0137s/iter; left time: 228.9919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0547063 Vali Loss: 0.0533696 Test Loss: 0.0594442\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0586530\n",
      "\tspeed: 0.0287s/iter; left time: 477.2321s\n",
      "\titers: 200, epoch: 27 | loss: 0.0519660\n",
      "\tspeed: 0.0136s/iter; left time: 224.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0546750 Vali Loss: 0.0533953 Test Loss: 0.0594027\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0549270\n",
      "\tspeed: 0.0294s/iter; left time: 481.3725s\n",
      "\titers: 200, epoch: 28 | loss: 0.0517543\n",
      "\tspeed: 0.0135s/iter; left time: 219.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0546615 Vali Loss: 0.0533006 Test Loss: 0.0593567\n",
      "Validation loss decreased (0.053369 --> 0.053301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0557347\n",
      "\tspeed: 0.0290s/iter; left time: 468.2238s\n",
      "\titers: 200, epoch: 29 | loss: 0.0538403\n",
      "\tspeed: 0.0129s/iter; left time: 207.9327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0546012 Vali Loss: 0.0533369 Test Loss: 0.0592920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516878\n",
      "\tspeed: 0.0296s/iter; left time: 471.9321s\n",
      "\titers: 200, epoch: 30 | loss: 0.0524874\n",
      "\tspeed: 0.0136s/iter; left time: 215.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0545499 Vali Loss: 0.0533188 Test Loss: 0.0593219\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0556062\n",
      "\tspeed: 0.0303s/iter; left time: 475.7911s\n",
      "\titers: 200, epoch: 31 | loss: 0.0533224\n",
      "\tspeed: 0.0139s/iter; left time: 216.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0545046 Vali Loss: 0.0533411 Test Loss: 0.0593881\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0547356\n",
      "\tspeed: 0.0282s/iter; left time: 437.0103s\n",
      "\titers: 200, epoch: 32 | loss: 0.0559356\n",
      "\tspeed: 0.0142s/iter; left time: 218.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0544690 Vali Loss: 0.0532426 Test Loss: 0.0593208\n",
      "Validation loss decreased (0.053301 --> 0.053243).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0555151\n",
      "\tspeed: 0.0287s/iter; left time: 438.1923s\n",
      "\titers: 200, epoch: 33 | loss: 0.0566518\n",
      "\tspeed: 0.0133s/iter; left time: 202.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0544179 Vali Loss: 0.0533163 Test Loss: 0.0592986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0558582\n",
      "\tspeed: 0.0281s/iter; left time: 422.6046s\n",
      "\titers: 200, epoch: 34 | loss: 0.0547988\n",
      "\tspeed: 0.0132s/iter; left time: 197.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0544022 Vali Loss: 0.0532038 Test Loss: 0.0591519\n",
      "Validation loss decreased (0.053243 --> 0.053204).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0563478\n",
      "\tspeed: 0.0299s/iter; left time: 442.8674s\n",
      "\titers: 200, epoch: 35 | loss: 0.0556942\n",
      "\tspeed: 0.0118s/iter; left time: 173.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0543788 Vali Loss: 0.0532233 Test Loss: 0.0592055\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0515261\n",
      "\tspeed: 0.0282s/iter; left time: 411.0176s\n",
      "\titers: 200, epoch: 36 | loss: 0.0552400\n",
      "\tspeed: 0.0135s/iter; left time: 195.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0543355 Vali Loss: 0.0531696 Test Loss: 0.0591507\n",
      "Validation loss decreased (0.053204 --> 0.053170).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0567131\n",
      "\tspeed: 0.0290s/iter; left time: 417.2604s\n",
      "\titers: 200, epoch: 37 | loss: 0.0568572\n",
      "\tspeed: 0.0153s/iter; left time: 218.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0543303 Vali Loss: 0.0532427 Test Loss: 0.0592053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0516365\n",
      "\tspeed: 0.0281s/iter; left time: 397.9304s\n",
      "\titers: 200, epoch: 38 | loss: 0.0545847\n",
      "\tspeed: 0.0114s/iter; left time: 160.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0543382 Vali Loss: 0.0532185 Test Loss: 0.0591625\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0540008\n",
      "\tspeed: 0.0277s/iter; left time: 385.6329s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528272\n",
      "\tspeed: 0.0118s/iter; left time: 162.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0542832 Vali Loss: 0.0531784 Test Loss: 0.0591502\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0516087\n",
      "\tspeed: 0.0261s/iter; left time: 357.7612s\n",
      "\titers: 200, epoch: 40 | loss: 0.0524877\n",
      "\tspeed: 0.0117s/iter; left time: 159.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0542918 Vali Loss: 0.0532291 Test Loss: 0.0591576\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0586451\n",
      "\tspeed: 0.0272s/iter; left time: 365.4904s\n",
      "\titers: 200, epoch: 41 | loss: 0.0575853\n",
      "\tspeed: 0.0117s/iter; left time: 156.9834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0542267 Vali Loss: 0.0530851 Test Loss: 0.0592127\n",
      "Validation loss decreased (0.053170 --> 0.053085).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0498054\n",
      "\tspeed: 0.0326s/iter; left time: 431.2476s\n",
      "\titers: 200, epoch: 42 | loss: 0.0552870\n",
      "\tspeed: 0.0123s/iter; left time: 161.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0543146 Vali Loss: 0.0531483 Test Loss: 0.0591471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0503690\n",
      "\tspeed: 0.0294s/iter; left time: 382.3126s\n",
      "\titers: 200, epoch: 43 | loss: 0.0562914\n",
      "\tspeed: 0.0128s/iter; left time: 165.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0542930 Vali Loss: 0.0531643 Test Loss: 0.0592036\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0539966\n",
      "\tspeed: 0.0299s/iter; left time: 382.5697s\n",
      "\titers: 200, epoch: 44 | loss: 0.0501583\n",
      "\tspeed: 0.0130s/iter; left time: 164.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0542000 Vali Loss: 0.0531088 Test Loss: 0.0590504\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0574259\n",
      "\tspeed: 0.0273s/iter; left time: 342.4563s\n",
      "\titers: 200, epoch: 45 | loss: 0.0551004\n",
      "\tspeed: 0.0111s/iter; left time: 138.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0542018 Vali Loss: 0.0531857 Test Loss: 0.0591267\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0549353\n",
      "\tspeed: 0.0265s/iter; left time: 326.4648s\n",
      "\titers: 200, epoch: 46 | loss: 0.0492027\n",
      "\tspeed: 0.0126s/iter; left time: 153.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0542488 Vali Loss: 0.0531209 Test Loss: 0.0592010\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0555106\n",
      "\tspeed: 0.0269s/iter; left time: 325.1362s\n",
      "\titers: 200, epoch: 47 | loss: 0.0540510\n",
      "\tspeed: 0.0113s/iter; left time: 136.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0542097 Vali Loss: 0.0531165 Test Loss: 0.0591204\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0553315\n",
      "\tspeed: 0.0270s/iter; left time: 320.2321s\n",
      "\titers: 200, epoch: 48 | loss: 0.0546300\n",
      "\tspeed: 0.0114s/iter; left time: 134.4081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541788 Vali Loss: 0.0531417 Test Loss: 0.0590926\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549805\n",
      "\tspeed: 0.0267s/iter; left time: 310.7206s\n",
      "\titers: 200, epoch: 49 | loss: 0.0557395\n",
      "\tspeed: 0.0112s/iter; left time: 128.9113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541946 Vali Loss: 0.0531759 Test Loss: 0.0591419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0542814\n",
      "\tspeed: 0.0268s/iter; left time: 306.4461s\n",
      "\titers: 200, epoch: 50 | loss: 0.0558326\n",
      "\tspeed: 0.0137s/iter; left time: 155.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0541970 Vali Loss: 0.0531588 Test Loss: 0.0592191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0540405\n",
      "\tspeed: 0.0286s/iter; left time: 319.9939s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547026\n",
      "\tspeed: 0.0130s/iter; left time: 144.2814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0541853 Vali Loss: 0.0531794 Test Loss: 0.0590807\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009818107821047306, rmse:0.09908636659383774, mae:0.05921265855431557, rse:0.29159918427467346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1507255\n",
      "\tspeed: 0.0146s/iter; left time: 327.6570s\n",
      "\titers: 200, epoch: 1 | loss: 0.1207082\n",
      "\tspeed: 0.0143s/iter; left time: 319.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.1465289 Vali Loss: 0.1071480 Test Loss: 0.1212301\n",
      "Validation loss decreased (inf --> 0.107148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0785520\n",
      "\tspeed: 0.0280s/iter; left time: 622.9595s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688930\n",
      "\tspeed: 0.0117s/iter; left time: 259.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0799033 Vali Loss: 0.0661498 Test Loss: 0.0729442\n",
      "Validation loss decreased (0.107148 --> 0.066150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675750\n",
      "\tspeed: 0.0298s/iter; left time: 657.1261s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637515\n",
      "\tspeed: 0.0114s/iter; left time: 249.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0680635 Vali Loss: 0.0614426 Test Loss: 0.0683460\n",
      "Validation loss decreased (0.066150 --> 0.061443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0669186\n",
      "\tspeed: 0.0290s/iter; left time: 633.9092s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643349\n",
      "\tspeed: 0.0131s/iter; left time: 283.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0648668 Vali Loss: 0.0593724 Test Loss: 0.0657995\n",
      "Validation loss decreased (0.061443 --> 0.059372).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610497\n",
      "\tspeed: 0.0305s/iter; left time: 658.0443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619393\n",
      "\tspeed: 0.0118s/iter; left time: 254.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0626716 Vali Loss: 0.0577798 Test Loss: 0.0641355\n",
      "Validation loss decreased (0.059372 --> 0.057780).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614329\n",
      "\tspeed: 0.0273s/iter; left time: 582.4532s\n",
      "\titers: 200, epoch: 6 | loss: 0.0615167\n",
      "\tspeed: 0.0124s/iter; left time: 263.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0611074 Vali Loss: 0.0574545 Test Loss: 0.0633995\n",
      "Validation loss decreased (0.057780 --> 0.057454).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597643\n",
      "\tspeed: 0.0283s/iter; left time: 599.3577s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607079\n",
      "\tspeed: 0.0116s/iter; left time: 244.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0599273 Vali Loss: 0.0563146 Test Loss: 0.0625127\n",
      "Validation loss decreased (0.057454 --> 0.056315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574845\n",
      "\tspeed: 0.0285s/iter; left time: 596.6742s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590476\n",
      "\tspeed: 0.0120s/iter; left time: 250.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0590586 Vali Loss: 0.0560240 Test Loss: 0.0619528\n",
      "Validation loss decreased (0.056315 --> 0.056024).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0639373\n",
      "\tspeed: 0.0279s/iter; left time: 576.6687s\n",
      "\titers: 200, epoch: 9 | loss: 0.0527270\n",
      "\tspeed: 0.0118s/iter; left time: 242.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0583976 Vali Loss: 0.0554776 Test Loss: 0.0613036\n",
      "Validation loss decreased (0.056024 --> 0.055478).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0565735\n",
      "\tspeed: 0.0287s/iter; left time: 587.6593s\n",
      "\titers: 200, epoch: 10 | loss: 0.0558760\n",
      "\tspeed: 0.0118s/iter; left time: 240.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0577687 Vali Loss: 0.0552871 Test Loss: 0.0610560\n",
      "Validation loss decreased (0.055478 --> 0.055287).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0571113\n",
      "\tspeed: 0.0293s/iter; left time: 592.0521s\n",
      "\titers: 200, epoch: 11 | loss: 0.0566703\n",
      "\tspeed: 0.0118s/iter; left time: 237.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0573187 Vali Loss: 0.0547834 Test Loss: 0.0607028\n",
      "Validation loss decreased (0.055287 --> 0.054783).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586570\n",
      "\tspeed: 0.0273s/iter; left time: 547.2207s\n",
      "\titers: 200, epoch: 12 | loss: 0.0570341\n",
      "\tspeed: 0.0119s/iter; left time: 236.3911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0569485 Vali Loss: 0.0544821 Test Loss: 0.0604087\n",
      "Validation loss decreased (0.054783 --> 0.054482).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0555787\n",
      "\tspeed: 0.0303s/iter; left time: 599.0129s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562803\n",
      "\tspeed: 0.0129s/iter; left time: 253.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0566200 Vali Loss: 0.0545550 Test Loss: 0.0603720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575179\n",
      "\tspeed: 0.0300s/iter; left time: 587.0186s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569978\n",
      "\tspeed: 0.0119s/iter; left time: 231.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 226 | Train Loss: 0.0562737 Vali Loss: 0.0543751 Test Loss: 0.0601368\n",
      "Validation loss decreased (0.054482 --> 0.054375).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0523732\n",
      "\tspeed: 0.0262s/iter; left time: 507.0347s\n",
      "\titers: 200, epoch: 15 | loss: 0.0562500\n",
      "\tspeed: 0.0124s/iter; left time: 239.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0560525 Vali Loss: 0.0540945 Test Loss: 0.0599775\n",
      "Validation loss decreased (0.054375 --> 0.054095).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0528089\n",
      "\tspeed: 0.0271s/iter; left time: 517.4916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597127\n",
      "\tspeed: 0.0117s/iter; left time: 222.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0558022 Vali Loss: 0.0539221 Test Loss: 0.0597435\n",
      "Validation loss decreased (0.054095 --> 0.053922).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0559879\n",
      "\tspeed: 0.0289s/iter; left time: 545.5689s\n",
      "\titers: 200, epoch: 17 | loss: 0.0581747\n",
      "\tspeed: 0.0117s/iter; left time: 218.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0556188 Vali Loss: 0.0539700 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0555314\n",
      "\tspeed: 0.0261s/iter; left time: 486.7138s\n",
      "\titers: 200, epoch: 18 | loss: 0.0544397\n",
      "\tspeed: 0.0110s/iter; left time: 203.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 226 | Train Loss: 0.0554477 Vali Loss: 0.0536921 Test Loss: 0.0595935\n",
      "Validation loss decreased (0.053922 --> 0.053692).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0524647\n",
      "\tspeed: 0.0272s/iter; left time: 501.1017s\n",
      "\titers: 200, epoch: 19 | loss: 0.0516993\n",
      "\tspeed: 0.0121s/iter; left time: 221.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0553181 Vali Loss: 0.0537883 Test Loss: 0.0596126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0527550\n",
      "\tspeed: 0.0291s/iter; left time: 529.7238s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565373\n",
      "\tspeed: 0.0142s/iter; left time: 257.1261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0551740 Vali Loss: 0.0537758 Test Loss: 0.0596166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569603\n",
      "\tspeed: 0.0264s/iter; left time: 474.5772s\n",
      "\titers: 200, epoch: 21 | loss: 0.0545343\n",
      "\tspeed: 0.0118s/iter; left time: 210.3655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 226 | Train Loss: 0.0550889 Vali Loss: 0.0533999 Test Loss: 0.0594185\n",
      "Validation loss decreased (0.053692 --> 0.053400).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0562903\n",
      "\tspeed: 0.0269s/iter; left time: 477.0942s\n",
      "\titers: 200, epoch: 22 | loss: 0.0577873\n",
      "\tspeed: 0.0137s/iter; left time: 241.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0549383 Vali Loss: 0.0534308 Test Loss: 0.0593246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0538595\n",
      "\tspeed: 0.0284s/iter; left time: 498.1272s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566281\n",
      "\tspeed: 0.0130s/iter; left time: 226.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 226 | Train Loss: 0.0548749 Vali Loss: 0.0534087 Test Loss: 0.0593133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0507098\n",
      "\tspeed: 0.0292s/iter; left time: 504.9074s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538428\n",
      "\tspeed: 0.0121s/iter; left time: 207.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0548080 Vali Loss: 0.0533418 Test Loss: 0.0593664\n",
      "Validation loss decreased (0.053400 --> 0.053342).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0554929\n",
      "\tspeed: 0.0276s/iter; left time: 471.6608s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567786\n",
      "\tspeed: 0.0115s/iter; left time: 195.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0546885 Vali Loss: 0.0534237 Test Loss: 0.0594419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548124\n",
      "\tspeed: 0.0265s/iter; left time: 446.6148s\n",
      "\titers: 200, epoch: 26 | loss: 0.0535798\n",
      "\tspeed: 0.0110s/iter; left time: 183.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.68s\n",
      "Steps: 226 | Train Loss: 0.0546452 Vali Loss: 0.0533526 Test Loss: 0.0591975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0557830\n",
      "\tspeed: 0.0274s/iter; left time: 455.9417s\n",
      "\titers: 200, epoch: 27 | loss: 0.0586098\n",
      "\tspeed: 0.0135s/iter; left time: 222.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0545553 Vali Loss: 0.0533763 Test Loss: 0.0592641\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0546051\n",
      "\tspeed: 0.0277s/iter; left time: 454.7507s\n",
      "\titers: 200, epoch: 28 | loss: 0.0558206\n",
      "\tspeed: 0.0126s/iter; left time: 204.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0545318 Vali Loss: 0.0532169 Test Loss: 0.0592011\n",
      "Validation loss decreased (0.053342 --> 0.053217).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0563632\n",
      "\tspeed: 0.0271s/iter; left time: 438.6456s\n",
      "\titers: 200, epoch: 29 | loss: 0.0581273\n",
      "\tspeed: 0.0125s/iter; left time: 200.6389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0544601 Vali Loss: 0.0531060 Test Loss: 0.0591692\n",
      "Validation loss decreased (0.053217 --> 0.053106).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0574518\n",
      "\tspeed: 0.0266s/iter; left time: 424.1283s\n",
      "\titers: 200, epoch: 30 | loss: 0.0555285\n",
      "\tspeed: 0.0108s/iter; left time: 171.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0544499 Vali Loss: 0.0530576 Test Loss: 0.0590920\n",
      "Validation loss decreased (0.053106 --> 0.053058).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0510666\n",
      "\tspeed: 0.0274s/iter; left time: 431.2590s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540474\n",
      "\tspeed: 0.0111s/iter; left time: 173.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0544246 Vali Loss: 0.0533034 Test Loss: 0.0591211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0568054\n",
      "\tspeed: 0.0268s/iter; left time: 416.0011s\n",
      "\titers: 200, epoch: 32 | loss: 0.0557136\n",
      "\tspeed: 0.0116s/iter; left time: 178.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0543331 Vali Loss: 0.0531352 Test Loss: 0.0590774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0552513\n",
      "\tspeed: 0.0290s/iter; left time: 443.3887s\n",
      "\titers: 200, epoch: 33 | loss: 0.0547300\n",
      "\tspeed: 0.0120s/iter; left time: 181.6856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0543432 Vali Loss: 0.0531316 Test Loss: 0.0590895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0512971\n",
      "\tspeed: 0.0261s/iter; left time: 392.2131s\n",
      "\titers: 200, epoch: 34 | loss: 0.0529503\n",
      "\tspeed: 0.0118s/iter; left time: 176.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 226 | Train Loss: 0.0543068 Vali Loss: 0.0530512 Test Loss: 0.0591309\n",
      "Validation loss decreased (0.053058 --> 0.053051).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0559119\n",
      "\tspeed: 0.0271s/iter; left time: 401.2238s\n",
      "\titers: 200, epoch: 35 | loss: 0.0545416\n",
      "\tspeed: 0.0123s/iter; left time: 180.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0542706 Vali Loss: 0.0530420 Test Loss: 0.0589782\n",
      "Validation loss decreased (0.053051 --> 0.053042).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0561696\n",
      "\tspeed: 0.0283s/iter; left time: 412.9282s\n",
      "\titers: 200, epoch: 36 | loss: 0.0561849\n",
      "\tspeed: 0.0117s/iter; left time: 169.7662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0542947 Vali Loss: 0.0530133 Test Loss: 0.0590346\n",
      "Validation loss decreased (0.053042 --> 0.053013).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0509262\n",
      "\tspeed: 0.0275s/iter; left time: 394.9990s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508690\n",
      "\tspeed: 0.0119s/iter; left time: 169.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0541840 Vali Loss: 0.0531005 Test Loss: 0.0591013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0554777\n",
      "\tspeed: 0.0279s/iter; left time: 394.2060s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548198\n",
      "\tspeed: 0.0120s/iter; left time: 169.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0542373 Vali Loss: 0.0530459 Test Loss: 0.0589842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0525637\n",
      "\tspeed: 0.0294s/iter; left time: 408.4744s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543035\n",
      "\tspeed: 0.0164s/iter; left time: 226.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0542141 Vali Loss: 0.0530863 Test Loss: 0.0589925\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0504019\n",
      "\tspeed: 0.0292s/iter; left time: 399.6585s\n",
      "\titers: 200, epoch: 40 | loss: 0.0561855\n",
      "\tspeed: 0.0114s/iter; left time: 154.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 226 | Train Loss: 0.0542050 Vali Loss: 0.0530611 Test Loss: 0.0590304\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0555407\n",
      "\tspeed: 0.0284s/iter; left time: 382.3314s\n",
      "\titers: 200, epoch: 41 | loss: 0.0573847\n",
      "\tspeed: 0.0121s/iter; left time: 161.0054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0541970 Vali Loss: 0.0529732 Test Loss: 0.0589725\n",
      "Validation loss decreased (0.053013 --> 0.052973).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0557087\n",
      "\tspeed: 0.0262s/iter; left time: 347.2037s\n",
      "\titers: 200, epoch: 42 | loss: 0.0507394\n",
      "\tspeed: 0.0107s/iter; left time: 140.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 226 | Train Loss: 0.0542100 Vali Loss: 0.0530530 Test Loss: 0.0589480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0532187\n",
      "\tspeed: 0.0280s/iter; left time: 364.2858s\n",
      "\titers: 200, epoch: 43 | loss: 0.0522638\n",
      "\tspeed: 0.0114s/iter; left time: 146.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0541853 Vali Loss: 0.0530456 Test Loss: 0.0589709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0523888\n",
      "\tspeed: 0.0294s/iter; left time: 376.4591s\n",
      "\titers: 200, epoch: 44 | loss: 0.0555471\n",
      "\tspeed: 0.0114s/iter; left time: 145.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0541429 Vali Loss: 0.0530979 Test Loss: 0.0590576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0518244\n",
      "\tspeed: 0.0268s/iter; left time: 336.3404s\n",
      "\titers: 200, epoch: 45 | loss: 0.0573724\n",
      "\tspeed: 0.0110s/iter; left time: 137.2029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541446 Vali Loss: 0.0530079 Test Loss: 0.0589412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0536192\n",
      "\tspeed: 0.0274s/iter; left time: 338.2583s\n",
      "\titers: 200, epoch: 46 | loss: 0.0520935\n",
      "\tspeed: 0.0119s/iter; left time: 146.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0541448 Vali Loss: 0.0530503 Test Loss: 0.0589884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0567641\n",
      "\tspeed: 0.0258s/iter; left time: 312.7587s\n",
      "\titers: 200, epoch: 47 | loss: 0.0499426\n",
      "\tspeed: 0.0110s/iter; left time: 132.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 226 | Train Loss: 0.0541792 Vali Loss: 0.0529625 Test Loss: 0.0589573\n",
      "Validation loss decreased (0.052973 --> 0.052963).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0543365\n",
      "\tspeed: 0.0311s/iter; left time: 369.0471s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528470\n",
      "\tspeed: 0.0118s/iter; left time: 139.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0540931 Vali Loss: 0.0529664 Test Loss: 0.0589474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0498530\n",
      "\tspeed: 0.0266s/iter; left time: 309.8380s\n",
      "\titers: 200, epoch: 49 | loss: 0.0562437\n",
      "\tspeed: 0.0115s/iter; left time: 133.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0541368 Vali Loss: 0.0529739 Test Loss: 0.0589651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547175\n",
      "\tspeed: 0.0263s/iter; left time: 300.8490s\n",
      "\titers: 200, epoch: 50 | loss: 0.0537487\n",
      "\tspeed: 0.0108s/iter; left time: 122.8662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 226 | Train Loss: 0.0540701 Vali Loss: 0.0530535 Test Loss: 0.0589779\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0549713\n",
      "\tspeed: 0.0263s/iter; left time: 294.7595s\n",
      "\titers: 200, epoch: 51 | loss: 0.0546206\n",
      "\tspeed: 0.0119s/iter; left time: 131.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541515 Vali Loss: 0.0530221 Test Loss: 0.0589595\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0527683\n",
      "\tspeed: 0.0266s/iter; left time: 292.3650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0574221\n",
      "\tspeed: 0.0120s/iter; left time: 130.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0541668 Vali Loss: 0.0530018 Test Loss: 0.0589725\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0534396\n",
      "\tspeed: 0.0290s/iter; left time: 311.5190s\n",
      "\titers: 200, epoch: 53 | loss: 0.0520115\n",
      "\tspeed: 0.0114s/iter; left time: 121.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0540821 Vali Loss: 0.0530134 Test Loss: 0.0589416\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0542039\n",
      "\tspeed: 0.0269s/iter; left time: 283.4755s\n",
      "\titers: 200, epoch: 54 | loss: 0.0522672\n",
      "\tspeed: 0.0119s/iter; left time: 124.2941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541188 Vali Loss: 0.0530085 Test Loss: 0.0589848\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0503511\n",
      "\tspeed: 0.0266s/iter; left time: 274.0105s\n",
      "\titers: 200, epoch: 55 | loss: 0.0528312\n",
      "\tspeed: 0.0115s/iter; left time: 117.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0540319 Vali Loss: 0.0529898 Test Loss: 0.0589086\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0524455\n",
      "\tspeed: 0.0277s/iter; left time: 278.7486s\n",
      "\titers: 200, epoch: 56 | loss: 0.0551980\n",
      "\tspeed: 0.0115s/iter; left time: 114.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541053 Vali Loss: 0.0529852 Test Loss: 0.0588668\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0554461\n",
      "\tspeed: 0.0263s/iter; left time: 259.1786s\n",
      "\titers: 200, epoch: 57 | loss: 0.0511636\n",
      "\tspeed: 0.0109s/iter; left time: 106.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 226 | Train Loss: 0.0540857 Vali Loss: 0.0530011 Test Loss: 0.0590005\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009839903563261032, rmse:0.09919628500938416, mae:0.058957286179065704, rse:0.2919226884841919\n",
      "Intermediate time for ES and pred_len 24: 00h:07m:56.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1514326\n",
      "\tspeed: 0.0397s/iter; left time: 889.9418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1340956\n",
      "\tspeed: 0.0111s/iter; left time: 247.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.1534535 Vali Loss: 0.1192981 Test Loss: 0.1362016\n",
      "Validation loss decreased (inf --> 0.119298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0992987\n",
      "\tspeed: 0.0289s/iter; left time: 640.6691s\n",
      "\titers: 200, epoch: 2 | loss: 0.0911604\n",
      "\tspeed: 0.0132s/iter; left time: 291.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0996113 Vali Loss: 0.0870584 Test Loss: 0.0990485\n",
      "Validation loss decreased (0.119298 --> 0.087058).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860890\n",
      "\tspeed: 0.0287s/iter; left time: 630.2518s\n",
      "\titers: 200, epoch: 3 | loss: 0.0849074\n",
      "\tspeed: 0.0134s/iter; left time: 292.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0886737 Vali Loss: 0.0814001 Test Loss: 0.0934050\n",
      "Validation loss decreased (0.087058 --> 0.081400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801919\n",
      "\tspeed: 0.0299s/iter; left time: 649.1137s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829801\n",
      "\tspeed: 0.0112s/iter; left time: 241.7950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0853538 Vali Loss: 0.0797981 Test Loss: 0.0914087\n",
      "Validation loss decreased (0.081400 --> 0.079798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849047\n",
      "\tspeed: 0.0306s/iter; left time: 657.2593s\n",
      "\titers: 200, epoch: 5 | loss: 0.0815262\n",
      "\tspeed: 0.0136s/iter; left time: 291.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0834915 Vali Loss: 0.0786919 Test Loss: 0.0897241\n",
      "Validation loss decreased (0.079798 --> 0.078692).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793926\n",
      "\tspeed: 0.0287s/iter; left time: 611.6769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799922\n",
      "\tspeed: 0.0113s/iter; left time: 238.2779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0820761 Vali Loss: 0.0781931 Test Loss: 0.0889015\n",
      "Validation loss decreased (0.078692 --> 0.078193).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787506\n",
      "\tspeed: 0.0286s/iter; left time: 601.3436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0792138\n",
      "\tspeed: 0.0109s/iter; left time: 228.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0810654 Vali Loss: 0.0774327 Test Loss: 0.0880531\n",
      "Validation loss decreased (0.078193 --> 0.077433).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0786066\n",
      "\tspeed: 0.0290s/iter; left time: 604.3271s\n",
      "\titers: 200, epoch: 8 | loss: 0.0784651\n",
      "\tspeed: 0.0110s/iter; left time: 228.6810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0803040 Vali Loss: 0.0773680 Test Loss: 0.0878483\n",
      "Validation loss decreased (0.077433 --> 0.077368).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771229\n",
      "\tspeed: 0.0279s/iter; left time: 575.3227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0784607\n",
      "\tspeed: 0.0111s/iter; left time: 228.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 225 | Train Loss: 0.0797460 Vali Loss: 0.0767728 Test Loss: 0.0873519\n",
      "Validation loss decreased (0.077368 --> 0.076773).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769961\n",
      "\tspeed: 0.0305s/iter; left time: 622.3057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839497\n",
      "\tspeed: 0.0112s/iter; left time: 227.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0792595 Vali Loss: 0.0770860 Test Loss: 0.0873690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784799\n",
      "\tspeed: 0.0265s/iter; left time: 533.1242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0806227\n",
      "\tspeed: 0.0124s/iter; left time: 248.0597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 225 | Train Loss: 0.0788540 Vali Loss: 0.0766369 Test Loss: 0.0871308\n",
      "Validation loss decreased (0.076773 --> 0.076637).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758444\n",
      "\tspeed: 0.0291s/iter; left time: 580.7146s\n",
      "\titers: 200, epoch: 12 | loss: 0.0784750\n",
      "\tspeed: 0.0133s/iter; left time: 262.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0784713 Vali Loss: 0.0762269 Test Loss: 0.0869149\n",
      "Validation loss decreased (0.076637 --> 0.076227).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0733879\n",
      "\tspeed: 0.0281s/iter; left time: 553.2530s\n",
      "\titers: 200, epoch: 13 | loss: 0.0769888\n",
      "\tspeed: 0.0111s/iter; left time: 218.1576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 225 | Train Loss: 0.0781977 Vali Loss: 0.0762897 Test Loss: 0.0870662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810686\n",
      "\tspeed: 0.0264s/iter; left time: 514.1753s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0113s/iter; left time: 219.2021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 225 | Train Loss: 0.0779459 Vali Loss: 0.0761060 Test Loss: 0.0869318\n",
      "Validation loss decreased (0.076227 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0744233\n",
      "\tspeed: 0.0289s/iter; left time: 555.8119s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829216\n",
      "\tspeed: 0.0138s/iter; left time: 264.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0777016 Vali Loss: 0.0759125 Test Loss: 0.0868220\n",
      "Validation loss decreased (0.076106 --> 0.075912).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0767097\n",
      "\tspeed: 0.0306s/iter; left time: 581.5039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0796856\n",
      "\tspeed: 0.0144s/iter; left time: 271.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0774920 Vali Loss: 0.0758455 Test Loss: 0.0867436\n",
      "Validation loss decreased (0.075912 --> 0.075846).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0774719\n",
      "\tspeed: 0.0277s/iter; left time: 521.3130s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752526\n",
      "\tspeed: 0.0130s/iter; left time: 243.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.0773374 Vali Loss: 0.0755446 Test Loss: 0.0865177\n",
      "Validation loss decreased (0.075846 --> 0.075545).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765253\n",
      "\tspeed: 0.0286s/iter; left time: 530.7867s\n",
      "\titers: 200, epoch: 18 | loss: 0.0765767\n",
      "\tspeed: 0.0122s/iter; left time: 225.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0771752 Vali Loss: 0.0757170 Test Loss: 0.0865492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0783547\n",
      "\tspeed: 0.0282s/iter; left time: 518.1567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767365\n",
      "\tspeed: 0.0143s/iter; left time: 261.0149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0769659 Vali Loss: 0.0754213 Test Loss: 0.0863692\n",
      "Validation loss decreased (0.075545 --> 0.075421).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790408\n",
      "\tspeed: 0.0282s/iter; left time: 510.8319s\n",
      "\titers: 200, epoch: 20 | loss: 0.0773466\n",
      "\tspeed: 0.0128s/iter; left time: 231.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0768425 Vali Loss: 0.0754664 Test Loss: 0.0864002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0753531\n",
      "\tspeed: 0.0301s/iter; left time: 539.1700s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731350\n",
      "\tspeed: 0.0137s/iter; left time: 243.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0766955 Vali Loss: 0.0754862 Test Loss: 0.0863862\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779898\n",
      "\tspeed: 0.0269s/iter; left time: 475.8422s\n",
      "\titers: 200, epoch: 22 | loss: 0.0825680\n",
      "\tspeed: 0.0122s/iter; left time: 214.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0766248 Vali Loss: 0.0755235 Test Loss: 0.0864362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0791111\n",
      "\tspeed: 0.0267s/iter; left time: 465.7960s\n",
      "\titers: 200, epoch: 23 | loss: 0.0759331\n",
      "\tspeed: 0.0114s/iter; left time: 197.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0765473 Vali Loss: 0.0753228 Test Loss: 0.0863299\n",
      "Validation loss decreased (0.075421 --> 0.075323).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761495\n",
      "\tspeed: 0.0284s/iter; left time: 488.6902s\n",
      "\titers: 200, epoch: 24 | loss: 0.0738292\n",
      "\tspeed: 0.0112s/iter; left time: 190.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0765094 Vali Loss: 0.0753156 Test Loss: 0.0862079\n",
      "Validation loss decreased (0.075323 --> 0.075316).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0779993\n",
      "\tspeed: 0.0305s/iter; left time: 519.3030s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782428\n",
      "\tspeed: 0.0151s/iter; left time: 255.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0763938 Vali Loss: 0.0753543 Test Loss: 0.0861947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0742307\n",
      "\tspeed: 0.0315s/iter; left time: 528.8139s\n",
      "\titers: 200, epoch: 26 | loss: 0.0757918\n",
      "\tspeed: 0.0134s/iter; left time: 223.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0762774 Vali Loss: 0.0752724 Test Loss: 0.0862290\n",
      "Validation loss decreased (0.075316 --> 0.075272).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0783321\n",
      "\tspeed: 0.0281s/iter; left time: 465.0481s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757260\n",
      "\tspeed: 0.0135s/iter; left time: 222.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0762253 Vali Loss: 0.0752488 Test Loss: 0.0862783\n",
      "Validation loss decreased (0.075272 --> 0.075249).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0790930\n",
      "\tspeed: 0.0276s/iter; left time: 450.5264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0729679\n",
      "\tspeed: 0.0121s/iter; left time: 195.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0761534 Vali Loss: 0.0751565 Test Loss: 0.0862070\n",
      "Validation loss decreased (0.075249 --> 0.075156).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0786199\n",
      "\tspeed: 0.0269s/iter; left time: 432.6455s\n",
      "\titers: 200, epoch: 29 | loss: 0.0761598\n",
      "\tspeed: 0.0112s/iter; left time: 179.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 225 | Train Loss: 0.0761940 Vali Loss: 0.0751621 Test Loss: 0.0861756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733554\n",
      "\tspeed: 0.0295s/iter; left time: 467.9329s\n",
      "\titers: 200, epoch: 30 | loss: 0.0730510\n",
      "\tspeed: 0.0106s/iter; left time: 167.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0761272 Vali Loss: 0.0751793 Test Loss: 0.0861981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0754577\n",
      "\tspeed: 0.0268s/iter; left time: 419.6410s\n",
      "\titers: 200, epoch: 31 | loss: 0.0763041\n",
      "\tspeed: 0.0118s/iter; left time: 183.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0761112 Vali Loss: 0.0752193 Test Loss: 0.0862073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0753690\n",
      "\tspeed: 0.0270s/iter; left time: 417.0290s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749692\n",
      "\tspeed: 0.0145s/iter; left time: 222.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0760013 Vali Loss: 0.0751270 Test Loss: 0.0861752\n",
      "Validation loss decreased (0.075156 --> 0.075127).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775594\n",
      "\tspeed: 0.0288s/iter; left time: 437.4118s\n",
      "\titers: 200, epoch: 33 | loss: 0.0772318\n",
      "\tspeed: 0.0126s/iter; left time: 189.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0760387 Vali Loss: 0.0752166 Test Loss: 0.0862664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0794576\n",
      "\tspeed: 0.0310s/iter; left time: 464.7791s\n",
      "\titers: 200, epoch: 34 | loss: 0.0768538\n",
      "\tspeed: 0.0135s/iter; left time: 200.1176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0760135 Vali Loss: 0.0751128 Test Loss: 0.0860821\n",
      "Validation loss decreased (0.075127 --> 0.075113).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735802\n",
      "\tspeed: 0.0271s/iter; left time: 400.3334s\n",
      "\titers: 200, epoch: 35 | loss: 0.0766621\n",
      "\tspeed: 0.0134s/iter; left time: 196.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0760044 Vali Loss: 0.0751563 Test Loss: 0.0862373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0772841\n",
      "\tspeed: 0.0301s/iter; left time: 436.7725s\n",
      "\titers: 200, epoch: 36 | loss: 0.0781624\n",
      "\tspeed: 0.0126s/iter; left time: 182.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0759210 Vali Loss: 0.0752047 Test Loss: 0.0861904\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786459\n",
      "\tspeed: 0.0323s/iter; left time: 462.1864s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782112\n",
      "\tspeed: 0.0140s/iter; left time: 199.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0759412 Vali Loss: 0.0751507 Test Loss: 0.0861724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0764863\n",
      "\tspeed: 0.0285s/iter; left time: 400.6951s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763690\n",
      "\tspeed: 0.0114s/iter; left time: 159.7223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 225 | Train Loss: 0.0758886 Vali Loss: 0.0750675 Test Loss: 0.0861431\n",
      "Validation loss decreased (0.075113 --> 0.075067).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0746387\n",
      "\tspeed: 0.0303s/iter; left time: 420.2301s\n",
      "\titers: 200, epoch: 39 | loss: 0.0787861\n",
      "\tspeed: 0.0153s/iter; left time: 210.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0758228 Vali Loss: 0.0751216 Test Loss: 0.0861156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0776882\n",
      "\tspeed: 0.0279s/iter; left time: 380.6277s\n",
      "\titers: 200, epoch: 40 | loss: 0.0786385\n",
      "\tspeed: 0.0113s/iter; left time: 152.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0759235 Vali Loss: 0.0751186 Test Loss: 0.0860987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0728601\n",
      "\tspeed: 0.0277s/iter; left time: 371.5797s\n",
      "\titers: 200, epoch: 41 | loss: 0.0760473\n",
      "\tspeed: 0.0117s/iter; left time: 155.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0759023 Vali Loss: 0.0751263 Test Loss: 0.0861959\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0754796\n",
      "\tspeed: 0.0293s/iter; left time: 385.9538s\n",
      "\titers: 200, epoch: 42 | loss: 0.0757237\n",
      "\tspeed: 0.0123s/iter; left time: 160.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0758651 Vali Loss: 0.0751259 Test Loss: 0.0861585\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0747819\n",
      "\tspeed: 0.0280s/iter; left time: 362.8419s\n",
      "\titers: 200, epoch: 43 | loss: 0.0768324\n",
      "\tspeed: 0.0109s/iter; left time: 139.8543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 225 | Train Loss: 0.0758420 Vali Loss: 0.0750790 Test Loss: 0.0861122\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0760698\n",
      "\tspeed: 0.0267s/iter; left time: 339.2354s\n",
      "\titers: 200, epoch: 44 | loss: 0.0753583\n",
      "\tspeed: 0.0144s/iter; left time: 181.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0758371 Vali Loss: 0.0751272 Test Loss: 0.0861907\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0728124\n",
      "\tspeed: 0.0275s/iter; left time: 344.0722s\n",
      "\titers: 200, epoch: 45 | loss: 0.0740116\n",
      "\tspeed: 0.0145s/iter; left time: 180.2584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 225 | Train Loss: 0.0758549 Vali Loss: 0.0751464 Test Loss: 0.0861597\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0761023\n",
      "\tspeed: 0.0271s/iter; left time: 333.1433s\n",
      "\titers: 200, epoch: 46 | loss: 0.0756330\n",
      "\tspeed: 0.0132s/iter; left time: 160.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0758372 Vali Loss: 0.0751317 Test Loss: 0.0862101\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0762448\n",
      "\tspeed: 0.0301s/iter; left time: 362.6132s\n",
      "\titers: 200, epoch: 47 | loss: 0.0742020\n",
      "\tspeed: 0.0126s/iter; left time: 151.0476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0758265 Vali Loss: 0.0751139 Test Loss: 0.0861376\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784523\n",
      "\tspeed: 0.0285s/iter; left time: 337.1899s\n",
      "\titers: 200, epoch: 48 | loss: 0.0720111\n",
      "\tspeed: 0.0114s/iter; left time: 133.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 225 | Train Loss: 0.0757754 Vali Loss: 0.0750921 Test Loss: 0.0861033\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019112445414066315, rmse:0.1382477730512619, mae:0.08614306151866913, rse:0.4061303436756134\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1577033\n",
      "\tspeed: 0.0132s/iter; left time: 295.0442s\n",
      "\titers: 200, epoch: 1 | loss: 0.1350389\n",
      "\tspeed: 0.0130s/iter; left time: 290.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.1574104 Vali Loss: 0.1217240 Test Loss: 0.1391744\n",
      "Validation loss decreased (inf --> 0.121724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0954664\n",
      "\tspeed: 0.0301s/iter; left time: 668.4554s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901520\n",
      "\tspeed: 0.0124s/iter; left time: 272.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0996074 Vali Loss: 0.0869710 Test Loss: 0.0990641\n",
      "Validation loss decreased (0.121724 --> 0.086971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872138\n",
      "\tspeed: 0.0288s/iter; left time: 633.0436s\n",
      "\titers: 200, epoch: 3 | loss: 0.0905658\n",
      "\tspeed: 0.0122s/iter; left time: 267.1381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0889019 Vali Loss: 0.0821534 Test Loss: 0.0939969\n",
      "Validation loss decreased (0.086971 --> 0.082153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868627\n",
      "\tspeed: 0.0313s/iter; left time: 680.1948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0845538\n",
      "\tspeed: 0.0119s/iter; left time: 256.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0855274 Vali Loss: 0.0803953 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.082153 --> 0.080395).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849042\n",
      "\tspeed: 0.0300s/iter; left time: 644.3792s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862014\n",
      "\tspeed: 0.0120s/iter; left time: 257.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 225 | Train Loss: 0.0836403 Vali Loss: 0.0792225 Test Loss: 0.0900389\n",
      "Validation loss decreased (0.080395 --> 0.079222).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834529\n",
      "\tspeed: 0.0287s/iter; left time: 609.7094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0859380\n",
      "\tspeed: 0.0122s/iter; left time: 257.3358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 225 | Train Loss: 0.0823096 Vali Loss: 0.0782612 Test Loss: 0.0890277\n",
      "Validation loss decreased (0.079222 --> 0.078261).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838038\n",
      "\tspeed: 0.0294s/iter; left time: 618.4004s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800350\n",
      "\tspeed: 0.0121s/iter; left time: 253.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0814003 Vali Loss: 0.0777358 Test Loss: 0.0884875\n",
      "Validation loss decreased (0.078261 --> 0.077736).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803438\n",
      "\tspeed: 0.0281s/iter; left time: 585.6875s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797413\n",
      "\tspeed: 0.0114s/iter; left time: 236.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0805841 Vali Loss: 0.0774105 Test Loss: 0.0880362\n",
      "Validation loss decreased (0.077736 --> 0.077410).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0753549\n",
      "\tspeed: 0.0284s/iter; left time: 584.4948s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840414\n",
      "\tspeed: 0.0139s/iter; left time: 285.0079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 225 | Train Loss: 0.0800004 Vali Loss: 0.0773046 Test Loss: 0.0879727\n",
      "Validation loss decreased (0.077410 --> 0.077305).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788011\n",
      "\tspeed: 0.0319s/iter; left time: 650.2066s\n",
      "\titers: 200, epoch: 10 | loss: 0.0813491\n",
      "\tspeed: 0.0128s/iter; left time: 259.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0794434 Vali Loss: 0.0767787 Test Loss: 0.0874287\n",
      "Validation loss decreased (0.077305 --> 0.076779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0806336\n",
      "\tspeed: 0.0278s/iter; left time: 560.6176s\n",
      "\titers: 200, epoch: 11 | loss: 0.0811494\n",
      "\tspeed: 0.0159s/iter; left time: 318.1278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0790037 Vali Loss: 0.0766619 Test Loss: 0.0873398\n",
      "Validation loss decreased (0.076779 --> 0.076662).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0747868\n",
      "\tspeed: 0.0323s/iter; left time: 643.0898s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767990\n",
      "\tspeed: 0.0126s/iter; left time: 250.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0786772 Vali Loss: 0.0761316 Test Loss: 0.0871168\n",
      "Validation loss decreased (0.076662 --> 0.076132).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763483\n",
      "\tspeed: 0.0292s/iter; left time: 575.5384s\n",
      "\titers: 200, epoch: 13 | loss: 0.0806691\n",
      "\tspeed: 0.0119s/iter; left time: 232.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0784107 Vali Loss: 0.0759851 Test Loss: 0.0868440\n",
      "Validation loss decreased (0.076132 --> 0.075985).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810251\n",
      "\tspeed: 0.0280s/iter; left time: 545.8384s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781442\n",
      "\tspeed: 0.0144s/iter; left time: 279.8245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0781160 Vali Loss: 0.0762808 Test Loss: 0.0871939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731684\n",
      "\tspeed: 0.0293s/iter; left time: 563.2923s\n",
      "\titers: 200, epoch: 15 | loss: 0.0800549\n",
      "\tspeed: 0.0114s/iter; left time: 217.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0779006 Vali Loss: 0.0761531 Test Loss: 0.0868299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0808244\n",
      "\tspeed: 0.0282s/iter; left time: 535.8622s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744877\n",
      "\tspeed: 0.0121s/iter; left time: 229.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0776603 Vali Loss: 0.0759935 Test Loss: 0.0866621\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0797293\n",
      "\tspeed: 0.0351s/iter; left time: 660.5789s\n",
      "\titers: 200, epoch: 17 | loss: 0.0745371\n",
      "\tspeed: 0.0166s/iter; left time: 310.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0774855 Vali Loss: 0.0758769 Test Loss: 0.0865073\n",
      "Validation loss decreased (0.075985 --> 0.075877).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0825204\n",
      "\tspeed: 0.0306s/iter; left time: 567.7591s\n",
      "\titers: 200, epoch: 18 | loss: 0.0759405\n",
      "\tspeed: 0.0110s/iter; left time: 203.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 225 | Train Loss: 0.0773324 Vali Loss: 0.0759104 Test Loss: 0.0866722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0751155\n",
      "\tspeed: 0.0279s/iter; left time: 511.4307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759723\n",
      "\tspeed: 0.0126s/iter; left time: 229.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0771947 Vali Loss: 0.0758913 Test Loss: 0.0865089\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0770257\n",
      "\tspeed: 0.0271s/iter; left time: 490.9193s\n",
      "\titers: 200, epoch: 20 | loss: 0.0793783\n",
      "\tspeed: 0.0117s/iter; left time: 211.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0770421 Vali Loss: 0.0759149 Test Loss: 0.0864828\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0808547\n",
      "\tspeed: 0.0325s/iter; left time: 581.6474s\n",
      "\titers: 200, epoch: 21 | loss: 0.0746658\n",
      "\tspeed: 0.0117s/iter; left time: 207.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0769642 Vali Loss: 0.0755270 Test Loss: 0.0862854\n",
      "Validation loss decreased (0.075877 --> 0.075527).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0799318\n",
      "\tspeed: 0.0300s/iter; left time: 529.7660s\n",
      "\titers: 200, epoch: 22 | loss: 0.0795009\n",
      "\tspeed: 0.0121s/iter; left time: 212.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0769058 Vali Loss: 0.0755863 Test Loss: 0.0861169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0806981\n",
      "\tspeed: 0.0276s/iter; left time: 481.9471s\n",
      "\titers: 200, epoch: 23 | loss: 0.0776285\n",
      "\tspeed: 0.0116s/iter; left time: 201.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0767392 Vali Loss: 0.0755869 Test Loss: 0.0862814\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0757655\n",
      "\tspeed: 0.0292s/iter; left time: 503.2249s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774275\n",
      "\tspeed: 0.0116s/iter; left time: 198.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0766776 Vali Loss: 0.0756844 Test Loss: 0.0863970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0719616\n",
      "\tspeed: 0.0294s/iter; left time: 500.1217s\n",
      "\titers: 200, epoch: 25 | loss: 0.0789211\n",
      "\tspeed: 0.0115s/iter; left time: 193.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.0766260 Vali Loss: 0.0756459 Test Loss: 0.0862978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0750893\n",
      "\tspeed: 0.0280s/iter; left time: 469.5322s\n",
      "\titers: 200, epoch: 26 | loss: 0.0768932\n",
      "\tspeed: 0.0116s/iter; left time: 193.4952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 225 | Train Loss: 0.0765750 Vali Loss: 0.0754100 Test Loss: 0.0859953\n",
      "Validation loss decreased (0.075527 --> 0.075410).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0803022\n",
      "\tspeed: 0.0282s/iter; left time: 466.6631s\n",
      "\titers: 200, epoch: 27 | loss: 0.0765712\n",
      "\tspeed: 0.0122s/iter; left time: 201.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0764555 Vali Loss: 0.0756538 Test Loss: 0.0862654\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0799393\n",
      "\tspeed: 0.0319s/iter; left time: 520.0467s\n",
      "\titers: 200, epoch: 28 | loss: 0.0732785\n",
      "\tspeed: 0.0129s/iter; left time: 209.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0764959 Vali Loss: 0.0755844 Test Loss: 0.0862349\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0759135\n",
      "\tspeed: 0.0282s/iter; left time: 454.3806s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728304\n",
      "\tspeed: 0.0118s/iter; left time: 188.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0763770 Vali Loss: 0.0755688 Test Loss: 0.0862012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0758216\n",
      "\tspeed: 0.0286s/iter; left time: 453.5418s\n",
      "\titers: 200, epoch: 30 | loss: 0.0788435\n",
      "\tspeed: 0.0122s/iter; left time: 193.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.0763523 Vali Loss: 0.0754775 Test Loss: 0.0861182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0740229\n",
      "\tspeed: 0.0326s/iter; left time: 509.6023s\n",
      "\titers: 200, epoch: 31 | loss: 0.0750465\n",
      "\tspeed: 0.0121s/iter; left time: 188.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0762969 Vali Loss: 0.0754892 Test Loss: 0.0860911\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0735503\n",
      "\tspeed: 0.0292s/iter; left time: 450.2291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0753440\n",
      "\tspeed: 0.0115s/iter; left time: 176.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 225 | Train Loss: 0.0762555 Vali Loss: 0.0753743 Test Loss: 0.0860091\n",
      "Validation loss decreased (0.075410 --> 0.075374).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0745924\n",
      "\tspeed: 0.0290s/iter; left time: 441.1284s\n",
      "\titers: 200, epoch: 33 | loss: 0.0805365\n",
      "\tspeed: 0.0129s/iter; left time: 195.3121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0762440 Vali Loss: 0.0754154 Test Loss: 0.0860034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0734176\n",
      "\tspeed: 0.0289s/iter; left time: 432.1467s\n",
      "\titers: 200, epoch: 34 | loss: 0.0756994\n",
      "\tspeed: 0.0121s/iter; left time: 180.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 225 | Train Loss: 0.0761795 Vali Loss: 0.0754332 Test Loss: 0.0861153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0789745\n",
      "\tspeed: 0.0296s/iter; left time: 436.9366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0763532\n",
      "\tspeed: 0.0154s/iter; left time: 225.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0761926 Vali Loss: 0.0754571 Test Loss: 0.0860438\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0762898\n",
      "\tspeed: 0.0288s/iter; left time: 418.2761s\n",
      "\titers: 200, epoch: 36 | loss: 0.0747354\n",
      "\tspeed: 0.0123s/iter; left time: 177.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0761171 Vali Loss: 0.0755036 Test Loss: 0.0860654\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0761736\n",
      "\tspeed: 0.0277s/iter; left time: 396.2141s\n",
      "\titers: 200, epoch: 37 | loss: 0.0747050\n",
      "\tspeed: 0.0137s/iter; left time: 194.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 225 | Train Loss: 0.0761568 Vali Loss: 0.0753613 Test Loss: 0.0860309\n",
      "Validation loss decreased (0.075374 --> 0.075361).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0727366\n",
      "\tspeed: 0.0293s/iter; left time: 412.1367s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777595\n",
      "\tspeed: 0.0129s/iter; left time: 180.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0761321 Vali Loss: 0.0753521 Test Loss: 0.0860522\n",
      "Validation loss decreased (0.075361 --> 0.075352).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0778039\n",
      "\tspeed: 0.0298s/iter; left time: 413.1627s\n",
      "\titers: 200, epoch: 39 | loss: 0.0722151\n",
      "\tspeed: 0.0128s/iter; left time: 176.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0760934 Vali Loss: 0.0754370 Test Loss: 0.0860848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0743089\n",
      "\tspeed: 0.0336s/iter; left time: 458.4894s\n",
      "\titers: 200, epoch: 40 | loss: 0.0775397\n",
      "\tspeed: 0.0140s/iter; left time: 188.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0760195 Vali Loss: 0.0753774 Test Loss: 0.0860355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0738335\n",
      "\tspeed: 0.0334s/iter; left time: 447.5114s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781013\n",
      "\tspeed: 0.0166s/iter; left time: 220.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0760308 Vali Loss: 0.0753938 Test Loss: 0.0860646\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0752735\n",
      "\tspeed: 0.0323s/iter; left time: 426.0101s\n",
      "\titers: 200, epoch: 42 | loss: 0.0769139\n",
      "\tspeed: 0.0115s/iter; left time: 150.9601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0760375 Vali Loss: 0.0753885 Test Loss: 0.0860948\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0789014\n",
      "\tspeed: 0.0278s/iter; left time: 359.7525s\n",
      "\titers: 200, epoch: 43 | loss: 0.0771543\n",
      "\tspeed: 0.0110s/iter; left time: 141.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 225 | Train Loss: 0.0760886 Vali Loss: 0.0754264 Test Loss: 0.0860126\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0794128\n",
      "\tspeed: 0.0305s/iter; left time: 388.6699s\n",
      "\titers: 200, epoch: 44 | loss: 0.0747860\n",
      "\tspeed: 0.0124s/iter; left time: 156.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0760847 Vali Loss: 0.0753687 Test Loss: 0.0860298\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0770456\n",
      "\tspeed: 0.0286s/iter; left time: 357.1021s\n",
      "\titers: 200, epoch: 45 | loss: 0.0763281\n",
      "\tspeed: 0.0129s/iter; left time: 160.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 225 | Train Loss: 0.0760148 Vali Loss: 0.0753657 Test Loss: 0.0860127\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0800752\n",
      "\tspeed: 0.0316s/iter; left time: 387.8871s\n",
      "\titers: 200, epoch: 46 | loss: 0.0794832\n",
      "\tspeed: 0.0119s/iter; left time: 144.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0760315 Vali Loss: 0.0753694 Test Loss: 0.0860104\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0796557\n",
      "\tspeed: 0.0317s/iter; left time: 382.5726s\n",
      "\titers: 200, epoch: 47 | loss: 0.0767693\n",
      "\tspeed: 0.0136s/iter; left time: 161.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0760123 Vali Loss: 0.0753986 Test Loss: 0.0860624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0745895\n",
      "\tspeed: 0.0291s/iter; left time: 343.7544s\n",
      "\titers: 200, epoch: 48 | loss: 0.0807312\n",
      "\tspeed: 0.0126s/iter; left time: 147.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0760364 Vali Loss: 0.0753589 Test Loss: 0.0860535\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019077060744166374, rmse:0.13811972737312317, mae:0.08605219423770905, rse:0.4057542085647583\n",
      "Intermediate time for ES and pred_len 96: 00h:06m:52.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1568499\n",
      "\tspeed: 0.0381s/iter; left time: 853.6006s\n",
      "\titers: 200, epoch: 1 | loss: 0.1316590\n",
      "\tspeed: 0.0128s/iter; left time: 285.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.1573622 Vali Loss: 0.1235502 Test Loss: 0.1400854\n",
      "Validation loss decreased (inf --> 0.123550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1035424\n",
      "\tspeed: 0.0314s/iter; left time: 696.2753s\n",
      "\titers: 200, epoch: 2 | loss: 0.1005864\n",
      "\tspeed: 0.0122s/iter; left time: 270.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.1043460 Vali Loss: 0.0933807 Test Loss: 0.1052763\n",
      "Validation loss decreased (0.123550 --> 0.093381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921834\n",
      "\tspeed: 0.0291s/iter; left time: 638.4836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0943769\n",
      "\tspeed: 0.0138s/iter; left time: 301.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0942344 Vali Loss: 0.0873603 Test Loss: 0.0990985\n",
      "Validation loss decreased (0.093381 --> 0.087360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907277\n",
      "\tspeed: 0.0332s/iter; left time: 720.7441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888133\n",
      "\tspeed: 0.0141s/iter; left time: 304.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0908532 Vali Loss: 0.0852744 Test Loss: 0.0964538\n",
      "Validation loss decreased (0.087360 --> 0.085274).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867176\n",
      "\tspeed: 0.0328s/iter; left time: 706.0179s\n",
      "\titers: 200, epoch: 5 | loss: 0.0870261\n",
      "\tspeed: 0.0137s/iter; left time: 293.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0889696 Vali Loss: 0.0843731 Test Loss: 0.0953252\n",
      "Validation loss decreased (0.085274 --> 0.084373).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0842111\n",
      "\tspeed: 0.0327s/iter; left time: 696.3192s\n",
      "\titers: 200, epoch: 6 | loss: 0.0886363\n",
      "\tspeed: 0.0137s/iter; left time: 289.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0875895 Vali Loss: 0.0837014 Test Loss: 0.0944848\n",
      "Validation loss decreased (0.084373 --> 0.083701).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0892857\n",
      "\tspeed: 0.0325s/iter; left time: 683.8164s\n",
      "\titers: 200, epoch: 7 | loss: 0.0852607\n",
      "\tspeed: 0.0141s/iter; left time: 296.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0865385 Vali Loss: 0.0830057 Test Loss: 0.0939623\n",
      "Validation loss decreased (0.083701 --> 0.083006).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0876576\n",
      "\tspeed: 0.0328s/iter; left time: 683.0705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0875875\n",
      "\tspeed: 0.0139s/iter; left time: 288.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0857704 Vali Loss: 0.0828423 Test Loss: 0.0935337\n",
      "Validation loss decreased (0.083006 --> 0.082842).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0869338\n",
      "\tspeed: 0.0333s/iter; left time: 686.7570s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878397\n",
      "\tspeed: 0.0133s/iter; left time: 272.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0851366 Vali Loss: 0.0828146 Test Loss: 0.0935755\n",
      "Validation loss decreased (0.082842 --> 0.082815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832062\n",
      "\tspeed: 0.0298s/iter; left time: 608.1331s\n",
      "\titers: 200, epoch: 10 | loss: 0.0817573\n",
      "\tspeed: 0.0143s/iter; left time: 289.2983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0846364 Vali Loss: 0.0826662 Test Loss: 0.0931646\n",
      "Validation loss decreased (0.082815 --> 0.082666).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0856273\n",
      "\tspeed: 0.0316s/iter; left time: 637.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0868291\n",
      "\tspeed: 0.0145s/iter; left time: 290.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0842443 Vali Loss: 0.0824437 Test Loss: 0.0931207\n",
      "Validation loss decreased (0.082666 --> 0.082444).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0871971\n",
      "\tspeed: 0.0311s/iter; left time: 620.3054s\n",
      "\titers: 200, epoch: 12 | loss: 0.0862963\n",
      "\tspeed: 0.0144s/iter; left time: 285.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0839270 Vali Loss: 0.0820603 Test Loss: 0.0927688\n",
      "Validation loss decreased (0.082444 --> 0.082060).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0827589\n",
      "\tspeed: 0.0322s/iter; left time: 633.7782s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821555\n",
      "\tspeed: 0.0140s/iter; left time: 275.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0836436 Vali Loss: 0.0825373 Test Loss: 0.0930180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0816468\n",
      "\tspeed: 0.0305s/iter; left time: 594.9166s\n",
      "\titers: 200, epoch: 14 | loss: 0.0777866\n",
      "\tspeed: 0.0142s/iter; left time: 274.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0833672 Vali Loss: 0.0822728 Test Loss: 0.0929308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0817904\n",
      "\tspeed: 0.0316s/iter; left time: 608.8828s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814839\n",
      "\tspeed: 0.0151s/iter; left time: 289.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0831294 Vali Loss: 0.0823914 Test Loss: 0.0927944\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831645\n",
      "\tspeed: 0.0281s/iter; left time: 534.4025s\n",
      "\titers: 200, epoch: 16 | loss: 0.0814912\n",
      "\tspeed: 0.0125s/iter; left time: 236.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0829364 Vali Loss: 0.0822596 Test Loss: 0.0928918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0829945\n",
      "\tspeed: 0.0293s/iter; left time: 551.2159s\n",
      "\titers: 200, epoch: 17 | loss: 0.0866629\n",
      "\tspeed: 0.0124s/iter; left time: 231.6541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.0827697 Vali Loss: 0.0822756 Test Loss: 0.0927913\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0808619\n",
      "\tspeed: 0.0289s/iter; left time: 536.1474s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827853\n",
      "\tspeed: 0.0123s/iter; left time: 226.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0825893 Vali Loss: 0.0821652 Test Loss: 0.0926397\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0829511\n",
      "\tspeed: 0.0302s/iter; left time: 554.6400s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840674\n",
      "\tspeed: 0.0144s/iter; left time: 263.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0824541 Vali Loss: 0.0822779 Test Loss: 0.0930222\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0822663\n",
      "\tspeed: 0.0309s/iter; left time: 559.9971s\n",
      "\titers: 200, epoch: 20 | loss: 0.0844956\n",
      "\tspeed: 0.0139s/iter; left time: 249.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0823565 Vali Loss: 0.0822376 Test Loss: 0.0928995\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0786321\n",
      "\tspeed: 0.0304s/iter; left time: 543.4276s\n",
      "\titers: 200, epoch: 21 | loss: 0.0809851\n",
      "\tspeed: 0.0137s/iter; left time: 244.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0822532 Vali Loss: 0.0821607 Test Loss: 0.0927439\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0797071\n",
      "\tspeed: 0.0305s/iter; left time: 538.3366s\n",
      "\titers: 200, epoch: 22 | loss: 0.0842925\n",
      "\tspeed: 0.0144s/iter; left time: 252.2247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0821002 Vali Loss: 0.0822368 Test Loss: 0.0929710\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021398216485977173, rmse:0.14628128707408905, mae:0.09276880323886871, rse:0.42976129055023193\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1665550\n",
      "\tspeed: 0.0171s/iter; left time: 383.3097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1342119\n",
      "\tspeed: 0.0155s/iter; left time: 345.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.1595942 Vali Loss: 0.1252286 Test Loss: 0.1425784\n",
      "Validation loss decreased (inf --> 0.125229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1071426\n",
      "\tspeed: 0.0318s/iter; left time: 705.9752s\n",
      "\titers: 200, epoch: 2 | loss: 0.0988839\n",
      "\tspeed: 0.0144s/iter; left time: 316.7955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.1038184 Vali Loss: 0.0923388 Test Loss: 0.1043468\n",
      "Validation loss decreased (0.125229 --> 0.092339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954366\n",
      "\tspeed: 0.0328s/iter; left time: 720.6446s\n",
      "\titers: 200, epoch: 3 | loss: 0.0929098\n",
      "\tspeed: 0.0141s/iter; left time: 307.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0936030 Vali Loss: 0.0874168 Test Loss: 0.0985869\n",
      "Validation loss decreased (0.092339 --> 0.087417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919800\n",
      "\tspeed: 0.0328s/iter; left time: 712.6136s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923115\n",
      "\tspeed: 0.0140s/iter; left time: 302.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0906089 Vali Loss: 0.0856613 Test Loss: 0.0964879\n",
      "Validation loss decreased (0.087417 --> 0.085661).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887270\n",
      "\tspeed: 0.0319s/iter; left time: 686.2710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917832\n",
      "\tspeed: 0.0149s/iter; left time: 319.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0887391 Vali Loss: 0.0848867 Test Loss: 0.0954072\n",
      "Validation loss decreased (0.085661 --> 0.084887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0873320\n",
      "\tspeed: 0.0322s/iter; left time: 685.0572s\n",
      "\titers: 200, epoch: 6 | loss: 0.0866217\n",
      "\tspeed: 0.0141s/iter; left time: 298.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0875130 Vali Loss: 0.0838974 Test Loss: 0.0948258\n",
      "Validation loss decreased (0.084887 --> 0.083897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0856005\n",
      "\tspeed: 0.0316s/iter; left time: 665.8393s\n",
      "\titers: 200, epoch: 7 | loss: 0.0889447\n",
      "\tspeed: 0.0143s/iter; left time: 299.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0866496 Vali Loss: 0.0836268 Test Loss: 0.0943554\n",
      "Validation loss decreased (0.083897 --> 0.083627).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0852821\n",
      "\tspeed: 0.0336s/iter; left time: 698.7176s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845993\n",
      "\tspeed: 0.0161s/iter; left time: 333.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0859998 Vali Loss: 0.0833807 Test Loss: 0.0940453\n",
      "Validation loss decreased (0.083627 --> 0.083381).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0903444\n",
      "\tspeed: 0.0305s/iter; left time: 628.0585s\n",
      "\titers: 200, epoch: 9 | loss: 0.0831527\n",
      "\tspeed: 0.0122s/iter; left time: 249.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0854311 Vali Loss: 0.0835337 Test Loss: 0.0938182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0861049\n",
      "\tspeed: 0.0310s/iter; left time: 631.4107s\n",
      "\titers: 200, epoch: 10 | loss: 0.0856074\n",
      "\tspeed: 0.0130s/iter; left time: 264.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0849855 Vali Loss: 0.0832467 Test Loss: 0.0936491\n",
      "Validation loss decreased (0.083381 --> 0.083247).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823327\n",
      "\tspeed: 0.0299s/iter; left time: 603.0824s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823785\n",
      "\tspeed: 0.0136s/iter; left time: 272.2093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0845717 Vali Loss: 0.0834375 Test Loss: 0.0938023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0852507\n",
      "\tspeed: 0.0306s/iter; left time: 610.6626s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844938\n",
      "\tspeed: 0.0131s/iter; left time: 260.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0841896 Vali Loss: 0.0829765 Test Loss: 0.0932096\n",
      "Validation loss decreased (0.083247 --> 0.082976).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0808426\n",
      "\tspeed: 0.0333s/iter; left time: 656.3417s\n",
      "\titers: 200, epoch: 13 | loss: 0.0806663\n",
      "\tspeed: 0.0167s/iter; left time: 327.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0839008 Vali Loss: 0.0827313 Test Loss: 0.0932784\n",
      "Validation loss decreased (0.082976 --> 0.082731).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810001\n",
      "\tspeed: 0.0325s/iter; left time: 632.8474s\n",
      "\titers: 200, epoch: 14 | loss: 0.0829864\n",
      "\tspeed: 0.0134s/iter; left time: 259.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0836157 Vali Loss: 0.0822975 Test Loss: 0.0925756\n",
      "Validation loss decreased (0.082731 --> 0.082298).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0856069\n",
      "\tspeed: 0.0336s/iter; left time: 646.3278s\n",
      "\titers: 200, epoch: 15 | loss: 0.0858787\n",
      "\tspeed: 0.0138s/iter; left time: 264.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0833859 Vali Loss: 0.0826017 Test Loss: 0.0927973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0810837\n",
      "\tspeed: 0.0321s/iter; left time: 610.0693s\n",
      "\titers: 200, epoch: 16 | loss: 0.0873101\n",
      "\tspeed: 0.0139s/iter; left time: 262.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0832361 Vali Loss: 0.0825363 Test Loss: 0.0927583\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0846607\n",
      "\tspeed: 0.0319s/iter; left time: 598.8119s\n",
      "\titers: 200, epoch: 17 | loss: 0.0821061\n",
      "\tspeed: 0.0150s/iter; left time: 281.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0830506 Vali Loss: 0.0828263 Test Loss: 0.0932079\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0788185\n",
      "\tspeed: 0.0334s/iter; left time: 620.2452s\n",
      "\titers: 200, epoch: 18 | loss: 0.0828428\n",
      "\tspeed: 0.0138s/iter; left time: 255.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0828306 Vali Loss: 0.0825819 Test Loss: 0.0928293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0817331\n",
      "\tspeed: 0.0304s/iter; left time: 558.5909s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834585\n",
      "\tspeed: 0.0134s/iter; left time: 245.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0827299 Vali Loss: 0.0825543 Test Loss: 0.0930653\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806477\n",
      "\tspeed: 0.0298s/iter; left time: 540.3614s\n",
      "\titers: 200, epoch: 20 | loss: 0.0841569\n",
      "\tspeed: 0.0147s/iter; left time: 264.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0826318 Vali Loss: 0.0825693 Test Loss: 0.0926642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0823159\n",
      "\tspeed: 0.0311s/iter; left time: 556.3385s\n",
      "\titers: 200, epoch: 21 | loss: 0.0850630\n",
      "\tspeed: 0.0157s/iter; left time: 280.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0824663 Vali Loss: 0.0825424 Test Loss: 0.0927273\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0775800\n",
      "\tspeed: 0.0318s/iter; left time: 562.2015s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822026\n",
      "\tspeed: 0.0134s/iter; left time: 235.9942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0823799 Vali Loss: 0.0825105 Test Loss: 0.0927264\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0850594\n",
      "\tspeed: 0.0313s/iter; left time: 545.4146s\n",
      "\titers: 200, epoch: 23 | loss: 0.0854007\n",
      "\tspeed: 0.0148s/iter; left time: 257.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0822438 Vali Loss: 0.0825739 Test Loss: 0.0928915\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0819938\n",
      "\tspeed: 0.0318s/iter; left time: 548.4068s\n",
      "\titers: 200, epoch: 24 | loss: 0.0815709\n",
      "\tspeed: 0.0136s/iter; left time: 232.0669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0821720 Vali Loss: 0.0823585 Test Loss: 0.0925500\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02151847630739212, rmse:0.14669176936149597, mae:0.09257563203573227, rse:0.43096721172332764\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:42.31s\n",
      "Intermediate time for ES: 00h:18m:31.27s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1076997\n",
      "\tspeed: 0.0366s/iter; left time: 822.6094s\n",
      "\titers: 200, epoch: 1 | loss: 0.0844932\n",
      "\tspeed: 0.0120s/iter; left time: 267.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.1071305 Vali Loss: 0.0901043 Test Loss: 0.0994532\n",
      "Validation loss decreased (inf --> 0.090104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561477\n",
      "\tspeed: 0.0277s/iter; left time: 615.9330s\n",
      "\titers: 200, epoch: 2 | loss: 0.0513192\n",
      "\tspeed: 0.0130s/iter; left time: 287.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0585561 Vali Loss: 0.0592476 Test Loss: 0.0617865\n",
      "Validation loss decreased (0.090104 --> 0.059248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513508\n",
      "\tspeed: 0.0291s/iter; left time: 642.1081s\n",
      "\titers: 200, epoch: 3 | loss: 0.0479516\n",
      "\tspeed: 0.0128s/iter; left time: 281.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0507629 Vali Loss: 0.0568690 Test Loss: 0.0597648\n",
      "Validation loss decreased (0.059248 --> 0.056869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0521114\n",
      "\tspeed: 0.0289s/iter; left time: 631.1283s\n",
      "\titers: 200, epoch: 4 | loss: 0.0502443\n",
      "\tspeed: 0.0111s/iter; left time: 240.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0488265 Vali Loss: 0.0553084 Test Loss: 0.0585132\n",
      "Validation loss decreased (0.056869 --> 0.055308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0463736\n",
      "\tspeed: 0.0269s/iter; left time: 582.0012s\n",
      "\titers: 200, epoch: 5 | loss: 0.0434525\n",
      "\tspeed: 0.0115s/iter; left time: 247.6833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0475343 Vali Loss: 0.0543128 Test Loss: 0.0578031\n",
      "Validation loss decreased (0.055308 --> 0.054313).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460580\n",
      "\tspeed: 0.0264s/iter; left time: 563.7507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0450222\n",
      "\tspeed: 0.0112s/iter; left time: 238.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0466277 Vali Loss: 0.0534805 Test Loss: 0.0573687\n",
      "Validation loss decreased (0.054313 --> 0.053480).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0470545\n",
      "\tspeed: 0.0273s/iter; left time: 577.0121s\n",
      "\titers: 200, epoch: 7 | loss: 0.0459243\n",
      "\tspeed: 0.0134s/iter; left time: 282.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0458450 Vali Loss: 0.0528845 Test Loss: 0.0568669\n",
      "Validation loss decreased (0.053480 --> 0.052884).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449147\n",
      "\tspeed: 0.0286s/iter; left time: 598.4418s\n",
      "\titers: 200, epoch: 8 | loss: 0.0446093\n",
      "\tspeed: 0.0121s/iter; left time: 252.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0452563 Vali Loss: 0.0526112 Test Loss: 0.0566168\n",
      "Validation loss decreased (0.052884 --> 0.052611).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0432319\n",
      "\tspeed: 0.0289s/iter; left time: 597.5363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445187\n",
      "\tspeed: 0.0134s/iter; left time: 276.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0447915 Vali Loss: 0.0519764 Test Loss: 0.0564366\n",
      "Validation loss decreased (0.052611 --> 0.051976).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441739\n",
      "\tspeed: 0.0284s/iter; left time: 581.9944s\n",
      "\titers: 200, epoch: 10 | loss: 0.0453514\n",
      "\tspeed: 0.0111s/iter; left time: 225.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0443843 Vali Loss: 0.0517694 Test Loss: 0.0559094\n",
      "Validation loss decreased (0.051976 --> 0.051769).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440916\n",
      "\tspeed: 0.0287s/iter; left time: 580.5034s\n",
      "\titers: 200, epoch: 11 | loss: 0.0410351\n",
      "\tspeed: 0.0130s/iter; left time: 261.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 226 | Train Loss: 0.0440559 Vali Loss: 0.0514138 Test Loss: 0.0556246\n",
      "Validation loss decreased (0.051769 --> 0.051414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0477772\n",
      "\tspeed: 0.0277s/iter; left time: 554.8615s\n",
      "\titers: 200, epoch: 12 | loss: 0.0450721\n",
      "\tspeed: 0.0112s/iter; left time: 222.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0437628 Vali Loss: 0.0512534 Test Loss: 0.0554950\n",
      "Validation loss decreased (0.051414 --> 0.051253).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0407731\n",
      "\tspeed: 0.0260s/iter; left time: 514.7758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0449747\n",
      "\tspeed: 0.0109s/iter; left time: 215.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 226 | Train Loss: 0.0434858 Vali Loss: 0.0510212 Test Loss: 0.0552484\n",
      "Validation loss decreased (0.051253 --> 0.051021).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0429213\n",
      "\tspeed: 0.0290s/iter; left time: 566.4141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441765\n",
      "\tspeed: 0.0119s/iter; left time: 231.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0432644 Vali Loss: 0.0510122 Test Loss: 0.0552304\n",
      "Validation loss decreased (0.051021 --> 0.051012).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0418309\n",
      "\tspeed: 0.0284s/iter; left time: 549.5122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0407279\n",
      "\tspeed: 0.0119s/iter; left time: 229.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0430998 Vali Loss: 0.0508352 Test Loss: 0.0550930\n",
      "Validation loss decreased (0.051012 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0448649\n",
      "\tspeed: 0.0265s/iter; left time: 506.1767s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415453\n",
      "\tspeed: 0.0116s/iter; left time: 220.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0428707 Vali Loss: 0.0507972 Test Loss: 0.0549450\n",
      "Validation loss decreased (0.050835 --> 0.050797).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0412447\n",
      "\tspeed: 0.0284s/iter; left time: 536.5456s\n",
      "\titers: 200, epoch: 17 | loss: 0.0421428\n",
      "\tspeed: 0.0124s/iter; left time: 233.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0427756 Vali Loss: 0.0509308 Test Loss: 0.0550025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0438714\n",
      "\tspeed: 0.0317s/iter; left time: 591.5384s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411248\n",
      "\tspeed: 0.0116s/iter; left time: 214.6642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 226 | Train Loss: 0.0427111 Vali Loss: 0.0506774 Test Loss: 0.0549089\n",
      "Validation loss decreased (0.050797 --> 0.050677).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0438699\n",
      "\tspeed: 0.0279s/iter; left time: 514.4521s\n",
      "\titers: 200, epoch: 19 | loss: 0.0439883\n",
      "\tspeed: 0.0120s/iter; left time: 219.2189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0425621 Vali Loss: 0.0504781 Test Loss: 0.0547615\n",
      "Validation loss decreased (0.050677 --> 0.050478).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443324\n",
      "\tspeed: 0.0284s/iter; left time: 517.3331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0498845\n",
      "\tspeed: 0.0132s/iter; left time: 238.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0424116 Vali Loss: 0.0505399 Test Loss: 0.0547433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0421793\n",
      "\tspeed: 0.0311s/iter; left time: 559.8406s\n",
      "\titers: 200, epoch: 21 | loss: 0.0429938\n",
      "\tspeed: 0.0119s/iter; left time: 212.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0423381 Vali Loss: 0.0505695 Test Loss: 0.0546886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414619\n",
      "\tspeed: 0.0274s/iter; left time: 486.8265s\n",
      "\titers: 200, epoch: 22 | loss: 0.0428697\n",
      "\tspeed: 0.0109s/iter; left time: 193.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0423087 Vali Loss: 0.0504615 Test Loss: 0.0547043\n",
      "Validation loss decreased (0.050478 --> 0.050462).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0432623\n",
      "\tspeed: 0.0273s/iter; left time: 478.8892s\n",
      "\titers: 200, epoch: 23 | loss: 0.0416626\n",
      "\tspeed: 0.0132s/iter; left time: 230.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0422408 Vali Loss: 0.0504132 Test Loss: 0.0545935\n",
      "Validation loss decreased (0.050462 --> 0.050413).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0429033\n",
      "\tspeed: 0.0276s/iter; left time: 478.1290s\n",
      "\titers: 200, epoch: 24 | loss: 0.0424754\n",
      "\tspeed: 0.0126s/iter; left time: 216.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0422113 Vali Loss: 0.0503552 Test Loss: 0.0545690\n",
      "Validation loss decreased (0.050413 --> 0.050355).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423113\n",
      "\tspeed: 0.0304s/iter; left time: 518.4762s\n",
      "\titers: 200, epoch: 25 | loss: 0.0433888\n",
      "\tspeed: 0.0114s/iter; left time: 193.2392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0421563 Vali Loss: 0.0502765 Test Loss: 0.0544758\n",
      "Validation loss decreased (0.050355 --> 0.050276).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0431847\n",
      "\tspeed: 0.0268s/iter; left time: 451.9787s\n",
      "\titers: 200, epoch: 26 | loss: 0.0440871\n",
      "\tspeed: 0.0124s/iter; left time: 208.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0420852 Vali Loss: 0.0502675 Test Loss: 0.0544903\n",
      "Validation loss decreased (0.050276 --> 0.050267).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0451052\n",
      "\tspeed: 0.0275s/iter; left time: 457.9538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0414471\n",
      "\tspeed: 0.0127s/iter; left time: 209.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0420029 Vali Loss: 0.0502640 Test Loss: 0.0544903\n",
      "Validation loss decreased (0.050267 --> 0.050264).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0410312\n",
      "\tspeed: 0.0275s/iter; left time: 451.0224s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397029\n",
      "\tspeed: 0.0112s/iter; left time: 181.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0420169 Vali Loss: 0.0502905 Test Loss: 0.0544227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0439552\n",
      "\tspeed: 0.0268s/iter; left time: 434.0147s\n",
      "\titers: 200, epoch: 29 | loss: 0.0436785\n",
      "\tspeed: 0.0121s/iter; left time: 194.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0420040 Vali Loss: 0.0502262 Test Loss: 0.0544775\n",
      "Validation loss decreased (0.050264 --> 0.050226).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0386494\n",
      "\tspeed: 0.0273s/iter; left time: 435.8998s\n",
      "\titers: 200, epoch: 30 | loss: 0.0414599\n",
      "\tspeed: 0.0114s/iter; left time: 180.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0419425 Vali Loss: 0.0501913 Test Loss: 0.0544087\n",
      "Validation loss decreased (0.050226 --> 0.050191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0415383\n",
      "\tspeed: 0.0284s/iter; left time: 446.9521s\n",
      "\titers: 200, epoch: 31 | loss: 0.0454751\n",
      "\tspeed: 0.0122s/iter; left time: 190.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0419474 Vali Loss: 0.0501453 Test Loss: 0.0544220\n",
      "Validation loss decreased (0.050191 --> 0.050145).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0417625\n",
      "\tspeed: 0.0254s/iter; left time: 393.5596s\n",
      "\titers: 200, epoch: 32 | loss: 0.0423680\n",
      "\tspeed: 0.0114s/iter; left time: 175.3526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 226 | Train Loss: 0.0418900 Vali Loss: 0.0501593 Test Loss: 0.0543905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0450227\n",
      "\tspeed: 0.0287s/iter; left time: 438.5214s\n",
      "\titers: 200, epoch: 33 | loss: 0.0442311\n",
      "\tspeed: 0.0111s/iter; left time: 168.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0418550 Vali Loss: 0.0501616 Test Loss: 0.0544021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0403130\n",
      "\tspeed: 0.0265s/iter; left time: 398.1377s\n",
      "\titers: 200, epoch: 34 | loss: 0.0437343\n",
      "\tspeed: 0.0123s/iter; left time: 184.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0418723 Vali Loss: 0.0501117 Test Loss: 0.0543684\n",
      "Validation loss decreased (0.050145 --> 0.050112).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0398785\n",
      "\tspeed: 0.0289s/iter; left time: 428.2609s\n",
      "\titers: 200, epoch: 35 | loss: 0.0417303\n",
      "\tspeed: 0.0115s/iter; left time: 169.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0418444 Vali Loss: 0.0501631 Test Loss: 0.0543461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0433487\n",
      "\tspeed: 0.0281s/iter; left time: 409.7674s\n",
      "\titers: 200, epoch: 36 | loss: 0.0434720\n",
      "\tspeed: 0.0119s/iter; left time: 172.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0417718 Vali Loss: 0.0501187 Test Loss: 0.0543627\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0401681\n",
      "\tspeed: 0.0268s/iter; left time: 385.0938s\n",
      "\titers: 200, epoch: 37 | loss: 0.0441142\n",
      "\tspeed: 0.0115s/iter; left time: 164.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0417959 Vali Loss: 0.0501724 Test Loss: 0.0543492\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0411178\n",
      "\tspeed: 0.0272s/iter; left time: 384.8570s\n",
      "\titers: 200, epoch: 38 | loss: 0.0432949\n",
      "\tspeed: 0.0118s/iter; left time: 164.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0417960 Vali Loss: 0.0501164 Test Loss: 0.0543611\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0413207\n",
      "\tspeed: 0.0268s/iter; left time: 373.2222s\n",
      "\titers: 200, epoch: 39 | loss: 0.0395798\n",
      "\tspeed: 0.0134s/iter; left time: 185.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0417862 Vali Loss: 0.0501370 Test Loss: 0.0543230\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0393236\n",
      "\tspeed: 0.0276s/iter; left time: 378.2623s\n",
      "\titers: 200, epoch: 40 | loss: 0.0432977\n",
      "\tspeed: 0.0140s/iter; left time: 190.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0417697 Vali Loss: 0.0501129 Test Loss: 0.0543245\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0413589\n",
      "\tspeed: 0.0276s/iter; left time: 371.8289s\n",
      "\titers: 200, epoch: 41 | loss: 0.0408612\n",
      "\tspeed: 0.0118s/iter; left time: 157.1315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0417722 Vali Loss: 0.0501124 Test Loss: 0.0543231\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0411079\n",
      "\tspeed: 0.0275s/iter; left time: 364.1753s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426689\n",
      "\tspeed: 0.0134s/iter; left time: 175.4101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0417917 Vali Loss: 0.0500473 Test Loss: 0.0543122\n",
      "Validation loss decreased (0.050112 --> 0.050047).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0426921\n",
      "\tspeed: 0.0298s/iter; left time: 387.4994s\n",
      "\titers: 200, epoch: 43 | loss: 0.0417973\n",
      "\tspeed: 0.0127s/iter; left time: 164.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0417330 Vali Loss: 0.0501269 Test Loss: 0.0543233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0460333\n",
      "\tspeed: 0.0263s/iter; left time: 336.7133s\n",
      "\titers: 200, epoch: 44 | loss: 0.0428604\n",
      "\tspeed: 0.0118s/iter; left time: 149.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0417183 Vali Loss: 0.0500891 Test Loss: 0.0543393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0413917\n",
      "\tspeed: 0.0278s/iter; left time: 349.1030s\n",
      "\titers: 200, epoch: 45 | loss: 0.0451330\n",
      "\tspeed: 0.0121s/iter; left time: 150.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0417131 Vali Loss: 0.0501954 Test Loss: 0.0542969\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0412224\n",
      "\tspeed: 0.0257s/iter; left time: 317.2667s\n",
      "\titers: 200, epoch: 46 | loss: 0.0388272\n",
      "\tspeed: 0.0122s/iter; left time: 149.6360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0417154 Vali Loss: 0.0500848 Test Loss: 0.0543053\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0411421\n",
      "\tspeed: 0.0256s/iter; left time: 309.2963s\n",
      "\titers: 200, epoch: 47 | loss: 0.0433625\n",
      "\tspeed: 0.0123s/iter; left time: 147.1452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0416896 Vali Loss: 0.0500637 Test Loss: 0.0543185\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0429682\n",
      "\tspeed: 0.0280s/iter; left time: 332.5864s\n",
      "\titers: 200, epoch: 48 | loss: 0.0388278\n",
      "\tspeed: 0.0115s/iter; left time: 135.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0417241 Vali Loss: 0.0501448 Test Loss: 0.0543115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0408700\n",
      "\tspeed: 0.0274s/iter; left time: 318.8413s\n",
      "\titers: 200, epoch: 49 | loss: 0.0415598\n",
      "\tspeed: 0.0126s/iter; left time: 145.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0417560 Vali Loss: 0.0500766 Test Loss: 0.0543064\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0433627\n",
      "\tspeed: 0.0270s/iter; left time: 307.9947s\n",
      "\titers: 200, epoch: 50 | loss: 0.0431110\n",
      "\tspeed: 0.0123s/iter; left time: 139.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0417134 Vali Loss: 0.0501223 Test Loss: 0.0543024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0428324\n",
      "\tspeed: 0.0267s/iter; left time: 298.6868s\n",
      "\titers: 200, epoch: 51 | loss: 0.0426559\n",
      "\tspeed: 0.0122s/iter; left time: 134.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0417224 Vali Loss: 0.0500905 Test Loss: 0.0542994\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0420346\n",
      "\tspeed: 0.0272s/iter; left time: 298.8920s\n",
      "\titers: 200, epoch: 52 | loss: 0.0446948\n",
      "\tspeed: 0.0113s/iter; left time: 122.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0417438 Vali Loss: 0.0500549 Test Loss: 0.0543111\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009950376115739346, rmse:0.09975156933069229, mae:0.05431215465068817, rse:0.3848387897014618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1132520\n",
      "\tspeed: 0.0132s/iter; left time: 297.2207s\n",
      "\titers: 200, epoch: 1 | loss: 0.0936352\n",
      "\tspeed: 0.0115s/iter; left time: 257.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.1100713 Vali Loss: 0.0928013 Test Loss: 0.1021270\n",
      "Validation loss decreased (inf --> 0.092801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561683\n",
      "\tspeed: 0.0279s/iter; left time: 621.7909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500469\n",
      "\tspeed: 0.0119s/iter; left time: 263.9628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0584609 Vali Loss: 0.0593945 Test Loss: 0.0617017\n",
      "Validation loss decreased (0.092801 --> 0.059395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0524821\n",
      "\tspeed: 0.0300s/iter; left time: 661.1010s\n",
      "\titers: 200, epoch: 3 | loss: 0.0518600\n",
      "\tspeed: 0.0117s/iter; left time: 257.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0507010 Vali Loss: 0.0567825 Test Loss: 0.0595066\n",
      "Validation loss decreased (0.059395 --> 0.056782).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0513417\n",
      "\tspeed: 0.0290s/iter; left time: 632.3452s\n",
      "\titers: 200, epoch: 4 | loss: 0.0476954\n",
      "\tspeed: 0.0115s/iter; left time: 250.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0487247 Vali Loss: 0.0548968 Test Loss: 0.0583465\n",
      "Validation loss decreased (0.056782 --> 0.054897).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0463436\n",
      "\tspeed: 0.0274s/iter; left time: 591.8462s\n",
      "\titers: 200, epoch: 5 | loss: 0.0457454\n",
      "\tspeed: 0.0131s/iter; left time: 280.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0475371 Vali Loss: 0.0540130 Test Loss: 0.0578556\n",
      "Validation loss decreased (0.054897 --> 0.054013).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0482146\n",
      "\tspeed: 0.0287s/iter; left time: 613.4564s\n",
      "\titers: 200, epoch: 6 | loss: 0.0426126\n",
      "\tspeed: 0.0118s/iter; left time: 249.9885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0466017 Vali Loss: 0.0535288 Test Loss: 0.0573014\n",
      "Validation loss decreased (0.054013 --> 0.053529).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0471374\n",
      "\tspeed: 0.0281s/iter; left time: 594.3587s\n",
      "\titers: 200, epoch: 7 | loss: 0.0462750\n",
      "\tspeed: 0.0129s/iter; left time: 271.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0458805 Vali Loss: 0.0530002 Test Loss: 0.0569769\n",
      "Validation loss decreased (0.053529 --> 0.053000).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0432870\n",
      "\tspeed: 0.0327s/iter; left time: 683.8869s\n",
      "\titers: 200, epoch: 8 | loss: 0.0464771\n",
      "\tspeed: 0.0157s/iter; left time: 327.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0453083 Vali Loss: 0.0525476 Test Loss: 0.0566880\n",
      "Validation loss decreased (0.053000 --> 0.052548).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0439847\n",
      "\tspeed: 0.0334s/iter; left time: 690.6590s\n",
      "\titers: 200, epoch: 9 | loss: 0.0429174\n",
      "\tspeed: 0.0119s/iter; left time: 244.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0448298 Vali Loss: 0.0522136 Test Loss: 0.0562477\n",
      "Validation loss decreased (0.052548 --> 0.052214).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0473599\n",
      "\tspeed: 0.0308s/iter; left time: 629.5455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0475908\n",
      "\tspeed: 0.0141s/iter; left time: 288.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0443794 Vali Loss: 0.0519422 Test Loss: 0.0561186\n",
      "Validation loss decreased (0.052214 --> 0.051942).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0444583\n",
      "\tspeed: 0.0281s/iter; left time: 567.8487s\n",
      "\titers: 200, epoch: 11 | loss: 0.0427089\n",
      "\tspeed: 0.0138s/iter; left time: 277.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0440518 Vali Loss: 0.0515362 Test Loss: 0.0558749\n",
      "Validation loss decreased (0.051942 --> 0.051536).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0448553\n",
      "\tspeed: 0.0275s/iter; left time: 550.6003s\n",
      "\titers: 200, epoch: 12 | loss: 0.0447962\n",
      "\tspeed: 0.0109s/iter; left time: 217.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0438076 Vali Loss: 0.0513053 Test Loss: 0.0556109\n",
      "Validation loss decreased (0.051536 --> 0.051305).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434728\n",
      "\tspeed: 0.0278s/iter; left time: 550.7100s\n",
      "\titers: 200, epoch: 13 | loss: 0.0442762\n",
      "\tspeed: 0.0111s/iter; left time: 219.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0434890 Vali Loss: 0.0513953 Test Loss: 0.0555171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0443075\n",
      "\tspeed: 0.0261s/iter; left time: 509.9389s\n",
      "\titers: 200, epoch: 14 | loss: 0.0430610\n",
      "\tspeed: 0.0115s/iter; left time: 224.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 226 | Train Loss: 0.0432744 Vali Loss: 0.0510744 Test Loss: 0.0554607\n",
      "Validation loss decreased (0.051305 --> 0.051074).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0478131\n",
      "\tspeed: 0.0278s/iter; left time: 538.2221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0429646\n",
      "\tspeed: 0.0122s/iter; left time: 235.0548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0430683 Vali Loss: 0.0510316 Test Loss: 0.0552032\n",
      "Validation loss decreased (0.051074 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0433127\n",
      "\tspeed: 0.0278s/iter; left time: 530.7388s\n",
      "\titers: 200, epoch: 16 | loss: 0.0383054\n",
      "\tspeed: 0.0116s/iter; left time: 220.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0430262 Vali Loss: 0.0509267 Test Loss: 0.0551992\n",
      "Validation loss decreased (0.051032 --> 0.050927).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0434445\n",
      "\tspeed: 0.0290s/iter; left time: 547.1359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0434979\n",
      "\tspeed: 0.0119s/iter; left time: 223.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0427973 Vali Loss: 0.0510822 Test Loss: 0.0551089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0394827\n",
      "\tspeed: 0.0273s/iter; left time: 509.1593s\n",
      "\titers: 200, epoch: 18 | loss: 0.0379569\n",
      "\tspeed: 0.0114s/iter; left time: 211.1277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0426730 Vali Loss: 0.0507940 Test Loss: 0.0550116\n",
      "Validation loss decreased (0.050927 --> 0.050794).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458686\n",
      "\tspeed: 0.0291s/iter; left time: 536.9927s\n",
      "\titers: 200, epoch: 19 | loss: 0.0403266\n",
      "\tspeed: 0.0116s/iter; left time: 212.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0425948 Vali Loss: 0.0506898 Test Loss: 0.0550069\n",
      "Validation loss decreased (0.050794 --> 0.050690).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0466481\n",
      "\tspeed: 0.0285s/iter; left time: 518.3718s\n",
      "\titers: 200, epoch: 20 | loss: 0.0429751\n",
      "\tspeed: 0.0122s/iter; left time: 220.2748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0425307 Vali Loss: 0.0506668 Test Loss: 0.0549237\n",
      "Validation loss decreased (0.050690 --> 0.050667).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0463741\n",
      "\tspeed: 0.0276s/iter; left time: 496.2116s\n",
      "\titers: 200, epoch: 21 | loss: 0.0434584\n",
      "\tspeed: 0.0125s/iter; left time: 223.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0424368 Vali Loss: 0.0507159 Test Loss: 0.0549146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0432137\n",
      "\tspeed: 0.0270s/iter; left time: 478.9800s\n",
      "\titers: 200, epoch: 22 | loss: 0.0440204\n",
      "\tspeed: 0.0135s/iter; left time: 239.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0423375 Vali Loss: 0.0507138 Test Loss: 0.0549455\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0391456\n",
      "\tspeed: 0.0269s/iter; left time: 471.1515s\n",
      "\titers: 200, epoch: 23 | loss: 0.0456504\n",
      "\tspeed: 0.0127s/iter; left time: 221.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0423303 Vali Loss: 0.0505761 Test Loss: 0.0547516\n",
      "Validation loss decreased (0.050667 --> 0.050576).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0495292\n",
      "\tspeed: 0.0277s/iter; left time: 479.3011s\n",
      "\titers: 200, epoch: 24 | loss: 0.0441425\n",
      "\tspeed: 0.0131s/iter; left time: 225.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0422179 Vali Loss: 0.0504646 Test Loss: 0.0548036\n",
      "Validation loss decreased (0.050576 --> 0.050465).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0434198\n",
      "\tspeed: 0.0265s/iter; left time: 453.2344s\n",
      "\titers: 200, epoch: 25 | loss: 0.0399199\n",
      "\tspeed: 0.0117s/iter; left time: 198.7763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0421116 Vali Loss: 0.0505635 Test Loss: 0.0547086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0391855\n",
      "\tspeed: 0.0289s/iter; left time: 486.2451s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404929\n",
      "\tspeed: 0.0113s/iter; left time: 189.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0420860 Vali Loss: 0.0504334 Test Loss: 0.0546581\n",
      "Validation loss decreased (0.050465 --> 0.050433).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0421239\n",
      "\tspeed: 0.0288s/iter; left time: 479.4316s\n",
      "\titers: 200, epoch: 27 | loss: 0.0430600\n",
      "\tspeed: 0.0117s/iter; left time: 193.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0420590 Vali Loss: 0.0504060 Test Loss: 0.0546327\n",
      "Validation loss decreased (0.050433 --> 0.050406).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0418076\n",
      "\tspeed: 0.0262s/iter; left time: 429.7771s\n",
      "\titers: 200, epoch: 28 | loss: 0.0465923\n",
      "\tspeed: 0.0110s/iter; left time: 179.8877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 226 | Train Loss: 0.0420133 Vali Loss: 0.0503824 Test Loss: 0.0546185\n",
      "Validation loss decreased (0.050406 --> 0.050382).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0430298\n",
      "\tspeed: 0.0268s/iter; left time: 433.2265s\n",
      "\titers: 200, epoch: 29 | loss: 0.0435396\n",
      "\tspeed: 0.0116s/iter; left time: 187.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0419836 Vali Loss: 0.0504460 Test Loss: 0.0546655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0395162\n",
      "\tspeed: 0.0268s/iter; left time: 427.9269s\n",
      "\titers: 200, epoch: 30 | loss: 0.0399079\n",
      "\tspeed: 0.0130s/iter; left time: 205.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0419524 Vali Loss: 0.0503811 Test Loss: 0.0545891\n",
      "Validation loss decreased (0.050382 --> 0.050381).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0434384\n",
      "\tspeed: 0.0285s/iter; left time: 447.4180s\n",
      "\titers: 200, epoch: 31 | loss: 0.0422784\n",
      "\tspeed: 0.0114s/iter; left time: 177.7662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0419383 Vali Loss: 0.0504887 Test Loss: 0.0545525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0440265\n",
      "\tspeed: 0.0284s/iter; left time: 440.6071s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421281\n",
      "\tspeed: 0.0110s/iter; left time: 169.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418608 Vali Loss: 0.0503399 Test Loss: 0.0545567\n",
      "Validation loss decreased (0.050381 --> 0.050340).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0409427\n",
      "\tspeed: 0.0294s/iter; left time: 449.6261s\n",
      "\titers: 200, epoch: 33 | loss: 0.0411612\n",
      "\tspeed: 0.0126s/iter; left time: 191.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0419174 Vali Loss: 0.0503196 Test Loss: 0.0545303\n",
      "Validation loss decreased (0.050340 --> 0.050320).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0402150\n",
      "\tspeed: 0.0267s/iter; left time: 401.9880s\n",
      "\titers: 200, epoch: 34 | loss: 0.0400097\n",
      "\tspeed: 0.0131s/iter; left time: 195.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0418580 Vali Loss: 0.0503860 Test Loss: 0.0545335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0419727\n",
      "\tspeed: 0.0287s/iter; left time: 424.6724s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405766\n",
      "\tspeed: 0.0123s/iter; left time: 180.5289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418350 Vali Loss: 0.0503724 Test Loss: 0.0545397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0433877\n",
      "\tspeed: 0.0278s/iter; left time: 405.8178s\n",
      "\titers: 200, epoch: 36 | loss: 0.0435869\n",
      "\tspeed: 0.0116s/iter; left time: 168.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0417693 Vali Loss: 0.0502802 Test Loss: 0.0544944\n",
      "Validation loss decreased (0.050320 --> 0.050280).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0458055\n",
      "\tspeed: 0.0283s/iter; left time: 405.9492s\n",
      "\titers: 200, epoch: 37 | loss: 0.0446754\n",
      "\tspeed: 0.0119s/iter; left time: 169.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418336 Vali Loss: 0.0503019 Test Loss: 0.0545030\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0411173\n",
      "\tspeed: 0.0282s/iter; left time: 398.5139s\n",
      "\titers: 200, epoch: 38 | loss: 0.0411220\n",
      "\tspeed: 0.0133s/iter; left time: 186.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0418050 Vali Loss: 0.0503602 Test Loss: 0.0544847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0413137\n",
      "\tspeed: 0.0278s/iter; left time: 387.2038s\n",
      "\titers: 200, epoch: 39 | loss: 0.0416295\n",
      "\tspeed: 0.0125s/iter; left time: 172.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0417889 Vali Loss: 0.0503047 Test Loss: 0.0544787\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0432878\n",
      "\tspeed: 0.0281s/iter; left time: 384.8453s\n",
      "\titers: 200, epoch: 40 | loss: 0.0432607\n",
      "\tspeed: 0.0111s/iter; left time: 150.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0417856 Vali Loss: 0.0502169 Test Loss: 0.0544858\n",
      "Validation loss decreased (0.050280 --> 0.050217).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0388566\n",
      "\tspeed: 0.0297s/iter; left time: 399.2168s\n",
      "\titers: 200, epoch: 41 | loss: 0.0415661\n",
      "\tspeed: 0.0135s/iter; left time: 180.3718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 226 | Train Loss: 0.0417968 Vali Loss: 0.0503313 Test Loss: 0.0544953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0421035\n",
      "\tspeed: 0.0279s/iter; left time: 368.7326s\n",
      "\titers: 200, epoch: 42 | loss: 0.0378885\n",
      "\tspeed: 0.0117s/iter; left time: 154.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0417965 Vali Loss: 0.0501956 Test Loss: 0.0544790\n",
      "Validation loss decreased (0.050217 --> 0.050196).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0376006\n",
      "\tspeed: 0.0267s/iter; left time: 347.5844s\n",
      "\titers: 200, epoch: 43 | loss: 0.0401736\n",
      "\tspeed: 0.0114s/iter; left time: 146.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0417676 Vali Loss: 0.0502214 Test Loss: 0.0544823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0423001\n",
      "\tspeed: 0.0292s/iter; left time: 372.6998s\n",
      "\titers: 200, epoch: 44 | loss: 0.0432456\n",
      "\tspeed: 0.0123s/iter; left time: 155.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 226 | Train Loss: 0.0417521 Vali Loss: 0.0502241 Test Loss: 0.0544708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0473008\n",
      "\tspeed: 0.0268s/iter; left time: 336.7709s\n",
      "\titers: 200, epoch: 45 | loss: 0.0419766\n",
      "\tspeed: 0.0125s/iter; left time: 155.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0417417 Vali Loss: 0.0502226 Test Loss: 0.0544550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400830\n",
      "\tspeed: 0.0257s/iter; left time: 316.9914s\n",
      "\titers: 200, epoch: 46 | loss: 0.0410218\n",
      "\tspeed: 0.0109s/iter; left time: 132.8488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.68s\n",
      "Steps: 226 | Train Loss: 0.0417677 Vali Loss: 0.0502597 Test Loss: 0.0544538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393896\n",
      "\tspeed: 0.0263s/iter; left time: 318.7374s\n",
      "\titers: 200, epoch: 47 | loss: 0.0409002\n",
      "\tspeed: 0.0120s/iter; left time: 144.0154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0417359 Vali Loss: 0.0502057 Test Loss: 0.0544625\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393750\n",
      "\tspeed: 0.0262s/iter; left time: 311.5134s\n",
      "\titers: 200, epoch: 48 | loss: 0.0431451\n",
      "\tspeed: 0.0119s/iter; left time: 140.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0417638 Vali Loss: 0.0502611 Test Loss: 0.0544590\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0408053\n",
      "\tspeed: 0.0261s/iter; left time: 303.7718s\n",
      "\titers: 200, epoch: 49 | loss: 0.0423045\n",
      "\tspeed: 0.0117s/iter; left time: 135.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0417316 Vali Loss: 0.0502708 Test Loss: 0.0544587\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0426644\n",
      "\tspeed: 0.0275s/iter; left time: 313.6911s\n",
      "\titers: 200, epoch: 50 | loss: 0.0394742\n",
      "\tspeed: 0.0124s/iter; left time: 140.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0417384 Vali Loss: 0.0502756 Test Loss: 0.0544553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0417658\n",
      "\tspeed: 0.0281s/iter; left time: 315.2885s\n",
      "\titers: 200, epoch: 51 | loss: 0.0443871\n",
      "\tspeed: 0.0110s/iter; left time: 121.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0417456 Vali Loss: 0.0502617 Test Loss: 0.0544569\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0391585\n",
      "\tspeed: 0.0267s/iter; left time: 293.0616s\n",
      "\titers: 200, epoch: 52 | loss: 0.0424905\n",
      "\tspeed: 0.0127s/iter; left time: 138.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0417283 Vali Loss: 0.0502521 Test Loss: 0.0544676\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009985145181417465, rmse:0.099925696849823, mae:0.05447903648018837, rse:0.3855105936527252\n",
      "Intermediate time for FR and pred_len 24: 00h:07m:07.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1123679\n",
      "\tspeed: 0.0368s/iter; left time: 823.6254s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958893\n",
      "\tspeed: 0.0191s/iter; left time: 424.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1128916 Vali Loss: 0.0989846 Test Loss: 0.1113308\n",
      "Validation loss decreased (inf --> 0.098985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745022\n",
      "\tspeed: 0.0299s/iter; left time: 663.2570s\n",
      "\titers: 200, epoch: 2 | loss: 0.0712615\n",
      "\tspeed: 0.0155s/iter; left time: 343.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0742915 Vali Loss: 0.0767684 Test Loss: 0.0858899\n",
      "Validation loss decreased (0.098985 --> 0.076768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0659868\n",
      "\tspeed: 0.0292s/iter; left time: 640.4535s\n",
      "\titers: 200, epoch: 3 | loss: 0.0683075\n",
      "\tspeed: 0.0142s/iter; left time: 309.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0667917 Vali Loss: 0.0733530 Test Loss: 0.0831187\n",
      "Validation loss decreased (0.076768 --> 0.073353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611087\n",
      "\tspeed: 0.0294s/iter; left time: 639.5643s\n",
      "\titers: 200, epoch: 4 | loss: 0.0628312\n",
      "\tspeed: 0.0154s/iter; left time: 333.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0646899 Vali Loss: 0.0722058 Test Loss: 0.0819560\n",
      "Validation loss decreased (0.073353 --> 0.072206).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643648\n",
      "\tspeed: 0.0304s/iter; left time: 653.2929s\n",
      "\titers: 200, epoch: 5 | loss: 0.0637357\n",
      "\tspeed: 0.0140s/iter; left time: 300.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0635126 Vali Loss: 0.0712091 Test Loss: 0.0811195\n",
      "Validation loss decreased (0.072206 --> 0.071209).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619154\n",
      "\tspeed: 0.0295s/iter; left time: 627.6468s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602226\n",
      "\tspeed: 0.0145s/iter; left time: 306.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0626181 Vali Loss: 0.0708816 Test Loss: 0.0805953\n",
      "Validation loss decreased (0.071209 --> 0.070882).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0573235\n",
      "\tspeed: 0.0315s/iter; left time: 662.3238s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595317\n",
      "\tspeed: 0.0144s/iter; left time: 301.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0619120 Vali Loss: 0.0703958 Test Loss: 0.0801718\n",
      "Validation loss decreased (0.070882 --> 0.070396).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658628\n",
      "\tspeed: 0.0313s/iter; left time: 652.1954s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633189\n",
      "\tspeed: 0.0138s/iter; left time: 286.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0613964 Vali Loss: 0.0702106 Test Loss: 0.0801473\n",
      "Validation loss decreased (0.070396 --> 0.070211).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600250\n",
      "\tspeed: 0.0294s/iter; left time: 605.1540s\n",
      "\titers: 200, epoch: 9 | loss: 0.0614435\n",
      "\tspeed: 0.0146s/iter; left time: 298.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0609292 Vali Loss: 0.0699040 Test Loss: 0.0799337\n",
      "Validation loss decreased (0.070211 --> 0.069904).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612160\n",
      "\tspeed: 0.0299s/iter; left time: 610.1638s\n",
      "\titers: 200, epoch: 10 | loss: 0.0641046\n",
      "\tspeed: 0.0140s/iter; left time: 284.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0605648 Vali Loss: 0.0696879 Test Loss: 0.0796519\n",
      "Validation loss decreased (0.069904 --> 0.069688).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595196\n",
      "\tspeed: 0.0293s/iter; left time: 591.3284s\n",
      "\titers: 200, epoch: 11 | loss: 0.0624229\n",
      "\tspeed: 0.0135s/iter; left time: 270.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0602561 Vali Loss: 0.0694851 Test Loss: 0.0793414\n",
      "Validation loss decreased (0.069688 --> 0.069485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0597834\n",
      "\tspeed: 0.0298s/iter; left time: 593.3318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628897\n",
      "\tspeed: 0.0145s/iter; left time: 286.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0599916 Vali Loss: 0.0693257 Test Loss: 0.0792334\n",
      "Validation loss decreased (0.069485 --> 0.069326).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0558545\n",
      "\tspeed: 0.0301s/iter; left time: 592.0259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0633420\n",
      "\tspeed: 0.0146s/iter; left time: 286.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0597048 Vali Loss: 0.0692271 Test Loss: 0.0793881\n",
      "Validation loss decreased (0.069326 --> 0.069227).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0623547\n",
      "\tspeed: 0.0304s/iter; left time: 591.3906s\n",
      "\titers: 200, epoch: 14 | loss: 0.0607159\n",
      "\tspeed: 0.0148s/iter; left time: 286.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0595040 Vali Loss: 0.0691486 Test Loss: 0.0791799\n",
      "Validation loss decreased (0.069227 --> 0.069149).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574526\n",
      "\tspeed: 0.0282s/iter; left time: 542.7165s\n",
      "\titers: 200, epoch: 15 | loss: 0.0585850\n",
      "\tspeed: 0.0125s/iter; left time: 239.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0592926 Vali Loss: 0.0690939 Test Loss: 0.0789895\n",
      "Validation loss decreased (0.069149 --> 0.069094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0594159\n",
      "\tspeed: 0.0278s/iter; left time: 528.4335s\n",
      "\titers: 200, epoch: 16 | loss: 0.0593273\n",
      "\tspeed: 0.0131s/iter; left time: 247.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0591808 Vali Loss: 0.0690333 Test Loss: 0.0789739\n",
      "Validation loss decreased (0.069094 --> 0.069033).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589404\n",
      "\tspeed: 0.0312s/iter; left time: 586.7048s\n",
      "\titers: 200, epoch: 17 | loss: 0.0600491\n",
      "\tspeed: 0.0145s/iter; left time: 271.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0589729 Vali Loss: 0.0689332 Test Loss: 0.0788983\n",
      "Validation loss decreased (0.069033 --> 0.068933).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599934\n",
      "\tspeed: 0.0300s/iter; left time: 556.4016s\n",
      "\titers: 200, epoch: 18 | loss: 0.0601626\n",
      "\tspeed: 0.0142s/iter; left time: 262.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0588744 Vali Loss: 0.0689585 Test Loss: 0.0789438\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0574171\n",
      "\tspeed: 0.0301s/iter; left time: 552.2804s\n",
      "\titers: 200, epoch: 19 | loss: 0.0597989\n",
      "\tspeed: 0.0142s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0587569 Vali Loss: 0.0688923 Test Loss: 0.0789166\n",
      "Validation loss decreased (0.068933 --> 0.068892).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0599075\n",
      "\tspeed: 0.0318s/iter; left time: 576.1903s\n",
      "\titers: 200, epoch: 20 | loss: 0.0607334\n",
      "\tspeed: 0.0144s/iter; left time: 260.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0586495 Vali Loss: 0.0688203 Test Loss: 0.0789143\n",
      "Validation loss decreased (0.068892 --> 0.068820).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0559591\n",
      "\tspeed: 0.0300s/iter; left time: 537.8844s\n",
      "\titers: 200, epoch: 21 | loss: 0.0560985\n",
      "\tspeed: 0.0136s/iter; left time: 242.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0585981 Vali Loss: 0.0689306 Test Loss: 0.0788465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0595138\n",
      "\tspeed: 0.0290s/iter; left time: 512.5853s\n",
      "\titers: 200, epoch: 22 | loss: 0.0625688\n",
      "\tspeed: 0.0151s/iter; left time: 265.3506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0584874 Vali Loss: 0.0688657 Test Loss: 0.0787652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0635147\n",
      "\tspeed: 0.0295s/iter; left time: 515.2432s\n",
      "\titers: 200, epoch: 23 | loss: 0.0556708\n",
      "\tspeed: 0.0137s/iter; left time: 237.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0584421 Vali Loss: 0.0688052 Test Loss: 0.0788075\n",
      "Validation loss decreased (0.068820 --> 0.068805).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0591203\n",
      "\tspeed: 0.0308s/iter; left time: 530.1169s\n",
      "\titers: 200, epoch: 24 | loss: 0.0588287\n",
      "\tspeed: 0.0145s/iter; left time: 247.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0583241 Vali Loss: 0.0688512 Test Loss: 0.0787713\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0583268\n",
      "\tspeed: 0.0289s/iter; left time: 491.5857s\n",
      "\titers: 200, epoch: 25 | loss: 0.0582507\n",
      "\tspeed: 0.0149s/iter; left time: 252.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0583419 Vali Loss: 0.0687748 Test Loss: 0.0787924\n",
      "Validation loss decreased (0.068805 --> 0.068775).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0603914\n",
      "\tspeed: 0.0310s/iter; left time: 519.6890s\n",
      "\titers: 200, epoch: 26 | loss: 0.0552229\n",
      "\tspeed: 0.0158s/iter; left time: 263.1600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0582278 Vali Loss: 0.0688510 Test Loss: 0.0787250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0577940\n",
      "\tspeed: 0.0299s/iter; left time: 495.3489s\n",
      "\titers: 200, epoch: 27 | loss: 0.0601696\n",
      "\tspeed: 0.0150s/iter; left time: 246.5478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0582012 Vali Loss: 0.0688192 Test Loss: 0.0786948\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578605\n",
      "\tspeed: 0.0294s/iter; left time: 480.7478s\n",
      "\titers: 200, epoch: 28 | loss: 0.0600844\n",
      "\tspeed: 0.0147s/iter; left time: 238.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0581673 Vali Loss: 0.0688492 Test Loss: 0.0787168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0583453\n",
      "\tspeed: 0.0299s/iter; left time: 480.8207s\n",
      "\titers: 200, epoch: 29 | loss: 0.0567716\n",
      "\tspeed: 0.0155s/iter; left time: 247.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0581208 Vali Loss: 0.0688215 Test Loss: 0.0787646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0565776\n",
      "\tspeed: 0.0270s/iter; left time: 428.6058s\n",
      "\titers: 200, epoch: 30 | loss: 0.0572355\n",
      "\tspeed: 0.0122s/iter; left time: 191.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0581081 Vali Loss: 0.0688053 Test Loss: 0.0787088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0574476\n",
      "\tspeed: 0.0281s/iter; left time: 439.2139s\n",
      "\titers: 200, epoch: 31 | loss: 0.0602526\n",
      "\tspeed: 0.0118s/iter; left time: 183.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0580495 Vali Loss: 0.0688045 Test Loss: 0.0786794\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0563497\n",
      "\tspeed: 0.0262s/iter; left time: 404.6826s\n",
      "\titers: 200, epoch: 32 | loss: 0.0547948\n",
      "\tspeed: 0.0159s/iter; left time: 243.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0580019 Vali Loss: 0.0688197 Test Loss: 0.0786736\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0594476\n",
      "\tspeed: 0.0313s/iter; left time: 475.3239s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562596\n",
      "\tspeed: 0.0155s/iter; left time: 233.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0580157 Vali Loss: 0.0687966 Test Loss: 0.0787213\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0581558\n",
      "\tspeed: 0.0301s/iter; left time: 450.2101s\n",
      "\titers: 200, epoch: 34 | loss: 0.0557810\n",
      "\tspeed: 0.0138s/iter; left time: 205.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0579935 Vali Loss: 0.0687963 Test Loss: 0.0786681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0563106\n",
      "\tspeed: 0.0292s/iter; left time: 430.2525s\n",
      "\titers: 200, epoch: 35 | loss: 0.0524707\n",
      "\tspeed: 0.0144s/iter; left time: 211.2295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0579753 Vali Loss: 0.0687898 Test Loss: 0.0786819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0190742090344429, rmse:0.13810941576957703, mae:0.07879239320755005, rse:0.5342438817024231\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1166308\n",
      "\tspeed: 0.0159s/iter; left time: 355.2066s\n",
      "\titers: 200, epoch: 1 | loss: 0.0994046\n",
      "\tspeed: 0.0146s/iter; left time: 326.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.1117094 Vali Loss: 0.0984777 Test Loss: 0.1107020\n",
      "Validation loss decreased (inf --> 0.098478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0687049\n",
      "\tspeed: 0.0310s/iter; left time: 688.1168s\n",
      "\titers: 200, epoch: 2 | loss: 0.0646807\n",
      "\tspeed: 0.0152s/iter; left time: 334.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0741771 Vali Loss: 0.0772416 Test Loss: 0.0861534\n",
      "Validation loss decreased (0.098478 --> 0.077242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0712700\n",
      "\tspeed: 0.0307s/iter; left time: 674.4700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663007\n",
      "\tspeed: 0.0142s/iter; left time: 310.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0670107 Vali Loss: 0.0735325 Test Loss: 0.0832724\n",
      "Validation loss decreased (0.077242 --> 0.073533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0639523\n",
      "\tspeed: 0.0304s/iter; left time: 660.3264s\n",
      "\titers: 200, epoch: 4 | loss: 0.0674347\n",
      "\tspeed: 0.0146s/iter; left time: 315.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0648524 Vali Loss: 0.0721268 Test Loss: 0.0823177\n",
      "Validation loss decreased (0.073533 --> 0.072127).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598700\n",
      "\tspeed: 0.0316s/iter; left time: 680.2964s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624903\n",
      "\tspeed: 0.0137s/iter; left time: 292.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0635970 Vali Loss: 0.0713102 Test Loss: 0.0813186\n",
      "Validation loss decreased (0.072127 --> 0.071310).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572047\n",
      "\tspeed: 0.0304s/iter; left time: 647.7199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0654277\n",
      "\tspeed: 0.0137s/iter; left time: 290.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0626289 Vali Loss: 0.0707619 Test Loss: 0.0812851\n",
      "Validation loss decreased (0.071310 --> 0.070762).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0640521\n",
      "\tspeed: 0.0322s/iter; left time: 677.7879s\n",
      "\titers: 200, epoch: 7 | loss: 0.0631458\n",
      "\tspeed: 0.0140s/iter; left time: 292.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0619283 Vali Loss: 0.0702095 Test Loss: 0.0806952\n",
      "Validation loss decreased (0.070762 --> 0.070209).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0586155\n",
      "\tspeed: 0.0303s/iter; left time: 630.4248s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610592\n",
      "\tspeed: 0.0125s/iter; left time: 259.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.0613886 Vali Loss: 0.0699927 Test Loss: 0.0804892\n",
      "Validation loss decreased (0.070209 --> 0.069993).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0590662\n",
      "\tspeed: 0.0295s/iter; left time: 607.9826s\n",
      "\titers: 200, epoch: 9 | loss: 0.0599735\n",
      "\tspeed: 0.0135s/iter; left time: 276.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 225 | Train Loss: 0.0609320 Vali Loss: 0.0695000 Test Loss: 0.0799430\n",
      "Validation loss decreased (0.069993 --> 0.069500).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586988\n",
      "\tspeed: 0.0293s/iter; left time: 597.5257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605690\n",
      "\tspeed: 0.0121s/iter; left time: 245.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0605663 Vali Loss: 0.0694764 Test Loss: 0.0797163\n",
      "Validation loss decreased (0.069500 --> 0.069476).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579402\n",
      "\tspeed: 0.0278s/iter; left time: 560.6244s\n",
      "\titers: 200, epoch: 11 | loss: 0.0572975\n",
      "\tspeed: 0.0127s/iter; left time: 254.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0602539 Vali Loss: 0.0695163 Test Loss: 0.0795091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0620443\n",
      "\tspeed: 0.0278s/iter; left time: 554.5792s\n",
      "\titers: 200, epoch: 12 | loss: 0.0597114\n",
      "\tspeed: 0.0126s/iter; left time: 249.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0599766 Vali Loss: 0.0692275 Test Loss: 0.0796349\n",
      "Validation loss decreased (0.069476 --> 0.069227).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643581\n",
      "\tspeed: 0.0307s/iter; left time: 604.3868s\n",
      "\titers: 200, epoch: 13 | loss: 0.0598506\n",
      "\tspeed: 0.0127s/iter; left time: 249.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 225 | Train Loss: 0.0596898 Vali Loss: 0.0689855 Test Loss: 0.0796881\n",
      "Validation loss decreased (0.069227 --> 0.068986).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0596512\n",
      "\tspeed: 0.0287s/iter; left time: 558.9535s\n",
      "\titers: 200, epoch: 14 | loss: 0.0564288\n",
      "\tspeed: 0.0193s/iter; left time: 374.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0595472 Vali Loss: 0.0690365 Test Loss: 0.0794910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0556980\n",
      "\tspeed: 0.0384s/iter; left time: 739.9536s\n",
      "\titers: 200, epoch: 15 | loss: 0.0596696\n",
      "\tspeed: 0.0159s/iter; left time: 303.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0593626 Vali Loss: 0.0688358 Test Loss: 0.0795370\n",
      "Validation loss decreased (0.068986 --> 0.068836).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0549609\n",
      "\tspeed: 0.0346s/iter; left time: 658.5274s\n",
      "\titers: 200, epoch: 16 | loss: 0.0632015\n",
      "\tspeed: 0.0176s/iter; left time: 333.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0592233 Vali Loss: 0.0688676 Test Loss: 0.0792973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562952\n",
      "\tspeed: 0.0360s/iter; left time: 676.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0567398\n",
      "\tspeed: 0.0190s/iter; left time: 355.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0590819 Vali Loss: 0.0688663 Test Loss: 0.0794996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0627169\n",
      "\tspeed: 0.0368s/iter; left time: 683.1355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0635834\n",
      "\tspeed: 0.0186s/iter; left time: 343.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0588690 Vali Loss: 0.0687865 Test Loss: 0.0791472\n",
      "Validation loss decreased (0.068836 --> 0.068786).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0616352\n",
      "\tspeed: 0.0353s/iter; left time: 648.4132s\n",
      "\titers: 200, epoch: 19 | loss: 0.0590960\n",
      "\tspeed: 0.0164s/iter; left time: 298.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0588683 Vali Loss: 0.0687898 Test Loss: 0.0792912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0610490\n",
      "\tspeed: 0.0321s/iter; left time: 582.4944s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584898\n",
      "\tspeed: 0.0136s/iter; left time: 245.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0587853 Vali Loss: 0.0687302 Test Loss: 0.0791306\n",
      "Validation loss decreased (0.068786 --> 0.068730).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0583889\n",
      "\tspeed: 0.0369s/iter; left time: 661.3062s\n",
      "\titers: 200, epoch: 21 | loss: 0.0628211\n",
      "\tspeed: 0.0122s/iter; left time: 217.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0586868 Vali Loss: 0.0687014 Test Loss: 0.0791981\n",
      "Validation loss decreased (0.068730 --> 0.068701).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0587090\n",
      "\tspeed: 0.0343s/iter; left time: 605.6964s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551478\n",
      "\tspeed: 0.0176s/iter; left time: 309.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0585566 Vali Loss: 0.0686361 Test Loss: 0.0792414\n",
      "Validation loss decreased (0.068701 --> 0.068636).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0580032\n",
      "\tspeed: 0.0365s/iter; left time: 636.1141s\n",
      "\titers: 200, epoch: 23 | loss: 0.0596124\n",
      "\tspeed: 0.0216s/iter; left time: 375.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0585786 Vali Loss: 0.0686573 Test Loss: 0.0791250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0593962\n",
      "\tspeed: 0.0341s/iter; left time: 586.5833s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610090\n",
      "\tspeed: 0.0186s/iter; left time: 317.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0584186 Vali Loss: 0.0686477 Test Loss: 0.0791397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0564482\n",
      "\tspeed: 0.0344s/iter; left time: 584.3063s\n",
      "\titers: 200, epoch: 25 | loss: 0.0560195\n",
      "\tspeed: 0.0201s/iter; left time: 339.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0583797 Vali Loss: 0.0685837 Test Loss: 0.0791009\n",
      "Validation loss decreased (0.068636 --> 0.068584).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0605035\n",
      "\tspeed: 0.0330s/iter; left time: 553.4683s\n",
      "\titers: 200, epoch: 26 | loss: 0.0577445\n",
      "\tspeed: 0.0185s/iter; left time: 308.7116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0583410 Vali Loss: 0.0685910 Test Loss: 0.0791649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584437\n",
      "\tspeed: 0.0342s/iter; left time: 565.2720s\n",
      "\titers: 200, epoch: 27 | loss: 0.0561151\n",
      "\tspeed: 0.0183s/iter; left time: 300.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0582971 Vali Loss: 0.0685541 Test Loss: 0.0791507\n",
      "Validation loss decreased (0.068584 --> 0.068554).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0558530\n",
      "\tspeed: 0.0352s/iter; left time: 573.8647s\n",
      "\titers: 200, epoch: 28 | loss: 0.0564394\n",
      "\tspeed: 0.0171s/iter; left time: 277.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0582924 Vali Loss: 0.0686031 Test Loss: 0.0790981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0609890\n",
      "\tspeed: 0.0321s/iter; left time: 516.7603s\n",
      "\titers: 200, epoch: 29 | loss: 0.0533565\n",
      "\tspeed: 0.0162s/iter; left time: 259.1166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0582134 Vali Loss: 0.0685947 Test Loss: 0.0790453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0584938\n",
      "\tspeed: 0.0349s/iter; left time: 553.8667s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573765\n",
      "\tspeed: 0.0175s/iter; left time: 276.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0582150 Vali Loss: 0.0685356 Test Loss: 0.0789865\n",
      "Validation loss decreased (0.068554 --> 0.068536).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0600751\n",
      "\tspeed: 0.0314s/iter; left time: 490.7125s\n",
      "\titers: 200, epoch: 31 | loss: 0.0535122\n",
      "\tspeed: 0.0156s/iter; left time: 242.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0581959 Vali Loss: 0.0685362 Test Loss: 0.0790093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585135\n",
      "\tspeed: 0.0328s/iter; left time: 506.1256s\n",
      "\titers: 200, epoch: 32 | loss: 0.0575287\n",
      "\tspeed: 0.0189s/iter; left time: 289.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0581202 Vali Loss: 0.0685129 Test Loss: 0.0790591\n",
      "Validation loss decreased (0.068536 --> 0.068513).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0580706\n",
      "\tspeed: 0.0356s/iter; left time: 541.7282s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604630\n",
      "\tspeed: 0.0184s/iter; left time: 278.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0581116 Vali Loss: 0.0685235 Test Loss: 0.0790510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0582404\n",
      "\tspeed: 0.0341s/iter; left time: 511.3092s\n",
      "\titers: 200, epoch: 34 | loss: 0.0577914\n",
      "\tspeed: 0.0210s/iter; left time: 312.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0580539 Vali Loss: 0.0685138 Test Loss: 0.0790187\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0584563\n",
      "\tspeed: 0.0364s/iter; left time: 536.4841s\n",
      "\titers: 200, epoch: 35 | loss: 0.0595547\n",
      "\tspeed: 0.0155s/iter; left time: 227.8006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0580781 Vali Loss: 0.0685244 Test Loss: 0.0790781\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0601649\n",
      "\tspeed: 0.0338s/iter; left time: 491.5926s\n",
      "\titers: 200, epoch: 36 | loss: 0.0602529\n",
      "\tspeed: 0.0210s/iter; left time: 303.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0580418 Vali Loss: 0.0685017 Test Loss: 0.0790352\n",
      "Validation loss decreased (0.068513 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0571623\n",
      "\tspeed: 0.0419s/iter; left time: 598.8166s\n",
      "\titers: 200, epoch: 37 | loss: 0.0578815\n",
      "\tspeed: 0.0212s/iter; left time: 300.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 225 | Train Loss: 0.0580344 Vali Loss: 0.0685067 Test Loss: 0.0790283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0573594\n",
      "\tspeed: 0.0360s/iter; left time: 507.2722s\n",
      "\titers: 200, epoch: 38 | loss: 0.0590343\n",
      "\tspeed: 0.0158s/iter; left time: 221.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0580271 Vali Loss: 0.0685113 Test Loss: 0.0789837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0553383\n",
      "\tspeed: 0.0376s/iter; left time: 520.1840s\n",
      "\titers: 200, epoch: 39 | loss: 0.0529877\n",
      "\tspeed: 0.0152s/iter; left time: 208.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0580175 Vali Loss: 0.0685062 Test Loss: 0.0790252\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0592485\n",
      "\tspeed: 0.0342s/iter; left time: 465.9658s\n",
      "\titers: 200, epoch: 40 | loss: 0.0586444\n",
      "\tspeed: 0.0172s/iter; left time: 232.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0579980 Vali Loss: 0.0684937 Test Loss: 0.0790323\n",
      "Validation loss decreased (0.068502 --> 0.068494).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0628458\n",
      "\tspeed: 0.0370s/iter; left time: 495.8552s\n",
      "\titers: 200, epoch: 41 | loss: 0.0581595\n",
      "\tspeed: 0.0167s/iter; left time: 222.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579853 Vali Loss: 0.0684993 Test Loss: 0.0790148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0597324\n",
      "\tspeed: 0.0307s/iter; left time: 404.9280s\n",
      "\titers: 200, epoch: 42 | loss: 0.0543683\n",
      "\tspeed: 0.0181s/iter; left time: 236.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0580027 Vali Loss: 0.0685095 Test Loss: 0.0790117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0602942\n",
      "\tspeed: 0.0344s/iter; left time: 445.4938s\n",
      "\titers: 200, epoch: 43 | loss: 0.0588281\n",
      "\tspeed: 0.0170s/iter; left time: 218.3892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0579897 Vali Loss: 0.0685076 Test Loss: 0.0789774\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0577775\n",
      "\tspeed: 0.0354s/iter; left time: 450.6939s\n",
      "\titers: 200, epoch: 44 | loss: 0.0578619\n",
      "\tspeed: 0.0146s/iter; left time: 184.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0579762 Vali Loss: 0.0685071 Test Loss: 0.0790132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0587692\n",
      "\tspeed: 0.0285s/iter; left time: 356.2176s\n",
      "\titers: 200, epoch: 45 | loss: 0.0575636\n",
      "\tspeed: 0.0171s/iter; left time: 211.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0579338 Vali Loss: 0.0685000 Test Loss: 0.0790003\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0571148\n",
      "\tspeed: 0.0347s/iter; left time: 426.0458s\n",
      "\titers: 200, epoch: 46 | loss: 0.0616274\n",
      "\tspeed: 0.0154s/iter; left time: 187.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0580003 Vali Loss: 0.0684827 Test Loss: 0.0790229\n",
      "Validation loss decreased (0.068494 --> 0.068483).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0560301\n",
      "\tspeed: 0.0333s/iter; left time: 401.3574s\n",
      "\titers: 200, epoch: 47 | loss: 0.0598776\n",
      "\tspeed: 0.0145s/iter; left time: 173.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0579353 Vali Loss: 0.0684818 Test Loss: 0.0790140\n",
      "Validation loss decreased (0.068483 --> 0.068482).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0621192\n",
      "\tspeed: 0.0364s/iter; left time: 431.0097s\n",
      "\titers: 200, epoch: 48 | loss: 0.0558696\n",
      "\tspeed: 0.0180s/iter; left time: 211.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579430 Vali Loss: 0.0684988 Test Loss: 0.0790144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549243\n",
      "\tspeed: 0.0354s/iter; left time: 411.1534s\n",
      "\titers: 200, epoch: 49 | loss: 0.0607253\n",
      "\tspeed: 0.0200s/iter; left time: 230.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0579465 Vali Loss: 0.0684958 Test Loss: 0.0789943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0580601\n",
      "\tspeed: 0.0360s/iter; left time: 409.2362s\n",
      "\titers: 200, epoch: 50 | loss: 0.0604288\n",
      "\tspeed: 0.0216s/iter; left time: 243.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.0578998 Vali Loss: 0.0684910 Test Loss: 0.0790050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0581676\n",
      "\tspeed: 0.0343s/iter; left time: 382.0332s\n",
      "\titers: 200, epoch: 51 | loss: 0.0585575\n",
      "\tspeed: 0.0185s/iter; left time: 204.3241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579432 Vali Loss: 0.0684809 Test Loss: 0.0790085\n",
      "Validation loss decreased (0.068482 --> 0.068481).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0603360\n",
      "\tspeed: 0.0393s/iter; left time: 429.5871s\n",
      "\titers: 200, epoch: 52 | loss: 0.0584841\n",
      "\tspeed: 0.0237s/iter; left time: 256.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0579319 Vali Loss: 0.0684904 Test Loss: 0.0789994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0585743\n",
      "\tspeed: 0.0372s/iter; left time: 397.6573s\n",
      "\titers: 200, epoch: 53 | loss: 0.0588034\n",
      "\tspeed: 0.0192s/iter; left time: 203.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0579132 Vali Loss: 0.0684941 Test Loss: 0.0790057\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0557282\n",
      "\tspeed: 0.0357s/iter; left time: 373.8456s\n",
      "\titers: 200, epoch: 54 | loss: 0.0613860\n",
      "\tspeed: 0.0172s/iter; left time: 178.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0579653 Vali Loss: 0.0685006 Test Loss: 0.0789996\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0585939\n",
      "\tspeed: 0.0368s/iter; left time: 376.8087s\n",
      "\titers: 200, epoch: 55 | loss: 0.0651440\n",
      "\tspeed: 0.0153s/iter; left time: 154.9025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0579389 Vali Loss: 0.0684873 Test Loss: 0.0790061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0619266\n",
      "\tspeed: 0.0351s/iter; left time: 351.5120s\n",
      "\titers: 200, epoch: 56 | loss: 0.0551651\n",
      "\tspeed: 0.0203s/iter; left time: 201.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0579282 Vali Loss: 0.0684934 Test Loss: 0.0789854\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0585389\n",
      "\tspeed: 0.0339s/iter; left time: 332.6475s\n",
      "\titers: 200, epoch: 57 | loss: 0.0609670\n",
      "\tspeed: 0.0187s/iter; left time: 181.5152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0579366 Vali Loss: 0.0684922 Test Loss: 0.0789980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598860\n",
      "\tspeed: 0.0352s/iter; left time: 337.3262s\n",
      "\titers: 200, epoch: 58 | loss: 0.0599037\n",
      "\tspeed: 0.0192s/iter; left time: 182.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0579010 Vali Loss: 0.0684900 Test Loss: 0.0789935\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599850\n",
      "\tspeed: 0.0360s/iter; left time: 336.9727s\n",
      "\titers: 200, epoch: 59 | loss: 0.0567161\n",
      "\tspeed: 0.0183s/iter; left time: 169.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0579170 Vali Loss: 0.0685022 Test Loss: 0.0789889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0599660\n",
      "\tspeed: 0.0346s/iter; left time: 316.1463s\n",
      "\titers: 200, epoch: 60 | loss: 0.0574773\n",
      "\tspeed: 0.0191s/iter; left time: 172.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0579000 Vali Loss: 0.0684907 Test Loss: 0.0789931\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0555947\n",
      "\tspeed: 0.0367s/iter; left time: 326.8183s\n",
      "\titers: 200, epoch: 61 | loss: 0.0567072\n",
      "\tspeed: 0.0197s/iter; left time: 173.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.0579001 Vali Loss: 0.0684961 Test Loss: 0.0790021\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019269950687885284, rmse:0.1388162523508072, mae:0.07900849729776382, rse:0.5369781255722046\n",
      "Intermediate time for FR and pred_len 96: 00h:07m:56.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1178433\n",
      "\tspeed: 0.0442s/iter; left time: 990.4424s\n",
      "\titers: 200, epoch: 1 | loss: 0.0979904\n",
      "\tspeed: 0.0151s/iter; left time: 335.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1161686 Vali Loss: 0.1026122 Test Loss: 0.1144287\n",
      "Validation loss decreased (inf --> 0.102612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0802685\n",
      "\tspeed: 0.0318s/iter; left time: 705.8233s\n",
      "\titers: 200, epoch: 2 | loss: 0.0758796\n",
      "\tspeed: 0.0206s/iter; left time: 453.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0786359 Vali Loss: 0.0817531 Test Loss: 0.0914209\n",
      "Validation loss decreased (0.102612 --> 0.081753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686616\n",
      "\tspeed: 0.0396s/iter; left time: 869.3379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0681255\n",
      "\tspeed: 0.0236s/iter; left time: 515.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 225 | Train Loss: 0.0712700 Vali Loss: 0.0772329 Test Loss: 0.0881135\n",
      "Validation loss decreased (0.081753 --> 0.077233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0735443\n",
      "\tspeed: 0.0391s/iter; left time: 848.8578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703870\n",
      "\tspeed: 0.0260s/iter; left time: 561.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0689783 Vali Loss: 0.0761214 Test Loss: 0.0871739\n",
      "Validation loss decreased (0.077233 --> 0.076121).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0685207\n",
      "\tspeed: 0.0397s/iter; left time: 854.0756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0634067\n",
      "\tspeed: 0.0196s/iter; left time: 418.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0678461 Vali Loss: 0.0758394 Test Loss: 0.0865922\n",
      "Validation loss decreased (0.076121 --> 0.075839).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0663654\n",
      "\tspeed: 0.0347s/iter; left time: 737.2492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0719434\n",
      "\tspeed: 0.0148s/iter; left time: 313.6845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0670404 Vali Loss: 0.0752677 Test Loss: 0.0862171\n",
      "Validation loss decreased (0.075839 --> 0.075268).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0663606\n",
      "\tspeed: 0.0406s/iter; left time: 854.5411s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665885\n",
      "\tspeed: 0.0240s/iter; left time: 503.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0664133 Vali Loss: 0.0750782 Test Loss: 0.0859377\n",
      "Validation loss decreased (0.075268 --> 0.075078).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0610192\n",
      "\tspeed: 0.0403s/iter; left time: 838.8842s\n",
      "\titers: 200, epoch: 8 | loss: 0.0643330\n",
      "\tspeed: 0.0140s/iter; left time: 291.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0659399 Vali Loss: 0.0749717 Test Loss: 0.0858859\n",
      "Validation loss decreased (0.075078 --> 0.074972).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0677186\n",
      "\tspeed: 0.0362s/iter; left time: 746.3905s\n",
      "\titers: 200, epoch: 9 | loss: 0.0667564\n",
      "\tspeed: 0.0157s/iter; left time: 321.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0655065 Vali Loss: 0.0745897 Test Loss: 0.0855368\n",
      "Validation loss decreased (0.074972 --> 0.074590).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658022\n",
      "\tspeed: 0.0340s/iter; left time: 693.1290s\n",
      "\titers: 200, epoch: 10 | loss: 0.0643987\n",
      "\tspeed: 0.0175s/iter; left time: 354.2846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0651897 Vali Loss: 0.0747029 Test Loss: 0.0855107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664462\n",
      "\tspeed: 0.0326s/iter; left time: 657.3021s\n",
      "\titers: 200, epoch: 11 | loss: 0.0612322\n",
      "\tspeed: 0.0131s/iter; left time: 261.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0649022 Vali Loss: 0.0745873 Test Loss: 0.0857235\n",
      "Validation loss decreased (0.074590 --> 0.074587).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0639878\n",
      "\tspeed: 0.0313s/iter; left time: 623.6526s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650366\n",
      "\tspeed: 0.0104s/iter; left time: 206.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0645888 Vali Loss: 0.0743928 Test Loss: 0.0858431\n",
      "Validation loss decreased (0.074587 --> 0.074393).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0629034\n",
      "\tspeed: 0.0336s/iter; left time: 662.0700s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618235\n",
      "\tspeed: 0.0180s/iter; left time: 352.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0643678 Vali Loss: 0.0744177 Test Loss: 0.0855179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0662641\n",
      "\tspeed: 0.0380s/iter; left time: 739.7201s\n",
      "\titers: 200, epoch: 14 | loss: 0.0653053\n",
      "\tspeed: 0.0193s/iter; left time: 374.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0641760 Vali Loss: 0.0742883 Test Loss: 0.0857224\n",
      "Validation loss decreased (0.074393 --> 0.074288).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0616458\n",
      "\tspeed: 0.0398s/iter; left time: 766.2188s\n",
      "\titers: 200, epoch: 15 | loss: 0.0615292\n",
      "\tspeed: 0.0170s/iter; left time: 325.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0639647 Vali Loss: 0.0742747 Test Loss: 0.0858672\n",
      "Validation loss decreased (0.074288 --> 0.074275).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0649231\n",
      "\tspeed: 0.0355s/iter; left time: 674.5108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0664912\n",
      "\tspeed: 0.0218s/iter; left time: 412.6628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0638754 Vali Loss: 0.0742751 Test Loss: 0.0856137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0634356\n",
      "\tspeed: 0.0361s/iter; left time: 678.0320s\n",
      "\titers: 200, epoch: 17 | loss: 0.0662411\n",
      "\tspeed: 0.0165s/iter; left time: 308.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0636968 Vali Loss: 0.0742034 Test Loss: 0.0857146\n",
      "Validation loss decreased (0.074275 --> 0.074203).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0625355\n",
      "\tspeed: 0.0384s/iter; left time: 714.0764s\n",
      "\titers: 200, epoch: 18 | loss: 0.0631167\n",
      "\tspeed: 0.0179s/iter; left time: 329.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0635564 Vali Loss: 0.0741951 Test Loss: 0.0855760\n",
      "Validation loss decreased (0.074203 --> 0.074195).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0636816\n",
      "\tspeed: 0.0388s/iter; left time: 711.9540s\n",
      "\titers: 200, epoch: 19 | loss: 0.0653322\n",
      "\tspeed: 0.0224s/iter; left time: 408.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0634603 Vali Loss: 0.0741919 Test Loss: 0.0857492\n",
      "Validation loss decreased (0.074195 --> 0.074192).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0619669\n",
      "\tspeed: 0.0425s/iter; left time: 770.9257s\n",
      "\titers: 200, epoch: 20 | loss: 0.0645041\n",
      "\tspeed: 0.0190s/iter; left time: 342.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0633220 Vali Loss: 0.0740985 Test Loss: 0.0858055\n",
      "Validation loss decreased (0.074192 --> 0.074098).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0634483\n",
      "\tspeed: 0.0358s/iter; left time: 640.4021s\n",
      "\titers: 200, epoch: 21 | loss: 0.0661550\n",
      "\tspeed: 0.0158s/iter; left time: 280.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0632298 Vali Loss: 0.0740741 Test Loss: 0.0856835\n",
      "Validation loss decreased (0.074098 --> 0.074074).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0665884\n",
      "\tspeed: 0.0412s/iter; left time: 727.7174s\n",
      "\titers: 200, epoch: 22 | loss: 0.0624136\n",
      "\tspeed: 0.0192s/iter; left time: 337.2748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0631625 Vali Loss: 0.0741992 Test Loss: 0.0855839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592897\n",
      "\tspeed: 0.0360s/iter; left time: 628.8964s\n",
      "\titers: 200, epoch: 23 | loss: 0.0609877\n",
      "\tspeed: 0.0190s/iter; left time: 329.3686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 225 | Train Loss: 0.0630976 Vali Loss: 0.0740889 Test Loss: 0.0858281\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0619836\n",
      "\tspeed: 0.0388s/iter; left time: 667.9136s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606376\n",
      "\tspeed: 0.0196s/iter; left time: 334.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0630359 Vali Loss: 0.0742436 Test Loss: 0.0856210\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0620375\n",
      "\tspeed: 0.0345s/iter; left time: 587.0172s\n",
      "\titers: 200, epoch: 25 | loss: 0.0610093\n",
      "\tspeed: 0.0175s/iter; left time: 295.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0629425 Vali Loss: 0.0740689 Test Loss: 0.0856918\n",
      "Validation loss decreased (0.074074 --> 0.074069).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0623213\n",
      "\tspeed: 0.0420s/iter; left time: 704.5601s\n",
      "\titers: 200, epoch: 26 | loss: 0.0607373\n",
      "\tspeed: 0.0224s/iter; left time: 373.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 225 | Train Loss: 0.0629212 Vali Loss: 0.0741398 Test Loss: 0.0855965\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0599672\n",
      "\tspeed: 0.0363s/iter; left time: 600.5544s\n",
      "\titers: 200, epoch: 27 | loss: 0.0638771\n",
      "\tspeed: 0.0233s/iter; left time: 382.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0628768 Vali Loss: 0.0741251 Test Loss: 0.0856418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0645678\n",
      "\tspeed: 0.0372s/iter; left time: 607.0370s\n",
      "\titers: 200, epoch: 28 | loss: 0.0622639\n",
      "\tspeed: 0.0179s/iter; left time: 290.0750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0628522 Vali Loss: 0.0740774 Test Loss: 0.0857350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0643791\n",
      "\tspeed: 0.0335s/iter; left time: 539.3548s\n",
      "\titers: 200, epoch: 29 | loss: 0.0624117\n",
      "\tspeed: 0.0174s/iter; left time: 278.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0628074 Vali Loss: 0.0740491 Test Loss: 0.0857703\n",
      "Validation loss decreased (0.074069 --> 0.074049).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0639029\n",
      "\tspeed: 0.0334s/iter; left time: 530.8416s\n",
      "\titers: 200, epoch: 30 | loss: 0.0644022\n",
      "\tspeed: 0.0198s/iter; left time: 312.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0627769 Vali Loss: 0.0741052 Test Loss: 0.0856595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0654455\n",
      "\tspeed: 0.0327s/iter; left time: 511.9813s\n",
      "\titers: 200, epoch: 31 | loss: 0.0616240\n",
      "\tspeed: 0.0176s/iter; left time: 273.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0627635 Vali Loss: 0.0741205 Test Loss: 0.0856111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611650\n",
      "\tspeed: 0.0301s/iter; left time: 465.0414s\n",
      "\titers: 200, epoch: 32 | loss: 0.0649987\n",
      "\tspeed: 0.0101s/iter; left time: 154.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 225 | Train Loss: 0.0627000 Vali Loss: 0.0740636 Test Loss: 0.0857006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0597707\n",
      "\tspeed: 0.0298s/iter; left time: 453.2348s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641938\n",
      "\tspeed: 0.0153s/iter; left time: 231.4744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0627276 Vali Loss: 0.0741174 Test Loss: 0.0856934\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0659970\n",
      "\tspeed: 0.0363s/iter; left time: 542.8981s\n",
      "\titers: 200, epoch: 34 | loss: 0.0607483\n",
      "\tspeed: 0.0221s/iter; left time: 329.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0626968 Vali Loss: 0.0741465 Test Loss: 0.0856483\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0599526\n",
      "\tspeed: 0.0340s/iter; left time: 501.6005s\n",
      "\titers: 200, epoch: 35 | loss: 0.0630129\n",
      "\tspeed: 0.0152s/iter; left time: 222.7658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0626719 Vali Loss: 0.0740543 Test Loss: 0.0856168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0640251\n",
      "\tspeed: 0.0362s/iter; left time: 525.7571s\n",
      "\titers: 200, epoch: 36 | loss: 0.0665271\n",
      "\tspeed: 0.0182s/iter; left time: 262.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0626520 Vali Loss: 0.0740346 Test Loss: 0.0856374\n",
      "Validation loss decreased (0.074049 --> 0.074035).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0650771\n",
      "\tspeed: 0.0383s/iter; left time: 547.4149s\n",
      "\titers: 200, epoch: 37 | loss: 0.0620096\n",
      "\tspeed: 0.0125s/iter; left time: 176.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0626566 Vali Loss: 0.0740899 Test Loss: 0.0856191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0620774\n",
      "\tspeed: 0.0358s/iter; left time: 503.2467s\n",
      "\titers: 200, epoch: 38 | loss: 0.0605291\n",
      "\tspeed: 0.0227s/iter; left time: 317.3686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0626232 Vali Loss: 0.0740508 Test Loss: 0.0856860\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0638552\n",
      "\tspeed: 0.0358s/iter; left time: 496.2853s\n",
      "\titers: 200, epoch: 39 | loss: 0.0609560\n",
      "\tspeed: 0.0127s/iter; left time: 174.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0626238 Vali Loss: 0.0741312 Test Loss: 0.0856796\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0629077\n",
      "\tspeed: 0.0332s/iter; left time: 452.9871s\n",
      "\titers: 200, epoch: 40 | loss: 0.0619635\n",
      "\tspeed: 0.0172s/iter; left time: 232.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0625679 Vali Loss: 0.0740890 Test Loss: 0.0856143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0585513\n",
      "\tspeed: 0.0334s/iter; left time: 447.2526s\n",
      "\titers: 200, epoch: 41 | loss: 0.0619032\n",
      "\tspeed: 0.0175s/iter; left time: 232.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0625734 Vali Loss: 0.0740964 Test Loss: 0.0856672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0622944\n",
      "\tspeed: 0.0330s/iter; left time: 434.3602s\n",
      "\titers: 200, epoch: 42 | loss: 0.0620603\n",
      "\tspeed: 0.0116s/iter; left time: 152.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0625519 Vali Loss: 0.0740899 Test Loss: 0.0856896\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0636618\n",
      "\tspeed: 0.0339s/iter; left time: 439.3911s\n",
      "\titers: 200, epoch: 43 | loss: 0.0662818\n",
      "\tspeed: 0.0193s/iter; left time: 247.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0625558 Vali Loss: 0.0740881 Test Loss: 0.0856588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0609411\n",
      "\tspeed: 0.0347s/iter; left time: 442.1387s\n",
      "\titers: 200, epoch: 44 | loss: 0.0611548\n",
      "\tspeed: 0.0181s/iter; left time: 228.6233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0625591 Vali Loss: 0.0740926 Test Loss: 0.0856833\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0599050\n",
      "\tspeed: 0.0359s/iter; left time: 448.8544s\n",
      "\titers: 200, epoch: 45 | loss: 0.0615746\n",
      "\tspeed: 0.0186s/iter; left time: 230.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0625465 Vali Loss: 0.0740532 Test Loss: 0.0857476\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0656682\n",
      "\tspeed: 0.0346s/iter; left time: 425.1519s\n",
      "\titers: 200, epoch: 46 | loss: 0.0665195\n",
      "\tspeed: 0.0171s/iter; left time: 208.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0625344 Vali Loss: 0.0740709 Test Loss: 0.0856607\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021044865250587463, rmse:0.1450684815645218, mae:0.08563748002052307, rse:0.5618639588356018\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1210394\n",
      "\tspeed: 0.0218s/iter; left time: 489.1919s\n",
      "\titers: 200, epoch: 1 | loss: 0.1047875\n",
      "\tspeed: 0.0180s/iter; left time: 401.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1171486 Vali Loss: 0.1032319 Test Loss: 0.1152084\n",
      "Validation loss decreased (inf --> 0.103232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0764794\n",
      "\tspeed: 0.0339s/iter; left time: 751.2943s\n",
      "\titers: 200, epoch: 2 | loss: 0.0732857\n",
      "\tspeed: 0.0101s/iter; left time: 224.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0785486 Vali Loss: 0.0815163 Test Loss: 0.0911878\n",
      "Validation loss decreased (0.103232 --> 0.081516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0692481\n",
      "\tspeed: 0.0352s/iter; left time: 773.6957s\n",
      "\titers: 200, epoch: 3 | loss: 0.0701355\n",
      "\tspeed: 0.0158s/iter; left time: 344.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0712442 Vali Loss: 0.0773953 Test Loss: 0.0882910\n",
      "Validation loss decreased (0.081516 --> 0.077395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0653713\n",
      "\tspeed: 0.0373s/iter; left time: 809.7535s\n",
      "\titers: 200, epoch: 4 | loss: 0.0740804\n",
      "\tspeed: 0.0200s/iter; left time: 432.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0692651 Vali Loss: 0.0763515 Test Loss: 0.0871971\n",
      "Validation loss decreased (0.077395 --> 0.076352).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0681931\n",
      "\tspeed: 0.0284s/iter; left time: 609.5723s\n",
      "\titers: 200, epoch: 5 | loss: 0.0681475\n",
      "\tspeed: 0.0171s/iter; left time: 365.1300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0681561 Vali Loss: 0.0757714 Test Loss: 0.0865808\n",
      "Validation loss decreased (0.076352 --> 0.075771).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646403\n",
      "\tspeed: 0.0391s/iter; left time: 831.2309s\n",
      "\titers: 200, epoch: 6 | loss: 0.0670295\n",
      "\tspeed: 0.0180s/iter; left time: 381.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0673313 Vali Loss: 0.0754521 Test Loss: 0.0862572\n",
      "Validation loss decreased (0.075771 --> 0.075452).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0610189\n",
      "\tspeed: 0.0350s/iter; left time: 737.7563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0690645\n",
      "\tspeed: 0.0175s/iter; left time: 366.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0667259 Vali Loss: 0.0749807 Test Loss: 0.0862407\n",
      "Validation loss decreased (0.075452 --> 0.074981).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0644768\n",
      "\tspeed: 0.0379s/iter; left time: 788.9388s\n",
      "\titers: 200, epoch: 8 | loss: 0.0653624\n",
      "\tspeed: 0.0185s/iter; left time: 382.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0662581 Vali Loss: 0.0748040 Test Loss: 0.0859648\n",
      "Validation loss decreased (0.074981 --> 0.074804).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657071\n",
      "\tspeed: 0.0377s/iter; left time: 777.6188s\n",
      "\titers: 200, epoch: 9 | loss: 0.0655997\n",
      "\tspeed: 0.0181s/iter; left time: 370.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0658779 Vali Loss: 0.0746631 Test Loss: 0.0856976\n",
      "Validation loss decreased (0.074804 --> 0.074663).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684024\n",
      "\tspeed: 0.0375s/iter; left time: 764.8521s\n",
      "\titers: 200, epoch: 10 | loss: 0.0660051\n",
      "\tspeed: 0.0208s/iter; left time: 422.6620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0655724 Vali Loss: 0.0745846 Test Loss: 0.0858406\n",
      "Validation loss decreased (0.074663 --> 0.074585).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0623031\n",
      "\tspeed: 0.0423s/iter; left time: 851.5952s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676518\n",
      "\tspeed: 0.0215s/iter; left time: 431.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0652500 Vali Loss: 0.0747508 Test Loss: 0.0857698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0664428\n",
      "\tspeed: 0.0370s/iter; left time: 737.4653s\n",
      "\titers: 200, epoch: 12 | loss: 0.0653762\n",
      "\tspeed: 0.0151s/iter; left time: 299.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0650192 Vali Loss: 0.0744734 Test Loss: 0.0855734\n",
      "Validation loss decreased (0.074585 --> 0.074473).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646388\n",
      "\tspeed: 0.0372s/iter; left time: 732.2521s\n",
      "\titers: 200, epoch: 13 | loss: 0.0651568\n",
      "\tspeed: 0.0187s/iter; left time: 365.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0647588 Vali Loss: 0.0744340 Test Loss: 0.0853351\n",
      "Validation loss decreased (0.074473 --> 0.074434).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0667653\n",
      "\tspeed: 0.0349s/iter; left time: 679.3370s\n",
      "\titers: 200, epoch: 14 | loss: 0.0626236\n",
      "\tspeed: 0.0170s/iter; left time: 328.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0645367 Vali Loss: 0.0741993 Test Loss: 0.0855686\n",
      "Validation loss decreased (0.074434 --> 0.074199).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0680252\n",
      "\tspeed: 0.0361s/iter; left time: 695.7682s\n",
      "\titers: 200, epoch: 15 | loss: 0.0593005\n",
      "\tspeed: 0.0169s/iter; left time: 323.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0643566 Vali Loss: 0.0741186 Test Loss: 0.0857946\n",
      "Validation loss decreased (0.074199 --> 0.074119).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0614194\n",
      "\tspeed: 0.0366s/iter; left time: 697.0894s\n",
      "\titers: 200, epoch: 16 | loss: 0.0623373\n",
      "\tspeed: 0.0210s/iter; left time: 397.6584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0642088 Vali Loss: 0.0741625 Test Loss: 0.0854788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665994\n",
      "\tspeed: 0.0375s/iter; left time: 705.5601s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648475\n",
      "\tspeed: 0.0137s/iter; left time: 256.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0640424 Vali Loss: 0.0741478 Test Loss: 0.0855078\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0663047\n",
      "\tspeed: 0.0415s/iter; left time: 770.2559s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661211\n",
      "\tspeed: 0.0182s/iter; left time: 335.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 225 | Train Loss: 0.0639167 Vali Loss: 0.0740825 Test Loss: 0.0855979\n",
      "Validation loss decreased (0.074119 --> 0.074082).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0629823\n",
      "\tspeed: 0.0371s/iter; left time: 680.3404s\n",
      "\titers: 200, epoch: 19 | loss: 0.0630848\n",
      "\tspeed: 0.0190s/iter; left time: 346.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0637715 Vali Loss: 0.0740956 Test Loss: 0.0853726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0632227\n",
      "\tspeed: 0.0390s/iter; left time: 707.3950s\n",
      "\titers: 200, epoch: 20 | loss: 0.0624366\n",
      "\tspeed: 0.0219s/iter; left time: 394.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0637345 Vali Loss: 0.0740992 Test Loss: 0.0856143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0620175\n",
      "\tspeed: 0.0429s/iter; left time: 768.7946s\n",
      "\titers: 200, epoch: 21 | loss: 0.0622662\n",
      "\tspeed: 0.0251s/iter; left time: 446.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0636170 Vali Loss: 0.0739984 Test Loss: 0.0854581\n",
      "Validation loss decreased (0.074082 --> 0.073998).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0642883\n",
      "\tspeed: 0.0401s/iter; left time: 709.4577s\n",
      "\titers: 200, epoch: 22 | loss: 0.0624295\n",
      "\tspeed: 0.0192s/iter; left time: 338.0463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0635554 Vali Loss: 0.0738083 Test Loss: 0.0854759\n",
      "Validation loss decreased (0.073998 --> 0.073808).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619837\n",
      "\tspeed: 0.0440s/iter; left time: 767.9425s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606846\n",
      "\tspeed: 0.0231s/iter; left time: 401.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0634304 Vali Loss: 0.0739375 Test Loss: 0.0856123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621821\n",
      "\tspeed: 0.0305s/iter; left time: 525.0064s\n",
      "\titers: 200, epoch: 24 | loss: 0.0660644\n",
      "\tspeed: 0.0144s/iter; left time: 246.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0633682 Vali Loss: 0.0739710 Test Loss: 0.0856309\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0619161\n",
      "\tspeed: 0.0325s/iter; left time: 552.7801s\n",
      "\titers: 200, epoch: 25 | loss: 0.0685211\n",
      "\tspeed: 0.0234s/iter; left time: 395.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 225 | Train Loss: 0.0633131 Vali Loss: 0.0738985 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625157\n",
      "\tspeed: 0.0427s/iter; left time: 716.5477s\n",
      "\titers: 200, epoch: 26 | loss: 0.0681692\n",
      "\tspeed: 0.0162s/iter; left time: 270.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0632651 Vali Loss: 0.0739015 Test Loss: 0.0856150\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0608956\n",
      "\tspeed: 0.0388s/iter; left time: 642.5381s\n",
      "\titers: 200, epoch: 27 | loss: 0.0656074\n",
      "\tspeed: 0.0127s/iter; left time: 208.9528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0632046 Vali Loss: 0.0739431 Test Loss: 0.0855818\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0641362\n",
      "\tspeed: 0.0339s/iter; left time: 554.2001s\n",
      "\titers: 200, epoch: 28 | loss: 0.0657411\n",
      "\tspeed: 0.0199s/iter; left time: 322.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0631599 Vali Loss: 0.0738821 Test Loss: 0.0856754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0651714\n",
      "\tspeed: 0.0356s/iter; left time: 573.7399s\n",
      "\titers: 200, epoch: 29 | loss: 0.0617112\n",
      "\tspeed: 0.0231s/iter; left time: 368.9746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0631507 Vali Loss: 0.0738765 Test Loss: 0.0856216\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0614604\n",
      "\tspeed: 0.0370s/iter; left time: 587.6082s\n",
      "\titers: 200, epoch: 30 | loss: 0.0620838\n",
      "\tspeed: 0.0102s/iter; left time: 161.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0630906 Vali Loss: 0.0737731 Test Loss: 0.0855447\n",
      "Validation loss decreased (0.073808 --> 0.073773).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0615081\n",
      "\tspeed: 0.0341s/iter; left time: 534.3254s\n",
      "\titers: 200, epoch: 31 | loss: 0.0636241\n",
      "\tspeed: 0.0191s/iter; left time: 297.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0630592 Vali Loss: 0.0738371 Test Loss: 0.0856570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0609704\n",
      "\tspeed: 0.0391s/iter; left time: 603.8718s\n",
      "\titers: 200, epoch: 32 | loss: 0.0635759\n",
      "\tspeed: 0.0171s/iter; left time: 261.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0630527 Vali Loss: 0.0738693 Test Loss: 0.0855334\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0646972\n",
      "\tspeed: 0.0420s/iter; left time: 637.8868s\n",
      "\titers: 200, epoch: 33 | loss: 0.0630995\n",
      "\tspeed: 0.0148s/iter; left time: 222.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0630115 Vali Loss: 0.0738945 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0654340\n",
      "\tspeed: 0.0340s/iter; left time: 509.1516s\n",
      "\titers: 200, epoch: 34 | loss: 0.0624656\n",
      "\tspeed: 0.0128s/iter; left time: 191.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0630298 Vali Loss: 0.0738741 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0638330\n",
      "\tspeed: 0.0341s/iter; left time: 502.8451s\n",
      "\titers: 200, epoch: 35 | loss: 0.0668810\n",
      "\tspeed: 0.0212s/iter; left time: 311.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0629951 Vali Loss: 0.0739457 Test Loss: 0.0855343\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0623147\n",
      "\tspeed: 0.0343s/iter; left time: 498.7837s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608723\n",
      "\tspeed: 0.0205s/iter; left time: 296.2423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0629881 Vali Loss: 0.0737848 Test Loss: 0.0855618\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0630879\n",
      "\tspeed: 0.0392s/iter; left time: 559.9751s\n",
      "\titers: 200, epoch: 37 | loss: 0.0650850\n",
      "\tspeed: 0.0183s/iter; left time: 260.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0629607 Vali Loss: 0.0738439 Test Loss: 0.0855667\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0633509\n",
      "\tspeed: 0.0409s/iter; left time: 575.3754s\n",
      "\titers: 200, epoch: 38 | loss: 0.0605446\n",
      "\tspeed: 0.0228s/iter; left time: 319.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0629436 Vali Loss: 0.0738411 Test Loss: 0.0855348\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0598986\n",
      "\tspeed: 0.0325s/iter; left time: 450.1978s\n",
      "\titers: 200, epoch: 39 | loss: 0.0613178\n",
      "\tspeed: 0.0182s/iter; left time: 250.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0628666 Vali Loss: 0.0738966 Test Loss: 0.0854778\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0665396\n",
      "\tspeed: 0.0381s/iter; left time: 518.5626s\n",
      "\titers: 200, epoch: 40 | loss: 0.0625084\n",
      "\tspeed: 0.0184s/iter; left time: 248.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0628995 Vali Loss: 0.0738050 Test Loss: 0.0855525\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021028192713856697, rmse:0.14501100778579712, mae:0.08554467558860779, rse:0.5616413950920105\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:01.02s\n",
      "Intermediate time for FR: 00h:23m:05.21s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1593821\n",
      "\tspeed: 0.0385s/iter; left time: 866.1848s\n",
      "\titers: 200, epoch: 1 | loss: 0.1234813\n",
      "\tspeed: 0.0164s/iter; left time: 367.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.1570896 Vali Loss: 0.1092966 Test Loss: 0.1122958\n",
      "Validation loss decreased (inf --> 0.109297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0768305\n",
      "\tspeed: 0.0344s/iter; left time: 767.1176s\n",
      "\titers: 200, epoch: 2 | loss: 0.0711576\n",
      "\tspeed: 0.0164s/iter; left time: 364.3583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0823309 Vali Loss: 0.0656439 Test Loss: 0.0675110\n",
      "Validation loss decreased (0.109297 --> 0.065644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0701625\n",
      "\tspeed: 0.0344s/iter; left time: 758.6147s\n",
      "\titers: 200, epoch: 3 | loss: 0.0677254\n",
      "\tspeed: 0.0169s/iter; left time: 371.2511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0685028 Vali Loss: 0.0616079 Test Loss: 0.0640182\n",
      "Validation loss decreased (0.065644 --> 0.061608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659868\n",
      "\tspeed: 0.0351s/iter; left time: 766.3866s\n",
      "\titers: 200, epoch: 4 | loss: 0.0607433\n",
      "\tspeed: 0.0153s/iter; left time: 332.6987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0651398 Vali Loss: 0.0595158 Test Loss: 0.0618037\n",
      "Validation loss decreased (0.061608 --> 0.059516).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0652476\n",
      "\tspeed: 0.0306s/iter; left time: 659.8101s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612183\n",
      "\tspeed: 0.0190s/iter; left time: 408.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0629467 Vali Loss: 0.0581176 Test Loss: 0.0603192\n",
      "Validation loss decreased (0.059516 --> 0.058118).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0603484\n",
      "\tspeed: 0.0346s/iter; left time: 738.6505s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601482\n",
      "\tspeed: 0.0182s/iter; left time: 386.2320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0615746 Vali Loss: 0.0571964 Test Loss: 0.0595768\n",
      "Validation loss decreased (0.058118 --> 0.057196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648735\n",
      "\tspeed: 0.0350s/iter; left time: 740.6096s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578561\n",
      "\tspeed: 0.0161s/iter; left time: 339.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0606378 Vali Loss: 0.0574239 Test Loss: 0.0596774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0606239\n",
      "\tspeed: 0.0338s/iter; left time: 706.0522s\n",
      "\titers: 200, epoch: 8 | loss: 0.0619788\n",
      "\tspeed: 0.0189s/iter; left time: 393.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0599561 Vali Loss: 0.0565249 Test Loss: 0.0588886\n",
      "Validation loss decreased (0.057196 --> 0.056525).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0612155\n",
      "\tspeed: 0.0348s/iter; left time: 719.4713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0603437\n",
      "\tspeed: 0.0223s/iter; left time: 458.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0592684 Vali Loss: 0.0561483 Test Loss: 0.0586221\n",
      "Validation loss decreased (0.056525 --> 0.056148).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0569037\n",
      "\tspeed: 0.0322s/iter; left time: 658.4225s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605587\n",
      "\tspeed: 0.0154s/iter; left time: 313.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0588348 Vali Loss: 0.0559605 Test Loss: 0.0583189\n",
      "Validation loss decreased (0.056148 --> 0.055961).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0575559\n",
      "\tspeed: 0.0350s/iter; left time: 709.0042s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598319\n",
      "\tspeed: 0.0183s/iter; left time: 368.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0583838 Vali Loss: 0.0558892 Test Loss: 0.0580843\n",
      "Validation loss decreased (0.055961 --> 0.055889).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0626877\n",
      "\tspeed: 0.0348s/iter; left time: 697.1967s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601823\n",
      "\tspeed: 0.0203s/iter; left time: 403.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0580430 Vali Loss: 0.0554932 Test Loss: 0.0579933\n",
      "Validation loss decreased (0.055889 --> 0.055493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0553428\n",
      "\tspeed: 0.0341s/iter; left time: 674.9824s\n",
      "\titers: 200, epoch: 13 | loss: 0.0518866\n",
      "\tspeed: 0.0216s/iter; left time: 425.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0577669 Vali Loss: 0.0554023 Test Loss: 0.0577424\n",
      "Validation loss decreased (0.055493 --> 0.055402).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0606736\n",
      "\tspeed: 0.0393s/iter; left time: 768.9665s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573600\n",
      "\tspeed: 0.0219s/iter; left time: 426.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 226 | Train Loss: 0.0575232 Vali Loss: 0.0553580 Test Loss: 0.0577659\n",
      "Validation loss decreased (0.055402 --> 0.055358).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0550222\n",
      "\tspeed: 0.0346s/iter; left time: 668.2236s\n",
      "\titers: 200, epoch: 15 | loss: 0.0600982\n",
      "\tspeed: 0.0158s/iter; left time: 304.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0572379 Vali Loss: 0.0551939 Test Loss: 0.0576582\n",
      "Validation loss decreased (0.055358 --> 0.055194).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0585859\n",
      "\tspeed: 0.0326s/iter; left time: 623.2261s\n",
      "\titers: 200, epoch: 16 | loss: 0.0548897\n",
      "\tspeed: 0.0212s/iter; left time: 403.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 226 | Train Loss: 0.0570594 Vali Loss: 0.0551680 Test Loss: 0.0576045\n",
      "Validation loss decreased (0.055194 --> 0.055168).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570717\n",
      "\tspeed: 0.0328s/iter; left time: 619.0840s\n",
      "\titers: 200, epoch: 17 | loss: 0.0575829\n",
      "\tspeed: 0.0171s/iter; left time: 321.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0569856 Vali Loss: 0.0549979 Test Loss: 0.0573956\n",
      "Validation loss decreased (0.055168 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0575156\n",
      "\tspeed: 0.0299s/iter; left time: 556.9840s\n",
      "\titers: 200, epoch: 18 | loss: 0.0545770\n",
      "\tspeed: 0.0154s/iter; left time: 285.1953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0567499 Vali Loss: 0.0549638 Test Loss: 0.0573878\n",
      "Validation loss decreased (0.054998 --> 0.054964).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0576251\n",
      "\tspeed: 0.0311s/iter; left time: 573.1316s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538437\n",
      "\tspeed: 0.0170s/iter; left time: 311.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0566140 Vali Loss: 0.0548153 Test Loss: 0.0572582\n",
      "Validation loss decreased (0.054964 --> 0.054815).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549435\n",
      "\tspeed: 0.0370s/iter; left time: 674.0809s\n",
      "\titers: 200, epoch: 20 | loss: 0.0604172\n",
      "\tspeed: 0.0197s/iter; left time: 357.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0564828 Vali Loss: 0.0547100 Test Loss: 0.0570773\n",
      "Validation loss decreased (0.054815 --> 0.054710).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0577941\n",
      "\tspeed: 0.0342s/iter; left time: 614.9415s\n",
      "\titers: 200, epoch: 21 | loss: 0.0589544\n",
      "\tspeed: 0.0195s/iter; left time: 347.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 226 | Train Loss: 0.0563989 Vali Loss: 0.0548747 Test Loss: 0.0571588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0532447\n",
      "\tspeed: 0.0364s/iter; left time: 646.6842s\n",
      "\titers: 200, epoch: 22 | loss: 0.0579227\n",
      "\tspeed: 0.0174s/iter; left time: 307.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0563174 Vali Loss: 0.0547841 Test Loss: 0.0570779\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529711\n",
      "\tspeed: 0.0317s/iter; left time: 556.5155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0534307\n",
      "\tspeed: 0.0172s/iter; left time: 299.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0561656 Vali Loss: 0.0546956 Test Loss: 0.0570976\n",
      "Validation loss decreased (0.054710 --> 0.054696).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0533154\n",
      "\tspeed: 0.0320s/iter; left time: 553.2430s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565265\n",
      "\tspeed: 0.0173s/iter; left time: 297.2476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0560654 Vali Loss: 0.0544975 Test Loss: 0.0569965\n",
      "Validation loss decreased (0.054696 --> 0.054497).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0553172\n",
      "\tspeed: 0.0346s/iter; left time: 590.9189s\n",
      "\titers: 200, epoch: 25 | loss: 0.0583547\n",
      "\tspeed: 0.0168s/iter; left time: 284.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0560763 Vali Loss: 0.0545897 Test Loss: 0.0569591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0532063\n",
      "\tspeed: 0.0335s/iter; left time: 564.5653s\n",
      "\titers: 200, epoch: 26 | loss: 0.0599777\n",
      "\tspeed: 0.0202s/iter; left time: 338.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0559622 Vali Loss: 0.0546010 Test Loss: 0.0569279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0548969\n",
      "\tspeed: 0.0322s/iter; left time: 535.6900s\n",
      "\titers: 200, epoch: 27 | loss: 0.0585928\n",
      "\tspeed: 0.0160s/iter; left time: 264.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0559206 Vali Loss: 0.0545490 Test Loss: 0.0569308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0570990\n",
      "\tspeed: 0.0350s/iter; left time: 573.2734s\n",
      "\titers: 200, epoch: 28 | loss: 0.0536195\n",
      "\tspeed: 0.0202s/iter; left time: 328.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0558758 Vali Loss: 0.0544448 Test Loss: 0.0568816\n",
      "Validation loss decreased (0.054497 --> 0.054445).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0576614\n",
      "\tspeed: 0.0360s/iter; left time: 582.2564s\n",
      "\titers: 200, epoch: 29 | loss: 0.0557368\n",
      "\tspeed: 0.0193s/iter; left time: 310.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0558452 Vali Loss: 0.0543916 Test Loss: 0.0567876\n",
      "Validation loss decreased (0.054445 --> 0.054392).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537613\n",
      "\tspeed: 0.0356s/iter; left time: 568.2374s\n",
      "\titers: 200, epoch: 30 | loss: 0.0583726\n",
      "\tspeed: 0.0197s/iter; left time: 312.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 226 | Train Loss: 0.0557715 Vali Loss: 0.0544268 Test Loss: 0.0568058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0558028\n",
      "\tspeed: 0.0337s/iter; left time: 529.2667s\n",
      "\titers: 200, epoch: 31 | loss: 0.0578166\n",
      "\tspeed: 0.0179s/iter; left time: 278.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0557194 Vali Loss: 0.0544070 Test Loss: 0.0568181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0546350\n",
      "\tspeed: 0.0384s/iter; left time: 595.2493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0560995\n",
      "\tspeed: 0.0170s/iter; left time: 261.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 226 | Train Loss: 0.0556565 Vali Loss: 0.0543337 Test Loss: 0.0567663\n",
      "Validation loss decreased (0.054392 --> 0.054334).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553093\n",
      "\tspeed: 0.0340s/iter; left time: 518.8935s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544334\n",
      "\tspeed: 0.0158s/iter; left time: 239.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0557085 Vali Loss: 0.0544495 Test Loss: 0.0567643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0517952\n",
      "\tspeed: 0.0335s/iter; left time: 503.3773s\n",
      "\titers: 200, epoch: 34 | loss: 0.0577175\n",
      "\tspeed: 0.0186s/iter; left time: 277.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0556033 Vali Loss: 0.0542944 Test Loss: 0.0567092\n",
      "Validation loss decreased (0.054334 --> 0.054294).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0554626\n",
      "\tspeed: 0.0333s/iter; left time: 493.7844s\n",
      "\titers: 200, epoch: 35 | loss: 0.0574955\n",
      "\tspeed: 0.0172s/iter; left time: 252.4543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0556600 Vali Loss: 0.0544349 Test Loss: 0.0567912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0561451\n",
      "\tspeed: 0.0317s/iter; left time: 462.0321s\n",
      "\titers: 200, epoch: 36 | loss: 0.0557724\n",
      "\tspeed: 0.0182s/iter; left time: 263.9853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0555661 Vali Loss: 0.0543601 Test Loss: 0.0567166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0554360\n",
      "\tspeed: 0.0333s/iter; left time: 478.6523s\n",
      "\titers: 200, epoch: 37 | loss: 0.0573009\n",
      "\tspeed: 0.0201s/iter; left time: 286.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0556243 Vali Loss: 0.0543863 Test Loss: 0.0567281\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0536021\n",
      "\tspeed: 0.0335s/iter; left time: 474.1719s\n",
      "\titers: 200, epoch: 38 | loss: 0.0571662\n",
      "\tspeed: 0.0178s/iter; left time: 250.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0555641 Vali Loss: 0.0543375 Test Loss: 0.0567224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0549302\n",
      "\tspeed: 0.0352s/iter; left time: 489.1106s\n",
      "\titers: 200, epoch: 39 | loss: 0.0537636\n",
      "\tspeed: 0.0171s/iter; left time: 236.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0555776 Vali Loss: 0.0542915 Test Loss: 0.0567141\n",
      "Validation loss decreased (0.054294 --> 0.054291).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0591478\n",
      "\tspeed: 0.0335s/iter; left time: 458.8138s\n",
      "\titers: 200, epoch: 40 | loss: 0.0551421\n",
      "\tspeed: 0.0189s/iter; left time: 256.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0555408 Vali Loss: 0.0542786 Test Loss: 0.0566839\n",
      "Validation loss decreased (0.054291 --> 0.054279).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0548276\n",
      "\tspeed: 0.0344s/iter; left time: 462.9470s\n",
      "\titers: 200, epoch: 41 | loss: 0.0597277\n",
      "\tspeed: 0.0158s/iter; left time: 211.6258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0555752 Vali Loss: 0.0542433 Test Loss: 0.0566768\n",
      "Validation loss decreased (0.054279 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0533049\n",
      "\tspeed: 0.0370s/iter; left time: 489.7141s\n",
      "\titers: 200, epoch: 42 | loss: 0.0562531\n",
      "\tspeed: 0.0172s/iter; left time: 225.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0555230 Vali Loss: 0.0542666 Test Loss: 0.0566782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0556623\n",
      "\tspeed: 0.0317s/iter; left time: 412.4533s\n",
      "\titers: 200, epoch: 43 | loss: 0.0522621\n",
      "\tspeed: 0.0143s/iter; left time: 184.1355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0555398 Vali Loss: 0.0542849 Test Loss: 0.0567014\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547930\n",
      "\tspeed: 0.0364s/iter; left time: 465.2045s\n",
      "\titers: 200, epoch: 44 | loss: 0.0556331\n",
      "\tspeed: 0.0173s/iter; left time: 220.0462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 226 | Train Loss: 0.0555342 Vali Loss: 0.0542565 Test Loss: 0.0566445\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0550974\n",
      "\tspeed: 0.0316s/iter; left time: 396.7160s\n",
      "\titers: 200, epoch: 45 | loss: 0.0577911\n",
      "\tspeed: 0.0199s/iter; left time: 248.0192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0554842 Vali Loss: 0.0542433 Test Loss: 0.0566635\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0575353\n",
      "\tspeed: 0.0373s/iter; left time: 460.4084s\n",
      "\titers: 200, epoch: 46 | loss: 0.0522142\n",
      "\tspeed: 0.0186s/iter; left time: 226.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 226 | Train Loss: 0.0554918 Vali Loss: 0.0542934 Test Loss: 0.0567038\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0574253\n",
      "\tspeed: 0.0366s/iter; left time: 442.6720s\n",
      "\titers: 200, epoch: 47 | loss: 0.0566233\n",
      "\tspeed: 0.0188s/iter; left time: 225.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0554435 Vali Loss: 0.0542549 Test Loss: 0.0566532\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0553350\n",
      "\tspeed: 0.0327s/iter; left time: 388.8370s\n",
      "\titers: 200, epoch: 48 | loss: 0.0556369\n",
      "\tspeed: 0.0110s/iter; left time: 129.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0554421 Vali Loss: 0.0542326 Test Loss: 0.0566230\n",
      "Validation loss decreased (0.054243 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0547879\n",
      "\tspeed: 0.0266s/iter; left time: 309.4427s\n",
      "\titers: 200, epoch: 49 | loss: 0.0571191\n",
      "\tspeed: 0.0154s/iter; left time: 178.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 226 | Train Loss: 0.0554875 Vali Loss: 0.0542973 Test Loss: 0.0566744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0545607\n",
      "\tspeed: 0.0302s/iter; left time: 345.2076s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601258\n",
      "\tspeed: 0.0158s/iter; left time: 179.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0554540 Vali Loss: 0.0543102 Test Loss: 0.0566505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0563313\n",
      "\tspeed: 0.0290s/iter; left time: 325.0505s\n",
      "\titers: 200, epoch: 51 | loss: 0.0548222\n",
      "\tspeed: 0.0199s/iter; left time: 221.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0554719 Vali Loss: 0.0542533 Test Loss: 0.0566383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0545011\n",
      "\tspeed: 0.0325s/iter; left time: 356.8565s\n",
      "\titers: 200, epoch: 52 | loss: 0.0588692\n",
      "\tspeed: 0.0156s/iter; left time: 169.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0554400 Vali Loss: 0.0542348 Test Loss: 0.0566454\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0573895\n",
      "\tspeed: 0.0347s/iter; left time: 373.1242s\n",
      "\titers: 200, epoch: 53 | loss: 0.0557008\n",
      "\tspeed: 0.0129s/iter; left time: 137.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0554208 Vali Loss: 0.0542583 Test Loss: 0.0566513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0584419\n",
      "\tspeed: 0.0320s/iter; left time: 336.7609s\n",
      "\titers: 200, epoch: 54 | loss: 0.0557770\n",
      "\tspeed: 0.0162s/iter; left time: 169.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0554332 Vali Loss: 0.0543062 Test Loss: 0.0566685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0592031\n",
      "\tspeed: 0.0389s/iter; left time: 400.3010s\n",
      "\titers: 200, epoch: 55 | loss: 0.0580452\n",
      "\tspeed: 0.0206s/iter; left time: 210.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 226 | Train Loss: 0.0554006 Vali Loss: 0.0542188 Test Loss: 0.0566485\n",
      "Validation loss decreased (0.054233 --> 0.054219).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0557944\n",
      "\tspeed: 0.0409s/iter; left time: 411.7455s\n",
      "\titers: 200, epoch: 56 | loss: 0.0575436\n",
      "\tspeed: 0.0207s/iter; left time: 206.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0554949 Vali Loss: 0.0542535 Test Loss: 0.0566425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0552367\n",
      "\tspeed: 0.0414s/iter; left time: 407.1292s\n",
      "\titers: 200, epoch: 57 | loss: 0.0526632\n",
      "\tspeed: 0.0241s/iter; left time: 235.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 226 | Train Loss: 0.0554752 Vali Loss: 0.0542661 Test Loss: 0.0566391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0547907\n",
      "\tspeed: 0.0400s/iter; left time: 384.9602s\n",
      "\titers: 200, epoch: 58 | loss: 0.0545247\n",
      "\tspeed: 0.0207s/iter; left time: 196.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0554905 Vali Loss: 0.0541866 Test Loss: 0.0566272\n",
      "Validation loss decreased (0.054219 --> 0.054187).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0552047\n",
      "\tspeed: 0.0409s/iter; left time: 384.3971s\n",
      "\titers: 200, epoch: 59 | loss: 0.0546905\n",
      "\tspeed: 0.0208s/iter; left time: 193.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554464 Vali Loss: 0.0542363 Test Loss: 0.0566469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0582271\n",
      "\tspeed: 0.0398s/iter; left time: 365.0822s\n",
      "\titers: 200, epoch: 60 | loss: 0.0584647\n",
      "\tspeed: 0.0210s/iter; left time: 190.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0553746 Vali Loss: 0.0542754 Test Loss: 0.0566607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0538022\n",
      "\tspeed: 0.0400s/iter; left time: 357.9140s\n",
      "\titers: 200, epoch: 61 | loss: 0.0595238\n",
      "\tspeed: 0.0210s/iter; left time: 185.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0554177 Vali Loss: 0.0542619 Test Loss: 0.0566389\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0548657\n",
      "\tspeed: 0.0397s/iter; left time: 345.9753s\n",
      "\titers: 200, epoch: 62 | loss: 0.0552229\n",
      "\tspeed: 0.0208s/iter; left time: 179.1133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0553776 Vali Loss: 0.0542065 Test Loss: 0.0566425\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0586561\n",
      "\tspeed: 0.0395s/iter; left time: 335.5264s\n",
      "\titers: 200, epoch: 63 | loss: 0.0528608\n",
      "\tspeed: 0.0208s/iter; left time: 174.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0554656 Vali Loss: 0.0543084 Test Loss: 0.0566508\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0573308\n",
      "\tspeed: 0.0396s/iter; left time: 327.3391s\n",
      "\titers: 200, epoch: 64 | loss: 0.0524875\n",
      "\tspeed: 0.0207s/iter; left time: 168.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0554920 Vali Loss: 0.0543357 Test Loss: 0.0566719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0554935\n",
      "\tspeed: 0.0400s/iter; left time: 321.1642s\n",
      "\titers: 200, epoch: 65 | loss: 0.0556387\n",
      "\tspeed: 0.0209s/iter; left time: 166.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554536 Vali Loss: 0.0542445 Test Loss: 0.0566510\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0557238\n",
      "\tspeed: 0.0407s/iter; left time: 317.9882s\n",
      "\titers: 200, epoch: 66 | loss: 0.0578800\n",
      "\tspeed: 0.0207s/iter; left time: 159.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0554466 Vali Loss: 0.0542907 Test Loss: 0.0566411\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0559544\n",
      "\tspeed: 0.0414s/iter; left time: 314.2850s\n",
      "\titers: 200, epoch: 67 | loss: 0.0554192\n",
      "\tspeed: 0.0211s/iter; left time: 158.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0554506 Vali Loss: 0.0542586 Test Loss: 0.0566385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0526508\n",
      "\tspeed: 0.0402s/iter; left time: 295.5240s\n",
      "\titers: 200, epoch: 68 | loss: 0.0582800\n",
      "\tspeed: 0.0209s/iter; left time: 151.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554338 Vali Loss: 0.0542876 Test Loss: 0.0566296\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010013620369136333, rmse:0.10006807744503021, mae:0.05662719905376434, rse:0.3781079947948456\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1573607\n",
      "\tspeed: 0.0223s/iter; left time: 501.1747s\n",
      "\titers: 200, epoch: 1 | loss: 0.1300314\n",
      "\tspeed: 0.0211s/iter; left time: 473.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.1577573 Vali Loss: 0.1105426 Test Loss: 0.1145439\n",
      "Validation loss decreased (inf --> 0.110543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0793203\n",
      "\tspeed: 0.0412s/iter; left time: 917.2832s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723160\n",
      "\tspeed: 0.0207s/iter; left time: 458.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0822697 Vali Loss: 0.0660343 Test Loss: 0.0675971\n",
      "Validation loss decreased (0.110543 --> 0.066034).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0746850\n",
      "\tspeed: 0.0424s/iter; left time: 935.3700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0648276\n",
      "\tspeed: 0.0207s/iter; left time: 455.0452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 226 | Train Loss: 0.0688575 Vali Loss: 0.0622213 Test Loss: 0.0644347\n",
      "Validation loss decreased (0.066034 --> 0.062221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676612\n",
      "\tspeed: 0.0410s/iter; left time: 893.8046s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647271\n",
      "\tspeed: 0.0206s/iter; left time: 448.5015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0654854 Vali Loss: 0.0597844 Test Loss: 0.0622531\n",
      "Validation loss decreased (0.062221 --> 0.059784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643532\n",
      "\tspeed: 0.0410s/iter; left time: 885.2005s\n",
      "\titers: 200, epoch: 5 | loss: 0.0649878\n",
      "\tspeed: 0.0208s/iter; left time: 447.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0632192 Vali Loss: 0.0583535 Test Loss: 0.0607662\n",
      "Validation loss decreased (0.059784 --> 0.058354).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636768\n",
      "\tspeed: 0.0413s/iter; left time: 883.6520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0600426\n",
      "\tspeed: 0.0208s/iter; left time: 442.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0617498 Vali Loss: 0.0575012 Test Loss: 0.0599200\n",
      "Validation loss decreased (0.058354 --> 0.057501).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585431\n",
      "\tspeed: 0.0420s/iter; left time: 887.2518s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626427\n",
      "\tspeed: 0.0207s/iter; left time: 435.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0607552 Vali Loss: 0.0570765 Test Loss: 0.0593813\n",
      "Validation loss decreased (0.057501 --> 0.057077).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0621818\n",
      "\tspeed: 0.0453s/iter; left time: 947.4440s\n",
      "\titers: 200, epoch: 8 | loss: 0.0585240\n",
      "\tspeed: 0.0223s/iter; left time: 463.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 226 | Train Loss: 0.0598608 Vali Loss: 0.0566811 Test Loss: 0.0587871\n",
      "Validation loss decreased (0.057077 --> 0.056681).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0634323\n",
      "\tspeed: 0.0434s/iter; left time: 898.4721s\n",
      "\titers: 200, epoch: 9 | loss: 0.0529604\n",
      "\tspeed: 0.0216s/iter; left time: 445.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 226 | Train Loss: 0.0592861 Vali Loss: 0.0563962 Test Loss: 0.0584393\n",
      "Validation loss decreased (0.056681 --> 0.056396).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0588704\n",
      "\tspeed: 0.0410s/iter; left time: 840.1156s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591631\n",
      "\tspeed: 0.0207s/iter; left time: 421.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0588297 Vali Loss: 0.0560655 Test Loss: 0.0582095\n",
      "Validation loss decreased (0.056396 --> 0.056065).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0584188\n",
      "\tspeed: 0.0406s/iter; left time: 822.6313s\n",
      "\titers: 200, epoch: 11 | loss: 0.0559009\n",
      "\tspeed: 0.0206s/iter; left time: 415.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0584830 Vali Loss: 0.0559946 Test Loss: 0.0581161\n",
      "Validation loss decreased (0.056065 --> 0.055995).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601121\n",
      "\tspeed: 0.0408s/iter; left time: 817.4414s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607920\n",
      "\tspeed: 0.0208s/iter; left time: 413.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0580687 Vali Loss: 0.0558722 Test Loss: 0.0578477\n",
      "Validation loss decreased (0.055995 --> 0.055872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0583283\n",
      "\tspeed: 0.0406s/iter; left time: 803.1971s\n",
      "\titers: 200, epoch: 13 | loss: 0.0573606\n",
      "\tspeed: 0.0206s/iter; left time: 405.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0577804 Vali Loss: 0.0556091 Test Loss: 0.0576085\n",
      "Validation loss decreased (0.055872 --> 0.055609).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0578804\n",
      "\tspeed: 0.0409s/iter; left time: 799.8185s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590153\n",
      "\tspeed: 0.0207s/iter; left time: 403.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0575066 Vali Loss: 0.0554821 Test Loss: 0.0575015\n",
      "Validation loss decreased (0.055609 --> 0.055482).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571506\n",
      "\tspeed: 0.0403s/iter; left time: 778.3618s\n",
      "\titers: 200, epoch: 15 | loss: 0.0561143\n",
      "\tspeed: 0.0206s/iter; left time: 397.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0572847 Vali Loss: 0.0552979 Test Loss: 0.0573816\n",
      "Validation loss decreased (0.055482 --> 0.055298).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0606932\n",
      "\tspeed: 0.0411s/iter; left time: 785.0597s\n",
      "\titers: 200, epoch: 16 | loss: 0.0601799\n",
      "\tspeed: 0.0209s/iter; left time: 397.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0570542 Vali Loss: 0.0552463 Test Loss: 0.0573230\n",
      "Validation loss decreased (0.055298 --> 0.055246).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562132\n",
      "\tspeed: 0.0421s/iter; left time: 795.8917s\n",
      "\titers: 200, epoch: 17 | loss: 0.0517945\n",
      "\tspeed: 0.0207s/iter; left time: 388.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0569558 Vali Loss: 0.0551512 Test Loss: 0.0572169\n",
      "Validation loss decreased (0.055246 --> 0.055151).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549782\n",
      "\tspeed: 0.0406s/iter; left time: 757.9198s\n",
      "\titers: 200, epoch: 18 | loss: 0.0557214\n",
      "\tspeed: 0.0207s/iter; left time: 383.2907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0567689 Vali Loss: 0.0550626 Test Loss: 0.0571761\n",
      "Validation loss decreased (0.055151 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578548\n",
      "\tspeed: 0.0408s/iter; left time: 751.9434s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540285\n",
      "\tspeed: 0.0207s/iter; left time: 380.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0566034 Vali Loss: 0.0548398 Test Loss: 0.0571010\n",
      "Validation loss decreased (0.055063 --> 0.054840).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0574559\n",
      "\tspeed: 0.0437s/iter; left time: 796.3183s\n",
      "\titers: 200, epoch: 20 | loss: 0.0562656\n",
      "\tspeed: 0.0207s/iter; left time: 374.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0564844 Vali Loss: 0.0550186 Test Loss: 0.0571432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0561579\n",
      "\tspeed: 0.0405s/iter; left time: 728.9998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0594371\n",
      "\tspeed: 0.0207s/iter; left time: 369.8702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0563916 Vali Loss: 0.0548216 Test Loss: 0.0570241\n",
      "Validation loss decreased (0.054840 --> 0.054822).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0581695\n",
      "\tspeed: 0.0408s/iter; left time: 725.0918s\n",
      "\titers: 200, epoch: 22 | loss: 0.0569547\n",
      "\tspeed: 0.0208s/iter; left time: 367.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0561927 Vali Loss: 0.0548563 Test Loss: 0.0569162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0582812\n",
      "\tspeed: 0.0404s/iter; left time: 708.2660s\n",
      "\titers: 200, epoch: 23 | loss: 0.0591026\n",
      "\tspeed: 0.0206s/iter; left time: 359.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0562241 Vali Loss: 0.0548312 Test Loss: 0.0568969\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0575212\n",
      "\tspeed: 0.0405s/iter; left time: 701.1362s\n",
      "\titers: 200, epoch: 24 | loss: 0.0577626\n",
      "\tspeed: 0.0208s/iter; left time: 357.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0560995 Vali Loss: 0.0546449 Test Loss: 0.0568261\n",
      "Validation loss decreased (0.054822 --> 0.054645).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0569925\n",
      "\tspeed: 0.0414s/iter; left time: 707.1271s\n",
      "\titers: 200, epoch: 25 | loss: 0.0539485\n",
      "\tspeed: 0.0208s/iter; left time: 352.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 226 | Train Loss: 0.0560700 Vali Loss: 0.0546967 Test Loss: 0.0567787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0563161\n",
      "\tspeed: 0.0406s/iter; left time: 684.3640s\n",
      "\titers: 200, epoch: 26 | loss: 0.0521550\n",
      "\tspeed: 0.0212s/iter; left time: 354.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0559894 Vali Loss: 0.0546580 Test Loss: 0.0567892\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0538891\n",
      "\tspeed: 0.0410s/iter; left time: 682.0252s\n",
      "\titers: 200, epoch: 27 | loss: 0.0539563\n",
      "\tspeed: 0.0207s/iter; left time: 342.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0559241 Vali Loss: 0.0546632 Test Loss: 0.0567738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0540387\n",
      "\tspeed: 0.0402s/iter; left time: 659.2702s\n",
      "\titers: 200, epoch: 28 | loss: 0.0539434\n",
      "\tspeed: 0.0207s/iter; left time: 338.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0559196 Vali Loss: 0.0546260 Test Loss: 0.0567322\n",
      "Validation loss decreased (0.054645 --> 0.054626).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0551787\n",
      "\tspeed: 0.0415s/iter; left time: 670.8148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0559215\n",
      "\tspeed: 0.0208s/iter; left time: 334.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0558759 Vali Loss: 0.0545475 Test Loss: 0.0567204\n",
      "Validation loss decreased (0.054626 --> 0.054548).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0539703\n",
      "\tspeed: 0.0407s/iter; left time: 649.3731s\n",
      "\titers: 200, epoch: 30 | loss: 0.0529386\n",
      "\tspeed: 0.0220s/iter; left time: 348.6622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 226 | Train Loss: 0.0558195 Vali Loss: 0.0545579 Test Loss: 0.0566725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0549525\n",
      "\tspeed: 0.0403s/iter; left time: 633.1932s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581255\n",
      "\tspeed: 0.0210s/iter; left time: 327.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0557404 Vali Loss: 0.0544842 Test Loss: 0.0566326\n",
      "Validation loss decreased (0.054548 --> 0.054484).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531414\n",
      "\tspeed: 0.0407s/iter; left time: 629.8803s\n",
      "\titers: 200, epoch: 32 | loss: 0.0568882\n",
      "\tspeed: 0.0208s/iter; left time: 320.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0557324 Vali Loss: 0.0545144 Test Loss: 0.0566872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0525673\n",
      "\tspeed: 0.0407s/iter; left time: 620.7663s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552366\n",
      "\tspeed: 0.0208s/iter; left time: 314.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0557313 Vali Loss: 0.0545479 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0545913\n",
      "\tspeed: 0.0407s/iter; left time: 612.7376s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527151\n",
      "\tspeed: 0.0214s/iter; left time: 320.3710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0556540 Vali Loss: 0.0545217 Test Loss: 0.0565855\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0528577\n",
      "\tspeed: 0.0404s/iter; left time: 598.0508s\n",
      "\titers: 200, epoch: 35 | loss: 0.0565141\n",
      "\tspeed: 0.0222s/iter; left time: 326.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 226 | Train Loss: 0.0556809 Vali Loss: 0.0545160 Test Loss: 0.0565746\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0542427\n",
      "\tspeed: 0.0414s/iter; left time: 603.8443s\n",
      "\titers: 200, epoch: 36 | loss: 0.0564523\n",
      "\tspeed: 0.0208s/iter; left time: 301.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0556686 Vali Loss: 0.0544228 Test Loss: 0.0565843\n",
      "Validation loss decreased (0.054484 --> 0.054423).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0549694\n",
      "\tspeed: 0.0408s/iter; left time: 586.3012s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558352\n",
      "\tspeed: 0.0208s/iter; left time: 296.1056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0556525 Vali Loss: 0.0544250 Test Loss: 0.0566035\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556710\n",
      "\tspeed: 0.0408s/iter; left time: 576.6104s\n",
      "\titers: 200, epoch: 38 | loss: 0.0572953\n",
      "\tspeed: 0.0212s/iter; left time: 297.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 226 | Train Loss: 0.0556188 Vali Loss: 0.0544323 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0535805\n",
      "\tspeed: 0.0412s/iter; left time: 572.9118s\n",
      "\titers: 200, epoch: 39 | loss: 0.0622349\n",
      "\tspeed: 0.0208s/iter; left time: 287.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0556048 Vali Loss: 0.0544680 Test Loss: 0.0565738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0561483\n",
      "\tspeed: 0.0412s/iter; left time: 564.3674s\n",
      "\titers: 200, epoch: 40 | loss: 0.0531933\n",
      "\tspeed: 0.0207s/iter; left time: 281.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0555662 Vali Loss: 0.0544984 Test Loss: 0.0565711\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0561239\n",
      "\tspeed: 0.0408s/iter; left time: 549.7383s\n",
      "\titers: 200, epoch: 41 | loss: 0.0517765\n",
      "\tspeed: 0.0217s/iter; left time: 289.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 226 | Train Loss: 0.0555728 Vali Loss: 0.0543907 Test Loss: 0.0565282\n",
      "Validation loss decreased (0.054423 --> 0.054391).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523082\n",
      "\tspeed: 0.0408s/iter; left time: 540.0180s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538820\n",
      "\tspeed: 0.0208s/iter; left time: 272.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0555350 Vali Loss: 0.0544950 Test Loss: 0.0565574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0518777\n",
      "\tspeed: 0.0401s/iter; left time: 521.5896s\n",
      "\titers: 200, epoch: 43 | loss: 0.0526231\n",
      "\tspeed: 0.0207s/iter; left time: 267.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0555422 Vali Loss: 0.0543530 Test Loss: 0.0565322\n",
      "Validation loss decreased (0.054391 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0558865\n",
      "\tspeed: 0.0432s/iter; left time: 552.5992s\n",
      "\titers: 200, epoch: 44 | loss: 0.0584679\n",
      "\tspeed: 0.0217s/iter; left time: 275.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 226 | Train Loss: 0.0555280 Vali Loss: 0.0543507 Test Loss: 0.0565503\n",
      "Validation loss decreased (0.054353 --> 0.054351).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0574074\n",
      "\tspeed: 0.0420s/iter; left time: 528.0008s\n",
      "\titers: 200, epoch: 45 | loss: 0.0555215\n",
      "\tspeed: 0.0212s/iter; left time: 264.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 226 | Train Loss: 0.0555235 Vali Loss: 0.0544811 Test Loss: 0.0565407\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0546385\n",
      "\tspeed: 0.0412s/iter; left time: 508.5139s\n",
      "\titers: 200, epoch: 46 | loss: 0.0590151\n",
      "\tspeed: 0.0210s/iter; left time: 256.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0555281 Vali Loss: 0.0544902 Test Loss: 0.0565665\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0578885\n",
      "\tspeed: 0.0403s/iter; left time: 487.7635s\n",
      "\titers: 200, epoch: 47 | loss: 0.0509819\n",
      "\tspeed: 0.0207s/iter; left time: 248.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0555610 Vali Loss: 0.0544188 Test Loss: 0.0565211\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0543291\n",
      "\tspeed: 0.0414s/iter; left time: 491.3178s\n",
      "\titers: 200, epoch: 48 | loss: 0.0562213\n",
      "\tspeed: 0.0212s/iter; left time: 249.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 226 | Train Loss: 0.0555136 Vali Loss: 0.0544448 Test Loss: 0.0565119\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0515884\n",
      "\tspeed: 0.0400s/iter; left time: 466.3707s\n",
      "\titers: 200, epoch: 49 | loss: 0.0570134\n",
      "\tspeed: 0.0207s/iter; left time: 239.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0555256 Vali Loss: 0.0544299 Test Loss: 0.0565411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0553536\n",
      "\tspeed: 0.0418s/iter; left time: 477.6535s\n",
      "\titers: 200, epoch: 50 | loss: 0.0554720\n",
      "\tspeed: 0.0207s/iter; left time: 234.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0554629 Vali Loss: 0.0543953 Test Loss: 0.0565168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0514704\n",
      "\tspeed: 0.0408s/iter; left time: 456.4795s\n",
      "\titers: 200, epoch: 51 | loss: 0.0539592\n",
      "\tspeed: 0.0208s/iter; left time: 230.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0554583 Vali Loss: 0.0544391 Test Loss: 0.0565219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0580358\n",
      "\tspeed: 0.0400s/iter; left time: 439.3845s\n",
      "\titers: 200, epoch: 52 | loss: 0.0561351\n",
      "\tspeed: 0.0208s/iter; left time: 225.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0555748 Vali Loss: 0.0544157 Test Loss: 0.0565323\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0542540\n",
      "\tspeed: 0.0416s/iter; left time: 447.1590s\n",
      "\titers: 200, epoch: 53 | loss: 0.0574763\n",
      "\tspeed: 0.0211s/iter; left time: 224.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0554894 Vali Loss: 0.0544404 Test Loss: 0.0565196\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0552687\n",
      "\tspeed: 0.0401s/iter; left time: 422.0096s\n",
      "\titers: 200, epoch: 54 | loss: 0.0548174\n",
      "\tspeed: 0.0211s/iter; left time: 219.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0555267 Vali Loss: 0.0543990 Test Loss: 0.0565228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009993644431233406, rmse:0.09996821731328964, mae:0.05655033513903618, rse:0.37773069739341736\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:50.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1669092\n",
      "\tspeed: 0.0452s/iter; left time: 1012.5820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1401041\n",
      "\tspeed: 0.0207s/iter; left time: 461.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.1638128 Vali Loss: 0.1188383 Test Loss: 0.1233246\n",
      "Validation loss decreased (inf --> 0.118838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1033055\n",
      "\tspeed: 0.0424s/iter; left time: 941.3287s\n",
      "\titers: 200, epoch: 2 | loss: 0.0938538\n",
      "\tspeed: 0.0208s/iter; left time: 459.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.1024199 Vali Loss: 0.0843555 Test Loss: 0.0881399\n",
      "Validation loss decreased (0.118838 --> 0.084356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874186\n",
      "\tspeed: 0.0430s/iter; left time: 944.8962s\n",
      "\titers: 200, epoch: 3 | loss: 0.0862540\n",
      "\tspeed: 0.0210s/iter; left time: 459.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0883068 Vali Loss: 0.0805757 Test Loss: 0.0844691\n",
      "Validation loss decreased (0.084356 --> 0.080576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0822606\n",
      "\tspeed: 0.0446s/iter; left time: 970.0285s\n",
      "\titers: 200, epoch: 4 | loss: 0.0853445\n",
      "\tspeed: 0.0209s/iter; left time: 451.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0851258 Vali Loss: 0.0790129 Test Loss: 0.0829461\n",
      "Validation loss decreased (0.080576 --> 0.079013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0794841\n",
      "\tspeed: 0.0420s/iter; left time: 904.0994s\n",
      "\titers: 200, epoch: 5 | loss: 0.0796301\n",
      "\tspeed: 0.0208s/iter; left time: 445.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0833385 Vali Loss: 0.0780248 Test Loss: 0.0820323\n",
      "Validation loss decreased (0.079013 --> 0.078025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0790213\n",
      "\tspeed: 0.0420s/iter; left time: 892.9639s\n",
      "\titers: 200, epoch: 6 | loss: 0.0824916\n",
      "\tspeed: 0.0209s/iter; left time: 443.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0820430 Vali Loss: 0.0773483 Test Loss: 0.0812382\n",
      "Validation loss decreased (0.078025 --> 0.077348).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770506\n",
      "\tspeed: 0.0432s/iter; left time: 910.1604s\n",
      "\titers: 200, epoch: 7 | loss: 0.0813279\n",
      "\tspeed: 0.0207s/iter; left time: 433.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0810946 Vali Loss: 0.0771037 Test Loss: 0.0812631\n",
      "Validation loss decreased (0.077348 --> 0.077104).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0820660\n",
      "\tspeed: 0.0430s/iter; left time: 895.8289s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803185\n",
      "\tspeed: 0.0206s/iter; left time: 427.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0803903 Vali Loss: 0.0763726 Test Loss: 0.0802872\n",
      "Validation loss decreased (0.077104 --> 0.076373).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0789092\n",
      "\tspeed: 0.0433s/iter; left time: 891.1467s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763635\n",
      "\tspeed: 0.0208s/iter; left time: 425.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0797350 Vali Loss: 0.0760175 Test Loss: 0.0801024\n",
      "Validation loss decreased (0.076373 --> 0.076018).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0757352\n",
      "\tspeed: 0.0423s/iter; left time: 862.3985s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821360\n",
      "\tspeed: 0.0207s/iter; left time: 419.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0792618 Vali Loss: 0.0760024 Test Loss: 0.0800756\n",
      "Validation loss decreased (0.076018 --> 0.076002).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765340\n",
      "\tspeed: 0.0424s/iter; left time: 854.6667s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766016\n",
      "\tspeed: 0.0208s/iter; left time: 417.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0788864 Vali Loss: 0.0757054 Test Loss: 0.0797140\n",
      "Validation loss decreased (0.076002 --> 0.075705).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787157\n",
      "\tspeed: 0.0427s/iter; left time: 850.0699s\n",
      "\titers: 200, epoch: 12 | loss: 0.0781840\n",
      "\tspeed: 0.0208s/iter; left time: 412.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0785617 Vali Loss: 0.0754555 Test Loss: 0.0794976\n",
      "Validation loss decreased (0.075705 --> 0.075456).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0803629\n",
      "\tspeed: 0.0424s/iter; left time: 835.8411s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813732\n",
      "\tspeed: 0.0208s/iter; left time: 407.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0782243 Vali Loss: 0.0753873 Test Loss: 0.0795178\n",
      "Validation loss decreased (0.075456 --> 0.075387).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805302\n",
      "\tspeed: 0.0426s/iter; left time: 830.4879s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788860\n",
      "\tspeed: 0.0208s/iter; left time: 403.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0779015 Vali Loss: 0.0751808 Test Loss: 0.0794455\n",
      "Validation loss decreased (0.075387 --> 0.075181).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0773549\n",
      "\tspeed: 0.0425s/iter; left time: 817.5567s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791559\n",
      "\tspeed: 0.0227s/iter; left time: 434.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0777317 Vali Loss: 0.0751953 Test Loss: 0.0795967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785272\n",
      "\tspeed: 0.0422s/iter; left time: 802.9055s\n",
      "\titers: 200, epoch: 16 | loss: 0.0769728\n",
      "\tspeed: 0.0209s/iter; left time: 394.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0774655 Vali Loss: 0.0749888 Test Loss: 0.0792939\n",
      "Validation loss decreased (0.075181 --> 0.074989).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0769738\n",
      "\tspeed: 0.0438s/iter; left time: 824.3760s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778376\n",
      "\tspeed: 0.0213s/iter; left time: 398.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0772400 Vali Loss: 0.0750678 Test Loss: 0.0794692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0805343\n",
      "\tspeed: 0.0424s/iter; left time: 787.8991s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752611\n",
      "\tspeed: 0.0207s/iter; left time: 383.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0770767 Vali Loss: 0.0748767 Test Loss: 0.0791836\n",
      "Validation loss decreased (0.074989 --> 0.074877).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779965\n",
      "\tspeed: 0.0429s/iter; left time: 787.0227s\n",
      "\titers: 200, epoch: 19 | loss: 0.0749951\n",
      "\tspeed: 0.0209s/iter; left time: 380.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0769474 Vali Loss: 0.0746936 Test Loss: 0.0789684\n",
      "Validation loss decreased (0.074877 --> 0.074694).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0736500\n",
      "\tspeed: 0.0420s/iter; left time: 762.0740s\n",
      "\titers: 200, epoch: 20 | loss: 0.0772865\n",
      "\tspeed: 0.0207s/iter; left time: 373.4359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0767863 Vali Loss: 0.0748690 Test Loss: 0.0791829\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0763280\n",
      "\tspeed: 0.0422s/iter; left time: 755.2023s\n",
      "\titers: 200, epoch: 21 | loss: 0.0714772\n",
      "\tspeed: 0.0208s/iter; left time: 370.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0766963 Vali Loss: 0.0748559 Test Loss: 0.0792080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0795258\n",
      "\tspeed: 0.0434s/iter; left time: 766.9435s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783744\n",
      "\tspeed: 0.0208s/iter; left time: 365.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0765899 Vali Loss: 0.0747872 Test Loss: 0.0790109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0773060\n",
      "\tspeed: 0.0423s/iter; left time: 738.0832s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768325\n",
      "\tspeed: 0.0213s/iter; left time: 368.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0765073 Vali Loss: 0.0747645 Test Loss: 0.0790767\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0763985\n",
      "\tspeed: 0.0426s/iter; left time: 733.1196s\n",
      "\titers: 200, epoch: 24 | loss: 0.0742462\n",
      "\tspeed: 0.0208s/iter; left time: 355.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0763747 Vali Loss: 0.0746120 Test Loss: 0.0790180\n",
      "Validation loss decreased (0.074694 --> 0.074612).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758858\n",
      "\tspeed: 0.0437s/iter; left time: 742.7844s\n",
      "\titers: 200, epoch: 25 | loss: 0.0799969\n",
      "\tspeed: 0.0208s/iter; left time: 351.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0762890 Vali Loss: 0.0746417 Test Loss: 0.0790498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812193\n",
      "\tspeed: 0.0425s/iter; left time: 713.7002s\n",
      "\titers: 200, epoch: 26 | loss: 0.0759417\n",
      "\tspeed: 0.0208s/iter; left time: 346.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0762690 Vali Loss: 0.0745990 Test Loss: 0.0788645\n",
      "Validation loss decreased (0.074612 --> 0.074599).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0765115\n",
      "\tspeed: 0.0425s/iter; left time: 703.0682s\n",
      "\titers: 200, epoch: 27 | loss: 0.0747217\n",
      "\tspeed: 0.0208s/iter; left time: 342.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0761361 Vali Loss: 0.0745715 Test Loss: 0.0788600\n",
      "Validation loss decreased (0.074599 --> 0.074571).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780237\n",
      "\tspeed: 0.0427s/iter; left time: 696.8410s\n",
      "\titers: 200, epoch: 28 | loss: 0.0751070\n",
      "\tspeed: 0.0209s/iter; left time: 338.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0761311 Vali Loss: 0.0746733 Test Loss: 0.0790727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0780154\n",
      "\tspeed: 0.0419s/iter; left time: 673.9280s\n",
      "\titers: 200, epoch: 29 | loss: 0.0717261\n",
      "\tspeed: 0.0208s/iter; left time: 333.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0760820 Vali Loss: 0.0745423 Test Loss: 0.0788420\n",
      "Validation loss decreased (0.074571 --> 0.074542).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0772073\n",
      "\tspeed: 0.0436s/iter; left time: 691.9070s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782413\n",
      "\tspeed: 0.0209s/iter; left time: 329.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0759955 Vali Loss: 0.0745012 Test Loss: 0.0788583\n",
      "Validation loss decreased (0.074542 --> 0.074501).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0736191\n",
      "\tspeed: 0.0427s/iter; left time: 667.9280s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757232\n",
      "\tspeed: 0.0219s/iter; left time: 339.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0759875 Vali Loss: 0.0745420 Test Loss: 0.0788668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0742540\n",
      "\tspeed: 0.0434s/iter; left time: 668.7807s\n",
      "\titers: 200, epoch: 32 | loss: 0.0766309\n",
      "\tspeed: 0.0209s/iter; left time: 320.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0758916 Vali Loss: 0.0745379 Test Loss: 0.0788726\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0806924\n",
      "\tspeed: 0.0426s/iter; left time: 647.6184s\n",
      "\titers: 200, epoch: 33 | loss: 0.0794868\n",
      "\tspeed: 0.0208s/iter; left time: 314.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0758924 Vali Loss: 0.0745164 Test Loss: 0.0788155\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0811082\n",
      "\tspeed: 0.0425s/iter; left time: 636.3328s\n",
      "\titers: 200, epoch: 34 | loss: 0.0749670\n",
      "\tspeed: 0.0210s/iter; left time: 311.9770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758676 Vali Loss: 0.0745435 Test Loss: 0.0788689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753011\n",
      "\tspeed: 0.0430s/iter; left time: 633.9118s\n",
      "\titers: 200, epoch: 35 | loss: 0.0762374\n",
      "\tspeed: 0.0208s/iter; left time: 304.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0758858 Vali Loss: 0.0745267 Test Loss: 0.0788663\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0790051\n",
      "\tspeed: 0.0434s/iter; left time: 630.9701s\n",
      "\titers: 200, epoch: 36 | loss: 0.0784262\n",
      "\tspeed: 0.0207s/iter; left time: 298.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758194 Vali Loss: 0.0745543 Test Loss: 0.0789160\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786390\n",
      "\tspeed: 0.0423s/iter; left time: 604.3992s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717152\n",
      "\tspeed: 0.0208s/iter; left time: 295.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757936 Vali Loss: 0.0745547 Test Loss: 0.0788500\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0799452\n",
      "\tspeed: 0.0417s/iter; left time: 587.3101s\n",
      "\titers: 200, epoch: 38 | loss: 0.0723355\n",
      "\tspeed: 0.0211s/iter; left time: 294.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757439 Vali Loss: 0.0744955 Test Loss: 0.0787958\n",
      "Validation loss decreased (0.074501 --> 0.074495).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0733191\n",
      "\tspeed: 0.0428s/iter; left time: 592.7958s\n",
      "\titers: 200, epoch: 39 | loss: 0.0772472\n",
      "\tspeed: 0.0208s/iter; left time: 286.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0757125 Vali Loss: 0.0745277 Test Loss: 0.0788285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0731022\n",
      "\tspeed: 0.0412s/iter; left time: 561.8233s\n",
      "\titers: 200, epoch: 40 | loss: 0.0813463\n",
      "\tspeed: 0.0208s/iter; left time: 281.5469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757605 Vali Loss: 0.0744777 Test Loss: 0.0787457\n",
      "Validation loss decreased (0.074495 --> 0.074478).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0726994\n",
      "\tspeed: 0.0424s/iter; left time: 567.6496s\n",
      "\titers: 200, epoch: 41 | loss: 0.0707508\n",
      "\tspeed: 0.0209s/iter; left time: 277.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0757570 Vali Loss: 0.0744992 Test Loss: 0.0788272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0751855\n",
      "\tspeed: 0.0425s/iter; left time: 559.6674s\n",
      "\titers: 200, epoch: 42 | loss: 0.0751205\n",
      "\tspeed: 0.0209s/iter; left time: 273.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0757228 Vali Loss: 0.0745397 Test Loss: 0.0788634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0758706\n",
      "\tspeed: 0.0418s/iter; left time: 541.9239s\n",
      "\titers: 200, epoch: 43 | loss: 0.0756615\n",
      "\tspeed: 0.0211s/iter; left time: 271.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756767 Vali Loss: 0.0745036 Test Loss: 0.0788214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0782793\n",
      "\tspeed: 0.0428s/iter; left time: 545.1089s\n",
      "\titers: 200, epoch: 44 | loss: 0.0709118\n",
      "\tspeed: 0.0208s/iter; left time: 262.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756931 Vali Loss: 0.0744941 Test Loss: 0.0787882\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769355\n",
      "\tspeed: 0.0436s/iter; left time: 544.8735s\n",
      "\titers: 200, epoch: 45 | loss: 0.0730018\n",
      "\tspeed: 0.0215s/iter; left time: 267.1578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0757256 Vali Loss: 0.0745007 Test Loss: 0.0788010\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0741454\n",
      "\tspeed: 0.0419s/iter; left time: 514.3173s\n",
      "\titers: 200, epoch: 46 | loss: 0.0757747\n",
      "\tspeed: 0.0208s/iter; left time: 252.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0757511 Vali Loss: 0.0745217 Test Loss: 0.0788470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0733297\n",
      "\tspeed: 0.0424s/iter; left time: 511.4022s\n",
      "\titers: 200, epoch: 47 | loss: 0.0752435\n",
      "\tspeed: 0.0212s/iter; left time: 253.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0756909 Vali Loss: 0.0744966 Test Loss: 0.0787864\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0742979\n",
      "\tspeed: 0.0416s/iter; left time: 492.4860s\n",
      "\titers: 200, epoch: 48 | loss: 0.0754963\n",
      "\tspeed: 0.0208s/iter; left time: 244.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0756908 Vali Loss: 0.0744999 Test Loss: 0.0788212\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0724371\n",
      "\tspeed: 0.0419s/iter; left time: 485.7096s\n",
      "\titers: 200, epoch: 49 | loss: 0.0771678\n",
      "\tspeed: 0.0209s/iter; left time: 240.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756535 Vali Loss: 0.0745001 Test Loss: 0.0788215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0750389\n",
      "\tspeed: 0.0418s/iter; left time: 475.4922s\n",
      "\titers: 200, epoch: 50 | loss: 0.0723733\n",
      "\tspeed: 0.0208s/iter; left time: 234.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0756713 Vali Loss: 0.0744728 Test Loss: 0.0788004\n",
      "Validation loss decreased (0.074478 --> 0.074473).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0770440\n",
      "\tspeed: 0.0433s/iter; left time: 483.0598s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769106\n",
      "\tspeed: 0.0208s/iter; left time: 229.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0756731 Vali Loss: 0.0744990 Test Loss: 0.0788114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0742975\n",
      "\tspeed: 0.0423s/iter; left time: 462.5962s\n",
      "\titers: 200, epoch: 52 | loss: 0.0723217\n",
      "\tspeed: 0.0216s/iter; left time: 233.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0755942 Vali Loss: 0.0744465 Test Loss: 0.0787730\n",
      "Validation loss decreased (0.074473 --> 0.074446).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0775662\n",
      "\tspeed: 0.0423s/iter; left time: 452.9437s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746110\n",
      "\tspeed: 0.0208s/iter; left time: 220.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756881 Vali Loss: 0.0744816 Test Loss: 0.0788015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0793720\n",
      "\tspeed: 0.0432s/iter; left time: 452.0537s\n",
      "\titers: 200, epoch: 54 | loss: 0.0751703\n",
      "\tspeed: 0.0208s/iter; left time: 215.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756899 Vali Loss: 0.0744729 Test Loss: 0.0787960\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0773408\n",
      "\tspeed: 0.0417s/iter; left time: 427.0356s\n",
      "\titers: 200, epoch: 55 | loss: 0.0790814\n",
      "\tspeed: 0.0208s/iter; left time: 211.1901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756388 Vali Loss: 0.0744965 Test Loss: 0.0788164\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0722554\n",
      "\tspeed: 0.0414s/iter; left time: 415.4101s\n",
      "\titers: 200, epoch: 56 | loss: 0.0734554\n",
      "\tspeed: 0.0207s/iter; left time: 205.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756295 Vali Loss: 0.0744851 Test Loss: 0.0788308\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0712699\n",
      "\tspeed: 0.0416s/iter; left time: 408.0694s\n",
      "\titers: 200, epoch: 57 | loss: 0.0767291\n",
      "\tspeed: 0.0209s/iter; left time: 203.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0756545 Vali Loss: 0.0744595 Test Loss: 0.0788006\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736074\n",
      "\tspeed: 0.0417s/iter; left time: 399.2716s\n",
      "\titers: 200, epoch: 58 | loss: 0.0721901\n",
      "\tspeed: 0.0208s/iter; left time: 196.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756565 Vali Loss: 0.0744689 Test Loss: 0.0787867\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0782748\n",
      "\tspeed: 0.0424s/iter; left time: 396.4029s\n",
      "\titers: 200, epoch: 59 | loss: 0.0734969\n",
      "\tspeed: 0.0208s/iter; left time: 192.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756559 Vali Loss: 0.0744646 Test Loss: 0.0787873\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0761360\n",
      "\tspeed: 0.0428s/iter; left time: 390.8161s\n",
      "\titers: 200, epoch: 60 | loss: 0.0774208\n",
      "\tspeed: 0.0227s/iter; left time: 204.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0756059 Vali Loss: 0.0744760 Test Loss: 0.0788017\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0744535\n",
      "\tspeed: 0.0415s/iter; left time: 369.6899s\n",
      "\titers: 200, epoch: 61 | loss: 0.0719408\n",
      "\tspeed: 0.0211s/iter; left time: 185.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0756347 Vali Loss: 0.0744701 Test Loss: 0.0788029\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0716773\n",
      "\tspeed: 0.0423s/iter; left time: 367.0738s\n",
      "\titers: 200, epoch: 62 | loss: 0.0718452\n",
      "\tspeed: 0.0207s/iter; left time: 177.7702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0756371 Vali Loss: 0.0744701 Test Loss: 0.0787790\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01815042831003666, rmse:0.13472352921962738, mae:0.07877302914857864, rse:0.509404182434082\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1637366\n",
      "\tspeed: 0.0231s/iter; left time: 517.0028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1366874\n",
      "\tspeed: 0.0209s/iter; left time: 466.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.1638897 Vali Loss: 0.1186297 Test Loss: 0.1232584\n",
      "Validation loss decreased (inf --> 0.118630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1025519\n",
      "\tspeed: 0.0436s/iter; left time: 967.0378s\n",
      "\titers: 200, epoch: 2 | loss: 0.0871551\n",
      "\tspeed: 0.0208s/iter; left time: 459.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.1019576 Vali Loss: 0.0846024 Test Loss: 0.0879323\n",
      "Validation loss decreased (0.118630 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878244\n",
      "\tspeed: 0.0432s/iter; left time: 947.6436s\n",
      "\titers: 200, epoch: 3 | loss: 0.0881555\n",
      "\tspeed: 0.0208s/iter; left time: 454.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0882597 Vali Loss: 0.0806726 Test Loss: 0.0843868\n",
      "Validation loss decreased (0.084602 --> 0.080673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0828160\n",
      "\tspeed: 0.0432s/iter; left time: 939.3650s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839197\n",
      "\tspeed: 0.0208s/iter; left time: 449.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0853353 Vali Loss: 0.0792031 Test Loss: 0.0830309\n",
      "Validation loss decreased (0.080673 --> 0.079203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871444\n",
      "\tspeed: 0.0431s/iter; left time: 927.0891s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783487\n",
      "\tspeed: 0.0208s/iter; left time: 445.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0834572 Vali Loss: 0.0779789 Test Loss: 0.0820830\n",
      "Validation loss decreased (0.079203 --> 0.077979).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861226\n",
      "\tspeed: 0.0424s/iter; left time: 903.0358s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838076\n",
      "\tspeed: 0.0209s/iter; left time: 442.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0821980 Vali Loss: 0.0772114 Test Loss: 0.0812530\n",
      "Validation loss decreased (0.077979 --> 0.077211).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0826203\n",
      "\tspeed: 0.0424s/iter; left time: 891.6210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811351\n",
      "\tspeed: 0.0223s/iter; left time: 467.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0812458 Vali Loss: 0.0769910 Test Loss: 0.0810177\n",
      "Validation loss decreased (0.077211 --> 0.076991).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0833413\n",
      "\tspeed: 0.0428s/iter; left time: 890.9293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0802773\n",
      "\tspeed: 0.0208s/iter; left time: 430.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0805587 Vali Loss: 0.0763516 Test Loss: 0.0804884\n",
      "Validation loss decreased (0.076991 --> 0.076352).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844949\n",
      "\tspeed: 0.0437s/iter; left time: 901.2843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0781104\n",
      "\tspeed: 0.0216s/iter; left time: 442.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0798999 Vali Loss: 0.0760150 Test Loss: 0.0802005\n",
      "Validation loss decreased (0.076352 --> 0.076015).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0761344\n",
      "\tspeed: 0.0433s/iter; left time: 883.0924s\n",
      "\titers: 200, epoch: 10 | loss: 0.0780614\n",
      "\tspeed: 0.0215s/iter; left time: 435.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0794445 Vali Loss: 0.0758701 Test Loss: 0.0802442\n",
      "Validation loss decreased (0.076015 --> 0.075870).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0743540\n",
      "\tspeed: 0.0430s/iter; left time: 866.9888s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809893\n",
      "\tspeed: 0.0208s/iter; left time: 417.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0789785 Vali Loss: 0.0756105 Test Loss: 0.0798962\n",
      "Validation loss decreased (0.075870 --> 0.075610).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815798\n",
      "\tspeed: 0.0427s/iter; left time: 851.0189s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788627\n",
      "\tspeed: 0.0208s/iter; left time: 412.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0785684 Vali Loss: 0.0752351 Test Loss: 0.0795540\n",
      "Validation loss decreased (0.075610 --> 0.075235).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776551\n",
      "\tspeed: 0.0428s/iter; left time: 843.9088s\n",
      "\titers: 200, epoch: 13 | loss: 0.0810024\n",
      "\tspeed: 0.0208s/iter; left time: 408.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0782453 Vali Loss: 0.0750905 Test Loss: 0.0796944\n",
      "Validation loss decreased (0.075235 --> 0.075090).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825704\n",
      "\tspeed: 0.0427s/iter; left time: 831.7960s\n",
      "\titers: 200, epoch: 14 | loss: 0.0778248\n",
      "\tspeed: 0.0208s/iter; left time: 403.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0779376 Vali Loss: 0.0748365 Test Loss: 0.0794269\n",
      "Validation loss decreased (0.075090 --> 0.074837).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0827974\n",
      "\tspeed: 0.0433s/iter; left time: 832.9973s\n",
      "\titers: 200, epoch: 15 | loss: 0.0739762\n",
      "\tspeed: 0.0208s/iter; left time: 398.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0777293 Vali Loss: 0.0748100 Test Loss: 0.0795144\n",
      "Validation loss decreased (0.074837 --> 0.074810).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0784488\n",
      "\tspeed: 0.0427s/iter; left time: 813.1082s\n",
      "\titers: 200, epoch: 16 | loss: 0.0808750\n",
      "\tspeed: 0.0208s/iter; left time: 394.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0774809 Vali Loss: 0.0746060 Test Loss: 0.0792269\n",
      "Validation loss decreased (0.074810 --> 0.074606).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0773868\n",
      "\tspeed: 0.0459s/iter; left time: 862.9082s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736612\n",
      "\tspeed: 0.0219s/iter; left time: 409.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0773585 Vali Loss: 0.0745304 Test Loss: 0.0792232\n",
      "Validation loss decreased (0.074606 --> 0.074530).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773715\n",
      "\tspeed: 0.0442s/iter; left time: 820.4977s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747276\n",
      "\tspeed: 0.0210s/iter; left time: 387.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0770840 Vali Loss: 0.0744964 Test Loss: 0.0793575\n",
      "Validation loss decreased (0.074530 --> 0.074496).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0817562\n",
      "\tspeed: 0.0428s/iter; left time: 784.5678s\n",
      "\titers: 200, epoch: 19 | loss: 0.0816317\n",
      "\tspeed: 0.0208s/iter; left time: 380.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0769545 Vali Loss: 0.0744677 Test Loss: 0.0792675\n",
      "Validation loss decreased (0.074496 --> 0.074468).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0807086\n",
      "\tspeed: 0.0424s/iter; left time: 767.8067s\n",
      "\titers: 200, epoch: 20 | loss: 0.0757208\n",
      "\tspeed: 0.0208s/iter; left time: 375.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0768689 Vali Loss: 0.0743737 Test Loss: 0.0792753\n",
      "Validation loss decreased (0.074468 --> 0.074374).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0757226\n",
      "\tspeed: 0.0429s/iter; left time: 767.8128s\n",
      "\titers: 200, epoch: 21 | loss: 0.0786389\n",
      "\tspeed: 0.0209s/iter; left time: 371.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0767737 Vali Loss: 0.0742612 Test Loss: 0.0792980\n",
      "Validation loss decreased (0.074374 --> 0.074261).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0767378\n",
      "\tspeed: 0.0428s/iter; left time: 755.7606s\n",
      "\titers: 200, epoch: 22 | loss: 0.0715712\n",
      "\tspeed: 0.0210s/iter; left time: 368.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0766468 Vali Loss: 0.0742626 Test Loss: 0.0791987\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740811\n",
      "\tspeed: 0.0424s/iter; left time: 739.8467s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805914\n",
      "\tspeed: 0.0208s/iter; left time: 361.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0765060 Vali Loss: 0.0741969 Test Loss: 0.0790897\n",
      "Validation loss decreased (0.074261 --> 0.074197).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789765\n",
      "\tspeed: 0.0431s/iter; left time: 741.6001s\n",
      "\titers: 200, epoch: 24 | loss: 0.0792555\n",
      "\tspeed: 0.0208s/iter; left time: 356.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0764295 Vali Loss: 0.0741928 Test Loss: 0.0790885\n",
      "Validation loss decreased (0.074197 --> 0.074193).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770093\n",
      "\tspeed: 0.0438s/iter; left time: 744.7209s\n",
      "\titers: 200, epoch: 25 | loss: 0.0734579\n",
      "\tspeed: 0.0207s/iter; left time: 349.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0763085 Vali Loss: 0.0740530 Test Loss: 0.0790376\n",
      "Validation loss decreased (0.074193 --> 0.074053).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0832152\n",
      "\tspeed: 0.0453s/iter; left time: 759.3065s\n",
      "\titers: 200, epoch: 26 | loss: 0.0771939\n",
      "\tspeed: 0.0208s/iter; left time: 347.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0762396 Vali Loss: 0.0740980 Test Loss: 0.0791892\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0793880\n",
      "\tspeed: 0.0434s/iter; left time: 718.4866s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780192\n",
      "\tspeed: 0.0211s/iter; left time: 347.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0762377 Vali Loss: 0.0741957 Test Loss: 0.0793163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0764170\n",
      "\tspeed: 0.0426s/iter; left time: 694.9966s\n",
      "\titers: 200, epoch: 28 | loss: 0.0761216\n",
      "\tspeed: 0.0208s/iter; left time: 338.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0761330 Vali Loss: 0.0740410 Test Loss: 0.0790464\n",
      "Validation loss decreased (0.074053 --> 0.074041).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0765215\n",
      "\tspeed: 0.0427s/iter; left time: 687.8919s\n",
      "\titers: 200, epoch: 29 | loss: 0.0725563\n",
      "\tspeed: 0.0208s/iter; left time: 332.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0760898 Vali Loss: 0.0741024 Test Loss: 0.0792137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0759419\n",
      "\tspeed: 0.0422s/iter; left time: 670.5457s\n",
      "\titers: 200, epoch: 30 | loss: 0.0745000\n",
      "\tspeed: 0.0209s/iter; left time: 330.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0760080 Vali Loss: 0.0740135 Test Loss: 0.0790522\n",
      "Validation loss decreased (0.074041 --> 0.074014).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778709\n",
      "\tspeed: 0.0429s/iter; left time: 671.6879s\n",
      "\titers: 200, epoch: 31 | loss: 0.0792639\n",
      "\tspeed: 0.0208s/iter; left time: 323.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0760577 Vali Loss: 0.0741240 Test Loss: 0.0792914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0790154\n",
      "\tspeed: 0.0419s/iter; left time: 645.6491s\n",
      "\titers: 200, epoch: 32 | loss: 0.0769542\n",
      "\tspeed: 0.0208s/iter; left time: 318.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0760318 Vali Loss: 0.0740355 Test Loss: 0.0791062\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0813910\n",
      "\tspeed: 0.0417s/iter; left time: 633.5168s\n",
      "\titers: 200, epoch: 33 | loss: 0.0737934\n",
      "\tspeed: 0.0213s/iter; left time: 321.0924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0759564 Vali Loss: 0.0739913 Test Loss: 0.0790909\n",
      "Validation loss decreased (0.074014 --> 0.073991).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0782049\n",
      "\tspeed: 0.0421s/iter; left time: 630.2455s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774192\n",
      "\tspeed: 0.0209s/iter; left time: 311.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0759514 Vali Loss: 0.0739873 Test Loss: 0.0791798\n",
      "Validation loss decreased (0.073991 --> 0.073987).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0769778\n",
      "\tspeed: 0.0436s/iter; left time: 642.9995s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772953\n",
      "\tspeed: 0.0208s/iter; left time: 304.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0758533 Vali Loss: 0.0739304 Test Loss: 0.0789606\n",
      "Validation loss decreased (0.073987 --> 0.073930).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0746399\n",
      "\tspeed: 0.0455s/iter; left time: 661.3682s\n",
      "\titers: 200, epoch: 36 | loss: 0.0737523\n",
      "\tspeed: 0.0208s/iter; left time: 299.9973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758686 Vali Loss: 0.0739765 Test Loss: 0.0790756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0740244\n",
      "\tspeed: 0.0424s/iter; left time: 605.7217s\n",
      "\titers: 200, epoch: 37 | loss: 0.0774450\n",
      "\tspeed: 0.0207s/iter; left time: 294.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0758347 Vali Loss: 0.0739992 Test Loss: 0.0791410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0760316\n",
      "\tspeed: 0.0423s/iter; left time: 594.7847s\n",
      "\titers: 200, epoch: 38 | loss: 0.0810028\n",
      "\tspeed: 0.0208s/iter; left time: 291.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0758681 Vali Loss: 0.0739593 Test Loss: 0.0791034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0781216\n",
      "\tspeed: 0.0430s/iter; left time: 595.2613s\n",
      "\titers: 200, epoch: 39 | loss: 0.0778835\n",
      "\tspeed: 0.0211s/iter; left time: 289.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0758622 Vali Loss: 0.0739404 Test Loss: 0.0790583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0765964\n",
      "\tspeed: 0.0419s/iter; left time: 570.6301s\n",
      "\titers: 200, epoch: 40 | loss: 0.0763901\n",
      "\tspeed: 0.0208s/iter; left time: 281.6789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0758224 Vali Loss: 0.0739679 Test Loss: 0.0791334\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0790652\n",
      "\tspeed: 0.0421s/iter; left time: 563.5811s\n",
      "\titers: 200, epoch: 41 | loss: 0.0755022\n",
      "\tspeed: 0.0209s/iter; left time: 278.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0757684 Vali Loss: 0.0739002 Test Loss: 0.0790835\n",
      "Validation loss decreased (0.073930 --> 0.073900).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0815259\n",
      "\tspeed: 0.0429s/iter; left time: 565.5794s\n",
      "\titers: 200, epoch: 42 | loss: 0.0795795\n",
      "\tspeed: 0.0208s/iter; left time: 272.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757486 Vali Loss: 0.0739190 Test Loss: 0.0790768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742600\n",
      "\tspeed: 0.0424s/iter; left time: 548.7140s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753905\n",
      "\tspeed: 0.0208s/iter; left time: 267.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0758130 Vali Loss: 0.0739081 Test Loss: 0.0790901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0768929\n",
      "\tspeed: 0.0432s/iter; left time: 549.9354s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757903\n",
      "\tspeed: 0.0212s/iter; left time: 267.8504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0757794 Vali Loss: 0.0738924 Test Loss: 0.0790688\n",
      "Validation loss decreased (0.073900 --> 0.073892).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0742073\n",
      "\tspeed: 0.0453s/iter; left time: 565.6969s\n",
      "\titers: 200, epoch: 45 | loss: 0.0791050\n",
      "\tspeed: 0.0209s/iter; left time: 259.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0756737 Vali Loss: 0.0739171 Test Loss: 0.0791214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0739328\n",
      "\tspeed: 0.0424s/iter; left time: 519.9308s\n",
      "\titers: 200, epoch: 46 | loss: 0.0770414\n",
      "\tspeed: 0.0207s/iter; left time: 252.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757725 Vali Loss: 0.0739116 Test Loss: 0.0790839\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0783244\n",
      "\tspeed: 0.0424s/iter; left time: 511.2184s\n",
      "\titers: 200, epoch: 47 | loss: 0.0803114\n",
      "\tspeed: 0.0207s/iter; left time: 247.8233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757178 Vali Loss: 0.0738894 Test Loss: 0.0791115\n",
      "Validation loss decreased (0.073892 --> 0.073889).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0748944\n",
      "\tspeed: 0.0432s/iter; left time: 510.9230s\n",
      "\titers: 200, epoch: 48 | loss: 0.0788200\n",
      "\tspeed: 0.0208s/iter; left time: 244.0267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0757473 Vali Loss: 0.0738987 Test Loss: 0.0791051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0736010\n",
      "\tspeed: 0.0431s/iter; left time: 500.0674s\n",
      "\titers: 200, epoch: 49 | loss: 0.0762456\n",
      "\tspeed: 0.0207s/iter; left time: 238.5617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0757577 Vali Loss: 0.0738834 Test Loss: 0.0790763\n",
      "Validation loss decreased (0.073889 --> 0.073883).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0700971\n",
      "\tspeed: 0.0430s/iter; left time: 488.8589s\n",
      "\titers: 200, epoch: 50 | loss: 0.0790049\n",
      "\tspeed: 0.0208s/iter; left time: 234.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757238 Vali Loss: 0.0739081 Test Loss: 0.0790725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0741337\n",
      "\tspeed: 0.0434s/iter; left time: 483.5952s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769934\n",
      "\tspeed: 0.0213s/iter; left time: 235.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 225 | Train Loss: 0.0757236 Vali Loss: 0.0738909 Test Loss: 0.0790586\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0763995\n",
      "\tspeed: 0.0427s/iter; left time: 466.1849s\n",
      "\titers: 200, epoch: 52 | loss: 0.0747798\n",
      "\tspeed: 0.0208s/iter; left time: 225.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757349 Vali Loss: 0.0738992 Test Loss: 0.0790633\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0728023\n",
      "\tspeed: 0.0423s/iter; left time: 452.7777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0762027\n",
      "\tspeed: 0.0209s/iter; left time: 221.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756397 Vali Loss: 0.0739138 Test Loss: 0.0791167\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0740082\n",
      "\tspeed: 0.0450s/iter; left time: 471.0190s\n",
      "\titers: 200, epoch: 54 | loss: 0.0776390\n",
      "\tspeed: 0.0218s/iter; left time: 226.0427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 225 | Train Loss: 0.0756919 Vali Loss: 0.0738933 Test Loss: 0.0790710\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0747488\n",
      "\tspeed: 0.0422s/iter; left time: 433.0729s\n",
      "\titers: 200, epoch: 55 | loss: 0.0785796\n",
      "\tspeed: 0.0208s/iter; left time: 211.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757207 Vali Loss: 0.0739212 Test Loss: 0.0790721\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0747373\n",
      "\tspeed: 0.0422s/iter; left time: 423.0414s\n",
      "\titers: 200, epoch: 56 | loss: 0.0743050\n",
      "\tspeed: 0.0208s/iter; left time: 206.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757606 Vali Loss: 0.0739115 Test Loss: 0.0790838\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0753724\n",
      "\tspeed: 0.0423s/iter; left time: 414.1041s\n",
      "\titers: 200, epoch: 57 | loss: 0.0762969\n",
      "\tspeed: 0.0208s/iter; left time: 202.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756882 Vali Loss: 0.0739037 Test Loss: 0.0791009\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0766754\n",
      "\tspeed: 0.0419s/iter; left time: 400.8963s\n",
      "\titers: 200, epoch: 58 | loss: 0.0779277\n",
      "\tspeed: 0.0209s/iter; left time: 198.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0756607 Vali Loss: 0.0738946 Test Loss: 0.0790789\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0737864\n",
      "\tspeed: 0.0425s/iter; left time: 397.3271s\n",
      "\titers: 200, epoch: 59 | loss: 0.0765655\n",
      "\tspeed: 0.0208s/iter; left time: 192.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0757330 Vali Loss: 0.0738989 Test Loss: 0.0790683\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01840369589626789, rmse:0.13566021621227264, mae:0.07907634228467941, rse:0.5129459500312805\n",
      "Intermediate time for IT and pred_len 96: 00h:13m:02.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1675196\n",
      "\tspeed: 0.0455s/iter; left time: 1019.6653s\n",
      "\titers: 200, epoch: 1 | loss: 0.1351112\n",
      "\tspeed: 0.0208s/iter; left time: 464.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 225 | Train Loss: 0.1671171 Vali Loss: 0.1215574 Test Loss: 0.1261611\n",
      "Validation loss decreased (inf --> 0.121557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031348\n",
      "\tspeed: 0.0437s/iter; left time: 969.0172s\n",
      "\titers: 200, epoch: 2 | loss: 0.0999422\n",
      "\tspeed: 0.0220s/iter; left time: 485.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.1065610 Vali Loss: 0.0884258 Test Loss: 0.0920818\n",
      "Validation loss decreased (0.121557 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0900225\n",
      "\tspeed: 0.0428s/iter; left time: 938.9655s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932892\n",
      "\tspeed: 0.0225s/iter; left time: 490.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0926197 Vali Loss: 0.0852258 Test Loss: 0.0879315\n",
      "Validation loss decreased (0.088426 --> 0.085226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0967898\n",
      "\tspeed: 0.0440s/iter; left time: 955.5760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888191\n",
      "\tspeed: 0.0210s/iter; left time: 454.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0894399 Vali Loss: 0.0838193 Test Loss: 0.0868821\n",
      "Validation loss decreased (0.085226 --> 0.083819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0854920\n",
      "\tspeed: 0.0425s/iter; left time: 914.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858616\n",
      "\tspeed: 0.0209s/iter; left time: 446.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0877595 Vali Loss: 0.0828019 Test Loss: 0.0860332\n",
      "Validation loss decreased (0.083819 --> 0.082802).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0848903\n",
      "\tspeed: 0.0431s/iter; left time: 917.5603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884574\n",
      "\tspeed: 0.0213s/iter; left time: 451.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0865596 Vali Loss: 0.0821893 Test Loss: 0.0856452\n",
      "Validation loss decreased (0.082802 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887724\n",
      "\tspeed: 0.0432s/iter; left time: 909.2714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849123\n",
      "\tspeed: 0.0210s/iter; left time: 439.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0856343 Vali Loss: 0.0817578 Test Loss: 0.0851978\n",
      "Validation loss decreased (0.082189 --> 0.081758).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789314\n",
      "\tspeed: 0.0439s/iter; left time: 914.9497s\n",
      "\titers: 200, epoch: 8 | loss: 0.0849873\n",
      "\tspeed: 0.0210s/iter; left time: 435.0862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0849655 Vali Loss: 0.0811689 Test Loss: 0.0848261\n",
      "Validation loss decreased (0.081758 --> 0.081169).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0853073\n",
      "\tspeed: 0.0431s/iter; left time: 887.0343s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846582\n",
      "\tspeed: 0.0215s/iter; left time: 441.0142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0844583 Vali Loss: 0.0811148 Test Loss: 0.0850324\n",
      "Validation loss decreased (0.081169 --> 0.081115).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0830734\n",
      "\tspeed: 0.0443s/iter; left time: 903.2897s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843825\n",
      "\tspeed: 0.0211s/iter; left time: 428.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0839714 Vali Loss: 0.0809264 Test Loss: 0.0847705\n",
      "Validation loss decreased (0.081115 --> 0.080926).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843134\n",
      "\tspeed: 0.0446s/iter; left time: 898.3811s\n",
      "\titers: 200, epoch: 11 | loss: 0.0844380\n",
      "\tspeed: 0.0212s/iter; left time: 424.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0835984 Vali Loss: 0.0808471 Test Loss: 0.0847906\n",
      "Validation loss decreased (0.080926 --> 0.080847).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834019\n",
      "\tspeed: 0.0448s/iter; left time: 892.2764s\n",
      "\titers: 200, epoch: 12 | loss: 0.0831338\n",
      "\tspeed: 0.0216s/iter; left time: 427.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0832907 Vali Loss: 0.0806723 Test Loss: 0.0847298\n",
      "Validation loss decreased (0.080847 --> 0.080672).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0809376\n",
      "\tspeed: 0.0437s/iter; left time: 860.7938s\n",
      "\titers: 200, epoch: 13 | loss: 0.0834955\n",
      "\tspeed: 0.0214s/iter; left time: 419.2213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0829945 Vali Loss: 0.0804892 Test Loss: 0.0845646\n",
      "Validation loss decreased (0.080672 --> 0.080489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0804204\n",
      "\tspeed: 0.0460s/iter; left time: 896.7504s\n",
      "\titers: 200, epoch: 14 | loss: 0.0837203\n",
      "\tspeed: 0.0226s/iter; left time: 437.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0827314 Vali Loss: 0.0807291 Test Loss: 0.0849005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0817830\n",
      "\tspeed: 0.0452s/iter; left time: 870.7303s\n",
      "\titers: 200, epoch: 15 | loss: 0.0796863\n",
      "\tspeed: 0.0223s/iter; left time: 426.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0825446 Vali Loss: 0.0806930 Test Loss: 0.0848130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0841687\n",
      "\tspeed: 0.0451s/iter; left time: 858.3058s\n",
      "\titers: 200, epoch: 16 | loss: 0.0846400\n",
      "\tspeed: 0.0212s/iter; left time: 400.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0823802 Vali Loss: 0.0802775 Test Loss: 0.0843863\n",
      "Validation loss decreased (0.080489 --> 0.080277).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0783478\n",
      "\tspeed: 0.0432s/iter; left time: 812.7774s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813191\n",
      "\tspeed: 0.0215s/iter; left time: 401.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0821796 Vali Loss: 0.0805252 Test Loss: 0.0847103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0785803\n",
      "\tspeed: 0.0444s/iter; left time: 824.1841s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818048\n",
      "\tspeed: 0.0222s/iter; left time: 410.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0820156 Vali Loss: 0.0805238 Test Loss: 0.0847063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800474\n",
      "\tspeed: 0.0458s/iter; left time: 840.6102s\n",
      "\titers: 200, epoch: 19 | loss: 0.0857451\n",
      "\tspeed: 0.0214s/iter; left time: 390.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0818886 Vali Loss: 0.0803709 Test Loss: 0.0845447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0820571\n",
      "\tspeed: 0.0427s/iter; left time: 774.2087s\n",
      "\titers: 200, epoch: 20 | loss: 0.0827842\n",
      "\tspeed: 0.0211s/iter; left time: 379.9213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0817707 Vali Loss: 0.0800992 Test Loss: 0.0843321\n",
      "Validation loss decreased (0.080277 --> 0.080099).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0820213\n",
      "\tspeed: 0.0448s/iter; left time: 801.3819s\n",
      "\titers: 200, epoch: 21 | loss: 0.0828019\n",
      "\tspeed: 0.0214s/iter; left time: 381.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0816757 Vali Loss: 0.0801997 Test Loss: 0.0845056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0833179\n",
      "\tspeed: 0.0437s/iter; left time: 771.6586s\n",
      "\titers: 200, epoch: 22 | loss: 0.0828262\n",
      "\tspeed: 0.0213s/iter; left time: 374.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0816062 Vali Loss: 0.0802053 Test Loss: 0.0843733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830522\n",
      "\tspeed: 0.0426s/iter; left time: 742.5511s\n",
      "\titers: 200, epoch: 23 | loss: 0.0795102\n",
      "\tspeed: 0.0209s/iter; left time: 361.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0814414 Vali Loss: 0.0802630 Test Loss: 0.0844419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0818892\n",
      "\tspeed: 0.0440s/iter; left time: 757.4071s\n",
      "\titers: 200, epoch: 24 | loss: 0.0818965\n",
      "\tspeed: 0.0213s/iter; left time: 365.4885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0813995 Vali Loss: 0.0802461 Test Loss: 0.0845363\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0841812\n",
      "\tspeed: 0.0458s/iter; left time: 779.0422s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822478\n",
      "\tspeed: 0.0225s/iter; left time: 380.5194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 225 | Train Loss: 0.0813018 Vali Loss: 0.0802634 Test Loss: 0.0843812\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0777834\n",
      "\tspeed: 0.0458s/iter; left time: 768.9485s\n",
      "\titers: 200, epoch: 26 | loss: 0.0825829\n",
      "\tspeed: 0.0231s/iter; left time: 385.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0812938 Vali Loss: 0.0803251 Test Loss: 0.0844741\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0830875\n",
      "\tspeed: 0.0447s/iter; left time: 739.8634s\n",
      "\titers: 200, epoch: 27 | loss: 0.0833670\n",
      "\tspeed: 0.0211s/iter; left time: 347.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0812281 Vali Loss: 0.0802615 Test Loss: 0.0844546\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0843309\n",
      "\tspeed: 0.0485s/iter; left time: 791.9854s\n",
      "\titers: 200, epoch: 28 | loss: 0.0831686\n",
      "\tspeed: 0.0210s/iter; left time: 340.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.0811787 Vali Loss: 0.0801265 Test Loss: 0.0844517\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0850645\n",
      "\tspeed: 0.0454s/iter; left time: 730.9687s\n",
      "\titers: 200, epoch: 29 | loss: 0.0777995\n",
      "\tspeed: 0.0213s/iter; left time: 341.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 225 | Train Loss: 0.0811257 Vali Loss: 0.0802395 Test Loss: 0.0844292\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0833312\n",
      "\tspeed: 0.0437s/iter; left time: 694.2218s\n",
      "\titers: 200, epoch: 30 | loss: 0.0835697\n",
      "\tspeed: 0.0210s/iter; left time: 331.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 225 | Train Loss: 0.0810430 Vali Loss: 0.0800870 Test Loss: 0.0843664\n",
      "Validation loss decreased (0.080099 --> 0.080087).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0794675\n",
      "\tspeed: 0.0447s/iter; left time: 698.9395s\n",
      "\titers: 200, epoch: 31 | loss: 0.0752372\n",
      "\tspeed: 0.0214s/iter; left time: 332.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0810523 Vali Loss: 0.0801989 Test Loss: 0.0844223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761456\n",
      "\tspeed: 0.0427s/iter; left time: 658.7947s\n",
      "\titers: 200, epoch: 32 | loss: 0.0814829\n",
      "\tspeed: 0.0209s/iter; left time: 321.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0809560 Vali Loss: 0.0802140 Test Loss: 0.0844132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0846063\n",
      "\tspeed: 0.0426s/iter; left time: 648.2480s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834327\n",
      "\tspeed: 0.0215s/iter; left time: 324.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0809523 Vali Loss: 0.0801794 Test Loss: 0.0844204\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0829760\n",
      "\tspeed: 0.0445s/iter; left time: 665.9268s\n",
      "\titers: 200, epoch: 34 | loss: 0.0789234\n",
      "\tspeed: 0.0211s/iter; left time: 314.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0809624 Vali Loss: 0.0801088 Test Loss: 0.0844282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0787716\n",
      "\tspeed: 0.0434s/iter; left time: 640.1970s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819648\n",
      "\tspeed: 0.0210s/iter; left time: 307.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0809053 Vali Loss: 0.0802213 Test Loss: 0.0844526\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0825160\n",
      "\tspeed: 0.0430s/iter; left time: 624.7136s\n",
      "\titers: 200, epoch: 36 | loss: 0.0825815\n",
      "\tspeed: 0.0236s/iter; left time: 340.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 225 | Train Loss: 0.0809145 Vali Loss: 0.0801888 Test Loss: 0.0844691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0832706\n",
      "\tspeed: 0.0461s/iter; left time: 659.4208s\n",
      "\titers: 200, epoch: 37 | loss: 0.0800724\n",
      "\tspeed: 0.0247s/iter; left time: 350.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 225 | Train Loss: 0.0809248 Vali Loss: 0.0802255 Test Loss: 0.0845230\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829193\n",
      "\tspeed: 0.0446s/iter; left time: 627.5722s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800956\n",
      "\tspeed: 0.0214s/iter; left time: 299.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0808739 Vali Loss: 0.0801478 Test Loss: 0.0844169\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0799479\n",
      "\tspeed: 0.0425s/iter; left time: 588.2335s\n",
      "\titers: 200, epoch: 39 | loss: 0.0808654\n",
      "\tspeed: 0.0212s/iter; left time: 291.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0808252 Vali Loss: 0.0801744 Test Loss: 0.0843554\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0795623\n",
      "\tspeed: 0.0441s/iter; left time: 601.1513s\n",
      "\titers: 200, epoch: 40 | loss: 0.0801233\n",
      "\tspeed: 0.0211s/iter; left time: 285.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0808554 Vali Loss: 0.0801609 Test Loss: 0.0843641\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019854335114359856, rmse:0.14090541005134583, mae:0.0843663439154625, rse:0.5332736968994141\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1652622\n",
      "\tspeed: 0.0232s/iter; left time: 519.1311s\n",
      "\titers: 200, epoch: 1 | loss: 0.1404813\n",
      "\tspeed: 0.0210s/iter; left time: 469.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.1664556 Vali Loss: 0.1211868 Test Loss: 0.1257116\n",
      "Validation loss decreased (inf --> 0.121187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1001732\n",
      "\tspeed: 0.0443s/iter; left time: 981.5909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941014\n",
      "\tspeed: 0.0212s/iter; left time: 467.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.1058553 Vali Loss: 0.0880442 Test Loss: 0.0913735\n",
      "Validation loss decreased (0.121187 --> 0.088044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0931144\n",
      "\tspeed: 0.0447s/iter; left time: 981.7382s\n",
      "\titers: 200, epoch: 3 | loss: 0.0911077\n",
      "\tspeed: 0.0211s/iter; left time: 461.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0923617 Vali Loss: 0.0853995 Test Loss: 0.0880064\n",
      "Validation loss decreased (0.088044 --> 0.085400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853205\n",
      "\tspeed: 0.0446s/iter; left time: 968.7180s\n",
      "\titers: 200, epoch: 4 | loss: 0.0874901\n",
      "\tspeed: 0.0210s/iter; left time: 454.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0895202 Vali Loss: 0.0841055 Test Loss: 0.0870050\n",
      "Validation loss decreased (0.085400 --> 0.084106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884530\n",
      "\tspeed: 0.0443s/iter; left time: 951.4534s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848126\n",
      "\tspeed: 0.0212s/iter; left time: 454.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0878166 Vali Loss: 0.0832510 Test Loss: 0.0864866\n",
      "Validation loss decreased (0.084106 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0878976\n",
      "\tspeed: 0.0458s/iter; left time: 973.4764s\n",
      "\titers: 200, epoch: 6 | loss: 0.0865265\n",
      "\tspeed: 0.0211s/iter; left time: 447.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 225 | Train Loss: 0.0865827 Vali Loss: 0.0824401 Test Loss: 0.0857387\n",
      "Validation loss decreased (0.083251 --> 0.082440).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860272\n",
      "\tspeed: 0.0474s/iter; left time: 998.4010s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851911\n",
      "\tspeed: 0.0226s/iter; left time: 472.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 225 | Train Loss: 0.0856870 Vali Loss: 0.0824135 Test Loss: 0.0859005\n",
      "Validation loss decreased (0.082440 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0836059\n",
      "\tspeed: 0.0474s/iter; left time: 987.9994s\n",
      "\titers: 200, epoch: 8 | loss: 0.0850868\n",
      "\tspeed: 0.0240s/iter; left time: 497.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 225 | Train Loss: 0.0850325 Vali Loss: 0.0819788 Test Loss: 0.0854102\n",
      "Validation loss decreased (0.082414 --> 0.081979).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0825220\n",
      "\tspeed: 0.0448s/iter; left time: 922.1460s\n",
      "\titers: 200, epoch: 9 | loss: 0.0837478\n",
      "\tspeed: 0.0209s/iter; left time: 429.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0845037 Vali Loss: 0.0815998 Test Loss: 0.0851035\n",
      "Validation loss decreased (0.081979 --> 0.081600).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0803746\n",
      "\tspeed: 0.0453s/iter; left time: 923.0652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0891691\n",
      "\tspeed: 0.0210s/iter; left time: 425.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0840277 Vali Loss: 0.0817864 Test Loss: 0.0854826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0864499\n",
      "\tspeed: 0.0432s/iter; left time: 870.8315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0839852\n",
      "\tspeed: 0.0208s/iter; left time: 417.1957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0836376 Vali Loss: 0.0811616 Test Loss: 0.0847526\n",
      "Validation loss decreased (0.081600 --> 0.081162).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767773\n",
      "\tspeed: 0.0456s/iter; left time: 907.7313s\n",
      "\titers: 200, epoch: 12 | loss: 0.0848929\n",
      "\tspeed: 0.0209s/iter; left time: 414.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0832515 Vali Loss: 0.0814082 Test Loss: 0.0850126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802320\n",
      "\tspeed: 0.0440s/iter; left time: 866.5832s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809709\n",
      "\tspeed: 0.0216s/iter; left time: 424.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0829782 Vali Loss: 0.0811389 Test Loss: 0.0850046\n",
      "Validation loss decreased (0.081162 --> 0.081139).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0820090\n",
      "\tspeed: 0.0441s/iter; left time: 858.8439s\n",
      "\titers: 200, epoch: 14 | loss: 0.0813529\n",
      "\tspeed: 0.0212s/iter; left time: 409.8720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0827546 Vali Loss: 0.0811062 Test Loss: 0.0849319\n",
      "Validation loss decreased (0.081139 --> 0.081106).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0848976\n",
      "\tspeed: 0.0447s/iter; left time: 860.7876s\n",
      "\titers: 200, epoch: 15 | loss: 0.0821725\n",
      "\tspeed: 0.0211s/iter; left time: 404.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0825002 Vali Loss: 0.0809575 Test Loss: 0.0847491\n",
      "Validation loss decreased (0.081106 --> 0.080958).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0843849\n",
      "\tspeed: 0.0445s/iter; left time: 846.6210s\n",
      "\titers: 200, epoch: 16 | loss: 0.0846112\n",
      "\tspeed: 0.0211s/iter; left time: 400.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0823768 Vali Loss: 0.0810634 Test Loss: 0.0850165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0804768\n",
      "\tspeed: 0.0445s/iter; left time: 837.5316s\n",
      "\titers: 200, epoch: 17 | loss: 0.0819272\n",
      "\tspeed: 0.0215s/iter; left time: 401.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0821746 Vali Loss: 0.0809309 Test Loss: 0.0847746\n",
      "Validation loss decreased (0.080958 --> 0.080931).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0849409\n",
      "\tspeed: 0.0486s/iter; left time: 902.0315s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796754\n",
      "\tspeed: 0.0231s/iter; left time: 426.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0820180 Vali Loss: 0.0812055 Test Loss: 0.0849243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0853030\n",
      "\tspeed: 0.0452s/iter; left time: 829.6599s\n",
      "\titers: 200, epoch: 19 | loss: 0.0831308\n",
      "\tspeed: 0.0222s/iter; left time: 405.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0819087 Vali Loss: 0.0809420 Test Loss: 0.0848769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0851120\n",
      "\tspeed: 0.0440s/iter; left time: 798.2612s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824348\n",
      "\tspeed: 0.0214s/iter; left time: 385.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0817413 Vali Loss: 0.0807580 Test Loss: 0.0846950\n",
      "Validation loss decreased (0.080931 --> 0.080758).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814391\n",
      "\tspeed: 0.0443s/iter; left time: 793.3440s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771562\n",
      "\tspeed: 0.0210s/iter; left time: 373.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0816750 Vali Loss: 0.0808036 Test Loss: 0.0846861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778086\n",
      "\tspeed: 0.0451s/iter; left time: 797.0586s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811467\n",
      "\tspeed: 0.0215s/iter; left time: 377.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0815788 Vali Loss: 0.0809256 Test Loss: 0.0848525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0824416\n",
      "\tspeed: 0.0441s/iter; left time: 770.0673s\n",
      "\titers: 200, epoch: 23 | loss: 0.0784462\n",
      "\tspeed: 0.0213s/iter; left time: 369.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0814378 Vali Loss: 0.0809654 Test Loss: 0.0849848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0791086\n",
      "\tspeed: 0.0436s/iter; left time: 751.3391s\n",
      "\titers: 200, epoch: 24 | loss: 0.0820934\n",
      "\tspeed: 0.0216s/iter; left time: 370.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0814123 Vali Loss: 0.0806765 Test Loss: 0.0846652\n",
      "Validation loss decreased (0.080758 --> 0.080677).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0811704\n",
      "\tspeed: 0.0457s/iter; left time: 776.4811s\n",
      "\titers: 200, epoch: 25 | loss: 0.0821694\n",
      "\tspeed: 0.0217s/iter; left time: 367.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0813322 Vali Loss: 0.0805845 Test Loss: 0.0845726\n",
      "Validation loss decreased (0.080677 --> 0.080584).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0817250\n",
      "\tspeed: 0.0462s/iter; left time: 774.3704s\n",
      "\titers: 200, epoch: 26 | loss: 0.0778832\n",
      "\tspeed: 0.0218s/iter; left time: 363.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0812857 Vali Loss: 0.0807814 Test Loss: 0.0848495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0824615\n",
      "\tspeed: 0.0433s/iter; left time: 717.2513s\n",
      "\titers: 200, epoch: 27 | loss: 0.0821413\n",
      "\tspeed: 0.0214s/iter; left time: 352.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0812399 Vali Loss: 0.0807473 Test Loss: 0.0846913\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0795153\n",
      "\tspeed: 0.0441s/iter; left time: 720.7613s\n",
      "\titers: 200, epoch: 28 | loss: 0.0785849\n",
      "\tspeed: 0.0215s/iter; left time: 348.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0811807 Vali Loss: 0.0805473 Test Loss: 0.0845542\n",
      "Validation loss decreased (0.080584 --> 0.080547).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777873\n",
      "\tspeed: 0.0468s/iter; left time: 752.7332s\n",
      "\titers: 200, epoch: 29 | loss: 0.0784044\n",
      "\tspeed: 0.0228s/iter; left time: 364.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 225 | Train Loss: 0.0810897 Vali Loss: 0.0807531 Test Loss: 0.0847337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0815641\n",
      "\tspeed: 0.0487s/iter; left time: 773.2801s\n",
      "\titers: 200, epoch: 30 | loss: 0.0812558\n",
      "\tspeed: 0.0239s/iter; left time: 376.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0810745 Vali Loss: 0.0806763 Test Loss: 0.0847119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0809474\n",
      "\tspeed: 0.0474s/iter; left time: 742.0042s\n",
      "\titers: 200, epoch: 31 | loss: 0.0841402\n",
      "\tspeed: 0.0215s/iter; left time: 334.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0810559 Vali Loss: 0.0807105 Test Loss: 0.0848644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0809512\n",
      "\tspeed: 0.0464s/iter; left time: 715.3745s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841629\n",
      "\tspeed: 0.0218s/iter; left time: 333.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0810150 Vali Loss: 0.0805942 Test Loss: 0.0846576\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0792692\n",
      "\tspeed: 0.0456s/iter; left time: 693.1431s\n",
      "\titers: 200, epoch: 33 | loss: 0.0807642\n",
      "\tspeed: 0.0216s/iter; left time: 325.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0809633 Vali Loss: 0.0807331 Test Loss: 0.0847103\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0831877\n",
      "\tspeed: 0.0474s/iter; left time: 709.9593s\n",
      "\titers: 200, epoch: 34 | loss: 0.0842134\n",
      "\tspeed: 0.0216s/iter; left time: 321.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0809410 Vali Loss: 0.0806199 Test Loss: 0.0846308\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0810156\n",
      "\tspeed: 0.0443s/iter; left time: 653.5369s\n",
      "\titers: 200, epoch: 35 | loss: 0.0843082\n",
      "\tspeed: 0.0222s/iter; left time: 325.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0809370 Vali Loss: 0.0806307 Test Loss: 0.0846762\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0791221\n",
      "\tspeed: 0.0443s/iter; left time: 643.9385s\n",
      "\titers: 200, epoch: 36 | loss: 0.0835913\n",
      "\tspeed: 0.0218s/iter; left time: 314.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.0809455 Vali Loss: 0.0806180 Test Loss: 0.0845773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0796506\n",
      "\tspeed: 0.0471s/iter; left time: 673.1462s\n",
      "\titers: 200, epoch: 37 | loss: 0.0805812\n",
      "\tspeed: 0.0217s/iter; left time: 307.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.0809259 Vali Loss: 0.0806551 Test Loss: 0.0846410\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0800527\n",
      "\tspeed: 0.0454s/iter; left time: 638.7925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819848\n",
      "\tspeed: 0.0221s/iter; left time: 309.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 225 | Train Loss: 0.0809210 Vali Loss: 0.0806320 Test Loss: 0.0846083\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019946319982409477, rmse:0.1412314474582672, mae:0.08455415815114975, rse:0.5345075726509094\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:50.21s\n",
      "Intermediate time for IT: 00h:33m:43.72s\n",
      "Total time: 01h:52m:05.01s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/21                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0212  0.1456  0.0882\n",
       "        96            0.0372  0.1928  0.1265\n",
       "        168           0.0408  0.2020  0.1344\n",
       "ES      24            0.0098  0.0991  0.0591\n",
       "        96            0.0191  0.1382  0.0861\n",
       "        168           0.0215  0.1465  0.0927\n",
       "FR      24            0.0100  0.0998  0.0544\n",
       "        96            0.0192  0.1385  0.0789\n",
       "        168           0.0210  0.1450  0.0856\n",
       "GB      24            0.0254  0.1592  0.1001\n",
       "        96            0.0455  0.2133  0.1443\n",
       "        168           0.0486  0.2204  0.1508\n",
       "IT      24            0.0100  0.1000  0.0566\n",
       "        96            0.0183  0.1352  0.0789\n",
       "        168           0.0199  0.1411  0.0845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "#os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "#os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1369714\n",
      "\tspeed: 0.0541s/iter; left time: 1205.4753s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247781\n",
      "\tspeed: 0.0266s/iter; left time: 591.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.1417671 Vali Loss: 0.1297606 Test Loss: 0.1347090\n",
      "Validation loss decreased (inf --> 0.129761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869461\n",
      "\tspeed: 0.0521s/iter; left time: 1150.1137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833711\n",
      "\tspeed: 0.0267s/iter; left time: 587.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0896184 Vali Loss: 0.0936917 Test Loss: 0.0950095\n",
      "Validation loss decreased (0.129761 --> 0.093692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0781575\n",
      "\tspeed: 0.0518s/iter; left time: 1132.7286s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792153\n",
      "\tspeed: 0.0268s/iter; left time: 582.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0797606 Vali Loss: 0.0909321 Test Loss: 0.0923397\n",
      "Validation loss decreased (0.093692 --> 0.090932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807218\n",
      "\tspeed: 0.0511s/iter; left time: 1106.0893s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808649\n",
      "\tspeed: 0.0267s/iter; left time: 574.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0773325 Vali Loss: 0.0890039 Test Loss: 0.0909385\n",
      "Validation loss decreased (0.090932 --> 0.089004).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773130\n",
      "\tspeed: 0.0520s/iter; left time: 1112.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0740610\n",
      "\tspeed: 0.0267s/iter; left time: 569.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0885584 Test Loss: 0.0901798\n",
      "Validation loss decreased (0.089004 --> 0.088558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830306\n",
      "\tspeed: 0.0516s/iter; left time: 1093.4893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726725\n",
      "\tspeed: 0.0267s/iter; left time: 563.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0749306 Vali Loss: 0.0880955 Test Loss: 0.0901085\n",
      "Validation loss decreased (0.088558 --> 0.088095).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732605\n",
      "\tspeed: 0.0517s/iter; left time: 1082.8480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776332\n",
      "\tspeed: 0.0267s/iter; left time: 555.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0740759 Vali Loss: 0.0876682 Test Loss: 0.0896309\n",
      "Validation loss decreased (0.088095 --> 0.087668).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715202\n",
      "\tspeed: 0.0528s/iter; left time: 1093.9648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723670\n",
      "\tspeed: 0.0267s/iter; left time: 550.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0736438 Vali Loss: 0.0882936 Test Loss: 0.0894522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775626\n",
      "\tspeed: 0.0514s/iter; left time: 1054.5261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756080\n",
      "\tspeed: 0.0267s/iter; left time: 545.5887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0733198 Vali Loss: 0.0876187 Test Loss: 0.0892001\n",
      "Validation loss decreased (0.087668 --> 0.087619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0764146\n",
      "\tspeed: 0.0525s/iter; left time: 1064.7971s\n",
      "\titers: 200, epoch: 10 | loss: 0.0708030\n",
      "\tspeed: 0.0265s/iter; left time: 535.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0727986 Vali Loss: 0.0873704 Test Loss: 0.0889288\n",
      "Validation loss decreased (0.087619 --> 0.087370).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678855\n",
      "\tspeed: 0.0522s/iter; left time: 1048.0739s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720052\n",
      "\tspeed: 0.0268s/iter; left time: 534.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0725260 Vali Loss: 0.0871207 Test Loss: 0.0886076\n",
      "Validation loss decreased (0.087370 --> 0.087121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715223\n",
      "\tspeed: 0.0519s/iter; left time: 1030.5229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0742159\n",
      "\tspeed: 0.0266s/iter; left time: 524.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0722907 Vali Loss: 0.0866924 Test Loss: 0.0887910\n",
      "Validation loss decreased (0.087121 --> 0.086692).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0667619\n",
      "\tspeed: 0.0517s/iter; left time: 1013.0115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701735\n",
      "\tspeed: 0.0267s/iter; left time: 520.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0720069 Vali Loss: 0.0869621 Test Loss: 0.0883650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710825\n",
      "\tspeed: 0.0510s/iter; left time: 988.5146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727319\n",
      "\tspeed: 0.0266s/iter; left time: 512.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0718207 Vali Loss: 0.0862084 Test Loss: 0.0881200\n",
      "Validation loss decreased (0.086692 --> 0.086208).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721587\n",
      "\tspeed: 0.0518s/iter; left time: 993.4135s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660384\n",
      "\tspeed: 0.0267s/iter; left time: 509.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0716865 Vali Loss: 0.0862676 Test Loss: 0.0882083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0726189\n",
      "\tspeed: 0.0513s/iter; left time: 971.7333s\n",
      "\titers: 200, epoch: 16 | loss: 0.0699743\n",
      "\tspeed: 0.0266s/iter; left time: 500.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0715561 Vali Loss: 0.0862403 Test Loss: 0.0882708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734295\n",
      "\tspeed: 0.0508s/iter; left time: 950.7064s\n",
      "\titers: 200, epoch: 17 | loss: 0.0729700\n",
      "\tspeed: 0.0269s/iter; left time: 499.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0714500 Vali Loss: 0.0860131 Test Loss: 0.0878391\n",
      "Validation loss decreased (0.086208 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720860\n",
      "\tspeed: 0.0510s/iter; left time: 943.6124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807038\n",
      "\tspeed: 0.0285s/iter; left time: 524.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0712926 Vali Loss: 0.0858605 Test Loss: 0.0881299\n",
      "Validation loss decreased (0.086013 --> 0.085860).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0672827\n",
      "\tspeed: 0.0521s/iter; left time: 952.6361s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683527\n",
      "\tspeed: 0.0268s/iter; left time: 486.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0712880 Vali Loss: 0.0860396 Test Loss: 0.0881207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685089\n",
      "\tspeed: 0.0512s/iter; left time: 924.0535s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723603\n",
      "\tspeed: 0.0266s/iter; left time: 477.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0711309 Vali Loss: 0.0858991 Test Loss: 0.0879555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0669795\n",
      "\tspeed: 0.0510s/iter; left time: 908.4794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729611\n",
      "\tspeed: 0.0266s/iter; left time: 471.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0710612 Vali Loss: 0.0858557 Test Loss: 0.0878603\n",
      "Validation loss decreased (0.085860 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0644646\n",
      "\tspeed: 0.0516s/iter; left time: 908.2609s\n",
      "\titers: 200, epoch: 22 | loss: 0.0674015\n",
      "\tspeed: 0.0267s/iter; left time: 466.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0709746 Vali Loss: 0.0858742 Test Loss: 0.0879468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0715065\n",
      "\tspeed: 0.0506s/iter; left time: 878.9808s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664888\n",
      "\tspeed: 0.0266s/iter; left time: 459.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0708909 Vali Loss: 0.0858572 Test Loss: 0.0878468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697132\n",
      "\tspeed: 0.0514s/iter; left time: 881.7388s\n",
      "\titers: 200, epoch: 24 | loss: 0.0695731\n",
      "\tspeed: 0.0265s/iter; left time: 451.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0709061 Vali Loss: 0.0856822 Test Loss: 0.0878505\n",
      "Validation loss decreased (0.085856 --> 0.085682).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0698776\n",
      "\tspeed: 0.0509s/iter; left time: 862.2074s\n",
      "\titers: 200, epoch: 25 | loss: 0.0794153\n",
      "\tspeed: 0.0264s/iter; left time: 444.6524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0708391 Vali Loss: 0.0857899 Test Loss: 0.0877605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0693570\n",
      "\tspeed: 0.0507s/iter; left time: 847.0964s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686728\n",
      "\tspeed: 0.0267s/iter; left time: 442.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708132 Vali Loss: 0.0856289 Test Loss: 0.0876225\n",
      "Validation loss decreased (0.085682 --> 0.085629).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736588\n",
      "\tspeed: 0.0522s/iter; left time: 859.5258s\n",
      "\titers: 200, epoch: 27 | loss: 0.0751999\n",
      "\tspeed: 0.0266s/iter; left time: 435.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0706946 Vali Loss: 0.0857887 Test Loss: 0.0877622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681836\n",
      "\tspeed: 0.0513s/iter; left time: 834.2176s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738424\n",
      "\tspeed: 0.0267s/iter; left time: 430.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0707199 Vali Loss: 0.0856799 Test Loss: 0.0876857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0720591\n",
      "\tspeed: 0.0512s/iter; left time: 820.0638s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661264\n",
      "\tspeed: 0.0267s/iter; left time: 425.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0706302 Vali Loss: 0.0856200 Test Loss: 0.0876701\n",
      "Validation loss decreased (0.085629 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0764758\n",
      "\tspeed: 0.0525s/iter; left time: 829.9523s\n",
      "\titers: 200, epoch: 30 | loss: 0.0717371\n",
      "\tspeed: 0.0265s/iter; left time: 415.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0705703 Vali Loss: 0.0856172 Test Loss: 0.0877889\n",
      "Validation loss decreased (0.085620 --> 0.085617).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0694562\n",
      "\tspeed: 0.0528s/iter; left time: 823.0867s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669540\n",
      "\tspeed: 0.0271s/iter; left time: 420.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0705669 Vali Loss: 0.0855405 Test Loss: 0.0876212\n",
      "Validation loss decreased (0.085617 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648792\n",
      "\tspeed: 0.0519s/iter; left time: 796.4069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0739037\n",
      "\tspeed: 0.0265s/iter; left time: 403.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0705570 Vali Loss: 0.0856224 Test Loss: 0.0876501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760883\n",
      "\tspeed: 0.0509s/iter; left time: 769.5590s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659316\n",
      "\tspeed: 0.0264s/iter; left time: 397.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0705282 Vali Loss: 0.0856680 Test Loss: 0.0876398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700403\n",
      "\tspeed: 0.0509s/iter; left time: 758.6267s\n",
      "\titers: 200, epoch: 34 | loss: 0.0733599\n",
      "\tspeed: 0.0265s/iter; left time: 392.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0705505 Vali Loss: 0.0856534 Test Loss: 0.0876419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0716821\n",
      "\tspeed: 0.0509s/iter; left time: 747.2629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0660121\n",
      "\tspeed: 0.0267s/iter; left time: 389.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0704936 Vali Loss: 0.0856017 Test Loss: 0.0876743\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702281\n",
      "\tspeed: 0.0520s/iter; left time: 751.7426s\n",
      "\titers: 200, epoch: 36 | loss: 0.0758533\n",
      "\tspeed: 0.0268s/iter; left time: 385.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704848 Vali Loss: 0.0856520 Test Loss: 0.0876421\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0775575\n",
      "\tspeed: 0.0516s/iter; left time: 734.5360s\n",
      "\titers: 200, epoch: 37 | loss: 0.0730687\n",
      "\tspeed: 0.0267s/iter; left time: 377.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0705037 Vali Loss: 0.0856726 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0694183\n",
      "\tspeed: 0.0517s/iter; left time: 724.0252s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666340\n",
      "\tspeed: 0.0268s/iter; left time: 372.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704922 Vali Loss: 0.0855943 Test Loss: 0.0876738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0741279\n",
      "\tspeed: 0.0517s/iter; left time: 713.1725s\n",
      "\titers: 200, epoch: 39 | loss: 0.0680151\n",
      "\tspeed: 0.0268s/iter; left time: 366.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704478 Vali Loss: 0.0855522 Test Loss: 0.0876500\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0680514\n",
      "\tspeed: 0.0510s/iter; left time: 691.1667s\n",
      "\titers: 200, epoch: 40 | loss: 0.0764029\n",
      "\tspeed: 0.0265s/iter; left time: 356.5305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704099 Vali Loss: 0.0856432 Test Loss: 0.0876450\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0655310\n",
      "\tspeed: 0.0508s/iter; left time: 677.2596s\n",
      "\titers: 200, epoch: 41 | loss: 0.0691073\n",
      "\tspeed: 0.0268s/iter; left time: 355.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703985 Vali Loss: 0.0854845 Test Loss: 0.0875877\n",
      "Validation loss decreased (0.085541 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682409\n",
      "\tspeed: 0.0513s/iter; left time: 672.5361s\n",
      "\titers: 200, epoch: 42 | loss: 0.0763331\n",
      "\tspeed: 0.0265s/iter; left time: 345.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0704444 Vali Loss: 0.0856361 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755680\n",
      "\tspeed: 0.0513s/iter; left time: 661.0572s\n",
      "\titers: 200, epoch: 43 | loss: 0.0719940\n",
      "\tspeed: 0.0265s/iter; left time: 339.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704495 Vali Loss: 0.0855508 Test Loss: 0.0876172\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644201\n",
      "\tspeed: 0.0509s/iter; left time: 645.4822s\n",
      "\titers: 200, epoch: 44 | loss: 0.0712258\n",
      "\tspeed: 0.0265s/iter; left time: 333.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704013 Vali Loss: 0.0855588 Test Loss: 0.0876322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0704731\n",
      "\tspeed: 0.0520s/iter; left time: 647.4943s\n",
      "\titers: 200, epoch: 45 | loss: 0.0729366\n",
      "\tspeed: 0.0265s/iter; left time: 327.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703918 Vali Loss: 0.0855635 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0704228\n",
      "\tspeed: 0.0513s/iter; left time: 627.0158s\n",
      "\titers: 200, epoch: 46 | loss: 0.0755504\n",
      "\tspeed: 0.0266s/iter; left time: 323.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703368 Vali Loss: 0.0855913 Test Loss: 0.0876351\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0714861\n",
      "\tspeed: 0.0527s/iter; left time: 632.7437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0703084\n",
      "\tspeed: 0.0270s/iter; left time: 321.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0703858 Vali Loss: 0.0855839 Test Loss: 0.0876863\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0716547\n",
      "\tspeed: 0.0512s/iter; left time: 603.1520s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697001\n",
      "\tspeed: 0.0269s/iter; left time: 314.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703595 Vali Loss: 0.0855201 Test Loss: 0.0876336\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0721770\n",
      "\tspeed: 0.0514s/iter; left time: 593.2863s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752482\n",
      "\tspeed: 0.0269s/iter; left time: 308.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703970 Vali Loss: 0.0854210 Test Loss: 0.0876339\n",
      "Validation loss decreased (0.085485 --> 0.085421).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0676463\n",
      "\tspeed: 0.0513s/iter; left time: 580.5348s\n",
      "\titers: 200, epoch: 50 | loss: 0.0677730\n",
      "\tspeed: 0.0265s/iter; left time: 297.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703362 Vali Loss: 0.0856355 Test Loss: 0.0876200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0666008\n",
      "\tspeed: 0.0516s/iter; left time: 573.0979s\n",
      "\titers: 200, epoch: 51 | loss: 0.0702993\n",
      "\tspeed: 0.0268s/iter; left time: 294.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0703573 Vali Loss: 0.0855665 Test Loss: 0.0876208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0723010\n",
      "\tspeed: 0.0510s/iter; left time: 555.1316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758060\n",
      "\tspeed: 0.0265s/iter; left time: 285.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703259 Vali Loss: 0.0854868 Test Loss: 0.0876280\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0706884\n",
      "\tspeed: 0.0514s/iter; left time: 547.3564s\n",
      "\titers: 200, epoch: 53 | loss: 0.0751953\n",
      "\tspeed: 0.0265s/iter; left time: 280.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703530 Vali Loss: 0.0855637 Test Loss: 0.0876266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0702771\n",
      "\tspeed: 0.0513s/iter; left time: 535.4939s\n",
      "\titers: 200, epoch: 54 | loss: 0.0684877\n",
      "\tspeed: 0.0268s/iter; left time: 277.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703710 Vali Loss: 0.0855449 Test Loss: 0.0876197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688983\n",
      "\tspeed: 0.0514s/iter; left time: 524.3484s\n",
      "\titers: 200, epoch: 55 | loss: 0.0738532\n",
      "\tspeed: 0.0269s/iter; left time: 271.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703545 Vali Loss: 0.0854906 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0730539\n",
      "\tspeed: 0.0526s/iter; left time: 525.1879s\n",
      "\titers: 200, epoch: 56 | loss: 0.0674224\n",
      "\tspeed: 0.0266s/iter; left time: 263.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704173 Vali Loss: 0.0854536 Test Loss: 0.0876250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0707048\n",
      "\tspeed: 0.0513s/iter; left time: 500.7753s\n",
      "\titers: 200, epoch: 57 | loss: 0.0710349\n",
      "\tspeed: 0.0265s/iter; left time: 255.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703584 Vali Loss: 0.0855452 Test Loss: 0.0876381\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736169\n",
      "\tspeed: 0.0504s/iter; left time: 480.1522s\n",
      "\titers: 200, epoch: 58 | loss: 0.0741034\n",
      "\tspeed: 0.0266s/iter; left time: 250.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703132 Vali Loss: 0.0855490 Test Loss: 0.0876148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0710790\n",
      "\tspeed: 0.0514s/iter; left time: 478.3326s\n",
      "\titers: 200, epoch: 59 | loss: 0.0729701\n",
      "\tspeed: 0.0269s/iter; left time: 247.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703250 Vali Loss: 0.0855128 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020939357578754425, rmse:0.14470438659191132, mae:0.08763387054204941, rse:0.5106817483901978\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1389406\n",
      "\tspeed: 0.0286s/iter; left time: 637.3228s\n",
      "\titers: 200, epoch: 1 | loss: 0.1228134\n",
      "\tspeed: 0.0266s/iter; left time: 590.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1422911 Vali Loss: 0.1295809 Test Loss: 0.1351006\n",
      "Validation loss decreased (inf --> 0.129581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877811\n",
      "\tspeed: 0.0524s/iter; left time: 1157.5606s\n",
      "\titers: 200, epoch: 2 | loss: 0.0832211\n",
      "\tspeed: 0.0267s/iter; left time: 585.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0894358 Vali Loss: 0.0936241 Test Loss: 0.0940987\n",
      "Validation loss decreased (0.129581 --> 0.093624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775893\n",
      "\tspeed: 0.0529s/iter; left time: 1155.7753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735417\n",
      "\tspeed: 0.0268s/iter; left time: 582.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0796590 Vali Loss: 0.0902558 Test Loss: 0.0915840\n",
      "Validation loss decreased (0.093624 --> 0.090256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0772389\n",
      "\tspeed: 0.0535s/iter; left time: 1157.4906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764423\n",
      "\tspeed: 0.0267s/iter; left time: 575.2471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0774734 Vali Loss: 0.0893443 Test Loss: 0.0907840\n",
      "Validation loss decreased (0.090256 --> 0.089344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743019\n",
      "\tspeed: 0.0524s/iter; left time: 1122.3344s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750691\n",
      "\tspeed: 0.0266s/iter; left time: 566.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0761713 Vali Loss: 0.0888839 Test Loss: 0.0900800\n",
      "Validation loss decreased (0.089344 --> 0.088884).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0693859\n",
      "\tspeed: 0.0531s/iter; left time: 1125.5393s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754470\n",
      "\tspeed: 0.0268s/iter; left time: 564.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0751449 Vali Loss: 0.0878856 Test Loss: 0.0899183\n",
      "Validation loss decreased (0.088884 --> 0.087886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723351\n",
      "\tspeed: 0.0524s/iter; left time: 1098.0215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741934\n",
      "\tspeed: 0.0266s/iter; left time: 553.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0744148 Vali Loss: 0.0882161 Test Loss: 0.0896968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743478\n",
      "\tspeed: 0.0515s/iter; left time: 1067.8407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734460\n",
      "\tspeed: 0.0266s/iter; left time: 547.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0738465 Vali Loss: 0.0875170 Test Loss: 0.0890645\n",
      "Validation loss decreased (0.087886 --> 0.087517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690735\n",
      "\tspeed: 0.0529s/iter; left time: 1085.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759658\n",
      "\tspeed: 0.0267s/iter; left time: 545.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0733618 Vali Loss: 0.0870617 Test Loss: 0.0888512\n",
      "Validation loss decreased (0.087517 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763888\n",
      "\tspeed: 0.0540s/iter; left time: 1095.9059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748855\n",
      "\tspeed: 0.0267s/iter; left time: 538.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0729996 Vali Loss: 0.0868114 Test Loss: 0.0887925\n",
      "Validation loss decreased (0.087062 --> 0.086811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753090\n",
      "\tspeed: 0.0522s/iter; left time: 1047.6334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728513\n",
      "\tspeed: 0.0265s/iter; left time: 528.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0726921 Vali Loss: 0.0872061 Test Loss: 0.0885696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705457\n",
      "\tspeed: 0.0520s/iter; left time: 1031.3150s\n",
      "\titers: 200, epoch: 12 | loss: 0.0726305\n",
      "\tspeed: 0.0265s/iter; left time: 523.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723711 Vali Loss: 0.0864833 Test Loss: 0.0882598\n",
      "Validation loss decreased (0.086811 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700529\n",
      "\tspeed: 0.0524s/iter; left time: 1027.1079s\n",
      "\titers: 200, epoch: 13 | loss: 0.0684496\n",
      "\tspeed: 0.0267s/iter; left time: 520.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0721546 Vali Loss: 0.0865951 Test Loss: 0.0883359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748019\n",
      "\tspeed: 0.0529s/iter; left time: 1024.8560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713811\n",
      "\tspeed: 0.0270s/iter; left time: 520.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0719527 Vali Loss: 0.0866737 Test Loss: 0.0880236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713503\n",
      "\tspeed: 0.0521s/iter; left time: 999.2792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763744\n",
      "\tspeed: 0.0266s/iter; left time: 506.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0716899 Vali Loss: 0.0864420 Test Loss: 0.0880862\n",
      "Validation loss decreased (0.086483 --> 0.086442).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746533\n",
      "\tspeed: 0.0524s/iter; left time: 992.8871s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665798\n",
      "\tspeed: 0.0265s/iter; left time: 499.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0715671 Vali Loss: 0.0860693 Test Loss: 0.0879256\n",
      "Validation loss decreased (0.086442 --> 0.086069).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704673\n",
      "\tspeed: 0.0527s/iter; left time: 987.2801s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683351\n",
      "\tspeed: 0.0268s/iter; left time: 498.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0714092 Vali Loss: 0.0860398 Test Loss: 0.0881202\n",
      "Validation loss decreased (0.086069 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692278\n",
      "\tspeed: 0.0532s/iter; left time: 984.5075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706096\n",
      "\tspeed: 0.0265s/iter; left time: 487.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0713103 Vali Loss: 0.0860568 Test Loss: 0.0880662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711174\n",
      "\tspeed: 0.0527s/iter; left time: 963.1993s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707833\n",
      "\tspeed: 0.0265s/iter; left time: 480.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0711834 Vali Loss: 0.0858907 Test Loss: 0.0879579\n",
      "Validation loss decreased (0.086040 --> 0.085891).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700932\n",
      "\tspeed: 0.0527s/iter; left time: 951.2086s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701582\n",
      "\tspeed: 0.0268s/iter; left time: 480.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0710876 Vali Loss: 0.0862701 Test Loss: 0.0880781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699507\n",
      "\tspeed: 0.0528s/iter; left time: 940.8659s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683075\n",
      "\tspeed: 0.0267s/iter; left time: 473.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0710427 Vali Loss: 0.0861612 Test Loss: 0.0881739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0751726\n",
      "\tspeed: 0.0519s/iter; left time: 912.4235s\n",
      "\titers: 200, epoch: 22 | loss: 0.0686039\n",
      "\tspeed: 0.0265s/iter; left time: 464.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0709314 Vali Loss: 0.0859297 Test Loss: 0.0879431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740635\n",
      "\tspeed: 0.0530s/iter; left time: 920.0264s\n",
      "\titers: 200, epoch: 23 | loss: 0.0754669\n",
      "\tspeed: 0.0267s/iter; left time: 460.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0708511 Vali Loss: 0.0858247 Test Loss: 0.0877661\n",
      "Validation loss decreased (0.085891 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0669902\n",
      "\tspeed: 0.0531s/iter; left time: 911.2386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0699968\n",
      "\tspeed: 0.0264s/iter; left time: 450.4041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708038 Vali Loss: 0.0857948 Test Loss: 0.0880593\n",
      "Validation loss decreased (0.085825 --> 0.085795).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0710267\n",
      "\tspeed: 0.0519s/iter; left time: 878.6579s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701005\n",
      "\tspeed: 0.0265s/iter; left time: 445.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0707550 Vali Loss: 0.0858620 Test Loss: 0.0879302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0675721\n",
      "\tspeed: 0.0519s/iter; left time: 866.8273s\n",
      "\titers: 200, epoch: 26 | loss: 0.0723306\n",
      "\tspeed: 0.0266s/iter; left time: 441.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0707452 Vali Loss: 0.0857506 Test Loss: 0.0878565\n",
      "Validation loss decreased (0.085795 --> 0.085751).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725780\n",
      "\tspeed: 0.0528s/iter; left time: 869.7247s\n",
      "\titers: 200, epoch: 27 | loss: 0.0715543\n",
      "\tspeed: 0.0268s/iter; left time: 438.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0706913 Vali Loss: 0.0857717 Test Loss: 0.0878863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0656819\n",
      "\tspeed: 0.0536s/iter; left time: 870.6048s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728222\n",
      "\tspeed: 0.0269s/iter; left time: 434.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0706028 Vali Loss: 0.0855976 Test Loss: 0.0878353\n",
      "Validation loss decreased (0.085751 --> 0.085598).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716999\n",
      "\tspeed: 0.0531s/iter; left time: 850.3424s\n",
      "\titers: 200, epoch: 29 | loss: 0.0711410\n",
      "\tspeed: 0.0265s/iter; left time: 422.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0705973 Vali Loss: 0.0859616 Test Loss: 0.0878585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0745615\n",
      "\tspeed: 0.0523s/iter; left time: 827.2763s\n",
      "\titers: 200, epoch: 30 | loss: 0.0758140\n",
      "\tspeed: 0.0269s/iter; left time: 422.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705595 Vali Loss: 0.0856872 Test Loss: 0.0878131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0744614\n",
      "\tspeed: 0.0525s/iter; left time: 818.0931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0705624\n",
      "\tspeed: 0.0267s/iter; left time: 414.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705045 Vali Loss: 0.0857018 Test Loss: 0.0878923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0687968\n",
      "\tspeed: 0.0528s/iter; left time: 810.4927s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645319\n",
      "\tspeed: 0.0267s/iter; left time: 406.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0705371 Vali Loss: 0.0856552 Test Loss: 0.0878005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0692253\n",
      "\tspeed: 0.0522s/iter; left time: 790.4230s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719842\n",
      "\tspeed: 0.0267s/iter; left time: 401.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0704541 Vali Loss: 0.0857210 Test Loss: 0.0878580\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0711537\n",
      "\tspeed: 0.0519s/iter; left time: 773.8731s\n",
      "\titers: 200, epoch: 34 | loss: 0.0700859\n",
      "\tspeed: 0.0267s/iter; left time: 395.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704086 Vali Loss: 0.0857385 Test Loss: 0.0877898\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0727249\n",
      "\tspeed: 0.0525s/iter; left time: 771.6492s\n",
      "\titers: 200, epoch: 35 | loss: 0.0703164\n",
      "\tspeed: 0.0265s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0704289 Vali Loss: 0.0856548 Test Loss: 0.0878404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0692909\n",
      "\tspeed: 0.0518s/iter; left time: 749.3944s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745890\n",
      "\tspeed: 0.0265s/iter; left time: 380.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704170 Vali Loss: 0.0855795 Test Loss: 0.0877761\n",
      "Validation loss decreased (0.085598 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669411\n",
      "\tspeed: 0.0523s/iter; left time: 743.9817s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717780\n",
      "\tspeed: 0.0265s/iter; left time: 374.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703451 Vali Loss: 0.0857678 Test Loss: 0.0877872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0692922\n",
      "\tspeed: 0.0523s/iter; left time: 732.2128s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706012\n",
      "\tspeed: 0.0274s/iter; left time: 381.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0703509 Vali Loss: 0.0856808 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0644956\n",
      "\tspeed: 0.0523s/iter; left time: 721.3358s\n",
      "\titers: 200, epoch: 39 | loss: 0.0683517\n",
      "\tspeed: 0.0265s/iter; left time: 362.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0703036 Vali Loss: 0.0857069 Test Loss: 0.0877940\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712174\n",
      "\tspeed: 0.0528s/iter; left time: 716.0116s\n",
      "\titers: 200, epoch: 40 | loss: 0.0717972\n",
      "\tspeed: 0.0266s/iter; left time: 357.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703386 Vali Loss: 0.0855974 Test Loss: 0.0877805\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0709783\n",
      "\tspeed: 0.0521s/iter; left time: 694.8751s\n",
      "\titers: 200, epoch: 41 | loss: 0.0727384\n",
      "\tspeed: 0.0267s/iter; left time: 353.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703057 Vali Loss: 0.0855847 Test Loss: 0.0877485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0696685\n",
      "\tspeed: 0.0521s/iter; left time: 684.0514s\n",
      "\titers: 200, epoch: 42 | loss: 0.0708702\n",
      "\tspeed: 0.0266s/iter; left time: 345.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0702815 Vali Loss: 0.0856937 Test Loss: 0.0877606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755521\n",
      "\tspeed: 0.0524s/iter; left time: 675.6540s\n",
      "\titers: 200, epoch: 43 | loss: 0.0711717\n",
      "\tspeed: 0.0266s/iter; left time: 340.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0703419 Vali Loss: 0.0854786 Test Loss: 0.0877750\n",
      "Validation loss decreased (0.085579 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0711064\n",
      "\tspeed: 0.0524s/iter; left time: 664.3796s\n",
      "\titers: 200, epoch: 44 | loss: 0.0720553\n",
      "\tspeed: 0.0267s/iter; left time: 335.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703236 Vali Loss: 0.0856422 Test Loss: 0.0877193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0685135\n",
      "\tspeed: 0.0518s/iter; left time: 645.1912s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710313\n",
      "\tspeed: 0.0270s/iter; left time: 333.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703195 Vali Loss: 0.0855412 Test Loss: 0.0877509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0682689\n",
      "\tspeed: 0.0519s/iter; left time: 634.1017s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663539\n",
      "\tspeed: 0.0265s/iter; left time: 321.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702857 Vali Loss: 0.0856832 Test Loss: 0.0877343\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0781750\n",
      "\tspeed: 0.0532s/iter; left time: 637.8936s\n",
      "\titers: 200, epoch: 47 | loss: 0.0668642\n",
      "\tspeed: 0.0267s/iter; left time: 317.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0703067 Vali Loss: 0.0856037 Test Loss: 0.0877680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0757289\n",
      "\tspeed: 0.0527s/iter; left time: 620.0069s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714607\n",
      "\tspeed: 0.0265s/iter; left time: 309.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703030 Vali Loss: 0.0855959 Test Loss: 0.0877536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0738765\n",
      "\tspeed: 0.0524s/iter; left time: 605.3152s\n",
      "\titers: 200, epoch: 49 | loss: 0.0682928\n",
      "\tspeed: 0.0268s/iter; left time: 306.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703193 Vali Loss: 0.0856737 Test Loss: 0.0877642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0721883\n",
      "\tspeed: 0.0523s/iter; left time: 592.4528s\n",
      "\titers: 200, epoch: 50 | loss: 0.0696596\n",
      "\tspeed: 0.0266s/iter; left time: 298.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0702247 Vali Loss: 0.0856217 Test Loss: 0.0877349\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0724216\n",
      "\tspeed: 0.0521s/iter; left time: 578.8286s\n",
      "\titers: 200, epoch: 51 | loss: 0.0683385\n",
      "\tspeed: 0.0264s/iter; left time: 290.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0702224 Vali Loss: 0.0856550 Test Loss: 0.0877666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707191\n",
      "\tspeed: 0.0517s/iter; left time: 562.1389s\n",
      "\titers: 200, epoch: 52 | loss: 0.0697485\n",
      "\tspeed: 0.0265s/iter; left time: 285.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702648 Vali Loss: 0.0856051 Test Loss: 0.0877736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0723032\n",
      "\tspeed: 0.0528s/iter; left time: 562.8959s\n",
      "\titers: 200, epoch: 53 | loss: 0.0695717\n",
      "\tspeed: 0.0266s/iter; left time: 280.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0702753 Vali Loss: 0.0856733 Test Loss: 0.0877745\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020994756370782852, rmse:0.14489567279815674, mae:0.08777499943971634, rse:0.5113568902015686\n",
      "Intermediate time for DE and pred_len 24: 00h:14m:50.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487391\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1487s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375452\n",
      "\tspeed: 0.0269s/iter; left time: 598.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.1484455 Vali Loss: 0.1405499 Test Loss: 0.1490060\n",
      "Validation loss decreased (inf --> 0.140550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1194897\n",
      "\tspeed: 0.0533s/iter; left time: 1176.9588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064227\n",
      "\tspeed: 0.0268s/iter; left time: 588.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1145359 Vali Loss: 0.1213630 Test Loss: 0.1295630\n",
      "Validation loss decreased (0.140550 --> 0.121363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036745\n",
      "\tspeed: 0.0540s/iter; left time: 1179.6751s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068880\n",
      "\tspeed: 0.0268s/iter; left time: 583.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1064633 Vali Loss: 0.1195266 Test Loss: 0.1282235\n",
      "Validation loss decreased (0.121363 --> 0.119527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1044791\n",
      "\tspeed: 0.0537s/iter; left time: 1160.7622s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004268\n",
      "\tspeed: 0.0269s/iter; left time: 579.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1045039 Vali Loss: 0.1190653 Test Loss: 0.1280503\n",
      "Validation loss decreased (0.119527 --> 0.119065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030031\n",
      "\tspeed: 0.0531s/iter; left time: 1137.1471s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965900\n",
      "\tspeed: 0.0268s/iter; left time: 570.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1033400 Vali Loss: 0.1186632 Test Loss: 0.1276050\n",
      "Validation loss decreased (0.119065 --> 0.118663).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1102587\n",
      "\tspeed: 0.0538s/iter; left time: 1140.5733s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076527\n",
      "\tspeed: 0.0269s/iter; left time: 567.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1024590 Vali Loss: 0.1179634 Test Loss: 0.1265461\n",
      "Validation loss decreased (0.118663 --> 0.117963).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025728\n",
      "\tspeed: 0.0538s/iter; left time: 1126.7627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953970\n",
      "\tspeed: 0.0269s/iter; left time: 560.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1016823 Vali Loss: 0.1186003 Test Loss: 0.1277381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998731\n",
      "\tspeed: 0.0539s/iter; left time: 1116.5655s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977558\n",
      "\tspeed: 0.0267s/iter; left time: 551.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1010973 Vali Loss: 0.1182861 Test Loss: 0.1272469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0999197\n",
      "\tspeed: 0.0532s/iter; left time: 1090.9066s\n",
      "\titers: 200, epoch: 9 | loss: 0.1026386\n",
      "\tspeed: 0.0268s/iter; left time: 546.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1004929 Vali Loss: 0.1175796 Test Loss: 0.1266904\n",
      "Validation loss decreased (0.117963 --> 0.117580).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008377\n",
      "\tspeed: 0.0538s/iter; left time: 1091.6922s\n",
      "\titers: 200, epoch: 10 | loss: 0.0974689\n",
      "\tspeed: 0.0268s/iter; left time: 541.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1000229 Vali Loss: 0.1174014 Test Loss: 0.1273050\n",
      "Validation loss decreased (0.117580 --> 0.117401).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0975121\n",
      "\tspeed: 0.0536s/iter; left time: 1074.5040s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031677\n",
      "\tspeed: 0.0268s/iter; left time: 534.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0996410 Vali Loss: 0.1172269 Test Loss: 0.1274734\n",
      "Validation loss decreased (0.117401 --> 0.117227).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019047\n",
      "\tspeed: 0.0535s/iter; left time: 1062.0590s\n",
      "\titers: 200, epoch: 12 | loss: 0.0963887\n",
      "\tspeed: 0.0268s/iter; left time: 528.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0992125 Vali Loss: 0.1170878 Test Loss: 0.1278752\n",
      "Validation loss decreased (0.117227 --> 0.117088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961119\n",
      "\tspeed: 0.0544s/iter; left time: 1066.5978s\n",
      "\titers: 200, epoch: 13 | loss: 0.0989636\n",
      "\tspeed: 0.0268s/iter; left time: 523.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0988020 Vali Loss: 0.1168609 Test Loss: 0.1279964\n",
      "Validation loss decreased (0.117088 --> 0.116861).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0999261\n",
      "\tspeed: 0.0537s/iter; left time: 1040.9073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937633\n",
      "\tspeed: 0.0269s/iter; left time: 517.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0984957 Vali Loss: 0.1170542 Test Loss: 0.1275455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0966726\n",
      "\tspeed: 0.0539s/iter; left time: 1033.5501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981507\n",
      "\tspeed: 0.0270s/iter; left time: 515.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0981710 Vali Loss: 0.1166702 Test Loss: 0.1279635\n",
      "Validation loss decreased (0.116861 --> 0.116670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1011894\n",
      "\tspeed: 0.0547s/iter; left time: 1036.4337s\n",
      "\titers: 200, epoch: 16 | loss: 0.1026321\n",
      "\tspeed: 0.0271s/iter; left time: 510.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0978653 Vali Loss: 0.1167809 Test Loss: 0.1274564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973510\n",
      "\tspeed: 0.0535s/iter; left time: 1000.7220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0980666\n",
      "\tspeed: 0.0269s/iter; left time: 501.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0976454 Vali Loss: 0.1168894 Test Loss: 0.1274555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0964897\n",
      "\tspeed: 0.0535s/iter; left time: 989.2355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0915851\n",
      "\tspeed: 0.0269s/iter; left time: 494.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0973645 Vali Loss: 0.1169818 Test Loss: 0.1278145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0937841\n",
      "\tspeed: 0.0539s/iter; left time: 984.7285s\n",
      "\titers: 200, epoch: 19 | loss: 0.0945172\n",
      "\tspeed: 0.0268s/iter; left time: 486.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0971042 Vali Loss: 0.1170631 Test Loss: 0.1279219\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0976394\n",
      "\tspeed: 0.0532s/iter; left time: 959.2814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025702\n",
      "\tspeed: 0.0268s/iter; left time: 480.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0969481 Vali Loss: 0.1168795 Test Loss: 0.1282358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0984403\n",
      "\tspeed: 0.0539s/iter; left time: 960.3656s\n",
      "\titers: 200, epoch: 21 | loss: 0.0932305\n",
      "\tspeed: 0.0269s/iter; left time: 477.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0967456 Vali Loss: 0.1170377 Test Loss: 0.1280329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0958503\n",
      "\tspeed: 0.0537s/iter; left time: 945.1394s\n",
      "\titers: 200, epoch: 22 | loss: 0.0987119\n",
      "\tspeed: 0.0269s/iter; left time: 471.5420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0965442 Vali Loss: 0.1168456 Test Loss: 0.1277162\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0967639\n",
      "\tspeed: 0.0528s/iter; left time: 917.3884s\n",
      "\titers: 200, epoch: 23 | loss: 0.1017741\n",
      "\tspeed: 0.0268s/iter; left time: 463.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0964595 Vali Loss: 0.1169775 Test Loss: 0.1280533\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1019816\n",
      "\tspeed: 0.0538s/iter; left time: 922.2519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0947855\n",
      "\tspeed: 0.0269s/iter; left time: 458.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0962695 Vali Loss: 0.1168131 Test Loss: 0.1279567\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0958062\n",
      "\tspeed: 0.0530s/iter; left time: 897.5916s\n",
      "\titers: 200, epoch: 25 | loss: 0.0925729\n",
      "\tspeed: 0.0269s/iter; left time: 452.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961852 Vali Loss: 0.1169263 Test Loss: 0.1279396\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03738878667354584, rmse:0.1933618038892746, mae:0.12796346843242645, rse:0.6847332715988159\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1453122\n",
      "\tspeed: 0.0287s/iter; left time: 639.1908s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341071\n",
      "\tspeed: 0.0268s/iter; left time: 594.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1493950 Vali Loss: 0.1402512 Test Loss: 0.1483553\n",
      "Validation loss decreased (inf --> 0.140251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097633\n",
      "\tspeed: 0.0543s/iter; left time: 1198.2260s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095724\n",
      "\tspeed: 0.0269s/iter; left time: 591.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1142674 Vali Loss: 0.1222842 Test Loss: 0.1300744\n",
      "Validation loss decreased (0.140251 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055942\n",
      "\tspeed: 0.0555s/iter; left time: 1212.4990s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084602\n",
      "\tspeed: 0.0270s/iter; left time: 587.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1065267 Vali Loss: 0.1205910 Test Loss: 0.1294958\n",
      "Validation loss decreased (0.122284 --> 0.120591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018099\n",
      "\tspeed: 0.0542s/iter; left time: 1171.7338s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051938\n",
      "\tspeed: 0.0269s/iter; left time: 579.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1047808 Vali Loss: 0.1190739 Test Loss: 0.1283687\n",
      "Validation loss decreased (0.120591 --> 0.119074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018800\n",
      "\tspeed: 0.0539s/iter; left time: 1153.8204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956694\n",
      "\tspeed: 0.0267s/iter; left time: 569.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1035395 Vali Loss: 0.1188459 Test Loss: 0.1280372\n",
      "Validation loss decreased (0.119074 --> 0.118846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0991640\n",
      "\tspeed: 0.0546s/iter; left time: 1156.3359s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049700\n",
      "\tspeed: 0.0269s/iter; left time: 568.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1181803 Test Loss: 0.1279618\n",
      "Validation loss decreased (0.118846 --> 0.118180).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013687\n",
      "\tspeed: 0.0545s/iter; left time: 1142.8758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993038\n",
      "\tspeed: 0.0268s/iter; left time: 557.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1018238 Vali Loss: 0.1180655 Test Loss: 0.1277595\n",
      "Validation loss decreased (0.118180 --> 0.118066).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997346\n",
      "\tspeed: 0.0555s/iter; left time: 1150.8520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997878\n",
      "\tspeed: 0.0270s/iter; left time: 557.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1010508 Vali Loss: 0.1179035 Test Loss: 0.1281448\n",
      "Validation loss decreased (0.118066 --> 0.117903).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0988701\n",
      "\tspeed: 0.0563s/iter; left time: 1154.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0968515\n",
      "\tspeed: 0.0271s/iter; left time: 552.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1004422 Vali Loss: 0.1178284 Test Loss: 0.1291293\n",
      "Validation loss decreased (0.117903 --> 0.117828).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008913\n",
      "\tspeed: 0.0546s/iter; left time: 1108.5587s\n",
      "\titers: 200, epoch: 10 | loss: 0.0954883\n",
      "\tspeed: 0.0267s/iter; left time: 539.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0998062 Vali Loss: 0.1179435 Test Loss: 0.1273128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1016945\n",
      "\tspeed: 0.0525s/iter; left time: 1052.5954s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974247\n",
      "\tspeed: 0.0269s/iter; left time: 536.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0992023 Vali Loss: 0.1177902 Test Loss: 0.1276344\n",
      "Validation loss decreased (0.117828 --> 0.117790).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0978504\n",
      "\tspeed: 0.0552s/iter; left time: 1094.3827s\n",
      "\titers: 200, epoch: 12 | loss: 0.1006840\n",
      "\tspeed: 0.0270s/iter; left time: 533.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0986686 Vali Loss: 0.1178868 Test Loss: 0.1283520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029566\n",
      "\tspeed: 0.0534s/iter; left time: 1048.1343s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995638\n",
      "\tspeed: 0.0267s/iter; left time: 521.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0982064 Vali Loss: 0.1177266 Test Loss: 0.1271849\n",
      "Validation loss decreased (0.117790 --> 0.117727).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966322\n",
      "\tspeed: 0.0541s/iter; left time: 1048.6480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0939447\n",
      "\tspeed: 0.0271s/iter; left time: 521.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0977019 Vali Loss: 0.1176199 Test Loss: 0.1285766\n",
      "Validation loss decreased (0.117727 --> 0.117620).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0955380\n",
      "\tspeed: 0.0567s/iter; left time: 1086.8307s\n",
      "\titers: 200, epoch: 15 | loss: 0.0928111\n",
      "\tspeed: 0.0271s/iter; left time: 516.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0973574 Vali Loss: 0.1177496 Test Loss: 0.1279720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019763\n",
      "\tspeed: 0.0549s/iter; left time: 1039.6933s\n",
      "\titers: 200, epoch: 16 | loss: 0.1012777\n",
      "\tspeed: 0.0270s/iter; left time: 509.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0969753 Vali Loss: 0.1177540 Test Loss: 0.1296667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0968168\n",
      "\tspeed: 0.0551s/iter; left time: 1030.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0930788\n",
      "\tspeed: 0.0270s/iter; left time: 502.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0968140 Vali Loss: 0.1179194 Test Loss: 0.1291604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0877084\n",
      "\tspeed: 0.0546s/iter; left time: 1009.5318s\n",
      "\titers: 200, epoch: 18 | loss: 0.0964585\n",
      "\tspeed: 0.0271s/iter; left time: 497.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0964126 Vali Loss: 0.1179514 Test Loss: 0.1292164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978073\n",
      "\tspeed: 0.0549s/iter; left time: 1002.6800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927446\n",
      "\tspeed: 0.0270s/iter; left time: 491.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0961563 Vali Loss: 0.1180256 Test Loss: 0.1296065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997547\n",
      "\tspeed: 0.0541s/iter; left time: 976.4935s\n",
      "\titers: 200, epoch: 20 | loss: 0.0986387\n",
      "\tspeed: 0.0274s/iter; left time: 491.8739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0959443 Vali Loss: 0.1176773 Test Loss: 0.1286344\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0958655\n",
      "\tspeed: 0.0560s/iter; left time: 998.6060s\n",
      "\titers: 200, epoch: 21 | loss: 0.0964852\n",
      "\tspeed: 0.0270s/iter; left time: 478.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0957407 Vali Loss: 0.1176798 Test Loss: 0.1287229\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0942021\n",
      "\tspeed: 0.0553s/iter; left time: 972.3128s\n",
      "\titers: 200, epoch: 22 | loss: 0.0922590\n",
      "\tspeed: 0.0270s/iter; left time: 472.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0955422 Vali Loss: 0.1179530 Test Loss: 0.1288881\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0922816\n",
      "\tspeed: 0.0546s/iter; left time: 948.8017s\n",
      "\titers: 200, epoch: 23 | loss: 0.0962126\n",
      "\tspeed: 0.0273s/iter; left time: 471.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0954098 Vali Loss: 0.1179873 Test Loss: 0.1291286\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0962873\n",
      "\tspeed: 0.0545s/iter; left time: 933.8682s\n",
      "\titers: 200, epoch: 24 | loss: 0.0961054\n",
      "\tspeed: 0.0271s/iter; left time: 462.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0953075 Vali Loss: 0.1179708 Test Loss: 0.1295294\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037975143641233444, rmse:0.19487212598323822, mae:0.1285766065120697, rse:0.6900815963745117\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:50.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1511204\n",
      "\tspeed: 0.0547s/iter; left time: 1213.9765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396091\n",
      "\tspeed: 0.0271s/iter; left time: 598.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.1507847 Vali Loss: 0.1426704 Test Loss: 0.1519556\n",
      "Validation loss decreased (inf --> 0.142670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1238355\n",
      "\tspeed: 0.0542s/iter; left time: 1191.4815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123134\n",
      "\tspeed: 0.0274s/iter; left time: 599.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1200940 Vali Loss: 0.1261885 Test Loss: 0.1355995\n",
      "Validation loss decreased (0.142670 --> 0.126188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164904\n",
      "\tspeed: 0.0582s/iter; left time: 1265.1403s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123756\n",
      "\tspeed: 0.0274s/iter; left time: 593.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1126304 Vali Loss: 0.1248742 Test Loss: 0.1346599\n",
      "Validation loss decreased (0.126188 --> 0.124874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090264\n",
      "\tspeed: 0.0564s/iter; left time: 1214.2777s\n",
      "\titers: 200, epoch: 4 | loss: 0.1161850\n",
      "\tspeed: 0.0277s/iter; left time: 593.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1108241 Vali Loss: 0.1231168 Test Loss: 0.1345049\n",
      "Validation loss decreased (0.124874 --> 0.123117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1067239\n",
      "\tspeed: 0.0557s/iter; left time: 1187.0533s\n",
      "\titers: 200, epoch: 5 | loss: 0.1134487\n",
      "\tspeed: 0.0273s/iter; left time: 578.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1096404 Vali Loss: 0.1232052 Test Loss: 0.1344802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046681\n",
      "\tspeed: 0.0548s/iter; left time: 1154.7548s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130422\n",
      "\tspeed: 0.0273s/iter; left time: 573.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1086139 Vali Loss: 0.1229566 Test Loss: 0.1347695\n",
      "Validation loss decreased (0.123117 --> 0.122957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1078895\n",
      "\tspeed: 0.0562s/iter; left time: 1172.1359s\n",
      "\titers: 200, epoch: 7 | loss: 0.1087261\n",
      "\tspeed: 0.0273s/iter; left time: 566.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1077184 Vali Loss: 0.1223245 Test Loss: 0.1334847\n",
      "Validation loss decreased (0.122957 --> 0.122324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035181\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6720s\n",
      "\titers: 200, epoch: 8 | loss: 0.1118061\n",
      "\tspeed: 0.0274s/iter; left time: 562.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1069834 Vali Loss: 0.1218858 Test Loss: 0.1330454\n",
      "Validation loss decreased (0.122324 --> 0.121886).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1058632\n",
      "\tspeed: 0.0555s/iter; left time: 1132.6126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987647\n",
      "\tspeed: 0.0272s/iter; left time: 553.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1062651 Vali Loss: 0.1219982 Test Loss: 0.1338042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1030127\n",
      "\tspeed: 0.0538s/iter; left time: 1086.2314s\n",
      "\titers: 200, epoch: 10 | loss: 0.1031541\n",
      "\tspeed: 0.0273s/iter; left time: 548.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1056596 Vali Loss: 0.1220121 Test Loss: 0.1338617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1061721\n",
      "\tspeed: 0.0545s/iter; left time: 1089.1685s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000139\n",
      "\tspeed: 0.0286s/iter; left time: 568.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1051509 Vali Loss: 0.1223389 Test Loss: 0.1343730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1016918\n",
      "\tspeed: 0.0557s/iter; left time: 1099.9068s\n",
      "\titers: 200, epoch: 12 | loss: 0.1091376\n",
      "\tspeed: 0.0273s/iter; left time: 536.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.1046909 Vali Loss: 0.1220724 Test Loss: 0.1342280\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1095180\n",
      "\tspeed: 0.0545s/iter; left time: 1064.6654s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059984\n",
      "\tspeed: 0.0273s/iter; left time: 529.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1042259 Vali Loss: 0.1223401 Test Loss: 0.1342049\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0977468\n",
      "\tspeed: 0.0541s/iter; left time: 1045.0044s\n",
      "\titers: 200, epoch: 14 | loss: 0.1107927\n",
      "\tspeed: 0.0270s/iter; left time: 518.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1039162 Vali Loss: 0.1222137 Test Loss: 0.1342742\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1054508\n",
      "\tspeed: 0.0546s/iter; left time: 1042.4705s\n",
      "\titers: 200, epoch: 15 | loss: 0.1117989\n",
      "\tspeed: 0.0273s/iter; left time: 517.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035189 Vali Loss: 0.1224293 Test Loss: 0.1347673\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1062974\n",
      "\tspeed: 0.0547s/iter; left time: 1030.8627s\n",
      "\titers: 200, epoch: 16 | loss: 0.1125161\n",
      "\tspeed: 0.0272s/iter; left time: 511.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1031467 Vali Loss: 0.1224126 Test Loss: 0.1339886\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1029710\n",
      "\tspeed: 0.0545s/iter; left time: 1015.8779s\n",
      "\titers: 200, epoch: 17 | loss: 0.1050183\n",
      "\tspeed: 0.0273s/iter; left time: 505.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1029577 Vali Loss: 0.1227930 Test Loss: 0.1340047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1025430\n",
      "\tspeed: 0.0542s/iter; left time: 998.1419s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046702\n",
      "\tspeed: 0.0272s/iter; left time: 497.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1026303 Vali Loss: 0.1226197 Test Loss: 0.1343808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03874775022268295, rmse:0.19684448838233948, mae:0.13304544985294342, rse:0.6972389817237854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1546361\n",
      "\tspeed: 0.0298s/iter; left time: 662.3935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357865\n",
      "\tspeed: 0.0272s/iter; left time: 600.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1520326 Vali Loss: 0.1427907 Test Loss: 0.1520844\n",
      "Validation loss decreased (inf --> 0.142791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183958\n",
      "\tspeed: 0.0566s/iter; left time: 1243.1818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188114\n",
      "\tspeed: 0.0273s/iter; left time: 597.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1199734 Vali Loss: 0.1263667 Test Loss: 0.1363375\n",
      "Validation loss decreased (0.142791 --> 0.126367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1155362\n",
      "\tspeed: 0.0556s/iter; left time: 1208.6087s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098592\n",
      "\tspeed: 0.0272s/iter; left time: 588.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1126673 Vali Loss: 0.1251423 Test Loss: 0.1348121\n",
      "Validation loss decreased (0.126367 --> 0.125142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086826\n",
      "\tspeed: 0.0557s/iter; left time: 1199.5182s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126055\n",
      "\tspeed: 0.0274s/iter; left time: 587.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1106587 Vali Loss: 0.1242879 Test Loss: 0.1354954\n",
      "Validation loss decreased (0.125142 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1116844\n",
      "\tspeed: 0.0560s/iter; left time: 1194.1369s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103760\n",
      "\tspeed: 0.0274s/iter; left time: 580.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1092648 Vali Loss: 0.1238110 Test Loss: 0.1339414\n",
      "Validation loss decreased (0.124288 --> 0.123811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062780\n",
      "\tspeed: 0.0556s/iter; left time: 1172.0651s\n",
      "\titers: 200, epoch: 6 | loss: 0.1105472\n",
      "\tspeed: 0.0275s/iter; left time: 576.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1083813 Vali Loss: 0.1230377 Test Loss: 0.1344151\n",
      "Validation loss decreased (0.123811 --> 0.123038).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1100236\n",
      "\tspeed: 0.0563s/iter; left time: 1173.7410s\n",
      "\titers: 200, epoch: 7 | loss: 0.1094361\n",
      "\tspeed: 0.0271s/iter; left time: 563.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1075638 Vali Loss: 0.1233376 Test Loss: 0.1351425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1083931\n",
      "\tspeed: 0.0550s/iter; left time: 1135.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076261\n",
      "\tspeed: 0.0272s/iter; left time: 559.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1067569 Vali Loss: 0.1231392 Test Loss: 0.1350849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042043\n",
      "\tspeed: 0.0562s/iter; left time: 1148.2966s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087456\n",
      "\tspeed: 0.0286s/iter; left time: 580.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.1061874 Vali Loss: 0.1229115 Test Loss: 0.1347596\n",
      "Validation loss decreased (0.123038 --> 0.122912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047019\n",
      "\tspeed: 0.0569s/iter; left time: 1149.2216s\n",
      "\titers: 200, epoch: 10 | loss: 0.1098653\n",
      "\tspeed: 0.0274s/iter; left time: 551.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1054878 Vali Loss: 0.1231185 Test Loss: 0.1345507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1028828\n",
      "\tspeed: 0.0549s/iter; left time: 1096.4879s\n",
      "\titers: 200, epoch: 11 | loss: 0.1091575\n",
      "\tspeed: 0.0277s/iter; left time: 549.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1048839 Vali Loss: 0.1236878 Test Loss: 0.1354434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043799\n",
      "\tspeed: 0.0562s/iter; left time: 1109.6457s\n",
      "\titers: 200, epoch: 12 | loss: 0.1061269\n",
      "\tspeed: 0.0280s/iter; left time: 549.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.1043107 Vali Loss: 0.1239945 Test Loss: 0.1346901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1080359\n",
      "\tspeed: 0.0548s/iter; left time: 1070.4594s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058448\n",
      "\tspeed: 0.0271s/iter; left time: 527.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1037742 Vali Loss: 0.1241476 Test Loss: 0.1351113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1032596\n",
      "\tspeed: 0.0556s/iter; left time: 1073.1232s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017853\n",
      "\tspeed: 0.0273s/iter; left time: 523.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1033254 Vali Loss: 0.1241768 Test Loss: 0.1357941\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1011182\n",
      "\tspeed: 0.0548s/iter; left time: 1044.6235s\n",
      "\titers: 200, epoch: 15 | loss: 0.1017340\n",
      "\tspeed: 0.0272s/iter; left time: 516.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1029318 Vali Loss: 0.1242862 Test Loss: 0.1359198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1043327\n",
      "\tspeed: 0.0555s/iter; left time: 1046.7619s\n",
      "\titers: 200, epoch: 16 | loss: 0.1076296\n",
      "\tspeed: 0.0273s/iter; left time: 511.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1024750 Vali Loss: 0.1245145 Test Loss: 0.1355859\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003824\n",
      "\tspeed: 0.0549s/iter; left time: 1023.8289s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016187\n",
      "\tspeed: 0.0274s/iter; left time: 507.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1022286 Vali Loss: 0.1240813 Test Loss: 0.1352433\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041608\n",
      "\tspeed: 0.0561s/iter; left time: 1032.5608s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061510\n",
      "\tspeed: 0.0277s/iter; left time: 506.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1019955 Vali Loss: 0.1249169 Test Loss: 0.1354775\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1080255\n",
      "\tspeed: 0.0557s/iter; left time: 1013.8191s\n",
      "\titers: 200, epoch: 19 | loss: 0.0987023\n",
      "\tspeed: 0.0274s/iter; left time: 496.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1016865 Vali Loss: 0.1249771 Test Loss: 0.1352909\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03975802659988403, rmse:0.19939415156841278, mae:0.13475961983203888, rse:0.7062700986862183\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:20.07s\n",
      "Intermediate time for DE: 00h:27m:01.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1243801\n",
      "\tspeed: 0.0543s/iter; left time: 1211.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137652\n",
      "\tspeed: 0.0266s/iter; left time: 590.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.1302879 Vali Loss: 0.1216964 Test Loss: 0.1408504\n",
      "Validation loss decreased (inf --> 0.121696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0839070\n",
      "\tspeed: 0.0520s/iter; left time: 1147.3483s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818553\n",
      "\tspeed: 0.0265s/iter; left time: 583.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0865396 Vali Loss: 0.0920018 Test Loss: 0.1033591\n",
      "Validation loss decreased (0.121696 --> 0.092002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733085\n",
      "\tspeed: 0.0515s/iter; left time: 1125.3848s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821068\n",
      "\tspeed: 0.0267s/iter; left time: 581.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0793856 Vali Loss: 0.0900384 Test Loss: 0.1024917\n",
      "Validation loss decreased (0.092002 --> 0.090038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0750556\n",
      "\tspeed: 0.0518s/iter; left time: 1121.1212s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780856\n",
      "\tspeed: 0.0264s/iter; left time: 568.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0779691 Vali Loss: 0.0899016 Test Loss: 0.1022058\n",
      "Validation loss decreased (0.090038 --> 0.089902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758535\n",
      "\tspeed: 0.0517s/iter; left time: 1107.5445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757776\n",
      "\tspeed: 0.0267s/iter; left time: 568.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0769919 Vali Loss: 0.0893033 Test Loss: 0.1019564\n",
      "Validation loss decreased (0.089902 --> 0.089303).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798705\n",
      "\tspeed: 0.0522s/iter; left time: 1104.7398s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816744\n",
      "\tspeed: 0.0267s/iter; left time: 563.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0762630 Vali Loss: 0.0887678 Test Loss: 0.1014424\n",
      "Validation loss decreased (0.089303 --> 0.088768).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754332\n",
      "\tspeed: 0.0518s/iter; left time: 1085.2478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806607\n",
      "\tspeed: 0.0267s/iter; left time: 557.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0756519 Vali Loss: 0.0887744 Test Loss: 0.1014127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728288\n",
      "\tspeed: 0.0511s/iter; left time: 1059.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775176\n",
      "\tspeed: 0.0266s/iter; left time: 547.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0752004 Vali Loss: 0.0885392 Test Loss: 0.1006487\n",
      "Validation loss decreased (0.088768 --> 0.088539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738876\n",
      "\tspeed: 0.0528s/iter; left time: 1082.2772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792237\n",
      "\tspeed: 0.0268s/iter; left time: 546.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0748653 Vali Loss: 0.0884795 Test Loss: 0.1006068\n",
      "Validation loss decreased (0.088539 --> 0.088479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808073\n",
      "\tspeed: 0.0520s/iter; left time: 1054.3701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720843\n",
      "\tspeed: 0.0267s/iter; left time: 538.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0745151 Vali Loss: 0.0878042 Test Loss: 0.1009895\n",
      "Validation loss decreased (0.088479 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773240\n",
      "\tspeed: 0.0519s/iter; left time: 1041.0894s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738162\n",
      "\tspeed: 0.0267s/iter; left time: 531.9959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0742512 Vali Loss: 0.0880865 Test Loss: 0.1001864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778451\n",
      "\tspeed: 0.0510s/iter; left time: 1012.4607s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704564\n",
      "\tspeed: 0.0267s/iter; left time: 527.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0739914 Vali Loss: 0.0879424 Test Loss: 0.1007774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728143\n",
      "\tspeed: 0.0519s/iter; left time: 1018.4859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723630\n",
      "\tspeed: 0.0266s/iter; left time: 520.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0738506 Vali Loss: 0.0879685 Test Loss: 0.1000657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773398\n",
      "\tspeed: 0.0518s/iter; left time: 1004.9878s\n",
      "\titers: 200, epoch: 14 | loss: 0.0699778\n",
      "\tspeed: 0.0267s/iter; left time: 514.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0736961 Vali Loss: 0.0878420 Test Loss: 0.0999213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665786\n",
      "\tspeed: 0.0518s/iter; left time: 992.4915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0686087\n",
      "\tspeed: 0.0266s/iter; left time: 507.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0734943 Vali Loss: 0.0880088 Test Loss: 0.1000402\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704044\n",
      "\tspeed: 0.0525s/iter; left time: 993.4795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735029\n",
      "\tspeed: 0.0268s/iter; left time: 505.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0733230 Vali Loss: 0.0875390 Test Loss: 0.1002045\n",
      "Validation loss decreased (0.087804 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733052\n",
      "\tspeed: 0.0529s/iter; left time: 989.9356s\n",
      "\titers: 200, epoch: 17 | loss: 0.0776525\n",
      "\tspeed: 0.0267s/iter; left time: 496.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0732607 Vali Loss: 0.0874719 Test Loss: 0.0997542\n",
      "Validation loss decreased (0.087539 --> 0.087472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0733563\n",
      "\tspeed: 0.0528s/iter; left time: 976.5661s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740419\n",
      "\tspeed: 0.0269s/iter; left time: 493.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0731655 Vali Loss: 0.0875383 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0704366\n",
      "\tspeed: 0.0523s/iter; left time: 956.2087s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727878\n",
      "\tspeed: 0.0269s/iter; left time: 488.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0730607 Vali Loss: 0.0878342 Test Loss: 0.0998149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639565\n",
      "\tspeed: 0.0523s/iter; left time: 943.3723s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710644\n",
      "\tspeed: 0.0268s/iter; left time: 481.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0729284 Vali Loss: 0.0876287 Test Loss: 0.0996863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751909\n",
      "\tspeed: 0.0521s/iter; left time: 928.5994s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704616\n",
      "\tspeed: 0.0265s/iter; left time: 469.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0727867 Vali Loss: 0.0875195 Test Loss: 0.0996076\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0709846\n",
      "\tspeed: 0.0528s/iter; left time: 928.9821s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672187\n",
      "\tspeed: 0.0271s/iter; left time: 473.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0727850 Vali Loss: 0.0873734 Test Loss: 0.0995667\n",
      "Validation loss decreased (0.087472 --> 0.087373).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724984\n",
      "\tspeed: 0.0546s/iter; left time: 947.7766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0676599\n",
      "\tspeed: 0.0269s/iter; left time: 464.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0727007 Vali Loss: 0.0874452 Test Loss: 0.0995794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0710710\n",
      "\tspeed: 0.0533s/iter; left time: 914.8627s\n",
      "\titers: 200, epoch: 24 | loss: 0.0718718\n",
      "\tspeed: 0.0272s/iter; left time: 463.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0726696 Vali Loss: 0.0874877 Test Loss: 0.0994474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0733318\n",
      "\tspeed: 0.0538s/iter; left time: 909.7842s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770599\n",
      "\tspeed: 0.0271s/iter; left time: 456.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0726920 Vali Loss: 0.0873381 Test Loss: 0.0994857\n",
      "Validation loss decreased (0.087373 --> 0.087338).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0732230\n",
      "\tspeed: 0.0537s/iter; left time: 896.6000s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704290\n",
      "\tspeed: 0.0268s/iter; left time: 445.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0726002 Vali Loss: 0.0874241 Test Loss: 0.0995524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722607\n",
      "\tspeed: 0.0535s/iter; left time: 881.7593s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757692\n",
      "\tspeed: 0.0273s/iter; left time: 446.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0725308 Vali Loss: 0.0873835 Test Loss: 0.0995856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780362\n",
      "\tspeed: 0.0530s/iter; left time: 860.7019s\n",
      "\titers: 200, epoch: 28 | loss: 0.0754186\n",
      "\tspeed: 0.0269s/iter; left time: 433.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724948 Vali Loss: 0.0874800 Test Loss: 0.0996659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0755497\n",
      "\tspeed: 0.0534s/iter; left time: 856.6310s\n",
      "\titers: 200, epoch: 29 | loss: 0.0672095\n",
      "\tspeed: 0.0269s/iter; left time: 427.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724994 Vali Loss: 0.0873726 Test Loss: 0.0994512\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743681\n",
      "\tspeed: 0.0530s/iter; left time: 837.2495s\n",
      "\titers: 200, epoch: 30 | loss: 0.0714248\n",
      "\tspeed: 0.0268s/iter; left time: 421.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0724325 Vali Loss: 0.0874007 Test Loss: 0.0996015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670253\n",
      "\tspeed: 0.0540s/iter; left time: 840.9434s\n",
      "\titers: 200, epoch: 31 | loss: 0.0738778\n",
      "\tspeed: 0.0265s/iter; left time: 410.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723963 Vali Loss: 0.0873461 Test Loss: 0.0995764\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0729594\n",
      "\tspeed: 0.0534s/iter; left time: 820.6041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0743888\n",
      "\tspeed: 0.0268s/iter; left time: 409.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0724081 Vali Loss: 0.0872245 Test Loss: 0.0994373\n",
      "Validation loss decreased (0.087338 --> 0.087224).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723266\n",
      "\tspeed: 0.0541s/iter; left time: 818.1361s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713193\n",
      "\tspeed: 0.0269s/iter; left time: 404.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0723961 Vali Loss: 0.0874335 Test Loss: 0.0996177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0732763\n",
      "\tspeed: 0.0532s/iter; left time: 793.2879s\n",
      "\titers: 200, epoch: 34 | loss: 0.0748497\n",
      "\tspeed: 0.0268s/iter; left time: 396.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0723704 Vali Loss: 0.0873889 Test Loss: 0.0995195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779761\n",
      "\tspeed: 0.0529s/iter; left time: 776.7366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0753652\n",
      "\tspeed: 0.0268s/iter; left time: 390.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723036 Vali Loss: 0.0872547 Test Loss: 0.0995013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686231\n",
      "\tspeed: 0.0528s/iter; left time: 764.0125s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763031\n",
      "\tspeed: 0.0268s/iter; left time: 384.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722592 Vali Loss: 0.0874217 Test Loss: 0.0995324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755020\n",
      "\tspeed: 0.0527s/iter; left time: 750.5292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0714776\n",
      "\tspeed: 0.0268s/iter; left time: 378.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723462 Vali Loss: 0.0874196 Test Loss: 0.0995449\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0748234\n",
      "\tspeed: 0.0534s/iter; left time: 747.9698s\n",
      "\titers: 200, epoch: 38 | loss: 0.0689176\n",
      "\tspeed: 0.0268s/iter; left time: 373.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0723155 Vali Loss: 0.0872684 Test Loss: 0.0995207\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765601\n",
      "\tspeed: 0.0540s/iter; left time: 744.7602s\n",
      "\titers: 200, epoch: 39 | loss: 0.0677570\n",
      "\tspeed: 0.0268s/iter; left time: 366.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722663 Vali Loss: 0.0874316 Test Loss: 0.0995467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0654785\n",
      "\tspeed: 0.0528s/iter; left time: 716.1290s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748680\n",
      "\tspeed: 0.0265s/iter; left time: 356.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0723363 Vali Loss: 0.0873764 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700707\n",
      "\tspeed: 0.0531s/iter; left time: 708.0991s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708900\n",
      "\tspeed: 0.0270s/iter; left time: 356.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0722918 Vali Loss: 0.0873483 Test Loss: 0.0995223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721399\n",
      "\tspeed: 0.0532s/iter; left time: 697.5313s\n",
      "\titers: 200, epoch: 42 | loss: 0.0775154\n",
      "\tspeed: 0.0272s/iter; left time: 353.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0722849 Vali Loss: 0.0872172 Test Loss: 0.0995116\n",
      "Validation loss decreased (0.087224 --> 0.087217).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0751871\n",
      "\tspeed: 0.0535s/iter; left time: 689.5227s\n",
      "\titers: 200, epoch: 43 | loss: 0.0700004\n",
      "\tspeed: 0.0269s/iter; left time: 343.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722874 Vali Loss: 0.0872460 Test Loss: 0.0994964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0771745\n",
      "\tspeed: 0.0536s/iter; left time: 678.9808s\n",
      "\titers: 200, epoch: 44 | loss: 0.0732692\n",
      "\tspeed: 0.0268s/iter; left time: 336.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722729 Vali Loss: 0.0872457 Test Loss: 0.0994803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0702146\n",
      "\tspeed: 0.0527s/iter; left time: 656.2688s\n",
      "\titers: 200, epoch: 45 | loss: 0.0754088\n",
      "\tspeed: 0.0268s/iter; left time: 330.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0872447 Test Loss: 0.0994848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0695563\n",
      "\tspeed: 0.0525s/iter; left time: 641.3707s\n",
      "\titers: 200, epoch: 46 | loss: 0.0708172\n",
      "\tspeed: 0.0269s/iter; left time: 325.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722368 Vali Loss: 0.0872585 Test Loss: 0.0994719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0748870\n",
      "\tspeed: 0.0531s/iter; left time: 636.6953s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730831\n",
      "\tspeed: 0.0269s/iter; left time: 319.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722215 Vali Loss: 0.0873487 Test Loss: 0.0995225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0761661\n",
      "\tspeed: 0.0530s/iter; left time: 624.1234s\n",
      "\titers: 200, epoch: 48 | loss: 0.0745982\n",
      "\tspeed: 0.0268s/iter; left time: 312.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721901 Vali Loss: 0.0873764 Test Loss: 0.0994837\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0708556\n",
      "\tspeed: 0.0533s/iter; left time: 615.7655s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708657\n",
      "\tspeed: 0.0268s/iter; left time: 307.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722119 Vali Loss: 0.0872935 Test Loss: 0.0994825\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738270\n",
      "\tspeed: 0.0525s/iter; left time: 594.2805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0708394\n",
      "\tspeed: 0.0269s/iter; left time: 301.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721791 Vali Loss: 0.0872133 Test Loss: 0.0994824\n",
      "Validation loss decreased (0.087217 --> 0.087213).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0729056\n",
      "\tspeed: 0.0537s/iter; left time: 596.5067s\n",
      "\titers: 200, epoch: 51 | loss: 0.0680218\n",
      "\tspeed: 0.0268s/iter; left time: 294.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721853 Vali Loss: 0.0873186 Test Loss: 0.0994690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0694491\n",
      "\tspeed: 0.0528s/iter; left time: 574.4605s\n",
      "\titers: 200, epoch: 52 | loss: 0.0776386\n",
      "\tspeed: 0.0269s/iter; left time: 289.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0722179 Vali Loss: 0.0873789 Test Loss: 0.0994850\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0731650\n",
      "\tspeed: 0.0526s/iter; left time: 559.9777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0769954\n",
      "\tspeed: 0.0268s/iter; left time: 283.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721883 Vali Loss: 0.0873961 Test Loss: 0.0994792\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0745562\n",
      "\tspeed: 0.0537s/iter; left time: 559.6576s\n",
      "\titers: 200, epoch: 54 | loss: 0.0707905\n",
      "\tspeed: 0.0268s/iter; left time: 276.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722220 Vali Loss: 0.0872954 Test Loss: 0.0995034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0701514\n",
      "\tspeed: 0.0533s/iter; left time: 543.8353s\n",
      "\titers: 200, epoch: 55 | loss: 0.0714959\n",
      "\tspeed: 0.0271s/iter; left time: 274.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0873029 Test Loss: 0.0994843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0704450\n",
      "\tspeed: 0.0535s/iter; left time: 534.3546s\n",
      "\titers: 200, epoch: 56 | loss: 0.0675059\n",
      "\tspeed: 0.0269s/iter; left time: 266.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0721501 Vali Loss: 0.0873734 Test Loss: 0.0994912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0738333\n",
      "\tspeed: 0.0537s/iter; left time: 523.7482s\n",
      "\titers: 200, epoch: 57 | loss: 0.0705020\n",
      "\tspeed: 0.0269s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0722345 Vali Loss: 0.0874336 Test Loss: 0.0994758\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0767229\n",
      "\tspeed: 0.0527s/iter; left time: 502.0444s\n",
      "\titers: 200, epoch: 58 | loss: 0.0729605\n",
      "\tspeed: 0.0268s/iter; left time: 253.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722041 Vali Loss: 0.0873020 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0756847\n",
      "\tspeed: 0.0534s/iter; left time: 497.0981s\n",
      "\titers: 200, epoch: 59 | loss: 0.0757611\n",
      "\tspeed: 0.0268s/iter; left time: 247.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0721992 Vali Loss: 0.0872928 Test Loss: 0.0994752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0702965\n",
      "\tspeed: 0.0524s/iter; left time: 476.4810s\n",
      "\titers: 200, epoch: 60 | loss: 0.0741313\n",
      "\tspeed: 0.0268s/iter; left time: 240.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722097 Vali Loss: 0.0873115 Test Loss: 0.0994877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02502487227320671, rmse:0.15819251537322998, mae:0.09948243200778961, rse:0.54571932554245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1281256\n",
      "\tspeed: 0.0292s/iter; left time: 650.2233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1138560\n",
      "\tspeed: 0.0268s/iter; left time: 594.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1290584 Vali Loss: 0.1207433 Test Loss: 0.1395016\n",
      "Validation loss decreased (inf --> 0.120743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853941\n",
      "\tspeed: 0.0536s/iter; left time: 1182.5697s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847853\n",
      "\tspeed: 0.0269s/iter; left time: 590.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0861361 Vali Loss: 0.0918532 Test Loss: 0.1040095\n",
      "Validation loss decreased (0.120743 --> 0.091853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775025\n",
      "\tspeed: 0.0535s/iter; left time: 1169.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788021\n",
      "\tspeed: 0.0268s/iter; left time: 583.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0792676 Vali Loss: 0.0905056 Test Loss: 0.1025451\n",
      "Validation loss decreased (0.091853 --> 0.090506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744780\n",
      "\tspeed: 0.0530s/iter; left time: 1146.1907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797157\n",
      "\tspeed: 0.0268s/iter; left time: 576.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0780674 Vali Loss: 0.0906739 Test Loss: 0.1020297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770665\n",
      "\tspeed: 0.0537s/iter; left time: 1149.1107s\n",
      "\titers: 200, epoch: 5 | loss: 0.0766374\n",
      "\tspeed: 0.0268s/iter; left time: 571.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0769707 Vali Loss: 0.0894935 Test Loss: 0.1018222\n",
      "Validation loss decreased (0.090506 --> 0.089494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809719\n",
      "\tspeed: 0.0542s/iter; left time: 1148.6083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820128\n",
      "\tspeed: 0.0268s/iter; left time: 565.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0762634 Vali Loss: 0.0891491 Test Loss: 0.1013036\n",
      "Validation loss decreased (0.089494 --> 0.089149).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794357\n",
      "\tspeed: 0.0534s/iter; left time: 1119.2823s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746093\n",
      "\tspeed: 0.0269s/iter; left time: 560.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0757042 Vali Loss: 0.0887241 Test Loss: 0.1007391\n",
      "Validation loss decreased (0.089149 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761330\n",
      "\tspeed: 0.0535s/iter; left time: 1109.9562s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747115\n",
      "\tspeed: 0.0269s/iter; left time: 555.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0752742 Vali Loss: 0.0889610 Test Loss: 0.1005073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797194\n",
      "\tspeed: 0.0531s/iter; left time: 1089.4519s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733876\n",
      "\tspeed: 0.0269s/iter; left time: 548.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0748621 Vali Loss: 0.0881851 Test Loss: 0.1004349\n",
      "Validation loss decreased (0.088724 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750555\n",
      "\tspeed: 0.0529s/iter; left time: 1073.6207s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730892\n",
      "\tspeed: 0.0268s/iter; left time: 540.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0745724 Vali Loss: 0.0886613 Test Loss: 0.0999387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0729881\n",
      "\tspeed: 0.0534s/iter; left time: 1071.6187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750049\n",
      "\tspeed: 0.0268s/iter; left time: 534.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0742235 Vali Loss: 0.0879054 Test Loss: 0.1000553\n",
      "Validation loss decreased (0.088185 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0731180\n",
      "\tspeed: 0.0537s/iter; left time: 1065.7722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704911\n",
      "\tspeed: 0.0268s/iter; left time: 529.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0739811 Vali Loss: 0.0880940 Test Loss: 0.1000203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0734993\n",
      "\tspeed: 0.0533s/iter; left time: 1046.3170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0771078\n",
      "\tspeed: 0.0268s/iter; left time: 522.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0738054 Vali Loss: 0.0879598 Test Loss: 0.1001505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748501\n",
      "\tspeed: 0.0532s/iter; left time: 1031.9631s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740310\n",
      "\tspeed: 0.0269s/iter; left time: 518.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0736476 Vali Loss: 0.0878529 Test Loss: 0.1002746\n",
      "Validation loss decreased (0.087905 --> 0.087853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738298\n",
      "\tspeed: 0.0543s/iter; left time: 1041.4646s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762812\n",
      "\tspeed: 0.0269s/iter; left time: 513.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0735278 Vali Loss: 0.0878173 Test Loss: 0.1001467\n",
      "Validation loss decreased (0.087853 --> 0.087817).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707365\n",
      "\tspeed: 0.0534s/iter; left time: 1010.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745331\n",
      "\tspeed: 0.0269s/iter; left time: 505.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0732803 Vali Loss: 0.0877546 Test Loss: 0.0999003\n",
      "Validation loss decreased (0.087817 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0703407\n",
      "\tspeed: 0.0537s/iter; left time: 1005.2025s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806976\n",
      "\tspeed: 0.0270s/iter; left time: 501.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0732293 Vali Loss: 0.0877284 Test Loss: 0.1001207\n",
      "Validation loss decreased (0.087755 --> 0.087728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721018\n",
      "\tspeed: 0.0533s/iter; left time: 985.6505s\n",
      "\titers: 200, epoch: 18 | loss: 0.0723104\n",
      "\tspeed: 0.0268s/iter; left time: 493.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0730768 Vali Loss: 0.0877988 Test Loss: 0.0999179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0745736\n",
      "\tspeed: 0.0523s/iter; left time: 954.9691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709844\n",
      "\tspeed: 0.0268s/iter; left time: 486.2546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0729765 Vali Loss: 0.0877342 Test Loss: 0.0999373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700831\n",
      "\tspeed: 0.0528s/iter; left time: 951.9676s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720744\n",
      "\tspeed: 0.0268s/iter; left time: 480.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728975 Vali Loss: 0.0876718 Test Loss: 0.0999224\n",
      "Validation loss decreased (0.087728 --> 0.087672).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748239\n",
      "\tspeed: 0.0530s/iter; left time: 943.8389s\n",
      "\titers: 200, epoch: 21 | loss: 0.0763428\n",
      "\tspeed: 0.0268s/iter; left time: 474.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728158 Vali Loss: 0.0874219 Test Loss: 0.0997877\n",
      "Validation loss decreased (0.087672 --> 0.087422).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0726125\n",
      "\tspeed: 0.0535s/iter; left time: 941.3583s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784063\n",
      "\tspeed: 0.0267s/iter; left time: 467.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0727590 Vali Loss: 0.0874105 Test Loss: 0.0995382\n",
      "Validation loss decreased (0.087422 --> 0.087410).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0671866\n",
      "\tspeed: 0.0535s/iter; left time: 929.4445s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725489\n",
      "\tspeed: 0.0268s/iter; left time: 462.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0726649 Vali Loss: 0.0874186 Test Loss: 0.0996998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0776832\n",
      "\tspeed: 0.0533s/iter; left time: 913.3976s\n",
      "\titers: 200, epoch: 24 | loss: 0.0751887\n",
      "\tspeed: 0.0268s/iter; left time: 456.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0726117 Vali Loss: 0.0874993 Test Loss: 0.0999176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748994\n",
      "\tspeed: 0.0529s/iter; left time: 894.5695s\n",
      "\titers: 200, epoch: 25 | loss: 0.0756038\n",
      "\tspeed: 0.0265s/iter; left time: 446.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0725972 Vali Loss: 0.0874437 Test Loss: 0.0998308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704204\n",
      "\tspeed: 0.0528s/iter; left time: 881.4889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690703\n",
      "\tspeed: 0.0265s/iter; left time: 439.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0725073 Vali Loss: 0.0873915 Test Loss: 0.0997966\n",
      "Validation loss decreased (0.087410 --> 0.087391).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722938\n",
      "\tspeed: 0.0550s/iter; left time: 906.8522s\n",
      "\titers: 200, epoch: 27 | loss: 0.0707320\n",
      "\tspeed: 0.0269s/iter; left time: 440.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0724955 Vali Loss: 0.0874042 Test Loss: 0.0997572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708005\n",
      "\tspeed: 0.0524s/iter; left time: 852.1813s\n",
      "\titers: 200, epoch: 28 | loss: 0.0706717\n",
      "\tspeed: 0.0265s/iter; left time: 427.8731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0725039 Vali Loss: 0.0873560 Test Loss: 0.0996761\n",
      "Validation loss decreased (0.087391 --> 0.087356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742883\n",
      "\tspeed: 0.0536s/iter; left time: 859.0053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742773\n",
      "\tspeed: 0.0269s/iter; left time: 427.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724317 Vali Loss: 0.0874750 Test Loss: 0.0997233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733841\n",
      "\tspeed: 0.0534s/iter; left time: 844.4930s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713019\n",
      "\tspeed: 0.0268s/iter; left time: 421.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724177 Vali Loss: 0.0873239 Test Loss: 0.0995659\n",
      "Validation loss decreased (0.087356 --> 0.087324).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0728526\n",
      "\tspeed: 0.0535s/iter; left time: 834.2808s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712871\n",
      "\tspeed: 0.0268s/iter; left time: 414.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0723862 Vali Loss: 0.0873993 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745156\n",
      "\tspeed: 0.0529s/iter; left time: 811.9430s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705794\n",
      "\tspeed: 0.0267s/iter; left time: 407.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0723662 Vali Loss: 0.0874361 Test Loss: 0.0997775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0698627\n",
      "\tspeed: 0.0531s/iter; left time: 804.2879s\n",
      "\titers: 200, epoch: 33 | loss: 0.0744560\n",
      "\tspeed: 0.0267s/iter; left time: 401.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723162 Vali Loss: 0.0872565 Test Loss: 0.0996848\n",
      "Validation loss decreased (0.087324 --> 0.087256).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720458\n",
      "\tspeed: 0.0529s/iter; left time: 789.0979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0796783\n",
      "\tspeed: 0.0267s/iter; left time: 395.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722920 Vali Loss: 0.0873715 Test Loss: 0.0996110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0731819\n",
      "\tspeed: 0.0527s/iter; left time: 773.4842s\n",
      "\titers: 200, epoch: 35 | loss: 0.0786404\n",
      "\tspeed: 0.0267s/iter; left time: 389.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723127 Vali Loss: 0.0874032 Test Loss: 0.0996725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0717856\n",
      "\tspeed: 0.0527s/iter; left time: 761.5788s\n",
      "\titers: 200, epoch: 36 | loss: 0.0735888\n",
      "\tspeed: 0.0267s/iter; left time: 383.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723288 Vali Loss: 0.0872270 Test Loss: 0.0996796\n",
      "Validation loss decreased (0.087256 --> 0.087227).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752889\n",
      "\tspeed: 0.0529s/iter; left time: 753.7263s\n",
      "\titers: 200, epoch: 37 | loss: 0.0713401\n",
      "\tspeed: 0.0268s/iter; left time: 378.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723031 Vali Loss: 0.0874127 Test Loss: 0.0996993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0730377\n",
      "\tspeed: 0.0528s/iter; left time: 740.2937s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670286\n",
      "\tspeed: 0.0266s/iter; left time: 369.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0722490 Vali Loss: 0.0873063 Test Loss: 0.0996096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0739416\n",
      "\tspeed: 0.0528s/iter; left time: 727.5970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706054\n",
      "\tspeed: 0.0266s/iter; left time: 364.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0722615 Vali Loss: 0.0873521 Test Loss: 0.0996684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0689131\n",
      "\tspeed: 0.0538s/iter; left time: 729.3039s\n",
      "\titers: 200, epoch: 40 | loss: 0.0731106\n",
      "\tspeed: 0.0269s/iter; left time: 362.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722557 Vali Loss: 0.0874369 Test Loss: 0.0997051\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0715132\n",
      "\tspeed: 0.0532s/iter; left time: 710.0583s\n",
      "\titers: 200, epoch: 41 | loss: 0.0690387\n",
      "\tspeed: 0.0267s/iter; left time: 353.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722332 Vali Loss: 0.0872902 Test Loss: 0.0996747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0766864\n",
      "\tspeed: 0.0525s/iter; left time: 688.9114s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704855\n",
      "\tspeed: 0.0265s/iter; left time: 345.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0722141 Vali Loss: 0.0873723 Test Loss: 0.0996596\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0717274\n",
      "\tspeed: 0.0530s/iter; left time: 683.2456s\n",
      "\titers: 200, epoch: 43 | loss: 0.0687616\n",
      "\tspeed: 0.0274s/iter; left time: 350.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0721847 Vali Loss: 0.0872899 Test Loss: 0.0996401\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682925\n",
      "\tspeed: 0.0532s/iter; left time: 673.6730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0717148\n",
      "\tspeed: 0.0267s/iter; left time: 336.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722191 Vali Loss: 0.0873592 Test Loss: 0.0996715\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0739661\n",
      "\tspeed: 0.0526s/iter; left time: 654.3423s\n",
      "\titers: 200, epoch: 45 | loss: 0.0704421\n",
      "\tspeed: 0.0268s/iter; left time: 330.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721614 Vali Loss: 0.0873060 Test Loss: 0.0996651\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0744253\n",
      "\tspeed: 0.0525s/iter; left time: 642.1980s\n",
      "\titers: 200, epoch: 46 | loss: 0.0733730\n",
      "\tspeed: 0.0268s/iter; left time: 324.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0721902 Vali Loss: 0.0871615 Test Loss: 0.0996455\n",
      "Validation loss decreased (0.087227 --> 0.087162).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738844\n",
      "\tspeed: 0.0523s/iter; left time: 627.0182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0732504\n",
      "\tspeed: 0.0265s/iter; left time: 315.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0721966 Vali Loss: 0.0873352 Test Loss: 0.0996582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0738569\n",
      "\tspeed: 0.0522s/iter; left time: 615.0724s\n",
      "\titers: 200, epoch: 48 | loss: 0.0660235\n",
      "\tspeed: 0.0265s/iter; left time: 309.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721567 Vali Loss: 0.0874393 Test Loss: 0.0996577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700567\n",
      "\tspeed: 0.0530s/iter; left time: 611.5923s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708773\n",
      "\tspeed: 0.0268s/iter; left time: 306.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0721437 Vali Loss: 0.0873161 Test Loss: 0.0996556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0701776\n",
      "\tspeed: 0.0522s/iter; left time: 590.7105s\n",
      "\titers: 200, epoch: 50 | loss: 0.0751142\n",
      "\tspeed: 0.0267s/iter; left time: 299.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0721538 Vali Loss: 0.0873739 Test Loss: 0.0996439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0683126\n",
      "\tspeed: 0.0519s/iter; left time: 576.3710s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737489\n",
      "\tspeed: 0.0270s/iter; left time: 297.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721442 Vali Loss: 0.0874031 Test Loss: 0.0996389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0686506\n",
      "\tspeed: 0.0521s/iter; left time: 566.9737s\n",
      "\titers: 200, epoch: 52 | loss: 0.0714018\n",
      "\tspeed: 0.0266s/iter; left time: 286.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0872806 Test Loss: 0.0996446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0680443\n",
      "\tspeed: 0.0520s/iter; left time: 553.8117s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746092\n",
      "\tspeed: 0.0268s/iter; left time: 282.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0721653 Vali Loss: 0.0872594 Test Loss: 0.0996658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0697796\n",
      "\tspeed: 0.0522s/iter; left time: 544.4062s\n",
      "\titers: 200, epoch: 54 | loss: 0.0704911\n",
      "\tspeed: 0.0264s/iter; left time: 273.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721745 Vali Loss: 0.0874115 Test Loss: 0.0996338\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0660143\n",
      "\tspeed: 0.0517s/iter; left time: 527.2257s\n",
      "\titers: 200, epoch: 55 | loss: 0.0712318\n",
      "\tspeed: 0.0265s/iter; left time: 268.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721330 Vali Loss: 0.0873371 Test Loss: 0.0996511\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0705199\n",
      "\tspeed: 0.0519s/iter; left time: 518.3399s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784174\n",
      "\tspeed: 0.0265s/iter; left time: 262.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0721358 Vali Loss: 0.0872928 Test Loss: 0.0996450\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025020133703947067, rmse:0.15817753970623016, mae:0.09964548796415329, rse:0.5456676483154297\n",
      "Intermediate time for GB and pred_len 24: 00h:15m:37.54s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1362466\n",
      "\tspeed: 0.0553s/iter; left time: 1234.0899s\n",
      "\titers: 200, epoch: 1 | loss: 0.1315828\n",
      "\tspeed: 0.0268s/iter; left time: 594.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.1354785 Vali Loss: 0.1317148 Test Loss: 0.1549259\n",
      "Validation loss decreased (inf --> 0.131715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100148\n",
      "\tspeed: 0.0537s/iter; left time: 1185.5225s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011972\n",
      "\tspeed: 0.0269s/iter; left time: 590.6520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1090403 Vali Loss: 0.1182589 Test Loss: 0.1401924\n",
      "Validation loss decreased (0.131715 --> 0.118259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020023\n",
      "\tspeed: 0.0538s/iter; left time: 1174.9266s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028889\n",
      "\tspeed: 0.0270s/iter; left time: 586.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1039733 Vali Loss: 0.1175403 Test Loss: 0.1411576\n",
      "Validation loss decreased (0.118259 --> 0.117540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018276\n",
      "\tspeed: 0.0529s/iter; left time: 1143.3982s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026525\n",
      "\tspeed: 0.0270s/iter; left time: 581.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1026064 Vali Loss: 0.1166299 Test Loss: 0.1399759\n",
      "Validation loss decreased (0.117540 --> 0.116630).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026763\n",
      "\tspeed: 0.0534s/iter; left time: 1144.0695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0943075\n",
      "\tspeed: 0.0268s/iter; left time: 570.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1015074 Vali Loss: 0.1164241 Test Loss: 0.1412032\n",
      "Validation loss decreased (0.116630 --> 0.116424).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1025002\n",
      "\tspeed: 0.0531s/iter; left time: 1123.7738s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032541\n",
      "\tspeed: 0.0271s/iter; left time: 571.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1006094 Vali Loss: 0.1160348 Test Loss: 0.1397788\n",
      "Validation loss decreased (0.116424 --> 0.116035).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038390\n",
      "\tspeed: 0.0535s/iter; left time: 1121.2498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0969341\n",
      "\tspeed: 0.0268s/iter; left time: 559.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0997999 Vali Loss: 0.1159833 Test Loss: 0.1389591\n",
      "Validation loss decreased (0.116035 --> 0.115983).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006562\n",
      "\tspeed: 0.0540s/iter; left time: 1120.2872s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981172\n",
      "\tspeed: 0.0270s/iter; left time: 557.5209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0990484 Vali Loss: 0.1169135 Test Loss: 0.1407297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0989951\n",
      "\tspeed: 0.0535s/iter; left time: 1097.1081s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990440\n",
      "\tspeed: 0.0271s/iter; left time: 553.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0983205 Vali Loss: 0.1171196 Test Loss: 0.1430553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1003540\n",
      "\tspeed: 0.0529s/iter; left time: 1073.5132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0943393\n",
      "\tspeed: 0.0269s/iter; left time: 543.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0977161 Vali Loss: 0.1167704 Test Loss: 0.1415311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969625\n",
      "\tspeed: 0.0539s/iter; left time: 1081.2312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986367\n",
      "\tspeed: 0.0268s/iter; left time: 534.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0971241 Vali Loss: 0.1168764 Test Loss: 0.1429615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012906\n",
      "\tspeed: 0.0530s/iter; left time: 1051.5503s\n",
      "\titers: 200, epoch: 12 | loss: 0.0969430\n",
      "\tspeed: 0.0268s/iter; left time: 529.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0966664 Vali Loss: 0.1162381 Test Loss: 0.1405379\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961613\n",
      "\tspeed: 0.0536s/iter; left time: 1050.6042s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981514\n",
      "\tspeed: 0.0270s/iter; left time: 525.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0962394 Vali Loss: 0.1173263 Test Loss: 0.1436641\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0961513\n",
      "\tspeed: 0.0532s/iter; left time: 1031.3833s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940166\n",
      "\tspeed: 0.0269s/iter; left time: 518.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0958293 Vali Loss: 0.1172846 Test Loss: 0.1412998\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0907448\n",
      "\tspeed: 0.0530s/iter; left time: 1015.5836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0936777\n",
      "\tspeed: 0.0269s/iter; left time: 513.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0954853 Vali Loss: 0.1174681 Test Loss: 0.1431191\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0971071\n",
      "\tspeed: 0.0530s/iter; left time: 1004.5613s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991246\n",
      "\tspeed: 0.0270s/iter; left time: 508.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0951561 Vali Loss: 0.1177430 Test Loss: 0.1433660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0933138\n",
      "\tspeed: 0.0532s/iter; left time: 996.3669s\n",
      "\titers: 200, epoch: 17 | loss: 0.0953560\n",
      "\tspeed: 0.0270s/iter; left time: 502.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0948642 Vali Loss: 0.1173937 Test Loss: 0.1422419\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04156280308961868, rmse:0.20386956632137299, mae:0.138959139585495, rse:0.705009400844574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1342963\n",
      "\tspeed: 0.0294s/iter; left time: 655.5017s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212572\n",
      "\tspeed: 0.0270s/iter; left time: 598.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1354378 Vali Loss: 0.1306439 Test Loss: 0.1532763\n",
      "Validation loss decreased (inf --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1063669\n",
      "\tspeed: 0.0539s/iter; left time: 1190.0957s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015290\n",
      "\tspeed: 0.0268s/iter; left time: 588.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1090908 Vali Loss: 0.1179647 Test Loss: 0.1400083\n",
      "Validation loss decreased (0.130644 --> 0.117965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034727\n",
      "\tspeed: 0.0543s/iter; left time: 1186.3327s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050127\n",
      "\tspeed: 0.0268s/iter; left time: 582.9759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1041194 Vali Loss: 0.1176144 Test Loss: 0.1397710\n",
      "Validation loss decreased (0.117965 --> 0.117614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971245\n",
      "\tspeed: 0.0556s/iter; left time: 1202.5577s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046980\n",
      "\tspeed: 0.0271s/iter; left time: 583.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1028142 Vali Loss: 0.1171384 Test Loss: 0.1404998\n",
      "Validation loss decreased (0.117614 --> 0.117138).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977949\n",
      "\tspeed: 0.0553s/iter; left time: 1182.8713s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043665\n",
      "\tspeed: 0.0268s/iter; left time: 571.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1018217 Vali Loss: 0.1171914 Test Loss: 0.1403327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947371\n",
      "\tspeed: 0.0534s/iter; left time: 1131.0207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1068232\n",
      "\tspeed: 0.0268s/iter; left time: 564.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1010497 Vali Loss: 0.1167937 Test Loss: 0.1400926\n",
      "Validation loss decreased (0.117138 --> 0.116794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955816\n",
      "\tspeed: 0.0545s/iter; left time: 1143.1946s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973860\n",
      "\tspeed: 0.0267s/iter; left time: 557.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1002006 Vali Loss: 0.1169059 Test Loss: 0.1398973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982215\n",
      "\tspeed: 0.0550s/iter; left time: 1140.3708s\n",
      "\titers: 200, epoch: 8 | loss: 0.0986912\n",
      "\tspeed: 0.0269s/iter; left time: 555.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0995622 Vali Loss: 0.1171644 Test Loss: 0.1394792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0983291\n",
      "\tspeed: 0.0544s/iter; left time: 1115.5611s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015055\n",
      "\tspeed: 0.0267s/iter; left time: 544.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0990405 Vali Loss: 0.1170354 Test Loss: 0.1404738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0966749\n",
      "\tspeed: 0.0548s/iter; left time: 1111.2377s\n",
      "\titers: 200, epoch: 10 | loss: 0.0984571\n",
      "\tspeed: 0.0271s/iter; left time: 547.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0984118 Vali Loss: 0.1174196 Test Loss: 0.1405433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945642\n",
      "\tspeed: 0.0554s/iter; left time: 1111.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0937180\n",
      "\tspeed: 0.0268s/iter; left time: 534.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0979818 Vali Loss: 0.1171703 Test Loss: 0.1407737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0964229\n",
      "\tspeed: 0.0543s/iter; left time: 1077.2916s\n",
      "\titers: 200, epoch: 12 | loss: 0.1007808\n",
      "\tspeed: 0.0270s/iter; left time: 533.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0975590 Vali Loss: 0.1174397 Test Loss: 0.1414426\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0947333\n",
      "\tspeed: 0.0534s/iter; left time: 1048.2167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915383\n",
      "\tspeed: 0.0268s/iter; left time: 523.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0971209 Vali Loss: 0.1181216 Test Loss: 0.1418197\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0964207\n",
      "\tspeed: 0.0543s/iter; left time: 1053.2275s\n",
      "\titers: 200, epoch: 14 | loss: 0.0957182\n",
      "\tspeed: 0.0268s/iter; left time: 516.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0966924 Vali Loss: 0.1173833 Test Loss: 0.1408844\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0976923\n",
      "\tspeed: 0.0538s/iter; left time: 1031.1701s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943371\n",
      "\tspeed: 0.0268s/iter; left time: 511.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0964538 Vali Loss: 0.1180992 Test Loss: 0.1427835\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0937670\n",
      "\tspeed: 0.0538s/iter; left time: 1018.7485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0968458\n",
      "\tspeed: 0.0268s/iter; left time: 505.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961151 Vali Loss: 0.1176016 Test Loss: 0.1419638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04211575910449028, rmse:0.2052212506532669, mae:0.1400926262140274, rse:0.7096836566925049\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:39.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354124\n",
      "\tspeed: 0.0554s/iter; left time: 1229.6732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1269919\n",
      "\tspeed: 0.0271s/iter; left time: 599.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.1370751 Vali Loss: 0.1339571 Test Loss: 0.1580050\n",
      "Validation loss decreased (inf --> 0.133957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1144067\n",
      "\tspeed: 0.0538s/iter; left time: 1181.8960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070809\n",
      "\tspeed: 0.0271s/iter; left time: 593.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1134790 Vali Loss: 0.1227112 Test Loss: 0.1471968\n",
      "Validation loss decreased (0.133957 --> 0.122711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099978\n",
      "\tspeed: 0.0546s/iter; left time: 1186.9160s\n",
      "\titers: 200, epoch: 3 | loss: 0.1067006\n",
      "\tspeed: 0.0272s/iter; left time: 588.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1086630 Vali Loss: 0.1216847 Test Loss: 0.1465340\n",
      "Validation loss decreased (0.122711 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087929\n",
      "\tspeed: 0.0553s/iter; left time: 1189.7324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128875\n",
      "\tspeed: 0.0271s/iter; left time: 580.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1071564 Vali Loss: 0.1216329 Test Loss: 0.1464036\n",
      "Validation loss decreased (0.121685 --> 0.121633).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036660\n",
      "\tspeed: 0.0565s/iter; left time: 1204.0028s\n",
      "\titers: 200, epoch: 5 | loss: 0.1098936\n",
      "\tspeed: 0.0271s/iter; left time: 575.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1058232 Vali Loss: 0.1211363 Test Loss: 0.1468929\n",
      "Validation loss decreased (0.121633 --> 0.121136).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023184\n",
      "\tspeed: 0.0551s/iter; left time: 1162.4825s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047149\n",
      "\tspeed: 0.0272s/iter; left time: 570.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1045786 Vali Loss: 0.1214660 Test Loss: 0.1477442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1030283\n",
      "\tspeed: 0.0551s/iter; left time: 1148.7618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983301\n",
      "\tspeed: 0.0274s/iter; left time: 568.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035771 Vali Loss: 0.1215716 Test Loss: 0.1494350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1021642\n",
      "\tspeed: 0.0551s/iter; left time: 1137.1951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1072234\n",
      "\tspeed: 0.0274s/iter; left time: 562.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026726 Vali Loss: 0.1215428 Test Loss: 0.1478654\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027741\n",
      "\tspeed: 0.0555s/iter; left time: 1132.5589s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979295\n",
      "\tspeed: 0.0273s/iter; left time: 554.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1020552 Vali Loss: 0.1213815 Test Loss: 0.1498316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996236\n",
      "\tspeed: 0.0543s/iter; left time: 1096.0517s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013777\n",
      "\tspeed: 0.0273s/iter; left time: 548.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1013867 Vali Loss: 0.1220490 Test Loss: 0.1514326\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994694\n",
      "\tspeed: 0.0553s/iter; left time: 1104.2498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0999421\n",
      "\tspeed: 0.0274s/iter; left time: 543.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1007758 Vali Loss: 0.1213371 Test Loss: 0.1484833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966362\n",
      "\tspeed: 0.0549s/iter; left time: 1083.1968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990719\n",
      "\tspeed: 0.0273s/iter; left time: 535.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1002209 Vali Loss: 0.1218838 Test Loss: 0.1496712\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996767\n",
      "\tspeed: 0.0548s/iter; left time: 1070.0136s\n",
      "\titers: 200, epoch: 13 | loss: 0.1026959\n",
      "\tspeed: 0.0272s/iter; left time: 528.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0997564 Vali Loss: 0.1217964 Test Loss: 0.1501298\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0985504\n",
      "\tspeed: 0.0554s/iter; left time: 1068.8520s\n",
      "\titers: 200, epoch: 14 | loss: 0.0999128\n",
      "\tspeed: 0.0272s/iter; left time: 523.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0993586 Vali Loss: 0.1223004 Test Loss: 0.1509998\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021761\n",
      "\tspeed: 0.0548s/iter; left time: 1045.3280s\n",
      "\titers: 200, epoch: 15 | loss: 0.1022515\n",
      "\tspeed: 0.0273s/iter; left time: 517.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0989366 Vali Loss: 0.1226592 Test Loss: 0.1515421\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459306597709656, rmse:0.21117070317268372, mae:0.14689284563064575, rse:0.7321591973304749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343334\n",
      "\tspeed: 0.0304s/iter; left time: 675.5745s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274043\n",
      "\tspeed: 0.0273s/iter; left time: 604.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1373720 Vali Loss: 0.1342096 Test Loss: 0.1581728\n",
      "Validation loss decreased (inf --> 0.134210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1134263\n",
      "\tspeed: 0.0564s/iter; left time: 1240.0853s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105637\n",
      "\tspeed: 0.0276s/iter; left time: 603.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1132997 Vali Loss: 0.1233650 Test Loss: 0.1481477\n",
      "Validation loss decreased (0.134210 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1110428\n",
      "\tspeed: 0.0561s/iter; left time: 1219.9967s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082572\n",
      "\tspeed: 0.0271s/iter; left time: 587.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1087510 Vali Loss: 0.1223908 Test Loss: 0.1466880\n",
      "Validation loss decreased (0.123365 --> 0.122391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1091575\n",
      "\tspeed: 0.0577s/iter; left time: 1241.7612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072541\n",
      "\tspeed: 0.0274s/iter; left time: 587.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1072281 Vali Loss: 0.1221424 Test Loss: 0.1471605\n",
      "Validation loss decreased (0.122391 --> 0.122142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074684\n",
      "\tspeed: 0.0569s/iter; left time: 1212.2677s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056222\n",
      "\tspeed: 0.0274s/iter; left time: 581.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1056581 Vali Loss: 0.1219717 Test Loss: 0.1469719\n",
      "Validation loss decreased (0.122142 --> 0.121972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063322\n",
      "\tspeed: 0.0565s/iter; left time: 1192.2183s\n",
      "\titers: 200, epoch: 6 | loss: 0.1021206\n",
      "\tspeed: 0.0273s/iter; left time: 572.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1043592 Vali Loss: 0.1220159 Test Loss: 0.1479042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1007787\n",
      "\tspeed: 0.0559s/iter; left time: 1165.4247s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071176\n",
      "\tspeed: 0.0273s/iter; left time: 565.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1034426 Vali Loss: 0.1219470 Test Loss: 0.1468008\n",
      "Validation loss decreased (0.121972 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024007\n",
      "\tspeed: 0.0562s/iter; left time: 1159.3587s\n",
      "\titers: 200, epoch: 8 | loss: 0.1011106\n",
      "\tspeed: 0.0273s/iter; left time: 560.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026371 Vali Loss: 0.1226881 Test Loss: 0.1485755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010926\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1769s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037420\n",
      "\tspeed: 0.0273s/iter; left time: 555.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1018770 Vali Loss: 0.1230170 Test Loss: 0.1505015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995526\n",
      "\tspeed: 0.0558s/iter; left time: 1126.7199s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030146\n",
      "\tspeed: 0.0273s/iter; left time: 549.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1011918 Vali Loss: 0.1236346 Test Loss: 0.1512475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1019870\n",
      "\tspeed: 0.0558s/iter; left time: 1114.2898s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035597\n",
      "\tspeed: 0.0274s/iter; left time: 543.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1005595 Vali Loss: 0.1228452 Test Loss: 0.1502132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1003256\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7425s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002665\n",
      "\tspeed: 0.0273s/iter; left time: 537.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1000163 Vali Loss: 0.1234094 Test Loss: 0.1494783\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1022886\n",
      "\tspeed: 0.0564s/iter; left time: 1101.7633s\n",
      "\titers: 200, epoch: 13 | loss: 0.1002941\n",
      "\tspeed: 0.0274s/iter; left time: 531.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0994505 Vali Loss: 0.1235107 Test Loss: 0.1497943\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975255\n",
      "\tspeed: 0.0559s/iter; left time: 1078.1402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0986446\n",
      "\tspeed: 0.0274s/iter; left time: 526.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0990837 Vali Loss: 0.1231035 Test Loss: 0.1512404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982782\n",
      "\tspeed: 0.0557s/iter; left time: 1061.8515s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003537\n",
      "\tspeed: 0.0273s/iter; left time: 518.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0986666 Vali Loss: 0.1234591 Test Loss: 0.1508010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1010868\n",
      "\tspeed: 0.0562s/iter; left time: 1058.7894s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004014\n",
      "\tspeed: 0.0274s/iter; left time: 513.3969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0983119 Vali Loss: 0.1234264 Test Loss: 0.1515623\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973225\n",
      "\tspeed: 0.0560s/iter; left time: 1042.6396s\n",
      "\titers: 200, epoch: 17 | loss: 0.0972442\n",
      "\tspeed: 0.0271s/iter; left time: 502.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0979932 Vali Loss: 0.1239732 Test Loss: 0.1527091\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486566409468651, rmse:0.21181516349315643, mae:0.14680077135562897, rse:0.7343935966491699\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:39.74s\n",
      "Intermediate time for GB: 00h:24m:56.87s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1297289\n",
      "\tspeed: 0.0455s/iter; left time: 1015.3594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1126045\n",
      "\tspeed: 0.0178s/iter; left time: 395.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1356361 Vali Loss: 0.0979728 Test Loss: 0.1105253\n",
      "Validation loss decreased (inf --> 0.097973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740920\n",
      "\tspeed: 0.0365s/iter; left time: 805.5324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695283\n",
      "\tspeed: 0.0174s/iter; left time: 382.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0769994 Vali Loss: 0.0646745 Test Loss: 0.0711548\n",
      "Validation loss decreased (0.097973 --> 0.064675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641058\n",
      "\tspeed: 0.0361s/iter; left time: 789.8069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0647144\n",
      "\tspeed: 0.0174s/iter; left time: 378.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0655269 Vali Loss: 0.0602642 Test Loss: 0.0665508\n",
      "Validation loss decreased (0.064675 --> 0.060264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620353\n",
      "\tspeed: 0.0359s/iter; left time: 777.5343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641675\n",
      "\tspeed: 0.0180s/iter; left time: 386.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0622778 Vali Loss: 0.0589169 Test Loss: 0.0652260\n",
      "Validation loss decreased (0.060264 --> 0.058917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600411\n",
      "\tspeed: 0.0386s/iter; left time: 827.2866s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605951\n",
      "\tspeed: 0.0208s/iter; left time: 443.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0604136 Vali Loss: 0.0574598 Test Loss: 0.0637832\n",
      "Validation loss decreased (0.058917 --> 0.057460).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0576362\n",
      "\tspeed: 0.0362s/iter; left time: 767.1964s\n",
      "\titers: 200, epoch: 6 | loss: 0.0572372\n",
      "\tspeed: 0.0185s/iter; left time: 389.9134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0592250 Vali Loss: 0.0569232 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.057460 --> 0.056923).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0641758\n",
      "\tspeed: 0.0404s/iter; left time: 847.3156s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604304\n",
      "\tspeed: 0.0228s/iter; left time: 474.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0582727 Vali Loss: 0.0563158 Test Loss: 0.0624014\n",
      "Validation loss decreased (0.056923 --> 0.056316).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597004\n",
      "\tspeed: 0.0397s/iter; left time: 823.0412s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545038\n",
      "\tspeed: 0.0217s/iter; left time: 448.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0575341 Vali Loss: 0.0555614 Test Loss: 0.0619747\n",
      "Validation loss decreased (0.056316 --> 0.055561).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581241\n",
      "\tspeed: 0.0373s/iter; left time: 764.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0560733\n",
      "\tspeed: 0.0177s/iter; left time: 361.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0569077 Vali Loss: 0.0551520 Test Loss: 0.0613294\n",
      "Validation loss decreased (0.055561 --> 0.055152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600654\n",
      "\tspeed: 0.0369s/iter; left time: 748.1508s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543051\n",
      "\tspeed: 0.0173s/iter; left time: 349.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0564565 Vali Loss: 0.0552002 Test Loss: 0.0615373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0573782\n",
      "\tspeed: 0.0354s/iter; left time: 710.7419s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561891\n",
      "\tspeed: 0.0173s/iter; left time: 346.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0560166 Vali Loss: 0.0547021 Test Loss: 0.0608617\n",
      "Validation loss decreased (0.055152 --> 0.054702).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549166\n",
      "\tspeed: 0.0368s/iter; left time: 730.5754s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550303\n",
      "\tspeed: 0.0175s/iter; left time: 345.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0556077 Vali Loss: 0.0544642 Test Loss: 0.0607819\n",
      "Validation loss decreased (0.054702 --> 0.054464).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530001\n",
      "\tspeed: 0.0374s/iter; left time: 734.4276s\n",
      "\titers: 200, epoch: 13 | loss: 0.0505261\n",
      "\tspeed: 0.0172s/iter; left time: 336.1488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0553481 Vali Loss: 0.0544108 Test Loss: 0.0603867\n",
      "Validation loss decreased (0.054464 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576824\n",
      "\tspeed: 0.0382s/iter; left time: 741.3690s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537340\n",
      "\tspeed: 0.0180s/iter; left time: 347.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0550210 Vali Loss: 0.0542770 Test Loss: 0.0605504\n",
      "Validation loss decreased (0.054411 --> 0.054277).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0541440\n",
      "\tspeed: 0.0374s/iter; left time: 716.8168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551845\n",
      "\tspeed: 0.0176s/iter; left time: 336.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0547780 Vali Loss: 0.0540772 Test Loss: 0.0603587\n",
      "Validation loss decreased (0.054277 --> 0.054077).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509629\n",
      "\tspeed: 0.0377s/iter; left time: 714.1568s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555559\n",
      "\tspeed: 0.0201s/iter; left time: 379.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0545937 Vali Loss: 0.0540071 Test Loss: 0.0602936\n",
      "Validation loss decreased (0.054077 --> 0.054007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533449\n",
      "\tspeed: 0.0376s/iter; left time: 702.8441s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549480\n",
      "\tspeed: 0.0232s/iter; left time: 431.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543840 Vali Loss: 0.0535351 Test Loss: 0.0598909\n",
      "Validation loss decreased (0.054007 --> 0.053535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534377\n",
      "\tspeed: 0.0413s/iter; left time: 763.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519669\n",
      "\tspeed: 0.0180s/iter; left time: 330.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0541835 Vali Loss: 0.0535182 Test Loss: 0.0599301\n",
      "Validation loss decreased (0.053535 --> 0.053518).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546421\n",
      "\tspeed: 0.0365s/iter; left time: 666.7154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532574\n",
      "\tspeed: 0.0173s/iter; left time: 315.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0541097 Vali Loss: 0.0536294 Test Loss: 0.0598268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540954\n",
      "\tspeed: 0.0388s/iter; left time: 699.9337s\n",
      "\titers: 200, epoch: 20 | loss: 0.0566773\n",
      "\tspeed: 0.0218s/iter; left time: 391.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0538978 Vali Loss: 0.0535801 Test Loss: 0.0599190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0543947\n",
      "\tspeed: 0.0428s/iter; left time: 762.3693s\n",
      "\titers: 200, epoch: 21 | loss: 0.0548367\n",
      "\tspeed: 0.0209s/iter; left time: 369.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0537692 Vali Loss: 0.0534152 Test Loss: 0.0598009\n",
      "Validation loss decreased (0.053518 --> 0.053415).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549492\n",
      "\tspeed: 0.0444s/iter; left time: 780.6195s\n",
      "\titers: 200, epoch: 22 | loss: 0.0514017\n",
      "\tspeed: 0.0198s/iter; left time: 346.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0537207 Vali Loss: 0.0533374 Test Loss: 0.0596908\n",
      "Validation loss decreased (0.053415 --> 0.053337).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0534591\n",
      "\tspeed: 0.0393s/iter; left time: 682.3595s\n",
      "\titers: 200, epoch: 23 | loss: 0.0526582\n",
      "\tspeed: 0.0216s/iter; left time: 372.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0536544 Vali Loss: 0.0533163 Test Loss: 0.0596185\n",
      "Validation loss decreased (0.053337 --> 0.053316).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0538955\n",
      "\tspeed: 0.0382s/iter; left time: 655.3983s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538660\n",
      "\tspeed: 0.0208s/iter; left time: 354.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0535522 Vali Loss: 0.0532527 Test Loss: 0.0594967\n",
      "Validation loss decreased (0.053316 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573650\n",
      "\tspeed: 0.0380s/iter; left time: 643.7574s\n",
      "\titers: 200, epoch: 25 | loss: 0.0528080\n",
      "\tspeed: 0.0178s/iter; left time: 300.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0534546 Vali Loss: 0.0532459 Test Loss: 0.0595710\n",
      "Validation loss decreased (0.053253 --> 0.053246).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537234\n",
      "\tspeed: 0.0401s/iter; left time: 669.8796s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546586\n",
      "\tspeed: 0.0176s/iter; left time: 292.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0533645 Vali Loss: 0.0533376 Test Loss: 0.0595235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516834\n",
      "\tspeed: 0.0371s/iter; left time: 610.6094s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571585\n",
      "\tspeed: 0.0177s/iter; left time: 289.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0532839 Vali Loss: 0.0533172 Test Loss: 0.0594809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0494189\n",
      "\tspeed: 0.0375s/iter; left time: 610.2077s\n",
      "\titers: 200, epoch: 28 | loss: 0.0522387\n",
      "\tspeed: 0.0174s/iter; left time: 281.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0533023 Vali Loss: 0.0531314 Test Loss: 0.0593853\n",
      "Validation loss decreased (0.053246 --> 0.053131).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0519411\n",
      "\tspeed: 0.0371s/iter; left time: 594.9347s\n",
      "\titers: 200, epoch: 29 | loss: 0.0522147\n",
      "\tspeed: 0.0180s/iter; left time: 286.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0532008 Vali Loss: 0.0530601 Test Loss: 0.0593986\n",
      "Validation loss decreased (0.053131 --> 0.053060).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523858\n",
      "\tspeed: 0.0420s/iter; left time: 664.5347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0539169\n",
      "\tspeed: 0.0184s/iter; left time: 288.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0532031 Vali Loss: 0.0530461 Test Loss: 0.0593301\n",
      "Validation loss decreased (0.053060 --> 0.053046).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542132\n",
      "\tspeed: 0.0406s/iter; left time: 633.3297s\n",
      "\titers: 200, epoch: 31 | loss: 0.0558742\n",
      "\tspeed: 0.0176s/iter; left time: 272.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0531557 Vali Loss: 0.0529637 Test Loss: 0.0594197\n",
      "Validation loss decreased (0.053046 --> 0.052964).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531322\n",
      "\tspeed: 0.0409s/iter; left time: 627.4583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0507826\n",
      "\tspeed: 0.0204s/iter; left time: 310.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531287 Vali Loss: 0.0530666 Test Loss: 0.0593458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0550206\n",
      "\tspeed: 0.0367s/iter; left time: 555.3600s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542851\n",
      "\tspeed: 0.0176s/iter; left time: 264.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0531302 Vali Loss: 0.0529413 Test Loss: 0.0592580\n",
      "Validation loss decreased (0.052964 --> 0.052941).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0553355\n",
      "\tspeed: 0.0431s/iter; left time: 642.1845s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519135\n",
      "\tspeed: 0.0197s/iter; left time: 292.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0530112 Vali Loss: 0.0529859 Test Loss: 0.0593040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532875\n",
      "\tspeed: 0.0362s/iter; left time: 530.9979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0528023\n",
      "\tspeed: 0.0181s/iter; left time: 264.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0530626 Vali Loss: 0.0530781 Test Loss: 0.0593102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0557845\n",
      "\tspeed: 0.0373s/iter; left time: 539.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521810\n",
      "\tspeed: 0.0176s/iter; left time: 252.7647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529679 Vali Loss: 0.0529296 Test Loss: 0.0592321\n",
      "Validation loss decreased (0.052941 --> 0.052930).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0516731\n",
      "\tspeed: 0.0358s/iter; left time: 510.3623s\n",
      "\titers: 200, epoch: 37 | loss: 0.0540236\n",
      "\tspeed: 0.0172s/iter; left time: 243.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0529866 Vali Loss: 0.0529916 Test Loss: 0.0592840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0508000\n",
      "\tspeed: 0.0362s/iter; left time: 507.2096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547213\n",
      "\tspeed: 0.0175s/iter; left time: 244.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0529485 Vali Loss: 0.0529122 Test Loss: 0.0592196\n",
      "Validation loss decreased (0.052930 --> 0.052912).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0529043\n",
      "\tspeed: 0.0439s/iter; left time: 605.4128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516311\n",
      "\tspeed: 0.0246s/iter; left time: 337.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0528965 Test Loss: 0.0592480\n",
      "Validation loss decreased (0.052912 --> 0.052897).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0494722\n",
      "\tspeed: 0.0396s/iter; left time: 537.3741s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527704\n",
      "\tspeed: 0.0175s/iter; left time: 235.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528899 Vali Loss: 0.0529518 Test Loss: 0.0593059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0527010\n",
      "\tspeed: 0.0354s/iter; left time: 471.6542s\n",
      "\titers: 200, epoch: 41 | loss: 0.0523881\n",
      "\tspeed: 0.0176s/iter; left time: 232.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529096 Vali Loss: 0.0528782 Test Loss: 0.0592054\n",
      "Validation loss decreased (0.052897 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0550479\n",
      "\tspeed: 0.0420s/iter; left time: 550.5007s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528131\n",
      "\tspeed: 0.0175s/iter; left time: 227.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0529324 Vali Loss: 0.0529419 Test Loss: 0.0592431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511567\n",
      "\tspeed: 0.0449s/iter; left time: 578.9241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0510774\n",
      "\tspeed: 0.0215s/iter; left time: 275.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0528664 Vali Loss: 0.0529480 Test Loss: 0.0592471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547131\n",
      "\tspeed: 0.0377s/iter; left time: 478.0473s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535225\n",
      "\tspeed: 0.0176s/iter; left time: 220.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0529409 Vali Loss: 0.0529403 Test Loss: 0.0591982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0499585\n",
      "\tspeed: 0.0368s/iter; left time: 458.5532s\n",
      "\titers: 200, epoch: 45 | loss: 0.0560696\n",
      "\tspeed: 0.0211s/iter; left time: 260.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0528784 Vali Loss: 0.0529030 Test Loss: 0.0592152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0512092\n",
      "\tspeed: 0.0385s/iter; left time: 470.9820s\n",
      "\titers: 200, epoch: 46 | loss: 0.0548510\n",
      "\tspeed: 0.0178s/iter; left time: 216.1218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0528416 Vali Loss: 0.0529498 Test Loss: 0.0591846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0539514\n",
      "\tspeed: 0.0358s/iter; left time: 429.2966s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507728\n",
      "\tspeed: 0.0174s/iter; left time: 207.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0528806 Vali Loss: 0.0529439 Test Loss: 0.0591778\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547237\n",
      "\tspeed: 0.0360s/iter; left time: 423.9098s\n",
      "\titers: 200, epoch: 48 | loss: 0.0500909\n",
      "\tspeed: 0.0175s/iter; left time: 204.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0528072 Vali Loss: 0.0529146 Test Loss: 0.0592384\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0538362\n",
      "\tspeed: 0.0378s/iter; left time: 436.7830s\n",
      "\titers: 200, epoch: 49 | loss: 0.0551731\n",
      "\tspeed: 0.0176s/iter; left time: 201.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0528127 Vali Loss: 0.0528409 Test Loss: 0.0591774\n",
      "Validation loss decreased (0.052878 --> 0.052841).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547548\n",
      "\tspeed: 0.0363s/iter; left time: 410.5844s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522613\n",
      "\tspeed: 0.0175s/iter; left time: 196.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0528483 Vali Loss: 0.0529676 Test Loss: 0.0592235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0515651\n",
      "\tspeed: 0.0434s/iter; left time: 482.0306s\n",
      "\titers: 200, epoch: 51 | loss: 0.0519167\n",
      "\tspeed: 0.0205s/iter; left time: 225.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0528751 Vali Loss: 0.0528772 Test Loss: 0.0591687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0547058\n",
      "\tspeed: 0.0394s/iter; left time: 428.2818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0527426\n",
      "\tspeed: 0.0233s/iter; left time: 251.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0528348 Vali Loss: 0.0528290 Test Loss: 0.0591753\n",
      "Validation loss decreased (0.052841 --> 0.052829).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529373\n",
      "\tspeed: 0.0379s/iter; left time: 404.1027s\n",
      "\titers: 200, epoch: 53 | loss: 0.0567268\n",
      "\tspeed: 0.0182s/iter; left time: 192.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0528269 Vali Loss: 0.0528880 Test Loss: 0.0591835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0536679\n",
      "\tspeed: 0.0388s/iter; left time: 404.9540s\n",
      "\titers: 200, epoch: 54 | loss: 0.0512394\n",
      "\tspeed: 0.0189s/iter; left time: 195.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0527903 Vali Loss: 0.0528845 Test Loss: 0.0591716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0511981\n",
      "\tspeed: 0.0394s/iter; left time: 401.7271s\n",
      "\titers: 200, epoch: 55 | loss: 0.0518198\n",
      "\tspeed: 0.0175s/iter; left time: 176.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0527804 Vali Loss: 0.0528382 Test Loss: 0.0591643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0501965\n",
      "\tspeed: 0.0377s/iter; left time: 376.6580s\n",
      "\titers: 200, epoch: 56 | loss: 0.0531978\n",
      "\tspeed: 0.0177s/iter; left time: 175.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0528132 Vali Loss: 0.0529282 Test Loss: 0.0592545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0523530\n",
      "\tspeed: 0.0383s/iter; left time: 373.5001s\n",
      "\titers: 200, epoch: 57 | loss: 0.0532235\n",
      "\tspeed: 0.0188s/iter; left time: 181.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0528334 Vali Loss: 0.0528543 Test Loss: 0.0591806\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0517060\n",
      "\tspeed: 0.0385s/iter; left time: 367.0567s\n",
      "\titers: 200, epoch: 58 | loss: 0.0537203\n",
      "\tspeed: 0.0222s/iter; left time: 209.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0528633 Vali Loss: 0.0529062 Test Loss: 0.0591597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0542901\n",
      "\tspeed: 0.0444s/iter; left time: 413.4854s\n",
      "\titers: 200, epoch: 59 | loss: 0.0490207\n",
      "\tspeed: 0.0196s/iter; left time: 180.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0527814 Vali Loss: 0.0528723 Test Loss: 0.0591480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0534826\n",
      "\tspeed: 0.0398s/iter; left time: 361.2870s\n",
      "\titers: 200, epoch: 60 | loss: 0.0522820\n",
      "\tspeed: 0.0175s/iter; left time: 157.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0528065 Vali Loss: 0.0528880 Test Loss: 0.0591799\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0541162\n",
      "\tspeed: 0.0382s/iter; left time: 338.2691s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526189\n",
      "\tspeed: 0.0199s/iter; left time: 174.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0528557 Vali Loss: 0.0528851 Test Loss: 0.0591978\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0529211\n",
      "\tspeed: 0.0372s/iter; left time: 321.3345s\n",
      "\titers: 200, epoch: 62 | loss: 0.0479516\n",
      "\tspeed: 0.0172s/iter; left time: 147.0690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0527867 Vali Loss: 0.0529483 Test Loss: 0.0591934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009751381352543831, rmse:0.0987490862607956, mae:0.05917529761791229, rse:0.29060661792755127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337921\n",
      "\tspeed: 0.0206s/iter; left time: 458.7822s\n",
      "\titers: 200, epoch: 1 | loss: 0.1069674\n",
      "\tspeed: 0.0206s/iter; left time: 458.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1356587 Vali Loss: 0.0968538 Test Loss: 0.1094441\n",
      "Validation loss decreased (inf --> 0.096854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746105\n",
      "\tspeed: 0.0394s/iter; left time: 869.6349s\n",
      "\titers: 200, epoch: 2 | loss: 0.0701489\n",
      "\tspeed: 0.0175s/iter; left time: 385.2628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0639559 Test Loss: 0.0706353\n",
      "Validation loss decreased (0.096854 --> 0.063956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675678\n",
      "\tspeed: 0.0370s/iter; left time: 807.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0615702\n",
      "\tspeed: 0.0174s/iter; left time: 379.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0655629 Vali Loss: 0.0605291 Test Loss: 0.0668655\n",
      "Validation loss decreased (0.063956 --> 0.060529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629944\n",
      "\tspeed: 0.0368s/iter; left time: 795.4977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0648704\n",
      "\tspeed: 0.0183s/iter; left time: 393.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0625614 Vali Loss: 0.0589684 Test Loss: 0.0655182\n",
      "Validation loss decreased (0.060529 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588870\n",
      "\tspeed: 0.0402s/iter; left time: 860.9520s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.0176s/iter; left time: 375.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0606106 Vali Loss: 0.0578980 Test Loss: 0.0645265\n",
      "Validation loss decreased (0.058968 --> 0.057898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592575\n",
      "\tspeed: 0.0370s/iter; left time: 782.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571381\n",
      "\tspeed: 0.0175s/iter; left time: 368.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593913 Vali Loss: 0.0566761 Test Loss: 0.0631738\n",
      "Validation loss decreased (0.057898 --> 0.056676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611145\n",
      "\tspeed: 0.0367s/iter; left time: 769.3887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605097\n",
      "\tspeed: 0.0174s/iter; left time: 362.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0583720 Vali Loss: 0.0562617 Test Loss: 0.0624770\n",
      "Validation loss decreased (0.056676 --> 0.056262).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629369\n",
      "\tspeed: 0.0418s/iter; left time: 866.8303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618621\n",
      "\tspeed: 0.0217s/iter; left time: 447.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0576425 Vali Loss: 0.0556517 Test Loss: 0.0618897\n",
      "Validation loss decreased (0.056262 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606712\n",
      "\tspeed: 0.0427s/iter; left time: 875.6113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555764\n",
      "\tspeed: 0.0222s/iter; left time: 453.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0555573 Test Loss: 0.0616752\n",
      "Validation loss decreased (0.055652 --> 0.055557).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596933\n",
      "\tspeed: 0.0453s/iter; left time: 919.0482s\n",
      "\titers: 200, epoch: 10 | loss: 0.0554582\n",
      "\tspeed: 0.0227s/iter; left time: 457.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0565138 Vali Loss: 0.0551991 Test Loss: 0.0614132\n",
      "Validation loss decreased (0.055557 --> 0.055199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0616147\n",
      "\tspeed: 0.0387s/iter; left time: 776.9877s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578825\n",
      "\tspeed: 0.0174s/iter; left time: 348.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0561789 Vali Loss: 0.0549304 Test Loss: 0.0611437\n",
      "Validation loss decreased (0.055199 --> 0.054930).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0537045\n",
      "\tspeed: 0.0367s/iter; left time: 727.8192s\n",
      "\titers: 200, epoch: 12 | loss: 0.0578890\n",
      "\tspeed: 0.0176s/iter; left time: 347.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0557681 Vali Loss: 0.0547644 Test Loss: 0.0607991\n",
      "Validation loss decreased (0.054930 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570883\n",
      "\tspeed: 0.0426s/iter; left time: 835.6845s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543759\n",
      "\tspeed: 0.0178s/iter; left time: 347.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0554576 Vali Loss: 0.0546486 Test Loss: 0.0609315\n",
      "Validation loss decreased (0.054764 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559569\n",
      "\tspeed: 0.0405s/iter; left time: 784.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576939\n",
      "\tspeed: 0.0206s/iter; left time: 397.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0551173 Vali Loss: 0.0543713 Test Loss: 0.0607464\n",
      "Validation loss decreased (0.054649 --> 0.054371).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574309\n",
      "\tspeed: 0.0404s/iter; left time: 773.9555s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533791\n",
      "\tspeed: 0.0193s/iter; left time: 367.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0548902 Vali Loss: 0.0541163 Test Loss: 0.0603891\n",
      "Validation loss decreased (0.054371 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0560301\n",
      "\tspeed: 0.0400s/iter; left time: 758.5325s\n",
      "\titers: 200, epoch: 16 | loss: 0.0556359\n",
      "\tspeed: 0.0215s/iter; left time: 404.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0546661 Vali Loss: 0.0540735 Test Loss: 0.0603688\n",
      "Validation loss decreased (0.054116 --> 0.054073).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567861\n",
      "\tspeed: 0.0400s/iter; left time: 749.0467s\n",
      "\titers: 200, epoch: 17 | loss: 0.0534253\n",
      "\tspeed: 0.0173s/iter; left time: 321.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0545065 Vali Loss: 0.0539584 Test Loss: 0.0603209\n",
      "Validation loss decreased (0.054073 --> 0.053958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0544936\n",
      "\tspeed: 0.0390s/iter; left time: 721.0882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0505661\n",
      "\tspeed: 0.0215s/iter; left time: 394.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0542611 Vali Loss: 0.0537714 Test Loss: 0.0600516\n",
      "Validation loss decreased (0.053958 --> 0.053771).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572401\n",
      "\tspeed: 0.0395s/iter; left time: 720.9557s\n",
      "\titers: 200, epoch: 19 | loss: 0.0509766\n",
      "\tspeed: 0.0203s/iter; left time: 368.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541876 Vali Loss: 0.0537230 Test Loss: 0.0601269\n",
      "Validation loss decreased (0.053771 --> 0.053723).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0581672\n",
      "\tspeed: 0.0391s/iter; left time: 704.9706s\n",
      "\titers: 200, epoch: 20 | loss: 0.0560375\n",
      "\tspeed: 0.0176s/iter; left time: 316.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540584 Vali Loss: 0.0535869 Test Loss: 0.0598196\n",
      "Validation loss decreased (0.053723 --> 0.053587).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0489908\n",
      "\tspeed: 0.0382s/iter; left time: 680.8923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556523\n",
      "\tspeed: 0.0175s/iter; left time: 310.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0539873 Vali Loss: 0.0535157 Test Loss: 0.0598667\n",
      "Validation loss decreased (0.053587 --> 0.053516).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0564136\n",
      "\tspeed: 0.0368s/iter; left time: 647.5133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0507003\n",
      "\tspeed: 0.0175s/iter; left time: 305.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0538451 Vali Loss: 0.0534693 Test Loss: 0.0597156\n",
      "Validation loss decreased (0.053516 --> 0.053469).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0500772\n",
      "\tspeed: 0.0375s/iter; left time: 651.1026s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531840\n",
      "\tspeed: 0.0175s/iter; left time: 301.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0537557 Vali Loss: 0.0533803 Test Loss: 0.0598192\n",
      "Validation loss decreased (0.053469 --> 0.053380).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0520380\n",
      "\tspeed: 0.0453s/iter; left time: 776.9973s\n",
      "\titers: 200, epoch: 24 | loss: 0.0564743\n",
      "\tspeed: 0.0176s/iter; left time: 300.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0536120 Vali Loss: 0.0534145 Test Loss: 0.0596311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0510081\n",
      "\tspeed: 0.0377s/iter; left time: 638.7096s\n",
      "\titers: 200, epoch: 25 | loss: 0.0502159\n",
      "\tspeed: 0.0174s/iter; left time: 293.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0535521 Vali Loss: 0.0534059 Test Loss: 0.0596591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0510387\n",
      "\tspeed: 0.0371s/iter; left time: 620.4239s\n",
      "\titers: 200, epoch: 26 | loss: 0.0527924\n",
      "\tspeed: 0.0177s/iter; left time: 293.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0534718 Vali Loss: 0.0533074 Test Loss: 0.0596614\n",
      "Validation loss decreased (0.053380 --> 0.053307).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0546484\n",
      "\tspeed: 0.0363s/iter; left time: 597.5156s\n",
      "\titers: 200, epoch: 27 | loss: 0.0502867\n",
      "\tspeed: 0.0173s/iter; left time: 283.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0534427 Vali Loss: 0.0532914 Test Loss: 0.0595673\n",
      "Validation loss decreased (0.053307 --> 0.053291).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513472\n",
      "\tspeed: 0.0380s/iter; left time: 617.8899s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544608\n",
      "\tspeed: 0.0177s/iter; left time: 286.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0534265 Vali Loss: 0.0533097 Test Loss: 0.0595132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543246\n",
      "\tspeed: 0.0378s/iter; left time: 606.4173s\n",
      "\titers: 200, epoch: 29 | loss: 0.0545000\n",
      "\tspeed: 0.0175s/iter; left time: 278.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0533031 Vali Loss: 0.0533129 Test Loss: 0.0596252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578123\n",
      "\tspeed: 0.0384s/iter; left time: 606.5506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523473\n",
      "\tspeed: 0.0175s/iter; left time: 275.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0532915 Vali Loss: 0.0531913 Test Loss: 0.0594889\n",
      "Validation loss decreased (0.053291 --> 0.053191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544150\n",
      "\tspeed: 0.0371s/iter; left time: 578.5391s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515520\n",
      "\tspeed: 0.0175s/iter; left time: 270.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0532813 Vali Loss: 0.0531744 Test Loss: 0.0595354\n",
      "Validation loss decreased (0.053191 --> 0.053174).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559174\n",
      "\tspeed: 0.0378s/iter; left time: 580.8415s\n",
      "\titers: 200, epoch: 32 | loss: 0.0526729\n",
      "\tspeed: 0.0173s/iter; left time: 264.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0532091 Vali Loss: 0.0531425 Test Loss: 0.0594587\n",
      "Validation loss decreased (0.053174 --> 0.053143).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0532093\n",
      "\tspeed: 0.0366s/iter; left time: 553.8593s\n",
      "\titers: 200, epoch: 33 | loss: 0.0478663\n",
      "\tspeed: 0.0173s/iter; left time: 259.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0531877 Vali Loss: 0.0531788 Test Loss: 0.0594424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0499334\n",
      "\tspeed: 0.0370s/iter; left time: 551.6185s\n",
      "\titers: 200, epoch: 34 | loss: 0.0506587\n",
      "\tspeed: 0.0175s/iter; left time: 259.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0531430 Vali Loss: 0.0531837 Test Loss: 0.0594441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517330\n",
      "\tspeed: 0.0424s/iter; left time: 622.5793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0551342\n",
      "\tspeed: 0.0203s/iter; left time: 295.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0531663 Vali Loss: 0.0531581 Test Loss: 0.0594528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506947\n",
      "\tspeed: 0.0403s/iter; left time: 582.4848s\n",
      "\titers: 200, epoch: 36 | loss: 0.0583177\n",
      "\tspeed: 0.0203s/iter; left time: 291.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531392 Vali Loss: 0.0531340 Test Loss: 0.0594451\n",
      "Validation loss decreased (0.053143 --> 0.053134).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542479\n",
      "\tspeed: 0.0454s/iter; left time: 646.6699s\n",
      "\titers: 200, epoch: 37 | loss: 0.0510775\n",
      "\tspeed: 0.0217s/iter; left time: 306.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0530918 Vali Loss: 0.0530867 Test Loss: 0.0593737\n",
      "Validation loss decreased (0.053134 --> 0.053087).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556557\n",
      "\tspeed: 0.0396s/iter; left time: 554.6645s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513426\n",
      "\tspeed: 0.0202s/iter; left time: 281.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0530756 Vali Loss: 0.0531610 Test Loss: 0.0594667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526359\n",
      "\tspeed: 0.0394s/iter; left time: 543.4934s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522014\n",
      "\tspeed: 0.0172s/iter; left time: 235.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0530237 Vali Loss: 0.0530525 Test Loss: 0.0593700\n",
      "Validation loss decreased (0.053087 --> 0.053052).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0489786\n",
      "\tspeed: 0.0409s/iter; left time: 554.8960s\n",
      "\titers: 200, epoch: 40 | loss: 0.0538423\n",
      "\tspeed: 0.0191s/iter; left time: 257.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0530496 Vali Loss: 0.0531109 Test Loss: 0.0593490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0539034\n",
      "\tspeed: 0.0382s/iter; left time: 508.9971s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502612\n",
      "\tspeed: 0.0201s/iter; left time: 266.3523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0529953 Vali Loss: 0.0531376 Test Loss: 0.0593575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509308\n",
      "\tspeed: 0.0407s/iter; left time: 533.3291s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528011\n",
      "\tspeed: 0.0203s/iter; left time: 264.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0530408 Vali Loss: 0.0531074 Test Loss: 0.0593930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536508\n",
      "\tspeed: 0.0398s/iter; left time: 513.6043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0535419\n",
      "\tspeed: 0.0209s/iter; left time: 267.6998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0530064 Vali Loss: 0.0531483 Test Loss: 0.0593524\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0534231\n",
      "\tspeed: 0.0422s/iter; left time: 534.2851s\n",
      "\titers: 200, epoch: 44 | loss: 0.0485632\n",
      "\tspeed: 0.0199s/iter; left time: 250.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0529402 Vali Loss: 0.0530934 Test Loss: 0.0593843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504932\n",
      "\tspeed: 0.0404s/iter; left time: 502.4356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0521229\n",
      "\tspeed: 0.0174s/iter; left time: 214.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0530215 Vali Loss: 0.0530575 Test Loss: 0.0593451\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0538279\n",
      "\tspeed: 0.0362s/iter; left time: 442.9136s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554503\n",
      "\tspeed: 0.0174s/iter; left time: 211.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529353 Vali Loss: 0.0530863 Test Loss: 0.0592994\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0534511\n",
      "\tspeed: 0.0370s/iter; left time: 444.1844s\n",
      "\titers: 200, epoch: 47 | loss: 0.0537172\n",
      "\tspeed: 0.0176s/iter; left time: 208.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0529956 Vali Loss: 0.0529808 Test Loss: 0.0593239\n",
      "Validation loss decreased (0.053052 --> 0.052981).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0545642\n",
      "\tspeed: 0.0414s/iter; left time: 487.0466s\n",
      "\titers: 200, epoch: 48 | loss: 0.0503907\n",
      "\tspeed: 0.0176s/iter; left time: 205.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0529698 Vali Loss: 0.0530103 Test Loss: 0.0593279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0509437\n",
      "\tspeed: 0.0385s/iter; left time: 444.9423s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518087\n",
      "\tspeed: 0.0175s/iter; left time: 200.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0529407 Vali Loss: 0.0531188 Test Loss: 0.0594364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0541317\n",
      "\tspeed: 0.0405s/iter; left time: 458.9719s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539311\n",
      "\tspeed: 0.0204s/iter; left time: 228.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0529140 Vali Loss: 0.0530143 Test Loss: 0.0593071\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0535859\n",
      "\tspeed: 0.0379s/iter; left time: 421.0638s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555147\n",
      "\tspeed: 0.0172s/iter; left time: 189.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0529585 Vali Loss: 0.0530431 Test Loss: 0.0593245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0542467\n",
      "\tspeed: 0.0359s/iter; left time: 390.8151s\n",
      "\titers: 200, epoch: 52 | loss: 0.0480840\n",
      "\tspeed: 0.0176s/iter; left time: 189.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0530876 Test Loss: 0.0593659\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0522306\n",
      "\tspeed: 0.0385s/iter; left time: 410.1747s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510478\n",
      "\tspeed: 0.0195s/iter; left time: 205.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0529877 Vali Loss: 0.0530985 Test Loss: 0.0593327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0538847\n",
      "\tspeed: 0.0378s/iter; left time: 394.1452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0531133\n",
      "\tspeed: 0.0174s/iter; left time: 179.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0529167 Vali Loss: 0.0530712 Test Loss: 0.0593545\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534907\n",
      "\tspeed: 0.0399s/iter; left time: 407.1084s\n",
      "\titers: 200, epoch: 55 | loss: 0.0500412\n",
      "\tspeed: 0.0200s/iter; left time: 202.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0529414 Vali Loss: 0.0530433 Test Loss: 0.0593276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0530696\n",
      "\tspeed: 0.0400s/iter; left time: 398.8456s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546860\n",
      "\tspeed: 0.0176s/iter; left time: 173.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0529148 Vali Loss: 0.0530499 Test Loss: 0.0593268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0518850\n",
      "\tspeed: 0.0382s/iter; left time: 372.5004s\n",
      "\titers: 200, epoch: 57 | loss: 0.0534603\n",
      "\tspeed: 0.0229s/iter; left time: 221.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0529192 Vali Loss: 0.0530396 Test Loss: 0.0593469\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009775502607226372, rmse:0.0988711416721344, mae:0.05932391434907913, rse:0.29096582531929016\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:39.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1329530\n",
      "\tspeed: 0.0443s/iter; left time: 987.1059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160002\n",
      "\tspeed: 0.0176s/iter; left time: 390.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1391902 Vali Loss: 0.1071772 Test Loss: 0.1206293\n",
      "Validation loss decreased (inf --> 0.107177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0942523\n",
      "\tspeed: 0.0385s/iter; left time: 850.8737s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861847\n",
      "\tspeed: 0.0185s/iter; left time: 406.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0945715 Vali Loss: 0.0842465 Test Loss: 0.0952013\n",
      "Validation loss decreased (0.107177 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845243\n",
      "\tspeed: 0.0382s/iter; left time: 834.0629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815090\n",
      "\tspeed: 0.0181s/iter; left time: 393.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0807858 Test Loss: 0.0915264\n",
      "Validation loss decreased (0.084247 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820356\n",
      "\tspeed: 0.0378s/iter; left time: 816.7261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805881\n",
      "\tspeed: 0.0176s/iter; left time: 378.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0823000 Vali Loss: 0.0797732 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.080786 --> 0.079773).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798331\n",
      "\tspeed: 0.0379s/iter; left time: 810.5959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755010\n",
      "\tspeed: 0.0177s/iter; left time: 376.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0804131 Vali Loss: 0.0779141 Test Loss: 0.0881555\n",
      "Validation loss decreased (0.079773 --> 0.077914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0796704\n",
      "\tspeed: 0.0375s/iter; left time: 793.5661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799784\n",
      "\tspeed: 0.0176s/iter; left time: 371.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0789057 Vali Loss: 0.0770733 Test Loss: 0.0876542\n",
      "Validation loss decreased (0.077914 --> 0.077073).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788884\n",
      "\tspeed: 0.0376s/iter; left time: 788.3541s\n",
      "\titers: 200, epoch: 7 | loss: 0.0752197\n",
      "\tspeed: 0.0177s/iter; left time: 368.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777904 Vali Loss: 0.0771061 Test Loss: 0.0872416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774317\n",
      "\tspeed: 0.0376s/iter; left time: 779.7228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751686\n",
      "\tspeed: 0.0205s/iter; left time: 423.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0770810 Vali Loss: 0.0767934 Test Loss: 0.0870996\n",
      "Validation loss decreased (0.077073 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771739\n",
      "\tspeed: 0.0401s/iter; left time: 823.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746005\n",
      "\tspeed: 0.0182s/iter; left time: 372.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0765222 Vali Loss: 0.0760892 Test Loss: 0.0869368\n",
      "Validation loss decreased (0.076793 --> 0.076089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779370\n",
      "\tspeed: 0.0435s/iter; left time: 882.3856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787978\n",
      "\tspeed: 0.0186s/iter; left time: 375.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0760347 Vali Loss: 0.0766135 Test Loss: 0.0868480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761426\n",
      "\tspeed: 0.0382s/iter; left time: 765.4540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789521\n",
      "\tspeed: 0.0178s/iter; left time: 355.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0756286 Vali Loss: 0.0763626 Test Loss: 0.0866961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0761763\n",
      "\tspeed: 0.0373s/iter; left time: 740.3132s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757204\n",
      "\tspeed: 0.0178s/iter; left time: 352.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0753164 Vali Loss: 0.0763749 Test Loss: 0.0863272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718356\n",
      "\tspeed: 0.0375s/iter; left time: 735.7471s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752915\n",
      "\tspeed: 0.0178s/iter; left time: 348.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0749505 Vali Loss: 0.0764924 Test Loss: 0.0864433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712507\n",
      "\tspeed: 0.0413s/iter; left time: 800.9626s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751940\n",
      "\tspeed: 0.0204s/iter; left time: 393.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0747298 Vali Loss: 0.0763432 Test Loss: 0.0865515\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0714074\n",
      "\tspeed: 0.0389s/iter; left time: 746.0339s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769075\n",
      "\tspeed: 0.0179s/iter; left time: 340.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0744110 Vali Loss: 0.0763409 Test Loss: 0.0860551\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736857\n",
      "\tspeed: 0.0390s/iter; left time: 738.2485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0758855\n",
      "\tspeed: 0.0179s/iter; left time: 336.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0741638 Vali Loss: 0.0763573 Test Loss: 0.0862534\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732683\n",
      "\tspeed: 0.0372s/iter; left time: 696.4759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766605\n",
      "\tspeed: 0.0178s/iter; left time: 332.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0739782 Vali Loss: 0.0760687 Test Loss: 0.0860618\n",
      "Validation loss decreased (0.076089 --> 0.076069).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758949\n",
      "\tspeed: 0.0420s/iter; left time: 775.8797s\n",
      "\titers: 200, epoch: 18 | loss: 0.0741989\n",
      "\tspeed: 0.0201s/iter; left time: 369.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0738317 Vali Loss: 0.0758029 Test Loss: 0.0859767\n",
      "Validation loss decreased (0.076069 --> 0.075803).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731899\n",
      "\tspeed: 0.0400s/iter; left time: 730.6615s\n",
      "\titers: 200, epoch: 19 | loss: 0.0783558\n",
      "\tspeed: 0.0180s/iter; left time: 326.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0736161 Vali Loss: 0.0767120 Test Loss: 0.0861842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724703\n",
      "\tspeed: 0.0395s/iter; left time: 713.2295s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739780\n",
      "\tspeed: 0.0187s/iter; left time: 335.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0735227 Vali Loss: 0.0763454 Test Loss: 0.0858723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0736979\n",
      "\tspeed: 0.0383s/iter; left time: 681.9721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0692475\n",
      "\tspeed: 0.0176s/iter; left time: 312.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733244 Vali Loss: 0.0759520 Test Loss: 0.0858447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0742377\n",
      "\tspeed: 0.0378s/iter; left time: 664.7089s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738283\n",
      "\tspeed: 0.0177s/iter; left time: 309.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0732371 Vali Loss: 0.0761869 Test Loss: 0.0859049\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716027\n",
      "\tspeed: 0.0386s/iter; left time: 671.2958s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768406\n",
      "\tspeed: 0.0176s/iter; left time: 304.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0730942 Vali Loss: 0.0761952 Test Loss: 0.0858184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739905\n",
      "\tspeed: 0.0375s/iter; left time: 643.1647s\n",
      "\titers: 200, epoch: 24 | loss: 0.0714365\n",
      "\tspeed: 0.0177s/iter; left time: 300.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0729818 Vali Loss: 0.0762859 Test Loss: 0.0857470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0700301\n",
      "\tspeed: 0.0383s/iter; left time: 648.7693s\n",
      "\titers: 200, epoch: 25 | loss: 0.0753928\n",
      "\tspeed: 0.0181s/iter; left time: 303.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0729328 Vali Loss: 0.0763261 Test Loss: 0.0859215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696138\n",
      "\tspeed: 0.0382s/iter; left time: 637.6291s\n",
      "\titers: 200, epoch: 26 | loss: 0.0715025\n",
      "\tspeed: 0.0196s/iter; left time: 325.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0728175 Vali Loss: 0.0762029 Test Loss: 0.0858192\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725613\n",
      "\tspeed: 0.0370s/iter; left time: 610.2925s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719680\n",
      "\tspeed: 0.0185s/iter; left time: 302.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0727753 Vali Loss: 0.0761756 Test Loss: 0.0857254\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751431\n",
      "\tspeed: 0.0390s/iter; left time: 634.0645s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738966\n",
      "\tspeed: 0.0178s/iter; left time: 287.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0727138 Vali Loss: 0.0765646 Test Loss: 0.0857118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01854773983359337, rmse:0.13619008660316467, mae:0.08597671240568161, rse:0.4000854790210724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1367538\n",
      "\tspeed: 0.0223s/iter; left time: 496.8574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153385\n",
      "\tspeed: 0.0233s/iter; left time: 517.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1400050 Vali Loss: 0.1071248 Test Loss: 0.1205454\n",
      "Validation loss decreased (inf --> 0.107125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936913\n",
      "\tspeed: 0.0460s/iter; left time: 1015.9851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879241\n",
      "\tspeed: 0.0176s/iter; left time: 387.3446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0942411 Vali Loss: 0.0843040 Test Loss: 0.0953580\n",
      "Validation loss decreased (0.107125 --> 0.084304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803946\n",
      "\tspeed: 0.0403s/iter; left time: 880.0693s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812021\n",
      "\tspeed: 0.0178s/iter; left time: 386.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0852106 Vali Loss: 0.0801856 Test Loss: 0.0912001\n",
      "Validation loss decreased (0.084304 --> 0.080186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788692\n",
      "\tspeed: 0.0415s/iter; left time: 898.5903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0762093\n",
      "\tspeed: 0.0216s/iter; left time: 466.0767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0821201 Vali Loss: 0.0789561 Test Loss: 0.0895967\n",
      "Validation loss decreased (0.080186 --> 0.078956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793223\n",
      "\tspeed: 0.0421s/iter; left time: 900.2679s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773962\n",
      "\tspeed: 0.0193s/iter; left time: 410.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802467 Vali Loss: 0.0778591 Test Loss: 0.0884357\n",
      "Validation loss decreased (0.078956 --> 0.077859).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816932\n",
      "\tspeed: 0.0403s/iter; left time: 853.8364s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778644\n",
      "\tspeed: 0.0177s/iter; left time: 373.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0790325 Vali Loss: 0.0767959 Test Loss: 0.0875439\n",
      "Validation loss decreased (0.077859 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745961\n",
      "\tspeed: 0.0387s/iter; left time: 810.0707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834768\n",
      "\tspeed: 0.0178s/iter; left time: 371.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0781038 Vali Loss: 0.0762627 Test Loss: 0.0873462\n",
      "Validation loss decreased (0.076796 --> 0.076263).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800848\n",
      "\tspeed: 0.0400s/iter; left time: 829.6929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742644\n",
      "\tspeed: 0.0178s/iter; left time: 367.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0773239 Vali Loss: 0.0775152 Test Loss: 0.0874873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721739\n",
      "\tspeed: 0.0381s/iter; left time: 780.9902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794274\n",
      "\tspeed: 0.0209s/iter; left time: 426.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0767547 Vali Loss: 0.0763608 Test Loss: 0.0870005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758219\n",
      "\tspeed: 0.0409s/iter; left time: 828.6589s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767745\n",
      "\tspeed: 0.0189s/iter; left time: 381.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0761915 Vali Loss: 0.0771433 Test Loss: 0.0867632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747136\n",
      "\tspeed: 0.0450s/iter; left time: 903.2435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756405\n",
      "\tspeed: 0.0197s/iter; left time: 394.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0757717 Vali Loss: 0.0765610 Test Loss: 0.0865518\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0714020\n",
      "\tspeed: 0.0425s/iter; left time: 843.1375s\n",
      "\titers: 200, epoch: 12 | loss: 0.0774138\n",
      "\tspeed: 0.0219s/iter; left time: 431.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0754335 Vali Loss: 0.0767363 Test Loss: 0.0865050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722883\n",
      "\tspeed: 0.0396s/iter; left time: 775.7284s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759881\n",
      "\tspeed: 0.0175s/iter; left time: 341.8679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0751549 Vali Loss: 0.0761463 Test Loss: 0.0862424\n",
      "Validation loss decreased (0.076263 --> 0.076146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745482\n",
      "\tspeed: 0.0412s/iter; left time: 799.4890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0744093\n",
      "\tspeed: 0.0245s/iter; left time: 471.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0747696 Vali Loss: 0.0762650 Test Loss: 0.0862187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720881\n",
      "\tspeed: 0.0400s/iter; left time: 765.8024s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781316\n",
      "\tspeed: 0.0174s/iter; left time: 331.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0745868 Vali Loss: 0.0765290 Test Loss: 0.0860522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0727114\n",
      "\tspeed: 0.0412s/iter; left time: 779.4685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736387\n",
      "\tspeed: 0.0179s/iter; left time: 337.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0743449 Vali Loss: 0.0765852 Test Loss: 0.0860310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706794\n",
      "\tspeed: 0.0388s/iter; left time: 726.9777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752406\n",
      "\tspeed: 0.0205s/iter; left time: 381.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0741923 Vali Loss: 0.0764369 Test Loss: 0.0859239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0744676\n",
      "\tspeed: 0.0419s/iter; left time: 775.4276s\n",
      "\titers: 200, epoch: 18 | loss: 0.0762818\n",
      "\tspeed: 0.0202s/iter; left time: 371.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0740024 Vali Loss: 0.0767829 Test Loss: 0.0857268\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720721\n",
      "\tspeed: 0.0437s/iter; left time: 797.7713s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713664\n",
      "\tspeed: 0.0189s/iter; left time: 342.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0738495 Vali Loss: 0.0765352 Test Loss: 0.0859384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717330\n",
      "\tspeed: 0.0413s/iter; left time: 745.2349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795915\n",
      "\tspeed: 0.0205s/iter; left time: 368.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0736705 Vali Loss: 0.0764407 Test Loss: 0.0857348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724586\n",
      "\tspeed: 0.0392s/iter; left time: 697.8497s\n",
      "\titers: 200, epoch: 21 | loss: 0.0760887\n",
      "\tspeed: 0.0186s/iter; left time: 329.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0735496 Vali Loss: 0.0764364 Test Loss: 0.0857035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712291\n",
      "\tspeed: 0.0433s/iter; left time: 762.3607s\n",
      "\titers: 200, epoch: 22 | loss: 0.0771685\n",
      "\tspeed: 0.0197s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0734158 Vali Loss: 0.0766588 Test Loss: 0.0858466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0699845\n",
      "\tspeed: 0.0433s/iter; left time: 751.8209s\n",
      "\titers: 200, epoch: 23 | loss: 0.0729147\n",
      "\tspeed: 0.0220s/iter; left time: 380.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0733128 Vali Loss: 0.0762644 Test Loss: 0.0857591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018521282821893692, rmse:0.1360929161310196, mae:0.08624237030744553, rse:0.39980003237724304\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:11.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1373530\n",
      "\tspeed: 0.0465s/iter; left time: 1032.9857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231130\n",
      "\tspeed: 0.0178s/iter; left time: 392.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1409036 Vali Loss: 0.1098791 Test Loss: 0.1227950\n",
      "Validation loss decreased (inf --> 0.109879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0984424\n",
      "\tspeed: 0.0383s/iter; left time: 841.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898476\n",
      "\tspeed: 0.0182s/iter; left time: 398.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0985992 Vali Loss: 0.0892979 Test Loss: 0.1007477\n",
      "Validation loss decreased (0.109879 --> 0.089298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924045\n",
      "\tspeed: 0.0405s/iter; left time: 880.7054s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917421\n",
      "\tspeed: 0.0180s/iter; left time: 389.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0898567 Vali Loss: 0.0863748 Test Loss: 0.0964161\n",
      "Validation loss decreased (0.089298 --> 0.086375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892772\n",
      "\tspeed: 0.0398s/iter; left time: 856.7383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851799\n",
      "\tspeed: 0.0179s/iter; left time: 383.3302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0869219 Vali Loss: 0.0845703 Test Loss: 0.0945225\n",
      "Validation loss decreased (0.086375 --> 0.084570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874058\n",
      "\tspeed: 0.0391s/iter; left time: 832.4707s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828013\n",
      "\tspeed: 0.0178s/iter; left time: 377.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0849152 Vali Loss: 0.0836334 Test Loss: 0.0937513\n",
      "Validation loss decreased (0.084570 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0815478\n",
      "\tspeed: 0.0387s/iter; left time: 816.1537s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822768\n",
      "\tspeed: 0.0180s/iter; left time: 377.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0835952 Vali Loss: 0.0829994 Test Loss: 0.0932573\n",
      "Validation loss decreased (0.083633 --> 0.082999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838339\n",
      "\tspeed: 0.0395s/iter; left time: 823.9421s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832751\n",
      "\tspeed: 0.0178s/iter; left time: 370.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0826350 Vali Loss: 0.0830178 Test Loss: 0.0929825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780568\n",
      "\tspeed: 0.0390s/iter; left time: 803.9680s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825638\n",
      "\tspeed: 0.0203s/iter; left time: 417.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0819650 Vali Loss: 0.0831217 Test Loss: 0.0930658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0815612\n",
      "\tspeed: 0.0383s/iter; left time: 782.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793496\n",
      "\tspeed: 0.0184s/iter; left time: 373.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0814262 Vali Loss: 0.0825041 Test Loss: 0.0924428\n",
      "Validation loss decreased (0.082999 --> 0.082504).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0814151\n",
      "\tspeed: 0.0392s/iter; left time: 790.9053s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819548\n",
      "\tspeed: 0.0179s/iter; left time: 360.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0809147 Vali Loss: 0.0830627 Test Loss: 0.0926520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803450\n",
      "\tspeed: 0.0384s/iter; left time: 767.3787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782218\n",
      "\tspeed: 0.0181s/iter; left time: 360.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0805403 Vali Loss: 0.0824139 Test Loss: 0.0921823\n",
      "Validation loss decreased (0.082504 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775920\n",
      "\tspeed: 0.0397s/iter; left time: 784.6760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816294\n",
      "\tspeed: 0.0182s/iter; left time: 357.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0801135 Vali Loss: 0.0824283 Test Loss: 0.0917523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782452\n",
      "\tspeed: 0.0407s/iter; left time: 794.1000s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793490\n",
      "\tspeed: 0.0190s/iter; left time: 369.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0797442 Vali Loss: 0.0824807 Test Loss: 0.0922180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785616\n",
      "\tspeed: 0.0401s/iter; left time: 773.2075s\n",
      "\titers: 200, epoch: 14 | loss: 0.0811015\n",
      "\tspeed: 0.0178s/iter; left time: 342.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0794834 Vali Loss: 0.0825382 Test Loss: 0.0917946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793498\n",
      "\tspeed: 0.0381s/iter; left time: 726.5424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0845542\n",
      "\tspeed: 0.0178s/iter; left time: 337.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0791975 Vali Loss: 0.0827265 Test Loss: 0.0922221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800094\n",
      "\tspeed: 0.0381s/iter; left time: 719.1809s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803068\n",
      "\tspeed: 0.0181s/iter; left time: 340.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0789066 Vali Loss: 0.0829194 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777317\n",
      "\tspeed: 0.0381s/iter; left time: 710.2658s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769415\n",
      "\tspeed: 0.0178s/iter; left time: 329.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0787117 Vali Loss: 0.0828620 Test Loss: 0.0919372\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754707\n",
      "\tspeed: 0.0418s/iter; left time: 769.0558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807448\n",
      "\tspeed: 0.0184s/iter; left time: 336.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0784592 Vali Loss: 0.0827428 Test Loss: 0.0919137\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788248\n",
      "\tspeed: 0.0387s/iter; left time: 703.3631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779088\n",
      "\tspeed: 0.0180s/iter; left time: 325.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0783152 Vali Loss: 0.0827719 Test Loss: 0.0921597\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814836\n",
      "\tspeed: 0.0378s/iter; left time: 678.8644s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774235\n",
      "\tspeed: 0.0178s/iter; left time: 317.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0781401 Vali Loss: 0.0830398 Test Loss: 0.0921266\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0771261\n",
      "\tspeed: 0.0382s/iter; left time: 677.8467s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789094\n",
      "\tspeed: 0.0178s/iter; left time: 314.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0780248 Vali Loss: 0.0829910 Test Loss: 0.0919375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020852474495768547, rmse:0.1444038599729538, mae:0.09218230098485947, rse:0.42424553632736206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1372358\n",
      "\tspeed: 0.0202s/iter; left time: 449.2328s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189031\n",
      "\tspeed: 0.0179s/iter; left time: 395.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1425659 Vali Loss: 0.1109068 Test Loss: 0.1238196\n",
      "Validation loss decreased (inf --> 0.110907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962597\n",
      "\tspeed: 0.0425s/iter; left time: 935.0872s\n",
      "\titers: 200, epoch: 2 | loss: 0.0892632\n",
      "\tspeed: 0.0180s/iter; left time: 393.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0986520 Vali Loss: 0.0897229 Test Loss: 0.1013632\n",
      "Validation loss decreased (0.110907 --> 0.089723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895527\n",
      "\tspeed: 0.0434s/iter; left time: 943.5019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0907336\n",
      "\tspeed: 0.0201s/iter; left time: 435.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0899338 Vali Loss: 0.0860113 Test Loss: 0.0964112\n",
      "Validation loss decreased (0.089723 --> 0.086011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0877847\n",
      "\tspeed: 0.0397s/iter; left time: 854.1758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873513\n",
      "\tspeed: 0.0179s/iter; left time: 383.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0867699 Vali Loss: 0.0845652 Test Loss: 0.0945405\n",
      "Validation loss decreased (0.086011 --> 0.084565).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860343\n",
      "\tspeed: 0.0392s/iter; left time: 834.4113s\n",
      "\titers: 200, epoch: 5 | loss: 0.0856858\n",
      "\tspeed: 0.0179s/iter; left time: 380.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0848098 Vali Loss: 0.0831996 Test Loss: 0.0935732\n",
      "Validation loss decreased (0.084565 --> 0.083200).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817515\n",
      "\tspeed: 0.0383s/iter; left time: 807.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0839486\n",
      "\tspeed: 0.0178s/iter; left time: 374.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0835718 Vali Loss: 0.0824345 Test Loss: 0.0923223\n",
      "Validation loss decreased (0.083200 --> 0.082434).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821306\n",
      "\tspeed: 0.0427s/iter; left time: 891.5068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817424\n",
      "\tspeed: 0.0198s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0828282 Vali Loss: 0.0827731 Test Loss: 0.0922567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816821\n",
      "\tspeed: 0.0384s/iter; left time: 791.9485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851653\n",
      "\tspeed: 0.0178s/iter; left time: 366.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0822374 Vali Loss: 0.0825162 Test Loss: 0.0923592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792334\n",
      "\tspeed: 0.0387s/iter; left time: 789.8722s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820873\n",
      "\tspeed: 0.0177s/iter; left time: 360.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0817259 Vali Loss: 0.0824933 Test Loss: 0.0925659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0831882\n",
      "\tspeed: 0.0420s/iter; left time: 848.0628s\n",
      "\titers: 200, epoch: 10 | loss: 0.0840190\n",
      "\tspeed: 0.0204s/iter; left time: 410.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0812772 Vali Loss: 0.0824480 Test Loss: 0.0920063\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844629\n",
      "\tspeed: 0.0422s/iter; left time: 842.0142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0821361\n",
      "\tspeed: 0.0217s/iter; left time: 430.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0809295 Vali Loss: 0.0831282 Test Loss: 0.0924046\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819720\n",
      "\tspeed: 0.0393s/iter; left time: 775.8412s\n",
      "\titers: 200, epoch: 12 | loss: 0.0770248\n",
      "\tspeed: 0.0181s/iter; left time: 356.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0805377 Vali Loss: 0.0823976 Test Loss: 0.0917684\n",
      "Validation loss decreased (0.082434 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825309\n",
      "\tspeed: 0.0393s/iter; left time: 768.1248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808482\n",
      "\tspeed: 0.0178s/iter; left time: 346.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0802130 Vali Loss: 0.0822795 Test Loss: 0.0915192\n",
      "Validation loss decreased (0.082398 --> 0.082279).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787355\n",
      "\tspeed: 0.0396s/iter; left time: 764.3940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800075\n",
      "\tspeed: 0.0178s/iter; left time: 341.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0799463 Vali Loss: 0.0827081 Test Loss: 0.0917543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0808903\n",
      "\tspeed: 0.0406s/iter; left time: 775.0545s\n",
      "\titers: 200, epoch: 15 | loss: 0.0780651\n",
      "\tspeed: 0.0209s/iter; left time: 397.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0796282 Vali Loss: 0.0825399 Test Loss: 0.0913055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823017\n",
      "\tspeed: 0.0437s/iter; left time: 823.8916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0812932\n",
      "\tspeed: 0.0181s/iter; left time: 339.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0794008 Vali Loss: 0.0822595 Test Loss: 0.0912687\n",
      "Validation loss decreased (0.082279 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0768999\n",
      "\tspeed: 0.0397s/iter; left time: 740.5874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793285\n",
      "\tspeed: 0.0182s/iter; left time: 337.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0792046 Vali Loss: 0.0824286 Test Loss: 0.0913005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0811558\n",
      "\tspeed: 0.0422s/iter; left time: 776.8880s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767288\n",
      "\tspeed: 0.0186s/iter; left time: 341.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0790217 Vali Loss: 0.0826947 Test Loss: 0.0914750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766188\n",
      "\tspeed: 0.0383s/iter; left time: 696.5783s\n",
      "\titers: 200, epoch: 19 | loss: 0.0823196\n",
      "\tspeed: 0.0180s/iter; left time: 325.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0788044 Vali Loss: 0.0827591 Test Loss: 0.0914700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801984\n",
      "\tspeed: 0.0382s/iter; left time: 686.2105s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807184\n",
      "\tspeed: 0.0179s/iter; left time: 319.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0786730 Vali Loss: 0.0820548 Test Loss: 0.0909845\n",
      "Validation loss decreased (0.082259 --> 0.082055).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0805757\n",
      "\tspeed: 0.0410s/iter; left time: 726.6098s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777372\n",
      "\tspeed: 0.0185s/iter; left time: 325.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0785318 Vali Loss: 0.0824276 Test Loss: 0.0911584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793678\n",
      "\tspeed: 0.0398s/iter; left time: 697.4270s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783650\n",
      "\tspeed: 0.0185s/iter; left time: 322.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0784128 Vali Loss: 0.0825987 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0799742\n",
      "\tspeed: 0.0389s/iter; left time: 673.1967s\n",
      "\titers: 200, epoch: 23 | loss: 0.0794193\n",
      "\tspeed: 0.0180s/iter; left time: 308.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0825067 Test Loss: 0.0911256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0774844\n",
      "\tspeed: 0.0408s/iter; left time: 695.8240s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797026\n",
      "\tspeed: 0.0187s/iter; left time: 317.2155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0781464 Vali Loss: 0.0826594 Test Loss: 0.0912149\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770763\n",
      "\tspeed: 0.0453s/iter; left time: 763.6968s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791379\n",
      "\tspeed: 0.0215s/iter; left time: 359.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0780359 Vali Loss: 0.0827667 Test Loss: 0.0911917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812251\n",
      "\tspeed: 0.0463s/iter; left time: 769.7062s\n",
      "\titers: 200, epoch: 26 | loss: 0.0773855\n",
      "\tspeed: 0.0217s/iter; left time: 358.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0779974 Vali Loss: 0.0827996 Test Loss: 0.0910253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775638\n",
      "\tspeed: 0.0450s/iter; left time: 737.7617s\n",
      "\titers: 200, epoch: 27 | loss: 0.0749843\n",
      "\tspeed: 0.0213s/iter; left time: 346.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0779365 Vali Loss: 0.0824053 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0782782\n",
      "\tspeed: 0.0427s/iter; left time: 691.0858s\n",
      "\titers: 200, epoch: 28 | loss: 0.0794728\n",
      "\tspeed: 0.0213s/iter; left time: 342.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0778237 Vali Loss: 0.0824167 Test Loss: 0.0909431\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744470\n",
      "\tspeed: 0.0498s/iter; left time: 794.5243s\n",
      "\titers: 200, epoch: 29 | loss: 0.0743873\n",
      "\tspeed: 0.0229s/iter; left time: 363.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0778208 Vali Loss: 0.0826677 Test Loss: 0.0910047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778956\n",
      "\tspeed: 0.0468s/iter; left time: 736.4441s\n",
      "\titers: 200, epoch: 30 | loss: 0.0735903\n",
      "\tspeed: 0.0199s/iter; left time: 311.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0826702 Test Loss: 0.0909662\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02058718539774418, rmse:0.14348235726356506, mae:0.09098456054925919, rse:0.42153823375701904\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:15.25s\n",
      "Intermediate time for ES: 00h:22m:06.03s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0923198\n",
      "\tspeed: 0.0471s/iter; left time: 1050.7328s\n",
      "\titers: 200, epoch: 1 | loss: 0.0812700\n",
      "\tspeed: 0.0175s/iter; left time: 389.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0997137 Vali Loss: 0.0826080 Test Loss: 0.0894115\n",
      "Validation loss decreased (inf --> 0.082608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0530040\n",
      "\tspeed: 0.0374s/iter; left time: 825.2455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500890\n",
      "\tspeed: 0.0176s/iter; left time: 386.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0568332 Vali Loss: 0.0584304 Test Loss: 0.0615740\n",
      "Validation loss decreased (0.082608 --> 0.058430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0495541\n",
      "\tspeed: 0.0390s/iter; left time: 852.1089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0470994\n",
      "\tspeed: 0.0178s/iter; left time: 386.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0492891 Vali Loss: 0.0561867 Test Loss: 0.0599419\n",
      "Validation loss decreased (0.058430 --> 0.056187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472196\n",
      "\tspeed: 0.0373s/iter; left time: 805.7826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496854\n",
      "\tspeed: 0.0175s/iter; left time: 375.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0474948 Vali Loss: 0.0547214 Test Loss: 0.0583943\n",
      "Validation loss decreased (0.056187 --> 0.054721).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0445898\n",
      "\tspeed: 0.0379s/iter; left time: 811.0635s\n",
      "\titers: 200, epoch: 5 | loss: 0.0486444\n",
      "\tspeed: 0.0175s/iter; left time: 373.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462286 Vali Loss: 0.0537535 Test Loss: 0.0576479\n",
      "Validation loss decreased (0.054721 --> 0.053753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0466075\n",
      "\tspeed: 0.0384s/iter; left time: 813.6643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427133\n",
      "\tspeed: 0.0173s/iter; left time: 364.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0453936 Vali Loss: 0.0532484 Test Loss: 0.0574954\n",
      "Validation loss decreased (0.053753 --> 0.053248).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0491663\n",
      "\tspeed: 0.0406s/iter; left time: 851.6473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448862\n",
      "\tspeed: 0.0174s/iter; left time: 362.2701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0447000 Vali Loss: 0.0526119 Test Loss: 0.0567984\n",
      "Validation loss decreased (0.053248 --> 0.052612).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0448391\n",
      "\tspeed: 0.0388s/iter; left time: 803.6487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0443497\n",
      "\tspeed: 0.0175s/iter; left time: 361.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0441658 Vali Loss: 0.0528287 Test Loss: 0.0566366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0405296\n",
      "\tspeed: 0.0380s/iter; left time: 779.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0458015\n",
      "\tspeed: 0.0173s/iter; left time: 354.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0437640 Vali Loss: 0.0521360 Test Loss: 0.0564570\n",
      "Validation loss decreased (0.052612 --> 0.052136).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441886\n",
      "\tspeed: 0.0407s/iter; left time: 826.5387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0448638\n",
      "\tspeed: 0.0206s/iter; left time: 415.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0434143 Vali Loss: 0.0517792 Test Loss: 0.0561378\n",
      "Validation loss decreased (0.052136 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440236\n",
      "\tspeed: 0.0429s/iter; left time: 861.3392s\n",
      "\titers: 200, epoch: 11 | loss: 0.0420616\n",
      "\tspeed: 0.0212s/iter; left time: 423.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0431010 Vali Loss: 0.0520836 Test Loss: 0.0564000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0403346\n",
      "\tspeed: 0.0366s/iter; left time: 726.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0413291\n",
      "\tspeed: 0.0175s/iter; left time: 345.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0428325 Vali Loss: 0.0517494 Test Loss: 0.0560631\n",
      "Validation loss decreased (0.051779 --> 0.051749).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406433\n",
      "\tspeed: 0.0376s/iter; left time: 737.7125s\n",
      "\titers: 200, epoch: 13 | loss: 0.0392740\n",
      "\tspeed: 0.0175s/iter; left time: 342.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0425714 Vali Loss: 0.0517062 Test Loss: 0.0557897\n",
      "Validation loss decreased (0.051749 --> 0.051706).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0407032\n",
      "\tspeed: 0.0399s/iter; left time: 773.5516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0415839\n",
      "\tspeed: 0.0184s/iter; left time: 355.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0424152 Vali Loss: 0.0514950 Test Loss: 0.0557442\n",
      "Validation loss decreased (0.051706 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0427796\n",
      "\tspeed: 0.0377s/iter; left time: 723.2441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0386341\n",
      "\tspeed: 0.0173s/iter; left time: 330.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0422304 Vali Loss: 0.0514152 Test Loss: 0.0555388\n",
      "Validation loss decreased (0.051495 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407047\n",
      "\tspeed: 0.0367s/iter; left time: 695.1301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0395314\n",
      "\tspeed: 0.0197s/iter; left time: 370.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0421071 Vali Loss: 0.0514455 Test Loss: 0.0555331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0455639\n",
      "\tspeed: 0.0411s/iter; left time: 768.5792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0418858\n",
      "\tspeed: 0.0178s/iter; left time: 331.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0419426 Vali Loss: 0.0512198 Test Loss: 0.0553853\n",
      "Validation loss decreased (0.051415 --> 0.051220).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0401110\n",
      "\tspeed: 0.0382s/iter; left time: 706.4201s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410072\n",
      "\tspeed: 0.0177s/iter; left time: 326.4655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418059 Vali Loss: 0.0510725 Test Loss: 0.0553629\n",
      "Validation loss decreased (0.051220 --> 0.051072).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0397940\n",
      "\tspeed: 0.0400s/iter; left time: 730.7567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415944\n",
      "\tspeed: 0.0209s/iter; left time: 378.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0416938 Vali Loss: 0.0510424 Test Loss: 0.0552553\n",
      "Validation loss decreased (0.051072 --> 0.051042).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0410033\n",
      "\tspeed: 0.0427s/iter; left time: 770.8388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0419177\n",
      "\tspeed: 0.0181s/iter; left time: 324.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0416170 Vali Loss: 0.0509896 Test Loss: 0.0552562\n",
      "Validation loss decreased (0.051042 --> 0.050990).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414350\n",
      "\tspeed: 0.0380s/iter; left time: 677.0998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0406842\n",
      "\tspeed: 0.0174s/iter; left time: 307.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0415393 Vali Loss: 0.0508995 Test Loss: 0.0550967\n",
      "Validation loss decreased (0.050990 --> 0.050899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0403014\n",
      "\tspeed: 0.0401s/iter; left time: 705.8079s\n",
      "\titers: 200, epoch: 22 | loss: 0.0367226\n",
      "\tspeed: 0.0178s/iter; left time: 310.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0414575 Vali Loss: 0.0509838 Test Loss: 0.0551132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0409429\n",
      "\tspeed: 0.0398s/iter; left time: 691.6798s\n",
      "\titers: 200, epoch: 23 | loss: 0.0429620\n",
      "\tspeed: 0.0223s/iter; left time: 385.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413607 Vali Loss: 0.0509441 Test Loss: 0.0551800\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404058\n",
      "\tspeed: 0.0397s/iter; left time: 681.0152s\n",
      "\titers: 200, epoch: 24 | loss: 0.0405565\n",
      "\tspeed: 0.0222s/iter; left time: 378.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0413338 Vali Loss: 0.0509188 Test Loss: 0.0551000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423914\n",
      "\tspeed: 0.0407s/iter; left time: 688.4196s\n",
      "\titers: 200, epoch: 25 | loss: 0.0413437\n",
      "\tspeed: 0.0197s/iter; left time: 330.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0412619 Vali Loss: 0.0509029 Test Loss: 0.0551642\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0389570\n",
      "\tspeed: 0.0380s/iter; left time: 634.0786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0388686\n",
      "\tspeed: 0.0176s/iter; left time: 292.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0412201 Vali Loss: 0.0509290 Test Loss: 0.0551733\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0415587\n",
      "\tspeed: 0.0369s/iter; left time: 607.7228s\n",
      "\titers: 200, epoch: 27 | loss: 0.0423500\n",
      "\tspeed: 0.0197s/iter; left time: 322.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0411406 Vali Loss: 0.0508458 Test Loss: 0.0550130\n",
      "Validation loss decreased (0.050899 --> 0.050846).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0435844\n",
      "\tspeed: 0.0411s/iter; left time: 668.6772s\n",
      "\titers: 200, epoch: 28 | loss: 0.0385247\n",
      "\tspeed: 0.0200s/iter; left time: 322.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0411405 Vali Loss: 0.0508347 Test Loss: 0.0550222\n",
      "Validation loss decreased (0.050846 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0420762\n",
      "\tspeed: 0.0368s/iter; left time: 589.5002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0388678\n",
      "\tspeed: 0.0175s/iter; left time: 278.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0411094 Vali Loss: 0.0508880 Test Loss: 0.0549905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0427229\n",
      "\tspeed: 0.0421s/iter; left time: 665.9101s\n",
      "\titers: 200, epoch: 30 | loss: 0.0388344\n",
      "\tspeed: 0.0202s/iter; left time: 317.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0410763 Vali Loss: 0.0508937 Test Loss: 0.0550308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0407782\n",
      "\tspeed: 0.0365s/iter; left time: 568.3944s\n",
      "\titers: 200, epoch: 31 | loss: 0.0419291\n",
      "\tspeed: 0.0195s/iter; left time: 302.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0410766 Vali Loss: 0.0506749 Test Loss: 0.0550058\n",
      "Validation loss decreased (0.050835 --> 0.050675).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0414399\n",
      "\tspeed: 0.0382s/iter; left time: 586.8291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421118\n",
      "\tspeed: 0.0199s/iter; left time: 303.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0410319 Vali Loss: 0.0507480 Test Loss: 0.0549598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0422271\n",
      "\tspeed: 0.0365s/iter; left time: 552.3449s\n",
      "\titers: 200, epoch: 33 | loss: 0.0414499\n",
      "\tspeed: 0.0175s/iter; left time: 263.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0409737 Vali Loss: 0.0507774 Test Loss: 0.0549851\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0413024\n",
      "\tspeed: 0.0361s/iter; left time: 538.2906s\n",
      "\titers: 200, epoch: 34 | loss: 0.0401151\n",
      "\tspeed: 0.0174s/iter; left time: 256.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0409406 Vali Loss: 0.0506703 Test Loss: 0.0549519\n",
      "Validation loss decreased (0.050675 --> 0.050670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0408263\n",
      "\tspeed: 0.0391s/iter; left time: 574.3639s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405118\n",
      "\tspeed: 0.0176s/iter; left time: 256.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0409528 Vali Loss: 0.0507586 Test Loss: 0.0549365\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0392115\n",
      "\tspeed: 0.0370s/iter; left time: 534.8904s\n",
      "\titers: 200, epoch: 36 | loss: 0.0404948\n",
      "\tspeed: 0.0175s/iter; left time: 251.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409394 Vali Loss: 0.0507388 Test Loss: 0.0549210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0423826\n",
      "\tspeed: 0.0361s/iter; left time: 513.9982s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399949\n",
      "\tspeed: 0.0187s/iter; left time: 264.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0409280 Vali Loss: 0.0507797 Test Loss: 0.0549513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0420419\n",
      "\tspeed: 0.0364s/iter; left time: 509.5619s\n",
      "\titers: 200, epoch: 38 | loss: 0.0414468\n",
      "\tspeed: 0.0180s/iter; left time: 250.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0408825 Vali Loss: 0.0506685 Test Loss: 0.0549180\n",
      "Validation loss decreased (0.050670 --> 0.050669).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0411821\n",
      "\tspeed: 0.0397s/iter; left time: 546.7866s\n",
      "\titers: 200, epoch: 39 | loss: 0.0366663\n",
      "\tspeed: 0.0173s/iter; left time: 236.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0409059 Vali Loss: 0.0507391 Test Loss: 0.0549399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0391978\n",
      "\tspeed: 0.0413s/iter; left time: 560.1932s\n",
      "\titers: 200, epoch: 40 | loss: 0.0425756\n",
      "\tspeed: 0.0195s/iter; left time: 263.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0409207 Vali Loss: 0.0506791 Test Loss: 0.0549067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416604\n",
      "\tspeed: 0.0367s/iter; left time: 489.4409s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402725\n",
      "\tspeed: 0.0173s/iter; left time: 228.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0408218 Vali Loss: 0.0507860 Test Loss: 0.0549271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0415616\n",
      "\tspeed: 0.0356s/iter; left time: 466.7670s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426821\n",
      "\tspeed: 0.0174s/iter; left time: 226.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0408661 Vali Loss: 0.0506999 Test Loss: 0.0549061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0412373\n",
      "\tspeed: 0.0362s/iter; left time: 466.9375s\n",
      "\titers: 200, epoch: 43 | loss: 0.0388965\n",
      "\tspeed: 0.0175s/iter; left time: 224.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408737 Vali Loss: 0.0507067 Test Loss: 0.0549184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0409356\n",
      "\tspeed: 0.0366s/iter; left time: 463.4980s\n",
      "\titers: 200, epoch: 44 | loss: 0.0419919\n",
      "\tspeed: 0.0175s/iter; left time: 220.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0407900 Vali Loss: 0.0507195 Test Loss: 0.0548893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0395876\n",
      "\tspeed: 0.0357s/iter; left time: 444.3419s\n",
      "\titers: 200, epoch: 45 | loss: 0.0424386\n",
      "\tspeed: 0.0176s/iter; left time: 217.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408467 Vali Loss: 0.0507040 Test Loss: 0.0548965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400761\n",
      "\tspeed: 0.0384s/iter; left time: 468.8836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0398946\n",
      "\tspeed: 0.0200s/iter; left time: 242.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0407960 Vali Loss: 0.0507497 Test Loss: 0.0548866\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393914\n",
      "\tspeed: 0.0370s/iter; left time: 443.4982s\n",
      "\titers: 200, epoch: 47 | loss: 0.0387283\n",
      "\tspeed: 0.0223s/iter; left time: 265.7545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408184 Vali Loss: 0.0507020 Test Loss: 0.0548986\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393765\n",
      "\tspeed: 0.0409s/iter; left time: 481.1759s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420225\n",
      "\tspeed: 0.0176s/iter; left time: 205.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0408080 Vali Loss: 0.0507258 Test Loss: 0.0548816\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010047451592981815, rmse:0.10023697465658188, mae:0.05491799861192703, rse:0.3867114782333374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0935595\n",
      "\tspeed: 0.0249s/iter; left time: 554.6922s\n",
      "\titers: 200, epoch: 1 | loss: 0.0815350\n",
      "\tspeed: 0.0238s/iter; left time: 529.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0985673 Vali Loss: 0.0815828 Test Loss: 0.0878835\n",
      "Validation loss decreased (inf --> 0.081583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0546182\n",
      "\tspeed: 0.0405s/iter; left time: 894.5638s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524375\n",
      "\tspeed: 0.0177s/iter; left time: 388.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0564773 Vali Loss: 0.0585265 Test Loss: 0.0620153\n",
      "Validation loss decreased (0.081583 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0516169\n",
      "\tspeed: 0.0405s/iter; left time: 883.9750s\n",
      "\titers: 200, epoch: 3 | loss: 0.0538712\n",
      "\tspeed: 0.0176s/iter; left time: 383.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0494922 Vali Loss: 0.0564595 Test Loss: 0.0600532\n",
      "Validation loss decreased (0.058526 --> 0.056460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0500758\n",
      "\tspeed: 0.0409s/iter; left time: 884.1769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0470287\n",
      "\tspeed: 0.0173s/iter; left time: 372.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0476510 Vali Loss: 0.0550841 Test Loss: 0.0591046\n",
      "Validation loss decreased (0.056460 --> 0.055084).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476657\n",
      "\tspeed: 0.0393s/iter; left time: 840.3386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0453900\n",
      "\tspeed: 0.0175s/iter; left time: 372.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0462703 Vali Loss: 0.0539240 Test Loss: 0.0578887\n",
      "Validation loss decreased (0.055084 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0436470\n",
      "\tspeed: 0.0385s/iter; left time: 815.6399s\n",
      "\titers: 200, epoch: 6 | loss: 0.0469544\n",
      "\tspeed: 0.0179s/iter; left time: 377.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0453504 Vali Loss: 0.0534992 Test Loss: 0.0576763\n",
      "Validation loss decreased (0.053924 --> 0.053499).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0498019\n",
      "\tspeed: 0.0372s/iter; left time: 780.1501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0435070\n",
      "\tspeed: 0.0173s/iter; left time: 361.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0447041 Vali Loss: 0.0528023 Test Loss: 0.0570895\n",
      "Validation loss decreased (0.053499 --> 0.052802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433632\n",
      "\tspeed: 0.0385s/iter; left time: 797.2715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472117\n",
      "\tspeed: 0.0184s/iter; left time: 380.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0442430 Vali Loss: 0.0525080 Test Loss: 0.0565417\n",
      "Validation loss decreased (0.052802 --> 0.052508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442935\n",
      "\tspeed: 0.0381s/iter; left time: 780.5073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439991\n",
      "\tspeed: 0.0181s/iter; left time: 369.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0437869 Vali Loss: 0.0521499 Test Loss: 0.0563267\n",
      "Validation loss decreased (0.052508 --> 0.052150).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457982\n",
      "\tspeed: 0.0375s/iter; left time: 761.0894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0451140\n",
      "\tspeed: 0.0175s/iter; left time: 354.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0434726 Vali Loss: 0.0523196 Test Loss: 0.0562200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0418626\n",
      "\tspeed: 0.0373s/iter; left time: 747.8968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0411332\n",
      "\tspeed: 0.0176s/iter; left time: 350.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0431422 Vali Loss: 0.0519555 Test Loss: 0.0562363\n",
      "Validation loss decreased (0.052150 --> 0.051955).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414568\n",
      "\tspeed: 0.0397s/iter; left time: 787.3697s\n",
      "\titers: 200, epoch: 12 | loss: 0.0442729\n",
      "\tspeed: 0.0185s/iter; left time: 365.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0429151 Vali Loss: 0.0517021 Test Loss: 0.0557212\n",
      "Validation loss decreased (0.051955 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0447191\n",
      "\tspeed: 0.0423s/iter; left time: 829.6593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0452590\n",
      "\tspeed: 0.0227s/iter; left time: 443.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0426312 Vali Loss: 0.0516790 Test Loss: 0.0557699\n",
      "Validation loss decreased (0.051702 --> 0.051679).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0460300\n",
      "\tspeed: 0.0378s/iter; left time: 732.2859s\n",
      "\titers: 200, epoch: 14 | loss: 0.0424465\n",
      "\tspeed: 0.0174s/iter; left time: 335.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0424535 Vali Loss: 0.0514955 Test Loss: 0.0555738\n",
      "Validation loss decreased (0.051679 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425895\n",
      "\tspeed: 0.0379s/iter; left time: 725.9930s\n",
      "\titers: 200, epoch: 15 | loss: 0.0400014\n",
      "\tspeed: 0.0199s/iter; left time: 379.4924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0422823 Vali Loss: 0.0517129 Test Loss: 0.0555978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0436068\n",
      "\tspeed: 0.0389s/iter; left time: 736.5599s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415642\n",
      "\tspeed: 0.0175s/iter; left time: 330.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0421010 Vali Loss: 0.0514501 Test Loss: 0.0553953\n",
      "Validation loss decreased (0.051495 --> 0.051450).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0403893\n",
      "\tspeed: 0.0378s/iter; left time: 707.0198s\n",
      "\titers: 200, epoch: 17 | loss: 0.0428705\n",
      "\tspeed: 0.0175s/iter; left time: 326.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0419437 Vali Loss: 0.0512283 Test Loss: 0.0553973\n",
      "Validation loss decreased (0.051450 --> 0.051228).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435594\n",
      "\tspeed: 0.0374s/iter; left time: 691.4029s\n",
      "\titers: 200, epoch: 18 | loss: 0.0430981\n",
      "\tspeed: 0.0176s/iter; left time: 323.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418711 Vali Loss: 0.0511208 Test Loss: 0.0552354\n",
      "Validation loss decreased (0.051228 --> 0.051121).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0425317\n",
      "\tspeed: 0.0388s/iter; left time: 708.5180s\n",
      "\titers: 200, epoch: 19 | loss: 0.0425620\n",
      "\tspeed: 0.0178s/iter; left time: 322.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0417220 Vali Loss: 0.0513766 Test Loss: 0.0552269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0389410\n",
      "\tspeed: 0.0386s/iter; left time: 696.3162s\n",
      "\titers: 200, epoch: 20 | loss: 0.0418354\n",
      "\tspeed: 0.0176s/iter; left time: 316.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0416325 Vali Loss: 0.0510026 Test Loss: 0.0550833\n",
      "Validation loss decreased (0.051121 --> 0.051003).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0438422\n",
      "\tspeed: 0.0370s/iter; left time: 659.7459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0418498\n",
      "\tspeed: 0.0176s/iter; left time: 311.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0415382 Vali Loss: 0.0509244 Test Loss: 0.0550689\n",
      "Validation loss decreased (0.051003 --> 0.050924).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414739\n",
      "\tspeed: 0.0399s/iter; left time: 701.7967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0414515\n",
      "\tspeed: 0.0176s/iter; left time: 307.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0414551 Vali Loss: 0.0509189 Test Loss: 0.0550239\n",
      "Validation loss decreased (0.050924 --> 0.050919).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412667\n",
      "\tspeed: 0.0418s/iter; left time: 726.3481s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385480\n",
      "\tspeed: 0.0183s/iter; left time: 316.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0414020 Vali Loss: 0.0509293 Test Loss: 0.0549526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404608\n",
      "\tspeed: 0.0433s/iter; left time: 742.8594s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383370\n",
      "\tspeed: 0.0182s/iter; left time: 310.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0413754 Vali Loss: 0.0509873 Test Loss: 0.0550544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0416779\n",
      "\tspeed: 0.0377s/iter; left time: 638.7238s\n",
      "\titers: 200, epoch: 25 | loss: 0.0415474\n",
      "\tspeed: 0.0176s/iter; left time: 295.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0412857 Vali Loss: 0.0509787 Test Loss: 0.0549485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0422339\n",
      "\tspeed: 0.0382s/iter; left time: 638.6748s\n",
      "\titers: 200, epoch: 26 | loss: 0.0430234\n",
      "\tspeed: 0.0173s/iter; left time: 287.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0412502 Vali Loss: 0.0510159 Test Loss: 0.0549871\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0391803\n",
      "\tspeed: 0.0425s/iter; left time: 699.8363s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413634\n",
      "\tspeed: 0.0215s/iter; left time: 351.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0412082 Vali Loss: 0.0509350 Test Loss: 0.0548990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0405897\n",
      "\tspeed: 0.0418s/iter; left time: 679.4927s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397338\n",
      "\tspeed: 0.0213s/iter; left time: 344.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0411314 Vali Loss: 0.0508925 Test Loss: 0.0549294\n",
      "Validation loss decreased (0.050919 --> 0.050893).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0437130\n",
      "\tspeed: 0.0387s/iter; left time: 619.6992s\n",
      "\titers: 200, epoch: 29 | loss: 0.0453305\n",
      "\tspeed: 0.0173s/iter; left time: 276.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0410808 Vali Loss: 0.0508684 Test Loss: 0.0549480\n",
      "Validation loss decreased (0.050893 --> 0.050868).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0404034\n",
      "\tspeed: 0.0374s/iter; left time: 591.2247s\n",
      "\titers: 200, epoch: 30 | loss: 0.0408411\n",
      "\tspeed: 0.0175s/iter; left time: 274.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0410524 Vali Loss: 0.0508277 Test Loss: 0.0548504\n",
      "Validation loss decreased (0.050868 --> 0.050828).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0427010\n",
      "\tspeed: 0.0380s/iter; left time: 592.4086s\n",
      "\titers: 200, epoch: 31 | loss: 0.0425292\n",
      "\tspeed: 0.0176s/iter; left time: 271.9788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0410449 Vali Loss: 0.0508885 Test Loss: 0.0548904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403372\n",
      "\tspeed: 0.0369s/iter; left time: 566.6934s\n",
      "\titers: 200, epoch: 32 | loss: 0.0405556\n",
      "\tspeed: 0.0175s/iter; left time: 266.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0410464 Vali Loss: 0.0508567 Test Loss: 0.0548694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0431220\n",
      "\tspeed: 0.0385s/iter; left time: 582.1933s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424416\n",
      "\tspeed: 0.0190s/iter; left time: 286.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0410148 Vali Loss: 0.0507454 Test Loss: 0.0548886\n",
      "Validation loss decreased (0.050828 --> 0.050745).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425253\n",
      "\tspeed: 0.0384s/iter; left time: 572.9638s\n",
      "\titers: 200, epoch: 34 | loss: 0.0445072\n",
      "\tspeed: 0.0176s/iter; left time: 260.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409694 Vali Loss: 0.0507921 Test Loss: 0.0548382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0386003\n",
      "\tspeed: 0.0386s/iter; left time: 567.2513s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397497\n",
      "\tspeed: 0.0178s/iter; left time: 259.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0409914 Vali Loss: 0.0507661 Test Loss: 0.0548480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0463726\n",
      "\tspeed: 0.0379s/iter; left time: 547.6972s\n",
      "\titers: 200, epoch: 36 | loss: 0.0397050\n",
      "\tspeed: 0.0176s/iter; left time: 252.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0409164 Vali Loss: 0.0508233 Test Loss: 0.0548441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0409133\n",
      "\tspeed: 0.0376s/iter; left time: 534.7156s\n",
      "\titers: 200, epoch: 37 | loss: 0.0423615\n",
      "\tspeed: 0.0175s/iter; left time: 247.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409337 Vali Loss: 0.0508035 Test Loss: 0.0548229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0406316\n",
      "\tspeed: 0.0387s/iter; left time: 542.5981s\n",
      "\titers: 200, epoch: 38 | loss: 0.0397512\n",
      "\tspeed: 0.0189s/iter; left time: 263.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0409042 Vali Loss: 0.0507964 Test Loss: 0.0548444\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0381033\n",
      "\tspeed: 0.0399s/iter; left time: 550.0490s\n",
      "\titers: 200, epoch: 39 | loss: 0.0382526\n",
      "\tspeed: 0.0173s/iter; left time: 236.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409219 Vali Loss: 0.0508203 Test Loss: 0.0548079\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0409601\n",
      "\tspeed: 0.0444s/iter; left time: 602.0461s\n",
      "\titers: 200, epoch: 40 | loss: 0.0414687\n",
      "\tspeed: 0.0204s/iter; left time: 274.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0408627 Vali Loss: 0.0507907 Test Loss: 0.0547983\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0436835\n",
      "\tspeed: 0.0442s/iter; left time: 590.2730s\n",
      "\titers: 200, epoch: 41 | loss: 0.0395844\n",
      "\tspeed: 0.0205s/iter; left time: 271.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0408995 Vali Loss: 0.0507025 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050745 --> 0.050702).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0397279\n",
      "\tspeed: 0.0438s/iter; left time: 574.0071s\n",
      "\titers: 200, epoch: 42 | loss: 0.0432200\n",
      "\tspeed: 0.0203s/iter; left time: 264.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408592 Vali Loss: 0.0507363 Test Loss: 0.0547963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0390139\n",
      "\tspeed: 0.0385s/iter; left time: 496.0208s\n",
      "\titers: 200, epoch: 43 | loss: 0.0416165\n",
      "\tspeed: 0.0176s/iter; left time: 225.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0409098 Vali Loss: 0.0507644 Test Loss: 0.0547888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0394929\n",
      "\tspeed: 0.0378s/iter; left time: 478.8054s\n",
      "\titers: 200, epoch: 44 | loss: 0.0391143\n",
      "\tspeed: 0.0177s/iter; left time: 222.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0408876 Vali Loss: 0.0507556 Test Loss: 0.0547861\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0385056\n",
      "\tspeed: 0.0373s/iter; left time: 463.8164s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418280\n",
      "\tspeed: 0.0176s/iter; left time: 216.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0408062 Vali Loss: 0.0506480 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050702 --> 0.050648).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0404662\n",
      "\tspeed: 0.0407s/iter; left time: 496.9452s\n",
      "\titers: 200, epoch: 46 | loss: 0.0425981\n",
      "\tspeed: 0.0212s/iter; left time: 257.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0408597 Vali Loss: 0.0507410 Test Loss: 0.0547948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0412951\n",
      "\tspeed: 0.0371s/iter; left time: 445.5673s\n",
      "\titers: 200, epoch: 47 | loss: 0.0460205\n",
      "\tspeed: 0.0176s/iter; left time: 209.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0408051 Vali Loss: 0.0507380 Test Loss: 0.0547790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0396187\n",
      "\tspeed: 0.0385s/iter; left time: 453.1386s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420261\n",
      "\tspeed: 0.0177s/iter; left time: 206.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0408679 Vali Loss: 0.0508199 Test Loss: 0.0547630\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0402250\n",
      "\tspeed: 0.0394s/iter; left time: 455.5809s\n",
      "\titers: 200, epoch: 49 | loss: 0.0436193\n",
      "\tspeed: 0.0194s/iter; left time: 222.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0408469 Vali Loss: 0.0507091 Test Loss: 0.0547697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0362207\n",
      "\tspeed: 0.0371s/iter; left time: 420.3064s\n",
      "\titers: 200, epoch: 50 | loss: 0.0385387\n",
      "\tspeed: 0.0175s/iter; left time: 196.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408548 Vali Loss: 0.0506502 Test Loss: 0.0547767\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440735\n",
      "\tspeed: 0.0385s/iter; left time: 427.6925s\n",
      "\titers: 200, epoch: 51 | loss: 0.0387501\n",
      "\tspeed: 0.0181s/iter; left time: 199.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0408112 Vali Loss: 0.0507077 Test Loss: 0.0547609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0404372\n",
      "\tspeed: 0.0432s/iter; left time: 470.1337s\n",
      "\titers: 200, epoch: 52 | loss: 0.0423694\n",
      "\tspeed: 0.0177s/iter; left time: 190.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408257 Vali Loss: 0.0507446 Test Loss: 0.0547665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0421164\n",
      "\tspeed: 0.0409s/iter; left time: 435.6301s\n",
      "\titers: 200, epoch: 53 | loss: 0.0415824\n",
      "\tspeed: 0.0186s/iter; left time: 196.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0408422 Vali Loss: 0.0507633 Test Loss: 0.0547696\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0443786\n",
      "\tspeed: 0.0368s/iter; left time: 383.9620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0391313\n",
      "\tspeed: 0.0175s/iter; left time: 181.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408320 Vali Loss: 0.0507100 Test Loss: 0.0547600\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0417649\n",
      "\tspeed: 0.0400s/iter; left time: 408.2279s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409617\n",
      "\tspeed: 0.0212s/iter; left time: 214.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408236 Vali Loss: 0.0506238 Test Loss: 0.0547631\n",
      "Validation loss decreased (0.050648 --> 0.050624).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0360162\n",
      "\tspeed: 0.0393s/iter; left time: 392.0179s\n",
      "\titers: 200, epoch: 56 | loss: 0.0408644\n",
      "\tspeed: 0.0177s/iter; left time: 174.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0407994 Vali Loss: 0.0507128 Test Loss: 0.0547610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0406955\n",
      "\tspeed: 0.0369s/iter; left time: 359.5597s\n",
      "\titers: 200, epoch: 57 | loss: 0.0420306\n",
      "\tspeed: 0.0176s/iter; left time: 170.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408128 Vali Loss: 0.0507455 Test Loss: 0.0547706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0457876\n",
      "\tspeed: 0.0364s/iter; left time: 346.5785s\n",
      "\titers: 200, epoch: 58 | loss: 0.0406639\n",
      "\tspeed: 0.0176s/iter; left time: 166.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0408230 Vali Loss: 0.0506479 Test Loss: 0.0547651\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0408023\n",
      "\tspeed: 0.0401s/iter; left time: 373.1203s\n",
      "\titers: 200, epoch: 59 | loss: 0.0427719\n",
      "\tspeed: 0.0178s/iter; left time: 163.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0407709 Vali Loss: 0.0507367 Test Loss: 0.0547671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0425067\n",
      "\tspeed: 0.0369s/iter; left time: 335.6411s\n",
      "\titers: 200, epoch: 60 | loss: 0.0396171\n",
      "\tspeed: 0.0190s/iter; left time: 170.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0408547 Vali Loss: 0.0507473 Test Loss: 0.0547641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0417092\n",
      "\tspeed: 0.0435s/iter; left time: 385.4814s\n",
      "\titers: 200, epoch: 61 | loss: 0.0407552\n",
      "\tspeed: 0.0225s/iter; left time: 196.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0408172 Vali Loss: 0.0507417 Test Loss: 0.0547586\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394446\n",
      "\tspeed: 0.0441s/iter; left time: 380.7387s\n",
      "\titers: 200, epoch: 62 | loss: 0.0394354\n",
      "\tspeed: 0.0205s/iter; left time: 174.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408144 Vali Loss: 0.0506968 Test Loss: 0.0547682\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0409796\n",
      "\tspeed: 0.0377s/iter; left time: 316.9350s\n",
      "\titers: 200, epoch: 63 | loss: 0.0429062\n",
      "\tspeed: 0.0180s/iter; left time: 149.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408127 Vali Loss: 0.0507607 Test Loss: 0.0547640\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0448329\n",
      "\tspeed: 0.0409s/iter; left time: 334.5994s\n",
      "\titers: 200, epoch: 64 | loss: 0.0424715\n",
      "\tspeed: 0.0195s/iter; left time: 157.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408103 Vali Loss: 0.0507010 Test Loss: 0.0547563\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0428965\n",
      "\tspeed: 0.0388s/iter; left time: 309.0573s\n",
      "\titers: 200, epoch: 65 | loss: 0.0406603\n",
      "\tspeed: 0.0200s/iter; left time: 156.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0407825 Vali Loss: 0.0506624 Test Loss: 0.0547556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009938369505107403, rmse:0.09969136863946915, mae:0.05476314201951027, rse:0.3846065402030945\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:01.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0980609\n",
      "\tspeed: 0.0442s/iter; left time: 986.0843s\n",
      "\titers: 200, epoch: 1 | loss: 0.0871001\n",
      "\tspeed: 0.0176s/iter; left time: 391.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1031007 Vali Loss: 0.0901211 Test Loss: 0.0987843\n",
      "Validation loss decreased (inf --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744202\n",
      "\tspeed: 0.0399s/iter; left time: 880.2678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0627046\n",
      "\tspeed: 0.0176s/iter; left time: 387.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0707878 Vali Loss: 0.0750685 Test Loss: 0.0840957\n",
      "Validation loss decreased (0.090121 --> 0.075069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646639\n",
      "\tspeed: 0.0380s/iter; left time: 829.7925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631343\n",
      "\tspeed: 0.0185s/iter; left time: 403.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0642391 Vali Loss: 0.0723593 Test Loss: 0.0822695\n",
      "Validation loss decreased (0.075069 --> 0.072359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610678\n",
      "\tspeed: 0.0388s/iter; left time: 838.9979s\n",
      "\titers: 200, epoch: 4 | loss: 0.0642769\n",
      "\tspeed: 0.0196s/iter; left time: 421.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0623806 Vali Loss: 0.0713594 Test Loss: 0.0812874\n",
      "Validation loss decreased (0.072359 --> 0.071359).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621786\n",
      "\tspeed: 0.0390s/iter; left time: 835.2215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588774\n",
      "\tspeed: 0.0199s/iter; left time: 424.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0612256 Vali Loss: 0.0713809 Test Loss: 0.0812414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647122\n",
      "\tspeed: 0.0367s/iter; left time: 776.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587326\n",
      "\tspeed: 0.0176s/iter; left time: 371.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0604238 Vali Loss: 0.0708679 Test Loss: 0.0803343\n",
      "Validation loss decreased (0.071359 --> 0.070868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0619604\n",
      "\tspeed: 0.0379s/iter; left time: 793.8591s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573329\n",
      "\tspeed: 0.0176s/iter; left time: 367.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0597714 Vali Loss: 0.0706334 Test Loss: 0.0803544\n",
      "Validation loss decreased (0.070868 --> 0.070633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0618974\n",
      "\tspeed: 0.0390s/iter; left time: 809.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577334\n",
      "\tspeed: 0.0230s/iter; left time: 475.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0593515 Vali Loss: 0.0705784 Test Loss: 0.0799828\n",
      "Validation loss decreased (0.070633 --> 0.070578).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578773\n",
      "\tspeed: 0.0423s/iter; left time: 866.8690s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587067\n",
      "\tspeed: 0.0201s/iter; left time: 411.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0589615 Vali Loss: 0.0703924 Test Loss: 0.0804243\n",
      "Validation loss decreased (0.070578 --> 0.070392).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590116\n",
      "\tspeed: 0.0401s/iter; left time: 813.8909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0577656\n",
      "\tspeed: 0.0204s/iter; left time: 410.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0585875 Vali Loss: 0.0701964 Test Loss: 0.0800692\n",
      "Validation loss decreased (0.070392 --> 0.070196).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595273\n",
      "\tspeed: 0.0388s/iter; left time: 777.9013s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568395\n",
      "\tspeed: 0.0190s/iter; left time: 379.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0582978 Vali Loss: 0.0700665 Test Loss: 0.0801848\n",
      "Validation loss decreased (0.070196 --> 0.070066).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0578398\n",
      "\tspeed: 0.0400s/iter; left time: 792.9082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565718\n",
      "\tspeed: 0.0179s/iter; left time: 352.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0580421 Vali Loss: 0.0702680 Test Loss: 0.0803339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582126\n",
      "\tspeed: 0.0399s/iter; left time: 783.3161s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575784\n",
      "\tspeed: 0.0212s/iter; left time: 414.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0577998 Vali Loss: 0.0704259 Test Loss: 0.0806946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0567649\n",
      "\tspeed: 0.0372s/iter; left time: 721.7618s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573596\n",
      "\tspeed: 0.0178s/iter; left time: 342.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0575422 Vali Loss: 0.0701961 Test Loss: 0.0797991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537720\n",
      "\tspeed: 0.0373s/iter; left time: 714.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.0601896\n",
      "\tspeed: 0.0177s/iter; left time: 338.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0573678 Vali Loss: 0.0700427 Test Loss: 0.0800929\n",
      "Validation loss decreased (0.070066 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578917\n",
      "\tspeed: 0.0399s/iter; left time: 756.3327s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594120\n",
      "\tspeed: 0.0189s/iter; left time: 355.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0571036 Vali Loss: 0.0701092 Test Loss: 0.0802814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0561508\n",
      "\tspeed: 0.0362s/iter; left time: 677.5379s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588087\n",
      "\tspeed: 0.0178s/iter; left time: 330.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0697514 Test Loss: 0.0801798\n",
      "Validation loss decreased (0.070043 --> 0.069751).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570127\n",
      "\tspeed: 0.0401s/iter; left time: 741.0149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0550547\n",
      "\tspeed: 0.0204s/iter; left time: 374.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0568377 Vali Loss: 0.0700514 Test Loss: 0.0800432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0599390\n",
      "\tspeed: 0.0424s/iter; left time: 773.9867s\n",
      "\titers: 200, epoch: 19 | loss: 0.0592506\n",
      "\tspeed: 0.0201s/iter; left time: 365.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0566340 Vali Loss: 0.0700143 Test Loss: 0.0800947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0555497\n",
      "\tspeed: 0.0402s/iter; left time: 725.6980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594845\n",
      "\tspeed: 0.0177s/iter; left time: 317.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0565479 Vali Loss: 0.0699431 Test Loss: 0.0799722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0595895\n",
      "\tspeed: 0.0426s/iter; left time: 758.6109s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514547\n",
      "\tspeed: 0.0180s/iter; left time: 319.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0564134 Vali Loss: 0.0699077 Test Loss: 0.0799024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0577438\n",
      "\tspeed: 0.0406s/iter; left time: 713.9933s\n",
      "\titers: 200, epoch: 22 | loss: 0.0570781\n",
      "\tspeed: 0.0180s/iter; left time: 315.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0562344 Vali Loss: 0.0699412 Test Loss: 0.0799161\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543055\n",
      "\tspeed: 0.0374s/iter; left time: 650.0469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0568372\n",
      "\tspeed: 0.0178s/iter; left time: 307.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0561991 Vali Loss: 0.0698163 Test Loss: 0.0800117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0562022\n",
      "\tspeed: 0.0401s/iter; left time: 687.3905s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531656\n",
      "\tspeed: 0.0196s/iter; left time: 334.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560687 Vali Loss: 0.0699291 Test Loss: 0.0799469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552870\n",
      "\tspeed: 0.0384s/iter; left time: 650.0462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552926\n",
      "\tspeed: 0.0192s/iter; left time: 322.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0560483 Vali Loss: 0.0698628 Test Loss: 0.0803341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0539591\n",
      "\tspeed: 0.0398s/iter; left time: 663.8899s\n",
      "\titers: 200, epoch: 26 | loss: 0.0611918\n",
      "\tspeed: 0.0195s/iter; left time: 323.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0559247 Vali Loss: 0.0697493 Test Loss: 0.0802485\n",
      "Validation loss decreased (0.069751 --> 0.069749).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0552940\n",
      "\tspeed: 0.0390s/iter; left time: 643.2036s\n",
      "\titers: 200, epoch: 27 | loss: 0.0568207\n",
      "\tspeed: 0.0177s/iter; left time: 290.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0558538 Vali Loss: 0.0698645 Test Loss: 0.0802962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553827\n",
      "\tspeed: 0.0366s/iter; left time: 595.1012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0563543\n",
      "\tspeed: 0.0176s/iter; left time: 283.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0558139 Vali Loss: 0.0699737 Test Loss: 0.0799117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0549611\n",
      "\tspeed: 0.0382s/iter; left time: 612.8983s\n",
      "\titers: 200, epoch: 29 | loss: 0.0588496\n",
      "\tspeed: 0.0220s/iter; left time: 350.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0557804 Vali Loss: 0.0698076 Test Loss: 0.0803077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0569736\n",
      "\tspeed: 0.0406s/iter; left time: 642.2532s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523944\n",
      "\tspeed: 0.0191s/iter; left time: 300.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0556698 Vali Loss: 0.0699552 Test Loss: 0.0799103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0591903\n",
      "\tspeed: 0.0438s/iter; left time: 682.9421s\n",
      "\titers: 200, epoch: 31 | loss: 0.0563744\n",
      "\tspeed: 0.0195s/iter; left time: 302.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0557028 Vali Loss: 0.0698280 Test Loss: 0.0799427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0564075\n",
      "\tspeed: 0.0367s/iter; left time: 563.8824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564259\n",
      "\tspeed: 0.0178s/iter; left time: 271.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0556475 Vali Loss: 0.0699557 Test Loss: 0.0800001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0571123\n",
      "\tspeed: 0.0371s/iter; left time: 561.7987s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562876\n",
      "\tspeed: 0.0178s/iter; left time: 267.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0555754 Vali Loss: 0.0698408 Test Loss: 0.0799727\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0549147\n",
      "\tspeed: 0.0368s/iter; left time: 549.0334s\n",
      "\titers: 200, epoch: 34 | loss: 0.0569688\n",
      "\tspeed: 0.0176s/iter; left time: 260.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0555628 Vali Loss: 0.0698081 Test Loss: 0.0801774\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539672\n",
      "\tspeed: 0.0394s/iter; left time: 577.9793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0568721\n",
      "\tspeed: 0.0178s/iter; left time: 259.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0555678 Vali Loss: 0.0698511 Test Loss: 0.0800220\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0555374\n",
      "\tspeed: 0.0413s/iter; left time: 596.6173s\n",
      "\titers: 200, epoch: 36 | loss: 0.0540787\n",
      "\tspeed: 0.0202s/iter; left time: 289.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0554807 Vali Loss: 0.0698264 Test Loss: 0.0801089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019129442051053047, rmse:0.13830922544002533, mae:0.08024851232767105, rse:0.5350168347358704\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0993653\n",
      "\tspeed: 0.0221s/iter; left time: 493.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925130\n",
      "\tspeed: 0.0200s/iter; left time: 443.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1028261 Vali Loss: 0.0896393 Test Loss: 0.0984749\n",
      "Validation loss decreased (inf --> 0.089639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0716707\n",
      "\tspeed: 0.0402s/iter; left time: 888.0405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649474\n",
      "\tspeed: 0.0206s/iter; left time: 452.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0706721 Vali Loss: 0.0753703 Test Loss: 0.0839644\n",
      "Validation loss decreased (0.089639 --> 0.075370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619266\n",
      "\tspeed: 0.0440s/iter; left time: 960.5970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0610446\n",
      "\tspeed: 0.0202s/iter; left time: 438.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0645758 Vali Loss: 0.0726078 Test Loss: 0.0825484\n",
      "Validation loss decreased (0.075370 --> 0.072608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586112\n",
      "\tspeed: 0.0396s/iter; left time: 856.5662s\n",
      "\titers: 200, epoch: 4 | loss: 0.0566655\n",
      "\tspeed: 0.0199s/iter; left time: 429.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0626355 Vali Loss: 0.0717694 Test Loss: 0.0815929\n",
      "Validation loss decreased (0.072608 --> 0.071769).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629928\n",
      "\tspeed: 0.0434s/iter; left time: 928.5031s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631500\n",
      "\tspeed: 0.0198s/iter; left time: 421.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0614584 Vali Loss: 0.0710907 Test Loss: 0.0806131\n",
      "Validation loss decreased (0.071769 --> 0.071091).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608282\n",
      "\tspeed: 0.0438s/iter; left time: 928.3181s\n",
      "\titers: 200, epoch: 6 | loss: 0.0621219\n",
      "\tspeed: 0.0202s/iter; left time: 425.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0605699 Vali Loss: 0.0708390 Test Loss: 0.0803163\n",
      "Validation loss decreased (0.071091 --> 0.070839).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0545628\n",
      "\tspeed: 0.0392s/iter; left time: 820.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0180s/iter; left time: 375.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0599846 Vali Loss: 0.0707349 Test Loss: 0.0810065\n",
      "Validation loss decreased (0.070839 --> 0.070735).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596696\n",
      "\tspeed: 0.0429s/iter; left time: 889.9808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551469\n",
      "\tspeed: 0.0199s/iter; left time: 409.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0594251 Vali Loss: 0.0704187 Test Loss: 0.0808286\n",
      "Validation loss decreased (0.070735 --> 0.070419).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0601396\n",
      "\tspeed: 0.0434s/iter; left time: 889.6753s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632646\n",
      "\tspeed: 0.0244s/iter; left time: 497.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0589964 Vali Loss: 0.0704514 Test Loss: 0.0805737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0605195\n",
      "\tspeed: 0.0416s/iter; left time: 844.5786s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591787\n",
      "\tspeed: 0.0232s/iter; left time: 467.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0585768 Vali Loss: 0.0702656 Test Loss: 0.0809564\n",
      "Validation loss decreased (0.070419 --> 0.070266).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585001\n",
      "\tspeed: 0.0410s/iter; left time: 822.7208s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562668\n",
      "\tspeed: 0.0186s/iter; left time: 371.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0582614 Vali Loss: 0.0702181 Test Loss: 0.0812004\n",
      "Validation loss decreased (0.070266 --> 0.070218).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0563077\n",
      "\tspeed: 0.0414s/iter; left time: 821.1961s\n",
      "\titers: 200, epoch: 12 | loss: 0.0616315\n",
      "\tspeed: 0.0200s/iter; left time: 395.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0579842 Vali Loss: 0.0700841 Test Loss: 0.0812889\n",
      "Validation loss decreased (0.070218 --> 0.070084).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0610500\n",
      "\tspeed: 0.0430s/iter; left time: 843.5268s\n",
      "\titers: 200, epoch: 13 | loss: 0.0572273\n",
      "\tspeed: 0.0196s/iter; left time: 381.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0576614 Vali Loss: 0.0702207 Test Loss: 0.0815973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575464\n",
      "\tspeed: 0.0443s/iter; left time: 859.2950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597506\n",
      "\tspeed: 0.0186s/iter; left time: 359.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0574103 Vali Loss: 0.0701746 Test Loss: 0.0815515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0539393\n",
      "\tspeed: 0.0410s/iter; left time: 785.1048s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575244\n",
      "\tspeed: 0.0180s/iter; left time: 343.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0571507 Vali Loss: 0.0700377 Test Loss: 0.0809218\n",
      "Validation loss decreased (0.070084 --> 0.070038).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0552823\n",
      "\tspeed: 0.0431s/iter; left time: 816.5003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567672\n",
      "\tspeed: 0.0242s/iter; left time: 456.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0569635 Vali Loss: 0.0699133 Test Loss: 0.0814106\n",
      "Validation loss decreased (0.070038 --> 0.069913).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533414\n",
      "\tspeed: 0.0426s/iter; left time: 796.9191s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565612\n",
      "\tspeed: 0.0203s/iter; left time: 377.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0567306 Vali Loss: 0.0700455 Test Loss: 0.0815984\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608345\n",
      "\tspeed: 0.0403s/iter; left time: 745.6117s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592519\n",
      "\tspeed: 0.0183s/iter; left time: 335.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0566090 Vali Loss: 0.0699562 Test Loss: 0.0814214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0590397\n",
      "\tspeed: 0.0403s/iter; left time: 735.9679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541783\n",
      "\tspeed: 0.0202s/iter; left time: 367.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0564276 Vali Loss: 0.0701004 Test Loss: 0.0813950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572432\n",
      "\tspeed: 0.0412s/iter; left time: 742.9460s\n",
      "\titers: 200, epoch: 20 | loss: 0.0551385\n",
      "\tspeed: 0.0200s/iter; left time: 358.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0562702 Vali Loss: 0.0701160 Test Loss: 0.0818849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536732\n",
      "\tspeed: 0.0392s/iter; left time: 698.7143s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556528\n",
      "\tspeed: 0.0213s/iter; left time: 378.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0561357 Vali Loss: 0.0701280 Test Loss: 0.0817430\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0569166\n",
      "\tspeed: 0.0418s/iter; left time: 734.7146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534606\n",
      "\tspeed: 0.0236s/iter; left time: 413.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0559808 Vali Loss: 0.0702114 Test Loss: 0.0819262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0560534\n",
      "\tspeed: 0.0420s/iter; left time: 729.4056s\n",
      "\titers: 200, epoch: 23 | loss: 0.0574485\n",
      "\tspeed: 0.0224s/iter; left time: 386.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0559322 Vali Loss: 0.0700866 Test Loss: 0.0819694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0585243\n",
      "\tspeed: 0.0422s/iter; left time: 724.4744s\n",
      "\titers: 200, epoch: 24 | loss: 0.0549269\n",
      "\tspeed: 0.0235s/iter; left time: 400.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0557595 Vali Loss: 0.0701298 Test Loss: 0.0818227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0532516\n",
      "\tspeed: 0.0463s/iter; left time: 783.6475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0586018\n",
      "\tspeed: 0.0249s/iter; left time: 419.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0557496 Vali Loss: 0.0702347 Test Loss: 0.0820146\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552508\n",
      "\tspeed: 0.0463s/iter; left time: 772.7935s\n",
      "\titers: 200, epoch: 26 | loss: 0.0518143\n",
      "\tspeed: 0.0206s/iter; left time: 342.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0555888 Vali Loss: 0.0702477 Test Loss: 0.0821850\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019507648423314095, rmse:0.13966979086399078, mae:0.08141053467988968, rse:0.5402798652648926\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:24.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1048215\n",
      "\tspeed: 0.0448s/iter; left time: 993.6942s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905720\n",
      "\tspeed: 0.0178s/iter; left time: 393.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.1048050 Vali Loss: 0.0926501 Test Loss: 0.1004419\n",
      "Validation loss decreased (inf --> 0.092650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0787801\n",
      "\tspeed: 0.0392s/iter; left time: 860.8228s\n",
      "\titers: 200, epoch: 2 | loss: 0.0704006\n",
      "\tspeed: 0.0178s/iter; left time: 390.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0745573 Vali Loss: 0.0786099 Test Loss: 0.0878751\n",
      "Validation loss decreased (0.092650 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726460\n",
      "\tspeed: 0.0391s/iter; left time: 849.8043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645619\n",
      "\tspeed: 0.0178s/iter; left time: 386.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0679619 Vali Loss: 0.0757840 Test Loss: 0.0871083\n",
      "Validation loss decreased (0.078610 --> 0.075784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659405\n",
      "\tspeed: 0.0392s/iter; left time: 844.1832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0691877\n",
      "\tspeed: 0.0180s/iter; left time: 385.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0661932 Vali Loss: 0.0753940 Test Loss: 0.0867535\n",
      "Validation loss decreased (0.075784 --> 0.075394).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0673685\n",
      "\tspeed: 0.0386s/iter; left time: 823.0725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653306\n",
      "\tspeed: 0.0184s/iter; left time: 390.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0651771 Vali Loss: 0.0749387 Test Loss: 0.0866767\n",
      "Validation loss decreased (0.075394 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0621401\n",
      "\tspeed: 0.0391s/iter; left time: 825.2142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653071\n",
      "\tspeed: 0.0183s/iter; left time: 385.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0644035 Vali Loss: 0.0745415 Test Loss: 0.0861986\n",
      "Validation loss decreased (0.074939 --> 0.074541).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0668753\n",
      "\tspeed: 0.0396s/iter; left time: 826.2922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647811\n",
      "\tspeed: 0.0181s/iter; left time: 376.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0638201 Vali Loss: 0.0746210 Test Loss: 0.0858707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0590196\n",
      "\tspeed: 0.0405s/iter; left time: 835.0479s\n",
      "\titers: 200, epoch: 8 | loss: 0.0675284\n",
      "\tspeed: 0.0182s/iter; left time: 374.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0633939 Vali Loss: 0.0744509 Test Loss: 0.0864062\n",
      "Validation loss decreased (0.074541 --> 0.074451).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666170\n",
      "\tspeed: 0.0394s/iter; left time: 805.2458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584317\n",
      "\tspeed: 0.0178s/iter; left time: 360.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0629750 Vali Loss: 0.0741344 Test Loss: 0.0858306\n",
      "Validation loss decreased (0.074451 --> 0.074134).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615673\n",
      "\tspeed: 0.0384s/iter; left time: 775.9894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0612158\n",
      "\tspeed: 0.0178s/iter; left time: 357.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0626131 Vali Loss: 0.0743963 Test Loss: 0.0868935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669771\n",
      "\tspeed: 0.0389s/iter; left time: 776.3254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0583333\n",
      "\tspeed: 0.0182s/iter; left time: 360.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0622680 Vali Loss: 0.0740912 Test Loss: 0.0864191\n",
      "Validation loss decreased (0.074134 --> 0.074091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0600857\n",
      "\tspeed: 0.0398s/iter; left time: 785.8133s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624289\n",
      "\tspeed: 0.0182s/iter; left time: 357.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0620072 Vali Loss: 0.0738088 Test Loss: 0.0868813\n",
      "Validation loss decreased (0.074091 --> 0.073809).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0633508\n",
      "\tspeed: 0.0382s/iter; left time: 746.2036s\n",
      "\titers: 200, epoch: 13 | loss: 0.0622426\n",
      "\tspeed: 0.0177s/iter; left time: 344.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0617034 Vali Loss: 0.0738194 Test Loss: 0.0859601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0624652\n",
      "\tspeed: 0.0432s/iter; left time: 833.1308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0640134\n",
      "\tspeed: 0.0223s/iter; left time: 428.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0614224 Vali Loss: 0.0735637 Test Loss: 0.0866766\n",
      "Validation loss decreased (0.073809 --> 0.073564).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0592811\n",
      "\tspeed: 0.0412s/iter; left time: 786.3647s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659775\n",
      "\tspeed: 0.0198s/iter; left time: 375.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0612476 Vali Loss: 0.0735167 Test Loss: 0.0868006\n",
      "Validation loss decreased (0.073564 --> 0.073517).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0644561\n",
      "\tspeed: 0.0412s/iter; left time: 777.3279s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619274\n",
      "\tspeed: 0.0179s/iter; left time: 336.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0610197 Vali Loss: 0.0734734 Test Loss: 0.0862646\n",
      "Validation loss decreased (0.073517 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604587\n",
      "\tspeed: 0.0385s/iter; left time: 717.5171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619207\n",
      "\tspeed: 0.0182s/iter; left time: 337.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0608512 Vali Loss: 0.0734382 Test Loss: 0.0864064\n",
      "Validation loss decreased (0.073473 --> 0.073438).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621410\n",
      "\tspeed: 0.0444s/iter; left time: 816.7679s\n",
      "\titers: 200, epoch: 18 | loss: 0.0610293\n",
      "\tspeed: 0.0209s/iter; left time: 382.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0606406 Vali Loss: 0.0735055 Test Loss: 0.0865836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0594858\n",
      "\tspeed: 0.0395s/iter; left time: 717.9466s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603400\n",
      "\tspeed: 0.0225s/iter; left time: 407.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0604943 Vali Loss: 0.0733934 Test Loss: 0.0866218\n",
      "Validation loss decreased (0.073438 --> 0.073393).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621189\n",
      "\tspeed: 0.0405s/iter; left time: 726.9494s\n",
      "\titers: 200, epoch: 20 | loss: 0.0579614\n",
      "\tspeed: 0.0179s/iter; left time: 320.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0603450 Vali Loss: 0.0734274 Test Loss: 0.0866431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0576071\n",
      "\tspeed: 0.0397s/iter; left time: 705.1230s\n",
      "\titers: 200, epoch: 21 | loss: 0.0587716\n",
      "\tspeed: 0.0182s/iter; left time: 320.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0602134 Vali Loss: 0.0735609 Test Loss: 0.0867124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0592390\n",
      "\tspeed: 0.0411s/iter; left time: 719.6329s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672747\n",
      "\tspeed: 0.0205s/iter; left time: 357.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0601358 Vali Loss: 0.0734848 Test Loss: 0.0864877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0589457\n",
      "\tspeed: 0.0420s/iter; left time: 727.1040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600802\n",
      "\tspeed: 0.0195s/iter; left time: 334.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0600169 Vali Loss: 0.0735971 Test Loss: 0.0867336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0622105\n",
      "\tspeed: 0.0390s/iter; left time: 665.8311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0587972\n",
      "\tspeed: 0.0185s/iter; left time: 314.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0599399 Vali Loss: 0.0733272 Test Loss: 0.0868346\n",
      "Validation loss decreased (0.073393 --> 0.073327).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0618487\n",
      "\tspeed: 0.0408s/iter; left time: 686.9191s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623286\n",
      "\tspeed: 0.0199s/iter; left time: 332.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0598832 Vali Loss: 0.0733698 Test Loss: 0.0870481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628185\n",
      "\tspeed: 0.0403s/iter; left time: 669.1997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600777\n",
      "\tspeed: 0.0178s/iter; left time: 294.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0597476 Vali Loss: 0.0735480 Test Loss: 0.0870731\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584035\n",
      "\tspeed: 0.0386s/iter; left time: 633.3759s\n",
      "\titers: 200, epoch: 27 | loss: 0.0596758\n",
      "\tspeed: 0.0178s/iter; left time: 290.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0597152 Vali Loss: 0.0735673 Test Loss: 0.0869513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0575937\n",
      "\tspeed: 0.0411s/iter; left time: 664.7704s\n",
      "\titers: 200, epoch: 28 | loss: 0.0598191\n",
      "\tspeed: 0.0194s/iter; left time: 311.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0596151 Vali Loss: 0.0735890 Test Loss: 0.0869191\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602850\n",
      "\tspeed: 0.0385s/iter; left time: 614.2782s\n",
      "\titers: 200, epoch: 29 | loss: 0.0603580\n",
      "\tspeed: 0.0199s/iter; left time: 315.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0595701 Vali Loss: 0.0735271 Test Loss: 0.0868389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0609483\n",
      "\tspeed: 0.0398s/iter; left time: 625.4291s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605431\n",
      "\tspeed: 0.0178s/iter; left time: 277.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0595073 Vali Loss: 0.0735774 Test Loss: 0.0868500\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565855\n",
      "\tspeed: 0.0380s/iter; left time: 588.8619s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568368\n",
      "\tspeed: 0.0178s/iter; left time: 273.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0594662 Vali Loss: 0.0736190 Test Loss: 0.0867959\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585387\n",
      "\tspeed: 0.0384s/iter; left time: 586.9124s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621870\n",
      "\tspeed: 0.0179s/iter; left time: 271.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0594207 Vali Loss: 0.0734954 Test Loss: 0.0867695\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0560987\n",
      "\tspeed: 0.0403s/iter; left time: 607.2936s\n",
      "\titers: 200, epoch: 33 | loss: 0.0594956\n",
      "\tspeed: 0.0179s/iter; left time: 267.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0594061 Vali Loss: 0.0736040 Test Loss: 0.0867877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592257\n",
      "\tspeed: 0.0398s/iter; left time: 590.9892s\n",
      "\titers: 200, epoch: 34 | loss: 0.0612799\n",
      "\tspeed: 0.0178s/iter; left time: 262.3133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0593490 Vali Loss: 0.0734889 Test Loss: 0.0869637\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021609371528029442, rmse:0.1470012664794922, mae:0.08683455735445023, rse:0.5693498253822327\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1029223\n",
      "\tspeed: 0.0243s/iter; left time: 539.9811s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873014\n",
      "\tspeed: 0.0203s/iter; left time: 449.2947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.1060672 Vali Loss: 0.0924755 Test Loss: 0.1004355\n",
      "Validation loss decreased (inf --> 0.092476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753753\n",
      "\tspeed: 0.0444s/iter; left time: 975.9962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723152\n",
      "\tspeed: 0.0240s/iter; left time: 525.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0746971 Vali Loss: 0.0789733 Test Loss: 0.0883853\n",
      "Validation loss decreased (0.092476 --> 0.078973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749349\n",
      "\tspeed: 0.0390s/iter; left time: 849.2280s\n",
      "\titers: 200, epoch: 3 | loss: 0.0635487\n",
      "\tspeed: 0.0181s/iter; left time: 391.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0682782 Vali Loss: 0.0764451 Test Loss: 0.0874010\n",
      "Validation loss decreased (0.078973 --> 0.076445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650547\n",
      "\tspeed: 0.0431s/iter; left time: 927.6328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0675071\n",
      "\tspeed: 0.0189s/iter; left time: 404.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0665174 Vali Loss: 0.0751456 Test Loss: 0.0865133\n",
      "Validation loss decreased (0.076445 --> 0.075146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633389\n",
      "\tspeed: 0.0399s/iter; left time: 850.2645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628508\n",
      "\tspeed: 0.0180s/iter; left time: 380.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0653938 Vali Loss: 0.0750249 Test Loss: 0.0866540\n",
      "Validation loss decreased (0.075146 --> 0.075025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610570\n",
      "\tspeed: 0.0435s/iter; left time: 916.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0691948\n",
      "\tspeed: 0.0227s/iter; left time: 476.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0645714 Vali Loss: 0.0748224 Test Loss: 0.0866774\n",
      "Validation loss decreased (0.075025 --> 0.074822).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0635364\n",
      "\tspeed: 0.0438s/iter; left time: 913.4307s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676383\n",
      "\tspeed: 0.0196s/iter; left time: 405.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0640450 Vali Loss: 0.0747084 Test Loss: 0.0860682\n",
      "Validation loss decreased (0.074822 --> 0.074708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0642655\n",
      "\tspeed: 0.0433s/iter; left time: 894.1643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633054\n",
      "\tspeed: 0.0209s/iter; left time: 430.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0635069 Vali Loss: 0.0743306 Test Loss: 0.0875940\n",
      "Validation loss decreased (0.074708 --> 0.074331).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672177\n",
      "\tspeed: 0.0429s/iter; left time: 874.8904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657890\n",
      "\tspeed: 0.0209s/iter; left time: 424.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0630452 Vali Loss: 0.0741678 Test Loss: 0.0868630\n",
      "Validation loss decreased (0.074331 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632034\n",
      "\tspeed: 0.0434s/iter; left time: 876.3151s\n",
      "\titers: 200, epoch: 10 | loss: 0.0645544\n",
      "\tspeed: 0.0202s/iter; left time: 404.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0627409 Vali Loss: 0.0743513 Test Loss: 0.0880571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0636334\n",
      "\tspeed: 0.0404s/iter; left time: 806.8377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602807\n",
      "\tspeed: 0.0178s/iter; left time: 353.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0623453 Vali Loss: 0.0742074 Test Loss: 0.0878647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583318\n",
      "\tspeed: 0.0410s/iter; left time: 808.9365s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650040\n",
      "\tspeed: 0.0179s/iter; left time: 352.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0620972 Vali Loss: 0.0737038 Test Loss: 0.0867297\n",
      "Validation loss decreased (0.074168 --> 0.073704).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0613920\n",
      "\tspeed: 0.0414s/iter; left time: 808.6399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0611318\n",
      "\tspeed: 0.0182s/iter; left time: 353.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0618523 Vali Loss: 0.0738235 Test Loss: 0.0875536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0610238\n",
      "\tspeed: 0.0386s/iter; left time: 744.5537s\n",
      "\titers: 200, epoch: 14 | loss: 0.0601860\n",
      "\tspeed: 0.0179s/iter; left time: 343.8556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0615380 Vali Loss: 0.0738372 Test Loss: 0.0877525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598381\n",
      "\tspeed: 0.0387s/iter; left time: 738.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0587940\n",
      "\tspeed: 0.0178s/iter; left time: 338.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0612895 Vali Loss: 0.0739167 Test Loss: 0.0872995\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566209\n",
      "\tspeed: 0.0421s/iter; left time: 794.7425s\n",
      "\titers: 200, epoch: 16 | loss: 0.0571298\n",
      "\tspeed: 0.0183s/iter; left time: 343.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0611391 Vali Loss: 0.0740395 Test Loss: 0.0877071\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624488\n",
      "\tspeed: 0.0436s/iter; left time: 813.1598s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577584\n",
      "\tspeed: 0.0198s/iter; left time: 367.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0609111 Vali Loss: 0.0737153 Test Loss: 0.0876156\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0645408\n",
      "\tspeed: 0.0412s/iter; left time: 758.7901s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614708\n",
      "\tspeed: 0.0182s/iter; left time: 332.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0607212 Vali Loss: 0.0740565 Test Loss: 0.0879836\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0585145\n",
      "\tspeed: 0.0441s/iter; left time: 802.3411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603509\n",
      "\tspeed: 0.0209s/iter; left time: 378.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0606192 Vali Loss: 0.0737144 Test Loss: 0.0875244\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0605584\n",
      "\tspeed: 0.0389s/iter; left time: 698.6056s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584688\n",
      "\tspeed: 0.0180s/iter; left time: 321.6657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0604933 Vali Loss: 0.0737341 Test Loss: 0.0881607\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0649967\n",
      "\tspeed: 0.0399s/iter; left time: 707.6438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591727\n",
      "\tspeed: 0.0178s/iter; left time: 314.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0603355 Vali Loss: 0.0738130 Test Loss: 0.0877827\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593023\n",
      "\tspeed: 0.0445s/iter; left time: 779.7140s\n",
      "\titers: 200, epoch: 22 | loss: 0.0619041\n",
      "\tspeed: 0.0183s/iter; left time: 319.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0601923 Vali Loss: 0.0737966 Test Loss: 0.0876334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021043021231889725, rmse:0.1450621336698532, mae:0.08672972023487091, rse:0.5618393421173096\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:46.06s\n",
      "Intermediate time for FR: 00h:23m:12.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1379552\n",
      "\tspeed: 0.0457s/iter; left time: 1019.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160477\n",
      "\tspeed: 0.0178s/iter; left time: 394.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1433041 Vali Loss: 0.0977655 Test Loss: 0.1001861\n",
      "Validation loss decreased (inf --> 0.097766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780573\n",
      "\tspeed: 0.0397s/iter; left time: 877.4531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670697\n",
      "\tspeed: 0.0178s/iter; left time: 390.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0783016 Vali Loss: 0.0630192 Test Loss: 0.0662496\n",
      "Validation loss decreased (0.097766 --> 0.063019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0623454\n",
      "\tspeed: 0.0369s/iter; left time: 805.5581s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655507\n",
      "\tspeed: 0.0175s/iter; left time: 381.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0659248 Vali Loss: 0.0605475 Test Loss: 0.0632674\n",
      "Validation loss decreased (0.063019 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630882\n",
      "\tspeed: 0.0372s/iter; left time: 805.2769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0590766\n",
      "\tspeed: 0.0177s/iter; left time: 380.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628566 Vali Loss: 0.0584909 Test Loss: 0.0608319\n",
      "Validation loss decreased (0.060548 --> 0.058491).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0591956\n",
      "\tspeed: 0.0442s/iter; left time: 946.6197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0613977\n",
      "\tspeed: 0.0240s/iter; left time: 510.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0611276 Vali Loss: 0.0580106 Test Loss: 0.0599504\n",
      "Validation loss decreased (0.058491 --> 0.058011).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577363\n",
      "\tspeed: 0.0466s/iter; left time: 987.1521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0550658\n",
      "\tspeed: 0.0258s/iter; left time: 543.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0599828 Vali Loss: 0.0571707 Test Loss: 0.0595299\n",
      "Validation loss decreased (0.058011 --> 0.057171).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0601596\n",
      "\tspeed: 0.0470s/iter; left time: 985.0367s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558117\n",
      "\tspeed: 0.0244s/iter; left time: 508.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0591725 Vali Loss: 0.0566996 Test Loss: 0.0588407\n",
      "Validation loss decreased (0.057171 --> 0.056700).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567679\n",
      "\tspeed: 0.0453s/iter; left time: 938.7148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577220\n",
      "\tspeed: 0.0207s/iter; left time: 427.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0585837 Vali Loss: 0.0563851 Test Loss: 0.0587719\n",
      "Validation loss decreased (0.056700 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0536918\n",
      "\tspeed: 0.0433s/iter; left time: 888.3929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0593248\n",
      "\tspeed: 0.0202s/iter; left time: 412.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0579274 Vali Loss: 0.0560959 Test Loss: 0.0584001\n",
      "Validation loss decreased (0.056385 --> 0.056096).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576015\n",
      "\tspeed: 0.0392s/iter; left time: 795.0024s\n",
      "\titers: 200, epoch: 10 | loss: 0.0572641\n",
      "\tspeed: 0.0197s/iter; left time: 397.1217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0574487 Vali Loss: 0.0561246 Test Loss: 0.0586067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603743\n",
      "\tspeed: 0.0446s/iter; left time: 894.4247s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529461\n",
      "\tspeed: 0.0243s/iter; left time: 485.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0571570 Vali Loss: 0.0558561 Test Loss: 0.0580777\n",
      "Validation loss decreased (0.056096 --> 0.055856).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538307\n",
      "\tspeed: 0.0408s/iter; left time: 809.1254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0569894\n",
      "\tspeed: 0.0203s/iter; left time: 401.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0567255 Vali Loss: 0.0555736 Test Loss: 0.0576931\n",
      "Validation loss decreased (0.055856 --> 0.055574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559114\n",
      "\tspeed: 0.0453s/iter; left time: 888.4679s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570156\n",
      "\tspeed: 0.0183s/iter; left time: 357.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0564412 Vali Loss: 0.0555875 Test Loss: 0.0576721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608026\n",
      "\tspeed: 0.0409s/iter; left time: 793.3031s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548942\n",
      "\tspeed: 0.0202s/iter; left time: 389.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0562439 Vali Loss: 0.0556266 Test Loss: 0.0576045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0568721\n",
      "\tspeed: 0.0432s/iter; left time: 828.8342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553573\n",
      "\tspeed: 0.0237s/iter; left time: 452.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0559618 Vali Loss: 0.0554153 Test Loss: 0.0574718\n",
      "Validation loss decreased (0.055574 --> 0.055415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573713\n",
      "\tspeed: 0.0398s/iter; left time: 754.3022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561678\n",
      "\tspeed: 0.0175s/iter; left time: 329.9052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0558215 Vali Loss: 0.0551744 Test Loss: 0.0573095\n",
      "Validation loss decreased (0.055415 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589329\n",
      "\tspeed: 0.0376s/iter; left time: 703.8887s\n",
      "\titers: 200, epoch: 17 | loss: 0.0574918\n",
      "\tspeed: 0.0179s/iter; left time: 332.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0556505 Vali Loss: 0.0550482 Test Loss: 0.0572504\n",
      "Validation loss decreased (0.055174 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534935\n",
      "\tspeed: 0.0414s/iter; left time: 765.8245s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574331\n",
      "\tspeed: 0.0198s/iter; left time: 364.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0554857 Vali Loss: 0.0549875 Test Loss: 0.0572133\n",
      "Validation loss decreased (0.055048 --> 0.054988).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556992\n",
      "\tspeed: 0.0385s/iter; left time: 704.2454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604655\n",
      "\tspeed: 0.0240s/iter; left time: 435.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0553156 Vali Loss: 0.0548461 Test Loss: 0.0571244\n",
      "Validation loss decreased (0.054988 --> 0.054846).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546956\n",
      "\tspeed: 0.0414s/iter; left time: 746.4803s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543233\n",
      "\tspeed: 0.0245s/iter; left time: 440.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0551500 Vali Loss: 0.0548050 Test Loss: 0.0570001\n",
      "Validation loss decreased (0.054846 --> 0.054805).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0572998\n",
      "\tspeed: 0.0456s/iter; left time: 812.4846s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540240\n",
      "\tspeed: 0.0193s/iter; left time: 341.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0551207 Vali Loss: 0.0548231 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534088\n",
      "\tspeed: 0.0378s/iter; left time: 664.9020s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502284\n",
      "\tspeed: 0.0173s/iter; left time: 302.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0549312 Vali Loss: 0.0548708 Test Loss: 0.0570204\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0540605\n",
      "\tspeed: 0.0385s/iter; left time: 668.9097s\n",
      "\titers: 200, epoch: 23 | loss: 0.0507261\n",
      "\tspeed: 0.0178s/iter; left time: 306.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0548571 Vali Loss: 0.0547824 Test Loss: 0.0569985\n",
      "Validation loss decreased (0.054805 --> 0.054782).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583674\n",
      "\tspeed: 0.0442s/iter; left time: 758.5964s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544730\n",
      "\tspeed: 0.0176s/iter; left time: 299.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0547987 Vali Loss: 0.0546288 Test Loss: 0.0570315\n",
      "Validation loss decreased (0.054782 --> 0.054629).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508277\n",
      "\tspeed: 0.0373s/iter; left time: 631.7015s\n",
      "\titers: 200, epoch: 25 | loss: 0.0581925\n",
      "\tspeed: 0.0194s/iter; left time: 327.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0547711 Vali Loss: 0.0544805 Test Loss: 0.0568517\n",
      "Validation loss decreased (0.054629 --> 0.054480).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556801\n",
      "\tspeed: 0.0391s/iter; left time: 653.4126s\n",
      "\titers: 200, epoch: 26 | loss: 0.0554455\n",
      "\tspeed: 0.0195s/iter; left time: 323.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0546281 Vali Loss: 0.0546029 Test Loss: 0.0568632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572915\n",
      "\tspeed: 0.0379s/iter; left time: 623.7133s\n",
      "\titers: 200, epoch: 27 | loss: 0.0576790\n",
      "\tspeed: 0.0253s/iter; left time: 414.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0545952 Vali Loss: 0.0546437 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563810\n",
      "\tspeed: 0.0466s/iter; left time: 756.6862s\n",
      "\titers: 200, epoch: 28 | loss: 0.0515816\n",
      "\tspeed: 0.0244s/iter; left time: 393.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0545041 Vali Loss: 0.0544355 Test Loss: 0.0567258\n",
      "Validation loss decreased (0.054480 --> 0.054436).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0575383\n",
      "\tspeed: 0.0415s/iter; left time: 665.5287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0517639\n",
      "\tspeed: 0.0202s/iter; left time: 321.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0544492 Vali Loss: 0.0544463 Test Loss: 0.0569202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0554202\n",
      "\tspeed: 0.0422s/iter; left time: 667.1427s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573169\n",
      "\tspeed: 0.0204s/iter; left time: 320.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0544512 Vali Loss: 0.0544945 Test Loss: 0.0567682\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525765\n",
      "\tspeed: 0.0452s/iter; left time: 704.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568761\n",
      "\tspeed: 0.0243s/iter; left time: 375.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0543604 Vali Loss: 0.0544442 Test Loss: 0.0567680\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0544155\n",
      "\tspeed: 0.0463s/iter; left time: 711.2055s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564592\n",
      "\tspeed: 0.0197s/iter; left time: 301.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0543330 Vali Loss: 0.0544301 Test Loss: 0.0567419\n",
      "Validation loss decreased (0.054436 --> 0.054430).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549597\n",
      "\tspeed: 0.0429s/iter; left time: 648.7709s\n",
      "\titers: 200, epoch: 33 | loss: 0.0541910\n",
      "\tspeed: 0.0181s/iter; left time: 272.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0543469 Vali Loss: 0.0543835 Test Loss: 0.0567440\n",
      "Validation loss decreased (0.054430 --> 0.054384).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0571987\n",
      "\tspeed: 0.0416s/iter; left time: 620.5499s\n",
      "\titers: 200, epoch: 34 | loss: 0.0567482\n",
      "\tspeed: 0.0201s/iter; left time: 297.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0543108 Vali Loss: 0.0543652 Test Loss: 0.0567222\n",
      "Validation loss decreased (0.054384 --> 0.054365).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535260\n",
      "\tspeed: 0.0423s/iter; left time: 621.8226s\n",
      "\titers: 200, epoch: 35 | loss: 0.0561866\n",
      "\tspeed: 0.0193s/iter; left time: 281.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0542972 Vali Loss: 0.0544265 Test Loss: 0.0567667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0549961\n",
      "\tspeed: 0.0410s/iter; left time: 593.5670s\n",
      "\titers: 200, epoch: 36 | loss: 0.0541536\n",
      "\tspeed: 0.0192s/iter; left time: 275.6673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0542406 Vali Loss: 0.0544166 Test Loss: 0.0566596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532916\n",
      "\tspeed: 0.0400s/iter; left time: 569.6183s\n",
      "\titers: 200, epoch: 37 | loss: 0.0511241\n",
      "\tspeed: 0.0198s/iter; left time: 280.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0542641 Vali Loss: 0.0543706 Test Loss: 0.0566760\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0539109\n",
      "\tspeed: 0.0399s/iter; left time: 558.4617s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564077\n",
      "\tspeed: 0.0205s/iter; left time: 285.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0541845 Vali Loss: 0.0543355 Test Loss: 0.0566975\n",
      "Validation loss decreased (0.054365 --> 0.054336).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503076\n",
      "\tspeed: 0.0409s/iter; left time: 563.8564s\n",
      "\titers: 200, epoch: 39 | loss: 0.0562198\n",
      "\tspeed: 0.0200s/iter; left time: 273.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0541782 Vali Loss: 0.0543724 Test Loss: 0.0566402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552053\n",
      "\tspeed: 0.0407s/iter; left time: 552.2094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0516493\n",
      "\tspeed: 0.0199s/iter; left time: 267.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0543906 Test Loss: 0.0566315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0556425\n",
      "\tspeed: 0.0412s/iter; left time: 550.0056s\n",
      "\titers: 200, epoch: 41 | loss: 0.0509712\n",
      "\tspeed: 0.0201s/iter; left time: 266.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0541427 Vali Loss: 0.0543536 Test Loss: 0.0566362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523108\n",
      "\tspeed: 0.0422s/iter; left time: 553.7186s\n",
      "\titers: 200, epoch: 42 | loss: 0.0576750\n",
      "\tspeed: 0.0195s/iter; left time: 253.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0541833 Vali Loss: 0.0542894 Test Loss: 0.0566669\n",
      "Validation loss decreased (0.054336 --> 0.054289).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0529656\n",
      "\tspeed: 0.0435s/iter; left time: 561.1621s\n",
      "\titers: 200, epoch: 43 | loss: 0.0502761\n",
      "\tspeed: 0.0229s/iter; left time: 292.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0541143 Vali Loss: 0.0543694 Test Loss: 0.0566259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537367\n",
      "\tspeed: 0.0447s/iter; left time: 566.3745s\n",
      "\titers: 200, epoch: 44 | loss: 0.0559055\n",
      "\tspeed: 0.0200s/iter; left time: 251.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0541310 Vali Loss: 0.0542568 Test Loss: 0.0566117\n",
      "Validation loss decreased (0.054289 --> 0.054257).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0569029\n",
      "\tspeed: 0.0405s/iter; left time: 504.4566s\n",
      "\titers: 200, epoch: 45 | loss: 0.0579741\n",
      "\tspeed: 0.0183s/iter; left time: 225.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0541451 Vali Loss: 0.0543393 Test Loss: 0.0566353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0510111\n",
      "\tspeed: 0.0435s/iter; left time: 531.5669s\n",
      "\titers: 200, epoch: 46 | loss: 0.0570540\n",
      "\tspeed: 0.0194s/iter; left time: 235.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0543384 Test Loss: 0.0565993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0603271\n",
      "\tspeed: 0.0408s/iter; left time: 489.8614s\n",
      "\titers: 200, epoch: 47 | loss: 0.0489362\n",
      "\tspeed: 0.0221s/iter; left time: 262.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0541158 Vali Loss: 0.0542949 Test Loss: 0.0566084\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0562014\n",
      "\tspeed: 0.0430s/iter; left time: 506.5203s\n",
      "\titers: 200, epoch: 48 | loss: 0.0527634\n",
      "\tspeed: 0.0175s/iter; left time: 204.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0541052 Vali Loss: 0.0542426 Test Loss: 0.0566221\n",
      "Validation loss decreased (0.054257 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0550343\n",
      "\tspeed: 0.0405s/iter; left time: 468.1700s\n",
      "\titers: 200, epoch: 49 | loss: 0.0519099\n",
      "\tspeed: 0.0199s/iter; left time: 227.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0540786 Vali Loss: 0.0543246 Test Loss: 0.0566017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0535444\n",
      "\tspeed: 0.0454s/iter; left time: 514.6661s\n",
      "\titers: 200, epoch: 50 | loss: 0.0502683\n",
      "\tspeed: 0.0237s/iter; left time: 265.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0540946 Vali Loss: 0.0542993 Test Loss: 0.0566170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525270\n",
      "\tspeed: 0.0416s/iter; left time: 462.1014s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515277\n",
      "\tspeed: 0.0226s/iter; left time: 248.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0542633 Test Loss: 0.0566191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0528202\n",
      "\tspeed: 0.0388s/iter; left time: 422.3969s\n",
      "\titers: 200, epoch: 52 | loss: 0.0524368\n",
      "\tspeed: 0.0174s/iter; left time: 187.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0540361 Vali Loss: 0.0542905 Test Loss: 0.0565996\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548940\n",
      "\tspeed: 0.0396s/iter; left time: 421.7677s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519573\n",
      "\tspeed: 0.0204s/iter; left time: 214.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0541037 Vali Loss: 0.0542877 Test Loss: 0.0566198\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533164\n",
      "\tspeed: 0.0430s/iter; left time: 448.0185s\n",
      "\titers: 200, epoch: 54 | loss: 0.0578958\n",
      "\tspeed: 0.0241s/iter; left time: 249.1271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0540474 Vali Loss: 0.0542890 Test Loss: 0.0566051\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548727\n",
      "\tspeed: 0.0412s/iter; left time: 419.9655s\n",
      "\titers: 200, epoch: 55 | loss: 0.0566967\n",
      "\tspeed: 0.0198s/iter; left time: 200.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0540961 Vali Loss: 0.0543088 Test Loss: 0.0566188\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0531577\n",
      "\tspeed: 0.0392s/iter; left time: 391.2384s\n",
      "\titers: 200, epoch: 56 | loss: 0.0580916\n",
      "\tspeed: 0.0175s/iter; left time: 173.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0540501 Vali Loss: 0.0543088 Test Loss: 0.0566136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0559601\n",
      "\tspeed: 0.0367s/iter; left time: 358.4146s\n",
      "\titers: 200, epoch: 57 | loss: 0.0543095\n",
      "\tspeed: 0.0174s/iter; left time: 167.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0540529 Vali Loss: 0.0542350 Test Loss: 0.0566049\n",
      "Validation loss decreased (0.054243 --> 0.054235).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538715\n",
      "\tspeed: 0.0394s/iter; left time: 375.2252s\n",
      "\titers: 200, epoch: 58 | loss: 0.0555631\n",
      "\tspeed: 0.0176s/iter; left time: 165.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0540707 Vali Loss: 0.0542733 Test Loss: 0.0566099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0560754\n",
      "\tspeed: 0.0395s/iter; left time: 367.5105s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519199\n",
      "\tspeed: 0.0216s/iter; left time: 199.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0540248 Vali Loss: 0.0542616 Test Loss: 0.0566028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0571120\n",
      "\tspeed: 0.0394s/iter; left time: 358.0110s\n",
      "\titers: 200, epoch: 60 | loss: 0.0582117\n",
      "\tspeed: 0.0174s/iter; left time: 156.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0542328 Test Loss: 0.0565980\n",
      "Validation loss decreased (0.054235 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0584766\n",
      "\tspeed: 0.0408s/iter; left time: 361.3126s\n",
      "\titers: 200, epoch: 61 | loss: 0.0535091\n",
      "\tspeed: 0.0177s/iter; left time: 154.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0540387 Vali Loss: 0.0543091 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0581197\n",
      "\tspeed: 0.0361s/iter; left time: 312.1834s\n",
      "\titers: 200, epoch: 62 | loss: 0.0556779\n",
      "\tspeed: 0.0181s/iter; left time: 154.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0540725 Vali Loss: 0.0543238 Test Loss: 0.0566121\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0515098\n",
      "\tspeed: 0.0379s/iter; left time: 318.9160s\n",
      "\titers: 200, epoch: 63 | loss: 0.0547690\n",
      "\tspeed: 0.0175s/iter; left time: 145.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0539889 Vali Loss: 0.0542935 Test Loss: 0.0566016\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0558435\n",
      "\tspeed: 0.0362s/iter; left time: 296.3327s\n",
      "\titers: 200, epoch: 64 | loss: 0.0558558\n",
      "\tspeed: 0.0176s/iter; left time: 141.9768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0540476 Vali Loss: 0.0542764 Test Loss: 0.0566100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546813\n",
      "\tspeed: 0.0395s/iter; left time: 314.6030s\n",
      "\titers: 200, epoch: 65 | loss: 0.0554467\n",
      "\tspeed: 0.0175s/iter; left time: 137.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540326 Vali Loss: 0.0543010 Test Loss: 0.0565934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0568983\n",
      "\tspeed: 0.0397s/iter; left time: 306.9717s\n",
      "\titers: 200, epoch: 66 | loss: 0.0544441\n",
      "\tspeed: 0.0206s/iter; left time: 157.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0540953 Vali Loss: 0.0543162 Test Loss: 0.0565933\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0554599\n",
      "\tspeed: 0.0427s/iter; left time: 321.0730s\n",
      "\titers: 200, epoch: 67 | loss: 0.0513533\n",
      "\tspeed: 0.0207s/iter; left time: 153.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0543076 Test Loss: 0.0566009\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0543297\n",
      "\tspeed: 0.0370s/iter; left time: 269.8459s\n",
      "\titers: 200, epoch: 68 | loss: 0.0517003\n",
      "\tspeed: 0.0173s/iter; left time: 124.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0540420 Vali Loss: 0.0542774 Test Loss: 0.0566046\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0578591\n",
      "\tspeed: 0.0356s/iter; left time: 251.9135s\n",
      "\titers: 200, epoch: 69 | loss: 0.0572697\n",
      "\tspeed: 0.0175s/iter; left time: 121.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0540791 Vali Loss: 0.0542371 Test Loss: 0.0566058\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0537115\n",
      "\tspeed: 0.0371s/iter; left time: 253.6271s\n",
      "\titers: 200, epoch: 70 | loss: 0.0505972\n",
      "\tspeed: 0.0210s/iter; left time: 141.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0540482 Vali Loss: 0.0542732 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083218105137348, rmse:0.10041522979736328, mae:0.0565979890525341, rse:0.3794197142124176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1359126\n",
      "\tspeed: 0.0225s/iter; left time: 502.7281s\n",
      "\titers: 200, epoch: 1 | loss: 0.1098680\n",
      "\tspeed: 0.0213s/iter; left time: 473.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1422349 Vali Loss: 0.0974500 Test Loss: 0.0992706\n",
      "Validation loss decreased (inf --> 0.097450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754588\n",
      "\tspeed: 0.0417s/iter; left time: 921.0493s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673907\n",
      "\tspeed: 0.0174s/iter; left time: 382.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0780355 Vali Loss: 0.0627294 Test Loss: 0.0657381\n",
      "Validation loss decreased (0.097450 --> 0.062729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637678\n",
      "\tspeed: 0.0431s/iter; left time: 942.5154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663196\n",
      "\tspeed: 0.0196s/iter; left time: 425.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0660164 Vali Loss: 0.0599926 Test Loss: 0.0628002\n",
      "Validation loss decreased (0.062729 --> 0.059993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638419\n",
      "\tspeed: 0.0413s/iter; left time: 893.2220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635814\n",
      "\tspeed: 0.0202s/iter; left time: 435.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0630481 Vali Loss: 0.0586561 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.059993 --> 0.058656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630238\n",
      "\tspeed: 0.0430s/iter; left time: 921.1678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610638\n",
      "\tspeed: 0.0176s/iter; left time: 373.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0612143 Vali Loss: 0.0575957 Test Loss: 0.0601869\n",
      "Validation loss decreased (0.058656 --> 0.057596).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0648216\n",
      "\tspeed: 0.0375s/iter; left time: 794.3087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634050\n",
      "\tspeed: 0.0176s/iter; left time: 370.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0601831 Vali Loss: 0.0573942 Test Loss: 0.0597799\n",
      "Validation loss decreased (0.057596 --> 0.057394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599069\n",
      "\tspeed: 0.0371s/iter; left time: 778.1308s\n",
      "\titers: 200, epoch: 7 | loss: 0.0612065\n",
      "\tspeed: 0.0175s/iter; left time: 364.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593155 Vali Loss: 0.0566541 Test Loss: 0.0591102\n",
      "Validation loss decreased (0.057394 --> 0.056654).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542986\n",
      "\tspeed: 0.0415s/iter; left time: 859.8482s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572991\n",
      "\tspeed: 0.0223s/iter; left time: 460.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0585377 Vali Loss: 0.0566305 Test Loss: 0.0588562\n",
      "Validation loss decreased (0.056654 --> 0.056631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0640263\n",
      "\tspeed: 0.0471s/iter; left time: 966.1459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615080\n",
      "\tspeed: 0.0202s/iter; left time: 412.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0579915 Vali Loss: 0.0559572 Test Loss: 0.0582891\n",
      "Validation loss decreased (0.056631 --> 0.055957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577642\n",
      "\tspeed: 0.0505s/iter; left time: 1025.0210s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594756\n",
      "\tspeed: 0.0264s/iter; left time: 532.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0575409 Vali Loss: 0.0558674 Test Loss: 0.0583287\n",
      "Validation loss decreased (0.055957 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579124\n",
      "\tspeed: 0.0448s/iter; left time: 899.5653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581660\n",
      "\tspeed: 0.0204s/iter; left time: 406.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0571616 Vali Loss: 0.0555863 Test Loss: 0.0582007\n",
      "Validation loss decreased (0.055867 --> 0.055586).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0618948\n",
      "\tspeed: 0.0424s/iter; left time: 840.9896s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521666\n",
      "\tspeed: 0.0205s/iter; left time: 405.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0569079 Vali Loss: 0.0554603 Test Loss: 0.0577516\n",
      "Validation loss decreased (0.055586 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0548473\n",
      "\tspeed: 0.0413s/iter; left time: 809.2691s\n",
      "\titers: 200, epoch: 13 | loss: 0.0552182\n",
      "\tspeed: 0.0208s/iter; left time: 405.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0565429 Vali Loss: 0.0553249 Test Loss: 0.0574627\n",
      "Validation loss decreased (0.055460 --> 0.055325).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554208\n",
      "\tspeed: 0.0444s/iter; left time: 861.4926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0541941\n",
      "\tspeed: 0.0230s/iter; left time: 443.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0562538 Vali Loss: 0.0553683 Test Loss: 0.0575624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0557231\n",
      "\tspeed: 0.0443s/iter; left time: 848.9220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574080\n",
      "\tspeed: 0.0209s/iter; left time: 397.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0560413 Vali Loss: 0.0551291 Test Loss: 0.0575157\n",
      "Validation loss decreased (0.055325 --> 0.055129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575104\n",
      "\tspeed: 0.0396s/iter; left time: 749.1542s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551079\n",
      "\tspeed: 0.0208s/iter; left time: 392.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0557593 Vali Loss: 0.0548837 Test Loss: 0.0574590\n",
      "Validation loss decreased (0.055129 --> 0.054884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595915\n",
      "\tspeed: 0.0407s/iter; left time: 761.5210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584150\n",
      "\tspeed: 0.0174s/iter; left time: 323.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0556200 Vali Loss: 0.0549069 Test Loss: 0.0572072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0574168\n",
      "\tspeed: 0.0400s/iter; left time: 740.2444s\n",
      "\titers: 200, epoch: 18 | loss: 0.0581237\n",
      "\tspeed: 0.0177s/iter; left time: 326.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0554449 Vali Loss: 0.0550244 Test Loss: 0.0573702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542099\n",
      "\tspeed: 0.0398s/iter; left time: 726.2855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559456\n",
      "\tspeed: 0.0176s/iter; left time: 319.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0553786 Vali Loss: 0.0548329 Test Loss: 0.0571894\n",
      "Validation loss decreased (0.054884 --> 0.054833).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572355\n",
      "\tspeed: 0.0380s/iter; left time: 686.2173s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561926\n",
      "\tspeed: 0.0173s/iter; left time: 310.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0551821 Vali Loss: 0.0546544 Test Loss: 0.0570234\n",
      "Validation loss decreased (0.054833 --> 0.054654).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563121\n",
      "\tspeed: 0.0377s/iter; left time: 671.9930s\n",
      "\titers: 200, epoch: 21 | loss: 0.0511623\n",
      "\tspeed: 0.0173s/iter; left time: 307.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0551742 Vali Loss: 0.0547604 Test Loss: 0.0571249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0555600\n",
      "\tspeed: 0.0370s/iter; left time: 651.3281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0522842\n",
      "\tspeed: 0.0177s/iter; left time: 309.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0550073 Vali Loss: 0.0546179 Test Loss: 0.0571097\n",
      "Validation loss decreased (0.054654 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0549146\n",
      "\tspeed: 0.0380s/iter; left time: 660.0129s\n",
      "\titers: 200, epoch: 23 | loss: 0.0585962\n",
      "\tspeed: 0.0176s/iter; left time: 303.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0548645 Vali Loss: 0.0546012 Test Loss: 0.0568507\n",
      "Validation loss decreased (0.054618 --> 0.054601).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522619\n",
      "\tspeed: 0.0411s/iter; left time: 705.5859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523071\n",
      "\tspeed: 0.0209s/iter; left time: 356.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0547287 Vali Loss: 0.0545045 Test Loss: 0.0567771\n",
      "Validation loss decreased (0.054601 --> 0.054504).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524549\n",
      "\tspeed: 0.0374s/iter; left time: 632.9479s\n",
      "\titers: 200, epoch: 25 | loss: 0.0523958\n",
      "\tspeed: 0.0175s/iter; left time: 294.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0546907 Vali Loss: 0.0543925 Test Loss: 0.0568053\n",
      "Validation loss decreased (0.054504 --> 0.054393).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0491656\n",
      "\tspeed: 0.0375s/iter; left time: 627.0800s\n",
      "\titers: 200, epoch: 26 | loss: 0.0519010\n",
      "\tspeed: 0.0187s/iter; left time: 309.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0546669 Vali Loss: 0.0544461 Test Loss: 0.0568800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0501324\n",
      "\tspeed: 0.0378s/iter; left time: 622.8373s\n",
      "\titers: 200, epoch: 27 | loss: 0.0555143\n",
      "\tspeed: 0.0176s/iter; left time: 287.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0545846 Vali Loss: 0.0543533 Test Loss: 0.0567463\n",
      "Validation loss decreased (0.054393 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0519045\n",
      "\tspeed: 0.0415s/iter; left time: 674.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0593164\n",
      "\tspeed: 0.0198s/iter; left time: 319.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0545893 Vali Loss: 0.0543581 Test Loss: 0.0567341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0529863\n",
      "\tspeed: 0.0364s/iter; left time: 583.2380s\n",
      "\titers: 200, epoch: 29 | loss: 0.0542369\n",
      "\tspeed: 0.0178s/iter; left time: 282.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0544853 Vali Loss: 0.0542986 Test Loss: 0.0568295\n",
      "Validation loss decreased (0.054353 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555674\n",
      "\tspeed: 0.0386s/iter; left time: 609.8705s\n",
      "\titers: 200, epoch: 30 | loss: 0.0536577\n",
      "\tspeed: 0.0180s/iter; left time: 283.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0544743 Vali Loss: 0.0543639 Test Loss: 0.0568086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0559736\n",
      "\tspeed: 0.0426s/iter; left time: 664.2999s\n",
      "\titers: 200, epoch: 31 | loss: 0.0530356\n",
      "\tspeed: 0.0198s/iter; left time: 307.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0543727 Vali Loss: 0.0542804 Test Loss: 0.0567701\n",
      "Validation loss decreased (0.054299 --> 0.054280).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506607\n",
      "\tspeed: 0.0423s/iter; left time: 648.9617s\n",
      "\titers: 200, epoch: 32 | loss: 0.0552089\n",
      "\tspeed: 0.0197s/iter; left time: 301.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543940 Vali Loss: 0.0542822 Test Loss: 0.0566895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0566098\n",
      "\tspeed: 0.0416s/iter; left time: 628.8243s\n",
      "\titers: 200, epoch: 33 | loss: 0.0505462\n",
      "\tspeed: 0.0176s/iter; left time: 264.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0543382 Vali Loss: 0.0542966 Test Loss: 0.0567221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0536274\n",
      "\tspeed: 0.0372s/iter; left time: 554.7289s\n",
      "\titers: 200, epoch: 34 | loss: 0.0556459\n",
      "\tspeed: 0.0177s/iter; left time: 262.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0542882 Vali Loss: 0.0541794 Test Loss: 0.0567122\n",
      "Validation loss decreased (0.054280 --> 0.054179).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517977\n",
      "\tspeed: 0.0418s/iter; left time: 614.2475s\n",
      "\titers: 200, epoch: 35 | loss: 0.0515377\n",
      "\tspeed: 0.0187s/iter; left time: 272.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0542845 Vali Loss: 0.0542402 Test Loss: 0.0566953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0548994\n",
      "\tspeed: 0.0390s/iter; left time: 564.5106s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516339\n",
      "\tspeed: 0.0174s/iter; left time: 249.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0543297 Vali Loss: 0.0541653 Test Loss: 0.0567088\n",
      "Validation loss decreased (0.054179 --> 0.054165).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532896\n",
      "\tspeed: 0.0374s/iter; left time: 532.2474s\n",
      "\titers: 200, epoch: 37 | loss: 0.0552534\n",
      "\tspeed: 0.0173s/iter; left time: 245.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0542318 Vali Loss: 0.0542396 Test Loss: 0.0566283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0579502\n",
      "\tspeed: 0.0363s/iter; left time: 509.2660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564580\n",
      "\tspeed: 0.0174s/iter; left time: 241.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0541829 Vali Loss: 0.0542048 Test Loss: 0.0566276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0524793\n",
      "\tspeed: 0.0436s/iter; left time: 601.4429s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540179\n",
      "\tspeed: 0.0233s/iter; left time: 319.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0542241 Vali Loss: 0.0542069 Test Loss: 0.0566297\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0576975\n",
      "\tspeed: 0.0376s/iter; left time: 509.5911s\n",
      "\titers: 200, epoch: 40 | loss: 0.0566987\n",
      "\tspeed: 0.0200s/iter; left time: 269.4703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0542656 Vali Loss: 0.0541664 Test Loss: 0.0566543\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545915\n",
      "\tspeed: 0.0367s/iter; left time: 489.2609s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532811\n",
      "\tspeed: 0.0210s/iter; left time: 277.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0542114 Vali Loss: 0.0541793 Test Loss: 0.0566813\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551827\n",
      "\tspeed: 0.0411s/iter; left time: 539.2438s\n",
      "\titers: 200, epoch: 42 | loss: 0.0532943\n",
      "\tspeed: 0.0185s/iter; left time: 241.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0541279 Vali Loss: 0.0542011 Test Loss: 0.0566544\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552357\n",
      "\tspeed: 0.0401s/iter; left time: 517.6390s\n",
      "\titers: 200, epoch: 43 | loss: 0.0531659\n",
      "\tspeed: 0.0226s/iter; left time: 288.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541679 Vali Loss: 0.0542149 Test Loss: 0.0566875\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508406\n",
      "\tspeed: 0.0397s/iter; left time: 502.6425s\n",
      "\titers: 200, epoch: 44 | loss: 0.0489071\n",
      "\tspeed: 0.0176s/iter; left time: 220.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0541656 Vali Loss: 0.0542703 Test Loss: 0.0566778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571226\n",
      "\tspeed: 0.0372s/iter; left time: 463.0165s\n",
      "\titers: 200, epoch: 45 | loss: 0.0516223\n",
      "\tspeed: 0.0175s/iter; left time: 216.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0541900 Test Loss: 0.0566624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0533346\n",
      "\tspeed: 0.0367s/iter; left time: 448.1339s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554680\n",
      "\tspeed: 0.0176s/iter; left time: 213.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0541046 Vali Loss: 0.0542059 Test Loss: 0.0566667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010069291107356548, rmse:0.10034585744142532, mae:0.05670879781246185, rse:0.37915757298469543\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:52.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1438253\n",
      "\tspeed: 0.0460s/iter; left time: 1024.9099s\n",
      "\titers: 200, epoch: 1 | loss: 0.1208758\n",
      "\tspeed: 0.0179s/iter; left time: 397.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1473302 Vali Loss: 0.1059266 Test Loss: 0.1091740\n",
      "Validation loss decreased (inf --> 0.105927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936386\n",
      "\tspeed: 0.0392s/iter; left time: 865.1550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860985\n",
      "\tspeed: 0.0179s/iter; left time: 392.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0960414 Vali Loss: 0.0816183 Test Loss: 0.0868534\n",
      "Validation loss decreased (0.105927 --> 0.081618).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0869685\n",
      "\tspeed: 0.0384s/iter; left time: 839.2529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824700\n",
      "\tspeed: 0.0177s/iter; left time: 384.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0850344 Vali Loss: 0.0794767 Test Loss: 0.0840807\n",
      "Validation loss decreased (0.081618 --> 0.079477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0811073\n",
      "\tspeed: 0.0395s/iter; left time: 854.8521s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803189\n",
      "\tspeed: 0.0192s/iter; left time: 413.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823571 Vali Loss: 0.0782248 Test Loss: 0.0828857\n",
      "Validation loss decreased (0.079477 --> 0.078225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829862\n",
      "\tspeed: 0.0391s/iter; left time: 837.2694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771629\n",
      "\tspeed: 0.0180s/iter; left time: 383.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0807140 Vali Loss: 0.0776065 Test Loss: 0.0829133\n",
      "Validation loss decreased (0.078225 --> 0.077606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808049\n",
      "\tspeed: 0.0381s/iter; left time: 806.9387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791209\n",
      "\tspeed: 0.0175s/iter; left time: 369.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0796624 Vali Loss: 0.0771222 Test Loss: 0.0819657\n",
      "Validation loss decreased (0.077606 --> 0.077122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0809408\n",
      "\tspeed: 0.0381s/iter; left time: 797.8413s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773605\n",
      "\tspeed: 0.0179s/iter; left time: 373.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0788298 Vali Loss: 0.0770251 Test Loss: 0.0816225\n",
      "Validation loss decreased (0.077122 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780101\n",
      "\tspeed: 0.0386s/iter; left time: 800.1361s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734982\n",
      "\tspeed: 0.0178s/iter; left time: 366.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0781991 Vali Loss: 0.0765766 Test Loss: 0.0813183\n",
      "Validation loss decreased (0.077025 --> 0.076577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775502\n",
      "\tspeed: 0.0390s/iter; left time: 800.2133s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727340\n",
      "\tspeed: 0.0179s/iter; left time: 365.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0776098 Vali Loss: 0.0765785 Test Loss: 0.0815433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0742046\n",
      "\tspeed: 0.0384s/iter; left time: 778.6754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804574\n",
      "\tspeed: 0.0179s/iter; left time: 361.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0770741 Vali Loss: 0.0760664 Test Loss: 0.0814565\n",
      "Validation loss decreased (0.076577 --> 0.076066).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781170\n",
      "\tspeed: 0.0385s/iter; left time: 771.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763606\n",
      "\tspeed: 0.0177s/iter; left time: 354.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0766591 Vali Loss: 0.0762633 Test Loss: 0.0814268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0788421\n",
      "\tspeed: 0.0386s/iter; left time: 765.1212s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785553\n",
      "\tspeed: 0.0186s/iter; left time: 367.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0762871 Vali Loss: 0.0763303 Test Loss: 0.0807374\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767044\n",
      "\tspeed: 0.0405s/iter; left time: 794.2752s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790308\n",
      "\tspeed: 0.0190s/iter; left time: 370.3604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0760010 Vali Loss: 0.0760269 Test Loss: 0.0811383\n",
      "Validation loss decreased (0.076066 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738585\n",
      "\tspeed: 0.0382s/iter; left time: 740.1297s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735675\n",
      "\tspeed: 0.0175s/iter; left time: 337.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0756241 Vali Loss: 0.0759628 Test Loss: 0.0812599\n",
      "Validation loss decreased (0.076027 --> 0.075963).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746233\n",
      "\tspeed: 0.0403s/iter; left time: 773.2452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766651\n",
      "\tspeed: 0.0178s/iter; left time: 340.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0754588 Vali Loss: 0.0756437 Test Loss: 0.0810107\n",
      "Validation loss decreased (0.075963 --> 0.075644).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0798216\n",
      "\tspeed: 0.0379s/iter; left time: 718.3975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763530\n",
      "\tspeed: 0.0177s/iter; left time: 333.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0750988 Vali Loss: 0.0756608 Test Loss: 0.0809585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749412\n",
      "\tspeed: 0.0400s/iter; left time: 748.7746s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748506\n",
      "\tspeed: 0.0177s/iter; left time: 329.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0748632 Vali Loss: 0.0757296 Test Loss: 0.0809511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732470\n",
      "\tspeed: 0.0383s/iter; left time: 708.6400s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771152\n",
      "\tspeed: 0.0177s/iter; left time: 325.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0746712 Vali Loss: 0.0759519 Test Loss: 0.0808242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716322\n",
      "\tspeed: 0.0374s/iter; left time: 682.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0734277\n",
      "\tspeed: 0.0175s/iter; left time: 318.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0744779 Vali Loss: 0.0757884 Test Loss: 0.0807449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720630\n",
      "\tspeed: 0.0396s/iter; left time: 714.6965s\n",
      "\titers: 200, epoch: 20 | loss: 0.0764352\n",
      "\tspeed: 0.0176s/iter; left time: 315.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0742645 Vali Loss: 0.0756426 Test Loss: 0.0808228\n",
      "Validation loss decreased (0.075644 --> 0.075643).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752152\n",
      "\tspeed: 0.0425s/iter; left time: 757.8532s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683738\n",
      "\tspeed: 0.0190s/iter; left time: 336.3019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0741271 Vali Loss: 0.0756992 Test Loss: 0.0806643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747552\n",
      "\tspeed: 0.0387s/iter; left time: 680.3511s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740042\n",
      "\tspeed: 0.0178s/iter; left time: 311.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0740510 Vali Loss: 0.0756657 Test Loss: 0.0808825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729785\n",
      "\tspeed: 0.0379s/iter; left time: 658.7155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724722\n",
      "\tspeed: 0.0175s/iter; left time: 302.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0738833 Vali Loss: 0.0756935 Test Loss: 0.0808874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741584\n",
      "\tspeed: 0.0379s/iter; left time: 650.3920s\n",
      "\titers: 200, epoch: 24 | loss: 0.0702976\n",
      "\tspeed: 0.0176s/iter; left time: 299.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0737572 Vali Loss: 0.0755926 Test Loss: 0.0806114\n",
      "Validation loss decreased (0.075643 --> 0.075593).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0726041\n",
      "\tspeed: 0.0387s/iter; left time: 654.9765s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721414\n",
      "\tspeed: 0.0177s/iter; left time: 297.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0735935 Vali Loss: 0.0755621 Test Loss: 0.0806927\n",
      "Validation loss decreased (0.075593 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0734444\n",
      "\tspeed: 0.0385s/iter; left time: 643.0189s\n",
      "\titers: 200, epoch: 26 | loss: 0.0754302\n",
      "\tspeed: 0.0175s/iter; left time: 291.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0735225 Vali Loss: 0.0756676 Test Loss: 0.0805907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747007\n",
      "\tspeed: 0.0378s/iter; left time: 623.2643s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694138\n",
      "\tspeed: 0.0177s/iter; left time: 290.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0734549 Vali Loss: 0.0755092 Test Loss: 0.0805312\n",
      "Validation loss decreased (0.075562 --> 0.075509).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0760770\n",
      "\tspeed: 0.0391s/iter; left time: 635.0650s\n",
      "\titers: 200, epoch: 28 | loss: 0.0724863\n",
      "\tspeed: 0.0178s/iter; left time: 287.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0733856 Vali Loss: 0.0755548 Test Loss: 0.0805923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0735273\n",
      "\tspeed: 0.0381s/iter; left time: 610.0264s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731055\n",
      "\tspeed: 0.0177s/iter; left time: 281.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0733169 Vali Loss: 0.0754803 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.075509 --> 0.075480).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0725225\n",
      "\tspeed: 0.0388s/iter; left time: 613.0244s\n",
      "\titers: 200, epoch: 30 | loss: 0.0722679\n",
      "\tspeed: 0.0177s/iter; left time: 278.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0732621 Vali Loss: 0.0754730 Test Loss: 0.0806382\n",
      "Validation loss decreased (0.075480 --> 0.075473).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0735552\n",
      "\tspeed: 0.0406s/iter; left time: 632.5392s\n",
      "\titers: 200, epoch: 31 | loss: 0.0696184\n",
      "\tspeed: 0.0177s/iter; left time: 273.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0732522 Vali Loss: 0.0753299 Test Loss: 0.0805189\n",
      "Validation loss decreased (0.075473 --> 0.075330).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0748394\n",
      "\tspeed: 0.0394s/iter; left time: 605.2338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749177\n",
      "\tspeed: 0.0178s/iter; left time: 271.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0731558 Vali Loss: 0.0754113 Test Loss: 0.0805488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731158\n",
      "\tspeed: 0.0415s/iter; left time: 628.1651s\n",
      "\titers: 200, epoch: 33 | loss: 0.0764134\n",
      "\tspeed: 0.0190s/iter; left time: 285.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0731354 Vali Loss: 0.0754464 Test Loss: 0.0805663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720409\n",
      "\tspeed: 0.0380s/iter; left time: 566.4270s\n",
      "\titers: 200, epoch: 34 | loss: 0.0738428\n",
      "\tspeed: 0.0178s/iter; left time: 262.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0730683 Vali Loss: 0.0754058 Test Loss: 0.0804376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0698061\n",
      "\tspeed: 0.0400s/iter; left time: 587.5626s\n",
      "\titers: 200, epoch: 35 | loss: 0.0759599\n",
      "\tspeed: 0.0194s/iter; left time: 283.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0730275 Vali Loss: 0.0754564 Test Loss: 0.0805740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716557\n",
      "\tspeed: 0.0385s/iter; left time: 557.2221s\n",
      "\titers: 200, epoch: 36 | loss: 0.0711207\n",
      "\tspeed: 0.0175s/iter; left time: 251.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0730016 Vali Loss: 0.0754517 Test Loss: 0.0805066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755870\n",
      "\tspeed: 0.0383s/iter; left time: 545.3388s\n",
      "\titers: 200, epoch: 37 | loss: 0.0734674\n",
      "\tspeed: 0.0181s/iter; left time: 255.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0729387 Vali Loss: 0.0754124 Test Loss: 0.0805279\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0684947\n",
      "\tspeed: 0.0376s/iter; left time: 526.9358s\n",
      "\titers: 200, epoch: 38 | loss: 0.0758405\n",
      "\tspeed: 0.0177s/iter; left time: 245.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0729181 Vali Loss: 0.0754555 Test Loss: 0.0805209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0743821\n",
      "\tspeed: 0.0375s/iter; left time: 517.0128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711856\n",
      "\tspeed: 0.0175s/iter; left time: 239.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0728928 Vali Loss: 0.0753763 Test Loss: 0.0805926\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0773584\n",
      "\tspeed: 0.0425s/iter; left time: 576.3701s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719035\n",
      "\tspeed: 0.0231s/iter; left time: 311.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0729117 Vali Loss: 0.0754172 Test Loss: 0.0805385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0723396\n",
      "\tspeed: 0.0413s/iter; left time: 551.6058s\n",
      "\titers: 200, epoch: 41 | loss: 0.0712304\n",
      "\tspeed: 0.0176s/iter; left time: 232.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0729427 Vali Loss: 0.0753424 Test Loss: 0.0805553\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678918480873108, rmse:0.13667084276676178, mae:0.08051890879869461, rse:0.5167672038078308\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446110\n",
      "\tspeed: 0.0221s/iter; left time: 493.8308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1253999\n",
      "\tspeed: 0.0199s/iter; left time: 441.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1496909 Vali Loss: 0.1045320 Test Loss: 0.1075368\n",
      "Validation loss decreased (inf --> 0.104532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924727\n",
      "\tspeed: 0.0412s/iter; left time: 910.6740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894741\n",
      "\tspeed: 0.0178s/iter; left time: 390.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0954484 Vali Loss: 0.0817993 Test Loss: 0.0867445\n",
      "Validation loss decreased (0.104532 --> 0.081799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0847295\n",
      "\tspeed: 0.0402s/iter; left time: 878.0263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0820517\n",
      "\tspeed: 0.0180s/iter; left time: 391.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0846861 Vali Loss: 0.0795831 Test Loss: 0.0841799\n",
      "Validation loss decreased (0.081799 --> 0.079583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826818\n",
      "\tspeed: 0.0404s/iter; left time: 873.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826001\n",
      "\tspeed: 0.0179s/iter; left time: 386.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823463 Vali Loss: 0.0784222 Test Loss: 0.0830313\n",
      "Validation loss decreased (0.079583 --> 0.078422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0834706\n",
      "\tspeed: 0.0389s/iter; left time: 833.0787s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793772\n",
      "\tspeed: 0.0177s/iter; left time: 376.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0808059 Vali Loss: 0.0778977 Test Loss: 0.0820265\n",
      "Validation loss decreased (0.078422 --> 0.077898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793130\n",
      "\tspeed: 0.0408s/iter; left time: 863.3459s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798471\n",
      "\tspeed: 0.0182s/iter; left time: 382.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0797353 Vali Loss: 0.0771687 Test Loss: 0.0820218\n",
      "Validation loss decreased (0.077898 --> 0.077169).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792806\n",
      "\tspeed: 0.0394s/iter; left time: 825.4901s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804888\n",
      "\tspeed: 0.0179s/iter; left time: 373.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0788949 Vali Loss: 0.0769688 Test Loss: 0.0814737\n",
      "Validation loss decreased (0.077169 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805822\n",
      "\tspeed: 0.0417s/iter; left time: 865.1671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799717\n",
      "\tspeed: 0.0187s/iter; left time: 385.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0782915 Vali Loss: 0.0768342 Test Loss: 0.0813357\n",
      "Validation loss decreased (0.076969 --> 0.076834).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787869\n",
      "\tspeed: 0.0384s/iter; left time: 787.5092s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796126\n",
      "\tspeed: 0.0176s/iter; left time: 358.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777337 Vali Loss: 0.0765885 Test Loss: 0.0811092\n",
      "Validation loss decreased (0.076834 --> 0.076589).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0715174\n",
      "\tspeed: 0.0388s/iter; left time: 786.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0793800\n",
      "\tspeed: 0.0177s/iter; left time: 358.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0773026 Vali Loss: 0.0766290 Test Loss: 0.0812185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754477\n",
      "\tspeed: 0.0381s/iter; left time: 764.6416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789837\n",
      "\tspeed: 0.0178s/iter; left time: 354.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0767757 Vali Loss: 0.0764785 Test Loss: 0.0808268\n",
      "Validation loss decreased (0.076589 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715470\n",
      "\tspeed: 0.0443s/iter; left time: 879.6698s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762711\n",
      "\tspeed: 0.0199s/iter; left time: 392.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0764457 Vali Loss: 0.0764530 Test Loss: 0.0807678\n",
      "Validation loss decreased (0.076479 --> 0.076453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757492\n",
      "\tspeed: 0.0450s/iter; left time: 883.5416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821893\n",
      "\tspeed: 0.0204s/iter; left time: 397.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0761522 Vali Loss: 0.0763963 Test Loss: 0.0806580\n",
      "Validation loss decreased (0.076453 --> 0.076396).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764003\n",
      "\tspeed: 0.0461s/iter; left time: 894.1181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738080\n",
      "\tspeed: 0.0196s/iter; left time: 378.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0758944 Vali Loss: 0.0761132 Test Loss: 0.0809184\n",
      "Validation loss decreased (0.076396 --> 0.076113).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746748\n",
      "\tspeed: 0.0406s/iter; left time: 778.9004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0724435\n",
      "\tspeed: 0.0194s/iter; left time: 370.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0755759 Vali Loss: 0.0764618 Test Loss: 0.0805427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719663\n",
      "\tspeed: 0.0390s/iter; left time: 737.9347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0697170\n",
      "\tspeed: 0.0178s/iter; left time: 335.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0753819 Vali Loss: 0.0761848 Test Loss: 0.0806028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727296\n",
      "\tspeed: 0.0406s/iter; left time: 760.1802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727161\n",
      "\tspeed: 0.0177s/iter; left time: 330.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0750679 Vali Loss: 0.0762574 Test Loss: 0.0805783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725658\n",
      "\tspeed: 0.0381s/iter; left time: 703.8773s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764599\n",
      "\tspeed: 0.0178s/iter; left time: 327.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0748732 Vali Loss: 0.0761443 Test Loss: 0.0805745\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0747242\n",
      "\tspeed: 0.0466s/iter; left time: 851.3817s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744604\n",
      "\tspeed: 0.0214s/iter; left time: 388.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0746945 Vali Loss: 0.0761027 Test Loss: 0.0805595\n",
      "Validation loss decreased (0.076113 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739140\n",
      "\tspeed: 0.0443s/iter; left time: 798.5066s\n",
      "\titers: 200, epoch: 20 | loss: 0.0799948\n",
      "\tspeed: 0.0225s/iter; left time: 403.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0745287 Vali Loss: 0.0761509 Test Loss: 0.0804114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0718822\n",
      "\tspeed: 0.0403s/iter; left time: 719.0455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0686560\n",
      "\tspeed: 0.0197s/iter; left time: 348.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0743691 Vali Loss: 0.0761282 Test Loss: 0.0804886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756082\n",
      "\tspeed: 0.0382s/iter; left time: 671.8549s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743395\n",
      "\tspeed: 0.0176s/iter; left time: 307.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0742769 Vali Loss: 0.0762186 Test Loss: 0.0808756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802817\n",
      "\tspeed: 0.0395s/iter; left time: 686.2851s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747382\n",
      "\tspeed: 0.0194s/iter; left time: 334.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0740906 Vali Loss: 0.0761006 Test Loss: 0.0809374\n",
      "Validation loss decreased (0.076103 --> 0.076101).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0721726\n",
      "\tspeed: 0.0388s/iter; left time: 665.4127s\n",
      "\titers: 200, epoch: 24 | loss: 0.0764399\n",
      "\tspeed: 0.0179s/iter; left time: 305.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0739739 Vali Loss: 0.0763183 Test Loss: 0.0805535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0713016\n",
      "\tspeed: 0.0377s/iter; left time: 638.2618s\n",
      "\titers: 200, epoch: 25 | loss: 0.0763350\n",
      "\tspeed: 0.0177s/iter; left time: 297.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0739049 Vali Loss: 0.0761669 Test Loss: 0.0804498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704296\n",
      "\tspeed: 0.0396s/iter; left time: 661.2235s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738422\n",
      "\tspeed: 0.0211s/iter; left time: 350.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0737833 Vali Loss: 0.0761739 Test Loss: 0.0806323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736066\n",
      "\tspeed: 0.0397s/iter; left time: 654.4782s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724954\n",
      "\tspeed: 0.0181s/iter; left time: 295.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0737053 Vali Loss: 0.0761146 Test Loss: 0.0805858\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708030\n",
      "\tspeed: 0.0417s/iter; left time: 678.2211s\n",
      "\titers: 200, epoch: 28 | loss: 0.0726346\n",
      "\tspeed: 0.0224s/iter; left time: 361.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0736342 Vali Loss: 0.0761730 Test Loss: 0.0805067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0736985\n",
      "\tspeed: 0.0394s/iter; left time: 631.5932s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757324\n",
      "\tspeed: 0.0175s/iter; left time: 279.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0736515 Vali Loss: 0.0762277 Test Loss: 0.0805709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0738680\n",
      "\tspeed: 0.0382s/iter; left time: 604.3951s\n",
      "\titers: 200, epoch: 30 | loss: 0.0754899\n",
      "\tspeed: 0.0175s/iter; left time: 275.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0735729 Vali Loss: 0.0761100 Test Loss: 0.0804291\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0771352\n",
      "\tspeed: 0.0394s/iter; left time: 614.2084s\n",
      "\titers: 200, epoch: 31 | loss: 0.0740414\n",
      "\tspeed: 0.0175s/iter; left time: 271.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0734717 Vali Loss: 0.0763483 Test Loss: 0.0805765\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0702331\n",
      "\tspeed: 0.0375s/iter; left time: 576.6210s\n",
      "\titers: 200, epoch: 32 | loss: 0.0758914\n",
      "\tspeed: 0.0181s/iter; left time: 276.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0734446 Vali Loss: 0.0761305 Test Loss: 0.0804661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723481\n",
      "\tspeed: 0.0372s/iter; left time: 563.5045s\n",
      "\titers: 200, epoch: 33 | loss: 0.0725820\n",
      "\tspeed: 0.0176s/iter; left time: 264.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0733762 Vali Loss: 0.0761667 Test Loss: 0.0805655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018912920728325844, rmse:0.13752426207065582, mae:0.08093737810850143, rse:0.5199940204620361\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:21.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423216\n",
      "\tspeed: 0.0461s/iter; left time: 1023.0411s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238418\n",
      "\tspeed: 0.0180s/iter; left time: 397.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1487374 Vali Loss: 0.1077961 Test Loss: 0.1103803\n",
      "Validation loss decreased (inf --> 0.107796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939423\n",
      "\tspeed: 0.0391s/iter; left time: 860.2094s\n",
      "\titers: 200, epoch: 2 | loss: 0.0893055\n",
      "\tspeed: 0.0179s/iter; left time: 392.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0994013 Vali Loss: 0.0860546 Test Loss: 0.0906314\n",
      "Validation loss decreased (0.107796 --> 0.086055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925718\n",
      "\tspeed: 0.0395s/iter; left time: 859.8668s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874189\n",
      "\tspeed: 0.0179s/iter; left time: 387.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0890840 Vali Loss: 0.0842465 Test Loss: 0.0879599\n",
      "Validation loss decreased (0.086055 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881069\n",
      "\tspeed: 0.0411s/iter; left time: 885.5673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0894828\n",
      "\tspeed: 0.0193s/iter; left time: 413.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0864151 Vali Loss: 0.0837157 Test Loss: 0.0879383\n",
      "Validation loss decreased (0.084247 --> 0.083716).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829716\n",
      "\tspeed: 0.0404s/iter; left time: 860.1269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826994\n",
      "\tspeed: 0.0179s/iter; left time: 379.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0848429 Vali Loss: 0.0827259 Test Loss: 0.0875212\n",
      "Validation loss decreased (0.083716 --> 0.082726).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817767\n",
      "\tspeed: 0.0409s/iter; left time: 861.8152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862948\n",
      "\tspeed: 0.0193s/iter; left time: 404.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0836924 Vali Loss: 0.0822996 Test Loss: 0.0872402\n",
      "Validation loss decreased (0.082726 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838116\n",
      "\tspeed: 0.0392s/iter; left time: 818.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848943\n",
      "\tspeed: 0.0179s/iter; left time: 370.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0827538 Vali Loss: 0.0820797 Test Loss: 0.0871094\n",
      "Validation loss decreased (0.082300 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825785\n",
      "\tspeed: 0.0387s/iter; left time: 799.7960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793753\n",
      "\tspeed: 0.0179s/iter; left time: 366.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0820263 Vali Loss: 0.0822556 Test Loss: 0.0876831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795462\n",
      "\tspeed: 0.0425s/iter; left time: 868.7222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789129\n",
      "\tspeed: 0.0228s/iter; left time: 464.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0815050 Vali Loss: 0.0815729 Test Loss: 0.0867696\n",
      "Validation loss decreased (0.082080 --> 0.081573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811481\n",
      "\tspeed: 0.0412s/iter; left time: 831.2948s\n",
      "\titers: 200, epoch: 10 | loss: 0.0825071\n",
      "\tspeed: 0.0183s/iter; left time: 368.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0810133 Vali Loss: 0.0817944 Test Loss: 0.0868367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0821963\n",
      "\tspeed: 0.0398s/iter; left time: 794.0686s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761625\n",
      "\tspeed: 0.0208s/iter; left time: 413.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0805028 Vali Loss: 0.0818734 Test Loss: 0.0874601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0790672\n",
      "\tspeed: 0.0383s/iter; left time: 756.6160s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799741\n",
      "\tspeed: 0.0178s/iter; left time: 350.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0801906 Vali Loss: 0.0817134 Test Loss: 0.0878104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782696\n",
      "\tspeed: 0.0420s/iter; left time: 820.3538s\n",
      "\titers: 200, epoch: 13 | loss: 0.0798471\n",
      "\tspeed: 0.0206s/iter; left time: 400.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0798508 Vali Loss: 0.0815302 Test Loss: 0.0871841\n",
      "Validation loss decreased (0.081573 --> 0.081530).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773299\n",
      "\tspeed: 0.0454s/iter; left time: 876.7918s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797019\n",
      "\tspeed: 0.0185s/iter; left time: 354.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0794928 Vali Loss: 0.0817144 Test Loss: 0.0871146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0791878\n",
      "\tspeed: 0.0386s/iter; left time: 736.6542s\n",
      "\titers: 200, epoch: 15 | loss: 0.0850011\n",
      "\tspeed: 0.0180s/iter; left time: 341.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0791677 Vali Loss: 0.0815923 Test Loss: 0.0870508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0806760\n",
      "\tspeed: 0.0414s/iter; left time: 779.9618s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801392\n",
      "\tspeed: 0.0179s/iter; left time: 336.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0789298 Vali Loss: 0.0816933 Test Loss: 0.0873272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782162\n",
      "\tspeed: 0.0394s/iter; left time: 734.2989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770024\n",
      "\tspeed: 0.0182s/iter; left time: 337.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0786994 Vali Loss: 0.0814644 Test Loss: 0.0871423\n",
      "Validation loss decreased (0.081530 --> 0.081464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750689\n",
      "\tspeed: 0.0393s/iter; left time: 723.2489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0791912\n",
      "\tspeed: 0.0179s/iter; left time: 326.9713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0784913 Vali Loss: 0.0817581 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772508\n",
      "\tspeed: 0.0385s/iter; left time: 700.3244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0785425\n",
      "\tspeed: 0.0179s/iter; left time: 323.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0782302 Vali Loss: 0.0813190 Test Loss: 0.0870724\n",
      "Validation loss decreased (0.081464 --> 0.081319).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0796085\n",
      "\tspeed: 0.0418s/iter; left time: 750.8243s\n",
      "\titers: 200, epoch: 20 | loss: 0.0747003\n",
      "\tspeed: 0.0179s/iter; left time: 319.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0780742 Vali Loss: 0.0815029 Test Loss: 0.0872391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0798976\n",
      "\tspeed: 0.0385s/iter; left time: 682.9507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783784\n",
      "\tspeed: 0.0205s/iter; left time: 360.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0778642 Vali Loss: 0.0814129 Test Loss: 0.0872288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798767\n",
      "\tspeed: 0.0401s/iter; left time: 701.9505s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798330\n",
      "\tspeed: 0.0185s/iter; left time: 323.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0777549 Vali Loss: 0.0814658 Test Loss: 0.0875085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0734261\n",
      "\tspeed: 0.0395s/iter; left time: 683.3050s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779886\n",
      "\tspeed: 0.0181s/iter; left time: 311.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0775775 Vali Loss: 0.0814620 Test Loss: 0.0873106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789265\n",
      "\tspeed: 0.0384s/iter; left time: 655.8847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768867\n",
      "\tspeed: 0.0181s/iter; left time: 306.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0774439 Vali Loss: 0.0814374 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0773396\n",
      "\tspeed: 0.0389s/iter; left time: 655.6546s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760351\n",
      "\tspeed: 0.0185s/iter; left time: 310.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0773691 Vali Loss: 0.0813845 Test Loss: 0.0871841\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796533\n",
      "\tspeed: 0.0399s/iter; left time: 662.7052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0774103\n",
      "\tspeed: 0.0180s/iter; left time: 297.4635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0771835 Vali Loss: 0.0814663 Test Loss: 0.0871791\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742327\n",
      "\tspeed: 0.0372s/iter; left time: 610.6163s\n",
      "\titers: 200, epoch: 27 | loss: 0.0805335\n",
      "\tspeed: 0.0178s/iter; left time: 289.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0771259 Vali Loss: 0.0814744 Test Loss: 0.0872126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0766790\n",
      "\tspeed: 0.0381s/iter; left time: 616.6928s\n",
      "\titers: 200, epoch: 28 | loss: 0.0775495\n",
      "\tspeed: 0.0179s/iter; left time: 288.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0770471 Vali Loss: 0.0813009 Test Loss: 0.0870816\n",
      "Validation loss decreased (0.081319 --> 0.081301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0757094\n",
      "\tspeed: 0.0408s/iter; left time: 650.4701s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760654\n",
      "\tspeed: 0.0180s/iter; left time: 285.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0769555 Vali Loss: 0.0812396 Test Loss: 0.0871117\n",
      "Validation loss decreased (0.081301 --> 0.081240).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0767229\n",
      "\tspeed: 0.0404s/iter; left time: 635.6768s\n",
      "\titers: 200, epoch: 30 | loss: 0.0786787\n",
      "\tspeed: 0.0180s/iter; left time: 282.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0768584 Vali Loss: 0.0815030 Test Loss: 0.0869776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778194\n",
      "\tspeed: 0.0383s/iter; left time: 594.6005s\n",
      "\titers: 200, epoch: 31 | loss: 0.0778298\n",
      "\tspeed: 0.0178s/iter; left time: 274.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0767776 Vali Loss: 0.0813545 Test Loss: 0.0871082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0754501\n",
      "\tspeed: 0.0407s/iter; left time: 622.4346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764830\n",
      "\tspeed: 0.0179s/iter; left time: 272.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0767559 Vali Loss: 0.0812562 Test Loss: 0.0870397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0755639\n",
      "\tspeed: 0.0414s/iter; left time: 624.0858s\n",
      "\titers: 200, epoch: 33 | loss: 0.0777980\n",
      "\tspeed: 0.0204s/iter; left time: 305.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0767118 Vali Loss: 0.0814427 Test Loss: 0.0868835\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754135\n",
      "\tspeed: 0.0393s/iter; left time: 583.4103s\n",
      "\titers: 200, epoch: 34 | loss: 0.0785940\n",
      "\tspeed: 0.0180s/iter; left time: 264.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0766594 Vali Loss: 0.0814381 Test Loss: 0.0870054\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776752\n",
      "\tspeed: 0.0433s/iter; left time: 633.2336s\n",
      "\titers: 200, epoch: 35 | loss: 0.0752889\n",
      "\tspeed: 0.0219s/iter; left time: 318.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0766568 Vali Loss: 0.0813767 Test Loss: 0.0870404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0754985\n",
      "\tspeed: 0.0434s/iter; left time: 624.6602s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774933\n",
      "\tspeed: 0.0183s/iter; left time: 261.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0765844 Vali Loss: 0.0814429 Test Loss: 0.0870331\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0767131\n",
      "\tspeed: 0.0404s/iter; left time: 572.0861s\n",
      "\titers: 200, epoch: 37 | loss: 0.0771547\n",
      "\tspeed: 0.0180s/iter; left time: 253.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0765541 Vali Loss: 0.0814060 Test Loss: 0.0868510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0774624\n",
      "\tspeed: 0.0379s/iter; left time: 528.8624s\n",
      "\titers: 200, epoch: 38 | loss: 0.0765092\n",
      "\tspeed: 0.0180s/iter; left time: 249.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0765164 Vali Loss: 0.0814066 Test Loss: 0.0870728\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0766422\n",
      "\tspeed: 0.0387s/iter; left time: 531.8544s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785535\n",
      "\tspeed: 0.0204s/iter; left time: 278.2109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0765010 Vali Loss: 0.0812689 Test Loss: 0.0869280\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02109212428331375, rmse:0.14523127675056458, mae:0.08711174875497818, rse:0.5496454238891602\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1449288\n",
      "\tspeed: 0.0237s/iter; left time: 527.1092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275386\n",
      "\tspeed: 0.0189s/iter; left time: 416.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1514120 Vali Loss: 0.1083481 Test Loss: 0.1111070\n",
      "Validation loss decreased (inf --> 0.108348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964038\n",
      "\tspeed: 0.0406s/iter; left time: 891.5062s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950081\n",
      "\tspeed: 0.0182s/iter; left time: 397.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0995364 Vali Loss: 0.0861125 Test Loss: 0.0903715\n",
      "Validation loss decreased (0.108348 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903619\n",
      "\tspeed: 0.0439s/iter; left time: 955.2516s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892618\n",
      "\tspeed: 0.0180s/iter; left time: 388.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0891035 Vali Loss: 0.0844135 Test Loss: 0.0887872\n",
      "Validation loss decreased (0.086113 --> 0.084413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915347\n",
      "\tspeed: 0.0401s/iter; left time: 863.5181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848709\n",
      "\tspeed: 0.0179s/iter; left time: 384.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0866611 Vali Loss: 0.0836004 Test Loss: 0.0878691\n",
      "Validation loss decreased (0.084413 --> 0.083600).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874841\n",
      "\tspeed: 0.0425s/iter; left time: 906.4325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0879956\n",
      "\tspeed: 0.0203s/iter; left time: 430.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0851195 Vali Loss: 0.0828480 Test Loss: 0.0873044\n",
      "Validation loss decreased (0.083600 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839838\n",
      "\tspeed: 0.0420s/iter; left time: 885.0919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821068\n",
      "\tspeed: 0.0179s/iter; left time: 375.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0839008 Vali Loss: 0.0822585 Test Loss: 0.0870409\n",
      "Validation loss decreased (0.082848 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821517\n",
      "\tspeed: 0.0422s/iter; left time: 879.5556s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844231\n",
      "\tspeed: 0.0184s/iter; left time: 381.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0830070 Vali Loss: 0.0822771 Test Loss: 0.0872937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803021\n",
      "\tspeed: 0.0392s/iter; left time: 809.3280s\n",
      "\titers: 200, epoch: 8 | loss: 0.0812417\n",
      "\tspeed: 0.0180s/iter; left time: 368.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0822285 Vali Loss: 0.0821905 Test Loss: 0.0874587\n",
      "Validation loss decreased (0.082259 --> 0.082190).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808798\n",
      "\tspeed: 0.0417s/iter; left time: 851.4096s\n",
      "\titers: 200, epoch: 9 | loss: 0.0797862\n",
      "\tspeed: 0.0180s/iter; left time: 364.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0815818 Vali Loss: 0.0818749 Test Loss: 0.0877508\n",
      "Validation loss decreased (0.082190 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799902\n",
      "\tspeed: 0.0440s/iter; left time: 888.7792s\n",
      "\titers: 200, epoch: 10 | loss: 0.0788336\n",
      "\tspeed: 0.0186s/iter; left time: 372.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0810375 Vali Loss: 0.0815037 Test Loss: 0.0872590\n",
      "Validation loss decreased (0.081875 --> 0.081504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795319\n",
      "\tspeed: 0.0391s/iter; left time: 780.5435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794025\n",
      "\tspeed: 0.0180s/iter; left time: 357.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0806232 Vali Loss: 0.0819767 Test Loss: 0.0874538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821759\n",
      "\tspeed: 0.0420s/iter; left time: 829.3506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778371\n",
      "\tspeed: 0.0198s/iter; left time: 388.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0801564 Vali Loss: 0.0814462 Test Loss: 0.0873747\n",
      "Validation loss decreased (0.081504 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842263\n",
      "\tspeed: 0.0417s/iter; left time: 814.4622s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809889\n",
      "\tspeed: 0.0182s/iter; left time: 352.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0797804 Vali Loss: 0.0816962 Test Loss: 0.0877320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0751703\n",
      "\tspeed: 0.0421s/iter; left time: 811.9402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763598\n",
      "\tspeed: 0.0207s/iter; left time: 397.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0794535 Vali Loss: 0.0814359 Test Loss: 0.0876379\n",
      "Validation loss decreased (0.081446 --> 0.081436).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0789681\n",
      "\tspeed: 0.0400s/iter; left time: 763.7075s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766760\n",
      "\tspeed: 0.0180s/iter; left time: 342.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0791543 Vali Loss: 0.0809303 Test Loss: 0.0873543\n",
      "Validation loss decreased (0.081436 --> 0.080930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803362\n",
      "\tspeed: 0.0399s/iter; left time: 753.0844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774697\n",
      "\tspeed: 0.0182s/iter; left time: 341.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0788688 Vali Loss: 0.0816369 Test Loss: 0.0876021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0793249\n",
      "\tspeed: 0.0407s/iter; left time: 757.9852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790591\n",
      "\tspeed: 0.0200s/iter; left time: 370.2881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0786432 Vali Loss: 0.0810094 Test Loss: 0.0877025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760391\n",
      "\tspeed: 0.0409s/iter; left time: 753.7718s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795988\n",
      "\tspeed: 0.0204s/iter; left time: 374.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0784823 Vali Loss: 0.0814446 Test Loss: 0.0877750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0790216\n",
      "\tspeed: 0.0412s/iter; left time: 749.6815s\n",
      "\titers: 200, epoch: 19 | loss: 0.0839612\n",
      "\tspeed: 0.0182s/iter; left time: 328.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0782333 Vali Loss: 0.0810218 Test Loss: 0.0872108\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764522\n",
      "\tspeed: 0.0399s/iter; left time: 716.8600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756822\n",
      "\tspeed: 0.0180s/iter; left time: 321.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0780890 Vali Loss: 0.0807879 Test Loss: 0.0873520\n",
      "Validation loss decreased (0.080930 --> 0.080788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766985\n",
      "\tspeed: 0.0389s/iter; left time: 689.3043s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789640\n",
      "\tspeed: 0.0181s/iter; left time: 319.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0778664 Vali Loss: 0.0809161 Test Loss: 0.0873467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0807523\n",
      "\tspeed: 0.0377s/iter; left time: 660.2344s\n",
      "\titers: 200, epoch: 22 | loss: 0.0760726\n",
      "\tspeed: 0.0180s/iter; left time: 313.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0777179 Vali Loss: 0.0807275 Test Loss: 0.0872172\n",
      "Validation loss decreased (0.080788 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772732\n",
      "\tspeed: 0.0393s/iter; left time: 680.4143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791408\n",
      "\tspeed: 0.0183s/iter; left time: 314.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0775855 Vali Loss: 0.0809376 Test Loss: 0.0875355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0792675\n",
      "\tspeed: 0.0397s/iter; left time: 677.4338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0806082\n",
      "\tspeed: 0.0195s/iter; left time: 331.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0774288 Vali Loss: 0.0809761 Test Loss: 0.0873712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786049\n",
      "\tspeed: 0.0395s/iter; left time: 665.1974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782466\n",
      "\tspeed: 0.0180s/iter; left time: 301.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0773741 Vali Loss: 0.0809126 Test Loss: 0.0873566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797315\n",
      "\tspeed: 0.0417s/iter; left time: 694.0438s\n",
      "\titers: 200, epoch: 26 | loss: 0.0777119\n",
      "\tspeed: 0.0210s/iter; left time: 347.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0772352 Vali Loss: 0.0808808 Test Loss: 0.0872862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776568\n",
      "\tspeed: 0.0410s/iter; left time: 671.8824s\n",
      "\titers: 200, epoch: 27 | loss: 0.0756376\n",
      "\tspeed: 0.0179s/iter; left time: 291.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0771665 Vali Loss: 0.0809822 Test Loss: 0.0873216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762978\n",
      "\tspeed: 0.0376s/iter; left time: 608.6421s\n",
      "\titers: 200, epoch: 28 | loss: 0.0765274\n",
      "\tspeed: 0.0178s/iter; left time: 286.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0770732 Vali Loss: 0.0810418 Test Loss: 0.0872446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0719681\n",
      "\tspeed: 0.0379s/iter; left time: 605.4086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788069\n",
      "\tspeed: 0.0182s/iter; left time: 288.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0769719 Vali Loss: 0.0809646 Test Loss: 0.0873285\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789183\n",
      "\tspeed: 0.0404s/iter; left time: 635.3260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782066\n",
      "\tspeed: 0.0180s/iter; left time: 281.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0769468 Vali Loss: 0.0807314 Test Loss: 0.0870685\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808447\n",
      "\tspeed: 0.0380s/iter; left time: 589.4340s\n",
      "\titers: 200, epoch: 31 | loss: 0.0765283\n",
      "\tspeed: 0.0181s/iter; left time: 278.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0768495 Vali Loss: 0.0806943 Test Loss: 0.0872749\n",
      "Validation loss decreased (0.080727 --> 0.080694).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761573\n",
      "\tspeed: 0.0438s/iter; left time: 668.9799s\n",
      "\titers: 200, epoch: 32 | loss: 0.0757153\n",
      "\tspeed: 0.0182s/iter; left time: 276.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0768053 Vali Loss: 0.0808349 Test Loss: 0.0872295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775786\n",
      "\tspeed: 0.0419s/iter; left time: 631.6551s\n",
      "\titers: 200, epoch: 33 | loss: 0.0767409\n",
      "\tspeed: 0.0190s/iter; left time: 283.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0767355 Vali Loss: 0.0808667 Test Loss: 0.0871681\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757100\n",
      "\tspeed: 0.0388s/iter; left time: 576.0192s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774558\n",
      "\tspeed: 0.0180s/iter; left time: 265.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0767543 Vali Loss: 0.0808929 Test Loss: 0.0871076\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778735\n",
      "\tspeed: 0.0407s/iter; left time: 594.7343s\n",
      "\titers: 200, epoch: 35 | loss: 0.0775153\n",
      "\tspeed: 0.0189s/iter; left time: 274.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0766747 Vali Loss: 0.0807420 Test Loss: 0.0872145\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0747025\n",
      "\tspeed: 0.0386s/iter; left time: 555.6579s\n",
      "\titers: 200, epoch: 36 | loss: 0.0751638\n",
      "\tspeed: 0.0182s/iter; left time: 260.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766659 Vali Loss: 0.0808573 Test Loss: 0.0873167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0759581\n",
      "\tspeed: 0.0399s/iter; left time: 565.5094s\n",
      "\titers: 200, epoch: 37 | loss: 0.0804632\n",
      "\tspeed: 0.0189s/iter; left time: 265.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0766658 Vali Loss: 0.0808365 Test Loss: 0.0872206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0759550\n",
      "\tspeed: 0.0397s/iter; left time: 554.0831s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777812\n",
      "\tspeed: 0.0181s/iter; left time: 251.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766106 Vali Loss: 0.0808862 Test Loss: 0.0872444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806029\n",
      "\tspeed: 0.0399s/iter; left time: 548.0181s\n",
      "\titers: 200, epoch: 39 | loss: 0.0741781\n",
      "\tspeed: 0.0183s/iter; left time: 248.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0765723 Vali Loss: 0.0807692 Test Loss: 0.0871365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0759363\n",
      "\tspeed: 0.0406s/iter; left time: 548.8343s\n",
      "\titers: 200, epoch: 40 | loss: 0.0809224\n",
      "\tspeed: 0.0184s/iter; left time: 246.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0764995 Vali Loss: 0.0808269 Test Loss: 0.0872263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0751095\n",
      "\tspeed: 0.0400s/iter; left time: 531.8427s\n",
      "\titers: 200, epoch: 41 | loss: 0.0726962\n",
      "\tspeed: 0.0206s/iter; left time: 271.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0764408 Vali Loss: 0.0807421 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020868754014372826, rmse:0.14446021616458893, mae:0.08727487176656723, rse:0.5467272400856018\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:06.28s\n",
      "Intermediate time for IT: 00h:27m:20.07s\n",
      "Total time: 02h:04m:37.46s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1448  0.0877\n",
       "        96            0.0377  0.1941  0.1283\n",
       "        168           0.0393  0.1981  0.1339\n",
       "ES      24            0.0098  0.0988  0.0592\n",
       "        96            0.0185  0.1361  0.0861\n",
       "        168           0.0207  0.1439  0.0916\n",
       "FR      24            0.0100  0.1000  0.0548\n",
       "        96            0.0193  0.1390  0.0808\n",
       "        168           0.0213  0.1460  0.0868\n",
       "GB      24            0.0250  0.1582  0.0996\n",
       "        96            0.0418  0.2045  0.1395\n",
       "        168           0.0447  0.2115  0.1468\n",
       "IT      24            0.0101  0.1004  0.0567\n",
       "        96            0.0188  0.1371  0.0807\n",
       "        168           0.0210  0.1448  0.0872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_512.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1321916\n",
      "\tspeed: 0.0728s/iter; left time: 1615.8326s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232382\n",
      "\tspeed: 0.0406s/iter; left time: 897.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 223 | Train Loss: 0.1358311 Vali Loss: 0.1260650 Test Loss: 0.1311714\n",
      "Validation loss decreased (inf --> 0.126065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869880\n",
      "\tspeed: 0.0734s/iter; left time: 1612.4742s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813422\n",
      "\tspeed: 0.0409s/iter; left time: 895.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0881644 Vali Loss: 0.0929616 Test Loss: 0.0951003\n",
      "Validation loss decreased (0.126065 --> 0.092962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0751677\n",
      "\tspeed: 0.0736s/iter; left time: 1600.3763s\n",
      "\titers: 200, epoch: 3 | loss: 0.0759952\n",
      "\tspeed: 0.0407s/iter; left time: 881.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0788886 Vali Loss: 0.0895641 Test Loss: 0.0921896\n",
      "Validation loss decreased (0.092962 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0797120\n",
      "\tspeed: 0.0735s/iter; left time: 1581.5937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827803\n",
      "\tspeed: 0.0406s/iter; left time: 870.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0885940 Test Loss: 0.0909947\n",
      "Validation loss decreased (0.089564 --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754906\n",
      "\tspeed: 0.0734s/iter; left time: 1563.9432s\n",
      "\titers: 200, epoch: 5 | loss: 0.0719414\n",
      "\tspeed: 0.0407s/iter; left time: 862.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0754300 Vali Loss: 0.0888515 Test Loss: 0.0910340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0806468\n",
      "\tspeed: 0.0728s/iter; left time: 1534.8053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0765860\n",
      "\tspeed: 0.0419s/iter; left time: 879.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0744171 Vali Loss: 0.0882697 Test Loss: 0.0900209\n",
      "Validation loss decreased (0.088594 --> 0.088270).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731639\n",
      "\tspeed: 0.0734s/iter; left time: 1530.8374s\n",
      "\titers: 200, epoch: 7 | loss: 0.0712213\n",
      "\tspeed: 0.0409s/iter; left time: 848.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0736002 Vali Loss: 0.0882780 Test Loss: 0.0900862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0723158\n",
      "\tspeed: 0.0753s/iter; left time: 1553.8959s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739186\n",
      "\tspeed: 0.0408s/iter; left time: 838.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0730063 Vali Loss: 0.0872233 Test Loss: 0.0892780\n",
      "Validation loss decreased (0.088270 --> 0.087223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0720197\n",
      "\tspeed: 0.0736s/iter; left time: 1502.4429s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719693\n",
      "\tspeed: 0.0413s/iter; left time: 839.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0725142 Vali Loss: 0.0873214 Test Loss: 0.0893505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0731357\n",
      "\tspeed: 0.0740s/iter; left time: 1493.4336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688657\n",
      "\tspeed: 0.0408s/iter; left time: 819.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0721618 Vali Loss: 0.0870030 Test Loss: 0.0891919\n",
      "Validation loss decreased (0.087223 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0748033\n",
      "\tspeed: 0.0759s/iter; left time: 1515.2200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748860\n",
      "\tspeed: 0.0417s/iter; left time: 829.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0719345 Vali Loss: 0.0867141 Test Loss: 0.0886792\n",
      "Validation loss decreased (0.087003 --> 0.086714).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0690829\n",
      "\tspeed: 0.0745s/iter; left time: 1470.9406s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754002\n",
      "\tspeed: 0.0429s/iter; left time: 842.0450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0716603 Vali Loss: 0.0863255 Test Loss: 0.0886338\n",
      "Validation loss decreased (0.086714 --> 0.086325).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659539\n",
      "\tspeed: 0.0744s/iter; left time: 1452.1265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692490\n",
      "\tspeed: 0.0412s/iter; left time: 799.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713583 Vali Loss: 0.0861463 Test Loss: 0.0882640\n",
      "Validation loss decreased (0.086325 --> 0.086146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732110\n",
      "\tspeed: 0.0779s/iter; left time: 1503.5926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664269\n",
      "\tspeed: 0.0411s/iter; left time: 788.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0712298 Vali Loss: 0.0862440 Test Loss: 0.0883915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0712718\n",
      "\tspeed: 0.0763s/iter; left time: 1455.3356s\n",
      "\titers: 200, epoch: 15 | loss: 0.0668620\n",
      "\tspeed: 0.0410s/iter; left time: 777.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0710672 Vali Loss: 0.0864471 Test Loss: 0.0887082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0729668\n",
      "\tspeed: 0.0740s/iter; left time: 1395.5402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0765959\n",
      "\tspeed: 0.0422s/iter; left time: 792.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0708319 Vali Loss: 0.0861513 Test Loss: 0.0883979\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704609\n",
      "\tspeed: 0.0735s/iter; left time: 1369.5178s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766587\n",
      "\tspeed: 0.0433s/iter; left time: 802.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707372 Vali Loss: 0.0861647 Test Loss: 0.0883205\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0681143\n",
      "\tspeed: 0.0750s/iter; left time: 1381.5339s\n",
      "\titers: 200, epoch: 18 | loss: 0.0640077\n",
      "\tspeed: 0.0409s/iter; left time: 749.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0706291 Vali Loss: 0.0860309 Test Loss: 0.0882354\n",
      "Validation loss decreased (0.086146 --> 0.086031).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720396\n",
      "\tspeed: 0.0783s/iter; left time: 1423.7136s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769060\n",
      "\tspeed: 0.0409s/iter; left time: 740.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0705093 Vali Loss: 0.0859334 Test Loss: 0.0882176\n",
      "Validation loss decreased (0.086031 --> 0.085933).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0715498\n",
      "\tspeed: 0.0772s/iter; left time: 1386.4974s\n",
      "\titers: 200, epoch: 20 | loss: 0.0696223\n",
      "\tspeed: 0.0410s/iter; left time: 732.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0704253 Vali Loss: 0.0860697 Test Loss: 0.0881779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699663\n",
      "\tspeed: 0.0728s/iter; left time: 1291.4193s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732786\n",
      "\tspeed: 0.0431s/iter; left time: 759.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0703514 Vali Loss: 0.0858988 Test Loss: 0.0881333\n",
      "Validation loss decreased (0.085933 --> 0.085899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0708477\n",
      "\tspeed: 0.0742s/iter; left time: 1300.1863s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705403\n",
      "\tspeed: 0.0415s/iter; left time: 722.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0702229 Vali Loss: 0.0858154 Test Loss: 0.0882537\n",
      "Validation loss decreased (0.085899 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0727449\n",
      "\tspeed: 0.0758s/iter; left time: 1310.7424s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709735\n",
      "\tspeed: 0.0411s/iter; left time: 705.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0702576 Vali Loss: 0.0857304 Test Loss: 0.0880756\n",
      "Validation loss decreased (0.085815 --> 0.085730).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739099\n",
      "\tspeed: 0.0758s/iter; left time: 1294.2116s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680970\n",
      "\tspeed: 0.0412s/iter; left time: 699.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0701341 Vali Loss: 0.0857846 Test Loss: 0.0882640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0694140\n",
      "\tspeed: 0.0753s/iter; left time: 1268.9373s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655354\n",
      "\tspeed: 0.0419s/iter; left time: 702.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0700403 Vali Loss: 0.0856874 Test Loss: 0.0880371\n",
      "Validation loss decreased (0.085730 --> 0.085687).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680513\n",
      "\tspeed: 0.0729s/iter; left time: 1211.8735s\n",
      "\titers: 200, epoch: 26 | loss: 0.0614008\n",
      "\tspeed: 0.0422s/iter; left time: 697.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0699876 Vali Loss: 0.0857602 Test Loss: 0.0880605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0681010\n",
      "\tspeed: 0.0737s/iter; left time: 1209.0005s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719286\n",
      "\tspeed: 0.0409s/iter; left time: 666.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699794 Vali Loss: 0.0856203 Test Loss: 0.0880215\n",
      "Validation loss decreased (0.085687 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0715455\n",
      "\tspeed: 0.0777s/iter; left time: 1257.7111s\n",
      "\titers: 200, epoch: 28 | loss: 0.0702468\n",
      "\tspeed: 0.0411s/iter; left time: 661.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0698950 Vali Loss: 0.0855330 Test Loss: 0.0880139\n",
      "Validation loss decreased (0.085620 --> 0.085533).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0714828\n",
      "\tspeed: 0.0763s/iter; left time: 1217.9411s\n",
      "\titers: 200, epoch: 29 | loss: 0.0706265\n",
      "\tspeed: 0.0408s/iter; left time: 647.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0698917 Vali Loss: 0.0855195 Test Loss: 0.0880248\n",
      "Validation loss decreased (0.085533 --> 0.085519).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0714619\n",
      "\tspeed: 0.0742s/iter; left time: 1168.2092s\n",
      "\titers: 200, epoch: 30 | loss: 0.0664505\n",
      "\tspeed: 0.0418s/iter; left time: 654.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0698095 Vali Loss: 0.0856531 Test Loss: 0.0880330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0732058\n",
      "\tspeed: 0.0729s/iter; left time: 1130.9088s\n",
      "\titers: 200, epoch: 31 | loss: 0.0680768\n",
      "\tspeed: 0.0425s/iter; left time: 655.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0698472 Vali Loss: 0.0855296 Test Loss: 0.0879514\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0710819\n",
      "\tspeed: 0.0745s/iter; left time: 1138.8016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0653720\n",
      "\tspeed: 0.0412s/iter; left time: 625.7304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0697666 Vali Loss: 0.0855339 Test Loss: 0.0879451\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689314\n",
      "\tspeed: 0.0769s/iter; left time: 1158.4537s\n",
      "\titers: 200, epoch: 33 | loss: 0.0689489\n",
      "\tspeed: 0.0411s/iter; left time: 614.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0697218 Vali Loss: 0.0855810 Test Loss: 0.0879584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0722149\n",
      "\tspeed: 0.0771s/iter; left time: 1144.5327s\n",
      "\titers: 200, epoch: 34 | loss: 0.0753755\n",
      "\tspeed: 0.0413s/iter; left time: 609.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0697024 Vali Loss: 0.0854558 Test Loss: 0.0879442\n",
      "Validation loss decreased (0.085519 --> 0.085456).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0695830\n",
      "\tspeed: 0.0736s/iter; left time: 1075.5888s\n",
      "\titers: 200, epoch: 35 | loss: 0.0714961\n",
      "\tspeed: 0.0434s/iter; left time: 630.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0696798 Vali Loss: 0.0855717 Test Loss: 0.0879177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0646781\n",
      "\tspeed: 0.0730s/iter; left time: 1051.0720s\n",
      "\titers: 200, epoch: 36 | loss: 0.0619496\n",
      "\tspeed: 0.0418s/iter; left time: 597.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0697064 Vali Loss: 0.0855166 Test Loss: 0.0879396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669930\n",
      "\tspeed: 0.0744s/iter; left time: 1054.2108s\n",
      "\titers: 200, epoch: 37 | loss: 0.0625971\n",
      "\tspeed: 0.0409s/iter; left time: 575.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0696672 Vali Loss: 0.0855014 Test Loss: 0.0879528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0678924\n",
      "\tspeed: 0.0749s/iter; left time: 1045.0660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0688178\n",
      "\tspeed: 0.0409s/iter; left time: 566.8978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696622 Vali Loss: 0.0855257 Test Loss: 0.0879750\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0701673\n",
      "\tspeed: 0.0754s/iter; left time: 1034.4748s\n",
      "\titers: 200, epoch: 39 | loss: 0.0690970\n",
      "\tspeed: 0.0415s/iter; left time: 565.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0696282 Vali Loss: 0.0855480 Test Loss: 0.0879980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0651396\n",
      "\tspeed: 0.0732s/iter; left time: 988.9090s\n",
      "\titers: 200, epoch: 40 | loss: 0.0684225\n",
      "\tspeed: 0.0432s/iter; left time: 579.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0696272 Vali Loss: 0.0855301 Test Loss: 0.0879082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700838\n",
      "\tspeed: 0.0731s/iter; left time: 971.4658s\n",
      "\titers: 200, epoch: 41 | loss: 0.0650603\n",
      "\tspeed: 0.0412s/iter; left time: 543.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696333 Vali Loss: 0.0853576 Test Loss: 0.0879209\n",
      "Validation loss decreased (0.085456 --> 0.085358).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721609\n",
      "\tspeed: 0.0791s/iter; left time: 1033.0047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0683571\n",
      "\tspeed: 0.0411s/iter; left time: 532.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0696497 Vali Loss: 0.0856114 Test Loss: 0.0879269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0659273\n",
      "\tspeed: 0.0750s/iter; left time: 962.9138s\n",
      "\titers: 200, epoch: 43 | loss: 0.0703276\n",
      "\tspeed: 0.0411s/iter; left time: 523.3529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0696177 Vali Loss: 0.0855228 Test Loss: 0.0879306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0707573\n",
      "\tspeed: 0.0740s/iter; left time: 933.1694s\n",
      "\titers: 200, epoch: 44 | loss: 0.0708191\n",
      "\tspeed: 0.0429s/iter; left time: 536.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0695830 Vali Loss: 0.0854188 Test Loss: 0.0879598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0725420\n",
      "\tspeed: 0.0733s/iter; left time: 908.7304s\n",
      "\titers: 200, epoch: 45 | loss: 0.0703637\n",
      "\tspeed: 0.0423s/iter; left time: 519.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696023 Vali Loss: 0.0854171 Test Loss: 0.0879375\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0657321\n",
      "\tspeed: 0.0741s/iter; left time: 901.0396s\n",
      "\titers: 200, epoch: 46 | loss: 0.0639107\n",
      "\tspeed: 0.0410s/iter; left time: 495.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0695614 Vali Loss: 0.0854853 Test Loss: 0.0879773\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0717126\n",
      "\tspeed: 0.0775s/iter; left time: 926.1534s\n",
      "\titers: 200, epoch: 47 | loss: 0.0683041\n",
      "\tspeed: 0.0410s/iter; left time: 485.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0695458 Vali Loss: 0.0855225 Test Loss: 0.0879506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0647682\n",
      "\tspeed: 0.0748s/iter; left time: 876.1091s\n",
      "\titers: 200, epoch: 48 | loss: 0.0752877\n",
      "\tspeed: 0.0412s/iter; left time: 479.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0695764 Vali Loss: 0.0855578 Test Loss: 0.0879192\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0669895\n",
      "\tspeed: 0.0739s/iter; left time: 849.1132s\n",
      "\titers: 200, epoch: 49 | loss: 0.0671645\n",
      "\tspeed: 0.0441s/iter; left time: 502.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0695500 Vali Loss: 0.0854582 Test Loss: 0.0879122\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0681623\n",
      "\tspeed: 0.0729s/iter; left time: 822.0261s\n",
      "\titers: 200, epoch: 50 | loss: 0.0670224\n",
      "\tspeed: 0.0411s/iter; left time: 459.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0695453 Vali Loss: 0.0854244 Test Loss: 0.0879608\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0734773\n",
      "\tspeed: 0.0750s/iter; left time: 828.5580s\n",
      "\titers: 200, epoch: 51 | loss: 0.0709416\n",
      "\tspeed: 0.0409s/iter; left time: 447.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0694864 Vali Loss: 0.0854223 Test Loss: 0.0879430\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02090967260301113, rmse:0.14460177719593048, mae:0.08792086690664291, rse:0.5103196501731873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1313960\n",
      "\tspeed: 0.0426s/iter; left time: 946.2350s\n",
      "\titers: 200, epoch: 1 | loss: 0.1188500\n",
      "\tspeed: 0.0409s/iter; left time: 903.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.1354943 Vali Loss: 0.1248697 Test Loss: 0.1301842\n",
      "Validation loss decreased (inf --> 0.124870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870410\n",
      "\tspeed: 0.0759s/iter; left time: 1669.0927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790940\n",
      "\tspeed: 0.0408s/iter; left time: 893.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0881939 Vali Loss: 0.0920127 Test Loss: 0.0943350\n",
      "Validation loss decreased (0.124870 --> 0.092013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0822242\n",
      "\tspeed: 0.0751s/iter; left time: 1634.8448s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795212\n",
      "\tspeed: 0.0421s/iter; left time: 912.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0792196 Vali Loss: 0.0897547 Test Loss: 0.0930960\n",
      "Validation loss decreased (0.092013 --> 0.089755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744526\n",
      "\tspeed: 0.0744s/iter; left time: 1602.0627s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765585\n",
      "\tspeed: 0.0431s/iter; left time: 922.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0770492 Vali Loss: 0.0888159 Test Loss: 0.0912558\n",
      "Validation loss decreased (0.089755 --> 0.088816).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0781723\n",
      "\tspeed: 0.0752s/iter; left time: 1602.5429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787505\n",
      "\tspeed: 0.0411s/iter; left time: 872.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0755762 Vali Loss: 0.0882391 Test Loss: 0.0905145\n",
      "Validation loss decreased (0.088816 --> 0.088239).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734662\n",
      "\tspeed: 0.0779s/iter; left time: 1642.4975s\n",
      "\titers: 200, epoch: 6 | loss: 0.0701560\n",
      "\tspeed: 0.0412s/iter; left time: 865.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0744702 Vali Loss: 0.0880928 Test Loss: 0.0901387\n",
      "Validation loss decreased (0.088239 --> 0.088093).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758411\n",
      "\tspeed: 0.0762s/iter; left time: 1589.9836s\n",
      "\titers: 200, epoch: 7 | loss: 0.0725631\n",
      "\tspeed: 0.0411s/iter; left time: 853.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0737651 Vali Loss: 0.0871508 Test Loss: 0.0891528\n",
      "Validation loss decreased (0.088093 --> 0.087151).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0738654\n",
      "\tspeed: 0.0756s/iter; left time: 1561.2701s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790533\n",
      "\tspeed: 0.0418s/iter; left time: 859.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0730526 Vali Loss: 0.0870921 Test Loss: 0.0889390\n",
      "Validation loss decreased (0.087151 --> 0.087092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0699977\n",
      "\tspeed: 0.0750s/iter; left time: 1531.8871s\n",
      "\titers: 200, epoch: 9 | loss: 0.0693552\n",
      "\tspeed: 0.0424s/iter; left time: 862.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0725657 Vali Loss: 0.0867596 Test Loss: 0.0892174\n",
      "Validation loss decreased (0.087092 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688242\n",
      "\tspeed: 0.0754s/iter; left time: 1522.1999s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768644\n",
      "\tspeed: 0.0416s/iter; left time: 836.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0722564 Vali Loss: 0.0868287 Test Loss: 0.0888822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0725663\n",
      "\tspeed: 0.0791s/iter; left time: 1580.5377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708728\n",
      "\tspeed: 0.0410s/iter; left time: 814.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0719054 Vali Loss: 0.0862284 Test Loss: 0.0885692\n",
      "Validation loss decreased (0.086760 --> 0.086228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754657\n",
      "\tspeed: 0.0760s/iter; left time: 1500.0768s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690805\n",
      "\tspeed: 0.0418s/iter; left time: 821.9923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0715601 Vali Loss: 0.0863634 Test Loss: 0.0886728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0692426\n",
      "\tspeed: 0.0739s/iter; left time: 1443.7657s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709148\n",
      "\tspeed: 0.0431s/iter; left time: 836.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713889 Vali Loss: 0.0865801 Test Loss: 0.0886077\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719159\n",
      "\tspeed: 0.0740s/iter; left time: 1427.5372s\n",
      "\titers: 200, epoch: 14 | loss: 0.0689385\n",
      "\tspeed: 0.0410s/iter; left time: 786.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0711120 Vali Loss: 0.0861776 Test Loss: 0.0885576\n",
      "Validation loss decreased (0.086228 --> 0.086178).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719024\n",
      "\tspeed: 0.0813s/iter; left time: 1550.3733s\n",
      "\titers: 200, epoch: 15 | loss: 0.0737916\n",
      "\tspeed: 0.0410s/iter; left time: 777.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0709302 Vali Loss: 0.0860182 Test Loss: 0.0885886\n",
      "Validation loss decreased (0.086178 --> 0.086018).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717600\n",
      "\tspeed: 0.0776s/iter; left time: 1464.1638s\n",
      "\titers: 200, epoch: 16 | loss: 0.0704221\n",
      "\tspeed: 0.0413s/iter; left time: 775.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707807 Vali Loss: 0.0859530 Test Loss: 0.0883362\n",
      "Validation loss decreased (0.086018 --> 0.085953).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685674\n",
      "\tspeed: 0.0748s/iter; left time: 1392.9540s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712534\n",
      "\tspeed: 0.0428s/iter; left time: 793.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0706162 Vali Loss: 0.0860626 Test Loss: 0.0882613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0664355\n",
      "\tspeed: 0.0736s/iter; left time: 1355.5983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0718288\n",
      "\tspeed: 0.0425s/iter; left time: 778.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0704577 Vali Loss: 0.0858960 Test Loss: 0.0883355\n",
      "Validation loss decreased (0.085953 --> 0.085896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726624\n",
      "\tspeed: 0.0749s/iter; left time: 1363.0548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683349\n",
      "\tspeed: 0.0410s/iter; left time: 741.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0703722 Vali Loss: 0.0862532 Test Loss: 0.0885259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739421\n",
      "\tspeed: 0.0768s/iter; left time: 1378.8048s\n",
      "\titers: 200, epoch: 20 | loss: 0.0741002\n",
      "\tspeed: 0.0422s/iter; left time: 753.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0702616 Vali Loss: 0.0857343 Test Loss: 0.0880173\n",
      "Validation loss decreased (0.085896 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0670575\n",
      "\tspeed: 0.0768s/iter; left time: 1363.3505s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731600\n",
      "\tspeed: 0.0413s/iter; left time: 728.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0701356 Vali Loss: 0.0856524 Test Loss: 0.0883831\n",
      "Validation loss decreased (0.085734 --> 0.085652).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0671976\n",
      "\tspeed: 0.0771s/iter; left time: 1350.7183s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740734\n",
      "\tspeed: 0.0431s/iter; left time: 751.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0701010 Vali Loss: 0.0857823 Test Loss: 0.0880972\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758784\n",
      "\tspeed: 0.0743s/iter; left time: 1285.6170s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709538\n",
      "\tspeed: 0.0424s/iter; left time: 729.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0700068 Vali Loss: 0.0856148 Test Loss: 0.0881205\n",
      "Validation loss decreased (0.085652 --> 0.085615).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0685787\n",
      "\tspeed: 0.0758s/iter; left time: 1294.4500s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710734\n",
      "\tspeed: 0.0412s/iter; left time: 699.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699610 Vali Loss: 0.0856896 Test Loss: 0.0881782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0676588\n",
      "\tspeed: 0.0764s/iter; left time: 1288.0852s\n",
      "\titers: 200, epoch: 25 | loss: 0.0711828\n",
      "\tspeed: 0.0412s/iter; left time: 689.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0698800 Vali Loss: 0.0855946 Test Loss: 0.0882437\n",
      "Validation loss decreased (0.085615 --> 0.085595).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0661857\n",
      "\tspeed: 0.0764s/iter; left time: 1269.5660s\n",
      "\titers: 200, epoch: 26 | loss: 0.0734557\n",
      "\tspeed: 0.0415s/iter; left time: 685.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0698155 Vali Loss: 0.0855840 Test Loss: 0.0880812\n",
      "Validation loss decreased (0.085595 --> 0.085584).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697222\n",
      "\tspeed: 0.0741s/iter; left time: 1215.0588s\n",
      "\titers: 200, epoch: 27 | loss: 0.0661289\n",
      "\tspeed: 0.0433s/iter; left time: 706.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0697875 Vali Loss: 0.0856633 Test Loss: 0.0882748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0737358\n",
      "\tspeed: 0.0768s/iter; left time: 1242.1764s\n",
      "\titers: 200, epoch: 28 | loss: 0.0681898\n",
      "\tspeed: 0.0414s/iter; left time: 665.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696683 Vali Loss: 0.0855569 Test Loss: 0.0882192\n",
      "Validation loss decreased (0.085584 --> 0.085557).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0692833\n",
      "\tspeed: 0.0779s/iter; left time: 1243.7463s\n",
      "\titers: 200, epoch: 29 | loss: 0.0726246\n",
      "\tspeed: 0.0413s/iter; left time: 655.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696357 Vali Loss: 0.0855218 Test Loss: 0.0881251\n",
      "Validation loss decreased (0.085557 --> 0.085522).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0657860\n",
      "\tspeed: 0.0770s/iter; left time: 1211.4838s\n",
      "\titers: 200, epoch: 30 | loss: 0.0708374\n",
      "\tspeed: 0.0408s/iter; left time: 638.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696056 Vali Loss: 0.0855264 Test Loss: 0.0880535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0701524\n",
      "\tspeed: 0.0745s/iter; left time: 1155.6664s\n",
      "\titers: 200, epoch: 31 | loss: 0.0725639\n",
      "\tspeed: 0.0423s/iter; left time: 651.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0695799 Vali Loss: 0.0855524 Test Loss: 0.0881440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0713260\n",
      "\tspeed: 0.0742s/iter; left time: 1133.8718s\n",
      "\titers: 200, epoch: 32 | loss: 0.0717980\n",
      "\tspeed: 0.0442s/iter; left time: 671.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0695398 Vali Loss: 0.0854926 Test Loss: 0.0880160\n",
      "Validation loss decreased (0.085522 --> 0.085493).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0683134\n",
      "\tspeed: 0.0759s/iter; left time: 1143.2825s\n",
      "\titers: 200, epoch: 33 | loss: 0.0729751\n",
      "\tspeed: 0.0419s/iter; left time: 626.3768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0695101 Vali Loss: 0.0854646 Test Loss: 0.0880804\n",
      "Validation loss decreased (0.085493 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0691466\n",
      "\tspeed: 0.0784s/iter; left time: 1164.2330s\n",
      "\titers: 200, epoch: 34 | loss: 0.0703526\n",
      "\tspeed: 0.0408s/iter; left time: 601.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0695376 Vali Loss: 0.0855198 Test Loss: 0.0880577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776221\n",
      "\tspeed: 0.0764s/iter; left time: 1116.7155s\n",
      "\titers: 200, epoch: 35 | loss: 0.0695363\n",
      "\tspeed: 0.0417s/iter; left time: 605.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0694531 Vali Loss: 0.0854499 Test Loss: 0.0880845\n",
      "Validation loss decreased (0.085465 --> 0.085450).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697098\n",
      "\tspeed: 0.0761s/iter; left time: 1094.8774s\n",
      "\titers: 200, epoch: 36 | loss: 0.0732048\n",
      "\tspeed: 0.0423s/iter; left time: 604.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0694773 Vali Loss: 0.0854531 Test Loss: 0.0880837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0732422\n",
      "\tspeed: 0.0739s/iter; left time: 1047.1660s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698277\n",
      "\tspeed: 0.0425s/iter; left time: 597.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0695019 Vali Loss: 0.0854309 Test Loss: 0.0880640\n",
      "Validation loss decreased (0.085450 --> 0.085431).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0662249\n",
      "\tspeed: 0.0747s/iter; left time: 1042.3577s\n",
      "\titers: 200, epoch: 38 | loss: 0.0669574\n",
      "\tspeed: 0.0411s/iter; left time: 569.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0694807 Vali Loss: 0.0854503 Test Loss: 0.0881496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0675080\n",
      "\tspeed: 0.0781s/iter; left time: 1072.2160s\n",
      "\titers: 200, epoch: 39 | loss: 0.0717927\n",
      "\tspeed: 0.0413s/iter; left time: 562.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0694395 Vali Loss: 0.0855308 Test Loss: 0.0881241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0681171\n",
      "\tspeed: 0.0763s/iter; left time: 1030.3686s\n",
      "\titers: 200, epoch: 40 | loss: 0.0687452\n",
      "\tspeed: 0.0418s/iter; left time: 559.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0694168 Vali Loss: 0.0854836 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0687454\n",
      "\tspeed: 0.0746s/iter; left time: 991.3941s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672896\n",
      "\tspeed: 0.0430s/iter; left time: 566.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0693724 Vali Loss: 0.0854263 Test Loss: 0.0880959\n",
      "Validation loss decreased (0.085431 --> 0.085426).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0690397\n",
      "\tspeed: 0.0747s/iter; left time: 975.1047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0734327\n",
      "\tspeed: 0.0412s/iter; left time: 533.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0693399 Vali Loss: 0.0855006 Test Loss: 0.0881062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0726071\n",
      "\tspeed: 0.0752s/iter; left time: 965.0980s\n",
      "\titers: 200, epoch: 43 | loss: 0.0722188\n",
      "\tspeed: 0.0411s/iter; left time: 523.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0693658 Vali Loss: 0.0854671 Test Loss: 0.0881068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0688466\n",
      "\tspeed: 0.0761s/iter; left time: 960.0431s\n",
      "\titers: 200, epoch: 44 | loss: 0.0752073\n",
      "\tspeed: 0.0427s/iter; left time: 534.0069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0694005 Vali Loss: 0.0854169 Test Loss: 0.0880969\n",
      "Validation loss decreased (0.085426 --> 0.085417).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0694189\n",
      "\tspeed: 0.0771s/iter; left time: 955.1548s\n",
      "\titers: 200, epoch: 45 | loss: 0.0663738\n",
      "\tspeed: 0.0411s/iter; left time: 505.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693401 Vali Loss: 0.0854222 Test Loss: 0.0881163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0687163\n",
      "\tspeed: 0.0740s/iter; left time: 900.7709s\n",
      "\titers: 200, epoch: 46 | loss: 0.0681874\n",
      "\tspeed: 0.0429s/iter; left time: 517.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693499 Vali Loss: 0.0854475 Test Loss: 0.0880975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0698357\n",
      "\tspeed: 0.0733s/iter; left time: 875.7307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0708191\n",
      "\tspeed: 0.0421s/iter; left time: 498.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693365 Vali Loss: 0.0854302 Test Loss: 0.0880839\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0703154\n",
      "\tspeed: 0.0770s/iter; left time: 902.2628s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697617\n",
      "\tspeed: 0.0409s/iter; left time: 475.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0693081 Vali Loss: 0.0854606 Test Loss: 0.0881088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0689715\n",
      "\tspeed: 0.0781s/iter; left time: 898.0791s\n",
      "\titers: 200, epoch: 49 | loss: 0.0643823\n",
      "\tspeed: 0.0409s/iter; left time: 465.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0693539 Vali Loss: 0.0854463 Test Loss: 0.0881050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0739108\n",
      "\tspeed: 0.0755s/iter; left time: 851.3720s\n",
      "\titers: 200, epoch: 50 | loss: 0.0687575\n",
      "\tspeed: 0.0411s/iter; left time: 459.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693257 Vali Loss: 0.0853803 Test Loss: 0.0880668\n",
      "Validation loss decreased (0.085417 --> 0.085380).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0741657\n",
      "\tspeed: 0.0741s/iter; left time: 819.4238s\n",
      "\titers: 200, epoch: 51 | loss: 0.0745502\n",
      "\tspeed: 0.0424s/iter; left time: 464.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0693099 Vali Loss: 0.0854465 Test Loss: 0.0880877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0701798\n",
      "\tspeed: 0.0752s/iter; left time: 814.4153s\n",
      "\titers: 200, epoch: 52 | loss: 0.0675897\n",
      "\tspeed: 0.0407s/iter; left time: 437.0012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0692942 Vali Loss: 0.0854767 Test Loss: 0.0881183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0710436\n",
      "\tspeed: 0.0766s/iter; left time: 812.8227s\n",
      "\titers: 200, epoch: 53 | loss: 0.0713551\n",
      "\tspeed: 0.0412s/iter; left time: 432.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0693223 Vali Loss: 0.0854564 Test Loss: 0.0880729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0713452\n",
      "\tspeed: 0.0751s/iter; left time: 779.1887s\n",
      "\titers: 200, epoch: 54 | loss: 0.0682029\n",
      "\tspeed: 0.0412s/iter; left time: 423.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693280 Vali Loss: 0.0854152 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0675052\n",
      "\tspeed: 0.0767s/iter; left time: 779.4137s\n",
      "\titers: 200, epoch: 55 | loss: 0.0720875\n",
      "\tspeed: 0.0431s/iter; left time: 433.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0692830 Vali Loss: 0.0854154 Test Loss: 0.0880911\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0677626\n",
      "\tspeed: 0.0738s/iter; left time: 732.9327s\n",
      "\titers: 200, epoch: 56 | loss: 0.0691914\n",
      "\tspeed: 0.0426s/iter; left time: 418.7587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693142 Vali Loss: 0.0854138 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0713836\n",
      "\tspeed: 0.0741s/iter; left time: 719.9243s\n",
      "\titers: 200, epoch: 57 | loss: 0.0689744\n",
      "\tspeed: 0.0409s/iter; left time: 392.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0692971 Vali Loss: 0.0853321 Test Loss: 0.0880808\n",
      "Validation loss decreased (0.085380 --> 0.085332).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0728526\n",
      "\tspeed: 0.0785s/iter; left time: 744.8295s\n",
      "\titers: 200, epoch: 58 | loss: 0.0730912\n",
      "\tspeed: 0.0415s/iter; left time: 389.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693028 Vali Loss: 0.0854990 Test Loss: 0.0880816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0685177\n",
      "\tspeed: 0.0763s/iter; left time: 706.6706s\n",
      "\titers: 200, epoch: 59 | loss: 0.0764130\n",
      "\tspeed: 0.0410s/iter; left time: 376.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0693449 Vali Loss: 0.0854073 Test Loss: 0.0880793\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0652238\n",
      "\tspeed: 0.0748s/iter; left time: 676.4479s\n",
      "\titers: 200, epoch: 60 | loss: 0.0730409\n",
      "\tspeed: 0.0425s/iter; left time: 380.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693224 Vali Loss: 0.0854565 Test Loss: 0.0880748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0622156\n",
      "\tspeed: 0.0740s/iter; left time: 652.8614s\n",
      "\titers: 200, epoch: 61 | loss: 0.0695777\n",
      "\tspeed: 0.0423s/iter; left time: 369.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0693130 Vali Loss: 0.0853348 Test Loss: 0.0880779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0691958\n",
      "\tspeed: 0.0746s/iter; left time: 641.5221s\n",
      "\titers: 200, epoch: 62 | loss: 0.0696925\n",
      "\tspeed: 0.0411s/iter; left time: 348.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0692719 Vali Loss: 0.0854249 Test Loss: 0.0880714\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0646419\n",
      "\tspeed: 0.0767s/iter; left time: 642.4102s\n",
      "\titers: 200, epoch: 63 | loss: 0.0696922\n",
      "\tspeed: 0.0415s/iter; left time: 343.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0692963 Vali Loss: 0.0855429 Test Loss: 0.0881021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0697859\n",
      "\tspeed: 0.0767s/iter; left time: 625.5754s\n",
      "\titers: 200, epoch: 64 | loss: 0.0695441\n",
      "\tspeed: 0.0416s/iter; left time: 334.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0693159 Vali Loss: 0.0854452 Test Loss: 0.0880868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0718862\n",
      "\tspeed: 0.0746s/iter; left time: 591.8343s\n",
      "\titers: 200, epoch: 65 | loss: 0.0714731\n",
      "\tspeed: 0.0427s/iter; left time: 334.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0692911 Vali Loss: 0.0855044 Test Loss: 0.0880898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0747009\n",
      "\tspeed: 0.0740s/iter; left time: 570.0327s\n",
      "\titers: 200, epoch: 66 | loss: 0.0683450\n",
      "\tspeed: 0.0414s/iter; left time: 315.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0692636 Vali Loss: 0.0854475 Test Loss: 0.0880977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0644507\n",
      "\tspeed: 0.0754s/iter; left time: 564.0547s\n",
      "\titers: 200, epoch: 67 | loss: 0.0695106\n",
      "\tspeed: 0.0409s/iter; left time: 301.6847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0692449 Vali Loss: 0.0854787 Test Loss: 0.0881008\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021135743707418442, rmse:0.1453813761472702, mae:0.08808080106973648, rse:0.5130710005760193\n",
      "Intermediate time for DE and pred_len 24: 00h:23m:13.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0689s/iter; left time: 1523.7622s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272170\n",
      "\tspeed: 0.0429s/iter; left time: 943.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 222 | Train Loss: 0.1436296 Vali Loss: 0.1367209 Test Loss: 0.1443836\n",
      "Validation loss decreased (inf --> 0.136721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1119428\n",
      "\tspeed: 0.0752s/iter; left time: 1645.3605s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102052\n",
      "\tspeed: 0.0433s/iter; left time: 942.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1122322 Vali Loss: 0.1209552 Test Loss: 0.1276630\n",
      "Validation loss decreased (0.136721 --> 0.120955).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019009\n",
      "\tspeed: 0.0775s/iter; left time: 1678.0483s\n",
      "\titers: 200, epoch: 3 | loss: 0.1073653\n",
      "\tspeed: 0.0414s/iter; left time: 893.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1050740 Vali Loss: 0.1188224 Test Loss: 0.1261629\n",
      "Validation loss decreased (0.120955 --> 0.118822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991714\n",
      "\tspeed: 0.0787s/iter; left time: 1687.2832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1060414\n",
      "\tspeed: 0.0412s/iter; left time: 879.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1032394 Vali Loss: 0.1185098 Test Loss: 0.1264228\n",
      "Validation loss decreased (0.118822 --> 0.118510).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1070811\n",
      "\tspeed: 0.0785s/iter; left time: 1664.3113s\n",
      "\titers: 200, epoch: 5 | loss: 0.1010344\n",
      "\tspeed: 0.0413s/iter; left time: 872.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1018696 Vali Loss: 0.1173460 Test Loss: 0.1256864\n",
      "Validation loss decreased (0.118510 --> 0.117346).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0988520\n",
      "\tspeed: 0.0769s/iter; left time: 1613.7952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993529\n",
      "\tspeed: 0.0432s/iter; left time: 902.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1007471 Vali Loss: 0.1172743 Test Loss: 0.1250511\n",
      "Validation loss decreased (0.117346 --> 0.117274).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983264\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1289s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031795\n",
      "\tspeed: 0.0416s/iter; left time: 860.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0996418 Vali Loss: 0.1161049 Test Loss: 0.1247776\n",
      "Validation loss decreased (0.117274 --> 0.116105).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0968254\n",
      "\tspeed: 0.0767s/iter; left time: 1576.2278s\n",
      "\titers: 200, epoch: 8 | loss: 0.0976769\n",
      "\tspeed: 0.0433s/iter; left time: 885.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0990161 Vali Loss: 0.1161650 Test Loss: 0.1246663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0972535\n",
      "\tspeed: 0.0757s/iter; left time: 1538.0982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927693\n",
      "\tspeed: 0.0424s/iter; left time: 856.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.0982024 Vali Loss: 0.1159731 Test Loss: 0.1244971\n",
      "Validation loss decreased (0.116105 --> 0.115973).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004171\n",
      "\tspeed: 0.0787s/iter; left time: 1581.5480s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019848\n",
      "\tspeed: 0.0417s/iter; left time: 833.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0975692 Vali Loss: 0.1164706 Test Loss: 0.1259885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969026\n",
      "\tspeed: 0.0806s/iter; left time: 1602.3917s\n",
      "\titers: 200, epoch: 11 | loss: 0.0972415\n",
      "\tspeed: 0.0417s/iter; left time: 825.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0970848 Vali Loss: 0.1161472 Test Loss: 0.1248178\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0945826\n",
      "\tspeed: 0.0765s/iter; left time: 1502.9973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0900184\n",
      "\tspeed: 0.0430s/iter; left time: 840.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0966333 Vali Loss: 0.1163193 Test Loss: 0.1255104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0919880\n",
      "\tspeed: 0.0762s/iter; left time: 1481.9078s\n",
      "\titers: 200, epoch: 13 | loss: 0.0924623\n",
      "\tspeed: 0.0448s/iter; left time: 866.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.0962716 Vali Loss: 0.1166060 Test Loss: 0.1256381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920922\n",
      "\tspeed: 0.0769s/iter; left time: 1478.2532s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965592\n",
      "\tspeed: 0.0415s/iter; left time: 792.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0958053 Vali Loss: 0.1166250 Test Loss: 0.1259447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982206\n",
      "\tspeed: 0.0792s/iter; left time: 1504.5394s\n",
      "\titers: 200, epoch: 15 | loss: 0.0993863\n",
      "\tspeed: 0.0412s/iter; left time: 777.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.0955025 Vali Loss: 0.1164518 Test Loss: 0.1254893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0987729\n",
      "\tspeed: 0.0787s/iter; left time: 1477.8527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0852301\n",
      "\tspeed: 0.0420s/iter; left time: 784.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0951404 Vali Loss: 0.1169241 Test Loss: 0.1264961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0946120\n",
      "\tspeed: 0.0763s/iter; left time: 1415.3852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0943329\n",
      "\tspeed: 0.0438s/iter; left time: 808.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0948563 Vali Loss: 0.1167530 Test Loss: 0.1260772\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0961872\n",
      "\tspeed: 0.0765s/iter; left time: 1402.3126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899222\n",
      "\tspeed: 0.0421s/iter; left time: 767.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0945491 Vali Loss: 0.1170323 Test Loss: 0.1264428\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0923800\n",
      "\tspeed: 0.0759s/iter; left time: 1373.4559s\n",
      "\titers: 200, epoch: 19 | loss: 0.0921431\n",
      "\tspeed: 0.0416s/iter; left time: 749.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0942993 Vali Loss: 0.1170631 Test Loss: 0.1265067\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03561720997095108, rmse:0.18872521817684174, mae:0.12449711561203003, rse:0.6683141589164734\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1400388\n",
      "\tspeed: 0.0437s/iter; left time: 964.9514s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282806\n",
      "\tspeed: 0.0418s/iter; left time: 920.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1451481 Vali Loss: 0.1368056 Test Loss: 0.1443637\n",
      "Validation loss decreased (inf --> 0.136806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1109583\n",
      "\tspeed: 0.0795s/iter; left time: 1738.7939s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087150\n",
      "\tspeed: 0.0413s/iter; left time: 898.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1123508 Vali Loss: 0.1206324 Test Loss: 0.1275795\n",
      "Validation loss decreased (0.136806 --> 0.120632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1061414\n",
      "\tspeed: 0.0774s/iter; left time: 1676.6510s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020828\n",
      "\tspeed: 0.0427s/iter; left time: 921.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1054388 Vali Loss: 0.1195631 Test Loss: 0.1275751\n",
      "Validation loss decreased (0.120632 --> 0.119563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1002767\n",
      "\tspeed: 0.0766s/iter; left time: 1640.9971s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011909\n",
      "\tspeed: 0.0444s/iter; left time: 947.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 222 | Train Loss: 0.1036856 Vali Loss: 0.1177835 Test Loss: 0.1259473\n",
      "Validation loss decreased (0.119563 --> 0.117784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005678\n",
      "\tspeed: 0.0804s/iter; left time: 1704.5139s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012293\n",
      "\tspeed: 0.0422s/iter; left time: 892.0216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1022701 Vali Loss: 0.1182866 Test Loss: 0.1259687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041436\n",
      "\tspeed: 0.0799s/iter; left time: 1677.0377s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036419\n",
      "\tspeed: 0.0416s/iter; left time: 868.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1011227 Vali Loss: 0.1171968 Test Loss: 0.1266128\n",
      "Validation loss decreased (0.117784 --> 0.117197).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0986257\n",
      "\tspeed: 0.0798s/iter; left time: 1657.7720s\n",
      "\titers: 200, epoch: 7 | loss: 0.0996775\n",
      "\tspeed: 0.0414s/iter; left time: 856.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1001962 Vali Loss: 0.1165839 Test Loss: 0.1266569\n",
      "Validation loss decreased (0.117197 --> 0.116584).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0976779\n",
      "\tspeed: 0.0806s/iter; left time: 1656.7433s\n",
      "\titers: 200, epoch: 8 | loss: 0.0970001\n",
      "\tspeed: 0.0439s/iter; left time: 897.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 222 | Train Loss: 0.0992992 Vali Loss: 0.1167001 Test Loss: 0.1258703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027840\n",
      "\tspeed: 0.0771s/iter; left time: 1566.7971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060535\n",
      "\tspeed: 0.0430s/iter; left time: 869.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0985650 Vali Loss: 0.1167805 Test Loss: 0.1263607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0944021\n",
      "\tspeed: 0.0790s/iter; left time: 1588.0037s\n",
      "\titers: 200, epoch: 10 | loss: 0.1016151\n",
      "\tspeed: 0.0413s/iter; left time: 825.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.0980308 Vali Loss: 0.1163658 Test Loss: 0.1254943\n",
      "Validation loss decreased (0.116584 --> 0.116366).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0977273\n",
      "\tspeed: 0.0795s/iter; left time: 1581.0516s\n",
      "\titers: 200, epoch: 11 | loss: 0.0998444\n",
      "\tspeed: 0.0419s/iter; left time: 829.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0972910 Vali Loss: 0.1168659 Test Loss: 0.1263906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0961552\n",
      "\tspeed: 0.0790s/iter; left time: 1552.8094s\n",
      "\titers: 200, epoch: 12 | loss: 0.0945634\n",
      "\tspeed: 0.0428s/iter; left time: 836.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.0967934 Vali Loss: 0.1168394 Test Loss: 0.1271407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0975530\n",
      "\tspeed: 0.0768s/iter; left time: 1493.3065s\n",
      "\titers: 200, epoch: 13 | loss: 0.0979478\n",
      "\tspeed: 0.0447s/iter; left time: 864.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.0963015 Vali Loss: 0.1170192 Test Loss: 0.1264434\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0950694\n",
      "\tspeed: 0.0771s/iter; left time: 1481.7566s\n",
      "\titers: 200, epoch: 14 | loss: 0.0953018\n",
      "\tspeed: 0.0414s/iter; left time: 790.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 222 | Train Loss: 0.0958852 Vali Loss: 0.1174900 Test Loss: 0.1265704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0917451\n",
      "\tspeed: 0.0798s/iter; left time: 1516.0533s\n",
      "\titers: 200, epoch: 15 | loss: 0.0947973\n",
      "\tspeed: 0.0414s/iter; left time: 781.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.0954877 Vali Loss: 0.1173866 Test Loss: 0.1267025\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0963200\n",
      "\tspeed: 0.0788s/iter; left time: 1478.6512s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930423\n",
      "\tspeed: 0.0423s/iter; left time: 789.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0950855 Vali Loss: 0.1175980 Test Loss: 0.1277074\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0916373\n",
      "\tspeed: 0.0815s/iter; left time: 1511.0478s\n",
      "\titers: 200, epoch: 17 | loss: 0.0967468\n",
      "\tspeed: 0.0506s/iter; left time: 933.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.78s\n",
      "Steps: 222 | Train Loss: 0.0947534 Vali Loss: 0.1174741 Test Loss: 0.1267105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0973670\n",
      "\tspeed: 0.0786s/iter; left time: 1440.3332s\n",
      "\titers: 200, epoch: 18 | loss: 0.0952947\n",
      "\tspeed: 0.0429s/iter; left time: 782.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 222 | Train Loss: 0.0943828 Vali Loss: 0.1179385 Test Loss: 0.1270582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973220\n",
      "\tspeed: 0.0781s/iter; left time: 1414.1248s\n",
      "\titers: 200, epoch: 19 | loss: 0.0969161\n",
      "\tspeed: 0.0420s/iter; left time: 756.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0941494 Vali Loss: 0.1176506 Test Loss: 0.1271805\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0945372\n",
      "\tspeed: 0.0828s/iter; left time: 1481.0696s\n",
      "\titers: 200, epoch: 20 | loss: 0.0925670\n",
      "\tspeed: 0.0417s/iter; left time: 741.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0939146 Vali Loss: 0.1181242 Test Loss: 0.1272864\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036110397428274155, rmse:0.1900273561477661, mae:0.12549425661563873, rse:0.6729252934455872\n",
      "Intermediate time for DE and pred_len 96: 00h:08m:04.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1397623\n",
      "\tspeed: 0.0685s/iter; left time: 1512.8747s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311453\n",
      "\tspeed: 0.0443s/iter; left time: 975.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 222 | Train Loss: 0.1455157 Vali Loss: 0.1382303 Test Loss: 0.1469418\n",
      "Validation loss decreased (inf --> 0.138230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1118676\n",
      "\tspeed: 0.0769s/iter; left time: 1681.6863s\n",
      "\titers: 200, epoch: 2 | loss: 0.1124648\n",
      "\tspeed: 0.0422s/iter; left time: 918.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1173347 Vali Loss: 0.1244901 Test Loss: 0.1326688\n",
      "Validation loss decreased (0.138230 --> 0.124490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142889\n",
      "\tspeed: 0.0829s/iter; left time: 1795.9465s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112246\n",
      "\tspeed: 0.0419s/iter; left time: 903.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.1107566 Vali Loss: 0.1233068 Test Loss: 0.1331108\n",
      "Validation loss decreased (0.124490 --> 0.123307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125001\n",
      "\tspeed: 0.0796s/iter; left time: 1705.7956s\n",
      "\titers: 200, epoch: 4 | loss: 0.1047679\n",
      "\tspeed: 0.0422s/iter; left time: 900.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1088656 Vali Loss: 0.1225500 Test Loss: 0.1325692\n",
      "Validation loss decreased (0.123307 --> 0.122550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1045422\n",
      "\tspeed: 0.0778s/iter; left time: 1651.2061s\n",
      "\titers: 200, epoch: 5 | loss: 0.1108324\n",
      "\tspeed: 0.0443s/iter; left time: 934.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.1072662 Vali Loss: 0.1221504 Test Loss: 0.1329006\n",
      "Validation loss decreased (0.122550 --> 0.122150).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041857\n",
      "\tspeed: 0.0778s/iter; left time: 1632.2456s\n",
      "\titers: 200, epoch: 6 | loss: 0.1052786\n",
      "\tspeed: 0.0448s/iter; left time: 936.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1058854 Vali Loss: 0.1215441 Test Loss: 0.1320615\n",
      "Validation loss decreased (0.122150 --> 0.121544).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038428\n",
      "\tspeed: 0.0791s/iter; left time: 1641.9992s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040158\n",
      "\tspeed: 0.0420s/iter; left time: 868.4266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1048011 Vali Loss: 0.1215408 Test Loss: 0.1310547\n",
      "Validation loss decreased (0.121544 --> 0.121541).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035512\n",
      "\tspeed: 0.0793s/iter; left time: 1629.1195s\n",
      "\titers: 200, epoch: 8 | loss: 0.1044740\n",
      "\tspeed: 0.0429s/iter; left time: 877.8017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1037952 Vali Loss: 0.1215836 Test Loss: 0.1319724\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043236\n",
      "\tspeed: 0.0805s/iter; left time: 1636.7817s\n",
      "\titers: 200, epoch: 9 | loss: 0.1052697\n",
      "\tspeed: 0.0427s/iter; left time: 862.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1029094 Vali Loss: 0.1222514 Test Loss: 0.1315340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996455\n",
      "\tspeed: 0.0792s/iter; left time: 1591.9196s\n",
      "\titers: 200, epoch: 10 | loss: 0.1033757\n",
      "\tspeed: 0.0422s/iter; left time: 843.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1021399 Vali Loss: 0.1226193 Test Loss: 0.1322068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1056792\n",
      "\tspeed: 0.0812s/iter; left time: 1613.7792s\n",
      "\titers: 200, epoch: 11 | loss: 0.1029007\n",
      "\tspeed: 0.0430s/iter; left time: 849.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 222 | Train Loss: 0.1013839 Vali Loss: 0.1223948 Test Loss: 0.1326800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1031876\n",
      "\tspeed: 0.0785s/iter; left time: 1543.2386s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028955\n",
      "\tspeed: 0.0448s/iter; left time: 876.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 222 | Train Loss: 0.1008144 Vali Loss: 0.1228269 Test Loss: 0.1327951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0969489\n",
      "\tspeed: 0.0775s/iter; left time: 1506.6652s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018683\n",
      "\tspeed: 0.0420s/iter; left time: 811.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1002138 Vali Loss: 0.1231768 Test Loss: 0.1335167\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0958620\n",
      "\tspeed: 0.0823s/iter; left time: 1582.0268s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960994\n",
      "\tspeed: 0.0425s/iter; left time: 812.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0996247 Vali Loss: 0.1232097 Test Loss: 0.1334005\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0970920\n",
      "\tspeed: 0.0815s/iter; left time: 1547.0298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0992540\n",
      "\tspeed: 0.0424s/iter; left time: 800.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 222 | Train Loss: 0.0991395 Vali Loss: 0.1234243 Test Loss: 0.1337967\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0988758\n",
      "\tspeed: 0.0778s/iter; left time: 1460.0914s\n",
      "\titers: 200, epoch: 16 | loss: 0.1006009\n",
      "\tspeed: 0.0429s/iter; left time: 801.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.0986473 Vali Loss: 0.1236352 Test Loss: 0.1343386\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0987671\n",
      "\tspeed: 0.0773s/iter; left time: 1434.3332s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016840\n",
      "\tspeed: 0.0433s/iter; left time: 798.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0981912 Vali Loss: 0.1233611 Test Loss: 0.1350610\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.037683311849832535, rmse:0.19412189722061157, mae:0.13105474412441254, rse:0.6875953674316406\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1464187\n",
      "\tspeed: 0.0438s/iter; left time: 969.1262s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341484\n",
      "\tspeed: 0.0436s/iter; left time: 958.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1460951 Vali Loss: 0.1378723 Test Loss: 0.1467569\n",
      "Validation loss decreased (inf --> 0.137872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1244008\n",
      "\tspeed: 0.0783s/iter; left time: 1714.2119s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136181\n",
      "\tspeed: 0.0421s/iter; left time: 917.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1175792 Vali Loss: 0.1241931 Test Loss: 0.1332423\n",
      "Validation loss decreased (0.137872 --> 0.124193).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168221\n",
      "\tspeed: 0.0842s/iter; left time: 1822.6471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108454\n",
      "\tspeed: 0.0422s/iter; left time: 908.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1109203 Vali Loss: 0.1232760 Test Loss: 0.1326479\n",
      "Validation loss decreased (0.124193 --> 0.123276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1095669\n",
      "\tspeed: 0.0842s/iter; left time: 1805.3797s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056824\n",
      "\tspeed: 0.0417s/iter; left time: 889.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1091623 Vali Loss: 0.1222856 Test Loss: 0.1327749\n",
      "Validation loss decreased (0.123276 --> 0.122286).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129397\n",
      "\tspeed: 0.0839s/iter; left time: 1779.1501s\n",
      "\titers: 200, epoch: 5 | loss: 0.1075838\n",
      "\tspeed: 0.0417s/iter; left time: 880.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1076867 Vali Loss: 0.1218808 Test Loss: 0.1322782\n",
      "Validation loss decreased (0.122286 --> 0.121881).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021544\n",
      "\tspeed: 0.0803s/iter; left time: 1684.8417s\n",
      "\titers: 200, epoch: 6 | loss: 0.1099828\n",
      "\tspeed: 0.0436s/iter; left time: 911.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.1062730 Vali Loss: 0.1218795 Test Loss: 0.1329139\n",
      "Validation loss decreased (0.121881 --> 0.121879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1045288\n",
      "\tspeed: 0.0787s/iter; left time: 1635.3227s\n",
      "\titers: 200, epoch: 7 | loss: 0.1049782\n",
      "\tspeed: 0.0442s/iter; left time: 912.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 222 | Train Loss: 0.1051721 Vali Loss: 0.1218529 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.121879 --> 0.121853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054067\n",
      "\tspeed: 0.0791s/iter; left time: 1625.8461s\n",
      "\titers: 200, epoch: 8 | loss: 0.1061499\n",
      "\tspeed: 0.0419s/iter; left time: 857.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1041193 Vali Loss: 0.1218142 Test Loss: 0.1342641\n",
      "Validation loss decreased (0.121853 --> 0.121814).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012625\n",
      "\tspeed: 0.0818s/iter; left time: 1661.8316s\n",
      "\titers: 200, epoch: 9 | loss: 0.1050227\n",
      "\tspeed: 0.0420s/iter; left time: 848.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1032028 Vali Loss: 0.1221258 Test Loss: 0.1326769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1042934\n",
      "\tspeed: 0.0803s/iter; left time: 1613.4620s\n",
      "\titers: 200, epoch: 10 | loss: 0.0979124\n",
      "\tspeed: 0.0422s/iter; left time: 843.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.1022348 Vali Loss: 0.1229397 Test Loss: 0.1328034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0992723\n",
      "\tspeed: 0.0782s/iter; left time: 1553.8170s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031113\n",
      "\tspeed: 0.0429s/iter; left time: 848.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.1014518 Vali Loss: 0.1221524 Test Loss: 0.1333573\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0981024\n",
      "\tspeed: 0.0796s/iter; left time: 1564.1103s\n",
      "\titers: 200, epoch: 12 | loss: 0.1039329\n",
      "\tspeed: 0.0420s/iter; left time: 820.8737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1004923 Vali Loss: 0.1232195 Test Loss: 0.1345381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996970\n",
      "\tspeed: 0.0800s/iter; left time: 1554.3746s\n",
      "\titers: 200, epoch: 13 | loss: 0.1020393\n",
      "\tspeed: 0.0420s/iter; left time: 812.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0998807 Vali Loss: 0.1230378 Test Loss: 0.1335723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1020292\n",
      "\tspeed: 0.0789s/iter; left time: 1515.2191s\n",
      "\titers: 200, epoch: 14 | loss: 0.0983770\n",
      "\tspeed: 0.0429s/iter; left time: 819.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 222 | Train Loss: 0.0993128 Vali Loss: 0.1233723 Test Loss: 0.1334894\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1019369\n",
      "\tspeed: 0.0786s/iter; left time: 1493.1534s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003085\n",
      "\tspeed: 0.0438s/iter; left time: 827.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986477 Vali Loss: 0.1239124 Test Loss: 0.1339220\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990376\n",
      "\tspeed: 0.0780s/iter; left time: 1463.5393s\n",
      "\titers: 200, epoch: 16 | loss: 0.0996671\n",
      "\tspeed: 0.0421s/iter; left time: 785.9176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0981405 Vali Loss: 0.1236752 Test Loss: 0.1338171\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0997125\n",
      "\tspeed: 0.0809s/iter; left time: 1500.4029s\n",
      "\titers: 200, epoch: 17 | loss: 0.0991643\n",
      "\tspeed: 0.0419s/iter; left time: 773.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0977311 Vali Loss: 0.1242002 Test Loss: 0.1341292\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0960976\n",
      "\tspeed: 0.0808s/iter; left time: 1481.3266s\n",
      "\titers: 200, epoch: 18 | loss: 0.0957674\n",
      "\tspeed: 0.0422s/iter; left time: 769.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 222 | Train Loss: 0.0973472 Vali Loss: 0.1244612 Test Loss: 0.1344188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03982341289520264, rmse:0.1995580494403839, mae:0.13426414132118225, rse:0.7068506479263306\n",
      "Intermediate time for DE and pred_len 168: 00h:07m:24.55s\n",
      "Intermediate time for DE: 00h:38m:43.17s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1188304\n",
      "\tspeed: 0.0652s/iter; left time: 1447.7247s\n",
      "\titers: 200, epoch: 1 | loss: 0.1158463\n",
      "\tspeed: 0.0436s/iter; left time: 964.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.1253345 Vali Loss: 0.1194196 Test Loss: 0.1384884\n",
      "Validation loss decreased (inf --> 0.119420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869500\n",
      "\tspeed: 0.0763s/iter; left time: 1677.7030s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823559\n",
      "\tspeed: 0.0412s/iter; left time: 901.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0858117 Vali Loss: 0.0921554 Test Loss: 0.1034357\n",
      "Validation loss decreased (0.119420 --> 0.092155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806272\n",
      "\tspeed: 0.0785s/iter; left time: 1708.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.0780588\n",
      "\tspeed: 0.0411s/iter; left time: 889.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0789248 Vali Loss: 0.0894574 Test Loss: 0.1027660\n",
      "Validation loss decreased (0.092155 --> 0.089457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818409\n",
      "\tspeed: 0.0777s/iter; left time: 1672.5881s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826696\n",
      "\tspeed: 0.0420s/iter; left time: 900.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0773095 Vali Loss: 0.0896718 Test Loss: 0.1028447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730246\n",
      "\tspeed: 0.0752s/iter; left time: 1601.9405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0735860\n",
      "\tspeed: 0.0431s/iter; left time: 913.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0762145 Vali Loss: 0.0891013 Test Loss: 0.1017014\n",
      "Validation loss decreased (0.089457 --> 0.089101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0732028\n",
      "\tspeed: 0.0745s/iter; left time: 1570.1271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779525\n",
      "\tspeed: 0.0428s/iter; left time: 898.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0755551 Vali Loss: 0.0885052 Test Loss: 0.1005966\n",
      "Validation loss decreased (0.089101 --> 0.088505).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749436\n",
      "\tspeed: 0.0767s/iter; left time: 1599.9896s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747769\n",
      "\tspeed: 0.0415s/iter; left time: 861.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0749858 Vali Loss: 0.0884487 Test Loss: 0.1012087\n",
      "Validation loss decreased (0.088505 --> 0.088449).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772606\n",
      "\tspeed: 0.0781s/iter; left time: 1611.0026s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730566\n",
      "\tspeed: 0.0413s/iter; left time: 847.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0745392 Vali Loss: 0.0878225 Test Loss: 0.1004115\n",
      "Validation loss decreased (0.088449 --> 0.087823).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728021\n",
      "\tspeed: 0.0764s/iter; left time: 1560.4706s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704910\n",
      "\tspeed: 0.0421s/iter; left time: 855.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0741072 Vali Loss: 0.0878454 Test Loss: 0.0995688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727380\n",
      "\tspeed: 0.0741s/iter; left time: 1497.3165s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768265\n",
      "\tspeed: 0.0429s/iter; left time: 862.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0736922 Vali Loss: 0.0878476 Test Loss: 0.1003193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0790198\n",
      "\tspeed: 0.0768s/iter; left time: 1532.9696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737132\n",
      "\tspeed: 0.0415s/iter; left time: 823.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0733805 Vali Loss: 0.0875606 Test Loss: 0.1003940\n",
      "Validation loss decreased (0.087823 --> 0.087561).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0658553\n",
      "\tspeed: 0.0744s/iter; left time: 1469.1125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785903\n",
      "\tspeed: 0.0411s/iter; left time: 807.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0731744 Vali Loss: 0.0876214 Test Loss: 0.0995508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719233\n",
      "\tspeed: 0.0767s/iter; left time: 1498.4702s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742535\n",
      "\tspeed: 0.0416s/iter; left time: 808.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0729265 Vali Loss: 0.0874835 Test Loss: 0.0995281\n",
      "Validation loss decreased (0.087561 --> 0.087484).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0725279\n",
      "\tspeed: 0.0758s/iter; left time: 1464.0409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0729276\n",
      "\tspeed: 0.0411s/iter; left time: 788.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0727757 Vali Loss: 0.0875945 Test Loss: 0.0995237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0727914\n",
      "\tspeed: 0.0749s/iter; left time: 1429.1084s\n",
      "\titers: 200, epoch: 15 | loss: 0.0719108\n",
      "\tspeed: 0.0424s/iter; left time: 804.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0725818 Vali Loss: 0.0873662 Test Loss: 0.0992842\n",
      "Validation loss decreased (0.087484 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703028\n",
      "\tspeed: 0.0752s/iter; left time: 1418.1670s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679876\n",
      "\tspeed: 0.0425s/iter; left time: 797.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0724623 Vali Loss: 0.0873758 Test Loss: 0.0991852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0762972\n",
      "\tspeed: 0.0754s/iter; left time: 1404.1466s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740745\n",
      "\tspeed: 0.0412s/iter; left time: 763.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0722771 Vali Loss: 0.0871907 Test Loss: 0.0993153\n",
      "Validation loss decreased (0.087366 --> 0.087191).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713437\n",
      "\tspeed: 0.0771s/iter; left time: 1419.2108s\n",
      "\titers: 200, epoch: 18 | loss: 0.0711351\n",
      "\tspeed: 0.0411s/iter; left time: 752.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0721830 Vali Loss: 0.0871974 Test Loss: 0.0992790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728786\n",
      "\tspeed: 0.0752s/iter; left time: 1366.7758s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766083\n",
      "\tspeed: 0.0418s/iter; left time: 756.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0720670 Vali Loss: 0.0873282 Test Loss: 0.0991362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0707023\n",
      "\tspeed: 0.0757s/iter; left time: 1360.3913s\n",
      "\titers: 200, epoch: 20 | loss: 0.0659706\n",
      "\tspeed: 0.0420s/iter; left time: 751.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0719200 Vali Loss: 0.0872897 Test Loss: 0.0990334\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683376\n",
      "\tspeed: 0.0744s/iter; left time: 1319.2726s\n",
      "\titers: 200, epoch: 21 | loss: 0.0744315\n",
      "\tspeed: 0.0418s/iter; left time: 738.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0718971 Vali Loss: 0.0872003 Test Loss: 0.0991050\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723205\n",
      "\tspeed: 0.0751s/iter; left time: 1315.7646s\n",
      "\titers: 200, epoch: 22 | loss: 0.0718565\n",
      "\tspeed: 0.0412s/iter; left time: 717.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0717617 Vali Loss: 0.0871217 Test Loss: 0.0991213\n",
      "Validation loss decreased (0.087191 --> 0.087122).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0754515\n",
      "\tspeed: 0.0776s/iter; left time: 1341.6347s\n",
      "\titers: 200, epoch: 23 | loss: 0.0666656\n",
      "\tspeed: 0.0417s/iter; left time: 716.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0717673 Vali Loss: 0.0870475 Test Loss: 0.0990244\n",
      "Validation loss decreased (0.087122 --> 0.087047).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0736613\n",
      "\tspeed: 0.0762s/iter; left time: 1300.7520s\n",
      "\titers: 200, epoch: 24 | loss: 0.0732239\n",
      "\tspeed: 0.0417s/iter; left time: 708.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716505 Vali Loss: 0.0871460 Test Loss: 0.0991912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0745001\n",
      "\tspeed: 0.0744s/iter; left time: 1253.5139s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714629\n",
      "\tspeed: 0.0430s/iter; left time: 719.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716034 Vali Loss: 0.0873583 Test Loss: 0.0990945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680236\n",
      "\tspeed: 0.0750s/iter; left time: 1246.2728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0676734\n",
      "\tspeed: 0.0411s/iter; left time: 679.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0715778 Vali Loss: 0.0872454 Test Loss: 0.0990852\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0735137\n",
      "\tspeed: 0.0766s/iter; left time: 1255.7564s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742956\n",
      "\tspeed: 0.0412s/iter; left time: 671.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0714903 Vali Loss: 0.0869934 Test Loss: 0.0989545\n",
      "Validation loss decreased (0.087047 --> 0.086993).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0663206\n",
      "\tspeed: 0.0771s/iter; left time: 1247.1326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0772928\n",
      "\tspeed: 0.0411s/iter; left time: 660.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0714377 Vali Loss: 0.0872516 Test Loss: 0.0991254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742304\n",
      "\tspeed: 0.0751s/iter; left time: 1197.9225s\n",
      "\titers: 200, epoch: 29 | loss: 0.0696663\n",
      "\tspeed: 0.0418s/iter; left time: 663.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714469 Vali Loss: 0.0871852 Test Loss: 0.0990446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0752319\n",
      "\tspeed: 0.0737s/iter; left time: 1160.2209s\n",
      "\titers: 200, epoch: 30 | loss: 0.0767607\n",
      "\tspeed: 0.0421s/iter; left time: 657.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714359 Vali Loss: 0.0872758 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0697839\n",
      "\tspeed: 0.0761s/iter; left time: 1180.0293s\n",
      "\titers: 200, epoch: 31 | loss: 0.0737064\n",
      "\tspeed: 0.0418s/iter; left time: 644.8325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0713810 Vali Loss: 0.0870711 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0747602\n",
      "\tspeed: 0.0786s/iter; left time: 1201.8673s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749984\n",
      "\tspeed: 0.0408s/iter; left time: 620.2149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0713382 Vali Loss: 0.0871204 Test Loss: 0.0990219\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0712683\n",
      "\tspeed: 0.0751s/iter; left time: 1130.8837s\n",
      "\titers: 200, epoch: 33 | loss: 0.0691796\n",
      "\tspeed: 0.0413s/iter; left time: 618.4426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713131 Vali Loss: 0.0871258 Test Loss: 0.0989417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0684355\n",
      "\tspeed: 0.0743s/iter; left time: 1103.0916s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734600\n",
      "\tspeed: 0.0426s/iter; left time: 627.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0713078 Vali Loss: 0.0871348 Test Loss: 0.0989215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735072\n",
      "\tspeed: 0.0742s/iter; left time: 1084.6726s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741483\n",
      "\tspeed: 0.0473s/iter; left time: 686.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0713056 Vali Loss: 0.0871275 Test Loss: 0.0989961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0728918\n",
      "\tspeed: 0.0826s/iter; left time: 1188.9078s\n",
      "\titers: 200, epoch: 36 | loss: 0.0666929\n",
      "\tspeed: 0.0412s/iter; left time: 589.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0712683 Vali Loss: 0.0871395 Test Loss: 0.0990887\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0745390\n",
      "\tspeed: 0.0750s/iter; left time: 1062.3159s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715760\n",
      "\tspeed: 0.0411s/iter; left time: 578.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0712489 Vali Loss: 0.0871422 Test Loss: 0.0990047\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02461354248225689, rmse:0.15688703954219818, mae:0.09895447641611099, rse:0.5412158370018005\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1241236\n",
      "\tspeed: 0.0443s/iter; left time: 984.5030s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141754\n",
      "\tspeed: 0.0409s/iter; left time: 903.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.1244885 Vali Loss: 0.1183953 Test Loss: 0.1381955\n",
      "Validation loss decreased (inf --> 0.118395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0812800\n",
      "\tspeed: 0.0752s/iter; left time: 1651.8621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813031\n",
      "\tspeed: 0.0428s/iter; left time: 935.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0860217 Vali Loss: 0.0911778 Test Loss: 0.1037141\n",
      "Validation loss decreased (0.118395 --> 0.091178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0854152\n",
      "\tspeed: 0.0753s/iter; left time: 1638.5817s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821180\n",
      "\tspeed: 0.0424s/iter; left time: 918.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0792323 Vali Loss: 0.0901997 Test Loss: 0.1024127\n",
      "Validation loss decreased (0.091178 --> 0.090200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771382\n",
      "\tspeed: 0.0779s/iter; left time: 1677.9186s\n",
      "\titers: 200, epoch: 4 | loss: 0.0748695\n",
      "\tspeed: 0.0417s/iter; left time: 892.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0776143 Vali Loss: 0.0893536 Test Loss: 0.1021961\n",
      "Validation loss decreased (0.090200 --> 0.089354).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746484\n",
      "\tspeed: 0.0788s/iter; left time: 1679.8393s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762351\n",
      "\tspeed: 0.0423s/iter; left time: 897.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0765393 Vali Loss: 0.0895949 Test Loss: 0.1016256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0704589\n",
      "\tspeed: 0.0762s/iter; left time: 1607.5950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779320\n",
      "\tspeed: 0.0453s/iter; left time: 949.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.0757048 Vali Loss: 0.0887313 Test Loss: 0.1005883\n",
      "Validation loss decreased (0.089354 --> 0.088731).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787142\n",
      "\tspeed: 0.0764s/iter; left time: 1594.4792s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723651\n",
      "\tspeed: 0.0421s/iter; left time: 874.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0752229 Vali Loss: 0.0888143 Test Loss: 0.1010623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749634\n",
      "\tspeed: 0.0752s/iter; left time: 1552.5956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0779372\n",
      "\tspeed: 0.0415s/iter; left time: 851.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0746250 Vali Loss: 0.0880766 Test Loss: 0.0999531\n",
      "Validation loss decreased (0.088731 --> 0.088077).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0755208\n",
      "\tspeed: 0.0779s/iter; left time: 1590.5388s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692909\n",
      "\tspeed: 0.0418s/iter; left time: 848.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0741197 Vali Loss: 0.0877385 Test Loss: 0.1002419\n",
      "Validation loss decreased (0.088077 --> 0.087739).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735870\n",
      "\tspeed: 0.0833s/iter; left time: 1682.1019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762803\n",
      "\tspeed: 0.0456s/iter; left time: 915.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 223 | Train Loss: 0.0737935 Vali Loss: 0.0875983 Test Loss: 0.0999065\n",
      "Validation loss decreased (0.087739 --> 0.087598).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739966\n",
      "\tspeed: 0.0797s/iter; left time: 1590.8784s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750790\n",
      "\tspeed: 0.0411s/iter; left time: 817.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0734880 Vali Loss: 0.0874614 Test Loss: 0.0996489\n",
      "Validation loss decreased (0.087598 --> 0.087461).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0765056\n",
      "\tspeed: 0.0749s/iter; left time: 1479.6047s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719574\n",
      "\tspeed: 0.0430s/iter; left time: 844.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0731832 Vali Loss: 0.0875553 Test Loss: 0.0998995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0682084\n",
      "\tspeed: 0.0759s/iter; left time: 1482.3639s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720051\n",
      "\tspeed: 0.0425s/iter; left time: 825.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0729966 Vali Loss: 0.0875060 Test Loss: 0.0998122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706566\n",
      "\tspeed: 0.0761s/iter; left time: 1468.0225s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754816\n",
      "\tspeed: 0.0429s/iter; left time: 823.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0728083 Vali Loss: 0.0875992 Test Loss: 0.0995544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706279\n",
      "\tspeed: 0.0773s/iter; left time: 1475.5315s\n",
      "\titers: 200, epoch: 15 | loss: 0.0750840\n",
      "\tspeed: 0.0413s/iter; left time: 783.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0726432 Vali Loss: 0.0872414 Test Loss: 0.0996507\n",
      "Validation loss decreased (0.087461 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0797694\n",
      "\tspeed: 0.0765s/iter; left time: 1442.0772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691095\n",
      "\tspeed: 0.0415s/iter; left time: 778.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0724336 Vali Loss: 0.0874647 Test Loss: 0.0995680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0743775\n",
      "\tspeed: 0.0749s/iter; left time: 1394.9423s\n",
      "\titers: 200, epoch: 17 | loss: 0.0741325\n",
      "\tspeed: 0.0427s/iter; left time: 790.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0723469 Vali Loss: 0.0873769 Test Loss: 0.0993158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726027\n",
      "\tspeed: 0.0748s/iter; left time: 1377.1837s\n",
      "\titers: 200, epoch: 18 | loss: 0.0659239\n",
      "\tspeed: 0.0414s/iter; left time: 757.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0721854 Vali Loss: 0.0872896 Test Loss: 0.0991555\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711987\n",
      "\tspeed: 0.0784s/iter; left time: 1426.3078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0673086\n",
      "\tspeed: 0.0418s/iter; left time: 756.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0721364 Vali Loss: 0.0871735 Test Loss: 0.0992202\n",
      "Validation loss decreased (0.087241 --> 0.087173).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731464\n",
      "\tspeed: 0.0767s/iter; left time: 1378.0725s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776331\n",
      "\tspeed: 0.0412s/iter; left time: 736.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0720103 Vali Loss: 0.0872837 Test Loss: 0.0991743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711740\n",
      "\tspeed: 0.0755s/iter; left time: 1339.7905s\n",
      "\titers: 200, epoch: 21 | loss: 0.0753554\n",
      "\tspeed: 0.0427s/iter; left time: 752.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0719040 Vali Loss: 0.0871968 Test Loss: 0.0992067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0715744\n",
      "\tspeed: 0.0759s/iter; left time: 1328.8578s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681315\n",
      "\tspeed: 0.0428s/iter; left time: 744.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0718549 Vali Loss: 0.0871228 Test Loss: 0.0991327\n",
      "Validation loss decreased (0.087173 --> 0.087123).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0704514\n",
      "\tspeed: 0.0766s/iter; left time: 1323.9731s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714713\n",
      "\tspeed: 0.0415s/iter; left time: 713.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0717374 Vali Loss: 0.0870542 Test Loss: 0.0989956\n",
      "Validation loss decreased (0.087123 --> 0.087054).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0751139\n",
      "\tspeed: 0.0781s/iter; left time: 1332.4945s\n",
      "\titers: 200, epoch: 24 | loss: 0.0752301\n",
      "\tspeed: 0.0419s/iter; left time: 711.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0716789 Vali Loss: 0.0870215 Test Loss: 0.0990368\n",
      "Validation loss decreased (0.087054 --> 0.087022).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0707601\n",
      "\tspeed: 0.0786s/iter; left time: 1324.3908s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697482\n",
      "\tspeed: 0.0426s/iter; left time: 713.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 223 | Train Loss: 0.0716772 Vali Loss: 0.0870498 Test Loss: 0.0989855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0707332\n",
      "\tspeed: 0.0748s/iter; left time: 1242.8210s\n",
      "\titers: 200, epoch: 26 | loss: 0.0765021\n",
      "\tspeed: 0.0425s/iter; left time: 702.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0716127 Vali Loss: 0.0868681 Test Loss: 0.0989585\n",
      "Validation loss decreased (0.087022 --> 0.086868).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0703442\n",
      "\tspeed: 0.0753s/iter; left time: 1234.9448s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724373\n",
      "\tspeed: 0.0416s/iter; left time: 677.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0715412 Vali Loss: 0.0870464 Test Loss: 0.0989664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0742472\n",
      "\tspeed: 0.0774s/iter; left time: 1252.0073s\n",
      "\titers: 200, epoch: 28 | loss: 0.0691978\n",
      "\tspeed: 0.0415s/iter; left time: 666.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0714920 Vali Loss: 0.0870631 Test Loss: 0.0991097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0707679\n",
      "\tspeed: 0.0762s/iter; left time: 1216.6364s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695740\n",
      "\tspeed: 0.0421s/iter; left time: 667.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0714264 Vali Loss: 0.0870037 Test Loss: 0.0989200\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0688290\n",
      "\tspeed: 0.0779s/iter; left time: 1225.5661s\n",
      "\titers: 200, epoch: 30 | loss: 0.0660956\n",
      "\tspeed: 0.0414s/iter; left time: 647.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0714084 Vali Loss: 0.0869053 Test Loss: 0.0989998\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0729475\n",
      "\tspeed: 0.0776s/iter; left time: 1204.0116s\n",
      "\titers: 200, epoch: 31 | loss: 0.0695744\n",
      "\tspeed: 0.0431s/iter; left time: 664.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0713882 Vali Loss: 0.0870360 Test Loss: 0.0989691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0672238\n",
      "\tspeed: 0.0760s/iter; left time: 1162.2643s\n",
      "\titers: 200, epoch: 32 | loss: 0.0767676\n",
      "\tspeed: 0.0418s/iter; left time: 634.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0714459 Vali Loss: 0.0869485 Test Loss: 0.0989849\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0716598\n",
      "\tspeed: 0.0799s/iter; left time: 1203.7757s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718821\n",
      "\tspeed: 0.0415s/iter; left time: 621.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713694 Vali Loss: 0.0869131 Test Loss: 0.0990300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0780078\n",
      "\tspeed: 0.0773s/iter; left time: 1147.5751s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725512\n",
      "\tspeed: 0.0423s/iter; left time: 623.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0713690 Vali Loss: 0.0870174 Test Loss: 0.0990362\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0721319\n",
      "\tspeed: 0.0758s/iter; left time: 1108.1308s\n",
      "\titers: 200, epoch: 35 | loss: 0.0699476\n",
      "\tspeed: 0.0417s/iter; left time: 605.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0713216 Vali Loss: 0.0868933 Test Loss: 0.0989647\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0715593\n",
      "\tspeed: 0.0743s/iter; left time: 1068.9621s\n",
      "\titers: 200, epoch: 36 | loss: 0.0704235\n",
      "\tspeed: 0.0422s/iter; left time: 603.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0713195 Vali Loss: 0.0871119 Test Loss: 0.0989298\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024664107710123062, rmse:0.15704810619354248, mae:0.09895854443311691, rse:0.5417714715003967\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:36.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1304873\n",
      "\tspeed: 0.0668s/iter; left time: 1476.8440s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175975\n",
      "\tspeed: 0.0416s/iter; left time: 914.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1310178 Vali Loss: 0.1288243 Test Loss: 0.1522491\n",
      "Validation loss decreased (inf --> 0.128824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1069379\n",
      "\tspeed: 0.0775s/iter; left time: 1694.8193s\n",
      "\titers: 200, epoch: 2 | loss: 0.1099608\n",
      "\tspeed: 0.0416s/iter; left time: 905.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1079090 Vali Loss: 0.1167949 Test Loss: 0.1385253\n",
      "Validation loss decreased (0.128824 --> 0.116795).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1021708\n",
      "\tspeed: 0.0785s/iter; left time: 1699.0059s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059996\n",
      "\tspeed: 0.0429s/iter; left time: 924.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1029873 Vali Loss: 0.1158553 Test Loss: 0.1394041\n",
      "Validation loss decreased (0.116795 --> 0.115855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966939\n",
      "\tspeed: 0.0764s/iter; left time: 1638.0518s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026029\n",
      "\tspeed: 0.0422s/iter; left time: 900.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1014688 Vali Loss: 0.1153081 Test Loss: 0.1391761\n",
      "Validation loss decreased (0.115855 --> 0.115308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027995\n",
      "\tspeed: 0.0787s/iter; left time: 1669.7876s\n",
      "\titers: 200, epoch: 5 | loss: 0.1021266\n",
      "\tspeed: 0.0419s/iter; left time: 885.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004789 Vali Loss: 0.1146756 Test Loss: 0.1379868\n",
      "Validation loss decreased (0.115308 --> 0.114676).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0975265\n",
      "\tspeed: 0.0800s/iter; left time: 1679.8588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993915\n",
      "\tspeed: 0.0419s/iter; left time: 875.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.0995412 Vali Loss: 0.1150273 Test Loss: 0.1383243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968614\n",
      "\tspeed: 0.0781s/iter; left time: 1622.8290s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959852\n",
      "\tspeed: 0.0430s/iter; left time: 888.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986773 Vali Loss: 0.1150765 Test Loss: 0.1379591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994884\n",
      "\tspeed: 0.0775s/iter; left time: 1591.3927s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979322\n",
      "\tspeed: 0.0417s/iter; left time: 852.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0979208 Vali Loss: 0.1156444 Test Loss: 0.1380379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0953856\n",
      "\tspeed: 0.0769s/iter; left time: 1563.0344s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962101\n",
      "\tspeed: 0.0413s/iter; left time: 836.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0971903 Vali Loss: 0.1157434 Test Loss: 0.1375536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941000\n",
      "\tspeed: 0.0782s/iter; left time: 1573.0348s\n",
      "\titers: 200, epoch: 10 | loss: 0.0939218\n",
      "\tspeed: 0.0415s/iter; left time: 829.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.0965265 Vali Loss: 0.1158402 Test Loss: 0.1391500\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0948607\n",
      "\tspeed: 0.0780s/iter; left time: 1551.6565s\n",
      "\titers: 200, epoch: 11 | loss: 0.0935992\n",
      "\tspeed: 0.0417s/iter; left time: 824.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0959107 Vali Loss: 0.1162248 Test Loss: 0.1396610\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0920896\n",
      "\tspeed: 0.0750s/iter; left time: 1474.6129s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940504\n",
      "\tspeed: 0.0425s/iter; left time: 830.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0953595 Vali Loss: 0.1159682 Test Loss: 0.1396242\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0913273\n",
      "\tspeed: 0.0759s/iter; left time: 1476.0173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0974089\n",
      "\tspeed: 0.0413s/iter; left time: 798.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0947790 Vali Loss: 0.1162849 Test Loss: 0.1413390\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0933513\n",
      "\tspeed: 0.0777s/iter; left time: 1493.3694s\n",
      "\titers: 200, epoch: 14 | loss: 0.0954880\n",
      "\tspeed: 0.0418s/iter; left time: 799.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0943125 Vali Loss: 0.1169559 Test Loss: 0.1414862\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0993926\n",
      "\tspeed: 0.0776s/iter; left time: 1474.3737s\n",
      "\titers: 200, epoch: 15 | loss: 0.0961179\n",
      "\tspeed: 0.0415s/iter; left time: 783.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.0938692 Vali Loss: 0.1164688 Test Loss: 0.1422094\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.040224574506282806, rmse:0.20056064426898956, mae:0.13798677921295166, rse:0.6935666799545288\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1305858\n",
      "\tspeed: 0.0446s/iter; left time: 986.5156s\n",
      "\titers: 200, epoch: 1 | loss: 0.1279940\n",
      "\tspeed: 0.0419s/iter; left time: 920.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1310129 Vali Loss: 0.1287763 Test Loss: 0.1517726\n",
      "Validation loss decreased (inf --> 0.128776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1047999\n",
      "\tspeed: 0.0773s/iter; left time: 1691.8110s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011871\n",
      "\tspeed: 0.0423s/iter; left time: 922.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1081233 Vali Loss: 0.1171175 Test Loss: 0.1384159\n",
      "Validation loss decreased (0.128776 --> 0.117118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041322\n",
      "\tspeed: 0.0768s/iter; left time: 1662.2105s\n",
      "\titers: 200, epoch: 3 | loss: 0.0997675\n",
      "\tspeed: 0.0435s/iter; left time: 936.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1030756 Vali Loss: 0.1154505 Test Loss: 0.1378653\n",
      "Validation loss decreased (0.117118 --> 0.115451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1052338\n",
      "\tspeed: 0.0782s/iter; left time: 1676.5682s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011579\n",
      "\tspeed: 0.0418s/iter; left time: 891.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1016301 Vali Loss: 0.1150195 Test Loss: 0.1379458\n",
      "Validation loss decreased (0.115451 --> 0.115019).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0983982\n",
      "\tspeed: 0.0802s/iter; left time: 1702.1037s\n",
      "\titers: 200, epoch: 5 | loss: 0.0970867\n",
      "\tspeed: 0.0416s/iter; left time: 877.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004418 Vali Loss: 0.1147584 Test Loss: 0.1383713\n",
      "Validation loss decreased (0.115019 --> 0.114758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1006362\n",
      "\tspeed: 0.0793s/iter; left time: 1664.9695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0965790\n",
      "\tspeed: 0.0416s/iter; left time: 868.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0992838 Vali Loss: 0.1148322 Test Loss: 0.1393588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966187\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1368s\n",
      "\titers: 200, epoch: 7 | loss: 0.0989298\n",
      "\tspeed: 0.0425s/iter; left time: 878.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0983812 Vali Loss: 0.1146387 Test Loss: 0.1399318\n",
      "Validation loss decreased (0.114758 --> 0.114639).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0930875\n",
      "\tspeed: 0.0778s/iter; left time: 1598.6296s\n",
      "\titers: 200, epoch: 8 | loss: 0.0929199\n",
      "\tspeed: 0.0429s/iter; left time: 877.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.0972934 Vali Loss: 0.1146473 Test Loss: 0.1403886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951188\n",
      "\tspeed: 0.0772s/iter; left time: 1568.9761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0949333\n",
      "\tspeed: 0.0414s/iter; left time: 838.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0964337 Vali Loss: 0.1151828 Test Loss: 0.1416367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989180\n",
      "\tspeed: 0.0785s/iter; left time: 1577.9541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0938160\n",
      "\tspeed: 0.0416s/iter; left time: 831.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0956362 Vali Loss: 0.1152233 Test Loss: 0.1418035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0915988\n",
      "\tspeed: 0.0785s/iter; left time: 1560.3960s\n",
      "\titers: 200, epoch: 11 | loss: 0.0964191\n",
      "\tspeed: 0.0415s/iter; left time: 820.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0949925 Vali Loss: 0.1158287 Test Loss: 0.1423944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0963742\n",
      "\tspeed: 0.0773s/iter; left time: 1519.4097s\n",
      "\titers: 200, epoch: 12 | loss: 0.0933959\n",
      "\tspeed: 0.0423s/iter; left time: 827.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.0941572 Vali Loss: 0.1160542 Test Loss: 0.1424110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961953\n",
      "\tspeed: 0.0762s/iter; left time: 1480.6556s\n",
      "\titers: 200, epoch: 13 | loss: 0.0965029\n",
      "\tspeed: 0.0421s/iter; left time: 814.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0936945 Vali Loss: 0.1154687 Test Loss: 0.1416178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0912792\n",
      "\tspeed: 0.0774s/iter; left time: 1486.3895s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940753\n",
      "\tspeed: 0.0413s/iter; left time: 789.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0929719 Vali Loss: 0.1157708 Test Loss: 0.1427507\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0968269\n",
      "\tspeed: 0.0794s/iter; left time: 1507.9914s\n",
      "\titers: 200, epoch: 15 | loss: 0.0915315\n",
      "\tspeed: 0.0417s/iter; left time: 787.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0925117 Vali Loss: 0.1161520 Test Loss: 0.1430477\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0888845\n",
      "\tspeed: 0.0785s/iter; left time: 1474.0309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930691\n",
      "\tspeed: 0.0414s/iter; left time: 772.2440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0921011 Vali Loss: 0.1164447 Test Loss: 0.1432250\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0904549\n",
      "\tspeed: 0.0771s/iter; left time: 1431.0215s\n",
      "\titers: 200, epoch: 17 | loss: 0.0925897\n",
      "\tspeed: 0.0430s/iter; left time: 792.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0916482 Vali Loss: 0.1165479 Test Loss: 0.1434288\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041966523975133896, rmse:0.20485731959342957, mae:0.13993188738822937, rse:0.7084251642227173\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:36.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1260497\n",
      "\tspeed: 0.0661s/iter; left time: 1461.0643s\n",
      "\titers: 200, epoch: 1 | loss: 0.1233853\n",
      "\tspeed: 0.0420s/iter; left time: 924.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1326778 Vali Loss: 0.1309269 Test Loss: 0.1548633\n",
      "Validation loss decreased (inf --> 0.130927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1094469\n",
      "\tspeed: 0.0794s/iter; left time: 1737.2973s\n",
      "\titers: 200, epoch: 2 | loss: 0.1086948\n",
      "\tspeed: 0.0417s/iter; left time: 908.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1121342 Vali Loss: 0.1213708 Test Loss: 0.1448956\n",
      "Validation loss decreased (0.130927 --> 0.121371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085828\n",
      "\tspeed: 0.0805s/iter; left time: 1744.2921s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110668\n",
      "\tspeed: 0.0420s/iter; left time: 905.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1075699 Vali Loss: 0.1199603 Test Loss: 0.1443719\n",
      "Validation loss decreased (0.121371 --> 0.119960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1096162\n",
      "\tspeed: 0.0780s/iter; left time: 1671.4152s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028981\n",
      "\tspeed: 0.0438s/iter; left time: 934.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1060007 Vali Loss: 0.1197756 Test Loss: 0.1440592\n",
      "Validation loss decreased (0.119960 --> 0.119776).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043223\n",
      "\tspeed: 0.0785s/iter; left time: 1664.7745s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071000\n",
      "\tspeed: 0.0431s/iter; left time: 908.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1046242 Vali Loss: 0.1203860 Test Loss: 0.1448624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994743\n",
      "\tspeed: 0.0777s/iter; left time: 1630.2978s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044898\n",
      "\tspeed: 0.0422s/iter; left time: 881.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.1033739 Vali Loss: 0.1210232 Test Loss: 0.1450372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1018771\n",
      "\tspeed: 0.0785s/iter; left time: 1630.0362s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027877\n",
      "\tspeed: 0.0421s/iter; left time: 869.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1023430 Vali Loss: 0.1218093 Test Loss: 0.1471738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995843\n",
      "\tspeed: 0.0778s/iter; left time: 1599.1551s\n",
      "\titers: 200, epoch: 8 | loss: 0.0966036\n",
      "\tspeed: 0.0417s/iter; left time: 853.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1014311 Vali Loss: 0.1216973 Test Loss: 0.1467350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010340\n",
      "\tspeed: 0.0765s/iter; left time: 1554.9552s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001390\n",
      "\tspeed: 0.0433s/iter; left time: 875.0557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1004857 Vali Loss: 0.1226195 Test Loss: 0.1462484\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983590\n",
      "\tspeed: 0.0768s/iter; left time: 1543.3019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0999743\n",
      "\tspeed: 0.0422s/iter; left time: 844.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.0997015 Vali Loss: 0.1216679 Test Loss: 0.1459581\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025495\n",
      "\tspeed: 0.0789s/iter; left time: 1567.7444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974560\n",
      "\tspeed: 0.0419s/iter; left time: 828.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.0988213 Vali Loss: 0.1222738 Test Loss: 0.1464456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1022936\n",
      "\tspeed: 0.0794s/iter; left time: 1561.1810s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971468\n",
      "\tspeed: 0.0421s/iter; left time: 823.0657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0980070 Vali Loss: 0.1221250 Test Loss: 0.1460842\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0957897\n",
      "\tspeed: 0.0791s/iter; left time: 1537.1685s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973659\n",
      "\tspeed: 0.0420s/iter; left time: 811.4997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0972951 Vali Loss: 0.1227004 Test Loss: 0.1479962\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920695\n",
      "\tspeed: 0.0766s/iter; left time: 1471.0401s\n",
      "\titers: 200, epoch: 14 | loss: 0.0948682\n",
      "\tspeed: 0.0431s/iter; left time: 823.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0966523 Vali Loss: 0.1230309 Test Loss: 0.1473147\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04283905029296875, rmse:0.20697596669197083, mae:0.14405910670757294, rse:0.7176154255867004\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354174\n",
      "\tspeed: 0.0440s/iter; left time: 971.9497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272134\n",
      "\tspeed: 0.0429s/iter; left time: 944.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.1335480 Vali Loss: 0.1309509 Test Loss: 0.1545976\n",
      "Validation loss decreased (inf --> 0.130951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1133488\n",
      "\tspeed: 0.0801s/iter; left time: 1753.2463s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126153\n",
      "\tspeed: 0.0433s/iter; left time: 942.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1122327 Vali Loss: 0.1214331 Test Loss: 0.1448028\n",
      "Validation loss decreased (0.130951 --> 0.121433).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069784\n",
      "\tspeed: 0.0798s/iter; left time: 1727.5802s\n",
      "\titers: 200, epoch: 3 | loss: 0.1111818\n",
      "\tspeed: 0.0419s/iter; left time: 903.1948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1077125 Vali Loss: 0.1202011 Test Loss: 0.1457766\n",
      "Validation loss decreased (0.121433 --> 0.120201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072374\n",
      "\tspeed: 0.0850s/iter; left time: 1821.7096s\n",
      "\titers: 200, epoch: 4 | loss: 0.1061509\n",
      "\tspeed: 0.0422s/iter; left time: 901.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.1062208 Vali Loss: 0.1202800 Test Loss: 0.1458177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077023\n",
      "\tspeed: 0.0798s/iter; left time: 1693.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043039\n",
      "\tspeed: 0.0420s/iter; left time: 886.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.1048119 Vali Loss: 0.1204090 Test Loss: 0.1450815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1053132\n",
      "\tspeed: 0.0778s/iter; left time: 1633.7682s\n",
      "\titers: 200, epoch: 6 | loss: 0.1045556\n",
      "\tspeed: 0.0430s/iter; left time: 897.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1033933 Vali Loss: 0.1211432 Test Loss: 0.1460922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1010433\n",
      "\tspeed: 0.0777s/iter; left time: 1614.5203s\n",
      "\titers: 200, epoch: 7 | loss: 0.0984273\n",
      "\tspeed: 0.0427s/iter; left time: 883.2299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1019883 Vali Loss: 0.1219406 Test Loss: 0.1475383\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1020061\n",
      "\tspeed: 0.0777s/iter; left time: 1596.4580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0999632\n",
      "\tspeed: 0.0422s/iter; left time: 862.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1006895 Vali Loss: 0.1223867 Test Loss: 0.1473340\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0978350\n",
      "\tspeed: 0.0805s/iter; left time: 1636.4255s\n",
      "\titers: 200, epoch: 9 | loss: 0.0947712\n",
      "\tspeed: 0.0417s/iter; left time: 843.6268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0993827 Vali Loss: 0.1230524 Test Loss: 0.1467847\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975076\n",
      "\tspeed: 0.0788s/iter; left time: 1583.7119s\n",
      "\titers: 200, epoch: 10 | loss: 0.0976299\n",
      "\tspeed: 0.0428s/iter; left time: 856.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.0981397 Vali Loss: 0.1236404 Test Loss: 0.1466535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0939989\n",
      "\tspeed: 0.0793s/iter; left time: 1575.7932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0989537\n",
      "\tspeed: 0.0428s/iter; left time: 846.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0970986 Vali Loss: 0.1238450 Test Loss: 0.1473410\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0958038\n",
      "\tspeed: 0.0792s/iter; left time: 1556.7527s\n",
      "\titers: 200, epoch: 12 | loss: 0.0997026\n",
      "\tspeed: 0.0424s/iter; left time: 829.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0961723 Vali Loss: 0.1241202 Test Loss: 0.1478169\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0963423\n",
      "\tspeed: 0.0793s/iter; left time: 1542.2571s\n",
      "\titers: 200, epoch: 13 | loss: 0.0922489\n",
      "\tspeed: 0.0446s/iter; left time: 861.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 222 | Train Loss: 0.0953029 Vali Loss: 0.1242875 Test Loss: 0.1478923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0440988764166832, rmse:0.20999732613563538, mae:0.14577659964561462, rse:0.7280909419059753\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:42.00s\n",
      "Intermediate time for GB: 00h:26m:55.22s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1177848\n",
      "\tspeed: 0.0475s/iter; left time: 1054.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1059930\n",
      "\tspeed: 0.0268s/iter; left time: 591.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.1258416 Vali Loss: 0.0933806 Test Loss: 0.1067235\n",
      "Validation loss decreased (inf --> 0.093381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721758\n",
      "\tspeed: 0.0526s/iter; left time: 1155.1685s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688074\n",
      "\tspeed: 0.0265s/iter; left time: 578.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0746695 Vali Loss: 0.0630054 Test Loss: 0.0701760\n",
      "Validation loss decreased (0.093381 --> 0.063005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640021\n",
      "\tspeed: 0.0541s/iter; left time: 1177.7243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631628\n",
      "\tspeed: 0.0266s/iter; left time: 575.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0643662 Vali Loss: 0.0596727 Test Loss: 0.0664817\n",
      "Validation loss decreased (0.063005 --> 0.059673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0633358\n",
      "\tspeed: 0.0522s/iter; left time: 1123.8531s\n",
      "\titers: 200, epoch: 4 | loss: 0.0598588\n",
      "\tspeed: 0.0274s/iter; left time: 587.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0616559 Vali Loss: 0.0577069 Test Loss: 0.0649258\n",
      "Validation loss decreased (0.059673 --> 0.057707).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600730\n",
      "\tspeed: 0.0542s/iter; left time: 1154.8282s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604561\n",
      "\tspeed: 0.0269s/iter; left time: 569.8563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0598165 Vali Loss: 0.0575377 Test Loss: 0.0640054\n",
      "Validation loss decreased (0.057707 --> 0.057538).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0562785\n",
      "\tspeed: 0.0525s/iter; left time: 1107.4072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0579553\n",
      "\tspeed: 0.0270s/iter; left time: 566.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0587862 Vali Loss: 0.0562634 Test Loss: 0.0629574\n",
      "Validation loss decreased (0.057538 --> 0.056263).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542753\n",
      "\tspeed: 0.0552s/iter; left time: 1152.4921s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573975\n",
      "\tspeed: 0.0267s/iter; left time: 554.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0578910 Vali Loss: 0.0557560 Test Loss: 0.0622238\n",
      "Validation loss decreased (0.056263 --> 0.055756).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0539824\n",
      "\tspeed: 0.0533s/iter; left time: 1100.2134s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542981\n",
      "\tspeed: 0.0279s/iter; left time: 572.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0572106 Vali Loss: 0.0555416 Test Loss: 0.0623640\n",
      "Validation loss decreased (0.055756 --> 0.055542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0544912\n",
      "\tspeed: 0.0526s/iter; left time: 1073.0902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0562044\n",
      "\tspeed: 0.0275s/iter; left time: 558.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0565972 Vali Loss: 0.0552657 Test Loss: 0.0625549\n",
      "Validation loss decreased (0.055542 --> 0.055266).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573178\n",
      "\tspeed: 0.0530s/iter; left time: 1070.0248s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550786\n",
      "\tspeed: 0.0288s/iter; left time: 577.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0561248 Vali Loss: 0.0548072 Test Loss: 0.0617649\n",
      "Validation loss decreased (0.055266 --> 0.054807).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0549671\n",
      "\tspeed: 0.0519s/iter; left time: 1037.4837s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561140\n",
      "\tspeed: 0.0264s/iter; left time: 525.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0556483 Vali Loss: 0.0546315 Test Loss: 0.0615806\n",
      "Validation loss decreased (0.054807 --> 0.054632).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561196\n",
      "\tspeed: 0.0520s/iter; left time: 1025.9605s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555787\n",
      "\tspeed: 0.0272s/iter; left time: 533.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0552293 Vali Loss: 0.0543794 Test Loss: 0.0613876\n",
      "Validation loss decreased (0.054632 --> 0.054379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533709\n",
      "\tspeed: 0.0533s/iter; left time: 1041.6509s\n",
      "\titers: 200, epoch: 13 | loss: 0.0539893\n",
      "\tspeed: 0.0267s/iter; left time: 517.7904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0549254 Vali Loss: 0.0543318 Test Loss: 0.0609576\n",
      "Validation loss decreased (0.054379 --> 0.054332).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530030\n",
      "\tspeed: 0.0521s/iter; left time: 1006.1253s\n",
      "\titers: 200, epoch: 14 | loss: 0.0533630\n",
      "\tspeed: 0.0285s/iter; left time: 547.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0545588 Vali Loss: 0.0541453 Test Loss: 0.0611451\n",
      "Validation loss decreased (0.054332 --> 0.054145).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500635\n",
      "\tspeed: 0.0516s/iter; left time: 985.3657s\n",
      "\titers: 200, epoch: 15 | loss: 0.0591192\n",
      "\tspeed: 0.0266s/iter; left time: 504.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0543057 Vali Loss: 0.0539221 Test Loss: 0.0611182\n",
      "Validation loss decreased (0.054145 --> 0.053922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566576\n",
      "\tspeed: 0.0524s/iter; left time: 987.9545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502781\n",
      "\tspeed: 0.0268s/iter; left time: 502.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0540829 Vali Loss: 0.0538061 Test Loss: 0.0607462\n",
      "Validation loss decreased (0.053922 --> 0.053806).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0566290\n",
      "\tspeed: 0.0521s/iter; left time: 971.4521s\n",
      "\titers: 200, epoch: 17 | loss: 0.0503884\n",
      "\tspeed: 0.0265s/iter; left time: 490.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0539302 Vali Loss: 0.0534953 Test Loss: 0.0605199\n",
      "Validation loss decreased (0.053806 --> 0.053495).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572149\n",
      "\tspeed: 0.0537s/iter; left time: 988.0298s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543917\n",
      "\tspeed: 0.0265s/iter; left time: 485.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0537375 Vali Loss: 0.0535588 Test Loss: 0.0605998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0552805\n",
      "\tspeed: 0.0514s/iter; left time: 935.1159s\n",
      "\titers: 200, epoch: 19 | loss: 0.0523237\n",
      "\tspeed: 0.0263s/iter; left time: 474.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0535796 Vali Loss: 0.0535295 Test Loss: 0.0603616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545848\n",
      "\tspeed: 0.0537s/iter; left time: 965.2525s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549286\n",
      "\tspeed: 0.0268s/iter; left time: 478.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0534138 Vali Loss: 0.0532950 Test Loss: 0.0604182\n",
      "Validation loss decreased (0.053495 --> 0.053295).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0529836\n",
      "\tspeed: 0.0532s/iter; left time: 944.3567s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538217\n",
      "\tspeed: 0.0264s/iter; left time: 465.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533455 Vali Loss: 0.0530735 Test Loss: 0.0601349\n",
      "Validation loss decreased (0.053295 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533596\n",
      "\tspeed: 0.0563s/iter; left time: 986.5509s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551906\n",
      "\tspeed: 0.0264s/iter; left time: 459.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0531747 Vali Loss: 0.0531457 Test Loss: 0.0603495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0533368\n",
      "\tspeed: 0.0512s/iter; left time: 885.7195s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566950\n",
      "\tspeed: 0.0280s/iter; left time: 481.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0530683 Vali Loss: 0.0531179 Test Loss: 0.0601824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560505\n",
      "\tspeed: 0.0540s/iter; left time: 922.4103s\n",
      "\titers: 200, epoch: 24 | loss: 0.0509092\n",
      "\tspeed: 0.0274s/iter; left time: 465.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0529976 Vali Loss: 0.0531084 Test Loss: 0.0601074\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0558175\n",
      "\tspeed: 0.0519s/iter; left time: 873.8136s\n",
      "\titers: 200, epoch: 25 | loss: 0.0517861\n",
      "\tspeed: 0.0268s/iter; left time: 449.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0529033 Vali Loss: 0.0531205 Test Loss: 0.0602300\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513149\n",
      "\tspeed: 0.0511s/iter; left time: 849.6052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0500016\n",
      "\tspeed: 0.0263s/iter; left time: 434.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0528154 Vali Loss: 0.0529059 Test Loss: 0.0601533\n",
      "Validation loss decreased (0.053073 --> 0.052906).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0518654\n",
      "\tspeed: 0.0519s/iter; left time: 851.0316s\n",
      "\titers: 200, epoch: 27 | loss: 0.0523646\n",
      "\tspeed: 0.0278s/iter; left time: 453.0433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0527788 Vali Loss: 0.0531640 Test Loss: 0.0602123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0533427\n",
      "\tspeed: 0.0525s/iter; left time: 849.6665s\n",
      "\titers: 200, epoch: 28 | loss: 0.0546841\n",
      "\tspeed: 0.0264s/iter; left time: 424.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0527124 Vali Loss: 0.0528726 Test Loss: 0.0599036\n",
      "Validation loss decreased (0.052906 --> 0.052873).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0509959\n",
      "\tspeed: 0.0522s/iter; left time: 833.0148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0543811\n",
      "\tspeed: 0.0274s/iter; left time: 435.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0526367 Vali Loss: 0.0528099 Test Loss: 0.0598749\n",
      "Validation loss decreased (0.052873 --> 0.052810).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0536711\n",
      "\tspeed: 0.0540s/iter; left time: 849.1549s\n",
      "\titers: 200, epoch: 30 | loss: 0.0521599\n",
      "\tspeed: 0.0265s/iter; left time: 414.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525897 Vali Loss: 0.0528667 Test Loss: 0.0601898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525367\n",
      "\tspeed: 0.0504s/iter; left time: 781.6923s\n",
      "\titers: 200, epoch: 31 | loss: 0.0528346\n",
      "\tspeed: 0.0267s/iter; left time: 411.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525614 Vali Loss: 0.0528139 Test Loss: 0.0600230\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510059\n",
      "\tspeed: 0.0549s/iter; left time: 839.7299s\n",
      "\titers: 200, epoch: 32 | loss: 0.0555225\n",
      "\tspeed: 0.0267s/iter; left time: 405.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0525297 Vali Loss: 0.0528147 Test Loss: 0.0600315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553756\n",
      "\tspeed: 0.0517s/iter; left time: 778.7115s\n",
      "\titers: 200, epoch: 33 | loss: 0.0561647\n",
      "\tspeed: 0.0269s/iter; left time: 402.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0524675 Vali Loss: 0.0527943 Test Loss: 0.0599646\n",
      "Validation loss decreased (0.052810 --> 0.052794).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547888\n",
      "\tspeed: 0.0546s/iter; left time: 810.3476s\n",
      "\titers: 200, epoch: 34 | loss: 0.0502540\n",
      "\tspeed: 0.0264s/iter; left time: 389.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0524123 Vali Loss: 0.0527812 Test Loss: 0.0600052\n",
      "Validation loss decreased (0.052794 --> 0.052781).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539715\n",
      "\tspeed: 0.0522s/iter; left time: 763.3288s\n",
      "\titers: 200, epoch: 35 | loss: 0.0542529\n",
      "\tspeed: 0.0288s/iter; left time: 417.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0523824 Vali Loss: 0.0526560 Test Loss: 0.0598498\n",
      "Validation loss decreased (0.052781 --> 0.052656).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0540629\n",
      "\tspeed: 0.0551s/iter; left time: 793.6323s\n",
      "\titers: 200, epoch: 36 | loss: 0.0535191\n",
      "\tspeed: 0.0267s/iter; left time: 381.9144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0523539 Vali Loss: 0.0526808 Test Loss: 0.0598498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0506244\n",
      "\tspeed: 0.0521s/iter; left time: 738.5504s\n",
      "\titers: 200, epoch: 37 | loss: 0.0530473\n",
      "\tspeed: 0.0274s/iter; left time: 385.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523549 Vali Loss: 0.0526425 Test Loss: 0.0598658\n",
      "Validation loss decreased (0.052656 --> 0.052643).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0527134\n",
      "\tspeed: 0.0556s/iter; left time: 775.5018s\n",
      "\titers: 200, epoch: 38 | loss: 0.0536440\n",
      "\tspeed: 0.0265s/iter; left time: 366.8005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523354 Vali Loss: 0.0528015 Test Loss: 0.0598641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0523238\n",
      "\tspeed: 0.0513s/iter; left time: 704.6534s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517573\n",
      "\tspeed: 0.0294s/iter; left time: 400.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0523230 Vali Loss: 0.0526925 Test Loss: 0.0598390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0538465\n",
      "\tspeed: 0.0518s/iter; left time: 699.8013s\n",
      "\titers: 200, epoch: 40 | loss: 0.0512804\n",
      "\tspeed: 0.0268s/iter; left time: 359.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522718 Vali Loss: 0.0526854 Test Loss: 0.0598257\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530373\n",
      "\tspeed: 0.0519s/iter; left time: 689.1349s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532438\n",
      "\tspeed: 0.0281s/iter; left time: 370.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522268 Vali Loss: 0.0526668 Test Loss: 0.0599239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0498807\n",
      "\tspeed: 0.0514s/iter; left time: 670.6596s\n",
      "\titers: 200, epoch: 42 | loss: 0.0523962\n",
      "\tspeed: 0.0267s/iter; left time: 346.4268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522847 Vali Loss: 0.0526407 Test Loss: 0.0598294\n",
      "Validation loss decreased (0.052643 --> 0.052641).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0534996\n",
      "\tspeed: 0.0540s/iter; left time: 692.4492s\n",
      "\titers: 200, epoch: 43 | loss: 0.0532958\n",
      "\tspeed: 0.0271s/iter; left time: 345.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0523306 Vali Loss: 0.0525946 Test Loss: 0.0597619\n",
      "Validation loss decreased (0.052641 --> 0.052595).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526985\n",
      "\tspeed: 0.0521s/iter; left time: 656.6391s\n",
      "\titers: 200, epoch: 44 | loss: 0.0511877\n",
      "\tspeed: 0.0270s/iter; left time: 337.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0521692 Vali Loss: 0.0526428 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556191\n",
      "\tspeed: 0.0533s/iter; left time: 660.9343s\n",
      "\titers: 200, epoch: 45 | loss: 0.0514222\n",
      "\tspeed: 0.0284s/iter; left time: 349.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0522454 Vali Loss: 0.0526971 Test Loss: 0.0597938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0529044\n",
      "\tspeed: 0.0522s/iter; left time: 635.0330s\n",
      "\titers: 200, epoch: 46 | loss: 0.0533347\n",
      "\tspeed: 0.0263s/iter; left time: 316.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0522511 Vali Loss: 0.0526150 Test Loss: 0.0598379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0525579\n",
      "\tspeed: 0.0556s/iter; left time: 663.7137s\n",
      "\titers: 200, epoch: 47 | loss: 0.0559584\n",
      "\tspeed: 0.0270s/iter; left time: 319.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522442 Vali Loss: 0.0526613 Test Loss: 0.0597907\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522379\n",
      "\tspeed: 0.0513s/iter; left time: 601.7284s\n",
      "\titers: 200, epoch: 48 | loss: 0.0542752\n",
      "\tspeed: 0.0267s/iter; left time: 310.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0521854 Vali Loss: 0.0526289 Test Loss: 0.0597892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549363\n",
      "\tspeed: 0.0526s/iter; left time: 604.4033s\n",
      "\titers: 200, epoch: 49 | loss: 0.0465775\n",
      "\tspeed: 0.0264s/iter; left time: 300.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0522630 Vali Loss: 0.0526140 Test Loss: 0.0598117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0494051\n",
      "\tspeed: 0.0507s/iter; left time: 571.0883s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522640\n",
      "\tspeed: 0.0267s/iter; left time: 298.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0522751 Vali Loss: 0.0526901 Test Loss: 0.0599105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0573033\n",
      "\tspeed: 0.0538s/iter; left time: 594.8035s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508314\n",
      "\tspeed: 0.0268s/iter; left time: 293.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521932 Vali Loss: 0.0526688 Test Loss: 0.0598051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0495923\n",
      "\tspeed: 0.0525s/iter; left time: 568.0226s\n",
      "\titers: 200, epoch: 52 | loss: 0.0519124\n",
      "\tspeed: 0.0267s/iter; left time: 286.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522027 Vali Loss: 0.0526402 Test Loss: 0.0598215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548224\n",
      "\tspeed: 0.0537s/iter; left time: 569.8401s\n",
      "\titers: 200, epoch: 53 | loss: 0.0511640\n",
      "\tspeed: 0.0267s/iter; left time: 280.9340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521802 Vali Loss: 0.0526538 Test Loss: 0.0598073\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009856260381639004, rmse:0.09927870333194733, mae:0.059761930257081985, rse:0.29216518998146057\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1225064\n",
      "\tspeed: 0.0293s/iter; left time: 649.8441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1018515\n",
      "\tspeed: 0.0285s/iter; left time: 630.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1260264 Vali Loss: 0.0930495 Test Loss: 0.1065131\n",
      "Validation loss decreased (inf --> 0.093049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0733656\n",
      "\tspeed: 0.0531s/iter; left time: 1166.1485s\n",
      "\titers: 200, epoch: 2 | loss: 0.0689993\n",
      "\tspeed: 0.0264s/iter; left time: 578.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0747297 Vali Loss: 0.0627035 Test Loss: 0.0696848\n",
      "Validation loss decreased (0.093049 --> 0.062703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641976\n",
      "\tspeed: 0.0527s/iter; left time: 1147.3285s\n",
      "\titers: 200, epoch: 3 | loss: 0.0600092\n",
      "\tspeed: 0.0267s/iter; left time: 577.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0643813 Vali Loss: 0.0594397 Test Loss: 0.0659568\n",
      "Validation loss decreased (0.062703 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0578316\n",
      "\tspeed: 0.0529s/iter; left time: 1139.9557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639258\n",
      "\tspeed: 0.0266s/iter; left time: 570.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0614354 Vali Loss: 0.0580388 Test Loss: 0.0646078\n",
      "Validation loss decreased (0.059440 --> 0.058039).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601949\n",
      "\tspeed: 0.0529s/iter; left time: 1127.1254s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646062\n",
      "\tspeed: 0.0263s/iter; left time: 557.4764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0598467 Vali Loss: 0.0574702 Test Loss: 0.0642393\n",
      "Validation loss decreased (0.058039 --> 0.057470).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582525\n",
      "\tspeed: 0.0531s/iter; left time: 1120.5297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598998\n",
      "\tspeed: 0.0264s/iter; left time: 554.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0587508 Vali Loss: 0.0564080 Test Loss: 0.0630445\n",
      "Validation loss decreased (0.057470 --> 0.056408).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556834\n",
      "\tspeed: 0.0529s/iter; left time: 1104.6372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605512\n",
      "\tspeed: 0.0266s/iter; left time: 552.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0577860 Vali Loss: 0.0561291 Test Loss: 0.0630853\n",
      "Validation loss decreased (0.056408 --> 0.056129).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0619714\n",
      "\tspeed: 0.0538s/iter; left time: 1110.8849s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560631\n",
      "\tspeed: 0.0274s/iter; left time: 563.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570553 Vali Loss: 0.0551744 Test Loss: 0.0620771\n",
      "Validation loss decreased (0.056129 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543769\n",
      "\tspeed: 0.0527s/iter; left time: 1076.3225s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573231\n",
      "\tspeed: 0.0267s/iter; left time: 542.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0564490 Vali Loss: 0.0553923 Test Loss: 0.0621985\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564896\n",
      "\tspeed: 0.0536s/iter; left time: 1082.7952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550005\n",
      "\tspeed: 0.0266s/iter; left time: 533.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0559311 Vali Loss: 0.0548954 Test Loss: 0.0616808\n",
      "Validation loss decreased (0.055174 --> 0.054895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559047\n",
      "\tspeed: 0.0522s/iter; left time: 1042.0117s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561010\n",
      "\tspeed: 0.0267s/iter; left time: 530.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0554993 Vali Loss: 0.0547145 Test Loss: 0.0616678\n",
      "Validation loss decreased (0.054895 --> 0.054715).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549887\n",
      "\tspeed: 0.0530s/iter; left time: 1046.4545s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535350\n",
      "\tspeed: 0.0274s/iter; left time: 537.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0550779 Vali Loss: 0.0541503 Test Loss: 0.0611615\n",
      "Validation loss decreased (0.054715 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564112\n",
      "\tspeed: 0.0521s/iter; left time: 1016.2813s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547302\n",
      "\tspeed: 0.0267s/iter; left time: 518.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0548484 Vali Loss: 0.0540437 Test Loss: 0.0611038\n",
      "Validation loss decreased (0.054150 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563114\n",
      "\tspeed: 0.0555s/iter; left time: 1071.2768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546800\n",
      "\tspeed: 0.0265s/iter; left time: 508.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0545632 Vali Loss: 0.0538223 Test Loss: 0.0608727\n",
      "Validation loss decreased (0.054044 --> 0.053822).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582940\n",
      "\tspeed: 0.0523s/iter; left time: 997.0774s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569442\n",
      "\tspeed: 0.0268s/iter; left time: 507.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0542870 Vali Loss: 0.0536832 Test Loss: 0.0606616\n",
      "Validation loss decreased (0.053822 --> 0.053683).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569478\n",
      "\tspeed: 0.0532s/iter; left time: 1003.7836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538614\n",
      "\tspeed: 0.0274s/iter; left time: 513.2290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0540642 Vali Loss: 0.0534916 Test Loss: 0.0607154\n",
      "Validation loss decreased (0.053683 --> 0.053492).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0559539\n",
      "\tspeed: 0.0518s/iter; left time: 965.5459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532772\n",
      "\tspeed: 0.0265s/iter; left time: 491.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0538495 Vali Loss: 0.0537074 Test Loss: 0.0608297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547949\n",
      "\tspeed: 0.0536s/iter; left time: 986.6825s\n",
      "\titers: 200, epoch: 18 | loss: 0.0560665\n",
      "\tspeed: 0.0266s/iter; left time: 486.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0536505 Vali Loss: 0.0534455 Test Loss: 0.0606475\n",
      "Validation loss decreased (0.053492 --> 0.053446).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0518258\n",
      "\tspeed: 0.0518s/iter; left time: 942.7260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0533621\n",
      "\tspeed: 0.0271s/iter; left time: 489.3186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0534612 Vali Loss: 0.0531519 Test Loss: 0.0604471\n",
      "Validation loss decreased (0.053446 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0547985\n",
      "\tspeed: 0.0555s/iter; left time: 997.1039s\n",
      "\titers: 200, epoch: 20 | loss: 0.0515255\n",
      "\tspeed: 0.0269s/iter; left time: 480.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0534055 Vali Loss: 0.0532615 Test Loss: 0.0602668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0534183\n",
      "\tspeed: 0.0526s/iter; left time: 932.3127s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536347\n",
      "\tspeed: 0.0276s/iter; left time: 487.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0532890 Vali Loss: 0.0531846 Test Loss: 0.0605303\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549916\n",
      "\tspeed: 0.0541s/iter; left time: 947.9029s\n",
      "\titers: 200, epoch: 22 | loss: 0.0554341\n",
      "\tspeed: 0.0266s/iter; left time: 462.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0531466 Vali Loss: 0.0528900 Test Loss: 0.0601454\n",
      "Validation loss decreased (0.053152 --> 0.052890).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513683\n",
      "\tspeed: 0.0526s/iter; left time: 909.7789s\n",
      "\titers: 200, epoch: 23 | loss: 0.0579329\n",
      "\tspeed: 0.0269s/iter; left time: 463.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0530312 Vali Loss: 0.0530480 Test Loss: 0.0602246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499048\n",
      "\tspeed: 0.0535s/iter; left time: 913.9284s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510843\n",
      "\tspeed: 0.0267s/iter; left time: 453.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0529737 Vali Loss: 0.0528694 Test Loss: 0.0602031\n",
      "Validation loss decreased (0.052890 --> 0.052869).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0577566\n",
      "\tspeed: 0.0523s/iter; left time: 881.3431s\n",
      "\titers: 200, epoch: 25 | loss: 0.0551628\n",
      "\tspeed: 0.0270s/iter; left time: 451.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0528067 Vali Loss: 0.0529870 Test Loss: 0.0601069\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513571\n",
      "\tspeed: 0.0522s/iter; left time: 867.8912s\n",
      "\titers: 200, epoch: 26 | loss: 0.0499296\n",
      "\tspeed: 0.0266s/iter; left time: 438.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0527925 Vali Loss: 0.0529492 Test Loss: 0.0600720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0509044\n",
      "\tspeed: 0.0517s/iter; left time: 848.6226s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493349\n",
      "\tspeed: 0.0272s/iter; left time: 443.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0527369 Vali Loss: 0.0528136 Test Loss: 0.0599594\n",
      "Validation loss decreased (0.052869 --> 0.052814).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532001\n",
      "\tspeed: 0.0525s/iter; left time: 849.3808s\n",
      "\titers: 200, epoch: 28 | loss: 0.0511784\n",
      "\tspeed: 0.0267s/iter; left time: 430.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526384 Vali Loss: 0.0528487 Test Loss: 0.0599587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0495770\n",
      "\tspeed: 0.0530s/iter; left time: 844.9906s\n",
      "\titers: 200, epoch: 29 | loss: 0.0464556\n",
      "\tspeed: 0.0269s/iter; left time: 427.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526565 Vali Loss: 0.0527931 Test Loss: 0.0599919\n",
      "Validation loss decreased (0.052814 --> 0.052793).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0552674\n",
      "\tspeed: 0.0517s/iter; left time: 813.9372s\n",
      "\titers: 200, epoch: 30 | loss: 0.0527033\n",
      "\tspeed: 0.0268s/iter; left time: 418.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0525646 Vali Loss: 0.0527250 Test Loss: 0.0599071\n",
      "Validation loss decreased (0.052793 --> 0.052725).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544455\n",
      "\tspeed: 0.0538s/iter; left time: 834.2253s\n",
      "\titers: 200, epoch: 31 | loss: 0.0547280\n",
      "\tspeed: 0.0275s/iter; left time: 424.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0525626 Vali Loss: 0.0527098 Test Loss: 0.0599193\n",
      "Validation loss decreased (0.052725 --> 0.052710).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0535513\n",
      "\tspeed: 0.0526s/iter; left time: 804.2974s\n",
      "\titers: 200, epoch: 32 | loss: 0.0491902\n",
      "\tspeed: 0.0270s/iter; left time: 409.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0524858 Vali Loss: 0.0527489 Test Loss: 0.0599410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0548159\n",
      "\tspeed: 0.0537s/iter; left time: 809.7204s\n",
      "\titers: 200, epoch: 33 | loss: 0.0534750\n",
      "\tspeed: 0.0265s/iter; left time: 396.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0524737 Vali Loss: 0.0526946 Test Loss: 0.0599220\n",
      "Validation loss decreased (0.052710 --> 0.052695).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547238\n",
      "\tspeed: 0.0519s/iter; left time: 770.9554s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526712\n",
      "\tspeed: 0.0265s/iter; left time: 390.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0524465 Vali Loss: 0.0526699 Test Loss: 0.0598708\n",
      "Validation loss decreased (0.052695 --> 0.052670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548534\n",
      "\tspeed: 0.0549s/iter; left time: 802.6370s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521703\n",
      "\tspeed: 0.0267s/iter; left time: 387.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0524024 Vali Loss: 0.0526626 Test Loss: 0.0597937\n",
      "Validation loss decreased (0.052670 --> 0.052663).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0503881\n",
      "\tspeed: 0.0526s/iter; left time: 757.2531s\n",
      "\titers: 200, epoch: 36 | loss: 0.0522587\n",
      "\tspeed: 0.0269s/iter; left time: 384.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523866 Vali Loss: 0.0526656 Test Loss: 0.0598915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0512503\n",
      "\tspeed: 0.0535s/iter; left time: 758.3364s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500938\n",
      "\tspeed: 0.0262s/iter; left time: 368.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0523500 Vali Loss: 0.0526616 Test Loss: 0.0599231\n",
      "Validation loss decreased (0.052663 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0501655\n",
      "\tspeed: 0.0518s/iter; left time: 722.8999s\n",
      "\titers: 200, epoch: 38 | loss: 0.0534852\n",
      "\tspeed: 0.0268s/iter; left time: 371.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523321 Vali Loss: 0.0527160 Test Loss: 0.0598248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0514224\n",
      "\tspeed: 0.0545s/iter; left time: 748.3258s\n",
      "\titers: 200, epoch: 39 | loss: 0.0514188\n",
      "\tspeed: 0.0269s/iter; left time: 366.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0523240 Vali Loss: 0.0526534 Test Loss: 0.0597652\n",
      "Validation loss decreased (0.052662 --> 0.052653).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0530570\n",
      "\tspeed: 0.0540s/iter; left time: 729.2703s\n",
      "\titers: 200, epoch: 40 | loss: 0.0543625\n",
      "\tspeed: 0.0265s/iter; left time: 355.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523358 Vali Loss: 0.0526050 Test Loss: 0.0597801\n",
      "Validation loss decreased (0.052653 --> 0.052605).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0526280\n",
      "\tspeed: 0.0538s/iter; left time: 714.3920s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502842\n",
      "\tspeed: 0.0269s/iter; left time: 354.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523034 Vali Loss: 0.0525962 Test Loss: 0.0597211\n",
      "Validation loss decreased (0.052605 --> 0.052596).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0504601\n",
      "\tspeed: 0.0519s/iter; left time: 677.2080s\n",
      "\titers: 200, epoch: 42 | loss: 0.0522450\n",
      "\tspeed: 0.0267s/iter; left time: 346.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522315 Vali Loss: 0.0525362 Test Loss: 0.0597368\n",
      "Validation loss decreased (0.052596 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511504\n",
      "\tspeed: 0.0536s/iter; left time: 687.5830s\n",
      "\titers: 200, epoch: 43 | loss: 0.0488503\n",
      "\tspeed: 0.0271s/iter; left time: 344.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0522311 Vali Loss: 0.0525445 Test Loss: 0.0597039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0522164\n",
      "\tspeed: 0.0529s/iter; left time: 667.3444s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535703\n",
      "\tspeed: 0.0284s/iter; left time: 354.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522388 Vali Loss: 0.0525645 Test Loss: 0.0597437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495954\n",
      "\tspeed: 0.0542s/iter; left time: 671.1270s\n",
      "\titers: 200, epoch: 45 | loss: 0.0532957\n",
      "\tspeed: 0.0266s/iter; left time: 327.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0521830 Vali Loss: 0.0525358 Test Loss: 0.0597217\n",
      "Validation loss decreased (0.052536 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547444\n",
      "\tspeed: 0.0524s/iter; left time: 637.6216s\n",
      "\titers: 200, epoch: 46 | loss: 0.0496140\n",
      "\tspeed: 0.0269s/iter; left time: 324.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521675 Vali Loss: 0.0525339 Test Loss: 0.0597081\n",
      "Validation loss decreased (0.052536 --> 0.052534).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0506746\n",
      "\tspeed: 0.0548s/iter; left time: 654.9451s\n",
      "\titers: 200, epoch: 47 | loss: 0.0512049\n",
      "\tspeed: 0.0264s/iter; left time: 313.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522126 Vali Loss: 0.0525633 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0528504\n",
      "\tspeed: 0.0519s/iter; left time: 608.0480s\n",
      "\titers: 200, epoch: 48 | loss: 0.0515653\n",
      "\tspeed: 0.0264s/iter; left time: 306.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 223 | Train Loss: 0.0522133 Vali Loss: 0.0525448 Test Loss: 0.0597099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0548897\n",
      "\tspeed: 0.0561s/iter; left time: 644.8778s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546200\n",
      "\tspeed: 0.0264s/iter; left time: 301.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521772 Vali Loss: 0.0526311 Test Loss: 0.0597383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0529519\n",
      "\tspeed: 0.0521s/iter; left time: 586.9512s\n",
      "\titers: 200, epoch: 50 | loss: 0.0546627\n",
      "\tspeed: 0.0266s/iter; left time: 297.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0522163 Vali Loss: 0.0525349 Test Loss: 0.0597257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0562787\n",
      "\tspeed: 0.0549s/iter; left time: 606.1844s\n",
      "\titers: 200, epoch: 51 | loss: 0.0525578\n",
      "\tspeed: 0.0263s/iter; left time: 288.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522028 Vali Loss: 0.0525564 Test Loss: 0.0597158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0567538\n",
      "\tspeed: 0.0519s/iter; left time: 561.7646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0543848\n",
      "\tspeed: 0.0270s/iter; left time: 289.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521792 Vali Loss: 0.0525038 Test Loss: 0.0596972\n",
      "Validation loss decreased (0.052534 --> 0.052504).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0541374\n",
      "\tspeed: 0.0558s/iter; left time: 591.2647s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519631\n",
      "\tspeed: 0.0267s/iter; left time: 280.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525617 Test Loss: 0.0597053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0510549\n",
      "\tspeed: 0.0519s/iter; left time: 538.9647s\n",
      "\titers: 200, epoch: 54 | loss: 0.0498644\n",
      "\tspeed: 0.0276s/iter; left time: 283.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0521371 Vali Loss: 0.0525328 Test Loss: 0.0597132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0494472\n",
      "\tspeed: 0.0524s/iter; left time: 532.0514s\n",
      "\titers: 200, epoch: 55 | loss: 0.0542947\n",
      "\tspeed: 0.0265s/iter; left time: 266.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521456 Vali Loss: 0.0525355 Test Loss: 0.0597412\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0560386\n",
      "\tspeed: 0.0519s/iter; left time: 515.1972s\n",
      "\titers: 200, epoch: 56 | loss: 0.0490938\n",
      "\tspeed: 0.0275s/iter; left time: 270.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0521942 Vali Loss: 0.0525360 Test Loss: 0.0596775\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0516569\n",
      "\tspeed: 0.0533s/iter; left time: 517.2387s\n",
      "\titers: 200, epoch: 57 | loss: 0.0514586\n",
      "\tspeed: 0.0265s/iter; left time: 255.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521401 Vali Loss: 0.0525131 Test Loss: 0.0596987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0532000\n",
      "\tspeed: 0.0516s/iter; left time: 490.0769s\n",
      "\titers: 200, epoch: 58 | loss: 0.0498075\n",
      "\tspeed: 0.0280s/iter; left time: 263.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521895 Vali Loss: 0.0524485 Test Loss: 0.0596977\n",
      "Validation loss decreased (0.052504 --> 0.052448).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0487121\n",
      "\tspeed: 0.0521s/iter; left time: 482.9457s\n",
      "\titers: 200, epoch: 59 | loss: 0.0520011\n",
      "\tspeed: 0.0263s/iter; left time: 241.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0520815 Vali Loss: 0.0525329 Test Loss: 0.0597163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0499147\n",
      "\tspeed: 0.0515s/iter; left time: 465.4498s\n",
      "\titers: 200, epoch: 60 | loss: 0.0494750\n",
      "\tspeed: 0.0274s/iter; left time: 245.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525106 Test Loss: 0.0596920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0571291\n",
      "\tspeed: 0.0513s/iter; left time: 452.4577s\n",
      "\titers: 200, epoch: 61 | loss: 0.0492495\n",
      "\tspeed: 0.0267s/iter; left time: 232.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0520912 Vali Loss: 0.0525052 Test Loss: 0.0597109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0515710\n",
      "\tspeed: 0.0543s/iter; left time: 467.0255s\n",
      "\titers: 200, epoch: 62 | loss: 0.0511826\n",
      "\tspeed: 0.0270s/iter; left time: 229.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0521550 Vali Loss: 0.0525164 Test Loss: 0.0596776\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0522274\n",
      "\tspeed: 0.0521s/iter; left time: 436.1762s\n",
      "\titers: 200, epoch: 63 | loss: 0.0504325\n",
      "\tspeed: 0.0266s/iter; left time: 220.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521259 Vali Loss: 0.0525472 Test Loss: 0.0597064\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0529144\n",
      "\tspeed: 0.0533s/iter; left time: 434.1040s\n",
      "\titers: 200, epoch: 64 | loss: 0.0512218\n",
      "\tspeed: 0.0271s/iter; left time: 218.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0521278 Vali Loss: 0.0525165 Test Loss: 0.0596788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0476370\n",
      "\tspeed: 0.0525s/iter; left time: 416.5912s\n",
      "\titers: 200, epoch: 65 | loss: 0.0538774\n",
      "\tspeed: 0.0265s/iter; left time: 207.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521600 Vali Loss: 0.0525308 Test Loss: 0.0596834\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0497716\n",
      "\tspeed: 0.0539s/iter; left time: 415.6925s\n",
      "\titers: 200, epoch: 66 | loss: 0.0530621\n",
      "\tspeed: 0.0270s/iter; left time: 205.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0521674 Vali Loss: 0.0524973 Test Loss: 0.0596974\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499892\n",
      "\tspeed: 0.0513s/iter; left time: 383.7247s\n",
      "\titers: 200, epoch: 67 | loss: 0.0548931\n",
      "\tspeed: 0.0257s/iter; left time: 190.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0520809 Vali Loss: 0.0525215 Test Loss: 0.0597028\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0492604\n",
      "\tspeed: 0.0538s/iter; left time: 390.9405s\n",
      "\titers: 200, epoch: 68 | loss: 0.0565043\n",
      "\tspeed: 0.0269s/iter; left time: 192.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521187 Vali Loss: 0.0525102 Test Loss: 0.0596645\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009862316772341728, rmse:0.09930919855833054, mae:0.0596977174282074, rse:0.2922549545764923\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:15.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265439\n",
      "\tspeed: 0.0400s/iter; left time: 884.7212s\n",
      "\titers: 200, epoch: 1 | loss: 0.1094258\n",
      "\tspeed: 0.0289s/iter; left time: 636.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.1312871 Vali Loss: 0.1025756 Test Loss: 0.1179928\n",
      "Validation loss decreased (inf --> 0.102576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907331\n",
      "\tspeed: 0.0535s/iter; left time: 1170.6404s\n",
      "\titers: 200, epoch: 2 | loss: 0.0867114\n",
      "\tspeed: 0.0266s/iter; left time: 579.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0917246 Vali Loss: 0.0830300 Test Loss: 0.0950562\n",
      "Validation loss decreased (0.102576 --> 0.083030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829765\n",
      "\tspeed: 0.0554s/iter; left time: 1198.8487s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798829\n",
      "\tspeed: 0.0265s/iter; left time: 571.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.0835803 Vali Loss: 0.0801783 Test Loss: 0.0919009\n",
      "Validation loss decreased (0.083030 --> 0.080178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0821674\n",
      "\tspeed: 0.0559s/iter; left time: 1197.5539s\n",
      "\titers: 200, epoch: 4 | loss: 0.0791295\n",
      "\tspeed: 0.0266s/iter; left time: 567.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0809995 Vali Loss: 0.0792776 Test Loss: 0.0911379\n",
      "Validation loss decreased (0.080178 --> 0.079278).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795954\n",
      "\tspeed: 0.0537s/iter; left time: 1138.2492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775064\n",
      "\tspeed: 0.0284s/iter; left time: 600.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0793633 Vali Loss: 0.0774794 Test Loss: 0.0889028\n",
      "Validation loss decreased (0.079278 --> 0.077479).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782045\n",
      "\tspeed: 0.0539s/iter; left time: 1131.9822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778508\n",
      "\tspeed: 0.0279s/iter; left time: 583.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0779934 Vali Loss: 0.0769796 Test Loss: 0.0893228\n",
      "Validation loss decreased (0.077479 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745626\n",
      "\tspeed: 0.0550s/iter; left time: 1143.0104s\n",
      "\titers: 200, epoch: 7 | loss: 0.0762473\n",
      "\tspeed: 0.0267s/iter; left time: 552.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 222 | Train Loss: 0.0769873 Vali Loss: 0.0768754 Test Loss: 0.0889773\n",
      "Validation loss decreased (0.076980 --> 0.076875).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770923\n",
      "\tspeed: 0.0562s/iter; left time: 1155.5033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742162\n",
      "\tspeed: 0.0270s/iter; left time: 552.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0761248 Vali Loss: 0.0765266 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.076875 --> 0.076527).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738049\n",
      "\tspeed: 0.0546s/iter; left time: 1110.0115s\n",
      "\titers: 200, epoch: 9 | loss: 0.0768474\n",
      "\tspeed: 0.0268s/iter; left time: 542.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0753436 Vali Loss: 0.0767246 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751446\n",
      "\tspeed: 0.0528s/iter; left time: 1061.9707s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730382\n",
      "\tspeed: 0.0278s/iter; left time: 556.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0746837 Vali Loss: 0.0759690 Test Loss: 0.0876617\n",
      "Validation loss decreased (0.076527 --> 0.075969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0742704\n",
      "\tspeed: 0.0547s/iter; left time: 1088.1799s\n",
      "\titers: 200, epoch: 11 | loss: 0.0734047\n",
      "\tspeed: 0.0283s/iter; left time: 558.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0740411 Vali Loss: 0.0764244 Test Loss: 0.0878260\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752044\n",
      "\tspeed: 0.0543s/iter; left time: 1066.5819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0752981\n",
      "\tspeed: 0.0268s/iter; left time: 523.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0736232 Vali Loss: 0.0767008 Test Loss: 0.0877754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0746256\n",
      "\tspeed: 0.0564s/iter; left time: 1096.2401s\n",
      "\titers: 200, epoch: 13 | loss: 0.0724523\n",
      "\tspeed: 0.0268s/iter; left time: 518.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0732229 Vali Loss: 0.0764604 Test Loss: 0.0875878\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758144\n",
      "\tspeed: 0.0548s/iter; left time: 1053.8924s\n",
      "\titers: 200, epoch: 14 | loss: 0.0700375\n",
      "\tspeed: 0.0271s/iter; left time: 518.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0728587 Vali Loss: 0.0766782 Test Loss: 0.0877830\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706620\n",
      "\tspeed: 0.0543s/iter; left time: 1030.7524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763170\n",
      "\tspeed: 0.0296s/iter; left time: 559.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0725805 Vali Loss: 0.0769847 Test Loss: 0.0880434\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0747856\n",
      "\tspeed: 0.0537s/iter; left time: 1007.8252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682468\n",
      "\tspeed: 0.0276s/iter; left time: 515.9298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0722561 Vali Loss: 0.0771711 Test Loss: 0.0879989\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0709803\n",
      "\tspeed: 0.0552s/iter; left time: 1024.6003s\n",
      "\titers: 200, epoch: 17 | loss: 0.0700381\n",
      "\tspeed: 0.0273s/iter; left time: 503.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0719847 Vali Loss: 0.0766064 Test Loss: 0.0875815\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710720\n",
      "\tspeed: 0.0554s/iter; left time: 1014.6048s\n",
      "\titers: 200, epoch: 18 | loss: 0.0727012\n",
      "\tspeed: 0.0283s/iter; left time: 516.3897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0717268 Vali Loss: 0.0767684 Test Loss: 0.0876820\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0743508\n",
      "\tspeed: 0.0547s/iter; left time: 989.5579s\n",
      "\titers: 200, epoch: 19 | loss: 0.0689420\n",
      "\tspeed: 0.0275s/iter; left time: 494.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0715864 Vali Loss: 0.0769818 Test Loss: 0.0876034\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733923\n",
      "\tspeed: 0.0529s/iter; left time: 946.8320s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733492\n",
      "\tspeed: 0.0284s/iter; left time: 505.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0712923 Vali Loss: 0.0767117 Test Loss: 0.0876483\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018943050876259804, rmse:0.13763375580310822, mae:0.08766170591115952, rse:0.40432655811309814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1253982\n",
      "\tspeed: 0.0289s/iter; left time: 638.4441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141047\n",
      "\tspeed: 0.0291s/iter; left time: 639.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1341000 Vali Loss: 0.1022669 Test Loss: 0.1178293\n",
      "Validation loss decreased (inf --> 0.102267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0919906\n",
      "\tspeed: 0.0538s/iter; left time: 1177.6209s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841853\n",
      "\tspeed: 0.0281s/iter; left time: 612.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0917120 Vali Loss: 0.0828372 Test Loss: 0.0952215\n",
      "Validation loss decreased (0.102267 --> 0.082837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804817\n",
      "\tspeed: 0.0553s/iter; left time: 1197.2060s\n",
      "\titers: 200, epoch: 3 | loss: 0.0846727\n",
      "\tspeed: 0.0272s/iter; left time: 585.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0834201 Vali Loss: 0.0801691 Test Loss: 0.0913734\n",
      "Validation loss decreased (0.082837 --> 0.080169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814359\n",
      "\tspeed: 0.0549s/iter; left time: 1177.4784s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801016\n",
      "\tspeed: 0.0268s/iter; left time: 570.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0809782 Vali Loss: 0.0786221 Test Loss: 0.0896895\n",
      "Validation loss decreased (0.080169 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773623\n",
      "\tspeed: 0.0557s/iter; left time: 1181.5318s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807470\n",
      "\tspeed: 0.0269s/iter; left time: 567.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0791465 Vali Loss: 0.0776870 Test Loss: 0.0884282\n",
      "Validation loss decreased (0.078622 --> 0.077687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764767\n",
      "\tspeed: 0.0557s/iter; left time: 1168.8908s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776939\n",
      "\tspeed: 0.0288s/iter; left time: 601.9911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0779017 Vali Loss: 0.0774003 Test Loss: 0.0885492\n",
      "Validation loss decreased (0.077687 --> 0.077400).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0810065\n",
      "\tspeed: 0.0550s/iter; left time: 1142.0334s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755886\n",
      "\tspeed: 0.0274s/iter; left time: 566.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0769723 Vali Loss: 0.0767423 Test Loss: 0.0886906\n",
      "Validation loss decreased (0.077400 --> 0.076742).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772487\n",
      "\tspeed: 0.0547s/iter; left time: 1123.3866s\n",
      "\titers: 200, epoch: 8 | loss: 0.0774471\n",
      "\tspeed: 0.0271s/iter; left time: 555.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0761289 Vali Loss: 0.0762937 Test Loss: 0.0885289\n",
      "Validation loss decreased (0.076742 --> 0.076294).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766210\n",
      "\tspeed: 0.0558s/iter; left time: 1134.4816s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749435\n",
      "\tspeed: 0.0269s/iter; left time: 544.2993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0755007 Vali Loss: 0.0760306 Test Loss: 0.0880587\n",
      "Validation loss decreased (0.076294 --> 0.076031).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0746958\n",
      "\tspeed: 0.0559s/iter; left time: 1123.7180s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730645\n",
      "\tspeed: 0.0275s/iter; left time: 550.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0748742 Vali Loss: 0.0756054 Test Loss: 0.0881646\n",
      "Validation loss decreased (0.076031 --> 0.075605).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0716690\n",
      "\tspeed: 0.0534s/iter; left time: 1061.9451s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740186\n",
      "\tspeed: 0.0284s/iter; left time: 561.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0743888 Vali Loss: 0.0763426 Test Loss: 0.0880540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0735602\n",
      "\tspeed: 0.0538s/iter; left time: 1057.8847s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751355\n",
      "\tspeed: 0.0281s/iter; left time: 549.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0739728 Vali Loss: 0.0759540 Test Loss: 0.0883263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0716493\n",
      "\tspeed: 0.0541s/iter; left time: 1051.5080s\n",
      "\titers: 200, epoch: 13 | loss: 0.0773238\n",
      "\tspeed: 0.0267s/iter; left time: 515.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0734238 Vali Loss: 0.0758260 Test Loss: 0.0877946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0718031\n",
      "\tspeed: 0.0554s/iter; left time: 1064.5978s\n",
      "\titers: 200, epoch: 14 | loss: 0.0764564\n",
      "\tspeed: 0.0270s/iter; left time: 516.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0731561 Vali Loss: 0.0764050 Test Loss: 0.0881921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733460\n",
      "\tspeed: 0.0543s/iter; left time: 1032.1122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0726849\n",
      "\tspeed: 0.0273s/iter; left time: 515.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0728082 Vali Loss: 0.0762584 Test Loss: 0.0878794\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713056\n",
      "\tspeed: 0.0524s/iter; left time: 982.8385s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673408\n",
      "\tspeed: 0.0280s/iter; left time: 523.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0725102 Vali Loss: 0.0764893 Test Loss: 0.0877887\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0729090\n",
      "\tspeed: 0.0530s/iter; left time: 982.7459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736606\n",
      "\tspeed: 0.0270s/iter; left time: 498.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0722571 Vali Loss: 0.0764543 Test Loss: 0.0877635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0751263\n",
      "\tspeed: 0.0551s/iter; left time: 1010.3302s\n",
      "\titers: 200, epoch: 18 | loss: 0.0732667\n",
      "\tspeed: 0.0264s/iter; left time: 480.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0720145 Vali Loss: 0.0763173 Test Loss: 0.0881959\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0712821\n",
      "\tspeed: 0.0561s/iter; left time: 1015.0635s\n",
      "\titers: 200, epoch: 19 | loss: 0.0737556\n",
      "\tspeed: 0.0275s/iter; left time: 494.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0717988 Vali Loss: 0.0764204 Test Loss: 0.0878492\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0701951\n",
      "\tspeed: 0.0559s/iter; left time: 1000.3240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730100\n",
      "\tspeed: 0.0292s/iter; left time: 519.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0715539 Vali Loss: 0.0763633 Test Loss: 0.0877618\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01899096928536892, rmse:0.1378077268600464, mae:0.08816458284854889, rse:0.40483760833740234\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:36.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1250355\n",
      "\tspeed: 0.0545s/iter; left time: 1204.7699s\n",
      "\titers: 200, epoch: 1 | loss: 0.1118319\n",
      "\tspeed: 0.0281s/iter; left time: 617.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 222 | Train Loss: 0.1330013 Vali Loss: 0.1052809 Test Loss: 0.1202528\n",
      "Validation loss decreased (inf --> 0.105281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916071\n",
      "\tspeed: 0.0549s/iter; left time: 1200.7462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897428\n",
      "\tspeed: 0.0272s/iter; left time: 591.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0956554 Vali Loss: 0.0879480 Test Loss: 0.1003329\n",
      "Validation loss decreased (0.105281 --> 0.087948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0914022\n",
      "\tspeed: 0.0579s/iter; left time: 1254.3048s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906762\n",
      "\tspeed: 0.0270s/iter; left time: 582.6198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0882966 Vali Loss: 0.0851394 Test Loss: 0.0968764\n",
      "Validation loss decreased (0.087948 --> 0.085139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0883625\n",
      "\tspeed: 0.0564s/iter; left time: 1209.4570s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835357\n",
      "\tspeed: 0.0272s/iter; left time: 580.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0856180 Vali Loss: 0.0840554 Test Loss: 0.0959844\n",
      "Validation loss decreased (0.085139 --> 0.084055).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803824\n",
      "\tspeed: 0.0554s/iter; left time: 1175.9016s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853965\n",
      "\tspeed: 0.0286s/iter; left time: 603.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0838570 Vali Loss: 0.0833926 Test Loss: 0.0951348\n",
      "Validation loss decreased (0.084055 --> 0.083393).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797744\n",
      "\tspeed: 0.0533s/iter; left time: 1118.2968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826659\n",
      "\tspeed: 0.0287s/iter; left time: 600.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0822528 Vali Loss: 0.0830472 Test Loss: 0.0943015\n",
      "Validation loss decreased (0.083393 --> 0.083047).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828038\n",
      "\tspeed: 0.0536s/iter; left time: 1112.2997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825458\n",
      "\tspeed: 0.0272s/iter; left time: 562.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0811129 Vali Loss: 0.0834605 Test Loss: 0.0947691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0849840\n",
      "\tspeed: 0.0559s/iter; left time: 1148.1936s\n",
      "\titers: 200, epoch: 8 | loss: 0.0815625\n",
      "\tspeed: 0.0274s/iter; left time: 559.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0801981 Vali Loss: 0.0829874 Test Loss: 0.0947762\n",
      "Validation loss decreased (0.083047 --> 0.082987).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0781479\n",
      "\tspeed: 0.0549s/iter; left time: 1115.8102s\n",
      "\titers: 200, epoch: 9 | loss: 0.0818327\n",
      "\tspeed: 0.0275s/iter; left time: 555.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0794156 Vali Loss: 0.0829935 Test Loss: 0.0946946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794938\n",
      "\tspeed: 0.0533s/iter; left time: 1071.4783s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774823\n",
      "\tspeed: 0.0288s/iter; left time: 576.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0786948 Vali Loss: 0.0832779 Test Loss: 0.0945250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782731\n",
      "\tspeed: 0.0537s/iter; left time: 1068.0314s\n",
      "\titers: 200, epoch: 11 | loss: 0.0724275\n",
      "\tspeed: 0.0286s/iter; left time: 565.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0781504 Vali Loss: 0.0839142 Test Loss: 0.0944648\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0773756\n",
      "\tspeed: 0.0547s/iter; left time: 1075.9521s\n",
      "\titers: 200, epoch: 12 | loss: 0.0790120\n",
      "\tspeed: 0.0270s/iter; left time: 528.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0776322 Vali Loss: 0.0839175 Test Loss: 0.0947209\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0759633\n",
      "\tspeed: 0.0562s/iter; left time: 1091.6846s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766064\n",
      "\tspeed: 0.0270s/iter; left time: 522.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0772161 Vali Loss: 0.0840464 Test Loss: 0.0945042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0776728\n",
      "\tspeed: 0.0551s/iter; left time: 1058.3260s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716171\n",
      "\tspeed: 0.0279s/iter; left time: 533.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0768410 Vali Loss: 0.0839806 Test Loss: 0.0951329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770181\n",
      "\tspeed: 0.0529s/iter; left time: 1004.0617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740275\n",
      "\tspeed: 0.0280s/iter; left time: 529.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0765493 Vali Loss: 0.0842260 Test Loss: 0.0949700\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0760478\n",
      "\tspeed: 0.0558s/iter; left time: 1047.1025s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732501\n",
      "\tspeed: 0.0275s/iter; left time: 512.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0762004 Vali Loss: 0.0838910 Test Loss: 0.0946376\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0764160\n",
      "\tspeed: 0.0565s/iter; left time: 1047.8797s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790075\n",
      "\tspeed: 0.0273s/iter; left time: 504.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0759705 Vali Loss: 0.0844240 Test Loss: 0.0951427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0746448\n",
      "\tspeed: 0.0552s/iter; left time: 1012.1262s\n",
      "\titers: 200, epoch: 18 | loss: 0.0749086\n",
      "\tspeed: 0.0282s/iter; left time: 513.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0756720 Vali Loss: 0.0843374 Test Loss: 0.0958508\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021302737295627594, rmse:0.14595457911491394, mae:0.0947762206196785, rse:0.42880141735076904\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1263854\n",
      "\tspeed: 0.0309s/iter; left time: 682.9684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1156874\n",
      "\tspeed: 0.0276s/iter; left time: 606.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1330581 Vali Loss: 0.1057428 Test Loss: 0.1209379\n",
      "Validation loss decreased (inf --> 0.105743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964121\n",
      "\tspeed: 0.0557s/iter; left time: 1218.0535s\n",
      "\titers: 200, epoch: 2 | loss: 0.0929709\n",
      "\tspeed: 0.0288s/iter; left time: 628.1006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0959172 Vali Loss: 0.0880870 Test Loss: 0.1012052\n",
      "Validation loss decreased (0.105743 --> 0.088087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0905122\n",
      "\tspeed: 0.0563s/iter; left time: 1219.2802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0891663\n",
      "\tspeed: 0.0291s/iter; left time: 628.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0886181 Vali Loss: 0.0859668 Test Loss: 0.0981919\n",
      "Validation loss decreased (0.088087 --> 0.085967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836552\n",
      "\tspeed: 0.0574s/iter; left time: 1231.0096s\n",
      "\titers: 200, epoch: 4 | loss: 0.0862615\n",
      "\tspeed: 0.0272s/iter; left time: 580.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0859728 Vali Loss: 0.0844449 Test Loss: 0.0958727\n",
      "Validation loss decreased (0.085967 --> 0.084445).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788982\n",
      "\tspeed: 0.0583s/iter; left time: 1237.0605s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824617\n",
      "\tspeed: 0.0274s/iter; left time: 577.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0840970 Vali Loss: 0.0829465 Test Loss: 0.0956325\n",
      "Validation loss decreased (0.084445 --> 0.082947).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843147\n",
      "\tspeed: 0.0562s/iter; left time: 1179.0831s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826297\n",
      "\tspeed: 0.0283s/iter; left time: 591.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0826575 Vali Loss: 0.0833131 Test Loss: 0.0959734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0814445\n",
      "\tspeed: 0.0537s/iter; left time: 1115.2986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826768\n",
      "\tspeed: 0.0289s/iter; left time: 597.0329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0814408 Vali Loss: 0.0830539 Test Loss: 0.0944358\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832167\n",
      "\tspeed: 0.0560s/iter; left time: 1149.8094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797981\n",
      "\tspeed: 0.0274s/iter; left time: 560.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0804610 Vali Loss: 0.0830255 Test Loss: 0.0940806\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808557\n",
      "\tspeed: 0.0570s/iter; left time: 1159.0573s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788599\n",
      "\tspeed: 0.0269s/iter; left time: 544.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0795982 Vali Loss: 0.0830813 Test Loss: 0.0943129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793939\n",
      "\tspeed: 0.0553s/iter; left time: 1112.2653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804769\n",
      "\tspeed: 0.0272s/iter; left time: 543.1426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0789372 Vali Loss: 0.0844544 Test Loss: 0.0946267\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0799205\n",
      "\tspeed: 0.0563s/iter; left time: 1120.1130s\n",
      "\titers: 200, epoch: 11 | loss: 0.0787828\n",
      "\tspeed: 0.0275s/iter; left time: 543.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0783694 Vali Loss: 0.0832267 Test Loss: 0.0936449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794356\n",
      "\tspeed: 0.0537s/iter; left time: 1055.5499s\n",
      "\titers: 200, epoch: 12 | loss: 0.0780849\n",
      "\tspeed: 0.0296s/iter; left time: 579.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0777887 Vali Loss: 0.0834535 Test Loss: 0.0943098\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0778237\n",
      "\tspeed: 0.0542s/iter; left time: 1054.2259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0756606\n",
      "\tspeed: 0.0274s/iter; left time: 529.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0773796 Vali Loss: 0.0838258 Test Loss: 0.0945887\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0753599\n",
      "\tspeed: 0.0570s/iter; left time: 1094.4866s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772503\n",
      "\tspeed: 0.0280s/iter; left time: 534.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0769784 Vali Loss: 0.0844897 Test Loss: 0.0947630\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747140\n",
      "\tspeed: 0.0574s/iter; left time: 1090.5105s\n",
      "\titers: 200, epoch: 15 | loss: 0.0749678\n",
      "\tspeed: 0.0272s/iter; left time: 514.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0766025 Vali Loss: 0.0839631 Test Loss: 0.0942935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021356923505663872, rmse:0.14614008367061615, mae:0.09563247114419937, rse:0.4293464124202728\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:47.34s\n",
      "Intermediate time for ES: 00h:26m:39.90s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0843132\n",
      "\tspeed: 0.0528s/iter; left time: 1172.4564s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826993\n",
      "\tspeed: 0.0273s/iter; left time: 602.6090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0928899 Vali Loss: 0.0809973 Test Loss: 0.0874650\n",
      "Validation loss decreased (inf --> 0.080997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0540009\n",
      "\tspeed: 0.0541s/iter; left time: 1189.4851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0534995\n",
      "\tspeed: 0.0274s/iter; left time: 599.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0554808 Vali Loss: 0.0583653 Test Loss: 0.0612634\n",
      "Validation loss decreased (0.080997 --> 0.058365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0485997\n",
      "\tspeed: 0.0511s/iter; left time: 1112.2014s\n",
      "\titers: 200, epoch: 3 | loss: 0.0472784\n",
      "\tspeed: 0.0265s/iter; left time: 574.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0488961 Vali Loss: 0.0559211 Test Loss: 0.0598280\n",
      "Validation loss decreased (0.058365 --> 0.055921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495222\n",
      "\tspeed: 0.0554s/iter; left time: 1193.9438s\n",
      "\titers: 200, epoch: 4 | loss: 0.0483923\n",
      "\tspeed: 0.0266s/iter; left time: 569.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0470500 Vali Loss: 0.0548929 Test Loss: 0.0586228\n",
      "Validation loss decreased (0.055921 --> 0.054893).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0458255\n",
      "\tspeed: 0.0540s/iter; left time: 1151.1256s\n",
      "\titers: 200, epoch: 5 | loss: 0.0433537\n",
      "\tspeed: 0.0277s/iter; left time: 587.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0458443 Vali Loss: 0.0543292 Test Loss: 0.0576505\n",
      "Validation loss decreased (0.054893 --> 0.054329).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0430197\n",
      "\tspeed: 0.0517s/iter; left time: 1090.1838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0458188\n",
      "\tspeed: 0.0268s/iter; left time: 562.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0450522 Vali Loss: 0.0533698 Test Loss: 0.0574189\n",
      "Validation loss decreased (0.054329 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0436309\n",
      "\tspeed: 0.0533s/iter; left time: 1111.0120s\n",
      "\titers: 200, epoch: 7 | loss: 0.0437001\n",
      "\tspeed: 0.0274s/iter; left time: 568.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0443619 Vali Loss: 0.0534138 Test Loss: 0.0570331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0455056\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6775s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435005\n",
      "\tspeed: 0.0267s/iter; left time: 547.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0438976 Vali Loss: 0.0529732 Test Loss: 0.0568599\n",
      "Validation loss decreased (0.053370 --> 0.052973).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0422169\n",
      "\tspeed: 0.0547s/iter; left time: 1116.5035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0433253\n",
      "\tspeed: 0.0267s/iter; left time: 542.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0434878 Vali Loss: 0.0527236 Test Loss: 0.0561925\n",
      "Validation loss decreased (0.052973 --> 0.052724).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0444294\n",
      "\tspeed: 0.0521s/iter; left time: 1051.5519s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413240\n",
      "\tspeed: 0.0280s/iter; left time: 562.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0431111 Vali Loss: 0.0524848 Test Loss: 0.0564840\n",
      "Validation loss decreased (0.052724 --> 0.052485).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0447372\n",
      "\tspeed: 0.0547s/iter; left time: 1091.9684s\n",
      "\titers: 200, epoch: 11 | loss: 0.0443235\n",
      "\tspeed: 0.0272s/iter; left time: 539.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0428224 Vali Loss: 0.0525295 Test Loss: 0.0564360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0440985\n",
      "\tspeed: 0.0526s/iter; left time: 1039.4210s\n",
      "\titers: 200, epoch: 12 | loss: 0.0438725\n",
      "\tspeed: 0.0282s/iter; left time: 553.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0425661 Vali Loss: 0.0519805 Test Loss: 0.0558995\n",
      "Validation loss decreased (0.052485 --> 0.051981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0421945\n",
      "\tspeed: 0.0540s/iter; left time: 1054.1201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0413549\n",
      "\tspeed: 0.0263s/iter; left time: 511.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0423398 Vali Loss: 0.0518698 Test Loss: 0.0560660\n",
      "Validation loss decreased (0.051981 --> 0.051870).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0388299\n",
      "\tspeed: 0.0537s/iter; left time: 1036.0091s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418125\n",
      "\tspeed: 0.0280s/iter; left time: 538.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0421227 Vali Loss: 0.0520392 Test Loss: 0.0560852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425634\n",
      "\tspeed: 0.0541s/iter; left time: 1032.7221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422673\n",
      "\tspeed: 0.0281s/iter; left time: 532.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0419951 Vali Loss: 0.0516969 Test Loss: 0.0556645\n",
      "Validation loss decreased (0.051870 --> 0.051697).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0408609\n",
      "\tspeed: 0.0569s/iter; left time: 1073.5040s\n",
      "\titers: 200, epoch: 16 | loss: 0.0428541\n",
      "\tspeed: 0.0264s/iter; left time: 495.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0417983 Vali Loss: 0.0516113 Test Loss: 0.0556568\n",
      "Validation loss decreased (0.051697 --> 0.051611).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0433161\n",
      "\tspeed: 0.0539s/iter; left time: 1004.8645s\n",
      "\titers: 200, epoch: 17 | loss: 0.0422571\n",
      "\tspeed: 0.0269s/iter; left time: 497.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0416500 Vali Loss: 0.0514052 Test Loss: 0.0555000\n",
      "Validation loss decreased (0.051611 --> 0.051405).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0451433\n",
      "\tspeed: 0.0543s/iter; left time: 1000.5573s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420981\n",
      "\tspeed: 0.0266s/iter; left time: 487.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0415242 Vali Loss: 0.0517223 Test Loss: 0.0556480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0410448\n",
      "\tspeed: 0.0513s/iter; left time: 932.6076s\n",
      "\titers: 200, epoch: 19 | loss: 0.0432532\n",
      "\tspeed: 0.0282s/iter; left time: 509.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0414556 Vali Loss: 0.0513815 Test Loss: 0.0556669\n",
      "Validation loss decreased (0.051405 --> 0.051381).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0432690\n",
      "\tspeed: 0.0525s/iter; left time: 942.6680s\n",
      "\titers: 200, epoch: 20 | loss: 0.0416686\n",
      "\tspeed: 0.0271s/iter; left time: 484.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0412836 Vali Loss: 0.0514204 Test Loss: 0.0554169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0411735\n",
      "\tspeed: 0.0527s/iter; left time: 935.6835s\n",
      "\titers: 200, epoch: 21 | loss: 0.0403434\n",
      "\tspeed: 0.0275s/iter; left time: 485.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0411740 Vali Loss: 0.0512162 Test Loss: 0.0553809\n",
      "Validation loss decreased (0.051381 --> 0.051216).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410238\n",
      "\tspeed: 0.0536s/iter; left time: 939.4560s\n",
      "\titers: 200, epoch: 22 | loss: 0.0431798\n",
      "\tspeed: 0.0267s/iter; left time: 464.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0411241 Vali Loss: 0.0512545 Test Loss: 0.0554124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0430400\n",
      "\tspeed: 0.0530s/iter; left time: 916.0372s\n",
      "\titers: 200, epoch: 23 | loss: 0.0405390\n",
      "\tspeed: 0.0280s/iter; left time: 481.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0410707 Vali Loss: 0.0511939 Test Loss: 0.0553393\n",
      "Validation loss decreased (0.051216 --> 0.051194).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0420456\n",
      "\tspeed: 0.0517s/iter; left time: 882.1424s\n",
      "\titers: 200, epoch: 24 | loss: 0.0422551\n",
      "\tspeed: 0.0284s/iter; left time: 482.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0409819 Vali Loss: 0.0512411 Test Loss: 0.0552675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0419776\n",
      "\tspeed: 0.0554s/iter; left time: 933.9544s\n",
      "\titers: 200, epoch: 25 | loss: 0.0394762\n",
      "\tspeed: 0.0267s/iter; left time: 447.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0409476 Vali Loss: 0.0512755 Test Loss: 0.0553754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0415562\n",
      "\tspeed: 0.0537s/iter; left time: 893.2178s\n",
      "\titers: 200, epoch: 26 | loss: 0.0394714\n",
      "\tspeed: 0.0278s/iter; left time: 459.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408676 Vali Loss: 0.0510152 Test Loss: 0.0553677\n",
      "Validation loss decreased (0.051194 --> 0.051015).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0425590\n",
      "\tspeed: 0.0547s/iter; left time: 897.5023s\n",
      "\titers: 200, epoch: 27 | loss: 0.0395341\n",
      "\tspeed: 0.0267s/iter; left time: 435.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408256 Vali Loss: 0.0510102 Test Loss: 0.0553386\n",
      "Validation loss decreased (0.051015 --> 0.051010).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0406038\n",
      "\tspeed: 0.0527s/iter; left time: 853.1032s\n",
      "\titers: 200, epoch: 28 | loss: 0.0398112\n",
      "\tspeed: 0.0281s/iter; left time: 452.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0407815 Vali Loss: 0.0511237 Test Loss: 0.0552632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0404074\n",
      "\tspeed: 0.0522s/iter; left time: 832.5402s\n",
      "\titers: 200, epoch: 29 | loss: 0.0439339\n",
      "\tspeed: 0.0265s/iter; left time: 419.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0407395 Vali Loss: 0.0510612 Test Loss: 0.0552591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0436032\n",
      "\tspeed: 0.0548s/iter; left time: 861.7810s\n",
      "\titers: 200, epoch: 30 | loss: 0.0381865\n",
      "\tspeed: 0.0266s/iter; left time: 415.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0406719 Vali Loss: 0.0511291 Test Loss: 0.0551437\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0385469\n",
      "\tspeed: 0.0521s/iter; left time: 808.2974s\n",
      "\titers: 200, epoch: 31 | loss: 0.0384711\n",
      "\tspeed: 0.0265s/iter; left time: 408.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0406380 Vali Loss: 0.0509718 Test Loss: 0.0551497\n",
      "Validation loss decreased (0.051010 --> 0.050972).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0395896\n",
      "\tspeed: 0.0563s/iter; left time: 860.3259s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421091\n",
      "\tspeed: 0.0276s/iter; left time: 419.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0406369 Vali Loss: 0.0510668 Test Loss: 0.0552206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0381517\n",
      "\tspeed: 0.0534s/iter; left time: 805.1249s\n",
      "\titers: 200, epoch: 33 | loss: 0.0395394\n",
      "\tspeed: 0.0287s/iter; left time: 429.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0406346 Vali Loss: 0.0509685 Test Loss: 0.0552220\n",
      "Validation loss decreased (0.050972 --> 0.050968).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0390877\n",
      "\tspeed: 0.0529s/iter; left time: 784.9570s\n",
      "\titers: 200, epoch: 34 | loss: 0.0426558\n",
      "\tspeed: 0.0271s/iter; left time: 399.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0406084 Vali Loss: 0.0509817 Test Loss: 0.0551818\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0396101\n",
      "\tspeed: 0.0550s/iter; left time: 804.7154s\n",
      "\titers: 200, epoch: 35 | loss: 0.0452002\n",
      "\tspeed: 0.0268s/iter; left time: 388.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0405750 Vali Loss: 0.0510232 Test Loss: 0.0551961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0396727\n",
      "\tspeed: 0.0535s/iter; left time: 770.7884s\n",
      "\titers: 200, epoch: 36 | loss: 0.0376845\n",
      "\tspeed: 0.0274s/iter; left time: 391.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0405536 Vali Loss: 0.0509294 Test Loss: 0.0551972\n",
      "Validation loss decreased (0.050968 --> 0.050929).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0383235\n",
      "\tspeed: 0.0553s/iter; left time: 784.1062s\n",
      "\titers: 200, epoch: 37 | loss: 0.0379358\n",
      "\tspeed: 0.0283s/iter; left time: 398.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0405320 Vali Loss: 0.0509095 Test Loss: 0.0551600\n",
      "Validation loss decreased (0.050929 --> 0.050909).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0440550\n",
      "\tspeed: 0.0517s/iter; left time: 721.2223s\n",
      "\titers: 200, epoch: 38 | loss: 0.0409360\n",
      "\tspeed: 0.0271s/iter; left time: 375.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0405302 Vali Loss: 0.0509632 Test Loss: 0.0551483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0424551\n",
      "\tspeed: 0.0544s/iter; left time: 746.2891s\n",
      "\titers: 200, epoch: 39 | loss: 0.0407349\n",
      "\tspeed: 0.0268s/iter; left time: 364.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404400 Vali Loss: 0.0509475 Test Loss: 0.0551755\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0399665\n",
      "\tspeed: 0.0539s/iter; left time: 727.9944s\n",
      "\titers: 200, epoch: 40 | loss: 0.0386363\n",
      "\tspeed: 0.0276s/iter; left time: 370.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0405515 Vali Loss: 0.0509822 Test Loss: 0.0551663\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0414642\n",
      "\tspeed: 0.0536s/iter; left time: 711.4697s\n",
      "\titers: 200, epoch: 41 | loss: 0.0414216\n",
      "\tspeed: 0.0270s/iter; left time: 356.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0405032 Vali Loss: 0.0509070 Test Loss: 0.0551836\n",
      "Validation loss decreased (0.050909 --> 0.050907).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0396513\n",
      "\tspeed: 0.0547s/iter; left time: 714.2081s\n",
      "\titers: 200, epoch: 42 | loss: 0.0407175\n",
      "\tspeed: 0.0273s/iter; left time: 354.3178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0404501 Vali Loss: 0.0509050 Test Loss: 0.0551621\n",
      "Validation loss decreased (0.050907 --> 0.050905).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0419802\n",
      "\tspeed: 0.0522s/iter; left time: 669.5941s\n",
      "\titers: 200, epoch: 43 | loss: 0.0435936\n",
      "\tspeed: 0.0268s/iter; left time: 341.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0404785 Vali Loss: 0.0510068 Test Loss: 0.0551562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0377414\n",
      "\tspeed: 0.0557s/iter; left time: 702.0427s\n",
      "\titers: 200, epoch: 44 | loss: 0.0404162\n",
      "\tspeed: 0.0268s/iter; left time: 335.1467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0404870 Vali Loss: 0.0509230 Test Loss: 0.0551347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0397641\n",
      "\tspeed: 0.0534s/iter; left time: 661.6692s\n",
      "\titers: 200, epoch: 45 | loss: 0.0363073\n",
      "\tspeed: 0.0280s/iter; left time: 343.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0404352 Vali Loss: 0.0509129 Test Loss: 0.0551449\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0382217\n",
      "\tspeed: 0.0512s/iter; left time: 622.3970s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383492\n",
      "\tspeed: 0.0275s/iter; left time: 331.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0404233 Vali Loss: 0.0509525 Test Loss: 0.0551411\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0375880\n",
      "\tspeed: 0.0539s/iter; left time: 644.2997s\n",
      "\titers: 200, epoch: 47 | loss: 0.0388351\n",
      "\tspeed: 0.0276s/iter; left time: 326.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404278 Vali Loss: 0.0509438 Test Loss: 0.0551423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0394593\n",
      "\tspeed: 0.0537s/iter; left time: 628.9858s\n",
      "\titers: 200, epoch: 48 | loss: 0.0419493\n",
      "\tspeed: 0.0263s/iter; left time: 305.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0404258 Vali Loss: 0.0509123 Test Loss: 0.0551539\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0434436\n",
      "\tspeed: 0.0508s/iter; left time: 584.4281s\n",
      "\titers: 200, epoch: 49 | loss: 0.0394077\n",
      "\tspeed: 0.0265s/iter; left time: 301.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404041 Vali Loss: 0.0509195 Test Loss: 0.0551415\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0392535\n",
      "\tspeed: 0.0513s/iter; left time: 577.8123s\n",
      "\titers: 200, epoch: 50 | loss: 0.0380202\n",
      "\tspeed: 0.0285s/iter; left time: 318.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404302 Vali Loss: 0.0509391 Test Loss: 0.0551524\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440110\n",
      "\tspeed: 0.0531s/iter; left time: 586.7326s\n",
      "\titers: 200, epoch: 51 | loss: 0.0394740\n",
      "\tspeed: 0.0266s/iter; left time: 291.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0404130 Vali Loss: 0.0508948 Test Loss: 0.0551422\n",
      "Validation loss decreased (0.050905 --> 0.050895).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0448568\n",
      "\tspeed: 0.0530s/iter; left time: 573.4647s\n",
      "\titers: 200, epoch: 52 | loss: 0.0377624\n",
      "\tspeed: 0.0274s/iter; left time: 294.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403924 Vali Loss: 0.0509185 Test Loss: 0.0551236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0432277\n",
      "\tspeed: 0.0544s/iter; left time: 577.3631s\n",
      "\titers: 200, epoch: 53 | loss: 0.0382022\n",
      "\tspeed: 0.0266s/iter; left time: 278.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0403406 Vali Loss: 0.0509090 Test Loss: 0.0551386\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0392583\n",
      "\tspeed: 0.0539s/iter; left time: 559.1625s\n",
      "\titers: 200, epoch: 54 | loss: 0.0379959\n",
      "\tspeed: 0.0282s/iter; left time: 289.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0403821 Vali Loss: 0.0509590 Test Loss: 0.0551205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0424123\n",
      "\tspeed: 0.0516s/iter; left time: 524.5061s\n",
      "\titers: 200, epoch: 55 | loss: 0.0390990\n",
      "\tspeed: 0.0277s/iter; left time: 278.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404026 Vali Loss: 0.0508852 Test Loss: 0.0551308\n",
      "Validation loss decreased (0.050895 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0409146\n",
      "\tspeed: 0.0545s/iter; left time: 541.4831s\n",
      "\titers: 200, epoch: 56 | loss: 0.0394938\n",
      "\tspeed: 0.0264s/iter; left time: 259.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403666 Vali Loss: 0.0509080 Test Loss: 0.0551149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0383278\n",
      "\tspeed: 0.0563s/iter; left time: 546.3756s\n",
      "\titers: 200, epoch: 57 | loss: 0.0380404\n",
      "\tspeed: 0.0269s/iter; left time: 258.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0403914 Vali Loss: 0.0508964 Test Loss: 0.0551263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0374241\n",
      "\tspeed: 0.0562s/iter; left time: 533.1406s\n",
      "\titers: 200, epoch: 58 | loss: 0.0384800\n",
      "\tspeed: 0.0266s/iter; left time: 250.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0404106 Vali Loss: 0.0509074 Test Loss: 0.0551193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0425259\n",
      "\tspeed: 0.0510s/iter; left time: 472.3618s\n",
      "\titers: 200, epoch: 59 | loss: 0.0383911\n",
      "\tspeed: 0.0300s/iter; left time: 275.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0403796 Vali Loss: 0.0508939 Test Loss: 0.0551248\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0411102\n",
      "\tspeed: 0.0529s/iter; left time: 478.6612s\n",
      "\titers: 200, epoch: 60 | loss: 0.0403990\n",
      "\tspeed: 0.0263s/iter; left time: 235.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0403918 Vali Loss: 0.0508964 Test Loss: 0.0551259\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0418877\n",
      "\tspeed: 0.0570s/iter; left time: 502.4903s\n",
      "\titers: 200, epoch: 61 | loss: 0.0403620\n",
      "\tspeed: 0.0272s/iter; left time: 236.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0403829 Vali Loss: 0.0509169 Test Loss: 0.0551298\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394381\n",
      "\tspeed: 0.0554s/iter; left time: 476.7332s\n",
      "\titers: 200, epoch: 62 | loss: 0.0413030\n",
      "\tspeed: 0.0270s/iter; left time: 229.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403858 Vali Loss: 0.0509289 Test Loss: 0.0551388\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0361456\n",
      "\tspeed: 0.0547s/iter; left time: 458.4112s\n",
      "\titers: 200, epoch: 63 | loss: 0.0410837\n",
      "\tspeed: 0.0283s/iter; left time: 234.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403752 Vali Loss: 0.0509146 Test Loss: 0.0551340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0410504\n",
      "\tspeed: 0.0519s/iter; left time: 422.6970s\n",
      "\titers: 200, epoch: 64 | loss: 0.0393771\n",
      "\tspeed: 0.0273s/iter; left time: 220.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0403604 Vali Loss: 0.0509011 Test Loss: 0.0551318\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0404327\n",
      "\tspeed: 0.0566s/iter; left time: 448.6071s\n",
      "\titers: 200, epoch: 65 | loss: 0.0426011\n",
      "\tspeed: 0.0267s/iter; left time: 209.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0403942 Vali Loss: 0.0509536 Test Loss: 0.0551359\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010024277493357658, rmse:0.10012131184339523, mae:0.055130843073129654, rse:0.38626524806022644\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0906341\n",
      "\tspeed: 0.0301s/iter; left time: 667.8155s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826328\n",
      "\tspeed: 0.0263s/iter; left time: 582.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0938272 Vali Loss: 0.0805418 Test Loss: 0.0871429\n",
      "Validation loss decreased (inf --> 0.080542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0551709\n",
      "\tspeed: 0.0576s/iter; left time: 1265.1429s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524309\n",
      "\tspeed: 0.0271s/iter; left time: 592.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0558666 Vali Loss: 0.0584886 Test Loss: 0.0616178\n",
      "Validation loss decreased (0.080542 --> 0.058489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486506\n",
      "\tspeed: 0.0536s/iter; left time: 1166.1015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0469318\n",
      "\tspeed: 0.0284s/iter; left time: 615.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0488140 Vali Loss: 0.0560299 Test Loss: 0.0600615\n",
      "Validation loss decreased (0.058489 --> 0.056030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0490200\n",
      "\tspeed: 0.0527s/iter; left time: 1134.7966s\n",
      "\titers: 200, epoch: 4 | loss: 0.0490843\n",
      "\tspeed: 0.0289s/iter; left time: 619.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0470409 Vali Loss: 0.0548938 Test Loss: 0.0585970\n",
      "Validation loss decreased (0.056030 --> 0.054894).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0493169\n",
      "\tspeed: 0.0564s/iter; left time: 1202.6886s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423416\n",
      "\tspeed: 0.0264s/iter; left time: 560.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0458134 Vali Loss: 0.0537671 Test Loss: 0.0576985\n",
      "Validation loss decreased (0.054894 --> 0.053767).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0481958\n",
      "\tspeed: 0.0571s/iter; left time: 1204.8272s\n",
      "\titers: 200, epoch: 6 | loss: 0.0447032\n",
      "\tspeed: 0.0268s/iter; left time: 561.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0449244 Vali Loss: 0.0531660 Test Loss: 0.0571905\n",
      "Validation loss decreased (0.053767 --> 0.053166).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0444714\n",
      "\tspeed: 0.0541s/iter; left time: 1128.9689s\n",
      "\titers: 200, epoch: 7 | loss: 0.0447756\n",
      "\tspeed: 0.0277s/iter; left time: 575.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0443288 Vali Loss: 0.0529909 Test Loss: 0.0570281\n",
      "Validation loss decreased (0.053166 --> 0.052991).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460659\n",
      "\tspeed: 0.0543s/iter; left time: 1119.9415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0454672\n",
      "\tspeed: 0.0291s/iter; left time: 598.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0438346 Vali Loss: 0.0530107 Test Loss: 0.0570792\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458995\n",
      "\tspeed: 0.0516s/iter; left time: 1054.2843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0426223\n",
      "\tspeed: 0.0270s/iter; left time: 548.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0434338 Vali Loss: 0.0526153 Test Loss: 0.0565650\n",
      "Validation loss decreased (0.052991 --> 0.052615).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0406584\n",
      "\tspeed: 0.0555s/iter; left time: 1121.0964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0479837\n",
      "\tspeed: 0.0265s/iter; left time: 533.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0430610 Vali Loss: 0.0523429 Test Loss: 0.0565098\n",
      "Validation loss decreased (0.052615 --> 0.052343).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441144\n",
      "\tspeed: 0.0565s/iter; left time: 1127.7538s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424211\n",
      "\tspeed: 0.0273s/iter; left time: 543.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0427796 Vali Loss: 0.0520273 Test Loss: 0.0561341\n",
      "Validation loss decreased (0.052343 --> 0.052027).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0395642\n",
      "\tspeed: 0.0539s/iter; left time: 1064.6384s\n",
      "\titers: 200, epoch: 12 | loss: 0.0417812\n",
      "\tspeed: 0.0275s/iter; left time: 541.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0424066 Vali Loss: 0.0522500 Test Loss: 0.0566746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465006\n",
      "\tspeed: 0.0542s/iter; left time: 1057.6991s\n",
      "\titers: 200, epoch: 13 | loss: 0.0409592\n",
      "\tspeed: 0.0280s/iter; left time: 543.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0422092 Vali Loss: 0.0518321 Test Loss: 0.0560570\n",
      "Validation loss decreased (0.052027 --> 0.051832).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417979\n",
      "\tspeed: 0.0529s/iter; left time: 1020.2572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418281\n",
      "\tspeed: 0.0271s/iter; left time: 520.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0420007 Vali Loss: 0.0518557 Test Loss: 0.0559012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0409619\n",
      "\tspeed: 0.0591s/iter; left time: 1127.5658s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422560\n",
      "\tspeed: 0.0264s/iter; left time: 501.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0418025 Vali Loss: 0.0515299 Test Loss: 0.0558530\n",
      "Validation loss decreased (0.051832 --> 0.051530).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0418751\n",
      "\tspeed: 0.0557s/iter; left time: 1050.5298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0431925\n",
      "\tspeed: 0.0278s/iter; left time: 521.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0416322 Vali Loss: 0.0516220 Test Loss: 0.0559839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0416599\n",
      "\tspeed: 0.0536s/iter; left time: 998.4634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0385930\n",
      "\tspeed: 0.0288s/iter; left time: 533.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0415159 Vali Loss: 0.0515925 Test Loss: 0.0557896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0403570\n",
      "\tspeed: 0.0546s/iter; left time: 1005.0983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0396579\n",
      "\tspeed: 0.0271s/iter; left time: 496.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0413374 Vali Loss: 0.0514856 Test Loss: 0.0555889\n",
      "Validation loss decreased (0.051530 --> 0.051486).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426625\n",
      "\tspeed: 0.0550s/iter; left time: 999.9825s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415856\n",
      "\tspeed: 0.0267s/iter; left time: 483.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0412477 Vali Loss: 0.0512750 Test Loss: 0.0556268\n",
      "Validation loss decreased (0.051486 --> 0.051275).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0406603\n",
      "\tspeed: 0.0572s/iter; left time: 1027.6752s\n",
      "\titers: 200, epoch: 20 | loss: 0.0444297\n",
      "\tspeed: 0.0266s/iter; left time: 475.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0412201 Vali Loss: 0.0512715 Test Loss: 0.0556442\n",
      "Validation loss decreased (0.051275 --> 0.051271).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0446360\n",
      "\tspeed: 0.0541s/iter; left time: 959.2371s\n",
      "\titers: 200, epoch: 21 | loss: 0.0451247\n",
      "\tspeed: 0.0288s/iter; left time: 508.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0410562 Vali Loss: 0.0510677 Test Loss: 0.0556257\n",
      "Validation loss decreased (0.051271 --> 0.051068).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0413175\n",
      "\tspeed: 0.0525s/iter; left time: 920.2055s\n",
      "\titers: 200, epoch: 22 | loss: 0.0406883\n",
      "\tspeed: 0.0282s/iter; left time: 491.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0409632 Vali Loss: 0.0511050 Test Loss: 0.0554848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0413638\n",
      "\tspeed: 0.0532s/iter; left time: 920.3822s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385806\n",
      "\tspeed: 0.0282s/iter; left time: 485.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0408717 Vali Loss: 0.0511044 Test Loss: 0.0554944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0418123\n",
      "\tspeed: 0.0560s/iter; left time: 956.3025s\n",
      "\titers: 200, epoch: 24 | loss: 0.0407323\n",
      "\tspeed: 0.0265s/iter; left time: 450.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0408074 Vali Loss: 0.0511794 Test Loss: 0.0554869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0389306\n",
      "\tspeed: 0.0548s/iter; left time: 924.0469s\n",
      "\titers: 200, epoch: 25 | loss: 0.0398802\n",
      "\tspeed: 0.0273s/iter; left time: 457.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0407822 Vali Loss: 0.0511632 Test Loss: 0.0554472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0406251\n",
      "\tspeed: 0.0514s/iter; left time: 854.9484s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404109\n",
      "\tspeed: 0.0297s/iter; left time: 491.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0406947 Vali Loss: 0.0510870 Test Loss: 0.0554563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0426260\n",
      "\tspeed: 0.0533s/iter; left time: 873.7834s\n",
      "\titers: 200, epoch: 27 | loss: 0.0422118\n",
      "\tspeed: 0.0264s/iter; left time: 430.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0406440 Vali Loss: 0.0510169 Test Loss: 0.0554277\n",
      "Validation loss decreased (0.051068 --> 0.051017).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0433261\n",
      "\tspeed: 0.0584s/iter; left time: 944.4422s\n",
      "\titers: 200, epoch: 28 | loss: 0.0414303\n",
      "\tspeed: 0.0272s/iter; left time: 438.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0406054 Vali Loss: 0.0510836 Test Loss: 0.0553864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0386375\n",
      "\tspeed: 0.0533s/iter; left time: 849.9980s\n",
      "\titers: 200, epoch: 29 | loss: 0.0398392\n",
      "\tspeed: 0.0267s/iter; left time: 422.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0405403 Vali Loss: 0.0510816 Test Loss: 0.0554030\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0395849\n",
      "\tspeed: 0.0570s/iter; left time: 897.0832s\n",
      "\titers: 200, epoch: 30 | loss: 0.0434685\n",
      "\tspeed: 0.0287s/iter; left time: 447.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0405472 Vali Loss: 0.0509714 Test Loss: 0.0553758\n",
      "Validation loss decreased (0.051017 --> 0.050971).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0404055\n",
      "\tspeed: 0.0524s/iter; left time: 812.5939s\n",
      "\titers: 200, epoch: 31 | loss: 0.0423716\n",
      "\tspeed: 0.0274s/iter; left time: 422.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0404917 Vali Loss: 0.0509903 Test Loss: 0.0553255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0410218\n",
      "\tspeed: 0.0558s/iter; left time: 853.0859s\n",
      "\titers: 200, epoch: 32 | loss: 0.0379313\n",
      "\tspeed: 0.0265s/iter; left time: 403.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0404833 Vali Loss: 0.0509146 Test Loss: 0.0553534\n",
      "Validation loss decreased (0.050971 --> 0.050915).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0403348\n",
      "\tspeed: 0.0554s/iter; left time: 834.4094s\n",
      "\titers: 200, epoch: 33 | loss: 0.0399958\n",
      "\tspeed: 0.0270s/iter; left time: 404.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0404073 Vali Loss: 0.0508854 Test Loss: 0.0553828\n",
      "Validation loss decreased (0.050915 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0402859\n",
      "\tspeed: 0.0528s/iter; left time: 784.3565s\n",
      "\titers: 200, epoch: 34 | loss: 0.0393198\n",
      "\tspeed: 0.0278s/iter; left time: 410.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404330 Vali Loss: 0.0509054 Test Loss: 0.0553213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0399488\n",
      "\tspeed: 0.0524s/iter; left time: 766.7168s\n",
      "\titers: 200, epoch: 35 | loss: 0.0390085\n",
      "\tspeed: 0.0271s/iter; left time: 392.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403941 Vali Loss: 0.0509035 Test Loss: 0.0553123\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0437253\n",
      "\tspeed: 0.0543s/iter; left time: 781.3251s\n",
      "\titers: 200, epoch: 36 | loss: 0.0389777\n",
      "\tspeed: 0.0265s/iter; left time: 379.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0403536 Vali Loss: 0.0508838 Test Loss: 0.0553374\n",
      "Validation loss decreased (0.050885 --> 0.050884).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0410785\n",
      "\tspeed: 0.0546s/iter; left time: 773.2454s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399544\n",
      "\tspeed: 0.0268s/iter; left time: 377.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0403515 Vali Loss: 0.0509292 Test Loss: 0.0553296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0391543\n",
      "\tspeed: 0.0525s/iter; left time: 732.7616s\n",
      "\titers: 200, epoch: 38 | loss: 0.0413559\n",
      "\tspeed: 0.0273s/iter; left time: 378.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0403439 Vali Loss: 0.0508500 Test Loss: 0.0553205\n",
      "Validation loss decreased (0.050884 --> 0.050850).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0417169\n",
      "\tspeed: 0.0569s/iter; left time: 780.8474s\n",
      "\titers: 200, epoch: 39 | loss: 0.0405512\n",
      "\tspeed: 0.0267s/iter; left time: 363.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0403442 Vali Loss: 0.0508796 Test Loss: 0.0553248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0447844\n",
      "\tspeed: 0.0542s/iter; left time: 731.6767s\n",
      "\titers: 200, epoch: 40 | loss: 0.0395523\n",
      "\tspeed: 0.0269s/iter; left time: 360.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0403389 Vali Loss: 0.0507638 Test Loss: 0.0552910\n",
      "Validation loss decreased (0.050850 --> 0.050764).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0417288\n",
      "\tspeed: 0.0538s/iter; left time: 714.9267s\n",
      "\titers: 200, epoch: 41 | loss: 0.0412049\n",
      "\tspeed: 0.0273s/iter; left time: 359.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0403560 Vali Loss: 0.0508435 Test Loss: 0.0553101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0378692\n",
      "\tspeed: 0.0529s/iter; left time: 690.6556s\n",
      "\titers: 200, epoch: 42 | loss: 0.0401617\n",
      "\tspeed: 0.0272s/iter; left time: 351.9640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403200 Vali Loss: 0.0508418 Test Loss: 0.0553548\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0384229\n",
      "\tspeed: 0.0534s/iter; left time: 685.2592s\n",
      "\titers: 200, epoch: 43 | loss: 0.0370391\n",
      "\tspeed: 0.0282s/iter; left time: 359.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0402477 Vali Loss: 0.0508064 Test Loss: 0.0553414\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0432439\n",
      "\tspeed: 0.0566s/iter; left time: 713.6192s\n",
      "\titers: 200, epoch: 44 | loss: 0.0400607\n",
      "\tspeed: 0.0265s/iter; left time: 331.6480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0402985 Vali Loss: 0.0508538 Test Loss: 0.0553522\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0387721\n",
      "\tspeed: 0.0530s/iter; left time: 656.5277s\n",
      "\titers: 200, epoch: 45 | loss: 0.0426491\n",
      "\tspeed: 0.0284s/iter; left time: 349.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0402648 Vali Loss: 0.0508805 Test Loss: 0.0553688\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0391906\n",
      "\tspeed: 0.0538s/iter; left time: 654.6966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383839\n",
      "\tspeed: 0.0274s/iter; left time: 331.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0401979 Vali Loss: 0.0508143 Test Loss: 0.0553381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0380304\n",
      "\tspeed: 0.0531s/iter; left time: 634.4437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0415097\n",
      "\tspeed: 0.0281s/iter; left time: 332.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0402226 Vali Loss: 0.0507866 Test Loss: 0.0553593\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0386002\n",
      "\tspeed: 0.0554s/iter; left time: 649.1937s\n",
      "\titers: 200, epoch: 48 | loss: 0.0388776\n",
      "\tspeed: 0.0274s/iter; left time: 318.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0401984 Vali Loss: 0.0508578 Test Loss: 0.0553353\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0421254\n",
      "\tspeed: 0.0550s/iter; left time: 632.6324s\n",
      "\titers: 200, epoch: 49 | loss: 0.0385936\n",
      "\tspeed: 0.0279s/iter; left time: 318.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0402498 Vali Loss: 0.0508001 Test Loss: 0.0553192\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0405090\n",
      "\tspeed: 0.0519s/iter; left time: 584.6391s\n",
      "\titers: 200, epoch: 50 | loss: 0.0411080\n",
      "\tspeed: 0.0275s/iter; left time: 307.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0402468 Vali Loss: 0.0508563 Test Loss: 0.0553059\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010074619203805923, rmse:0.10037240386009216, mae:0.055291011929512024, rse:0.3872339427471161\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:47.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0946442\n",
      "\tspeed: 0.0544s/iter; left time: 1201.8179s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807172\n",
      "\tspeed: 0.0280s/iter; left time: 615.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.0976983 Vali Loss: 0.0885321 Test Loss: 0.0971842\n",
      "Validation loss decreased (inf --> 0.088532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0547s/iter; left time: 1197.6152s\n",
      "\titers: 200, epoch: 2 | loss: 0.0639201\n",
      "\tspeed: 0.0271s/iter; left time: 589.6803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0691408 Vali Loss: 0.0740071 Test Loss: 0.0823792\n",
      "Validation loss decreased (0.088532 --> 0.074007).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0629653\n",
      "\tspeed: 0.0547s/iter; left time: 1183.5931s\n",
      "\titers: 200, epoch: 3 | loss: 0.0609960\n",
      "\tspeed: 0.0295s/iter; left time: 635.9466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0631580 Vali Loss: 0.0724165 Test Loss: 0.0810770\n",
      "Validation loss decreased (0.074007 --> 0.072416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0591992\n",
      "\tspeed: 0.0530s/iter; left time: 1135.7080s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622611\n",
      "\tspeed: 0.0286s/iter; left time: 609.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0616025 Vali Loss: 0.0718696 Test Loss: 0.0810709\n",
      "Validation loss decreased (0.072416 --> 0.071870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633924\n",
      "\tspeed: 0.0580s/iter; left time: 1231.3352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584497\n",
      "\tspeed: 0.0269s/iter; left time: 567.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0605206 Vali Loss: 0.0706461 Test Loss: 0.0808803\n",
      "Validation loss decreased (0.071870 --> 0.070646).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0617116\n",
      "\tspeed: 0.0574s/iter; left time: 1203.8881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603344\n",
      "\tspeed: 0.0279s/iter; left time: 581.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0597658 Vali Loss: 0.0708851 Test Loss: 0.0804708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572835\n",
      "\tspeed: 0.0551s/iter; left time: 1143.7419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595429\n",
      "\tspeed: 0.0276s/iter; left time: 569.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0592192 Vali Loss: 0.0702724 Test Loss: 0.0811357\n",
      "Validation loss decreased (0.070646 --> 0.070272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0600042\n",
      "\tspeed: 0.0542s/iter; left time: 1114.4691s\n",
      "\titers: 200, epoch: 8 | loss: 0.0576544\n",
      "\tspeed: 0.0292s/iter; left time: 597.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0586930 Vali Loss: 0.0699404 Test Loss: 0.0809467\n",
      "Validation loss decreased (0.070272 --> 0.069940).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0586163\n",
      "\tspeed: 0.0551s/iter; left time: 1119.9328s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577755\n",
      "\tspeed: 0.0277s/iter; left time: 560.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0582909 Vali Loss: 0.0698899 Test Loss: 0.0808146\n",
      "Validation loss decreased (0.069940 --> 0.069890).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633654\n",
      "\tspeed: 0.0606s/iter; left time: 1218.7369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593716\n",
      "\tspeed: 0.0269s/iter; left time: 537.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0578296 Vali Loss: 0.0697316 Test Loss: 0.0806795\n",
      "Validation loss decreased (0.069890 --> 0.069732).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0568299\n",
      "\tspeed: 0.0564s/iter; left time: 1121.0738s\n",
      "\titers: 200, epoch: 11 | loss: 0.0571765\n",
      "\tspeed: 0.0281s/iter; left time: 556.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 222 | Train Loss: 0.0575434 Vali Loss: 0.0695331 Test Loss: 0.0808393\n",
      "Validation loss decreased (0.069732 --> 0.069533).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0532095\n",
      "\tspeed: 0.0540s/iter; left time: 1061.8762s\n",
      "\titers: 200, epoch: 12 | loss: 0.0552783\n",
      "\tspeed: 0.0286s/iter; left time: 559.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0572077 Vali Loss: 0.0695406 Test Loss: 0.0809313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564464\n",
      "\tspeed: 0.0544s/iter; left time: 1058.2301s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570819\n",
      "\tspeed: 0.0273s/iter; left time: 527.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0568615 Vali Loss: 0.0693137 Test Loss: 0.0810390\n",
      "Validation loss decreased (0.069533 --> 0.069314).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0539912\n",
      "\tspeed: 0.0568s/iter; left time: 1090.8423s\n",
      "\titers: 200, epoch: 14 | loss: 0.0568080\n",
      "\tspeed: 0.0266s/iter; left time: 507.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0565855 Vali Loss: 0.0695845 Test Loss: 0.0809268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0593582\n",
      "\tspeed: 0.0516s/iter; left time: 979.2710s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566474\n",
      "\tspeed: 0.0271s/iter; left time: 511.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0563461 Vali Loss: 0.0693047 Test Loss: 0.0811887\n",
      "Validation loss decreased (0.069314 --> 0.069305).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0594476\n",
      "\tspeed: 0.0555s/iter; left time: 1040.9186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0533540\n",
      "\tspeed: 0.0293s/iter; left time: 546.7886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0560892 Vali Loss: 0.0693481 Test Loss: 0.0814752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0553667\n",
      "\tspeed: 0.0528s/iter; left time: 979.3788s\n",
      "\titers: 200, epoch: 17 | loss: 0.0557630\n",
      "\tspeed: 0.0302s/iter; left time: 556.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.0558328 Vali Loss: 0.0694838 Test Loss: 0.0814889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601683\n",
      "\tspeed: 0.0535s/iter; left time: 980.2696s\n",
      "\titers: 200, epoch: 18 | loss: 0.0555220\n",
      "\tspeed: 0.0278s/iter; left time: 506.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0556501 Vali Loss: 0.0696565 Test Loss: 0.0816849\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0553780\n",
      "\tspeed: 0.0552s/iter; left time: 999.6674s\n",
      "\titers: 200, epoch: 19 | loss: 0.0562586\n",
      "\tspeed: 0.0275s/iter; left time: 495.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0554732 Vali Loss: 0.0695040 Test Loss: 0.0815747\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0575418\n",
      "\tspeed: 0.0550s/iter; left time: 983.9110s\n",
      "\titers: 200, epoch: 20 | loss: 0.0529493\n",
      "\tspeed: 0.0278s/iter; left time: 494.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0552923 Vali Loss: 0.0695789 Test Loss: 0.0819936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0552874\n",
      "\tspeed: 0.0537s/iter; left time: 949.1304s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571044\n",
      "\tspeed: 0.0302s/iter; left time: 530.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0551806 Vali Loss: 0.0696505 Test Loss: 0.0819064\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523697\n",
      "\tspeed: 0.0560s/iter; left time: 975.7897s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539634\n",
      "\tspeed: 0.0272s/iter; left time: 471.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0550097 Vali Loss: 0.0697481 Test Loss: 0.0818706\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570134\n",
      "\tspeed: 0.0566s/iter; left time: 973.8350s\n",
      "\titers: 200, epoch: 23 | loss: 0.0503240\n",
      "\tspeed: 0.0277s/iter; left time: 473.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0549191 Vali Loss: 0.0695426 Test Loss: 0.0819507\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0564718\n",
      "\tspeed: 0.0544s/iter; left time: 924.8548s\n",
      "\titers: 200, epoch: 24 | loss: 0.0560874\n",
      "\tspeed: 0.0284s/iter; left time: 479.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0547920 Vali Loss: 0.0694288 Test Loss: 0.0827027\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0538619\n",
      "\tspeed: 0.0546s/iter; left time: 916.5744s\n",
      "\titers: 200, epoch: 25 | loss: 0.0557052\n",
      "\tspeed: 0.0294s/iter; left time: 490.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0546779 Vali Loss: 0.0694937 Test Loss: 0.0824538\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019583983346819878, rmse:0.13994278013706207, mae:0.08118870854377747, rse:0.5413358807563782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0952129\n",
      "\tspeed: 0.0302s/iter; left time: 667.3766s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885167\n",
      "\tspeed: 0.0308s/iter; left time: 677.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0985027 Vali Loss: 0.0886972 Test Loss: 0.0972691\n",
      "Validation loss decreased (inf --> 0.088697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0681498\n",
      "\tspeed: 0.0563s/iter; left time: 1232.1622s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649547\n",
      "\tspeed: 0.0270s/iter; left time: 587.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0695079 Vali Loss: 0.0742967 Test Loss: 0.0827173\n",
      "Validation loss decreased (0.088697 --> 0.074297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636618\n",
      "\tspeed: 0.0621s/iter; left time: 1344.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675858\n",
      "\tspeed: 0.0272s/iter; left time: 585.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0632788 Vali Loss: 0.0724602 Test Loss: 0.0818352\n",
      "Validation loss decreased (0.074297 --> 0.072460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0607947\n",
      "\tspeed: 0.0583s/iter; left time: 1248.7349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615927\n",
      "\tspeed: 0.0288s/iter; left time: 613.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0616307 Vali Loss: 0.0715656 Test Loss: 0.0804375\n",
      "Validation loss decreased (0.072460 --> 0.071566).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622085\n",
      "\tspeed: 0.0546s/iter; left time: 1158.1798s\n",
      "\titers: 200, epoch: 5 | loss: 0.0607410\n",
      "\tspeed: 0.0310s/iter; left time: 653.6964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0605575 Vali Loss: 0.0711619 Test Loss: 0.0811173\n",
      "Validation loss decreased (0.071566 --> 0.071162).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583275\n",
      "\tspeed: 0.0554s/iter; left time: 1163.7437s\n",
      "\titers: 200, epoch: 6 | loss: 0.0605036\n",
      "\tspeed: 0.0276s/iter; left time: 576.9671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0598762 Vali Loss: 0.0707136 Test Loss: 0.0810201\n",
      "Validation loss decreased (0.071162 --> 0.070714).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571717\n",
      "\tspeed: 0.0581s/iter; left time: 1205.9736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580162\n",
      "\tspeed: 0.0270s/iter; left time: 558.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0591734 Vali Loss: 0.0701467 Test Loss: 0.0805756\n",
      "Validation loss decreased (0.070714 --> 0.070147).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549409\n",
      "\tspeed: 0.0596s/iter; left time: 1225.5543s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589893\n",
      "\tspeed: 0.0269s/iter; left time: 549.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0587496 Vali Loss: 0.0706592 Test Loss: 0.0805735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562943\n",
      "\tspeed: 0.0540s/iter; left time: 1097.0223s\n",
      "\titers: 200, epoch: 9 | loss: 0.0623835\n",
      "\tspeed: 0.0310s/iter; left time: 626.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.0582612 Vali Loss: 0.0701556 Test Loss: 0.0809764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0560510\n",
      "\tspeed: 0.0546s/iter; left time: 1098.6045s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569311\n",
      "\tspeed: 0.0277s/iter; left time: 553.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0579194 Vali Loss: 0.0698631 Test Loss: 0.0805883\n",
      "Validation loss decreased (0.070147 --> 0.069863).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552880\n",
      "\tspeed: 0.0576s/iter; left time: 1145.5217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567831\n",
      "\tspeed: 0.0276s/iter; left time: 546.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0575630 Vali Loss: 0.0698857 Test Loss: 0.0814239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0589652\n",
      "\tspeed: 0.0585s/iter; left time: 1149.6359s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571650\n",
      "\tspeed: 0.0272s/iter; left time: 531.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0572331 Vali Loss: 0.0696580 Test Loss: 0.0805479\n",
      "Validation loss decreased (0.069863 --> 0.069658).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596699\n",
      "\tspeed: 0.0590s/iter; left time: 1146.2923s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586063\n",
      "\tspeed: 0.0274s/iter; left time: 529.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0569622 Vali Loss: 0.0694498 Test Loss: 0.0804356\n",
      "Validation loss decreased (0.069658 --> 0.069450).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589501\n",
      "\tspeed: 0.0537s/iter; left time: 1032.2106s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569431\n",
      "\tspeed: 0.0325s/iter; left time: 620.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0566912 Vali Loss: 0.0693219 Test Loss: 0.0799958\n",
      "Validation loss decreased (0.069450 --> 0.069322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506507\n",
      "\tspeed: 0.0546s/iter; left time: 1037.9295s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569483\n",
      "\tspeed: 0.0267s/iter; left time: 503.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0564393 Vali Loss: 0.0695112 Test Loss: 0.0806874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580912\n",
      "\tspeed: 0.0570s/iter; left time: 1069.7731s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560368\n",
      "\tspeed: 0.0276s/iter; left time: 514.8626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0562285 Vali Loss: 0.0692488 Test Loss: 0.0806654\n",
      "Validation loss decreased (0.069322 --> 0.069249).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0560966\n",
      "\tspeed: 0.0579s/iter; left time: 1074.1554s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546358\n",
      "\tspeed: 0.0272s/iter; left time: 501.0310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0560600 Vali Loss: 0.0693445 Test Loss: 0.0808701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0536982\n",
      "\tspeed: 0.0545s/iter; left time: 998.5697s\n",
      "\titers: 200, epoch: 18 | loss: 0.0576510\n",
      "\tspeed: 0.0297s/iter; left time: 541.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0558209 Vali Loss: 0.0692960 Test Loss: 0.0809055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0568429\n",
      "\tspeed: 0.0538s/iter; left time: 974.8709s\n",
      "\titers: 200, epoch: 19 | loss: 0.0548730\n",
      "\tspeed: 0.0272s/iter; left time: 488.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0556284 Vali Loss: 0.0691479 Test Loss: 0.0808090\n",
      "Validation loss decreased (0.069249 --> 0.069148).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542075\n",
      "\tspeed: 0.0588s/iter; left time: 1052.1349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543660\n",
      "\tspeed: 0.0270s/iter; left time: 480.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0555214 Vali Loss: 0.0692614 Test Loss: 0.0808009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560614\n",
      "\tspeed: 0.0583s/iter; left time: 1029.5537s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538527\n",
      "\tspeed: 0.0276s/iter; left time: 483.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0553980 Vali Loss: 0.0693827 Test Loss: 0.0812554\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0574554\n",
      "\tspeed: 0.0532s/iter; left time: 927.7367s\n",
      "\titers: 200, epoch: 22 | loss: 0.0532297\n",
      "\tspeed: 0.0295s/iter; left time: 511.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0552347 Vali Loss: 0.0692179 Test Loss: 0.0811274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0512069\n",
      "\tspeed: 0.0557s/iter; left time: 958.7464s\n",
      "\titers: 200, epoch: 23 | loss: 0.0576784\n",
      "\tspeed: 0.0279s/iter; left time: 476.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0551042 Vali Loss: 0.0693131 Test Loss: 0.0809331\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0545038\n",
      "\tspeed: 0.0566s/iter; left time: 961.7671s\n",
      "\titers: 200, epoch: 24 | loss: 0.0525213\n",
      "\tspeed: 0.0287s/iter; left time: 484.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0549631 Vali Loss: 0.0693683 Test Loss: 0.0808207\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0531886\n",
      "\tspeed: 0.0581s/iter; left time: 974.3355s\n",
      "\titers: 200, epoch: 25 | loss: 0.0607770\n",
      "\tspeed: 0.0270s/iter; left time: 450.1486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0548838 Vali Loss: 0.0693077 Test Loss: 0.0809227\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0545997\n",
      "\tspeed: 0.0576s/iter; left time: 953.2549s\n",
      "\titers: 200, epoch: 26 | loss: 0.0549107\n",
      "\tspeed: 0.0294s/iter; left time: 483.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0547993 Vali Loss: 0.0692610 Test Loss: 0.0812203\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0559376\n",
      "\tspeed: 0.0530s/iter; left time: 865.3901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532648\n",
      "\tspeed: 0.0288s/iter; left time: 467.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0547550 Vali Loss: 0.0691140 Test Loss: 0.0808653\n",
      "Validation loss decreased (0.069148 --> 0.069114).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0582528\n",
      "\tspeed: 0.0569s/iter; left time: 915.8264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525920\n",
      "\tspeed: 0.0273s/iter; left time: 436.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0546527 Vali Loss: 0.0690959 Test Loss: 0.0806358\n",
      "Validation loss decreased (0.069114 --> 0.069096).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0547554\n",
      "\tspeed: 0.0570s/iter; left time: 905.6622s\n",
      "\titers: 200, epoch: 29 | loss: 0.0558492\n",
      "\tspeed: 0.0281s/iter; left time: 444.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0545580 Vali Loss: 0.0692201 Test Loss: 0.0810624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0513949\n",
      "\tspeed: 0.0554s/iter; left time: 867.4813s\n",
      "\titers: 200, epoch: 30 | loss: 0.0538825\n",
      "\tspeed: 0.0268s/iter; left time: 417.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0545313 Vali Loss: 0.0691521 Test Loss: 0.0810161\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517632\n",
      "\tspeed: 0.0559s/iter; left time: 862.8661s\n",
      "\titers: 200, epoch: 31 | loss: 0.0539208\n",
      "\tspeed: 0.0308s/iter; left time: 472.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0545053 Vali Loss: 0.0692572 Test Loss: 0.0809226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0550982\n",
      "\tspeed: 0.0542s/iter; left time: 824.9185s\n",
      "\titers: 200, epoch: 32 | loss: 0.0533233\n",
      "\tspeed: 0.0273s/iter; left time: 412.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0544201 Vali Loss: 0.0691529 Test Loss: 0.0810605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533810\n",
      "\tspeed: 0.0567s/iter; left time: 850.9174s\n",
      "\titers: 200, epoch: 33 | loss: 0.0557891\n",
      "\tspeed: 0.0270s/iter; left time: 402.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0543391 Vali Loss: 0.0690889 Test Loss: 0.0809323\n",
      "Validation loss decreased (0.069096 --> 0.069089).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0543540\n",
      "\tspeed: 0.0533s/iter; left time: 787.3487s\n",
      "\titers: 200, epoch: 34 | loss: 0.0501789\n",
      "\tspeed: 0.0319s/iter; left time: 467.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0543403 Vali Loss: 0.0692075 Test Loss: 0.0809898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572097\n",
      "\tspeed: 0.0542s/iter; left time: 789.1576s\n",
      "\titers: 200, epoch: 35 | loss: 0.0554948\n",
      "\tspeed: 0.0274s/iter; left time: 396.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0543257 Vali Loss: 0.0691925 Test Loss: 0.0809306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536229\n",
      "\tspeed: 0.0581s/iter; left time: 832.6273s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524175\n",
      "\tspeed: 0.0276s/iter; left time: 392.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0542763 Vali Loss: 0.0691631 Test Loss: 0.0809931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568595\n",
      "\tspeed: 0.0557s/iter; left time: 786.2092s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558364\n",
      "\tspeed: 0.0270s/iter; left time: 378.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0542079 Vali Loss: 0.0692795 Test Loss: 0.0810558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0523561\n",
      "\tspeed: 0.0560s/iter; left time: 777.7551s\n",
      "\titers: 200, epoch: 38 | loss: 0.0541448\n",
      "\tspeed: 0.0290s/iter; left time: 400.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0541932 Vali Loss: 0.0691731 Test Loss: 0.0809929\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0515040\n",
      "\tspeed: 0.0532s/iter; left time: 727.3661s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538739\n",
      "\tspeed: 0.0318s/iter; left time: 430.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 222 | Train Loss: 0.0542231 Vali Loss: 0.0692040 Test Loss: 0.0808713\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0547240\n",
      "\tspeed: 0.0587s/iter; left time: 789.4755s\n",
      "\titers: 200, epoch: 40 | loss: 0.0544746\n",
      "\tspeed: 0.0281s/iter; left time: 374.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0541712 Vali Loss: 0.0691869 Test Loss: 0.0810898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535738\n",
      "\tspeed: 0.0576s/iter; left time: 762.1386s\n",
      "\titers: 200, epoch: 41 | loss: 0.0521586\n",
      "\tspeed: 0.0274s/iter; left time: 359.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0541541 Vali Loss: 0.0692053 Test Loss: 0.0810138\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0560169\n",
      "\tspeed: 0.0569s/iter; left time: 739.6913s\n",
      "\titers: 200, epoch: 42 | loss: 0.0550496\n",
      "\tspeed: 0.0286s/iter; left time: 368.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0541010 Vali Loss: 0.0692285 Test Loss: 0.0811099\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0485699\n",
      "\tspeed: 0.0567s/iter; left time: 724.9226s\n",
      "\titers: 200, epoch: 43 | loss: 0.0563646\n",
      "\tspeed: 0.0295s/iter; left time: 374.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0541447 Vali Loss: 0.0692108 Test Loss: 0.0810611\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019895073026418686, rmse:0.14104989171028137, mae:0.08093231916427612, rse:0.54561847448349\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:44.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0938556\n",
      "\tspeed: 0.0537s/iter; left time: 1187.7679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0854498\n",
      "\tspeed: 0.0275s/iter; left time: 605.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0996454 Vali Loss: 0.0909195 Test Loss: 0.0982277\n",
      "Validation loss decreased (inf --> 0.090919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0675109\n",
      "\tspeed: 0.0616s/iter; left time: 1348.6246s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670425\n",
      "\tspeed: 0.0271s/iter; left time: 591.2223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0727755 Vali Loss: 0.0776914 Test Loss: 0.0867592\n",
      "Validation loss decreased (0.090919 --> 0.077691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0661314\n",
      "\tspeed: 0.0576s/iter; left time: 1247.1888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0677241\n",
      "\tspeed: 0.0282s/iter; left time: 608.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0669249 Vali Loss: 0.0761548 Test Loss: 0.0854462\n",
      "Validation loss decreased (0.077691 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0679322\n",
      "\tspeed: 0.0568s/iter; left time: 1217.4635s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632045\n",
      "\tspeed: 0.0299s/iter; left time: 637.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0654356 Vali Loss: 0.0749669 Test Loss: 0.0855714\n",
      "Validation loss decreased (0.076155 --> 0.074967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612492\n",
      "\tspeed: 0.0552s/iter; left time: 1171.6811s\n",
      "\titers: 200, epoch: 5 | loss: 0.0665668\n",
      "\tspeed: 0.0289s/iter; left time: 609.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 222 | Train Loss: 0.0643432 Vali Loss: 0.0746899 Test Loss: 0.0860002\n",
      "Validation loss decreased (0.074967 --> 0.074690).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619588\n",
      "\tspeed: 0.0563s/iter; left time: 1181.4707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662285\n",
      "\tspeed: 0.0271s/iter; left time: 566.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0634915 Vali Loss: 0.0741637 Test Loss: 0.0862336\n",
      "Validation loss decreased (0.074690 --> 0.074164).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630885\n",
      "\tspeed: 0.0599s/iter; left time: 1244.1855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668416\n",
      "\tspeed: 0.0271s/iter; left time: 560.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0628616 Vali Loss: 0.0739373 Test Loss: 0.0866496\n",
      "Validation loss decreased (0.074164 --> 0.073937).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0633949\n",
      "\tspeed: 0.0595s/iter; left time: 1222.1403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0597458\n",
      "\tspeed: 0.0301s/iter; left time: 615.7145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 222 | Train Loss: 0.0622367 Vali Loss: 0.0738674 Test Loss: 0.0874078\n",
      "Validation loss decreased (0.073937 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600061\n",
      "\tspeed: 0.0550s/iter; left time: 1118.5541s\n",
      "\titers: 200, epoch: 9 | loss: 0.0622538\n",
      "\tspeed: 0.0301s/iter; left time: 608.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0617032 Vali Loss: 0.0734540 Test Loss: 0.0876739\n",
      "Validation loss decreased (0.073867 --> 0.073454).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591503\n",
      "\tspeed: 0.0574s/iter; left time: 1153.2995s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608495\n",
      "\tspeed: 0.0293s/iter; left time: 585.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0612152 Vali Loss: 0.0735651 Test Loss: 0.0878582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628291\n",
      "\tspeed: 0.0580s/iter; left time: 1152.1630s\n",
      "\titers: 200, epoch: 11 | loss: 0.0591405\n",
      "\tspeed: 0.0276s/iter; left time: 546.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0608145 Vali Loss: 0.0734721 Test Loss: 0.0884252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628089\n",
      "\tspeed: 0.0565s/iter; left time: 1110.0706s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601851\n",
      "\tspeed: 0.0275s/iter; left time: 537.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0604573 Vali Loss: 0.0732824 Test Loss: 0.0882674\n",
      "Validation loss decreased (0.073454 --> 0.073282).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586489\n",
      "\tspeed: 0.0549s/iter; left time: 1067.0806s\n",
      "\titers: 200, epoch: 13 | loss: 0.0620482\n",
      "\tspeed: 0.0302s/iter; left time: 583.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0600379 Vali Loss: 0.0735289 Test Loss: 0.0874406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0555771\n",
      "\tspeed: 0.0543s/iter; left time: 1044.1961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605145\n",
      "\tspeed: 0.0276s/iter; left time: 527.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0596907 Vali Loss: 0.0732599 Test Loss: 0.0885390\n",
      "Validation loss decreased (0.073282 --> 0.073260).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584461\n",
      "\tspeed: 0.0618s/iter; left time: 1173.1642s\n",
      "\titers: 200, epoch: 15 | loss: 0.0568878\n",
      "\tspeed: 0.0271s/iter; left time: 511.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0593595 Vali Loss: 0.0733622 Test Loss: 0.0882639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593707\n",
      "\tspeed: 0.0574s/iter; left time: 1076.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0584661\n",
      "\tspeed: 0.0274s/iter; left time: 512.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0590356 Vali Loss: 0.0734783 Test Loss: 0.0876160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0588905\n",
      "\tspeed: 0.0564s/iter; left time: 1045.8583s\n",
      "\titers: 200, epoch: 17 | loss: 0.0621994\n",
      "\tspeed: 0.0304s/iter; left time: 560.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0587787 Vali Loss: 0.0732299 Test Loss: 0.0877349\n",
      "Validation loss decreased (0.073260 --> 0.073230).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621530\n",
      "\tspeed: 0.0544s/iter; left time: 996.3035s\n",
      "\titers: 200, epoch: 18 | loss: 0.0605658\n",
      "\tspeed: 0.0306s/iter; left time: 556.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0585481 Vali Loss: 0.0734606 Test Loss: 0.0877434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0583042\n",
      "\tspeed: 0.0553s/iter; left time: 1000.5556s\n",
      "\titers: 200, epoch: 19 | loss: 0.0605425\n",
      "\tspeed: 0.0278s/iter; left time: 500.8201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0582981 Vali Loss: 0.0732683 Test Loss: 0.0879471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0579087\n",
      "\tspeed: 0.0598s/iter; left time: 1069.7862s\n",
      "\titers: 200, epoch: 20 | loss: 0.0559152\n",
      "\tspeed: 0.0272s/iter; left time: 484.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0581190 Vali Loss: 0.0734302 Test Loss: 0.0868313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0566728\n",
      "\tspeed: 0.0571s/iter; left time: 1009.1655s\n",
      "\titers: 200, epoch: 21 | loss: 0.0573363\n",
      "\tspeed: 0.0278s/iter; left time: 488.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 222 | Train Loss: 0.0579168 Vali Loss: 0.0733025 Test Loss: 0.0868867\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0599002\n",
      "\tspeed: 0.0547s/iter; left time: 953.8582s\n",
      "\titers: 200, epoch: 22 | loss: 0.0579244\n",
      "\tspeed: 0.0308s/iter; left time: 534.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0577381 Vali Loss: 0.0734787 Test Loss: 0.0877282\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0576215\n",
      "\tspeed: 0.0563s/iter; left time: 968.5148s\n",
      "\titers: 200, epoch: 23 | loss: 0.0555970\n",
      "\tspeed: 0.0275s/iter; left time: 471.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0576474 Vali Loss: 0.0734664 Test Loss: 0.0873497\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0549140\n",
      "\tspeed: 0.0574s/iter; left time: 976.1575s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565494\n",
      "\tspeed: 0.0277s/iter; left time: 467.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0575239 Vali Loss: 0.0731563 Test Loss: 0.0869676\n",
      "Validation loss decreased (0.073230 --> 0.073156).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0596233\n",
      "\tspeed: 0.0578s/iter; left time: 968.7979s\n",
      "\titers: 200, epoch: 25 | loss: 0.0541902\n",
      "\tspeed: 0.0281s/iter; left time: 468.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0573391 Vali Loss: 0.0734023 Test Loss: 0.0868268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0555391\n",
      "\tspeed: 0.0544s/iter; left time: 900.2221s\n",
      "\titers: 200, epoch: 26 | loss: 0.0553594\n",
      "\tspeed: 0.0313s/iter; left time: 514.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0572754 Vali Loss: 0.0733688 Test Loss: 0.0870272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0564770\n",
      "\tspeed: 0.0558s/iter; left time: 910.6911s\n",
      "\titers: 200, epoch: 27 | loss: 0.0569422\n",
      "\tspeed: 0.0281s/iter; left time: 455.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0571740 Vali Loss: 0.0734585 Test Loss: 0.0868808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0568383\n",
      "\tspeed: 0.0574s/iter; left time: 923.9326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0575890\n",
      "\tspeed: 0.0276s/iter; left time: 442.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0571011 Vali Loss: 0.0735396 Test Loss: 0.0867445\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602893\n",
      "\tspeed: 0.0554s/iter; left time: 879.4234s\n",
      "\titers: 200, epoch: 29 | loss: 0.0582584\n",
      "\tspeed: 0.0274s/iter; left time: 432.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0570145 Vali Loss: 0.0735997 Test Loss: 0.0871782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537078\n",
      "\tspeed: 0.0572s/iter; left time: 896.0460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0555406\n",
      "\tspeed: 0.0280s/iter; left time: 436.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0569776 Vali Loss: 0.0735232 Test Loss: 0.0871077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0557368\n",
      "\tspeed: 0.0533s/iter; left time: 822.2656s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554728\n",
      "\tspeed: 0.0318s/iter; left time: 488.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 222 | Train Loss: 0.0569504 Vali Loss: 0.0735121 Test Loss: 0.0870237\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584505\n",
      "\tspeed: 0.0546s/iter; left time: 831.0824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0585560\n",
      "\tspeed: 0.0277s/iter; left time: 419.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0568485 Vali Loss: 0.0734587 Test Loss: 0.0867984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0601608\n",
      "\tspeed: 0.0571s/iter; left time: 855.6341s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542788\n",
      "\tspeed: 0.0279s/iter; left time: 416.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0568110 Vali Loss: 0.0735852 Test Loss: 0.0870490\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0593282\n",
      "\tspeed: 0.0565s/iter; left time: 834.2108s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566462\n",
      "\tspeed: 0.0280s/iter; left time: 410.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0568219 Vali Loss: 0.0735635 Test Loss: 0.0869921\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02209530398249626, rmse:0.14864489436149597, mae:0.0869675725698471, rse:0.5757157206535339\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0926753\n",
      "\tspeed: 0.0322s/iter; left time: 711.0785s\n",
      "\titers: 200, epoch: 1 | loss: 0.0864850\n",
      "\tspeed: 0.0273s/iter; left time: 601.1498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0998092 Vali Loss: 0.0912169 Test Loss: 0.0984884\n",
      "Validation loss decreased (inf --> 0.091217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0706366\n",
      "\tspeed: 0.0576s/iter; left time: 1260.3439s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685956\n",
      "\tspeed: 0.0308s/iter; left time: 670.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0732876 Vali Loss: 0.0785562 Test Loss: 0.0867374\n",
      "Validation loss decreased (0.091217 --> 0.078556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0673651\n",
      "\tspeed: 0.0541s/iter; left time: 1171.8726s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663863\n",
      "\tspeed: 0.0280s/iter; left time: 604.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0673279 Vali Loss: 0.0765334 Test Loss: 0.0856419\n",
      "Validation loss decreased (0.078556 --> 0.076533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0669243\n",
      "\tspeed: 0.0600s/iter; left time: 1286.9608s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647952\n",
      "\tspeed: 0.0271s/iter; left time: 578.9654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0655516 Vali Loss: 0.0755698 Test Loss: 0.0860987\n",
      "Validation loss decreased (0.076533 --> 0.075570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0669611\n",
      "\tspeed: 0.0548s/iter; left time: 1161.8915s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653353\n",
      "\tspeed: 0.0279s/iter; left time: 588.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0644662 Vali Loss: 0.0751957 Test Loss: 0.0860627\n",
      "Validation loss decreased (0.075570 --> 0.075196).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651973\n",
      "\tspeed: 0.0596s/iter; left time: 1250.0752s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602959\n",
      "\tspeed: 0.0282s/iter; left time: 589.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0636211 Vali Loss: 0.0742472 Test Loss: 0.0868280\n",
      "Validation loss decreased (0.075196 --> 0.074247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0617981\n",
      "\tspeed: 0.0553s/iter; left time: 1148.7227s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661122\n",
      "\tspeed: 0.0295s/iter; left time: 609.3023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0629225 Vali Loss: 0.0737034 Test Loss: 0.0874572\n",
      "Validation loss decreased (0.074247 --> 0.073703).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658991\n",
      "\tspeed: 0.0551s/iter; left time: 1132.5147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613267\n",
      "\tspeed: 0.0280s/iter; left time: 571.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0623983 Vali Loss: 0.0734330 Test Loss: 0.0871008\n",
      "Validation loss decreased (0.073703 --> 0.073433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0611679\n",
      "\tspeed: 0.0582s/iter; left time: 1182.8415s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620157\n",
      "\tspeed: 0.0271s/iter; left time: 547.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0617476 Vali Loss: 0.0734691 Test Loss: 0.0874490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0648440\n",
      "\tspeed: 0.0565s/iter; left time: 1135.3078s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623541\n",
      "\tspeed: 0.0273s/iter; left time: 546.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0612791 Vali Loss: 0.0735913 Test Loss: 0.0876361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0566490\n",
      "\tspeed: 0.0557s/iter; left time: 1106.8575s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592110\n",
      "\tspeed: 0.0281s/iter; left time: 555.7768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0607181 Vali Loss: 0.0732275 Test Loss: 0.0882248\n",
      "Validation loss decreased (0.073433 --> 0.073228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0632455\n",
      "\tspeed: 0.0554s/iter; left time: 1089.5562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584063\n",
      "\tspeed: 0.0298s/iter; left time: 582.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0603093 Vali Loss: 0.0735247 Test Loss: 0.0875141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0591289\n",
      "\tspeed: 0.0542s/iter; left time: 1053.2718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0583428\n",
      "\tspeed: 0.0280s/iter; left time: 540.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0599433 Vali Loss: 0.0735825 Test Loss: 0.0874094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605066\n",
      "\tspeed: 0.0570s/iter; left time: 1095.4285s\n",
      "\titers: 200, epoch: 14 | loss: 0.0622422\n",
      "\tspeed: 0.0276s/iter; left time: 526.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0595383 Vali Loss: 0.0733542 Test Loss: 0.0877012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0608642\n",
      "\tspeed: 0.0570s/iter; left time: 1083.1895s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595879\n",
      "\tspeed: 0.0279s/iter; left time: 526.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0591768 Vali Loss: 0.0733836 Test Loss: 0.0872333\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593759\n",
      "\tspeed: 0.0561s/iter; left time: 1053.7193s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591774\n",
      "\tspeed: 0.0282s/iter; left time: 527.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0589033 Vali Loss: 0.0735029 Test Loss: 0.0868597\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616219\n",
      "\tspeed: 0.0540s/iter; left time: 1001.4667s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582787\n",
      "\tspeed: 0.0291s/iter; left time: 536.0442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0586167 Vali Loss: 0.0735510 Test Loss: 0.0873291\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608582\n",
      "\tspeed: 0.0538s/iter; left time: 986.6374s\n",
      "\titers: 200, epoch: 18 | loss: 0.0558169\n",
      "\tspeed: 0.0274s/iter; left time: 499.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0583472 Vali Loss: 0.0736005 Test Loss: 0.0866306\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0579800\n",
      "\tspeed: 0.0574s/iter; left time: 1039.8457s\n",
      "\titers: 200, epoch: 19 | loss: 0.0586734\n",
      "\tspeed: 0.0274s/iter; left time: 492.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0581088 Vali Loss: 0.0736148 Test Loss: 0.0869817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582891\n",
      "\tspeed: 0.0546s/iter; left time: 976.7968s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546571\n",
      "\tspeed: 0.0274s/iter; left time: 487.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0578948 Vali Loss: 0.0738315 Test Loss: 0.0869170\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569176\n",
      "\tspeed: 0.0556s/iter; left time: 982.4490s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584212\n",
      "\tspeed: 0.0285s/iter; left time: 499.6546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0577929 Vali Loss: 0.0737043 Test Loss: 0.0868128\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02231057547032833, rmse:0.14936724305152893, mae:0.08822478353977203, rse:0.578513503074646\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:00.54s\n",
      "Intermediate time for FR: 00h:33m:33.22s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1220752\n",
      "\tspeed: 0.0509s/iter; left time: 1130.2764s\n",
      "\titers: 200, epoch: 1 | loss: 0.1124015\n",
      "\tspeed: 0.0281s/iter; left time: 622.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.1325993 Vali Loss: 0.0942944 Test Loss: 0.0955565\n",
      "Validation loss decreased (inf --> 0.094294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693890\n",
      "\tspeed: 0.0528s/iter; left time: 1159.9153s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668445\n",
      "\tspeed: 0.0266s/iter; left time: 582.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0759136 Vali Loss: 0.0627112 Test Loss: 0.0656406\n",
      "Validation loss decreased (0.094294 --> 0.062711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662491\n",
      "\tspeed: 0.0544s/iter; left time: 1183.8244s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660577\n",
      "\tspeed: 0.0273s/iter; left time: 591.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0650764 Vali Loss: 0.0596654 Test Loss: 0.0621885\n",
      "Validation loss decreased (0.062711 --> 0.059665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611442\n",
      "\tspeed: 0.0533s/iter; left time: 1147.3704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643807\n",
      "\tspeed: 0.0267s/iter; left time: 571.7833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0621614 Vali Loss: 0.0590315 Test Loss: 0.0613040\n",
      "Validation loss decreased (0.059665 --> 0.059032).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575514\n",
      "\tspeed: 0.0530s/iter; left time: 1129.6298s\n",
      "\titers: 200, epoch: 5 | loss: 0.0622045\n",
      "\tspeed: 0.0281s/iter; left time: 596.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0607118 Vali Loss: 0.0582237 Test Loss: 0.0606797\n",
      "Validation loss decreased (0.059032 --> 0.058224).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0604667\n",
      "\tspeed: 0.0516s/iter; left time: 1088.1781s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586946\n",
      "\tspeed: 0.0273s/iter; left time: 572.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0596630 Vali Loss: 0.0575096 Test Loss: 0.0601424\n",
      "Validation loss decreased (0.058224 --> 0.057510).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605737\n",
      "\tspeed: 0.0555s/iter; left time: 1157.0877s\n",
      "\titers: 200, epoch: 7 | loss: 0.0577191\n",
      "\tspeed: 0.0267s/iter; left time: 553.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0587539 Vali Loss: 0.0573150 Test Loss: 0.0599158\n",
      "Validation loss decreased (0.057510 --> 0.057315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569133\n",
      "\tspeed: 0.0554s/iter; left time: 1144.2128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609494\n",
      "\tspeed: 0.0269s/iter; left time: 552.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0581800 Vali Loss: 0.0571470 Test Loss: 0.0595391\n",
      "Validation loss decreased (0.057315 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543008\n",
      "\tspeed: 0.0537s/iter; left time: 1096.9061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0545223\n",
      "\tspeed: 0.0267s/iter; left time: 542.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0575996 Vali Loss: 0.0566902 Test Loss: 0.0590270\n",
      "Validation loss decreased (0.057147 --> 0.056690).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564065\n",
      "\tspeed: 0.0527s/iter; left time: 1064.7117s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549191\n",
      "\tspeed: 0.0283s/iter; left time: 569.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0571505 Vali Loss: 0.0567421 Test Loss: 0.0591187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0562808\n",
      "\tspeed: 0.0510s/iter; left time: 1019.5154s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546165\n",
      "\tspeed: 0.0269s/iter; left time: 533.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0566563 Vali Loss: 0.0563506 Test Loss: 0.0590622\n",
      "Validation loss decreased (0.056690 --> 0.056351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594916\n",
      "\tspeed: 0.0541s/iter; left time: 1068.2255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550755\n",
      "\tspeed: 0.0265s/iter; left time: 520.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0563721 Vali Loss: 0.0559727 Test Loss: 0.0584474\n",
      "Validation loss decreased (0.056351 --> 0.055973).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533181\n",
      "\tspeed: 0.0545s/iter; left time: 1064.3111s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591052\n",
      "\tspeed: 0.0266s/iter; left time: 516.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0560483 Vali Loss: 0.0560773 Test Loss: 0.0585655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576542\n",
      "\tspeed: 0.0512s/iter; left time: 988.1637s\n",
      "\titers: 200, epoch: 14 | loss: 0.0536710\n",
      "\tspeed: 0.0273s/iter; left time: 524.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0557588 Vali Loss: 0.0557475 Test Loss: 0.0584036\n",
      "Validation loss decreased (0.055973 --> 0.055747).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0577584\n",
      "\tspeed: 0.0550s/iter; left time: 1048.6455s\n",
      "\titers: 200, epoch: 15 | loss: 0.0573185\n",
      "\tspeed: 0.0283s/iter; left time: 536.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0554317 Vali Loss: 0.0554833 Test Loss: 0.0582388\n",
      "Validation loss decreased (0.055747 --> 0.055483).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574488\n",
      "\tspeed: 0.0530s/iter; left time: 998.9107s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597576\n",
      "\tspeed: 0.0268s/iter; left time: 502.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0553067 Vali Loss: 0.0555447 Test Loss: 0.0582300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0528388\n",
      "\tspeed: 0.0548s/iter; left time: 1020.4668s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528586\n",
      "\tspeed: 0.0266s/iter; left time: 492.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0550844 Vali Loss: 0.0555010 Test Loss: 0.0580867\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0575727\n",
      "\tspeed: 0.0531s/iter; left time: 978.1223s\n",
      "\titers: 200, epoch: 18 | loss: 0.0554257\n",
      "\tspeed: 0.0283s/iter; left time: 518.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0548954 Vali Loss: 0.0554527 Test Loss: 0.0580303\n",
      "Validation loss decreased (0.055483 --> 0.055453).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0514130\n",
      "\tspeed: 0.0530s/iter; left time: 964.1856s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547660\n",
      "\tspeed: 0.0275s/iter; left time: 496.5606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0548206 Vali Loss: 0.0552508 Test Loss: 0.0577160\n",
      "Validation loss decreased (0.055453 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535157\n",
      "\tspeed: 0.0514s/iter; left time: 923.5797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577883\n",
      "\tspeed: 0.0279s/iter; left time: 498.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0545696 Vali Loss: 0.0552697 Test Loss: 0.0577830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555147\n",
      "\tspeed: 0.0520s/iter; left time: 923.1396s\n",
      "\titers: 200, epoch: 21 | loss: 0.0544950\n",
      "\tspeed: 0.0266s/iter; left time: 469.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0544441 Vali Loss: 0.0549807 Test Loss: 0.0576976\n",
      "Validation loss decreased (0.055251 --> 0.054981).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534422\n",
      "\tspeed: 0.0547s/iter; left time: 957.8440s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564228\n",
      "\tspeed: 0.0264s/iter; left time: 459.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0543254 Vali Loss: 0.0550190 Test Loss: 0.0575762\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0517031\n",
      "\tspeed: 0.0519s/iter; left time: 897.4414s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587856\n",
      "\tspeed: 0.0267s/iter; left time: 458.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0543248 Vali Loss: 0.0550559 Test Loss: 0.0577396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560705\n",
      "\tspeed: 0.0509s/iter; left time: 869.2080s\n",
      "\titers: 200, epoch: 24 | loss: 0.0528798\n",
      "\tspeed: 0.0286s/iter; left time: 486.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0541613 Vali Loss: 0.0549477 Test Loss: 0.0576477\n",
      "Validation loss decreased (0.054981 --> 0.054948).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0560655\n",
      "\tspeed: 0.0556s/iter; left time: 937.5092s\n",
      "\titers: 200, epoch: 25 | loss: 0.0542304\n",
      "\tspeed: 0.0268s/iter; left time: 448.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0541076 Vali Loss: 0.0548136 Test Loss: 0.0576309\n",
      "Validation loss decreased (0.054948 --> 0.054814).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548747\n",
      "\tspeed: 0.0533s/iter; left time: 885.5314s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538855\n",
      "\tspeed: 0.0266s/iter; left time: 439.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0540087 Vali Loss: 0.0549526 Test Loss: 0.0575554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517120\n",
      "\tspeed: 0.0527s/iter; left time: 864.8934s\n",
      "\titers: 200, epoch: 27 | loss: 0.0527826\n",
      "\tspeed: 0.0266s/iter; left time: 434.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0539188 Vali Loss: 0.0549253 Test Loss: 0.0575773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0549809\n",
      "\tspeed: 0.0516s/iter; left time: 835.4098s\n",
      "\titers: 200, epoch: 28 | loss: 0.0554980\n",
      "\tspeed: 0.0271s/iter; left time: 435.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538956 Vali Loss: 0.0548986 Test Loss: 0.0574903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0527975\n",
      "\tspeed: 0.0508s/iter; left time: 809.8721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0547849\n",
      "\tspeed: 0.0276s/iter; left time: 437.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0538247 Vali Loss: 0.0547120 Test Loss: 0.0574399\n",
      "Validation loss decreased (0.054814 --> 0.054712).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0507995\n",
      "\tspeed: 0.0515s/iter; left time: 809.8363s\n",
      "\titers: 200, epoch: 30 | loss: 0.0500010\n",
      "\tspeed: 0.0266s/iter; left time: 415.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0537853 Vali Loss: 0.0547885 Test Loss: 0.0574554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550639\n",
      "\tspeed: 0.0535s/iter; left time: 829.3732s\n",
      "\titers: 200, epoch: 31 | loss: 0.0518903\n",
      "\tspeed: 0.0264s/iter; left time: 407.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0537086 Vali Loss: 0.0547136 Test Loss: 0.0574395\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559142\n",
      "\tspeed: 0.0537s/iter; left time: 820.9508s\n",
      "\titers: 200, epoch: 32 | loss: 0.0563869\n",
      "\tspeed: 0.0273s/iter; left time: 415.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0537152 Vali Loss: 0.0546903 Test Loss: 0.0574024\n",
      "Validation loss decreased (0.054712 --> 0.054690).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0501247\n",
      "\tspeed: 0.0517s/iter; left time: 779.3576s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544526\n",
      "\tspeed: 0.0277s/iter; left time: 413.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0536137 Vali Loss: 0.0547255 Test Loss: 0.0573914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0529143\n",
      "\tspeed: 0.0514s/iter; left time: 762.4844s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530024\n",
      "\tspeed: 0.0265s/iter; left time: 389.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0535995 Vali Loss: 0.0547244 Test Loss: 0.0574674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510959\n",
      "\tspeed: 0.0529s/iter; left time: 773.3129s\n",
      "\titers: 200, epoch: 35 | loss: 0.0544512\n",
      "\tspeed: 0.0266s/iter; left time: 385.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0535950 Vali Loss: 0.0546488 Test Loss: 0.0574228\n",
      "Validation loss decreased (0.054690 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0535187\n",
      "\tspeed: 0.0517s/iter; left time: 743.7813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0523912\n",
      "\tspeed: 0.0271s/iter; left time: 386.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0535439 Vali Loss: 0.0546921 Test Loss: 0.0573547\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519122\n",
      "\tspeed: 0.0512s/iter; left time: 726.0438s\n",
      "\titers: 200, epoch: 37 | loss: 0.0526450\n",
      "\tspeed: 0.0276s/iter; left time: 388.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535251 Vali Loss: 0.0546742 Test Loss: 0.0573575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0550824\n",
      "\tspeed: 0.0506s/iter; left time: 705.9884s\n",
      "\titers: 200, epoch: 38 | loss: 0.0517140\n",
      "\tspeed: 0.0267s/iter; left time: 370.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0535045 Vali Loss: 0.0546824 Test Loss: 0.0573583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0504631\n",
      "\tspeed: 0.0538s/iter; left time: 737.9139s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540452\n",
      "\tspeed: 0.0267s/iter; left time: 364.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0535086 Vali Loss: 0.0546178 Test Loss: 0.0573389\n",
      "Validation loss decreased (0.054649 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0553547\n",
      "\tspeed: 0.0533s/iter; left time: 719.5076s\n",
      "\titers: 200, epoch: 40 | loss: 0.0607494\n",
      "\tspeed: 0.0266s/iter; left time: 355.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0534950 Vali Loss: 0.0546346 Test Loss: 0.0573255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535479\n",
      "\tspeed: 0.0517s/iter; left time: 686.2660s\n",
      "\titers: 200, epoch: 41 | loss: 0.0538877\n",
      "\tspeed: 0.0283s/iter; left time: 373.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0534341 Vali Loss: 0.0546129 Test Loss: 0.0573383\n",
      "Validation loss decreased (0.054618 --> 0.054613).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0530539\n",
      "\tspeed: 0.0519s/iter; left time: 677.9868s\n",
      "\titers: 200, epoch: 42 | loss: 0.0503627\n",
      "\tspeed: 0.0266s/iter; left time: 344.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534945 Vali Loss: 0.0546511 Test Loss: 0.0573564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522355\n",
      "\tspeed: 0.0524s/iter; left time: 672.6512s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554015\n",
      "\tspeed: 0.0266s/iter; left time: 338.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0534944 Vali Loss: 0.0545573 Test Loss: 0.0572970\n",
      "Validation loss decreased (0.054613 --> 0.054557).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508118\n",
      "\tspeed: 0.0527s/iter; left time: 664.7909s\n",
      "\titers: 200, epoch: 44 | loss: 0.0487365\n",
      "\tspeed: 0.0265s/iter; left time: 331.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0534317 Vali Loss: 0.0546139 Test Loss: 0.0573201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0559016\n",
      "\tspeed: 0.0525s/iter; left time: 650.4442s\n",
      "\titers: 200, epoch: 45 | loss: 0.0545299\n",
      "\tspeed: 0.0274s/iter; left time: 336.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533953 Vali Loss: 0.0546057 Test Loss: 0.0572799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0540960\n",
      "\tspeed: 0.0502s/iter; left time: 611.0743s\n",
      "\titers: 200, epoch: 46 | loss: 0.0512552\n",
      "\tspeed: 0.0266s/iter; left time: 321.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533736 Vali Loss: 0.0546207 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0561732\n",
      "\tspeed: 0.0534s/iter; left time: 637.7349s\n",
      "\titers: 200, epoch: 47 | loss: 0.0581061\n",
      "\tspeed: 0.0267s/iter; left time: 316.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0533965 Vali Loss: 0.0546026 Test Loss: 0.0573136\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520449\n",
      "\tspeed: 0.0535s/iter; left time: 627.0966s\n",
      "\titers: 200, epoch: 48 | loss: 0.0524969\n",
      "\tspeed: 0.0268s/iter; left time: 311.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0534021 Vali Loss: 0.0545990 Test Loss: 0.0572868\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543634\n",
      "\tspeed: 0.0521s/iter; left time: 599.3406s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546120\n",
      "\tspeed: 0.0273s/iter; left time: 311.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533844 Vali Loss: 0.0545882 Test Loss: 0.0572972\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0534620\n",
      "\tspeed: 0.0506s/iter; left time: 570.4850s\n",
      "\titers: 200, epoch: 50 | loss: 0.0547533\n",
      "\tspeed: 0.0275s/iter; left time: 307.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0533451 Vali Loss: 0.0545814 Test Loss: 0.0573124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0546054\n",
      "\tspeed: 0.0523s/iter; left time: 578.0639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510880\n",
      "\tspeed: 0.0267s/iter; left time: 292.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533503 Vali Loss: 0.0546255 Test Loss: 0.0573027\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0514563\n",
      "\tspeed: 0.0527s/iter; left time: 570.8214s\n",
      "\titers: 200, epoch: 52 | loss: 0.0495366\n",
      "\tspeed: 0.0267s/iter; left time: 286.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0533897 Vali Loss: 0.0545539 Test Loss: 0.0572905\n",
      "Validation loss decreased (0.054557 --> 0.054554).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0526214\n",
      "\tspeed: 0.0521s/iter; left time: 552.3314s\n",
      "\titers: 200, epoch: 53 | loss: 0.0528501\n",
      "\tspeed: 0.0272s/iter; left time: 285.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533348 Vali Loss: 0.0545499 Test Loss: 0.0572744\n",
      "Validation loss decreased (0.054554 --> 0.054550).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0534821\n",
      "\tspeed: 0.0511s/iter; left time: 530.3323s\n",
      "\titers: 200, epoch: 54 | loss: 0.0502692\n",
      "\tspeed: 0.0278s/iter; left time: 286.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533270 Vali Loss: 0.0546059 Test Loss: 0.0572837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0566965\n",
      "\tspeed: 0.0525s/iter; left time: 533.3248s\n",
      "\titers: 200, epoch: 55 | loss: 0.0537091\n",
      "\tspeed: 0.0265s/iter; left time: 266.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0533742 Vali Loss: 0.0545576 Test Loss: 0.0572765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0570078\n",
      "\tspeed: 0.0548s/iter; left time: 544.3453s\n",
      "\titers: 200, epoch: 56 | loss: 0.0543868\n",
      "\tspeed: 0.0266s/iter; left time: 262.0291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533093 Vali Loss: 0.0545547 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0484664\n",
      "\tspeed: 0.0542s/iter; left time: 526.0091s\n",
      "\titers: 200, epoch: 57 | loss: 0.0509104\n",
      "\tspeed: 0.0266s/iter; left time: 255.6188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533533 Vali Loss: 0.0545238 Test Loss: 0.0572867\n",
      "Validation loss decreased (0.054550 --> 0.054524).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0565883\n",
      "\tspeed: 0.0532s/iter; left time: 505.2635s\n",
      "\titers: 200, epoch: 58 | loss: 0.0582136\n",
      "\tspeed: 0.0271s/iter; left time: 254.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533185 Vali Loss: 0.0546001 Test Loss: 0.0572918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0523805\n",
      "\tspeed: 0.0508s/iter; left time: 470.7098s\n",
      "\titers: 200, epoch: 59 | loss: 0.0535988\n",
      "\tspeed: 0.0265s/iter; left time: 242.7708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533365 Vali Loss: 0.0545593 Test Loss: 0.0572962\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0546732\n",
      "\tspeed: 0.0535s/iter; left time: 483.9101s\n",
      "\titers: 200, epoch: 60 | loss: 0.0520667\n",
      "\tspeed: 0.0265s/iter; left time: 237.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533063 Vali Loss: 0.0545351 Test Loss: 0.0572758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0580502\n",
      "\tspeed: 0.0526s/iter; left time: 464.3747s\n",
      "\titers: 200, epoch: 61 | loss: 0.0520758\n",
      "\tspeed: 0.0265s/iter; left time: 230.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0533507 Vali Loss: 0.0545636 Test Loss: 0.0572944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0565598\n",
      "\tspeed: 0.0535s/iter; left time: 460.1389s\n",
      "\titers: 200, epoch: 62 | loss: 0.0505943\n",
      "\tspeed: 0.0289s/iter; left time: 245.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0533690 Vali Loss: 0.0546163 Test Loss: 0.0573110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0569731\n",
      "\tspeed: 0.0512s/iter; left time: 428.7700s\n",
      "\titers: 200, epoch: 63 | loss: 0.0532570\n",
      "\tspeed: 0.0279s/iter; left time: 230.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0533448 Vali Loss: 0.0545721 Test Loss: 0.0572936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0568857\n",
      "\tspeed: 0.0515s/iter; left time: 419.9548s\n",
      "\titers: 200, epoch: 64 | loss: 0.0522906\n",
      "\tspeed: 0.0266s/iter; left time: 214.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0533268 Vali Loss: 0.0545559 Test Loss: 0.0572829\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0549613\n",
      "\tspeed: 0.0542s/iter; left time: 429.4227s\n",
      "\titers: 200, epoch: 65 | loss: 0.0547876\n",
      "\tspeed: 0.0264s/iter; left time: 206.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0533261 Vali Loss: 0.0546123 Test Loss: 0.0572819\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0571021\n",
      "\tspeed: 0.0533s/iter; left time: 410.3956s\n",
      "\titers: 200, epoch: 66 | loss: 0.0556666\n",
      "\tspeed: 0.0267s/iter; left time: 203.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0533458 Vali Loss: 0.0545249 Test Loss: 0.0572845\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0536378\n",
      "\tspeed: 0.0511s/iter; left time: 382.4235s\n",
      "\titers: 200, epoch: 67 | loss: 0.0556360\n",
      "\tspeed: 0.0278s/iter; left time: 205.4955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0533135 Vali Loss: 0.0545504 Test Loss: 0.0572871\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01012159138917923, rmse:0.10060612112283707, mae:0.057286690920591354, rse:0.3801409900188446\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248728\n",
      "\tspeed: 0.0282s/iter; left time: 626.4181s\n",
      "\titers: 200, epoch: 1 | loss: 0.1110343\n",
      "\tspeed: 0.0278s/iter; left time: 615.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1324539 Vali Loss: 0.0937511 Test Loss: 0.0949556\n",
      "Validation loss decreased (inf --> 0.093751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0720905\n",
      "\tspeed: 0.0539s/iter; left time: 1184.2051s\n",
      "\titers: 200, epoch: 2 | loss: 0.0645590\n",
      "\tspeed: 0.0274s/iter; left time: 599.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0755588 Vali Loss: 0.0620441 Test Loss: 0.0650663\n",
      "Validation loss decreased (0.093751 --> 0.062044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640341\n",
      "\tspeed: 0.0545s/iter; left time: 1186.3514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0612153\n",
      "\tspeed: 0.0269s/iter; left time: 582.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0647354 Vali Loss: 0.0599341 Test Loss: 0.0626789\n",
      "Validation loss decreased (0.062044 --> 0.059934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0636144\n",
      "\tspeed: 0.0552s/iter; left time: 1188.4956s\n",
      "\titers: 200, epoch: 4 | loss: 0.0610736\n",
      "\tspeed: 0.0266s/iter; left time: 569.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0622370 Vali Loss: 0.0586477 Test Loss: 0.0611086\n",
      "Validation loss decreased (0.059934 --> 0.058648).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597302\n",
      "\tspeed: 0.0525s/iter; left time: 1118.1597s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593400\n",
      "\tspeed: 0.0267s/iter; left time: 565.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0605518 Vali Loss: 0.0583430 Test Loss: 0.0606032\n",
      "Validation loss decreased (0.058648 --> 0.058343).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601675\n",
      "\tspeed: 0.0519s/iter; left time: 1094.6959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0591417\n",
      "\tspeed: 0.0276s/iter; left time: 580.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0595355 Vali Loss: 0.0577077 Test Loss: 0.0602866\n",
      "Validation loss decreased (0.058343 --> 0.057708).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0616218\n",
      "\tspeed: 0.0527s/iter; left time: 1100.1340s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583670\n",
      "\tspeed: 0.0267s/iter; left time: 554.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0587154 Vali Loss: 0.0572509 Test Loss: 0.0596006\n",
      "Validation loss decreased (0.057708 --> 0.057251).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568723\n",
      "\tspeed: 0.0575s/iter; left time: 1187.0474s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633062\n",
      "\tspeed: 0.0266s/iter; left time: 545.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0581127 Vali Loss: 0.0571833 Test Loss: 0.0592898\n",
      "Validation loss decreased (0.057251 --> 0.057183).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551414\n",
      "\tspeed: 0.0534s/iter; left time: 1090.9052s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602552\n",
      "\tspeed: 0.0265s/iter; left time: 538.2335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0575728 Vali Loss: 0.0565193 Test Loss: 0.0591429\n",
      "Validation loss decreased (0.057183 --> 0.056519).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0542222\n",
      "\tspeed: 0.0522s/iter; left time: 1053.9653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0603032\n",
      "\tspeed: 0.0276s/iter; left time: 554.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570322 Vali Loss: 0.0563715 Test Loss: 0.0591157\n",
      "Validation loss decreased (0.056519 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0570678\n",
      "\tspeed: 0.0515s/iter; left time: 1029.4251s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550144\n",
      "\tspeed: 0.0277s/iter; left time: 550.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0566705 Vali Loss: 0.0562801 Test Loss: 0.0587650\n",
      "Validation loss decreased (0.056372 --> 0.056280).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0574326\n",
      "\tspeed: 0.0526s/iter; left time: 1038.9030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546103\n",
      "\tspeed: 0.0268s/iter; left time: 527.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0563215 Vali Loss: 0.0561686 Test Loss: 0.0584310\n",
      "Validation loss decreased (0.056280 --> 0.056169).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0557495\n",
      "\tspeed: 0.0545s/iter; left time: 1063.4217s\n",
      "\titers: 200, epoch: 13 | loss: 0.0531652\n",
      "\tspeed: 0.0266s/iter; left time: 516.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0559293 Vali Loss: 0.0560087 Test Loss: 0.0585652\n",
      "Validation loss decreased (0.056169 --> 0.056009).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552769\n",
      "\tspeed: 0.0533s/iter; left time: 1029.0034s\n",
      "\titers: 200, epoch: 14 | loss: 0.0531435\n",
      "\tspeed: 0.0268s/iter; left time: 515.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0556957 Vali Loss: 0.0558831 Test Loss: 0.0582514\n",
      "Validation loss decreased (0.056009 --> 0.055883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521481\n",
      "\tspeed: 0.0524s/iter; left time: 999.6095s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553430\n",
      "\tspeed: 0.0283s/iter; left time: 536.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0555145 Vali Loss: 0.0557019 Test Loss: 0.0581627\n",
      "Validation loss decreased (0.055883 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609594\n",
      "\tspeed: 0.0527s/iter; left time: 993.4804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542896\n",
      "\tspeed: 0.0272s/iter; left time: 509.3344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0552573 Vali Loss: 0.0554980 Test Loss: 0.0579392\n",
      "Validation loss decreased (0.055702 --> 0.055498).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0568106\n",
      "\tspeed: 0.0542s/iter; left time: 1009.8471s\n",
      "\titers: 200, epoch: 17 | loss: 0.0526110\n",
      "\tspeed: 0.0264s/iter; left time: 489.3135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0551050 Vali Loss: 0.0555646 Test Loss: 0.0581667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543328\n",
      "\tspeed: 0.0534s/iter; left time: 982.9672s\n",
      "\titers: 200, epoch: 18 | loss: 0.0529872\n",
      "\tspeed: 0.0265s/iter; left time: 484.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0549972 Vali Loss: 0.0554904 Test Loss: 0.0578824\n",
      "Validation loss decreased (0.055498 --> 0.055490).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0561036\n",
      "\tspeed: 0.0511s/iter; left time: 929.3392s\n",
      "\titers: 200, epoch: 19 | loss: 0.0585789\n",
      "\tspeed: 0.0269s/iter; left time: 486.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0547228 Vali Loss: 0.0551855 Test Loss: 0.0576403\n",
      "Validation loss decreased (0.055490 --> 0.055185).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0551048\n",
      "\tspeed: 0.0535s/iter; left time: 961.2267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0540609\n",
      "\tspeed: 0.0283s/iter; left time: 505.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0546380 Vali Loss: 0.0555217 Test Loss: 0.0577946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0542702\n",
      "\tspeed: 0.0516s/iter; left time: 916.2719s\n",
      "\titers: 200, epoch: 21 | loss: 0.0512278\n",
      "\tspeed: 0.0263s/iter; left time: 464.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0545288 Vali Loss: 0.0553299 Test Loss: 0.0576920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0561697\n",
      "\tspeed: 0.0550s/iter; left time: 962.6244s\n",
      "\titers: 200, epoch: 22 | loss: 0.0527409\n",
      "\tspeed: 0.0268s/iter; left time: 466.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0544019 Vali Loss: 0.0552929 Test Loss: 0.0575224\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529760\n",
      "\tspeed: 0.0534s/iter; left time: 923.4529s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520137\n",
      "\tspeed: 0.0270s/iter; left time: 463.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0542588 Vali Loss: 0.0552379 Test Loss: 0.0575204\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0544704\n",
      "\tspeed: 0.0515s/iter; left time: 878.6230s\n",
      "\titers: 200, epoch: 24 | loss: 0.0581453\n",
      "\tspeed: 0.0287s/iter; left time: 486.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0542069 Vali Loss: 0.0551895 Test Loss: 0.0574684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0549121\n",
      "\tspeed: 0.0518s/iter; left time: 872.9043s\n",
      "\titers: 200, epoch: 25 | loss: 0.0512915\n",
      "\tspeed: 0.0269s/iter; left time: 450.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0541660 Vali Loss: 0.0550061 Test Loss: 0.0575668\n",
      "Validation loss decreased (0.055185 --> 0.055006).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0542531\n",
      "\tspeed: 0.0547s/iter; left time: 910.0617s\n",
      "\titers: 200, epoch: 26 | loss: 0.0534555\n",
      "\tspeed: 0.0271s/iter; left time: 447.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0540092 Vali Loss: 0.0549437 Test Loss: 0.0573728\n",
      "Validation loss decreased (0.055006 --> 0.054944).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0522741\n",
      "\tspeed: 0.0547s/iter; left time: 897.5644s\n",
      "\titers: 200, epoch: 27 | loss: 0.0540177\n",
      "\tspeed: 0.0269s/iter; left time: 438.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0539847 Vali Loss: 0.0550816 Test Loss: 0.0574916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0527179\n",
      "\tspeed: 0.0518s/iter; left time: 838.5554s\n",
      "\titers: 200, epoch: 28 | loss: 0.0534733\n",
      "\tspeed: 0.0276s/iter; left time: 443.3765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0539413 Vali Loss: 0.0550135 Test Loss: 0.0575341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0502411\n",
      "\tspeed: 0.0513s/iter; left time: 819.2275s\n",
      "\titers: 200, epoch: 29 | loss: 0.0528361\n",
      "\tspeed: 0.0275s/iter; left time: 435.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538017 Vali Loss: 0.0548889 Test Loss: 0.0573778\n",
      "Validation loss decreased (0.054944 --> 0.054889).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0518792\n",
      "\tspeed: 0.0524s/iter; left time: 824.7375s\n",
      "\titers: 200, epoch: 30 | loss: 0.0557014\n",
      "\tspeed: 0.0265s/iter; left time: 414.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0537871 Vali Loss: 0.0549768 Test Loss: 0.0574409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0499483\n",
      "\tspeed: 0.0546s/iter; left time: 847.1963s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548199\n",
      "\tspeed: 0.0265s/iter; left time: 408.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0537241 Vali Loss: 0.0548849 Test Loss: 0.0573524\n",
      "Validation loss decreased (0.054889 --> 0.054885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0519677\n",
      "\tspeed: 0.0530s/iter; left time: 809.8001s\n",
      "\titers: 200, epoch: 32 | loss: 0.0509725\n",
      "\tspeed: 0.0269s/iter; left time: 408.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0537428 Vali Loss: 0.0548889 Test Loss: 0.0573561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0516712\n",
      "\tspeed: 0.0519s/iter; left time: 781.2646s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521875\n",
      "\tspeed: 0.0286s/iter; left time: 428.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536519 Vali Loss: 0.0549251 Test Loss: 0.0573139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525791\n",
      "\tspeed: 0.0522s/iter; left time: 775.0032s\n",
      "\titers: 200, epoch: 34 | loss: 0.0539121\n",
      "\tspeed: 0.0266s/iter; left time: 392.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0536618 Vali Loss: 0.0548495 Test Loss: 0.0573276\n",
      "Validation loss decreased (0.054885 --> 0.054850).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548193\n",
      "\tspeed: 0.0559s/iter; left time: 817.7348s\n",
      "\titers: 200, epoch: 35 | loss: 0.0560694\n",
      "\tspeed: 0.0269s/iter; left time: 390.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0536223 Vali Loss: 0.0549313 Test Loss: 0.0573653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0531555\n",
      "\tspeed: 0.0537s/iter; left time: 772.3500s\n",
      "\titers: 200, epoch: 36 | loss: 0.0529074\n",
      "\tspeed: 0.0270s/iter; left time: 385.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0535724 Vali Loss: 0.0548796 Test Loss: 0.0573130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542191\n",
      "\tspeed: 0.0515s/iter; left time: 729.6216s\n",
      "\titers: 200, epoch: 37 | loss: 0.0521309\n",
      "\tspeed: 0.0284s/iter; left time: 399.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536354 Vali Loss: 0.0548213 Test Loss: 0.0573156\n",
      "Validation loss decreased (0.054850 --> 0.054821).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0513455\n",
      "\tspeed: 0.0514s/iter; left time: 716.9502s\n",
      "\titers: 200, epoch: 38 | loss: 0.0484909\n",
      "\tspeed: 0.0283s/iter; left time: 391.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0535302 Vali Loss: 0.0548031 Test Loss: 0.0572883\n",
      "Validation loss decreased (0.054821 --> 0.054803).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0567436\n",
      "\tspeed: 0.0533s/iter; left time: 731.9007s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543030\n",
      "\tspeed: 0.0268s/iter; left time: 364.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0535580 Vali Loss: 0.0548298 Test Loss: 0.0572565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0577767\n",
      "\tspeed: 0.0542s/iter; left time: 731.7697s\n",
      "\titers: 200, epoch: 40 | loss: 0.0489657\n",
      "\tspeed: 0.0265s/iter; left time: 355.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535311 Vali Loss: 0.0547384 Test Loss: 0.0572284\n",
      "Validation loss decreased (0.054803 --> 0.054738).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0492260\n",
      "\tspeed: 0.0523s/iter; left time: 695.0258s\n",
      "\titers: 200, epoch: 41 | loss: 0.0530771\n",
      "\tspeed: 0.0274s/iter; left time: 361.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0535195 Vali Loss: 0.0547555 Test Loss: 0.0572335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536120\n",
      "\tspeed: 0.0524s/iter; left time: 683.8322s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539439\n",
      "\tspeed: 0.0290s/iter; left time: 375.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0535063 Vali Loss: 0.0547998 Test Loss: 0.0572487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0516886\n",
      "\tspeed: 0.0513s/iter; left time: 659.0389s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514923\n",
      "\tspeed: 0.0263s/iter; left time: 335.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0534249 Vali Loss: 0.0548376 Test Loss: 0.0572255\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0577250\n",
      "\tspeed: 0.0549s/iter; left time: 692.4608s\n",
      "\titers: 200, epoch: 44 | loss: 0.0516380\n",
      "\tspeed: 0.0269s/iter; left time: 336.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0534548 Vali Loss: 0.0547533 Test Loss: 0.0572155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551903\n",
      "\tspeed: 0.0531s/iter; left time: 657.8252s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587276\n",
      "\tspeed: 0.0268s/iter; left time: 329.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0534890 Vali Loss: 0.0547240 Test Loss: 0.0572646\n",
      "Validation loss decreased (0.054738 --> 0.054724).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0569799\n",
      "\tspeed: 0.0520s/iter; left time: 632.1113s\n",
      "\titers: 200, epoch: 46 | loss: 0.0528706\n",
      "\tspeed: 0.0281s/iter; left time: 339.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0534028 Vali Loss: 0.0548343 Test Loss: 0.0572270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0535365\n",
      "\tspeed: 0.0521s/iter; left time: 622.7815s\n",
      "\titers: 200, epoch: 47 | loss: 0.0522014\n",
      "\tspeed: 0.0276s/iter; left time: 327.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0534371 Vali Loss: 0.0548092 Test Loss: 0.0572257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0540526\n",
      "\tspeed: 0.0528s/iter; left time: 618.2454s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521358\n",
      "\tspeed: 0.0267s/iter; left time: 309.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534032 Vali Loss: 0.0547515 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0514734\n",
      "\tspeed: 0.0548s/iter; left time: 630.1869s\n",
      "\titers: 200, epoch: 49 | loss: 0.0515570\n",
      "\tspeed: 0.0268s/iter; left time: 305.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0533995 Vali Loss: 0.0547729 Test Loss: 0.0572376\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0553200\n",
      "\tspeed: 0.0539s/iter; left time: 607.7663s\n",
      "\titers: 200, epoch: 50 | loss: 0.0507628\n",
      "\tspeed: 0.0283s/iter; left time: 316.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0534180 Vali Loss: 0.0548830 Test Loss: 0.0572152\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0522079\n",
      "\tspeed: 0.0516s/iter; left time: 570.3257s\n",
      "\titers: 200, epoch: 51 | loss: 0.0526080\n",
      "\tspeed: 0.0291s/iter; left time: 319.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0533703 Vali Loss: 0.0547865 Test Loss: 0.0572359\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0549524\n",
      "\tspeed: 0.0527s/iter; left time: 570.7138s\n",
      "\titers: 200, epoch: 52 | loss: 0.0532417\n",
      "\tspeed: 0.0268s/iter; left time: 287.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0534304 Vali Loss: 0.0547305 Test Loss: 0.0572217\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0537086\n",
      "\tspeed: 0.0548s/iter; left time: 580.8395s\n",
      "\titers: 200, epoch: 53 | loss: 0.0529253\n",
      "\tspeed: 0.0266s/iter; left time: 279.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0533663 Vali Loss: 0.0548078 Test Loss: 0.0572288\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0523412\n",
      "\tspeed: 0.0540s/iter; left time: 560.4656s\n",
      "\titers: 200, epoch: 54 | loss: 0.0549152\n",
      "\tspeed: 0.0271s/iter; left time: 278.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 223 | Train Loss: 0.0533426 Vali Loss: 0.0547861 Test Loss: 0.0572313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0475683\n",
      "\tspeed: 0.0546s/iter; left time: 554.5516s\n",
      "\titers: 200, epoch: 55 | loss: 0.0524945\n",
      "\tspeed: 0.0275s/iter; left time: 276.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0534049 Vali Loss: 0.0548184 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083268396556377, rmse:0.10041547566652298, mae:0.05726462975144386, rse:0.3794206380844116\n",
      "Intermediate time for IT and pred_len 24: 00h:16m:28.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1321838\n",
      "\tspeed: 0.0528s/iter; left time: 1166.6778s\n",
      "\titers: 200, epoch: 1 | loss: 0.1144970\n",
      "\tspeed: 0.0271s/iter; left time: 597.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1387064 Vali Loss: 0.1032817 Test Loss: 0.1052682\n",
      "Validation loss decreased (inf --> 0.103282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853616\n",
      "\tspeed: 0.0561s/iter; left time: 1228.0293s\n",
      "\titers: 200, epoch: 2 | loss: 0.0828326\n",
      "\tspeed: 0.0272s/iter; left time: 592.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932694 Vali Loss: 0.0822700 Test Loss: 0.0855554\n",
      "Validation loss decreased (0.103282 --> 0.082270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840157\n",
      "\tspeed: 0.0575s/iter; left time: 1245.1145s\n",
      "\titers: 200, epoch: 3 | loss: 0.0772976\n",
      "\tspeed: 0.0294s/iter; left time: 633.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0837174 Vali Loss: 0.0802281 Test Loss: 0.0841231\n",
      "Validation loss decreased (0.082270 --> 0.080228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776535\n",
      "\tspeed: 0.0538s/iter; left time: 1152.2520s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804181\n",
      "\tspeed: 0.0279s/iter; left time: 595.0900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0811037 Vali Loss: 0.0788419 Test Loss: 0.0832654\n",
      "Validation loss decreased (0.080228 --> 0.078842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817597\n",
      "\tspeed: 0.0555s/iter; left time: 1177.6018s\n",
      "\titers: 200, epoch: 5 | loss: 0.0780218\n",
      "\tspeed: 0.0272s/iter; left time: 573.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0794239 Vali Loss: 0.0786723 Test Loss: 0.0830877\n",
      "Validation loss decreased (0.078842 --> 0.078672).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774737\n",
      "\tspeed: 0.0564s/iter; left time: 1183.8263s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789120\n",
      "\tspeed: 0.0275s/iter; left time: 574.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0783094 Vali Loss: 0.0786543 Test Loss: 0.0826141\n",
      "Validation loss decreased (0.078672 --> 0.078654).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756353\n",
      "\tspeed: 0.0550s/iter; left time: 1142.9273s\n",
      "\titers: 200, epoch: 7 | loss: 0.0770764\n",
      "\tspeed: 0.0279s/iter; left time: 577.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0773383 Vali Loss: 0.0779212 Test Loss: 0.0822634\n",
      "Validation loss decreased (0.078654 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771187\n",
      "\tspeed: 0.0532s/iter; left time: 1092.8138s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760235\n",
      "\tspeed: 0.0281s/iter; left time: 574.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0764953 Vali Loss: 0.0783359 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729671\n",
      "\tspeed: 0.0537s/iter; left time: 1091.8457s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753743\n",
      "\tspeed: 0.0275s/iter; left time: 555.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0758295 Vali Loss: 0.0776675 Test Loss: 0.0825013\n",
      "Validation loss decreased (0.077921 --> 0.077668).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0795718\n",
      "\tspeed: 0.0567s/iter; left time: 1138.8475s\n",
      "\titers: 200, epoch: 10 | loss: 0.0746166\n",
      "\tspeed: 0.0272s/iter; left time: 543.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0753310 Vali Loss: 0.0781949 Test Loss: 0.0824108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762351\n",
      "\tspeed: 0.0550s/iter; left time: 1093.5082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735926\n",
      "\tspeed: 0.0272s/iter; left time: 537.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0748693 Vali Loss: 0.0781084 Test Loss: 0.0827782\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725338\n",
      "\tspeed: 0.0526s/iter; left time: 1033.7681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0750147\n",
      "\tspeed: 0.0284s/iter; left time: 555.6160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0743695 Vali Loss: 0.0778181 Test Loss: 0.0824795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0748884\n",
      "\tspeed: 0.0529s/iter; left time: 1028.8589s\n",
      "\titers: 200, epoch: 13 | loss: 0.0768396\n",
      "\tspeed: 0.0279s/iter; left time: 539.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0740004 Vali Loss: 0.0777673 Test Loss: 0.0825389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0698381\n",
      "\tspeed: 0.0549s/iter; left time: 1055.0927s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717925\n",
      "\tspeed: 0.0269s/iter; left time: 513.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0736021 Vali Loss: 0.0778859 Test Loss: 0.0826246\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0710938\n",
      "\tspeed: 0.0559s/iter; left time: 1062.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687255\n",
      "\tspeed: 0.0270s/iter; left time: 510.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0732304 Vali Loss: 0.0778723 Test Loss: 0.0830562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0749232\n",
      "\tspeed: 0.0533s/iter; left time: 1000.4663s\n",
      "\titers: 200, epoch: 16 | loss: 0.0746401\n",
      "\tspeed: 0.0276s/iter; left time: 516.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0729620 Vali Loss: 0.0777781 Test Loss: 0.0827808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733482\n",
      "\tspeed: 0.0528s/iter; left time: 979.8157s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715483\n",
      "\tspeed: 0.0288s/iter; left time: 531.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0726490 Vali Loss: 0.0779078 Test Loss: 0.0832266\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739253\n",
      "\tspeed: 0.0536s/iter; left time: 981.6920s\n",
      "\titers: 200, epoch: 18 | loss: 0.0751582\n",
      "\tspeed: 0.0272s/iter; left time: 495.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0724323 Vali Loss: 0.0774746 Test Loss: 0.0825534\n",
      "Validation loss decreased (0.077668 --> 0.077475).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730057\n",
      "\tspeed: 0.0590s/iter; left time: 1068.9870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744534\n",
      "\tspeed: 0.0269s/iter; left time: 484.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0721436 Vali Loss: 0.0777745 Test Loss: 0.0828253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0702813\n",
      "\tspeed: 0.0554s/iter; left time: 989.9029s\n",
      "\titers: 200, epoch: 20 | loss: 0.0714406\n",
      "\tspeed: 0.0274s/iter; left time: 486.6499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0719519 Vali Loss: 0.0777934 Test Loss: 0.0831720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752490\n",
      "\tspeed: 0.0530s/iter; left time: 936.4262s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729214\n",
      "\tspeed: 0.0297s/iter; left time: 522.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0717573 Vali Loss: 0.0775301 Test Loss: 0.0829119\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0729312\n",
      "\tspeed: 0.0534s/iter; left time: 930.4178s\n",
      "\titers: 200, epoch: 22 | loss: 0.0712821\n",
      "\tspeed: 0.0279s/iter; left time: 483.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0716219 Vali Loss: 0.0775715 Test Loss: 0.0831647\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0745800\n",
      "\tspeed: 0.0545s/iter; left time: 939.0949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0710693\n",
      "\tspeed: 0.0268s/iter; left time: 458.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0714176 Vali Loss: 0.0774375 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.077475 --> 0.077438).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0726332\n",
      "\tspeed: 0.0550s/iter; left time: 934.8110s\n",
      "\titers: 200, epoch: 24 | loss: 0.0703410\n",
      "\tspeed: 0.0270s/iter; left time: 455.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0712783 Vali Loss: 0.0776950 Test Loss: 0.0831947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0688102\n",
      "\tspeed: 0.0542s/iter; left time: 908.8879s\n",
      "\titers: 200, epoch: 25 | loss: 0.0745878\n",
      "\tspeed: 0.0288s/iter; left time: 480.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0710946 Vali Loss: 0.0775712 Test Loss: 0.0831804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0722734\n",
      "\tspeed: 0.0529s/iter; left time: 874.8612s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690523\n",
      "\tspeed: 0.0284s/iter; left time: 467.9860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0710367 Vali Loss: 0.0774692 Test Loss: 0.0832843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0757137\n",
      "\tspeed: 0.0539s/iter; left time: 880.8381s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672927\n",
      "\tspeed: 0.0275s/iter; left time: 445.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0709873 Vali Loss: 0.0775369 Test Loss: 0.0832190\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734061\n",
      "\tspeed: 0.0564s/iter; left time: 908.3009s\n",
      "\titers: 200, epoch: 28 | loss: 0.0689125\n",
      "\tspeed: 0.0269s/iter; left time: 430.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0708438 Vali Loss: 0.0776351 Test Loss: 0.0832205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0706797\n",
      "\tspeed: 0.0549s/iter; left time: 871.6611s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731136\n",
      "\tspeed: 0.0278s/iter; left time: 439.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0707727 Vali Loss: 0.0773896 Test Loss: 0.0832303\n",
      "Validation loss decreased (0.077438 --> 0.077390).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0717404\n",
      "\tspeed: 0.0534s/iter; left time: 835.9623s\n",
      "\titers: 200, epoch: 30 | loss: 0.0729116\n",
      "\tspeed: 0.0290s/iter; left time: 451.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0706910 Vali Loss: 0.0774434 Test Loss: 0.0832887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0757121\n",
      "\tspeed: 0.0534s/iter; left time: 825.1587s\n",
      "\titers: 200, epoch: 31 | loss: 0.0711617\n",
      "\tspeed: 0.0271s/iter; left time: 415.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0706033 Vali Loss: 0.0776396 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712611\n",
      "\tspeed: 0.0575s/iter; left time: 874.6293s\n",
      "\titers: 200, epoch: 32 | loss: 0.0727751\n",
      "\tspeed: 0.0272s/iter; left time: 411.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0705892 Vali Loss: 0.0775814 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0709131\n",
      "\tspeed: 0.0545s/iter; left time: 817.8930s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718555\n",
      "\tspeed: 0.0271s/iter; left time: 403.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0705573 Vali Loss: 0.0772810 Test Loss: 0.0833159\n",
      "Validation loss decreased (0.077390 --> 0.077281).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0690060\n",
      "\tspeed: 0.0518s/iter; left time: 765.6173s\n",
      "\titers: 200, epoch: 34 | loss: 0.0711988\n",
      "\tspeed: 0.0280s/iter; left time: 410.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0705202 Vali Loss: 0.0774535 Test Loss: 0.0832982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732094\n",
      "\tspeed: 0.0534s/iter; left time: 776.4035s\n",
      "\titers: 200, epoch: 35 | loss: 0.0739846\n",
      "\tspeed: 0.0278s/iter; left time: 401.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0704378 Vali Loss: 0.0774655 Test Loss: 0.0832758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0734195\n",
      "\tspeed: 0.0536s/iter; left time: 768.0877s\n",
      "\titers: 200, epoch: 36 | loss: 0.0688326\n",
      "\tspeed: 0.0276s/iter; left time: 393.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0703314 Vali Loss: 0.0775375 Test Loss: 0.0834405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0667930\n",
      "\tspeed: 0.0559s/iter; left time: 788.8954s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698663\n",
      "\tspeed: 0.0271s/iter; left time: 379.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0703407 Vali Loss: 0.0774669 Test Loss: 0.0833736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0679398\n",
      "\tspeed: 0.0555s/iter; left time: 771.3706s\n",
      "\titers: 200, epoch: 38 | loss: 0.0724612\n",
      "\tspeed: 0.0274s/iter; left time: 377.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0703553 Vali Loss: 0.0775958 Test Loss: 0.0833337\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0718481\n",
      "\tspeed: 0.0526s/iter; left time: 718.1055s\n",
      "\titers: 200, epoch: 39 | loss: 0.0735828\n",
      "\tspeed: 0.0286s/iter; left time: 388.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702385 Vali Loss: 0.0774214 Test Loss: 0.0832950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0657273\n",
      "\tspeed: 0.0537s/iter; left time: 722.4613s\n",
      "\titers: 200, epoch: 40 | loss: 0.0679445\n",
      "\tspeed: 0.0268s/iter; left time: 357.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0702638 Vali Loss: 0.0775013 Test Loss: 0.0834430\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673170\n",
      "\tspeed: 0.0568s/iter; left time: 750.9906s\n",
      "\titers: 200, epoch: 41 | loss: 0.0687927\n",
      "\tspeed: 0.0269s/iter; left time: 352.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0702658 Vali Loss: 0.0773642 Test Loss: 0.0834067\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0763263\n",
      "\tspeed: 0.0575s/iter; left time: 746.9921s\n",
      "\titers: 200, epoch: 42 | loss: 0.0653355\n",
      "\tspeed: 0.0279s/iter; left time: 359.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0701891 Vali Loss: 0.0775082 Test Loss: 0.0834283\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0718496\n",
      "\tspeed: 0.0548s/iter; left time: 700.0664s\n",
      "\titers: 200, epoch: 43 | loss: 0.0727848\n",
      "\tspeed: 0.0281s/iter; left time: 355.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702348 Vali Loss: 0.0775226 Test Loss: 0.0834311\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019748352468013763, rmse:0.1405288279056549, mae:0.0833158940076828, rse:0.5313546657562256\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1307300\n",
      "\tspeed: 0.0299s/iter; left time: 661.4012s\n",
      "\titers: 200, epoch: 1 | loss: 0.1169153\n",
      "\tspeed: 0.0295s/iter; left time: 649.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.1395382 Vali Loss: 0.1032388 Test Loss: 0.1049907\n",
      "Validation loss decreased (inf --> 0.103239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0917928\n",
      "\tspeed: 0.0557s/iter; left time: 1217.6038s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827175\n",
      "\tspeed: 0.0287s/iter; left time: 624.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932693 Vali Loss: 0.0824907 Test Loss: 0.0859276\n",
      "Validation loss decreased (0.103239 --> 0.082491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872422\n",
      "\tspeed: 0.0548s/iter; left time: 1186.2276s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782116\n",
      "\tspeed: 0.0270s/iter; left time: 582.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0836970 Vali Loss: 0.0801819 Test Loss: 0.0838659\n",
      "Validation loss decreased (0.082491 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816273\n",
      "\tspeed: 0.0592s/iter; left time: 1268.5184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826085\n",
      "\tspeed: 0.0267s/iter; left time: 569.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0810833 Vali Loss: 0.0788540 Test Loss: 0.0829947\n",
      "Validation loss decreased (0.080182 --> 0.078854).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0761694\n",
      "\tspeed: 0.0566s/iter; left time: 1201.0110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798683\n",
      "\tspeed: 0.0270s/iter; left time: 569.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0795185 Vali Loss: 0.0781875 Test Loss: 0.0825942\n",
      "Validation loss decreased (0.078854 --> 0.078187).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777261\n",
      "\tspeed: 0.0551s/iter; left time: 1156.6782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0814498\n",
      "\tspeed: 0.0286s/iter; left time: 598.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0783964 Vali Loss: 0.0775421 Test Loss: 0.0821851\n",
      "Validation loss decreased (0.078187 --> 0.077542).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739338\n",
      "\tspeed: 0.0550s/iter; left time: 1142.5101s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811702\n",
      "\tspeed: 0.0280s/iter; left time: 578.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0774509 Vali Loss: 0.0783391 Test Loss: 0.0824711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753421\n",
      "\tspeed: 0.0553s/iter; left time: 1136.8596s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756552\n",
      "\tspeed: 0.0269s/iter; left time: 550.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0767014 Vali Loss: 0.0771883 Test Loss: 0.0820175\n",
      "Validation loss decreased (0.077542 --> 0.077188).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738878\n",
      "\tspeed: 0.0593s/iter; left time: 1204.7930s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749177\n",
      "\tspeed: 0.0268s/iter; left time: 542.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0760252 Vali Loss: 0.0781950 Test Loss: 0.0820919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0755344\n",
      "\tspeed: 0.0569s/iter; left time: 1143.6002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751255\n",
      "\tspeed: 0.0270s/iter; left time: 539.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0755306 Vali Loss: 0.0778631 Test Loss: 0.0822712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782155\n",
      "\tspeed: 0.0549s/iter; left time: 1091.8220s\n",
      "\titers: 200, epoch: 11 | loss: 0.0755833\n",
      "\tspeed: 0.0290s/iter; left time: 573.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0749816 Vali Loss: 0.0776737 Test Loss: 0.0817804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0693621\n",
      "\tspeed: 0.0548s/iter; left time: 1077.9669s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719745\n",
      "\tspeed: 0.0273s/iter; left time: 533.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0745667 Vali Loss: 0.0779224 Test Loss: 0.0818569\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0694613\n",
      "\tspeed: 0.0573s/iter; left time: 1113.5811s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725119\n",
      "\tspeed: 0.0269s/iter; left time: 521.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0740950 Vali Loss: 0.0777880 Test Loss: 0.0819785\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0775695\n",
      "\tspeed: 0.0581s/iter; left time: 1115.6870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0681774\n",
      "\tspeed: 0.0270s/iter; left time: 516.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0736995 Vali Loss: 0.0773107 Test Loss: 0.0820360\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733372\n",
      "\tspeed: 0.0569s/iter; left time: 1081.2037s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732900\n",
      "\tspeed: 0.0273s/iter; left time: 516.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0734037 Vali Loss: 0.0772424 Test Loss: 0.0821582\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713919\n",
      "\tspeed: 0.0549s/iter; left time: 1030.8488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0709377\n",
      "\tspeed: 0.0313s/iter; left time: 583.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0731161 Vali Loss: 0.0773405 Test Loss: 0.0820549\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754753\n",
      "\tspeed: 0.0540s/iter; left time: 1001.8352s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705882\n",
      "\tspeed: 0.0272s/iter; left time: 501.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0728018 Vali Loss: 0.0775164 Test Loss: 0.0821095\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0719491\n",
      "\tspeed: 0.0591s/iter; left time: 1083.3750s\n",
      "\titers: 200, epoch: 18 | loss: 0.0699536\n",
      "\tspeed: 0.0275s/iter; left time: 500.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0726074 Vali Loss: 0.0776926 Test Loss: 0.0821289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01836535520851612, rmse:0.13551883399486542, mae:0.08201750367879868, rse:0.51241135597229\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:37.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1298100\n",
      "\tspeed: 0.0534s/iter; left time: 1180.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.1176691\n",
      "\tspeed: 0.0292s/iter; left time: 643.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.1401385 Vali Loss: 0.1051041 Test Loss: 0.1060515\n",
      "Validation loss decreased (inf --> 0.105104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0925689\n",
      "\tspeed: 0.0530s/iter; left time: 1158.9939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0874640\n",
      "\tspeed: 0.0274s/iter; left time: 597.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0966582 Vali Loss: 0.0868458 Test Loss: 0.0894829\n",
      "Validation loss decreased (0.105104 --> 0.086846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0902038\n",
      "\tspeed: 0.0607s/iter; left time: 1313.8809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0879562\n",
      "\tspeed: 0.0273s/iter; left time: 588.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0874138 Vali Loss: 0.0842694 Test Loss: 0.0879542\n",
      "Validation loss decreased (0.086846 --> 0.084269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857633\n",
      "\tspeed: 0.0538s/iter; left time: 1153.1748s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834477\n",
      "\tspeed: 0.0272s/iter; left time: 580.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0846647 Vali Loss: 0.0835778 Test Loss: 0.0880411\n",
      "Validation loss decreased (0.084269 --> 0.083578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838752\n",
      "\tspeed: 0.0540s/iter; left time: 1144.7333s\n",
      "\titers: 200, epoch: 5 | loss: 0.0841271\n",
      "\tspeed: 0.0300s/iter; left time: 632.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0829673 Vali Loss: 0.0838262 Test Loss: 0.0883332\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0792901\n",
      "\tspeed: 0.0527s/iter; left time: 1106.0900s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827553\n",
      "\tspeed: 0.0281s/iter; left time: 587.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0816290 Vali Loss: 0.0842234 Test Loss: 0.0882273\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829263\n",
      "\tspeed: 0.0550s/iter; left time: 1142.8870s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831176\n",
      "\tspeed: 0.0273s/iter; left time: 563.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0805962 Vali Loss: 0.0847038 Test Loss: 0.0883791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816610\n",
      "\tspeed: 0.0575s/iter; left time: 1181.3405s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787463\n",
      "\tspeed: 0.0276s/iter; left time: 564.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0797245 Vali Loss: 0.0845396 Test Loss: 0.0883748\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766695\n",
      "\tspeed: 0.0528s/iter; left time: 1073.0838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811797\n",
      "\tspeed: 0.0309s/iter; left time: 625.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0790013 Vali Loss: 0.0842658 Test Loss: 0.0882581\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0773436\n",
      "\tspeed: 0.0541s/iter; left time: 1086.6544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0750153\n",
      "\tspeed: 0.0282s/iter; left time: 563.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0784806 Vali Loss: 0.0848489 Test Loss: 0.0890048\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781072\n",
      "\tspeed: 0.0543s/iter; left time: 1079.4039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776325\n",
      "\tspeed: 0.0273s/iter; left time: 540.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0778847 Vali Loss: 0.0847653 Test Loss: 0.0893754\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0796271\n",
      "\tspeed: 0.0551s/iter; left time: 1082.2326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788494\n",
      "\tspeed: 0.0272s/iter; left time: 532.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0774273 Vali Loss: 0.0847762 Test Loss: 0.0897269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719526\n",
      "\tspeed: 0.0518s/iter; left time: 1006.1097s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759829\n",
      "\tspeed: 0.0291s/iter; left time: 562.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0770110 Vali Loss: 0.0850721 Test Loss: 0.0895426\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745691\n",
      "\tspeed: 0.0531s/iter; left time: 1020.3689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722817\n",
      "\tspeed: 0.0281s/iter; left time: 537.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0765886 Vali Loss: 0.0847122 Test Loss: 0.0897249\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0201936773955822, rmse:0.14210446178913116, mae:0.08804111182689667, rse:0.5378115773200989\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1329002\n",
      "\tspeed: 0.0291s/iter; left time: 642.7910s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175623\n",
      "\tspeed: 0.0281s/iter; left time: 619.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1417617 Vali Loss: 0.1047845 Test Loss: 0.1055077\n",
      "Validation loss decreased (inf --> 0.104784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0927295\n",
      "\tspeed: 0.0578s/iter; left time: 1264.0138s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941170\n",
      "\tspeed: 0.0277s/iter; left time: 604.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0963996 Vali Loss: 0.0871643 Test Loss: 0.0895704\n",
      "Validation loss decreased (0.104784 --> 0.087164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878410\n",
      "\tspeed: 0.0590s/iter; left time: 1278.2876s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902920\n",
      "\tspeed: 0.0280s/iter; left time: 603.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0870747 Vali Loss: 0.0847243 Test Loss: 0.0878319\n",
      "Validation loss decreased (0.087164 --> 0.084724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853640\n",
      "\tspeed: 0.0566s/iter; left time: 1213.5422s\n",
      "\titers: 200, epoch: 4 | loss: 0.0840227\n",
      "\tspeed: 0.0282s/iter; left time: 601.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0846555 Vali Loss: 0.0835151 Test Loss: 0.0876056\n",
      "Validation loss decreased (0.084724 --> 0.083515).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0851938\n",
      "\tspeed: 0.0580s/iter; left time: 1229.8414s\n",
      "\titers: 200, epoch: 5 | loss: 0.0813548\n",
      "\tspeed: 0.0306s/iter; left time: 645.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0830201 Vali Loss: 0.0840696 Test Loss: 0.0879182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0852846\n",
      "\tspeed: 0.0531s/iter; left time: 1114.5854s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810560\n",
      "\tspeed: 0.0272s/iter; left time: 567.2324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0818896 Vali Loss: 0.0842003 Test Loss: 0.0879094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0802038\n",
      "\tspeed: 0.0572s/iter; left time: 1187.9462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809201\n",
      "\tspeed: 0.0271s/iter; left time: 559.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0808258 Vali Loss: 0.0832934 Test Loss: 0.0873938\n",
      "Validation loss decreased (0.083515 --> 0.083293).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792483\n",
      "\tspeed: 0.0624s/iter; left time: 1281.8376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819951\n",
      "\tspeed: 0.0279s/iter; left time: 570.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 222 | Train Loss: 0.0800518 Vali Loss: 0.0839962 Test Loss: 0.0880267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774117\n",
      "\tspeed: 0.0541s/iter; left time: 1098.8363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0775325\n",
      "\tspeed: 0.0285s/iter; left time: 576.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0793224 Vali Loss: 0.0844191 Test Loss: 0.0877155\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0806580\n",
      "\tspeed: 0.0556s/iter; left time: 1116.7889s\n",
      "\titers: 200, epoch: 10 | loss: 0.0799583\n",
      "\tspeed: 0.0277s/iter; left time: 555.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0787225 Vali Loss: 0.0840966 Test Loss: 0.0883957\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771481\n",
      "\tspeed: 0.0573s/iter; left time: 1138.9736s\n",
      "\titers: 200, epoch: 11 | loss: 0.0804428\n",
      "\tspeed: 0.0278s/iter; left time: 549.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0780882 Vali Loss: 0.0844000 Test Loss: 0.0881920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0766762\n",
      "\tspeed: 0.0586s/iter; left time: 1151.7988s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793117\n",
      "\tspeed: 0.0274s/iter; left time: 535.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0776378 Vali Loss: 0.0840316 Test Loss: 0.0880184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769361\n",
      "\tspeed: 0.0577s/iter; left time: 1121.7394s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785047\n",
      "\tspeed: 0.0276s/iter; left time: 532.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0771586 Vali Loss: 0.0841548 Test Loss: 0.0880232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0777556\n",
      "\tspeed: 0.0529s/iter; left time: 1017.3781s\n",
      "\titers: 200, epoch: 14 | loss: 0.0767437\n",
      "\tspeed: 0.0300s/iter; left time: 573.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0767452 Vali Loss: 0.0836313 Test Loss: 0.0883247\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787518\n",
      "\tspeed: 0.0534s/iter; left time: 1014.7503s\n",
      "\titers: 200, epoch: 15 | loss: 0.0794870\n",
      "\tspeed: 0.0274s/iter; left time: 518.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0763562 Vali Loss: 0.0837894 Test Loss: 0.0880314\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0768457\n",
      "\tspeed: 0.0613s/iter; left time: 1150.8829s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772194\n",
      "\tspeed: 0.0280s/iter; left time: 523.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0760031 Vali Loss: 0.0840183 Test Loss: 0.0883679\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0778723\n",
      "\tspeed: 0.0571s/iter; left time: 1058.7481s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730445\n",
      "\tspeed: 0.0282s/iter; left time: 519.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0756556 Vali Loss: 0.0837157 Test Loss: 0.0881411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020205043256282806, rmse:0.14214444160461426, mae:0.08739381283521652, rse:0.5379629135131836\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:33.10s\n",
      "Intermediate time for IT: 00h:29m:38.75s\n",
      "Total time: 02h:35m:30.27s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.0827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1450  0.0880\n",
       "        96            0.0359  0.1894  0.1250\n",
       "        168           0.0388  0.1968  0.1327\n",
       "ES      24            0.0099  0.0993  0.0597\n",
       "        96            0.0190  0.1377  0.0879\n",
       "        168           0.0213  0.1460  0.0952\n",
       "FR      24            0.0100  0.1002  0.0552\n",
       "        96            0.0197  0.1405  0.0811\n",
       "        168           0.0222  0.1490  0.0876\n",
       "GB      24            0.0246  0.1570  0.0990\n",
       "        96            0.0411  0.2027  0.1390\n",
       "        168           0.0435  0.2085  0.1449\n",
       "IT      24            0.0101  0.1005  0.0573\n",
       "        96            0.0191  0.1380  0.0827\n",
       "        168           0.0202  0.1421  0.0877"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
