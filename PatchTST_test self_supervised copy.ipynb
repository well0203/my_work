{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain \n",
    "## Epochs = 10\n",
    "## Mask_ratio = 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=32, num_workers=0, features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=2, n_heads=8, d_model=512, d_ff=2048, dropout=0.05, head_dropout=0.0, mask_ratio=0.2, n_epochs_pretrain=50, lr=0.001, pretrained_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 6339084\n",
      "suggested_lr 5.590810182512223e-05\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 6339084\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.9256258263832384.\n",
      "              0       0.938697       0.925626          00:18\n",
      "Better model found at epoch 1 with valid_loss value: 0.9216505257068756.\n",
      "              1       0.919815       0.921651          00:18\n",
      "Better model found at epoch 2 with valid_loss value: 0.9177396670311229.\n",
      "              2       0.915497       0.917740          00:18\n",
      "              3       0.913634       0.920424          00:18\n",
      "              4       0.913856       0.918214          00:18\n",
      "Better model found at epoch 5 with valid_loss value: 0.9170504316263222.\n",
      "              5       0.912314       0.917050          00:18\n",
      "Better model found at epoch 6 with valid_loss value: 0.9147312347436941.\n",
      "              6       0.911901       0.914731          00:18\n",
      "Better model found at epoch 7 with valid_loss value: 0.7013120423108218.\n",
      "              7       0.729124       0.701312          00:18\n",
      "Better model found at epoch 8 with valid_loss value: 0.6890678238150936.\n",
      "              8       0.693489       0.689068          00:18\n",
      "^C\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain50_mask0.2_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain50_mask0.2_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "# 29       0.473083       0.481049          \n",
    "# Define parameters in a dictionary\n",
    "params = {\n",
    "    \"--dset\": \"IT\",\n",
    "    \"--mask_ratio\": 0.2,\n",
    "    \"--scaler_type\": \"minmax\",\n",
    "    \"--if_relu\": None,  # Flags that don't require a value\n",
    "    \"--batch_size\": 32,\n",
    "    \"--stride\": 12, # non-overlapping\n",
    "    \"--patch_len\": 12,\n",
    "    \"--n_layers\": 2,\n",
    "    \"--d_ff\": 2048,\n",
    "    \"--n_heads\": 8,\n",
    "    \"--d_model\": 512,\n",
    "    \"--dropout\": 0.05,\n",
    "    \"--head_dropout\": 0.0,\n",
    "    \"--n_epochs_pretrain\": 50,\n",
    "    \"--lr\": 0.001\n",
    "}\n",
    "\n",
    "# Build the command string\n",
    "command = \"python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py \"\n",
    "\n",
    "# Add parameters to the command\n",
    "for key, value in params.items():\n",
    "    if value is not None:\n",
    "        command += f\"{key} {value} \"\n",
    "    else:\n",
    "        command += f\"{key} \"  # Add flags with no value\n",
    "\n",
    "# Complete command\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(linear_prob_finetune=1, is_finetune=0, is_linear_probe=0, n_epochs_linear_probe=10, dset_finetune='IT', context_points=512, target_points=96, batch_size=32, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=2, n_heads=8, d_model=512, d_ff=2048, dropout=0.05, head_dropout=0.0, n_epochs_finetune=30, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain30_mask0.4_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 8397408\n",
      "weights from saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain30_mask0.4_model1.pth successfully transferred!\n",
      "\n",
      "suggested_lr 3.853528593710531e-05\n",
      "Performing linear probing followed by end-to-end fine-tuning\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 8397408\n",
      "weights from saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain30_mask0.4_model1.pth successfully transferred!\n",
      "\n",
      "Starting linear probing for 10 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.14541466560084418.\n",
      "              0       0.157233       0.145415       0.145415          00:07\n",
      "Better model found at epoch 1 with valid_loss value: 0.14422027364409581.\n",
      "              1       0.146588       0.144220       0.144220          00:07\n",
      "Better model found at epoch 2 with valid_loss value: 0.14405901965520748.\n",
      "              2       0.145694       0.144059       0.144059          00:07\n",
      "Better model found at epoch 3 with valid_loss value: 0.14318870500978947.\n",
      "              3       0.144977       0.143189       0.143189          00:07\n",
      "Better model found at epoch 4 with valid_loss value: 0.14269470264506204.\n",
      "              4       0.144302       0.142695       0.142695          00:07\n",
      "Better model found at epoch 5 with valid_loss value: 0.14201480378165685.\n",
      "              5       0.143612       0.142015       0.142015          00:07\n",
      "Better model found at epoch 6 with valid_loss value: 0.14145015160954028.\n",
      "              6       0.142918       0.141450       0.141450          00:07\n",
      "Better model found at epoch 7 with valid_loss value: 0.14091860442941415.\n",
      "              7       0.142328       0.140919       0.140919          00:07\n",
      "Better model found at epoch 8 with valid_loss value: 0.14056839473466742.\n",
      "              8       0.141852       0.140568       0.140568          00:07\n",
      "Better model found at epoch 9 with valid_loss value: 0.14043081980395647.\n",
      "              9       0.141602       0.140431       0.140431          00:07\n",
      "Starting full fine-tuning for 20 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "              0       0.141793       0.141072       0.141072          00:07\n",
      "              1       0.142660       0.142153       0.142153          00:07\n",
      "              2       0.143395       0.142424       0.142424          00:07\n",
      "              3       0.143370       0.142675       0.142675          00:07\n",
      "              4       0.142984       0.142588       0.142588          00:07\n",
      "              5       0.142472       0.141201       0.141201          00:07\n",
      "              6       0.141855       0.140904       0.140904          00:07\n",
      "              7       0.141328       0.140562       0.140562          00:07\n",
      "Better model found at epoch 8 with valid_loss value: 0.14016304978323332.\n",
      "              8       0.140902       0.140163       0.140163          00:07\n",
      "Better model found at epoch 9 with valid_loss value: 0.1400971775039412.\n",
      "              9       0.140655       0.140097       0.140097          00:07\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.14009277741049633.\n",
      "              0       0.140557       0.140093       0.140093          00:17\n",
      "Better model found at epoch 1 with valid_loss value: 0.13992248485493797.\n",
      "              1       0.140291       0.139922       0.139922          00:18\n",
      "              2       0.140015       0.139970       0.139970          00:18\n",
      "Better model found at epoch 3 with valid_loss value: 0.1397542383924939.\n",
      "              3       0.139665       0.139754       0.139754          00:16\n",
      "              4       0.139262       0.140362       0.140362          00:17\n",
      "              5       0.138708       0.140276       0.140276          00:16\n",
      "              6       0.138039       0.140509       0.140509          00:16\n",
      "              7       0.137265       0.140976       0.140976          00:16\n",
      "              8       0.136504       0.141863       0.141863          00:16\n",
      "              9       0.135698       0.141443       0.141443          00:16\n",
      "             10       0.134982       0.141973       0.141973          00:16\n",
      "             11       0.134275       0.141845       0.141845          00:16\n",
      "             12       0.133621       0.141561       0.141561          00:17\n",
      "             13       0.132955       0.141299       0.141299          00:16\n",
      "             14       0.132336       0.141427       0.141427          00:16\n",
      "             15       0.131790       0.143236       0.143236          00:16\n",
      "             16       0.131240       0.141973       0.141973          00:16\n",
      "             17       0.130758       0.142674       0.142674          00:16\n",
      "             18       0.130272       0.142039       0.142039          00:16\n",
      "             19       0.129924       0.142425       0.142425          00:17\n",
      "             20       0.129521       0.142214       0.142214          00:17\n",
      "             21       0.129201       0.142585       0.142585          00:17\n",
      "             22       0.128849       0.142330       0.142330          00:16\n",
      "             23       0.128654       0.142228       0.142228          00:16\n",
      "             24       0.128412       0.142361       0.142361          00:16\n",
      "             25       0.128242       0.142377       0.142377          00:16\n",
      "             26       0.128097       0.142383       0.142383          00:16\n",
      "             27       0.128026       0.142507       0.142507          00:16\n",
      "             28       0.127971       0.142462       0.142462          00:16\n",
      "             29       0.127920       0.142389       0.142389          00:16\n",
      "Linear probing and finetune completed\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 8397408\n",
      "scores: mse: 0.03538904 rmse: 0.18811975 mae: 0.15005693\n",
      "----------- Complete! -----------\n"
     ]
    }
   ],
   "source": [
    "# Define parameters in a dictionary\n",
    "params = {\n",
    "    \"--dset\": \"IT\",\n",
    "    \"--linear_prob_finetune\": 1,\n",
    "    \"--pretrained_model\": \"saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain30_mask0.4_model1.pth\",    \n",
    "    \"--scaler_type\": \"minmax\",\n",
    "    \"--if_relu\": None,  # Flags that don't require a value\n",
    "    \"--batch_size\": 32,\n",
    "    \"--stride\": 12,\n",
    "    \"--patch_len\": 12,\n",
    "    \"--n_layers\": 2,\n",
    "    \"--d_ff\": 2048,\n",
    "    \"--n_heads\": 8,\n",
    "    \"--d_model\": 512,\n",
    "    \"--dropout\": 0.05,\n",
    "    \"--head_dropout\": 0.0,\n",
    "    \"--n_epochs_finetune\": 30,\n",
    "    \"--n_epochs_linear_probe\": 10\n",
    "}\n",
    "\n",
    "# Build the command string\n",
    "command = \"python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py \"\n",
    "\n",
    "# Add parameters to the command\n",
    "for key, value in params.items():\n",
    "    if value is not None:\n",
    "        command += f\"{key} {value} \"\n",
    "    else:\n",
    "        command += f\"{key} \"  # Add flags with no value\n",
    "\n",
    "# Run the command with !\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.000298364724028334\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.9396839560872661.\n",
      "              0       0.960868       0.939684          00:11\n",
      "Better model found at epoch 1 with valid_loss value: 0.936014099369406.\n",
      "              1       0.933757       0.936014          00:11\n",
      "Better model found at epoch 2 with valid_loss value: 0.9334741628102116.\n",
      "              2       0.930378       0.933474          00:11\n",
      "Better model found at epoch 3 with valid_loss value: 0.7131503000406835.\n",
      "              3       0.765316       0.713150          00:11\n",
      "Better model found at epoch 4 with valid_loss value: 0.7123715132984133.\n",
      "              4       0.713887       0.712372          00:11\n",
      "Better model found at epoch 5 with valid_loss value: 0.7093881903478437.\n",
      "              5       0.711447       0.709388          00:11\n",
      "              6       0.709750       0.710327          00:11\n",
      "              7       0.708047       0.709833          00:11\n",
      "Better model found at epoch 8 with valid_loss value: 0.7070547701383239.\n",
      "              8       0.706682       0.707055          00:11\n",
      "              9       0.707885       0.707937          00:11\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4 --scaler_type minmax --if_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(is_finetune=1, is_linear_probe=0, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.2_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 0.00011768119524349978\n",
      "end-to-end finetuning\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.03460147072378458.\n",
      "              0       0.042033       0.034601       0.152185          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.0333345020564229.\n",
      "              1       0.035798       0.033335       0.147897          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.03277997109247864.\n",
      "              2       0.034525       0.032780       0.146029          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.03252638218556118.\n",
      "              3       0.033726       0.032526       0.144965          00:02\n",
      "Better model found at epoch 4 with valid_loss value: 0.03236253333343928.\n",
      "              4       0.033212       0.032363       0.144487          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.03230625832342733.\n",
      "              5       0.032906       0.032306       0.144476          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.032278213935523034.\n",
      "              6       0.032711       0.032278       0.144110          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.03222903817334342.\n",
      "              7       0.032558       0.032229       0.144060          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.032199307745117985.\n",
      "              8       0.032491       0.032199       0.143825          00:02\n",
      "Better model found at epoch 9 with valid_loss value: 0.03218804678362108.\n",
      "              9       0.032462       0.032188       0.143845          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.03212651500282877.\n",
      "              0       0.032431       0.032127       0.143555          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.0320320868123538.\n",
      "              1       0.032273       0.032032       0.143026          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.03191563580655004.\n",
      "              2       0.032034       0.031916       0.142443          00:10\n",
      "Better model found at epoch 3 with valid_loss value: 0.03179110471944289.\n",
      "              3       0.031767       0.031791       0.142093          00:10\n",
      "              4       0.031502       0.031792       0.142047          00:10\n",
      "              5       0.031277       0.031823       0.141809          00:09\n",
      "              6       0.031070       0.031855       0.141777          00:10\n",
      "              7       0.030878       0.031848       0.141774          00:10\n",
      "              8       0.030716       0.031928       0.141821          00:11\n",
      "              9       0.030553       0.031869       0.141748          00:10\n",
      "             10       0.030400       0.032169       0.142450          00:10\n",
      "             11       0.030259       0.032027       0.141980          00:10\n",
      "             12       0.030156       0.032077       0.142149          00:10\n",
      "             13       0.030062       0.032000       0.142007          00:04\n",
      "             14       0.029978       0.032048       0.142020          00:04\n",
      "             15       0.029923       0.032062       0.142047          00:04\n",
      "             16       0.029878       0.032079       0.142072          00:04\n",
      "             17       0.029831       0.032098       0.142140          00:10\n",
      "             18       0.029822       0.032100       0.142139          00:10\n",
      "             19       0.029821       0.032032       0.142040          00:10\n",
      "finetune completed\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "scores: mse: 0.03523118 rmse: 0.1876997 mae: 0.15119967\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py\", line 230, in <module>\n",
      "    out = test_func(args.save_path+args.save_finetuned_model)         \n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py\", line 216, in test_func\n",
      "    pd.DataFrame(np.array(out[2]).reshape(1,-1), columns=['mse','mae']).to_csv(args.save_path + args.save_finetuned_model + '_acc.csv', float_format='%.6f', index=False)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/frame.py\", line 722, in __init__\n",
      "    mgr = ndarray_to_mgr(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/internals/construction.py\", line 349, in ndarray_to_mgr\n",
      "    _check_values_indices_shape_match(values, index, columns)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/internals/construction.py\", line 420, in _check_values_indices_shape_match\n",
      "    raise ValueError(f\"Shape of passed values is {passed}, indices imply {implied}\")\n",
      "ValueError: Shape of passed values is (1, 3), indices imply (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# score: [array(0.03520434, dtype=float32), array(0.15043405, dtype=float32)]\n",
    "# scores: mse: 0.03537787 mae: 0.15080553\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py --dset IT --is_finetune 1 --pretrained_model saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.2_model1.pth --scaler_type minmax --if_relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.0002477076355991711\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.8858883937652563.\n",
      "              0       0.933535       0.885888          00:11\n",
      "^C\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.00017073526474706903\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.8872300746287632.\n",
      "              0       0.942443       0.887230          00:08\n",
      "Better model found at epoch 1 with valid_loss value: 0.8765522496694467.\n",
      "              1       0.879432       0.876552          00:05\n",
      "^C\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(is_finetune=1, is_linear_probe=0, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 8.111308307896872e-05\n",
      "end-to-end finetuning\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mse           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.41477148119660295.\n",
      "              0       0.755971       0.414771       0.414771          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.36928234177939384.\n",
      "              1       0.528718       0.369282       0.369282          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.3521397763679821.\n",
      "              2       0.458563       0.352140       0.352140          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.34393247972182667.\n",
      "              3       0.412447       0.343932       0.343933          00:02\n",
      "              4       0.387422       0.344598       0.344598          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.33935693875864525.\n",
      "              5       0.373936       0.339357       0.339357          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.33897092243439786.\n",
      "              6       0.365762       0.338971       0.338971          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.33810230624491455.\n",
      "              7       0.361831       0.338102       0.338102          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.33741946736421885.\n",
      "              8       0.359460       0.337419       0.337419          00:02\n",
      "              9       0.358488       0.337625       0.337625          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss      valid_mse           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.33576598574806754.\n",
      "              0       0.356681       0.335766       0.335766          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.33318790842402357.\n",
      "              1       0.352328       0.333188       0.333188          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.33019371932846825.\n",
      "              2       0.346426       0.330194       0.330194          00:10\n",
      "Better model found at epoch 3 with valid_loss value: 0.32762317083248577.\n",
      "              3       0.339938       0.327623       0.327623          00:10\n",
      "              4       0.332391       0.328190       0.328189          00:10\n",
      "Better model found at epoch 5 with valid_loss value: 0.3253272159784378.\n",
      "              5       0.325821       0.325327       0.325327          00:09\n",
      "              6       0.319472       0.325361       0.325361          00:10\n",
      "Better model found at epoch 7 with valid_loss value: 0.3207517743401648.\n",
      "              7       0.314101       0.320752       0.320752          00:04\n",
      "              8       0.309127       0.324733       0.324733          00:04\n",
      "              9       0.305546       0.322477       0.322477          00:05\n",
      "             10       0.302396       0.320871       0.320871          00:10\n",
      "             11       0.298669       0.322160       0.322160          00:08\n",
      "             12       0.295239       0.321158       0.321158          00:09\n",
      "             13       0.293238       0.324921       0.324921          00:04\n",
      "             14       0.291271       0.326656       0.326657          00:04\n",
      "             15       0.290286       0.325635       0.325635          00:10\n",
      "             16       0.288479       0.324677       0.324677          00:10\n",
      "             17       0.287576       0.324321       0.324321          00:10\n",
      "             18       0.287653       0.324585       0.324585          00:10\n",
      "             19       0.287561       0.324591       0.324591          00:10\n",
      "finetune completed\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "score: [array(0.34755072, dtype=float32), array(0.37232623, dtype=float32)]\n",
      "----------- Complete! -----------\n"
     ]
    }
   ],
   "source": [
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py --dset IT --is_finetune 1 --pretrained_model saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
