{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time LLM\n",
    "## small, 15%, 15%\n",
    "\n",
    "### torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 610.88 MiB is free. Process 42461 has 2.24 GiB memory in use. Process 20767 has 1.78 GiB memory in use. Process 10768 has 2.56 GiB memory in use. Process 42631 has 13.69 GiB memory in use. Process 47813 has 7.21 GiB memory in use. Including non-PyTorch memory, this process has 3.63 GiB memory in use. Of the allocated memory 2.62 GiB is allocated by PyTorch, and 338.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Tesla V100-PCIE-32GB\n",
      "Device 1: Tesla V100-PCIE-32GB\n",
      "Device 2: Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the number of available CUDA devices\n",
    "num_devices = torch.cuda.device_count()\n",
    "\n",
    "# Loop through each device and print its name\n",
    "for i in range(num_devices):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "[2024-05-03 15:31:27,516] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 15:31:28,873] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 15:31:28,873] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 15:31:28,873] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 15:31:29,768] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-03 15:31:29,769] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 15:31:30,539] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 15:31:30,540] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 15:31:30,540] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 15:31:30,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 15:31:30,541] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 15:31:30,541] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 15:31:31,003] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 15:31:31,004] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,004] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.18 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,143] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 15:31:31,143] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,144] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.22 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,144] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 15:31:31,313] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 15:31:31,315] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,315] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.25 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 15:31:31,317] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faa79743610>\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:15,  6.72it/s]\titers: 100, epoch: 1 | loss: 0.5468196\n",
      "\tspeed: 0.2003s/iter; left time: 734.1552s\n",
      "199it [00:30,  7.22it/s]\titers: 200, epoch: 1 | loss: 0.4214458\n",
      "\tspeed: 0.1453s/iter; left time: 518.0681s\n",
      "299it [00:45,  6.76it/s]\titers: 300, epoch: 1 | loss: 0.4011628\n",
      "\tspeed: 0.1504s/iter; left time: 521.3495s\n",
      "399it [01:00,  6.01it/s]\titers: 400, epoch: 1 | loss: 0.5255764\n",
      "\tspeed: 0.1471s/iter; left time: 495.2141s\n",
      "499it [01:14,  6.59it/s]\titers: 500, epoch: 1 | loss: 0.2808782\n",
      "\tspeed: 0.1478s/iter; left time: 482.6114s\n",
      "599it [01:30,  6.71it/s]\titers: 600, epoch: 1 | loss: 0.5445550\n",
      "\tspeed: 0.1548s/iter; left time: 490.0809s\n",
      "699it [01:45,  7.23it/s]\titers: 700, epoch: 1 | loss: 0.2627008\n",
      "\tspeed: 0.1484s/iter; left time: 454.8922s\n",
      "799it [02:00,  7.21it/s]\titers: 800, epoch: 1 | loss: 0.3114898\n",
      "\tspeed: 0.1523s/iter; left time: 451.8232s\n",
      "899it [02:16,  5.85it/s]\titers: 900, epoch: 1 | loss: 0.2767449\n",
      "\tspeed: 0.1640s/iter; left time: 470.0796s\n",
      "999it [02:32,  6.19it/s]\titers: 1000, epoch: 1 | loss: 0.2889755\n",
      "\tspeed: 0.1538s/iter; left time: 425.2956s\n",
      "1099it [02:47,  7.41it/s]\titers: 1100, epoch: 1 | loss: 0.2072158\n",
      "\tspeed: 0.1547s/iter; left time: 412.5457s\n",
      "1199it [03:02,  6.28it/s]\titers: 1200, epoch: 1 | loss: 0.1756039\n",
      "\tspeed: 0.1485s/iter; left time: 380.9509s\n",
      "1299it [03:17,  7.17it/s]\titers: 1300, epoch: 1 | loss: 0.1881783\n",
      "\tspeed: 0.1536s/iter; left time: 378.8370s\n",
      "1399it [03:33,  7.34it/s]\titers: 1400, epoch: 1 | loss: 0.2366187\n",
      "\tspeed: 0.1521s/iter; left time: 359.9760s\n",
      "1499it [03:47,  7.32it/s]\titers: 1500, epoch: 1 | loss: 0.4451137\n",
      "\tspeed: 0.1472s/iter; left time: 333.5190s\n",
      "1599it [04:02,  7.09it/s]\titers: 1600, epoch: 1 | loss: 0.4389757\n",
      "\tspeed: 0.1503s/iter; left time: 325.5284s\n",
      "1699it [04:17,  5.95it/s]\titers: 1700, epoch: 1 | loss: 0.2678942\n",
      "\tspeed: 0.1499s/iter; left time: 309.6764s\n",
      "1799it [04:32,  7.13it/s]\titers: 1800, epoch: 1 | loss: 0.2379295\n",
      "\tspeed: 0.1463s/iter; left time: 287.5315s\n",
      "1899it [04:47,  6.17it/s]\titers: 1900, epoch: 1 | loss: 0.1710269\n",
      "\tspeed: 0.1512s/iter; left time: 282.0733s\n",
      "1999it [05:02,  6.78it/s]\titers: 2000, epoch: 1 | loss: 0.1779455\n",
      "\tspeed: 0.1474s/iter; left time: 260.2522s\n",
      "2099it [05:17,  6.90it/s]\titers: 2100, epoch: 1 | loss: 0.2390940\n",
      "\tspeed: 0.1471s/iter; left time: 245.0705s\n",
      "2199it [05:32,  7.43it/s]\titers: 2200, epoch: 1 | loss: 0.4671702\n",
      "\tspeed: 0.1508s/iter; left time: 236.0952s\n",
      "2299it [05:45,  7.29it/s]\titers: 2300, epoch: 1 | loss: 0.2660964\n",
      "\tspeed: 0.1376s/iter; left time: 201.6830s\n",
      "2399it [06:00,  6.20it/s]\titers: 2400, epoch: 1 | loss: 0.4123612\n",
      "\tspeed: 0.1493s/iter; left time: 203.9067s\n",
      "2499it [06:14,  7.27it/s]\titers: 2500, epoch: 1 | loss: 0.1834874\n",
      "\tspeed: 0.1407s/iter; left time: 178.1314s\n",
      "2599it [06:28,  7.25it/s]\titers: 2600, epoch: 1 | loss: 0.2996213\n",
      "\tspeed: 0.1413s/iter; left time: 164.7838s\n",
      "2699it [06:44,  6.28it/s]\titers: 2700, epoch: 1 | loss: 0.4658841\n",
      "\tspeed: 0.1546s/iter; left time: 164.7644s\n",
      "2799it [07:00,  6.65it/s]\titers: 2800, epoch: 1 | loss: 0.2089916\n",
      "\tspeed: 0.1591s/iter; left time: 153.7254s\n",
      "2899it [07:15,  6.61it/s]\titers: 2900, epoch: 1 | loss: 0.3584861\n",
      "\tspeed: 0.1473s/iter; left time: 127.5209s\n",
      "2999it [07:30,  6.75it/s]\titers: 3000, epoch: 1 | loss: 0.3548172\n",
      "\tspeed: 0.1499s/iter; left time: 114.8503s\n",
      "3099it [07:44,  6.36it/s]\titers: 3100, epoch: 1 | loss: 0.3082316\n",
      "\tspeed: 0.1497s/iter; left time: 99.6967s\n",
      "3199it [07:59,  6.72it/s]\titers: 3200, epoch: 1 | loss: 0.4097749\n",
      "\tspeed: 0.1485s/iter; left time: 84.0279s\n",
      "3299it [08:15,  7.03it/s]\titers: 3300, epoch: 1 | loss: 0.2170641\n",
      "\tspeed: 0.1514s/iter; left time: 70.5686s\n",
      "3399it [08:29,  6.03it/s]\titers: 3400, epoch: 1 | loss: 0.4186157\n",
      "\tspeed: 0.1447s/iter; left time: 52.9657s\n",
      "3499it [08:44,  6.84it/s]\titers: 3500, epoch: 1 | loss: 0.2876329\n",
      "\tspeed: 0.1528s/iter; left time: 40.6424s\n",
      "3599it [08:59,  6.00it/s]\titers: 3600, epoch: 1 | loss: 0.3456867\n",
      "\tspeed: 0.1467s/iter; left time: 24.3444s\n",
      "3699it [09:14,  7.14it/s]\titers: 3700, epoch: 1 | loss: 0.2103202\n",
      "\tspeed: 0.1515s/iter; left time: 9.9983s\n",
      "3765it [09:24,  6.67it/s]\n",
      "Epoch: 1 cost time: 564.7272717952728\n",
      "810it [01:06, 12.18it/s]\n",
      "807it [01:04, 12.60it/s]\n",
      "Epoch: 1 | Train Loss: 0.3082688 Vali Loss: 0.3276033 Test Loss: 0.3916928 MAE Loss: 0.3958873\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 11.988454163074493 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.1 and COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 00:55:33,780] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 00:55:34,706] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 00:55:34,706] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 00:55:34,706] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 00:55:35,629] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 00:55:35,630] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 00:55:36,489] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 00:55:36,490] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 00:55:36,490] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 00:55:36,491] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 00:55:36,491] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 00:55:36,491] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.55 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,877] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 00:55:36,878] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,878] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.65 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,878] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 00:55:36,998] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 00:55:36,999] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,999] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.91 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.1], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8efcb28d90>\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:06, 19.71it/s]\titers: 100, epoch: 1 | loss: 2.3399429\n",
      "\tspeed: 0.1048s/iter; left time: 384.2641s\n",
      "197it [00:11, 22.15it/s]\titers: 200, epoch: 1 | loss: 0.7920554\n",
      "\tspeed: 0.0490s/iter; left time: 174.8364s\n",
      "297it [00:16, 21.15it/s]\titers: 300, epoch: 1 | loss: 0.8496119\n",
      "\tspeed: 0.0480s/iter; left time: 166.2888s\n",
      "399it [00:21, 19.41it/s]\titers: 400, epoch: 1 | loss: 0.7877753\n",
      "\tspeed: 0.0529s/iter; left time: 178.0721s\n",
      "499it [00:27, 19.71it/s]\titers: 500, epoch: 1 | loss: 0.5706695\n",
      "\tspeed: 0.0521s/iter; left time: 170.2929s\n",
      "598it [00:32, 19.76it/s]\titers: 600, epoch: 1 | loss: 0.6946025\n",
      "\tspeed: 0.0507s/iter; left time: 160.4279s\n",
      "699it [00:37, 19.68it/s]\titers: 700, epoch: 1 | loss: 0.6073106\n",
      "\tspeed: 0.0509s/iter; left time: 156.0419s\n",
      "797it [00:42, 19.04it/s]\titers: 800, epoch: 1 | loss: 0.4599146\n",
      "\tspeed: 0.0558s/iter; left time: 165.4963s\n",
      "898it [00:47, 19.78it/s]\titers: 900, epoch: 1 | loss: 0.4064088\n",
      "\tspeed: 0.0505s/iter; left time: 144.7993s\n",
      "998it [00:52, 19.55it/s]\titers: 1000, epoch: 1 | loss: 0.4211301\n",
      "\tspeed: 0.0506s/iter; left time: 140.0576s\n",
      "1098it [00:58, 19.61it/s]\titers: 1100, epoch: 1 | loss: 0.3501645\n",
      "\tspeed: 0.0528s/iter; left time: 140.6342s\n",
      "1198it [01:03, 19.80it/s]\titers: 1200, epoch: 1 | loss: 0.4622425\n",
      "\tspeed: 0.0514s/iter; left time: 131.7736s\n",
      "1299it [01:08, 19.71it/s]\titers: 1300, epoch: 1 | loss: 0.5496085\n",
      "\tspeed: 0.0505s/iter; left time: 124.6213s\n",
      "1398it [01:13, 19.12it/s]\titers: 1400, epoch: 1 | loss: 0.4305887\n",
      "\tspeed: 0.0497s/iter; left time: 117.5330s\n",
      "1498it [01:18, 19.79it/s]\titers: 1500, epoch: 1 | loss: 0.5792931\n",
      "\tspeed: 0.0503s/iter; left time: 113.8895s\n",
      "1598it [01:23, 19.74it/s]\titers: 1600, epoch: 1 | loss: 0.8634565\n",
      "\tspeed: 0.0514s/iter; left time: 111.3422s\n",
      "1698it [01:28, 19.72it/s]\titers: 1700, epoch: 1 | loss: 0.4591581\n",
      "\tspeed: 0.0513s/iter; left time: 106.0389s\n",
      "1798it [01:33, 19.44it/s]\titers: 1800, epoch: 1 | loss: 0.5615884\n",
      "\tspeed: 0.0497s/iter; left time: 97.6214s\n",
      "1899it [01:38, 19.12it/s]\titers: 1900, epoch: 1 | loss: 0.2650222\n",
      "\tspeed: 0.0521s/iter; left time: 97.2151s\n",
      "1998it [01:43, 19.35it/s]\titers: 2000, epoch: 1 | loss: 0.2934964\n",
      "\tspeed: 0.0513s/iter; left time: 90.5302s\n",
      "2099it [01:48, 24.81it/s]\titers: 2100, epoch: 1 | loss: 0.4234182\n",
      "\tspeed: 0.0438s/iter; left time: 73.0245s\n",
      "2198it [01:52, 24.55it/s]\titers: 2200, epoch: 1 | loss: 0.8064783\n",
      "\tspeed: 0.0407s/iter; left time: 63.7582s\n",
      "2297it [01:56, 24.29it/s]\titers: 2300, epoch: 1 | loss: 0.4523402\n",
      "\tspeed: 0.0426s/iter; left time: 62.4038s\n",
      "2399it [02:00, 24.59it/s]\titers: 2400, epoch: 1 | loss: 0.8422226\n",
      "\tspeed: 0.0418s/iter; left time: 57.0409s\n",
      "2498it [02:04, 24.41it/s]\titers: 2500, epoch: 1 | loss: 0.3995953\n",
      "\tspeed: 0.0408s/iter; left time: 51.7143s\n",
      "2597it [02:09, 24.43it/s]\titers: 2600, epoch: 1 | loss: 0.5259956\n",
      "\tspeed: 0.0411s/iter; left time: 47.9438s\n",
      "2698it [02:14, 18.66it/s]\titers: 2700, epoch: 1 | loss: 0.6131414\n",
      "\tspeed: 0.0523s/iter; left time: 55.7895s\n",
      "2799it [02:19, 19.30it/s]\titers: 2800, epoch: 1 | loss: 0.3428200\n",
      "\tspeed: 0.0535s/iter; left time: 51.6506s\n",
      "2899it [02:24, 19.18it/s]\titers: 2900, epoch: 1 | loss: 0.6192741\n",
      "\tspeed: 0.0509s/iter; left time: 44.1182s\n",
      "2997it [02:29, 20.83it/s]\titers: 3000, epoch: 1 | loss: 0.6037298\n",
      "\tspeed: 0.0507s/iter; left time: 38.8089s\n",
      "3099it [02:35, 18.09it/s]\titers: 3100, epoch: 1 | loss: 0.5096310\n",
      "\tspeed: 0.0525s/iter; left time: 34.9383s\n",
      "3198it [02:40, 21.59it/s]\titers: 3200, epoch: 1 | loss: 0.8142599\n",
      "\tspeed: 0.0518s/iter; left time: 29.3185s\n",
      "3298it [02:45, 19.31it/s]\titers: 3300, epoch: 1 | loss: 0.3007298\n",
      "\tspeed: 0.0535s/iter; left time: 24.9203s\n",
      "3398it [02:50, 19.55it/s]\titers: 3400, epoch: 1 | loss: 0.7066584\n",
      "\tspeed: 0.0525s/iter; left time: 19.2007s\n",
      "3498it [02:56, 19.68it/s]\titers: 3500, epoch: 1 | loss: 0.7107752\n",
      "\tspeed: 0.0549s/iter; left time: 14.6028s\n",
      "3598it [03:01, 19.28it/s]\titers: 3600, epoch: 1 | loss: 0.6457136\n",
      "\tspeed: 0.0507s/iter; left time: 8.4086s\n",
      "3699it [03:07, 18.12it/s]\titers: 3700, epoch: 1 | loss: 0.4646868\n",
      "\tspeed: 0.0557s/iter; left time: 3.6784s\n",
      "3765it [03:10, 19.76it/s]\n",
      "Epoch: 1 cost time: 190.57677745819092\n",
      "810it [00:21, 37.58it/s]\n",
      "807it [00:22, 36.60it/s]\n",
      "Epoch: 1 | Train Loss: 2.8133810 Vali Loss: 1.0487908 Test Loss: 1.3057802 MAE Loss: 0.8279922\n",
      "lr = 0.0993844171\n",
      "Total time: 4.262420868873596 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 16:00:53 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             36W /  250W |    6770MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off |   00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   41C    P0             62W /  250W |   26301MiB /  32768MiB |     35%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                Off |   00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   26C    P8             13W /  250W |       8MiB /  23040MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    0   N/A  N/A     10768    C+G   ...aries/Linux/CarlaUE4-Linux-Shipping       2624MiB |\n",
      "|    0   N/A  N/A     20767      C   ...1/reinbene/bene/MA/myenv/bin/python       1826MiB |\n",
      "|    0   N/A  N/A     42461      C   ...1/reinbene/bene/MA/myenv/bin/python       2298MiB |\n",
      "|    1   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    1   N/A  N/A     58879      C   python                                      26292MiB |\n",
      "|    2   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "learning_rate 0.1\n",
      "lr 0.1\n",
      "[2024-05-06 16:01:07,517] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 16:01:08,061] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 16:01:08,061] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 16:01:08,061] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 16:01:08,836] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 16:01:08,836] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 16:01:09,380] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 16:01:09,381] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 16:01:09,381] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 16:01:09,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 16:01:09,382] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 16:01:09,382] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 16:01:09,383] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 16:01:09,383] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 16:01:09,383] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 16:01:09,383] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 16:01:09,737] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 16:01:09,738] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:01:09,738] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.76 GB, percent = 16.3%\n",
      "[2024-05-06 16:01:09,911] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 16:01:09,912] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:01:09,912] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.75 GB, percent = 16.3%\n",
      "[2024-05-06 16:01:09,912] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 16:01:10,013] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 16:01:10,014] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:01:10,014] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.75 GB, percent = 16.3%\n",
      "[2024-05-06 16:01:10,014] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 16:01:10,015] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 16:01:10,015] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 16:01:10,015] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 16:01:10,015] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8fdc8d6810>\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 8\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   train_batch_size ............. 192\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 16:01:10,016] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 16:01:10,017] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 8, \n",
      "    \"train_batch_size\": 192, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:16,  6.19it/s]\titers: 100, epoch: 1 | loss: 1.3035094\n",
      "\tspeed: 0.1960s/iter; left time: 708.3743s\n",
      "199it [00:32,  6.31it/s]\titers: 200, epoch: 1 | loss: 0.6135600\n",
      "\tspeed: 0.1600s/iter; left time: 562.3661s\n",
      "206it [00:33,  6.27it/s]^C\n",
      "206it [00:33,  6.09it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 234, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 2002, in backward\n",
      "    self.allreduce_gradients()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1918, in allreduce_gradients\n",
      "    self.optimizer.overlapping_partition_gradients_reduce_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 859, in overlapping_partition_gradients_reduce_epilogue\n",
      "    self.independent_gradient_partition_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 760, in independent_gradient_partition_epilogue\n",
      "    get_accelerator().synchronize()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/accelerator/cuda_accelerator.py\", line 77, in synchronize\n",
      "    return torch.cuda.synchronize(device_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 801, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 0.7441335280736288 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print / debug learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "learning_rate 0.1\n",
      "lr 0.1\n",
      "[2024-05-06 16:08:14,219] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 16:08:14,591] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 16:08:14,591] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 16:08:14,591] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 16:08:15,343] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 16:08:15,344] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 16:08:15,962] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 16:08:15,962] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 16:08:15,962] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 16:08:15,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 16:08:15,963] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 16:08:15,963] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 16:08:15,963] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 16:08:15,963] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 16:08:15,963] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 16:08:15,963] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 16:08:16,318] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 16:08:16,318] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:08:16,319] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.46 GB, percent = 16.4%\n",
      "[2024-05-06 16:08:16,439] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 16:08:16,440] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:08:16,440] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.46 GB, percent = 16.4%\n",
      "[2024-05-06 16:08:16,440] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 16:08:16,540] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 16:08:16,541] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:08:16,541] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.46 GB, percent = 16.4%\n",
      "[2024-05-06 16:08:16,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 16:08:16,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 16:08:16,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 16:08:16,541] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb951431110>\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 16:08:16,542] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 16:08:16,543] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 16:08:16,544] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:17,  5.90it/s]\titers: 100, epoch: 1 | loss: 0.7224666\n",
      "\tspeed: 0.2003s/iter; left time: 723.8384s\n",
      "199it [00:34,  5.94it/s]\titers: 200, epoch: 1 | loss: 0.3539959\n",
      "\tspeed: 0.1690s/iter; left time: 593.8891s\n",
      "299it [00:51,  5.93it/s]\titers: 300, epoch: 1 | loss: 0.3806745\n",
      "\tspeed: 0.1686s/iter; left time: 575.6918s\n",
      "399it [01:07,  5.93it/s]\titers: 400, epoch: 1 | loss: 0.2579581\n",
      "\tspeed: 0.1686s/iter; left time: 558.6385s\n",
      "499it [01:24,  5.93it/s]\titers: 500, epoch: 1 | loss: 0.2964526\n",
      "\tspeed: 0.1688s/iter; left time: 542.5140s\n",
      "599it [01:41,  5.92it/s]\titers: 600, epoch: 1 | loss: 0.3597670\n",
      "\tspeed: 0.1687s/iter; left time: 525.2596s\n",
      "699it [01:58,  5.94it/s]\titers: 700, epoch: 1 | loss: 0.5668161\n",
      "\tspeed: 0.1686s/iter; left time: 508.0802s\n",
      "799it [02:15,  5.89it/s]\titers: 800, epoch: 1 | loss: 0.4650008\n",
      "\tspeed: 0.1691s/iter; left time: 492.7156s\n",
      "899it [02:32,  5.87it/s]\titers: 900, epoch: 1 | loss: 0.5931702\n",
      "\tspeed: 0.1700s/iter; left time: 478.4019s\n",
      "999it [02:49,  5.86it/s]\titers: 1000, epoch: 1 | loss: 0.4793293\n",
      "\tspeed: 0.1701s/iter; left time: 461.6519s\n",
      "1099it [03:06,  5.88it/s]\titers: 1100, epoch: 1 | loss: 0.3929631\n",
      "\tspeed: 0.1702s/iter; left time: 444.8555s\n",
      "1199it [03:23,  5.88it/s]\titers: 1200, epoch: 1 | loss: 0.4431814\n",
      "\tspeed: 0.1698s/iter; left time: 426.7661s\n",
      "1299it [03:40,  5.89it/s]\titers: 1300, epoch: 1 | loss: 0.3253015\n",
      "\tspeed: 0.1697s/iter; left time: 409.6300s\n",
      "1399it [03:57,  5.90it/s]\titers: 1400, epoch: 1 | loss: 0.4308687\n",
      "\tspeed: 0.1697s/iter; left time: 392.5893s\n",
      "1499it [04:14,  5.89it/s]\titers: 1500, epoch: 1 | loss: 0.4591449\n",
      "\tspeed: 0.1701s/iter; left time: 376.6376s\n",
      "1599it [04:31,  5.89it/s]\titers: 1600, epoch: 1 | loss: 0.4353184\n",
      "\tspeed: 0.1700s/iter; left time: 359.4165s\n",
      "1699it [04:48,  5.89it/s]\titers: 1700, epoch: 1 | loss: 0.7422853\n",
      "\tspeed: 0.1695s/iter; left time: 341.2767s\n",
      "1799it [05:05,  5.90it/s]\titers: 1800, epoch: 1 | loss: 0.3146717\n",
      "\tspeed: 0.1694s/iter; left time: 324.2032s\n",
      "1899it [05:22,  5.90it/s]\titers: 1900, epoch: 1 | loss: 0.3456522\n",
      "\tspeed: 0.1696s/iter; left time: 307.7215s\n",
      "1999it [05:39,  5.89it/s]\titers: 2000, epoch: 1 | loss: 0.5872148\n",
      "\tspeed: 0.1697s/iter; left time: 290.8365s\n",
      "2099it [05:56,  5.87it/s]\titers: 2100, epoch: 1 | loss: 0.4555999\n",
      "\tspeed: 0.1698s/iter; left time: 274.1204s\n",
      "2199it [06:13,  5.92it/s]\titers: 2200, epoch: 1 | loss: 0.2967562\n",
      "\tspeed: 0.1700s/iter; left time: 257.3317s\n",
      "2299it [06:30,  5.88it/s]\titers: 2300, epoch: 1 | loss: 0.5006604\n",
      "\tspeed: 0.1701s/iter; left time: 240.4667s\n",
      "2399it [06:47,  5.88it/s]\titers: 2400, epoch: 1 | loss: 0.6905553\n",
      "\tspeed: 0.1701s/iter; left time: 223.4965s\n",
      "2499it [07:04,  5.88it/s]\titers: 2500, epoch: 1 | loss: 0.3959525\n",
      "\tspeed: 0.1699s/iter; left time: 206.2667s\n",
      "2599it [07:21,  5.92it/s]\titers: 2600, epoch: 1 | loss: 0.2818548\n",
      "\tspeed: 0.1701s/iter; left time: 189.4744s\n",
      "2699it [07:38,  5.92it/s]\titers: 2700, epoch: 1 | loss: 0.4867347\n",
      "\tspeed: 0.1688s/iter; left time: 171.1981s\n",
      "2799it [07:54,  5.94it/s]\titers: 2800, epoch: 1 | loss: 0.2815517\n",
      "\tspeed: 0.1687s/iter; left time: 154.2163s\n",
      "2899it [08:11,  5.91it/s]\titers: 2900, epoch: 1 | loss: 0.5378835\n",
      "\tspeed: 0.1694s/iter; left time: 137.9060s\n",
      "2999it [08:28,  5.94it/s]\titers: 3000, epoch: 1 | loss: 0.2304018\n",
      "\tspeed: 0.1689s/iter; left time: 120.6247s\n",
      "3099it [08:45,  5.92it/s]\titers: 3100, epoch: 1 | loss: 0.4641265\n",
      "\tspeed: 0.1688s/iter; left time: 103.6365s\n",
      "3199it [09:02,  5.91it/s]\titers: 3200, epoch: 1 | loss: 0.4981674\n",
      "\tspeed: 0.1689s/iter; left time: 86.8303s\n",
      "3299it [09:19,  5.89it/s]\titers: 3300, epoch: 1 | loss: 0.3765714\n",
      "\tspeed: 0.1691s/iter; left time: 69.9898s\n",
      "3399it [09:36,  5.90it/s]\titers: 3400, epoch: 1 | loss: 0.4325723\n",
      "\tspeed: 0.1693s/iter; left time: 53.1633s\n",
      "3499it [09:53,  5.87it/s]\titers: 3500, epoch: 1 | loss: 0.5126200\n",
      "\tspeed: 0.1697s/iter; left time: 36.3073s\n",
      "3599it [10:10,  5.91it/s]\titers: 3600, epoch: 1 | loss: 0.6838058\n",
      "\tspeed: 0.1694s/iter; left time: 19.3074s\n",
      "3699it [10:27,  5.93it/s]\titers: 3700, epoch: 1 | loss: 0.2513401\n",
      "\tspeed: 0.1688s/iter; left time: 2.3630s\n",
      "3713it [10:29,  5.90it/s]\n",
      "Epoch: 1 cost time: 629.5582394599915\n",
      "810it [01:09, 11.73it/s]\n",
      "807it [01:08, 11.72it/s]\n",
      "Epoch: 1 | Train Loss: 0.5001839 Vali Loss: 0.5328993 Test Loss: 0.6672727 MAE Loss: 0.5869091\n",
      "lr = 0.0040000000\n",
      "Updating learning rate to 0.0040000000000000036\n",
      "Total time: 13.195123064517976 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 16:23:21,025] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 16:23:21,834] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 16:23:21,834] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 16:23:21,834] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 16:23:22,650] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 16:23:22,650] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 16:23:23,186] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 16:23:23,188] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 16:23:23,188] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 16:23:23,189] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 16:23:23,189] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 16:23:23,189] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 16:23:23,190] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 16:23:23,190] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 16:23:23,190] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 16:23:23,190] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 16:23:23,628] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 16:23:23,628] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:23:23,628] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.95 GB, percent = 16.4%\n",
      "[2024-05-06 16:23:23,733] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 16:23:23,733] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:23:23,734] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.95 GB, percent = 16.4%\n",
      "[2024-05-06 16:23:23,734] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 16:23:23,834] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 16:23:23,835] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 16:23:23,835] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.95 GB, percent = 16.4%\n",
      "[2024-05-06 16:23:23,835] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 16:23:23,836] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 16:23:23,836] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 16:23:23,836] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 16:23:23,836] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f76806a67d0>\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 16:23:23,837] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 16:23:23,838] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.1\n",
      "lr 0.0040000000000000036\n",
      "99it [00:17,  5.93it/s]\titers: 100, epoch: 1 | loss: 0.7224666\n",
      "\tspeed: 0.2071s/iter; left time: 7669.8339s\n",
      "199it [00:34,  5.93it/s]\titers: 200, epoch: 1 | loss: 0.3539959\n",
      "\tspeed: 0.1690s/iter; left time: 6240.1798s\n",
      "299it [00:51,  5.93it/s]\titers: 300, epoch: 1 | loss: 0.3806745\n",
      "\tspeed: 0.1691s/iter; left time: 6226.3281s\n",
      "399it [01:08,  5.92it/s]\titers: 400, epoch: 1 | loss: 0.2579581\n",
      "\tspeed: 0.1689s/iter; left time: 6202.9748s\n",
      "499it [01:24,  5.93it/s]\titers: 500, epoch: 1 | loss: 0.2964526\n",
      "\tspeed: 0.1689s/iter; left time: 6185.8225s\n",
      "599it [01:41,  5.94it/s]\titers: 600, epoch: 1 | loss: 0.3597670\n",
      "\tspeed: 0.1686s/iter; left time: 6159.0031s\n",
      "699it [01:58,  5.91it/s]\titers: 700, epoch: 1 | loss: 0.5668161\n",
      "\tspeed: 0.1691s/iter; left time: 6159.3356s\n",
      "799it [02:15,  5.90it/s]\titers: 800, epoch: 1 | loss: 0.4650008\n",
      "\tspeed: 0.1694s/iter; left time: 6155.6046s\n",
      "899it [02:32,  5.91it/s]\titers: 900, epoch: 1 | loss: 0.5931702\n",
      "\tspeed: 0.1695s/iter; left time: 6139.4471s\n",
      "999it [02:49,  5.89it/s]\titers: 1000, epoch: 1 | loss: 0.4793293\n",
      "\tspeed: 0.1697s/iter; left time: 6130.1625s\n",
      "1099it [03:06,  5.88it/s]\titers: 1100, epoch: 1 | loss: 0.3929631\n",
      "\tspeed: 0.1697s/iter; left time: 6114.9202s\n",
      "1199it [03:23,  5.89it/s]\titers: 1200, epoch: 1 | loss: 0.4431814\n",
      "\tspeed: 0.1698s/iter; left time: 6099.3113s\n",
      "1299it [03:40,  5.90it/s]\titers: 1300, epoch: 1 | loss: 0.3253015\n",
      "\tspeed: 0.1693s/iter; left time: 6064.7322s\n",
      "1399it [03:57,  5.90it/s]\titers: 1400, epoch: 1 | loss: 0.4308687\n",
      "\tspeed: 0.1696s/iter; left time: 6058.4045s\n",
      "1499it [04:14,  5.92it/s]\titers: 1500, epoch: 1 | loss: 0.4591449\n",
      "\tspeed: 0.1691s/iter; left time: 6025.7005s\n",
      "1599it [04:31,  5.88it/s]\titers: 1600, epoch: 1 | loss: 0.4353184\n",
      "\tspeed: 0.1700s/iter; left time: 6039.9035s\n",
      "1699it [04:48,  5.89it/s]\titers: 1700, epoch: 1 | loss: 0.7422853\n",
      "\tspeed: 0.1700s/iter; left time: 6021.5344s\n",
      "1799it [05:05,  5.90it/s]\titers: 1800, epoch: 1 | loss: 0.3146717\n",
      "\tspeed: 0.1694s/iter; left time: 5983.5433s\n",
      "1899it [05:22,  5.90it/s]\titers: 1900, epoch: 1 | loss: 0.3456522\n",
      "\tspeed: 0.1695s/iter; left time: 5970.2006s\n",
      "1999it [05:39,  5.89it/s]\titers: 2000, epoch: 1 | loss: 0.5872148\n",
      "\tspeed: 0.1693s/iter; left time: 5948.5258s\n",
      "2099it [05:56,  5.92it/s]\titers: 2100, epoch: 1 | loss: 0.4555999\n",
      "\tspeed: 0.1690s/iter; left time: 5918.9610s\n",
      "2199it [06:12,  5.90it/s]\titers: 2200, epoch: 1 | loss: 0.2967562\n",
      "\tspeed: 0.1693s/iter; left time: 5915.2793s\n",
      "2299it [06:29,  5.90it/s]\titers: 2300, epoch: 1 | loss: 0.5006604\n",
      "\tspeed: 0.1695s/iter; left time: 5902.9253s\n",
      "2399it [06:46,  5.91it/s]\titers: 2400, epoch: 1 | loss: 0.6905553\n",
      "\tspeed: 0.1692s/iter; left time: 5875.0927s\n",
      "2499it [07:03,  5.87it/s]\titers: 2500, epoch: 1 | loss: 0.3959525\n",
      "\tspeed: 0.1700s/iter; left time: 5887.7904s\n",
      "2599it [07:20,  5.94it/s]\titers: 2600, epoch: 1 | loss: 0.2818548\n",
      "\tspeed: 0.1699s/iter; left time: 5868.4163s\n",
      "2699it [07:37,  5.91it/s]\titers: 2700, epoch: 1 | loss: 0.4867347\n",
      "\tspeed: 0.1691s/iter; left time: 5823.0830s\n",
      "2799it [07:54,  5.91it/s]\titers: 2800, epoch: 1 | loss: 0.2815517\n",
      "\tspeed: 0.1692s/iter; left time: 5809.3345s\n",
      "2899it [08:11,  5.93it/s]\titers: 2900, epoch: 1 | loss: 0.5378835\n",
      "\tspeed: 0.1691s/iter; left time: 5787.5274s\n",
      "2999it [08:28,  5.95it/s]\titers: 3000, epoch: 1 | loss: 0.2304018\n",
      "\tspeed: 0.1687s/iter; left time: 5758.7074s\n",
      "3099it [08:45,  5.93it/s]\titers: 3100, epoch: 1 | loss: 0.4641265\n",
      "\tspeed: 0.1686s/iter; left time: 5738.1094s\n",
      "3199it [09:02,  5.92it/s]\titers: 3200, epoch: 1 | loss: 0.4981674\n",
      "\tspeed: 0.1696s/iter; left time: 5753.0823s\n",
      "3299it [09:19,  5.93it/s]\titers: 3300, epoch: 1 | loss: 0.3765714\n",
      "\tspeed: 0.1687s/iter; left time: 5707.4552s\n",
      "3399it [09:35,  5.94it/s]\titers: 3400, epoch: 1 | loss: 0.4325723\n",
      "\tspeed: 0.1685s/iter; left time: 5684.1310s\n",
      "3499it [09:52,  5.91it/s]\titers: 3500, epoch: 1 | loss: 0.5126200\n",
      "\tspeed: 0.1687s/iter; left time: 5673.3786s\n",
      "3599it [10:09,  5.92it/s]\titers: 3600, epoch: 1 | loss: 0.6838058\n",
      "\tspeed: 0.1688s/iter; left time: 5658.4371s\n",
      "3699it [10:26,  5.93it/s]\titers: 3700, epoch: 1 | loss: 0.2513401\n",
      "\tspeed: 0.1690s/iter; left time: 5649.5480s\n",
      "3713it [10:29,  5.90it/s]\n",
      "Epoch: 1 cost time: 629.0086028575897\n",
      "810it [01:09, 11.73it/s]\n",
      "807it [01:08, 11.74it/s]\n",
      "Epoch: 1 | Train Loss: 0.5001839 Vali Loss: 0.5328993 Test Loss: 0.6672727 MAE Loss: 0.5869091\n",
      "lr = 0.0040000000\n",
      "Updating learning rate to 0.0040000000000000036\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0040000000000000036\n",
      "99it [00:16,  6.02it/s]\titers: 100, epoch: 2 | loss: 0.3502413\n",
      "\tspeed: 1.5827s/iter; left time: 52733.9163s\n",
      "199it [00:33,  6.02it/s]\titers: 200, epoch: 2 | loss: 0.3360737\n",
      "\tspeed: 0.1665s/iter; left time: 5532.4257s\n",
      "299it [00:50,  6.03it/s]\titers: 300, epoch: 2 | loss: 0.4027624\n",
      "\tspeed: 0.1659s/iter; left time: 5494.6001s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 2 | loss: 0.4083579\n",
      "\tspeed: 0.1653s/iter; left time: 5456.6369s\n",
      "499it [01:23,  6.05it/s]\titers: 500, epoch: 2 | loss: 0.3066200\n",
      "\tspeed: 0.1659s/iter; left time: 5460.2017s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 2 | loss: 0.5876783\n",
      "\tspeed: 0.1654s/iter; left time: 5429.1009s\n",
      "699it [01:56,  6.06it/s]\titers: 700, epoch: 2 | loss: 0.2537562\n",
      "\tspeed: 0.1654s/iter; left time: 5410.8463s\n",
      "799it [02:12,  6.04it/s]\titers: 800, epoch: 2 | loss: 0.3538025\n",
      "\tspeed: 0.1652s/iter; left time: 5389.4889s\n",
      "899it [02:29,  6.02it/s]\titers: 900, epoch: 2 | loss: 0.8541349\n",
      "\tspeed: 0.1652s/iter; left time: 5372.3253s\n",
      "999it [02:45,  6.03it/s]\titers: 1000, epoch: 2 | loss: 0.1786588\n",
      "\tspeed: 0.1654s/iter; left time: 5362.5618s\n",
      "1099it [03:02,  6.06it/s]\titers: 1100, epoch: 2 | loss: 0.3696922\n",
      "\tspeed: 0.1652s/iter; left time: 5340.0482s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 2 | loss: 0.6142011\n",
      "\tspeed: 0.1650s/iter; left time: 5315.5758s\n",
      "1299it [03:35,  6.07it/s]\titers: 1300, epoch: 2 | loss: 0.2744029\n",
      "\tspeed: 0.1649s/iter; left time: 5296.7504s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 2 | loss: 0.4276495\n",
      "\tspeed: 0.1650s/iter; left time: 5283.8621s\n",
      "1499it [04:08,  6.06it/s]\titers: 1500, epoch: 2 | loss: 0.2803231\n",
      "\tspeed: 0.1650s/iter; left time: 5267.0955s\n",
      "1599it [04:24,  6.05it/s]\titers: 1600, epoch: 2 | loss: 0.7855385\n",
      "\tspeed: 0.1650s/iter; left time: 5248.7678s\n",
      "1699it [04:41,  6.05it/s]\titers: 1700, epoch: 2 | loss: 0.3895613\n",
      "\tspeed: 0.1653s/iter; left time: 5242.0410s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 2 | loss: 0.5157345\n",
      "\tspeed: 0.1655s/iter; left time: 5232.4830s\n",
      "1899it [05:14,  6.05it/s]\titers: 1900, epoch: 2 | loss: 0.4659766\n",
      "\tspeed: 0.1650s/iter; left time: 5201.6517s\n",
      "1999it [05:30,  6.05it/s]\titers: 2000, epoch: 2 | loss: 0.6146966\n",
      "\tspeed: 0.1652s/iter; left time: 5189.7730s\n",
      "2099it [05:47,  6.05it/s]\titers: 2100, epoch: 2 | loss: 0.7178262\n",
      "\tspeed: 0.1650s/iter; left time: 5169.0044s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 2 | loss: 0.4131571\n",
      "\tspeed: 0.1649s/iter; left time: 5146.4628s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 2 | loss: 0.5189355\n",
      "\tspeed: 0.1649s/iter; left time: 5130.2594s\n",
      "2399it [06:36,  6.06it/s]\titers: 2400, epoch: 2 | loss: 0.4629318\n",
      "\tspeed: 0.1650s/iter; left time: 5117.1840s\n",
      "2499it [06:53,  6.06it/s]\titers: 2500, epoch: 2 | loss: 0.3559010\n",
      "\tspeed: 0.1652s/iter; left time: 5108.7683s\n",
      "2599it [07:09,  6.07it/s]\titers: 2600, epoch: 2 | loss: 0.3144288\n",
      "\tspeed: 0.1652s/iter; left time: 5089.7708s\n",
      "2699it [07:26,  6.02it/s]\titers: 2700, epoch: 2 | loss: 0.3665635\n",
      "\tspeed: 0.1654s/iter; left time: 5081.4966s\n",
      "2799it [07:43,  6.02it/s]\titers: 2800, epoch: 2 | loss: 0.4836561\n",
      "\tspeed: 0.1652s/iter; left time: 5057.2886s\n",
      "2899it [07:59,  6.04it/s]\titers: 2900, epoch: 2 | loss: 0.4225220\n",
      "\tspeed: 0.1655s/iter; left time: 5051.6911s\n",
      "2999it [08:16,  6.06it/s]\titers: 3000, epoch: 2 | loss: 0.3637490\n",
      "\tspeed: 0.1652s/iter; left time: 5024.0875s\n",
      "3099it [08:32,  6.07it/s]\titers: 3100, epoch: 2 | loss: 0.3995622\n",
      "\tspeed: 0.1652s/iter; left time: 5007.4869s\n",
      "3199it [08:49,  6.06it/s]\titers: 3200, epoch: 2 | loss: 0.4233486\n",
      "\tspeed: 0.1653s/iter; left time: 4996.0426s\n",
      "3299it [09:05,  6.05it/s]\titers: 3300, epoch: 2 | loss: 0.3576169\n",
      "\tspeed: 0.1657s/iter; left time: 4991.2924s\n",
      "3399it [09:22,  6.05it/s]\titers: 3400, epoch: 2 | loss: 0.5287344\n",
      "\tspeed: 0.1651s/iter; left time: 4955.4620s\n",
      "3499it [09:38,  6.07it/s]\titers: 3500, epoch: 2 | loss: 0.4585082\n",
      "\tspeed: 0.1651s/iter; left time: 4938.1047s\n",
      "3599it [09:55,  6.05it/s]\titers: 3600, epoch: 2 | loss: 0.5473402\n",
      "\tspeed: 0.1654s/iter; left time: 4933.2886s\n",
      "3699it [10:11,  6.07it/s]\titers: 3700, epoch: 2 | loss: 0.4319811\n",
      "\tspeed: 0.1656s/iter; left time: 4920.0946s\n",
      "3713it [10:14,  6.05it/s]\n",
      "Epoch: 2 cost time: 614.1866674423218\n",
      "810it [01:05, 12.27it/s]\n",
      "807it [01:05, 12.26it/s]\n",
      "Epoch: 2 | Train Loss: 0.4360154 Vali Loss: 0.4978501 Test Loss: 0.6172231 MAE Loss: 0.5572104\n",
      "Updating learning rate to 0.0020000000000000018\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0020000000000000018\n",
      "99it [00:16,  6.04it/s]\titers: 100, epoch: 3 | loss: 0.4303295\n",
      "\tspeed: 1.5212s/iter; left time: 45036.5631s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 3 | loss: 0.2771498\n",
      "\tspeed: 0.1660s/iter; left time: 4898.1306s\n",
      "299it [00:49,  6.04it/s]\titers: 300, epoch: 3 | loss: 0.4990565\n",
      "\tspeed: 0.1654s/iter; left time: 4862.6448s\n",
      "399it [01:06,  6.05it/s]\titers: 400, epoch: 3 | loss: 0.3592515\n",
      "\tspeed: 0.1654s/iter; left time: 4847.0573s\n",
      "499it [01:22,  6.03it/s]\titers: 500, epoch: 3 | loss: 0.3701052\n",
      "\tspeed: 0.1653s/iter; left time: 4826.6353s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 3 | loss: 0.3270285\n",
      "\tspeed: 0.1653s/iter; left time: 4811.5361s\n",
      "699it [01:56,  6.05it/s]\titers: 700, epoch: 3 | loss: 0.4449060\n",
      "\tspeed: 0.1652s/iter; left time: 4792.2583s\n",
      "799it [02:12,  5.92it/s]\titers: 800, epoch: 3 | loss: 0.2854516\n",
      "\tspeed: 0.1657s/iter; left time: 4788.1705s\n",
      "899it [02:29,  6.02it/s]\titers: 900, epoch: 3 | loss: 0.2514527\n",
      "\tspeed: 0.1657s/iter; left time: 4772.2688s\n",
      "999it [02:45,  6.02it/s]\titers: 1000, epoch: 3 | loss: 0.2835534\n",
      "\tspeed: 0.1659s/iter; left time: 4762.8940s\n",
      "1099it [03:02,  6.04it/s]\titers: 1100, epoch: 3 | loss: 0.2697057\n",
      "\tspeed: 0.1655s/iter; left time: 4733.3055s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 3 | loss: 0.1969525\n",
      "\tspeed: 0.1651s/iter; left time: 4706.2348s\n",
      "1299it [03:35,  6.05it/s]\titers: 1300, epoch: 3 | loss: 0.3549285\n",
      "\tspeed: 0.1652s/iter; left time: 4692.8803s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 3 | loss: 0.3464519\n",
      "\tspeed: 0.1653s/iter; left time: 4677.4654s\n",
      "1499it [04:08,  6.04it/s]\titers: 1500, epoch: 3 | loss: 0.5636867\n",
      "\tspeed: 0.1652s/iter; left time: 4659.6531s\n",
      "1599it [04:24,  6.05it/s]\titers: 1600, epoch: 3 | loss: 0.3600194\n",
      "\tspeed: 0.1653s/iter; left time: 4645.6319s\n",
      "1699it [04:41,  6.06it/s]\titers: 1700, epoch: 3 | loss: 0.3238720\n",
      "\tspeed: 0.1652s/iter; left time: 4626.0844s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 3 | loss: 0.2421953\n",
      "\tspeed: 0.1654s/iter; left time: 4614.9890s\n",
      "1899it [05:14,  6.04it/s]\titers: 1900, epoch: 3 | loss: 0.5728974\n",
      "\tspeed: 0.1655s/iter; left time: 4600.4679s\n",
      "1999it [05:31,  6.04it/s]\titers: 2000, epoch: 3 | loss: 0.5479270\n",
      "\tspeed: 0.1655s/iter; left time: 4586.3724s\n",
      "2099it [05:47,  6.05it/s]\titers: 2100, epoch: 3 | loss: 0.3138304\n",
      "\tspeed: 0.1653s/iter; left time: 4564.3008s\n",
      "2199it [06:04,  6.06it/s]\titers: 2200, epoch: 3 | loss: 0.3342245\n",
      "\tspeed: 0.1655s/iter; left time: 4552.4662s\n",
      "2299it [06:20,  6.04it/s]\titers: 2300, epoch: 3 | loss: 0.3850319\n",
      "\tspeed: 0.1653s/iter; left time: 4530.5533s\n",
      "2399it [06:37,  6.02it/s]\titers: 2400, epoch: 3 | loss: 0.5179683\n",
      "\tspeed: 0.1658s/iter; left time: 4527.1380s\n",
      "2499it [06:53,  6.02it/s]\titers: 2500, epoch: 3 | loss: 0.2403398\n",
      "\tspeed: 0.1656s/iter; left time: 4504.5989s\n",
      "2599it [07:10,  6.04it/s]\titers: 2600, epoch: 3 | loss: 0.5026017\n",
      "\tspeed: 0.1657s/iter; left time: 4491.3015s\n",
      "2699it [07:26,  6.05it/s]\titers: 2700, epoch: 3 | loss: 0.2527866\n",
      "\tspeed: 0.1655s/iter; left time: 4469.7420s\n",
      "2799it [07:43,  6.04it/s]\titers: 2800, epoch: 3 | loss: 0.3908583\n",
      "\tspeed: 0.1652s/iter; left time: 4445.9324s\n",
      "2899it [07:59,  6.05it/s]\titers: 2900, epoch: 3 | loss: 0.3636400\n",
      "\tspeed: 0.1653s/iter; left time: 4430.1131s\n",
      "2999it [08:16,  6.04it/s]\titers: 3000, epoch: 3 | loss: 0.3154917\n",
      "\tspeed: 0.1652s/iter; left time: 4412.8390s\n",
      "3099it [08:33,  6.06it/s]\titers: 3100, epoch: 3 | loss: 0.4973474\n",
      "\tspeed: 0.1653s/iter; left time: 4397.5653s\n",
      "3199it [08:49,  6.05it/s]\titers: 3200, epoch: 3 | loss: 0.4724675\n",
      "\tspeed: 0.1654s/iter; left time: 4384.5450s\n",
      "3299it [09:06,  6.05it/s]\titers: 3300, epoch: 3 | loss: 0.3848812\n",
      "\tspeed: 0.1653s/iter; left time: 4364.8015s\n",
      "3399it [09:22,  6.04it/s]\titers: 3400, epoch: 3 | loss: 0.3242784\n",
      "\tspeed: 0.1655s/iter; left time: 4353.3959s\n",
      "3499it [09:39,  6.05it/s]\titers: 3500, epoch: 3 | loss: 0.3661088\n",
      "\tspeed: 0.1654s/iter; left time: 4335.3442s\n",
      "3599it [09:55,  6.03it/s]\titers: 3600, epoch: 3 | loss: 0.5475364\n",
      "\tspeed: 0.1658s/iter; left time: 4327.0511s\n",
      "3699it [10:12,  6.05it/s]\titers: 3700, epoch: 3 | loss: 0.2863446\n",
      "\tspeed: 0.1655s/iter; left time: 4303.2168s\n",
      "3713it [10:14,  6.04it/s]\n",
      "Epoch: 3 cost time: 614.7204430103302\n",
      "810it [01:06, 12.23it/s]\n",
      "807it [01:05, 12.28it/s]\n",
      "Epoch: 3 | Train Loss: 0.3693308 Vali Loss: 0.4219438 Test Loss: 0.5429367 MAE Loss: 0.4976103\n",
      "^C\n",
      "Total time: 40.285811452070874 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:00:42,930] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:00:43,947] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:00:43,947] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:00:43,947] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:00:44,862] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:00:44,862] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:00:45,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:00:45,822] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:00:45,823] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:00:45,823] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:00:45,824] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:00:45,824] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:00:46,245] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:00:46,245] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,246] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 141.6 GB, percent = 18.8%\n",
      "[2024-05-04 01:00:46,406] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:00:46,406] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,407] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 143.21 GB, percent = 19.0%\n",
      "[2024-05-04 01:00:46,407] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:00:46,562] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:00:46,563] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,563] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 144.73 GB, percent = 19.2%\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.01], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f93dcae3a50>\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "98it [00:05, 19.74it/s]\titers: 100, epoch: 1 | loss: 0.3833525\n",
      "\tspeed: 0.0991s/iter; left time: 363.4518s\n",
      "199it [00:11, 18.14it/s]\titers: 200, epoch: 1 | loss: 0.4552666\n",
      "\tspeed: 0.0513s/iter; left time: 182.8345s\n",
      "298it [00:16, 19.32it/s]\titers: 300, epoch: 1 | loss: 0.4083411\n",
      "\tspeed: 0.0520s/iter; left time: 180.1069s\n",
      "398it [00:22, 18.00it/s]\titers: 400, epoch: 1 | loss: 0.6283149\n",
      "\tspeed: 0.0581s/iter; left time: 195.4085s\n",
      "498it [00:27, 17.33it/s]\titers: 500, epoch: 1 | loss: 0.4329080\n",
      "\tspeed: 0.0567s/iter; left time: 185.1532s\n",
      "598it [00:33, 17.63it/s]\titers: 600, epoch: 1 | loss: 0.6069039\n",
      "\tspeed: 0.0549s/iter; left time: 173.9277s\n",
      "698it [00:39, 12.99it/s]\titers: 700, epoch: 1 | loss: 0.2976454\n",
      "\tspeed: 0.0610s/iter; left time: 186.8963s\n",
      "799it [00:44, 15.92it/s]\titers: 800, epoch: 1 | loss: 0.4251925\n",
      "\tspeed: 0.0562s/iter; left time: 166.6386s\n",
      "899it [00:49, 22.97it/s]\titers: 900, epoch: 1 | loss: 0.3497310\n",
      "\tspeed: 0.0501s/iter; left time: 143.7281s\n",
      "998it [00:54, 17.70it/s]\titers: 1000, epoch: 1 | loss: 0.3576183\n",
      "\tspeed: 0.0484s/iter; left time: 133.8296s\n",
      "1099it [00:59, 22.52it/s]\titers: 1100, epoch: 1 | loss: 0.2790441\n",
      "\tspeed: 0.0483s/iter; left time: 128.7607s\n",
      "1198it [01:04, 22.76it/s]\titers: 1200, epoch: 1 | loss: 0.2876119\n",
      "\tspeed: 0.0439s/iter; left time: 112.7725s\n",
      "1299it [01:09, 16.51it/s]\titers: 1300, epoch: 1 | loss: 0.3232446\n",
      "\tspeed: 0.0572s/iter; left time: 141.0901s\n",
      "1398it [01:15, 18.89it/s]\titers: 1400, epoch: 1 | loss: 0.3362528\n",
      "\tspeed: 0.0537s/iter; left time: 127.1556s\n",
      "1498it [01:20, 19.80it/s]\titers: 1500, epoch: 1 | loss: 0.5864910\n",
      "\tspeed: 0.0552s/iter; left time: 125.1710s\n",
      "1598it [01:25, 16.45it/s]\titers: 1600, epoch: 1 | loss: 0.4934716\n",
      "\tspeed: 0.0528s/iter; left time: 114.4164s\n",
      "1698it [01:31, 17.16it/s]\titers: 1700, epoch: 1 | loss: 0.3434920\n",
      "\tspeed: 0.0534s/iter; left time: 110.3824s\n",
      "1799it [01:36, 17.48it/s]\titers: 1800, epoch: 1 | loss: 0.3418876\n",
      "\tspeed: 0.0538s/iter; left time: 105.7837s\n",
      "1898it [01:41, 20.05it/s]\titers: 1900, epoch: 1 | loss: 0.2126407\n",
      "\tspeed: 0.0461s/iter; left time: 86.0041s\n",
      "1998it [01:45, 23.09it/s]\titers: 2000, epoch: 1 | loss: 0.2516538\n",
      "\tspeed: 0.0472s/iter; left time: 83.2785s\n",
      "2097it [01:50, 24.43it/s]\titers: 2100, epoch: 1 | loss: 0.2494175\n",
      "\tspeed: 0.0411s/iter; left time: 68.5439s\n",
      "2197it [01:54, 21.58it/s]\titers: 2200, epoch: 1 | loss: 0.7722250\n",
      "\tspeed: 0.0491s/iter; left time: 76.8812s\n",
      "2299it [02:00, 19.08it/s]\titers: 2300, epoch: 1 | loss: 0.3824512\n",
      "\tspeed: 0.0537s/iter; left time: 78.7065s\n",
      "2398it [02:06, 15.90it/s]\titers: 2400, epoch: 1 | loss: 0.5584468\n",
      "\tspeed: 0.0588s/iter; left time: 80.3414s\n",
      "2498it [02:11, 18.05it/s]\titers: 2500, epoch: 1 | loss: 0.3547414\n",
      "\tspeed: 0.0577s/iter; left time: 73.0801s\n",
      "2597it [02:17, 22.18it/s]\titers: 2600, epoch: 1 | loss: 0.4724534\n",
      "\tspeed: 0.0596s/iter; left time: 69.4480s\n",
      "2698it [02:22, 19.66it/s]\titers: 2700, epoch: 1 | loss: 0.5569499\n",
      "\tspeed: 0.0488s/iter; left time: 52.0168s\n",
      "2799it [02:28, 18.37it/s]\titers: 2800, epoch: 1 | loss: 0.2892987\n",
      "\tspeed: 0.0559s/iter; left time: 53.9638s\n",
      "2897it [02:33, 20.49it/s]\titers: 2900, epoch: 1 | loss: 0.5243725\n",
      "\tspeed: 0.0513s/iter; left time: 44.3949s\n",
      "2999it [02:39, 17.36it/s]\titers: 3000, epoch: 1 | loss: 0.5551785\n",
      "\tspeed: 0.0564s/iter; left time: 43.2289s\n",
      "3098it [02:44, 19.04it/s]\titers: 3100, epoch: 1 | loss: 0.4308146\n",
      "\tspeed: 0.0528s/iter; left time: 35.1929s\n",
      "3198it [02:49, 19.82it/s]\titers: 3200, epoch: 1 | loss: 0.4954969\n",
      "\tspeed: 0.0509s/iter; left time: 28.8101s\n",
      "3298it [02:54, 19.26it/s]\titers: 3300, epoch: 1 | loss: 0.4035384\n",
      "\tspeed: 0.0510s/iter; left time: 23.7868s\n",
      "3399it [03:00, 16.37it/s]\titers: 3400, epoch: 1 | loss: 0.4612993\n",
      "\tspeed: 0.0600s/iter; left time: 21.9721s\n",
      "3499it [03:06, 19.38it/s]\titers: 3500, epoch: 1 | loss: 0.4572044\n",
      "\tspeed: 0.0547s/iter; left time: 14.5440s\n",
      "3599it [03:11, 19.59it/s]\titers: 3600, epoch: 1 | loss: 0.4272820\n",
      "\tspeed: 0.0516s/iter; left time: 8.5640s\n",
      "3699it [03:16, 18.58it/s]\titers: 3700, epoch: 1 | loss: 0.3220913\n",
      "\tspeed: 0.0565s/iter; left time: 3.7313s\n",
      "3765it [03:20, 18.79it/s]\n",
      "Epoch: 1 cost time: 200.42578125\n",
      "810it [00:21, 37.89it/s]\n",
      "807it [00:21, 37.21it/s]\n",
      "Epoch: 1 | Train Loss: 0.4341944 Vali Loss: 0.4873109 Test Loss: 0.5950663 MAE Loss: 0.5342518\n",
      "lr = 0.0099384418\n",
      "Total time: 4.399978641668955 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.01\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.001 LR, COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:05:42,797] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:05:43,797] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:05:43,797] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:05:43,797] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:05:44,691] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:05:44,691] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:05:45,496] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:05:45,497] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:05:45,497] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:05:45,498] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:05:45,498] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:05:45,498] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:05:45,498] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:05:45,775] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:05:45,776] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:45,776] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:45,889] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:05:46,007] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f99955b3310>\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "97it [00:05, 21.81it/s]\titers: 100, epoch: 1 | loss: 0.3218488\n",
      "\tspeed: 0.0931s/iter; left time: 341.4297s\n",
      "197it [00:10, 20.03it/s]\titers: 200, epoch: 1 | loss: 0.3640255\n",
      "\tspeed: 0.0497s/iter; left time: 177.3949s\n",
      "298it [00:15, 19.25it/s]\titers: 300, epoch: 1 | loss: 0.3463034\n",
      "\tspeed: 0.0531s/iter; left time: 184.1536s\n",
      "398it [00:20, 19.35it/s]\titers: 400, epoch: 1 | loss: 0.4982204\n",
      "\tspeed: 0.0503s/iter; left time: 169.4555s\n",
      "499it [00:26, 18.99it/s]\titers: 500, epoch: 1 | loss: 0.3414853\n",
      "\tspeed: 0.0525s/iter; left time: 171.4618s\n",
      "598it [00:31, 18.81it/s]\titers: 600, epoch: 1 | loss: 0.4336272\n",
      "\tspeed: 0.0554s/iter; left time: 175.3656s\n",
      "697it [00:37, 18.15it/s]\titers: 700, epoch: 1 | loss: 0.2342097\n",
      "\tspeed: 0.0554s/iter; left time: 169.8075s\n",
      "798it [00:42, 19.69it/s]\titers: 800, epoch: 1 | loss: 0.4338324\n",
      "\tspeed: 0.0494s/iter; left time: 146.5944s\n",
      "897it [00:47, 22.03it/s]\titers: 900, epoch: 1 | loss: 0.2272563\n",
      "\tspeed: 0.0500s/iter; left time: 143.1758s\n",
      "999it [00:52, 19.83it/s]\titers: 1000, epoch: 1 | loss: 0.3176199\n",
      "\tspeed: 0.0518s/iter; left time: 143.2047s\n",
      "1098it [00:57, 19.82it/s]\titers: 1100, epoch: 1 | loss: 0.2765396\n",
      "\tspeed: 0.0513s/iter; left time: 136.8769s\n",
      "1198it [01:02, 19.82it/s]\titers: 1200, epoch: 1 | loss: 0.2411615\n",
      "\tspeed: 0.0505s/iter; left time: 129.6712s\n",
      "1299it [01:07, 19.74it/s]\titers: 1300, epoch: 1 | loss: 0.2387251\n",
      "\tspeed: 0.0506s/iter; left time: 124.7376s\n",
      "1399it [01:13, 19.56it/s]\titers: 1400, epoch: 1 | loss: 0.2932905\n",
      "\tspeed: 0.0561s/iter; left time: 132.6344s\n",
      "1498it [01:18, 19.80it/s]\titers: 1500, epoch: 1 | loss: 0.4869284\n",
      "\tspeed: 0.0509s/iter; left time: 115.2751s\n",
      "1598it [01:23, 19.80it/s]\titers: 1600, epoch: 1 | loss: 0.4639114\n",
      "\tspeed: 0.0505s/iter; left time: 109.4299s\n",
      "1698it [01:28, 19.78it/s]\titers: 1700, epoch: 1 | loss: 0.2877363\n",
      "\tspeed: 0.0529s/iter; left time: 109.2087s\n",
      "1798it [01:33, 19.76it/s]\titers: 1800, epoch: 1 | loss: 0.3020300\n",
      "\tspeed: 0.0513s/iter; left time: 100.8949s\n",
      "1899it [01:38, 21.15it/s]\titers: 1900, epoch: 1 | loss: 0.1911741\n",
      "\tspeed: 0.0501s/iter; left time: 93.4019s\n",
      "1998it [01:43, 19.75it/s]\titers: 2000, epoch: 1 | loss: 0.2240178\n",
      "\tspeed: 0.0498s/iter; left time: 87.9272s\n",
      "2098it [01:49, 19.12it/s]\titers: 2100, epoch: 1 | loss: 0.2505400\n",
      "\tspeed: 0.0528s/iter; left time: 87.9313s\n",
      "2198it [01:54, 19.85it/s]\titers: 2200, epoch: 1 | loss: 0.7034073\n",
      "\tspeed: 0.0506s/iter; left time: 79.1717s\n",
      "2299it [01:59, 19.83it/s]\titers: 2300, epoch: 1 | loss: 0.3349081\n",
      "\tspeed: 0.0505s/iter; left time: 74.0502s\n",
      "2398it [02:04, 19.78it/s]\titers: 2400, epoch: 1 | loss: 0.4542590\n",
      "\tspeed: 0.0522s/iter; left time: 71.2671s\n",
      "2499it [02:09, 19.71it/s]\titers: 2500, epoch: 1 | loss: 0.2569482\n",
      "\tspeed: 0.0514s/iter; left time: 65.1099s\n",
      "2598it [02:14, 19.82it/s]\titers: 2600, epoch: 1 | loss: 0.4264008\n",
      "\tspeed: 0.0505s/iter; left time: 58.8988s\n",
      "2698it [02:19, 19.79it/s]\titers: 2700, epoch: 1 | loss: 0.5491066\n",
      "\tspeed: 0.0507s/iter; left time: 54.0757s\n",
      "2799it [02:25, 19.42it/s]\titers: 2800, epoch: 1 | loss: 0.2827885\n",
      "\tspeed: 0.0537s/iter; left time: 51.8541s\n",
      "2898it [02:30, 19.76it/s]\titers: 2900, epoch: 1 | loss: 0.4395315\n",
      "\tspeed: 0.0507s/iter; left time: 43.8695s\n",
      "2997it [02:35, 17.76it/s]\titers: 3000, epoch: 1 | loss: 0.3619106\n",
      "\tspeed: 0.0513s/iter; left time: 39.2710s\n",
      "3098it [02:40, 19.04it/s]\titers: 3100, epoch: 1 | loss: 0.3247359\n",
      "\tspeed: 0.0497s/iter; left time: 33.1289s\n",
      "3199it [02:45, 19.75it/s]\titers: 3200, epoch: 1 | loss: 0.4476379\n",
      "\tspeed: 0.0515s/iter; left time: 29.1428s\n",
      "3298it [02:50, 19.70it/s]\titers: 3300, epoch: 1 | loss: 0.2920132\n",
      "\tspeed: 0.0506s/iter; left time: 23.5638s\n",
      "3398it [02:55, 19.55it/s]\titers: 3400, epoch: 1 | loss: 0.4767970\n",
      "\tspeed: 0.0512s/iter; left time: 18.7401s\n",
      "3498it [03:00, 19.68it/s]\titers: 3500, epoch: 1 | loss: 0.3559366\n",
      "\tspeed: 0.0546s/iter; left time: 14.5164s\n",
      "3599it [03:06, 19.75it/s]\titers: 3600, epoch: 1 | loss: 0.3848062\n",
      "\tspeed: 0.0513s/iter; left time: 8.5223s\n",
      "3699it [03:11, 19.69it/s]\titers: 3700, epoch: 1 | loss: 0.2997992\n",
      "\tspeed: 0.0505s/iter; left time: 3.3363s\n",
      "3765it [03:14, 19.35it/s]\n",
      "Epoch: 1 cost time: 194.56459307670593\n",
      "810it [00:20, 38.77it/s]\n",
      "807it [00:21, 36.91it/s]\n",
      "Epoch: 1 | Train Loss: 0.3494510 Vali Loss: 0.4042036 Test Loss: 0.4891832 MAE Loss: 0.4678651\n",
      "lr = 0.0009938442\n",
      "Total time: 4.295554093519846 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.05.2024, START FROM HERE:\n",
    "# 0.001, COS, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:12:44,664] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:12:45,708] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:12:45,709] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:12:45,709] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:12:46,639] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:12:46,639] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:12:47,491] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:12:47,492] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:12:47,492] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:12:47,493] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:12:47,493] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:12:47,493] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:12:47,804] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:12:47,804] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:47,805] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.83 GB, percent = 16.3%\n",
      "[2024-05-04 01:12:47,979] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:12:47,980] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:47,980] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.28 GB, percent = 16.7%\n",
      "[2024-05-04 01:12:47,980] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:12:48,151] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:12:48,152] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:48,152] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 129.6 GB, percent = 17.2%\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:12:48,153] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbaad018490>\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "97it [00:05, 24.52it/s]\titers: 100, epoch: 1 | loss: 0.3218488\n",
      "\tspeed: 0.0899s/iter; left time: 3375.8297s\n",
      "199it [00:09, 20.81it/s]\titers: 200, epoch: 1 | loss: 0.3640255\n",
      "\tspeed: 0.0420s/iter; left time: 1572.7611s\n",
      "298it [00:14, 19.02it/s]\titers: 300, epoch: 1 | loss: 0.3463034\n",
      "\tspeed: 0.0513s/iter; left time: 1915.8920s\n",
      "399it [00:19, 14.70it/s]\titers: 400, epoch: 1 | loss: 0.4982204\n",
      "\tspeed: 0.0532s/iter; left time: 1983.2761s\n",
      "498it [00:24, 19.84it/s]\titers: 500, epoch: 1 | loss: 0.3414853\n",
      "\tspeed: 0.0511s/iter; left time: 1899.9747s\n",
      "598it [00:29, 20.41it/s]\titers: 600, epoch: 1 | loss: 0.4336272\n",
      "\tspeed: 0.0460s/iter; left time: 1705.1351s\n",
      "699it [00:34, 19.57it/s]\titers: 700, epoch: 1 | loss: 0.2342097\n",
      "\tspeed: 0.0491s/iter; left time: 1815.6723s\n",
      "799it [00:39, 16.66it/s]\titers: 800, epoch: 1 | loss: 0.4338324\n",
      "\tspeed: 0.0528s/iter; left time: 1946.3409s\n",
      "898it [00:44, 19.81it/s]\titers: 900, epoch: 1 | loss: 0.2272563\n",
      "\tspeed: 0.0523s/iter; left time: 1922.6969s\n",
      "998it [00:49, 19.69it/s]\titers: 1000, epoch: 1 | loss: 0.3176199\n",
      "\tspeed: 0.0508s/iter; left time: 1860.9846s\n",
      "1099it [00:55, 19.29it/s]\titers: 1100, epoch: 1 | loss: 0.2765396\n",
      "\tspeed: 0.0514s/iter; left time: 1878.2548s\n",
      "1198it [01:00, 19.65it/s]\titers: 1200, epoch: 1 | loss: 0.2411615\n",
      "\tspeed: 0.0528s/iter; left time: 1926.2170s\n",
      "1299it [01:05, 19.82it/s]\titers: 1300, epoch: 1 | loss: 0.2387251\n",
      "\tspeed: 0.0512s/iter; left time: 1862.6276s\n",
      "1398it [01:10, 19.72it/s]\titers: 1400, epoch: 1 | loss: 0.2932905\n",
      "\tspeed: 0.0506s/iter; left time: 1832.5454s\n",
      "1499it [01:15, 19.81it/s]\titers: 1500, epoch: 1 | loss: 0.4869284\n",
      "\tspeed: 0.0506s/iter; left time: 1830.1516s\n",
      "1598it [01:21, 18.08it/s]\titers: 1600, epoch: 1 | loss: 0.4639114\n",
      "\tspeed: 0.0546s/iter; left time: 1967.5195s\n",
      "1698it [01:26, 19.82it/s]\titers: 1700, epoch: 1 | loss: 0.2877363\n",
      "\tspeed: 0.0506s/iter; left time: 1818.3207s\n",
      "1798it [01:31, 21.20it/s]\titers: 1800, epoch: 1 | loss: 0.3020300\n",
      "\tspeed: 0.0498s/iter; left time: 1785.8629s\n",
      "1898it [01:36, 18.23it/s]\titers: 1900, epoch: 1 | loss: 0.1911741\n",
      "\tspeed: 0.0501s/iter; left time: 1790.8680s\n",
      "1997it [01:40, 22.64it/s]\titers: 2000, epoch: 1 | loss: 0.2240178\n",
      "\tspeed: 0.0459s/iter; left time: 1635.2162s\n",
      "2099it [01:44, 25.17it/s]\titers: 2100, epoch: 1 | loss: 0.2505400\n",
      "\tspeed: 0.0396s/iter; left time: 1408.1162s\n",
      "2198it [01:48, 24.92it/s]\titers: 2200, epoch: 1 | loss: 0.7034073\n",
      "\tspeed: 0.0403s/iter; left time: 1427.2466s\n",
      "2297it [01:52, 24.78it/s]\titers: 2300, epoch: 1 | loss: 0.3349081\n",
      "\tspeed: 0.0404s/iter; left time: 1429.3990s\n",
      "2399it [01:57, 21.37it/s]\titers: 2400, epoch: 1 | loss: 0.4542590\n",
      "\tspeed: 0.0427s/iter; left time: 1504.8166s\n",
      "2498it [02:01, 24.14it/s]\titers: 2500, epoch: 1 | loss: 0.2569482\n",
      "\tspeed: 0.0410s/iter; left time: 1439.8893s\n",
      "2597it [02:05, 25.32it/s]\titers: 2600, epoch: 1 | loss: 0.4264008\n",
      "\tspeed: 0.0396s/iter; left time: 1389.3301s\n",
      "2699it [02:09, 25.08it/s]\titers: 2700, epoch: 1 | loss: 0.5491066\n",
      "\tspeed: 0.0398s/iter; left time: 1392.4019s\n",
      "2798it [02:13, 24.86it/s]\titers: 2800, epoch: 1 | loss: 0.2827885\n",
      "\tspeed: 0.0402s/iter; left time: 1399.8930s\n",
      "2897it [02:17, 25.21it/s]\titers: 2900, epoch: 1 | loss: 0.4395315\n",
      "\tspeed: 0.0425s/iter; left time: 1475.3369s\n",
      "2999it [02:21, 25.46it/s]\titers: 3000, epoch: 1 | loss: 0.3619106\n",
      "\tspeed: 0.0404s/iter; left time: 1400.6069s\n",
      "3098it [02:25, 24.67it/s]\titers: 3100, epoch: 1 | loss: 0.3247359\n",
      "\tspeed: 0.0400s/iter; left time: 1381.6410s\n",
      "3197it [02:29, 24.76it/s]\titers: 3200, epoch: 1 | loss: 0.4476379\n",
      "\tspeed: 0.0403s/iter; left time: 1387.4492s\n",
      "3299it [02:33, 21.57it/s]\titers: 3300, epoch: 1 | loss: 0.2920132\n",
      "\tspeed: 0.0415s/iter; left time: 1424.1715s\n",
      "3398it [02:37, 20.86it/s]\titers: 3400, epoch: 1 | loss: 0.4767970\n",
      "\tspeed: 0.0420s/iter; left time: 1439.9707s\n",
      "3497it [02:41, 25.03it/s]\titers: 3500, epoch: 1 | loss: 0.3559366\n",
      "\tspeed: 0.0396s/iter; left time: 1351.2094s\n",
      "3599it [02:45, 25.02it/s]\titers: 3600, epoch: 1 | loss: 0.3848062\n",
      "\tspeed: 0.0400s/iter; left time: 1361.9900s\n",
      "3698it [02:49, 24.68it/s]\titers: 3700, epoch: 1 | loss: 0.2997992\n",
      "\tspeed: 0.0402s/iter; left time: 1364.0844s\n",
      "3765it [02:52, 21.82it/s]\n",
      "Epoch: 1 cost time: 172.53425121307373\n",
      "810it [00:21, 38.14it/s]\n",
      "807it [00:20, 38.44it/s]\n",
      "Epoch: 1 | Train Loss: 0.3494510 Vali Loss: 0.4042036 Test Loss: 0.4891832 MAE Loss: 0.4678651\n",
      "lr = 0.0009938442\n",
      "97it [00:04, 23.65it/s]\titers: 100, epoch: 2 | loss: 0.1884180\n",
      "\tspeed: 0.5119s/iter; left time: 17295.5830s\n",
      "199it [00:09, 19.76it/s]\titers: 200, epoch: 2 | loss: 0.5682016\n",
      "\tspeed: 0.0501s/iter; left time: 1687.3782s\n",
      "299it [00:15, 20.03it/s]\titers: 300, epoch: 2 | loss: 0.1953925\n",
      "\tspeed: 0.0538s/iter; left time: 1807.3006s\n",
      "397it [00:20, 20.95it/s]\titers: 400, epoch: 2 | loss: 0.1639849\n",
      "\tspeed: 0.0494s/iter; left time: 1654.2717s\n",
      "499it [00:24, 21.20it/s]\titers: 500, epoch: 2 | loss: 0.2742581\n",
      "\tspeed: 0.0474s/iter; left time: 1581.3881s\n",
      "598it [00:29, 20.65it/s]\titers: 600, epoch: 2 | loss: 0.1830232\n",
      "\tspeed: 0.0476s/iter; left time: 1584.9567s\n",
      "699it [00:35, 20.47it/s]\titers: 700, epoch: 2 | loss: 0.4593197\n",
      "\tspeed: 0.0540s/iter; left time: 1792.4596s\n",
      "798it [00:39, 21.35it/s]\titers: 800, epoch: 2 | loss: 0.2955022\n",
      "\tspeed: 0.0471s/iter; left time: 1558.4398s\n",
      "897it [00:44, 21.24it/s]\titers: 900, epoch: 2 | loss: 0.3457933\n",
      "\tspeed: 0.0471s/iter; left time: 1552.3766s\n",
      "998it [00:49, 21.07it/s]\titers: 1000, epoch: 2 | loss: 0.3679632\n",
      "\tspeed: 0.0498s/iter; left time: 1637.0270s\n",
      "1099it [00:54, 21.19it/s]\titers: 1100, epoch: 2 | loss: 0.6786941\n",
      "\tspeed: 0.0480s/iter; left time: 1573.0370s\n",
      "1198it [00:59, 21.13it/s]\titers: 1200, epoch: 2 | loss: 0.3862898\n",
      "\tspeed: 0.0474s/iter; left time: 1550.5010s\n",
      "1297it [01:03, 21.03it/s]\titers: 1300, epoch: 2 | loss: 0.2986697\n",
      "\tspeed: 0.0474s/iter; left time: 1544.0944s\n",
      "1399it [01:08, 27.22it/s]\titers: 1400, epoch: 2 | loss: 0.2336269\n",
      "\tspeed: 0.0426s/iter; left time: 1385.1263s\n",
      "1498it [01:12, 21.25it/s]\titers: 1500, epoch: 2 | loss: 0.2864751\n",
      "\tspeed: 0.0471s/iter; left time: 1524.7288s\n",
      "1597it [01:17, 21.05it/s]\titers: 1600, epoch: 2 | loss: 0.2528131\n",
      "\tspeed: 0.0474s/iter; left time: 1531.6752s\n",
      "1699it [01:22, 20.46it/s]\titers: 1700, epoch: 2 | loss: 0.3811564\n",
      "\tspeed: 0.0446s/iter; left time: 1434.7995s\n",
      "1798it [01:26, 21.14it/s]\titers: 1800, epoch: 2 | loss: 0.3493163\n",
      "\tspeed: 0.0500s/iter; left time: 1604.7663s\n",
      "1897it [01:31, 21.28it/s]\titers: 1900, epoch: 2 | loss: 0.2031413\n",
      "\tspeed: 0.0480s/iter; left time: 1536.1018s\n",
      "1999it [01:36, 20.90it/s]\titers: 2000, epoch: 2 | loss: 0.3165319\n",
      "\tspeed: 0.0471s/iter; left time: 1503.2753s\n",
      "2098it [01:41, 18.25it/s]\titers: 2100, epoch: 2 | loss: 0.2364211\n",
      "\tspeed: 0.0488s/iter; left time: 1552.2675s\n",
      "2198it [01:45, 23.36it/s]\titers: 2200, epoch: 2 | loss: 0.3688861\n",
      "\tspeed: 0.0408s/iter; left time: 1292.4452s\n",
      "2297it [01:49, 27.72it/s]\titers: 2300, epoch: 2 | loss: 0.2263474\n",
      "\tspeed: 0.0363s/iter; left time: 1146.5078s\n",
      "2399it [01:52, 27.44it/s]\titers: 2400, epoch: 2 | loss: 0.1810660\n",
      "\tspeed: 0.0362s/iter; left time: 1141.2930s\n",
      "2498it [01:56, 27.35it/s]\titers: 2500, epoch: 2 | loss: 0.3030196\n",
      "\tspeed: 0.0365s/iter; left time: 1147.0440s\n",
      "2597it [02:00, 21.23it/s]\titers: 2600, epoch: 2 | loss: 0.3515817\n",
      "\tspeed: 0.0454s/iter; left time: 1420.8245s\n",
      "2698it [02:05, 21.24it/s]\titers: 2700, epoch: 2 | loss: 0.2677218\n",
      "\tspeed: 0.0479s/iter; left time: 1493.7406s\n",
      "2797it [02:10, 21.21it/s]\titers: 2800, epoch: 2 | loss: 0.1962819\n",
      "\tspeed: 0.0471s/iter; left time: 1464.4102s\n",
      "2899it [02:14, 24.79it/s]\titers: 2900, epoch: 2 | loss: 0.3394377\n",
      "\tspeed: 0.0376s/iter; left time: 1166.5003s\n",
      "2997it [02:19, 21.18it/s]\titers: 3000, epoch: 2 | loss: 0.3117361\n",
      "\tspeed: 0.0501s/iter; left time: 1547.0080s\n",
      "3099it [02:24, 21.01it/s]\titers: 3100, epoch: 2 | loss: 0.4270400\n",
      "\tspeed: 0.0484s/iter; left time: 1490.0564s\n",
      "3198it [02:28, 21.11it/s]\titers: 3200, epoch: 2 | loss: 0.5073355\n",
      "\tspeed: 0.0477s/iter; left time: 1464.7755s\n",
      "3299it [02:33, 18.97it/s]\titers: 3300, epoch: 2 | loss: 0.3378738\n",
      "\tspeed: 0.0487s/iter; left time: 1488.3815s\n",
      "3397it [02:38, 20.06it/s]\titers: 3400, epoch: 2 | loss: 0.3007434\n",
      "\tspeed: 0.0493s/iter; left time: 1502.5871s\n",
      "3499it [02:43, 21.01it/s]\titers: 3500, epoch: 2 | loss: 0.2726682\n",
      "\tspeed: 0.0477s/iter; left time: 1448.9228s\n",
      "3598it [02:48, 20.80it/s]\titers: 3600, epoch: 2 | loss: 0.4995877\n",
      "\tspeed: 0.0478s/iter; left time: 1448.1655s\n",
      "3698it [02:53, 15.41it/s]\titers: 3700, epoch: 2 | loss: 0.3445364\n",
      "\tspeed: 0.0521s/iter; left time: 1571.4180s\n",
      "3765it [02:56, 21.32it/s]\n",
      "Epoch: 2 cost time: 176.63169884681702\n",
      "810it [00:18, 44.35it/s]\n",
      "807it [00:17, 44.84it/s]\n",
      "Epoch: 2 | Train Loss: 0.3222216 Vali Loss: 0.3956181 Test Loss: 0.4783413 MAE Loss: 0.4657086\n",
      "lr = 0.0009755285\n",
      "99it [00:05, 21.00it/s]\titers: 100, epoch: 3 | loss: 0.2258751\n",
      "\tspeed: 0.4593s/iter; left time: 13789.0348s\n",
      "198it [00:09, 21.00it/s]\titers: 200, epoch: 3 | loss: 0.3039617\n",
      "\tspeed: 0.0475s/iter; left time: 1422.1909s\n",
      "297it [00:14, 21.15it/s]\titers: 300, epoch: 3 | loss: 0.3753062\n",
      "\tspeed: 0.0494s/iter; left time: 1472.1753s\n",
      "399it [00:19, 21.06it/s]\titers: 400, epoch: 3 | loss: 0.3365389\n",
      "\tspeed: 0.0483s/iter; left time: 1435.3169s\n",
      "498it [00:24, 20.59it/s]\titers: 500, epoch: 3 | loss: 0.2426460\n",
      "\tspeed: 0.0477s/iter; left time: 1413.5959s\n",
      "597it [00:29, 20.64it/s]\titers: 600, epoch: 3 | loss: 0.2107975\n",
      "\tspeed: 0.0478s/iter; left time: 1411.8247s\n",
      "698it [00:34, 21.24it/s]\titers: 700, epoch: 3 | loss: 0.3931471\n",
      "\tspeed: 0.0501s/iter; left time: 1475.0841s\n",
      "797it [00:38, 20.97it/s]\titers: 800, epoch: 3 | loss: 0.1803274\n",
      "\tspeed: 0.0483s/iter; left time: 1416.4358s\n",
      "899it [00:43, 20.88it/s]\titers: 900, epoch: 3 | loss: 0.4390911\n",
      "\tspeed: 0.0476s/iter; left time: 1390.9931s\n",
      "999it [00:48, 19.57it/s]\titers: 1000, epoch: 3 | loss: 0.2596957\n",
      "\tspeed: 0.0484s/iter; left time: 1410.3691s\n",
      "1099it [00:53, 21.23it/s]\titers: 1100, epoch: 3 | loss: 0.3385699\n",
      "\tspeed: 0.0502s/iter; left time: 1457.7535s\n",
      "1198it [00:58, 21.10it/s]\titers: 1200, epoch: 3 | loss: 0.2414210\n",
      "\tspeed: 0.0480s/iter; left time: 1388.7373s\n",
      "1297it [01:03, 20.73it/s]\titers: 1300, epoch: 3 | loss: 0.1900485\n",
      "\tspeed: 0.0478s/iter; left time: 1379.0185s\n",
      "1399it [01:07, 22.96it/s]\titers: 1400, epoch: 3 | loss: 0.3608666\n",
      "\tspeed: 0.0429s/iter; left time: 1231.9189s\n",
      "1498it [01:12, 21.11it/s]\titers: 1500, epoch: 3 | loss: 0.4074781\n",
      "\tspeed: 0.0483s/iter; left time: 1382.6899s\n",
      "1597it [01:16, 21.16it/s]\titers: 1600, epoch: 3 | loss: 0.3291973\n",
      "\tspeed: 0.0478s/iter; left time: 1364.5941s\n",
      "1699it [01:21, 20.94it/s]\titers: 1700, epoch: 3 | loss: 0.2674252\n",
      "\tspeed: 0.0476s/iter; left time: 1352.1213s\n",
      "1798it [01:26, 20.74it/s]\titers: 1800, epoch: 3 | loss: 0.2115812\n",
      "\tspeed: 0.0480s/iter; left time: 1358.7219s\n",
      "1897it [01:31, 26.81it/s]\titers: 1900, epoch: 3 | loss: 0.4105255\n",
      "\tspeed: 0.0458s/iter; left time: 1292.6668s\n",
      "1999it [01:35, 23.01it/s]\titers: 2000, epoch: 3 | loss: 0.3016213\n",
      "\tspeed: 0.0472s/iter; left time: 1328.5290s\n",
      "2097it [01:40, 21.64it/s]\titers: 2100, epoch: 3 | loss: 0.2844736\n",
      "\tspeed: 0.0475s/iter; left time: 1329.7423s\n",
      "2199it [01:45, 20.41it/s]\titers: 2200, epoch: 3 | loss: 0.2430025\n",
      "\tspeed: 0.0477s/iter; left time: 1333.0817s\n",
      "2298it [01:50, 17.59it/s]\titers: 2300, epoch: 3 | loss: 0.3116939\n",
      "\tspeed: 0.0502s/iter; left time: 1395.4890s\n",
      "2398it [01:55, 20.07it/s]\titers: 2400, epoch: 3 | loss: 0.2711376\n",
      "\tspeed: 0.0505s/iter; left time: 1399.0249s\n",
      "2499it [01:59, 24.21it/s]\titers: 2500, epoch: 3 | loss: 0.2704870\n",
      "\tspeed: 0.0444s/iter; left time: 1225.4879s\n",
      "2599it [02:04, 20.30it/s]\titers: 2600, epoch: 3 | loss: 0.2521930\n",
      "\tspeed: 0.0460s/iter; left time: 1264.9958s\n",
      "2697it [02:09, 20.98it/s]\titers: 2700, epoch: 3 | loss: 0.4915278\n",
      "\tspeed: 0.0494s/iter; left time: 1353.5384s\n",
      "2798it [02:14, 20.36it/s]\titers: 2800, epoch: 3 | loss: 0.1962674\n",
      "\tspeed: 0.0490s/iter; left time: 1337.7393s\n",
      "2897it [02:19, 20.90it/s]\titers: 2900, epoch: 3 | loss: 0.3470823\n",
      "\tspeed: 0.0483s/iter; left time: 1316.0824s\n",
      "2999it [02:24, 20.32it/s]\titers: 3000, epoch: 3 | loss: 0.2476108\n",
      "\tspeed: 0.0483s/iter; left time: 1309.8367s\n",
      "3099it [02:29, 21.16it/s]\titers: 3100, epoch: 3 | loss: 0.2597793\n",
      "\tspeed: 0.0523s/iter; left time: 1413.8309s\n",
      "3197it [02:34, 20.79it/s]\titers: 3200, epoch: 3 | loss: 0.3018452\n",
      "\tspeed: 0.0481s/iter; left time: 1295.1872s\n",
      "3299it [02:38, 20.66it/s]\titers: 3300, epoch: 3 | loss: 0.2853025\n",
      "\tspeed: 0.0482s/iter; left time: 1293.8346s\n",
      "3398it [02:43, 20.50it/s]\titers: 3400, epoch: 3 | loss: 0.1616981\n",
      "\tspeed: 0.0483s/iter; left time: 1291.6865s\n",
      "3497it [02:48, 21.15it/s]\titers: 3500, epoch: 3 | loss: 0.4743453\n",
      "\tspeed: 0.0512s/iter; left time: 1361.7858s\n",
      "3598it [02:53, 21.19it/s]\titers: 3600, epoch: 3 | loss: 0.1709010\n",
      "\tspeed: 0.0479s/iter; left time: 1269.2155s\n",
      "3697it [02:58, 21.25it/s]\titers: 3700, epoch: 3 | loss: 0.1959947\n",
      "\tspeed: 0.0472s/iter; left time: 1246.1218s\n",
      "3765it [03:01, 20.73it/s]\n",
      "Epoch: 3 cost time: 181.61116743087769\n",
      "810it [00:18, 44.29it/s]\n",
      "807it [00:18, 44.46it/s]\n",
      "Epoch: 3 | Train Loss: 0.3183608 Vali Loss: 0.3893458 Test Loss: 0.4791180 MAE Loss: 0.4585129\n",
      "lr = 0.0009455038\n",
      "99it [00:04, 23.59it/s]\titers: 100, epoch: 4 | loss: 0.2845196\n",
      "\tspeed: 0.4555s/iter; left time: 11958.7077s\n",
      "198it [00:08, 26.88it/s]\titers: 200, epoch: 4 | loss: 0.4451150\n",
      "\tspeed: 0.0374s/iter; left time: 978.0496s\n",
      "297it [00:12, 26.60it/s]\titers: 300, epoch: 4 | loss: 0.1756459\n",
      "\tspeed: 0.0374s/iter; left time: 974.1361s\n",
      "399it [00:15, 26.84it/s]\titers: 400, epoch: 4 | loss: 0.5349078\n",
      "\tspeed: 0.0374s/iter; left time: 972.0196s\n",
      "498it [00:19, 26.63it/s]\titers: 500, epoch: 4 | loss: 0.5543185\n",
      "\tspeed: 0.0377s/iter; left time: 973.6663s\n",
      "599it [00:24, 21.02it/s]\titers: 600, epoch: 4 | loss: 0.3005570\n",
      "\tspeed: 0.0467s/iter; left time: 1202.7182s\n",
      "698it [00:29, 21.06it/s]\titers: 700, epoch: 4 | loss: 0.3341551\n",
      "\tspeed: 0.0481s/iter; left time: 1234.0499s\n",
      "797it [00:33, 21.20it/s]\titers: 800, epoch: 4 | loss: 0.4031752\n",
      "\tspeed: 0.0474s/iter; left time: 1211.4897s\n",
      "899it [00:38, 21.72it/s]\titers: 900, epoch: 4 | loss: 0.2782830\n",
      "\tspeed: 0.0480s/iter; left time: 1221.9241s\n",
      "998it [00:42, 27.34it/s]\titers: 1000, epoch: 4 | loss: 0.4282401\n",
      "\tspeed: 0.0382s/iter; left time: 968.0250s\n",
      "1097it [00:46, 27.46it/s]\titers: 1100, epoch: 4 | loss: 0.4354928\n",
      "\tspeed: 0.0373s/iter; left time: 941.1677s\n",
      "1199it [00:49, 27.28it/s]\titers: 1200, epoch: 4 | loss: 0.4087144\n",
      "\tspeed: 0.0368s/iter; left time: 926.7109s\n",
      "1298it [00:53, 26.90it/s]\titers: 1300, epoch: 4 | loss: 0.2480121\n",
      "\tspeed: 0.0370s/iter; left time: 925.9840s\n",
      "1397it [00:57, 22.94it/s]\titers: 1400, epoch: 4 | loss: 0.3314148\n",
      "\tspeed: 0.0387s/iter; left time: 965.0886s\n",
      "1499it [01:01, 27.02it/s]\titers: 1500, epoch: 4 | loss: 0.4992851\n",
      "\tspeed: 0.0389s/iter; left time: 967.9335s\n",
      "1598it [01:04, 27.58it/s]\titers: 1600, epoch: 4 | loss: 0.2349755\n",
      "\tspeed: 0.0365s/iter; left time: 902.9021s\n",
      "1697it [01:09, 21.23it/s]\titers: 1700, epoch: 4 | loss: 0.7015923\n",
      "\tspeed: 0.0472s/iter; left time: 1164.1638s\n",
      "1797it [01:14, 23.60it/s]\titers: 1800, epoch: 4 | loss: 0.3498228\n",
      "\tspeed: 0.0493s/iter; left time: 1210.3181s\n",
      "1899it [01:18, 27.37it/s]\titers: 1900, epoch: 4 | loss: 0.4449454\n",
      "\tspeed: 0.0376s/iter; left time: 920.5018s\n",
      "1998it [01:22, 27.09it/s]\titers: 2000, epoch: 4 | loss: 0.4502485\n",
      "\tspeed: 0.0366s/iter; left time: 891.3059s\n",
      "2097it [01:25, 27.19it/s]\titers: 2100, epoch: 4 | loss: 0.2690628\n",
      "\tspeed: 0.0369s/iter; left time: 894.3936s\n",
      "2199it [01:29, 27.16it/s]\titers: 2200, epoch: 4 | loss: 0.3947301\n",
      "\tspeed: 0.0367s/iter; left time: 886.9535s\n",
      "2298it [01:33, 26.00it/s]\titers: 2300, epoch: 4 | loss: 0.3304965\n",
      "\tspeed: 0.0393s/iter; left time: 944.8989s\n",
      "2397it [01:37, 27.32it/s]\titers: 2400, epoch: 4 | loss: 0.3419580\n",
      "\tspeed: 0.0377s/iter; left time: 903.0345s\n",
      "2499it [01:40, 27.58it/s]\titers: 2500, epoch: 4 | loss: 0.2142911\n",
      "\tspeed: 0.0363s/iter; left time: 865.4773s\n",
      "2598it [01:44, 27.24it/s]\titers: 2600, epoch: 4 | loss: 0.3281462\n",
      "\tspeed: 0.0366s/iter; left time: 868.3157s\n",
      "2697it [01:47, 27.06it/s]\titers: 2700, epoch: 4 | loss: 0.2933129\n",
      "\tspeed: 0.0368s/iter; left time: 870.6020s\n",
      "2799it [01:52, 21.15it/s]\titers: 2800, epoch: 4 | loss: 0.3378268\n",
      "\tspeed: 0.0437s/iter; left time: 1028.8432s\n",
      "2899it [01:56, 21.29it/s]\titers: 2900, epoch: 4 | loss: 0.3537287\n",
      "\tspeed: 0.0452s/iter; left time: 1060.6516s\n",
      "2998it [02:01, 20.69it/s]\titers: 3000, epoch: 4 | loss: 0.2953578\n",
      "\tspeed: 0.0482s/iter; left time: 1126.2479s\n",
      "3097it [02:06, 20.62it/s]\titers: 3100, epoch: 4 | loss: 0.2514821\n",
      "\tspeed: 0.0483s/iter; left time: 1123.0122s\n",
      "3198it [02:11, 21.08it/s]\titers: 3200, epoch: 4 | loss: 0.2664630\n",
      "\tspeed: 0.0516s/iter; left time: 1194.3097s\n",
      "3299it [02:16, 21.24it/s]\titers: 3300, epoch: 4 | loss: 0.3089044\n",
      "\tspeed: 0.0479s/iter; left time: 1104.7481s\n",
      "3398it [02:21, 21.09it/s]\titers: 3400, epoch: 4 | loss: 0.2029448\n",
      "\tspeed: 0.0471s/iter; left time: 1081.0275s\n",
      "3497it [02:25, 20.95it/s]\titers: 3500, epoch: 4 | loss: 0.3088215\n",
      "\tspeed: 0.0476s/iter; left time: 1087.5622s\n",
      "3599it [02:30, 27.27it/s]\titers: 3600, epoch: 4 | loss: 0.1561490\n",
      "\tspeed: 0.0401s/iter; left time: 912.9358s\n",
      "3698it [02:33, 27.36it/s]\titers: 3700, epoch: 4 | loss: 0.3454553\n",
      "\tspeed: 0.0376s/iter; left time: 852.8090s\n",
      "3765it [02:36, 24.09it/s]\n",
      "Epoch: 4 cost time: 156.27535557746887\n",
      "810it [00:17, 45.01it/s]\n",
      "807it [00:18, 43.44it/s]\n",
      "Epoch: 4 | Train Loss: 0.3204753 Vali Loss: 0.3905744 Test Loss: 0.4751004 MAE Loss: 0.4565349\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009045095\n",
      "99it [00:05, 20.50it/s]\titers: 100, epoch: 5 | loss: 0.5114356\n",
      "\tspeed: 0.4423s/iter; left time: 9947.7212s\n",
      "198it [00:10, 21.05it/s]\titers: 200, epoch: 5 | loss: 0.2971494\n",
      "\tspeed: 0.0505s/iter; left time: 1131.6382s\n",
      "297it [00:14, 21.01it/s]\titers: 300, epoch: 5 | loss: 0.3125830\n",
      "\tspeed: 0.0483s/iter; left time: 1077.4839s\n",
      "399it [00:19, 21.21it/s]\titers: 400, epoch: 5 | loss: 0.4674928\n",
      "\tspeed: 0.0473s/iter; left time: 1050.3463s\n",
      "498it [00:24, 20.48it/s]\titers: 500, epoch: 5 | loss: 0.3742061\n",
      "\tspeed: 0.0480s/iter; left time: 1059.8783s\n",
      "599it [00:29, 21.20it/s]\titers: 600, epoch: 5 | loss: 0.3702931\n",
      "\tspeed: 0.0518s/iter; left time: 1138.2132s\n",
      "697it [00:34, 21.15it/s]\titers: 700, epoch: 5 | loss: 0.4345067\n",
      "\tspeed: 0.0481s/iter; left time: 1053.7569s\n",
      "799it [00:39, 20.85it/s]\titers: 800, epoch: 5 | loss: 0.3023509\n",
      "\tspeed: 0.0477s/iter; left time: 1038.7366s\n",
      "898it [00:43, 20.56it/s]\titers: 900, epoch: 5 | loss: 0.3903047\n",
      "\tspeed: 0.0475s/iter; left time: 1030.5947s\n",
      "997it [00:47, 27.38it/s]\titers: 1000, epoch: 5 | loss: 0.4191611\n",
      "\tspeed: 0.0387s/iter; left time: 834.5451s\n",
      "1099it [00:51, 27.36it/s]\titers: 1100, epoch: 5 | loss: 0.3491889\n",
      "\tspeed: 0.0374s/iter; left time: 803.4166s\n",
      "1198it [00:55, 27.15it/s]\titers: 1200, epoch: 5 | loss: 0.2972980\n",
      "\tspeed: 0.0366s/iter; left time: 783.1440s\n",
      "1297it [00:58, 26.84it/s]\titers: 1300, epoch: 5 | loss: 0.2884289\n",
      "\tspeed: 0.0370s/iter; left time: 786.9208s\n",
      "1399it [01:02, 22.90it/s]\titers: 1400, epoch: 5 | loss: 0.3549766\n",
      "\tspeed: 0.0386s/iter; left time: 817.0576s\n",
      "1498it [01:06, 22.84it/s]\titers: 1500, epoch: 5 | loss: 0.3484952\n",
      "\tspeed: 0.0392s/iter; left time: 825.7628s\n",
      "1597it [01:10, 27.13it/s]\titers: 1600, epoch: 5 | loss: 0.5403878\n",
      "\tspeed: 0.0365s/iter; left time: 765.5356s\n",
      "1699it [01:14, 27.05it/s]\titers: 1700, epoch: 5 | loss: 0.1983688\n",
      "\tspeed: 0.0368s/iter; left time: 769.0428s\n",
      "1798it [01:17, 27.02it/s]\titers: 1800, epoch: 5 | loss: 0.2171077\n",
      "\tspeed: 0.0371s/iter; left time: 770.3824s\n",
      "1897it [01:21, 22.84it/s]\titers: 1900, epoch: 5 | loss: 0.4971854\n",
      "\tspeed: 0.0391s/iter; left time: 808.3311s\n",
      "1998it [01:26, 21.04it/s]\titers: 2000, epoch: 5 | loss: 0.2002450\n",
      "\tspeed: 0.0483s/iter; left time: 995.2059s\n",
      "2097it [01:31, 20.99it/s]\titers: 2100, epoch: 5 | loss: 0.5598083\n",
      "\tspeed: 0.0474s/iter; left time: 971.8616s\n",
      "2199it [01:36, 20.69it/s]\titers: 2200, epoch: 5 | loss: 0.3465590\n",
      "\tspeed: 0.0478s/iter; left time: 975.7022s\n",
      "2298it [01:41, 15.77it/s]\titers: 2300, epoch: 5 | loss: 0.2491348\n",
      "\tspeed: 0.0517s/iter; left time: 1049.8368s\n",
      "2397it [01:46, 20.88it/s]\titers: 2400, epoch: 5 | loss: 0.2876121\n",
      "\tspeed: 0.0492s/iter; left time: 992.6685s\n",
      "2499it [01:50, 21.08it/s]\titers: 2500, epoch: 5 | loss: 0.2320451\n",
      "\tspeed: 0.0473s/iter; left time: 950.2775s\n",
      "2598it [01:55, 20.96it/s]\titers: 2600, epoch: 5 | loss: 0.2770251\n",
      "\tspeed: 0.0476s/iter; left time: 950.9846s\n",
      "2699it [02:00, 25.32it/s]\titers: 2700, epoch: 5 | loss: 0.4038777\n",
      "\tspeed: 0.0466s/iter; left time: 927.1267s\n",
      "2798it [02:04, 26.62it/s]\titers: 2800, epoch: 5 | loss: 0.2016129\n",
      "\tspeed: 0.0385s/iter; left time: 761.9415s\n",
      "2897it [02:07, 26.76it/s]\titers: 2900, epoch: 5 | loss: 0.2829544\n",
      "\tspeed: 0.0374s/iter; left time: 736.9993s\n",
      "2999it [02:11, 20.61it/s]\titers: 3000, epoch: 5 | loss: 0.2861705\n",
      "\tspeed: 0.0395s/iter; left time: 774.4572s\n",
      "3099it [02:16, 19.57it/s]\titers: 3100, epoch: 5 | loss: 0.2588844\n",
      "\tspeed: 0.0507s/iter; left time: 987.3758s\n",
      "3197it [02:21, 26.86it/s]\titers: 3200, epoch: 5 | loss: 0.2216300\n",
      "\tspeed: 0.0445s/iter; left time: 862.0830s\n",
      "3299it [02:25, 21.27it/s]\titers: 3300, epoch: 5 | loss: 0.1830666\n",
      "\tspeed: 0.0459s/iter; left time: 884.6158s\n",
      "3398it [02:30, 20.26it/s]\titers: 3400, epoch: 5 | loss: 0.2615009\n",
      "\tspeed: 0.0468s/iter; left time: 898.1271s\n",
      "3499it [02:35, 20.10it/s]\titers: 3500, epoch: 5 | loss: 0.2588952\n",
      "\tspeed: 0.0478s/iter; left time: 913.2631s\n",
      "3598it [02:40, 20.94it/s]\titers: 3600, epoch: 5 | loss: 0.3004991\n",
      "\tspeed: 0.0500s/iter; left time: 949.7210s\n",
      "3699it [02:45, 19.94it/s]\titers: 3700, epoch: 5 | loss: 0.1559768\n",
      "\tspeed: 0.0493s/iter; left time: 930.9505s\n",
      "3765it [02:48, 22.35it/s]\n",
      "Epoch: 5 cost time: 168.4597749710083\n",
      "810it [00:18, 44.00it/s]\n",
      "807it [00:18, 43.17it/s]\n",
      "Epoch: 5 | Train Loss: 0.3224744 Vali Loss: 0.3772124 Test Loss: 0.4597662 MAE Loss: 0.4469471\n",
      "lr = 0.0008535549\n",
      "99it [00:05, 21.19it/s]\titers: 100, epoch: 6 | loss: 0.2958024\n",
      "\tspeed: 0.4623s/iter; left time: 8656.4711s\n",
      "199it [00:10, 21.03it/s]\titers: 200, epoch: 6 | loss: 0.2543693\n",
      "\tspeed: 0.0516s/iter; left time: 961.6236s\n",
      "298it [00:14, 23.69it/s]\titers: 300, epoch: 6 | loss: 0.2879804\n",
      "\tspeed: 0.0473s/iter; left time: 876.2281s\n",
      "397it [00:19, 20.96it/s]\titers: 400, epoch: 6 | loss: 0.2328642\n",
      "\tspeed: 0.0442s/iter; left time: 814.7067s\n",
      "499it [00:24, 22.62it/s]\titers: 500, epoch: 6 | loss: 0.1856288\n",
      "\tspeed: 0.0475s/iter; left time: 869.6534s\n",
      "599it [00:29, 21.18it/s]\titers: 600, epoch: 6 | loss: 0.2731483\n",
      "\tspeed: 0.0507s/iter; left time: 923.5205s\n",
      "698it [00:33, 21.82it/s]\titers: 700, epoch: 6 | loss: 0.3817542\n",
      "\tspeed: 0.0475s/iter; left time: 860.8417s\n",
      "797it [00:38, 23.05it/s]\titers: 800, epoch: 6 | loss: 0.8012062\n",
      "\tspeed: 0.0442s/iter; left time: 795.8678s\n",
      "899it [00:43, 20.84it/s]\titers: 900, epoch: 6 | loss: 0.2722598\n",
      "\tspeed: 0.0476s/iter; left time: 852.5490s\n",
      "997it [00:47, 21.14it/s]\titers: 1000, epoch: 6 | loss: 0.2642626\n",
      "\tspeed: 0.0496s/iter; left time: 883.4337s\n",
      "1099it [00:52, 20.92it/s]\titers: 1100, epoch: 6 | loss: 0.2800905\n",
      "\tspeed: 0.0484s/iter; left time: 857.7048s\n",
      "1198it [00:57, 20.84it/s]\titers: 1200, epoch: 6 | loss: 0.3022359\n",
      "\tspeed: 0.0479s/iter; left time: 843.8720s\n",
      "1297it [01:02, 20.70it/s]\titers: 1300, epoch: 6 | loss: 0.2131541\n",
      "\tspeed: 0.0482s/iter; left time: 844.5874s\n",
      "1397it [01:07, 18.02it/s]\titers: 1400, epoch: 6 | loss: 0.2865126\n",
      "\tspeed: 0.0504s/iter; left time: 878.1772s\n",
      "1499it [01:12, 21.13it/s]\titers: 1500, epoch: 6 | loss: 0.2035251\n",
      "\tspeed: 0.0473s/iter; left time: 819.0392s\n",
      "1598it [01:16, 20.96it/s]\titers: 1600, epoch: 6 | loss: 0.3789158\n",
      "\tspeed: 0.0476s/iter; left time: 819.1669s\n",
      "1699it [01:21, 20.07it/s]\titers: 1700, epoch: 6 | loss: 0.4201375\n",
      "\tspeed: 0.0494s/iter; left time: 846.8244s\n",
      "1797it [01:26, 21.17it/s]\titers: 1800, epoch: 6 | loss: 0.2539242\n",
      "\tspeed: 0.0481s/iter; left time: 818.6785s\n",
      "1899it [01:31, 21.15it/s]\titers: 1900, epoch: 6 | loss: 0.3878720\n",
      "\tspeed: 0.0474s/iter; left time: 802.3934s\n",
      "1998it [01:36, 20.89it/s]\titers: 2000, epoch: 6 | loss: 0.3672203\n",
      "\tspeed: 0.0476s/iter; left time: 801.1784s\n",
      "2097it [01:41, 21.08it/s]\titers: 2100, epoch: 6 | loss: 0.3250736\n",
      "\tspeed: 0.0494s/iter; left time: 826.8834s\n",
      "2198it [01:45, 21.17it/s]\titers: 2200, epoch: 6 | loss: 0.3259186\n",
      "\tspeed: 0.0481s/iter; left time: 799.0424s\n",
      "2297it [01:50, 20.97it/s]\titers: 2300, epoch: 6 | loss: 0.2795841\n",
      "\tspeed: 0.0474s/iter; left time: 784.0305s\n",
      "2399it [01:55, 20.55it/s]\titers: 2400, epoch: 6 | loss: 0.1800817\n",
      "\tspeed: 0.0480s/iter; left time: 788.5787s\n",
      "2498it [02:00, 19.51it/s]\titers: 2500, epoch: 6 | loss: 0.2662502\n",
      "\tspeed: 0.0498s/iter; left time: 812.4997s\n",
      "2597it [02:05, 20.44it/s]\titers: 2600, epoch: 6 | loss: 0.3422699\n",
      "\tspeed: 0.0482s/iter; left time: 782.3520s\n",
      "2697it [02:10, 21.08it/s]\titers: 2700, epoch: 6 | loss: 0.2123109\n",
      "\tspeed: 0.0477s/iter; left time: 769.9223s\n",
      "2798it [02:15, 20.55it/s]\titers: 2800, epoch: 6 | loss: 0.2100588\n",
      "\tspeed: 0.0512s/iter; left time: 820.7193s\n",
      "2899it [02:20, 21.42it/s]\titers: 2900, epoch: 6 | loss: 0.3533497\n",
      "\tspeed: 0.0536s/iter; left time: 853.6616s\n",
      "2999it [02:25, 21.12it/s]\titers: 3000, epoch: 6 | loss: 0.2326804\n",
      "\tspeed: 0.0481s/iter; left time: 761.5920s\n",
      "3098it [02:30, 20.74it/s]\titers: 3100, epoch: 6 | loss: 0.3390313\n",
      "\tspeed: 0.0469s/iter; left time: 737.9092s\n",
      "3197it [02:34, 19.97it/s]\titers: 3200, epoch: 6 | loss: 0.2468730\n",
      "\tspeed: 0.0488s/iter; left time: 761.9891s\n",
      "3298it [02:39, 18.75it/s]\titers: 3300, epoch: 6 | loss: 0.2851472\n",
      "\tspeed: 0.0467s/iter; left time: 725.0941s\n",
      "3397it [02:44, 21.01it/s]\titers: 3400, epoch: 6 | loss: 0.2096411\n",
      "\tspeed: 0.0475s/iter; left time: 732.9611s\n",
      "3499it [02:49, 20.83it/s]\titers: 3500, epoch: 6 | loss: 0.2350686\n",
      "\tspeed: 0.0478s/iter; left time: 732.5273s\n",
      "3599it [02:54, 14.74it/s]\titers: 3600, epoch: 6 | loss: 0.5517228\n",
      "\tspeed: 0.0498s/iter; left time: 757.5323s\n",
      "3699it [02:59, 21.10it/s]\titers: 3700, epoch: 6 | loss: 0.1718680\n",
      "\tspeed: 0.0493s/iter; left time: 746.2608s\n",
      "3765it [03:02, 20.65it/s]\n",
      "Epoch: 6 cost time: 182.2835602760315\n",
      "810it [00:18, 44.60it/s]\n",
      "807it [00:17, 44.92it/s]\n",
      "Epoch: 6 | Train Loss: 0.3213154 Vali Loss: 0.4017328 Test Loss: 0.4942164 MAE Loss: 0.4657476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:05, 20.55it/s]\titers: 100, epoch: 7 | loss: 0.2587365\n",
      "\tspeed: 0.4454s/iter; left time: 6662.9005s\n",
      "198it [00:10, 16.38it/s]\titers: 200, epoch: 7 | loss: 0.2547185\n",
      "\tspeed: 0.0510s/iter; left time: 757.5494s\n",
      "299it [00:15, 20.93it/s]\titers: 300, epoch: 7 | loss: 0.1711255\n",
      "\tspeed: 0.0489s/iter; left time: 721.7260s\n",
      "398it [00:19, 21.09it/s]\titers: 400, epoch: 7 | loss: 0.2923927\n",
      "\tspeed: 0.0476s/iter; left time: 697.2360s\n",
      "497it [00:23, 26.99it/s]\titers: 500, epoch: 7 | loss: 0.1488027\n",
      "\tspeed: 0.0366s/iter; left time: 532.9011s\n",
      "599it [00:27, 25.63it/s]\titers: 600, epoch: 7 | loss: 0.2476059\n",
      "\tspeed: 0.0375s/iter; left time: 542.8747s\n",
      "698it [00:31, 27.17it/s]\titers: 700, epoch: 7 | loss: 0.3122873\n",
      "\tspeed: 0.0390s/iter; left time: 560.4698s\n",
      "797it [00:34, 27.43it/s]\titers: 800, epoch: 7 | loss: 0.3172768\n",
      "\tspeed: 0.0376s/iter; left time: 536.6844s\n",
      "899it [00:38, 27.41it/s]\titers: 900, epoch: 7 | loss: 0.3705570\n",
      "\tspeed: 0.0365s/iter; left time: 517.0791s\n",
      "998it [00:42, 26.85it/s]\titers: 1000, epoch: 7 | loss: 0.3579290\n",
      "\tspeed: 0.0369s/iter; left time: 518.3106s\n",
      "1097it [00:46, 22.44it/s]\titers: 1100, epoch: 7 | loss: 0.2547010\n",
      "\tspeed: 0.0390s/iter; left time: 544.1085s\n",
      "1198it [00:51, 20.64it/s]\titers: 1200, epoch: 7 | loss: 0.2480060\n",
      "\tspeed: 0.0496s/iter; left time: 687.8022s\n",
      "1297it [00:55, 26.54it/s]\titers: 1300, epoch: 7 | loss: 0.3988118\n",
      "\tspeed: 0.0450s/iter; left time: 619.4049s\n",
      "1399it [00:59, 27.14it/s]\titers: 1400, epoch: 7 | loss: 0.5011163\n",
      "\tspeed: 0.0369s/iter; left time: 503.7082s\n",
      "1498it [01:02, 26.86it/s]\titers: 1500, epoch: 7 | loss: 0.4515625\n",
      "\tspeed: 0.0370s/iter; left time: 501.9912s\n",
      "1599it [01:07, 20.30it/s]\titers: 1600, epoch: 7 | loss: 0.3117883\n",
      "\tspeed: 0.0421s/iter; left time: 567.0180s\n",
      "1697it [01:11, 21.14it/s]\titers: 1700, epoch: 7 | loss: 0.2716990\n",
      "\tspeed: 0.0479s/iter; left time: 640.2915s\n",
      "1799it [01:16, 20.88it/s]\titers: 1800, epoch: 7 | loss: 0.7125716\n",
      "\tspeed: 0.0476s/iter; left time: 631.4124s\n",
      "1898it [01:21, 20.75it/s]\titers: 1900, epoch: 7 | loss: 0.2071300\n",
      "\tspeed: 0.0482s/iter; left time: 634.4243s\n",
      "1997it [01:26, 20.86it/s]\titers: 2000, epoch: 7 | loss: 0.2426393\n",
      "\tspeed: 0.0518s/iter; left time: 676.1557s\n",
      "2098it [01:31, 21.27it/s]\titers: 2100, epoch: 7 | loss: 0.1984317\n",
      "\tspeed: 0.0481s/iter; left time: 623.0700s\n",
      "2197it [01:36, 21.06it/s]\titers: 2200, epoch: 7 | loss: 0.1494288\n",
      "\tspeed: 0.0473s/iter; left time: 608.5924s\n",
      "2299it [01:41, 20.81it/s]\titers: 2300, epoch: 7 | loss: 0.5832052\n",
      "\tspeed: 0.0478s/iter; left time: 610.3334s\n",
      "2398it [01:46, 21.22it/s]\titers: 2400, epoch: 7 | loss: 0.3682876\n",
      "\tspeed: 0.0497s/iter; left time: 629.0434s\n",
      "2499it [01:50, 21.03it/s]\titers: 2500, epoch: 7 | loss: 0.2163977\n",
      "\tspeed: 0.0482s/iter; left time: 605.6113s\n",
      "2598it [01:55, 20.55it/s]\titers: 2600, epoch: 7 | loss: 0.2967719\n",
      "\tspeed: 0.0483s/iter; left time: 601.8369s\n",
      "2697it [02:00, 20.62it/s]\titers: 2700, epoch: 7 | loss: 0.1685931\n",
      "\tspeed: 0.0483s/iter; left time: 596.8250s\n",
      "2798it [02:05, 21.09it/s]\titers: 2800, epoch: 7 | loss: 0.3736131\n",
      "\tspeed: 0.0479s/iter; left time: 587.8981s\n",
      "2899it [02:10, 21.22it/s]\titers: 2900, epoch: 7 | loss: 0.3515452\n",
      "\tspeed: 0.0480s/iter; left time: 583.2520s\n",
      "2998it [02:14, 21.02it/s]\titers: 3000, epoch: 7 | loss: 0.2952559\n",
      "\tspeed: 0.0474s/iter; left time: 571.1567s\n",
      "3097it [02:19, 20.23it/s]\titers: 3100, epoch: 7 | loss: 0.2084351\n",
      "\tspeed: 0.0478s/iter; left time: 571.7854s\n",
      "3198it [02:24, 20.42it/s]\titers: 3200, epoch: 7 | loss: 0.3070467\n",
      "\tspeed: 0.0506s/iter; left time: 599.6979s\n",
      "3297it [02:29, 21.60it/s]\titers: 3300, epoch: 7 | loss: 0.6324226\n",
      "\tspeed: 0.0466s/iter; left time: 548.0819s\n",
      "3399it [02:34, 21.10it/s]\titers: 3400, epoch: 7 | loss: 0.3521353\n",
      "\tspeed: 0.0476s/iter; left time: 555.4930s\n",
      "3498it [02:39, 19.67it/s]\titers: 3500, epoch: 7 | loss: 0.4087745\n",
      "\tspeed: 0.0500s/iter; left time: 577.7285s\n",
      "3599it [02:43, 21.24it/s]\titers: 3600, epoch: 7 | loss: 0.3843343\n",
      "\tspeed: 0.0479s/iter; left time: 548.7708s\n",
      "3698it [02:48, 20.73it/s]\titers: 3700, epoch: 7 | loss: 0.3293202\n",
      "\tspeed: 0.0478s/iter; left time: 543.4140s\n",
      "3765it [02:51, 21.90it/s]\n",
      "Epoch: 7 cost time: 171.95327973365784\n",
      "810it [00:18, 44.44it/s]\n",
      "807it [00:18, 42.84it/s]\n",
      "Epoch: 7 | Train Loss: 0.3234013 Vali Loss: 0.3747493 Test Loss: 0.4566241 MAE Loss: 0.4435625\n",
      "lr = 0.0007269980\n",
      "98it [00:04, 26.95it/s]\titers: 100, epoch: 8 | loss: 0.2370737\n",
      "\tspeed: 0.4635s/iter; left time: 5188.9216s\n",
      "199it [00:10, 26.83it/s]\titers: 200, epoch: 8 | loss: 0.2688916\n",
      "\tspeed: 0.0574s/iter; left time: 636.9600s\n",
      "298it [00:14, 26.09it/s]\titers: 300, epoch: 8 | loss: 0.3205290\n",
      "\tspeed: 0.0375s/iter; left time: 412.0353s\n",
      "397it [00:17, 27.66it/s]\titers: 400, epoch: 8 | loss: 0.3317786\n",
      "\tspeed: 0.0362s/iter; left time: 394.7026s\n",
      "499it [00:21, 27.31it/s]\titers: 500, epoch: 8 | loss: 0.2706827\n",
      "\tspeed: 0.0367s/iter; left time: 396.6736s\n",
      "599it [00:26, 18.93it/s]\titers: 600, epoch: 8 | loss: 0.2474581\n",
      "\tspeed: 0.0469s/iter; left time: 501.6240s\n",
      "697it [00:31, 20.77it/s]\titers: 700, epoch: 8 | loss: 0.2209042\n",
      "\tspeed: 0.0507s/iter; left time: 536.8410s\n",
      "798it [00:36, 21.10it/s]\titers: 800, epoch: 8 | loss: 0.2024046\n",
      "\tspeed: 0.0477s/iter; left time: 500.4043s\n",
      "897it [00:40, 21.11it/s]\titers: 900, epoch: 8 | loss: 0.2397825\n",
      "\tspeed: 0.0470s/iter; left time: 488.4791s\n",
      "999it [00:45, 20.11it/s]\titers: 1000, epoch: 8 | loss: 0.2143180\n",
      "\tspeed: 0.0491s/iter; left time: 505.1641s\n",
      "1097it [00:50, 20.93it/s]\titers: 1100, epoch: 8 | loss: 0.2608615\n",
      "\tspeed: 0.0483s/iter; left time: 492.8664s\n",
      "1199it [00:55, 20.71it/s]\titers: 1200, epoch: 8 | loss: 0.4630672\n",
      "\tspeed: 0.0482s/iter; left time: 486.8689s\n",
      "1298it [01:00, 20.90it/s]\titers: 1300, epoch: 8 | loss: 0.1618113\n",
      "\tspeed: 0.0477s/iter; left time: 477.2932s\n",
      "1399it [01:05, 20.78it/s]\titers: 1400, epoch: 8 | loss: 0.3430657\n",
      "\tspeed: 0.0498s/iter; left time: 493.3012s\n",
      "1497it [01:09, 21.07it/s]\titers: 1500, epoch: 8 | loss: 0.4110596\n",
      "\tspeed: 0.0481s/iter; left time: 470.7673s\n",
      "1599it [01:14, 21.13it/s]\titers: 1600, epoch: 8 | loss: 0.2552519\n",
      "\tspeed: 0.0473s/iter; left time: 458.6032s\n",
      "1698it [01:19, 21.21it/s]\titers: 1700, epoch: 8 | loss: 0.3897755\n",
      "\tspeed: 0.0473s/iter; left time: 453.4321s\n",
      "1797it [01:24, 21.12it/s]\titers: 1800, epoch: 8 | loss: 0.2326892\n",
      "\tspeed: 0.0507s/iter; left time: 481.2013s\n",
      "1897it [01:29, 20.96it/s]\titers: 1900, epoch: 8 | loss: 0.3441693\n",
      "\tspeed: 0.0483s/iter; left time: 453.9980s\n",
      "1999it [01:34, 20.81it/s]\titers: 2000, epoch: 8 | loss: 0.2448245\n",
      "\tspeed: 0.0477s/iter; left time: 443.7403s\n",
      "2097it [01:38, 27.13it/s]\titers: 2100, epoch: 8 | loss: 0.4092216\n",
      "\tspeed: 0.0417s/iter; left time: 383.5085s\n",
      "2199it [01:42, 21.21it/s]\titers: 2200, epoch: 8 | loss: 0.2047655\n",
      "\tspeed: 0.0457s/iter; left time: 415.7672s\n",
      "2297it [01:47, 21.10it/s]\titers: 2300, epoch: 8 | loss: 0.1774275\n",
      "\tspeed: 0.0481s/iter; left time: 432.8215s\n",
      "2399it [01:52, 22.97it/s]\titers: 2400, epoch: 8 | loss: 0.4591852\n",
      "\tspeed: 0.0467s/iter; left time: 415.1618s\n",
      "2498it [01:57, 18.88it/s]\titers: 2500, epoch: 8 | loss: 0.2251620\n",
      "\tspeed: 0.0473s/iter; left time: 416.1399s\n",
      "2599it [02:02, 19.77it/s]\titers: 2600, epoch: 8 | loss: 0.5411199\n",
      "\tspeed: 0.0537s/iter; left time: 467.2429s\n",
      "2699it [02:07, 19.82it/s]\titers: 2700, epoch: 8 | loss: 0.2770391\n",
      "\tspeed: 0.0509s/iter; left time: 437.8115s\n",
      "2799it [02:12, 23.03it/s]\titers: 2800, epoch: 8 | loss: 0.3129892\n",
      "\tspeed: 0.0470s/iter; left time: 399.5721s\n",
      "2898it [02:17, 19.29it/s]\titers: 2900, epoch: 8 | loss: 0.2220390\n",
      "\tspeed: 0.0523s/iter; left time: 438.7485s\n",
      "2998it [02:22, 18.97it/s]\titers: 3000, epoch: 8 | loss: 0.3038004\n",
      "\tspeed: 0.0523s/iter; left time: 433.5256s\n",
      "3098it [02:27, 22.55it/s]\titers: 3100, epoch: 8 | loss: 0.3250084\n",
      "\tspeed: 0.0476s/iter; left time: 389.7898s\n",
      "3197it [02:31, 21.86it/s]\titers: 3200, epoch: 8 | loss: 0.4287906\n",
      "\tspeed: 0.0454s/iter; left time: 367.3743s\n",
      "3299it [02:37, 18.40it/s]\titers: 3300, epoch: 8 | loss: 0.3246199\n",
      "\tspeed: 0.0546s/iter; left time: 436.3940s\n",
      "3399it [02:42, 25.38it/s]\titers: 3400, epoch: 8 | loss: 0.4069696\n",
      "\tspeed: 0.0465s/iter; left time: 366.9141s\n",
      "3498it [02:46, 23.40it/s]\titers: 3500, epoch: 8 | loss: 0.4347954\n",
      "\tspeed: 0.0467s/iter; left time: 364.4541s\n",
      "3597it [02:51, 18.77it/s]\titers: 3600, epoch: 8 | loss: 0.2451416\n",
      "\tspeed: 0.0505s/iter; left time: 388.9816s\n",
      "3698it [02:56, 21.19it/s]\titers: 3700, epoch: 8 | loss: 0.2654694\n",
      "\tspeed: 0.0462s/iter; left time: 350.9345s\n",
      "3765it [02:59, 20.98it/s]\n",
      "Epoch: 8 cost time: 179.48489117622375\n",
      "810it [00:17, 45.07it/s]\n",
      "807it [00:18, 43.79it/s]\n",
      "Epoch: 8 | Train Loss: 0.3110532 Vali Loss: 0.3892361 Test Loss: 0.4766645 MAE Loss: 0.4625494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0006545120\n",
      "97it [00:04, 20.07it/s]\titers: 100, epoch: 9 | loss: 0.3401400\n",
      "\tspeed: 0.4453s/iter; left time: 3308.8656s\n",
      "199it [00:09, 22.79it/s]\titers: 200, epoch: 9 | loss: 0.2310641\n",
      "\tspeed: 0.0475s/iter; left time: 347.9327s\n",
      "298it [00:14, 24.71it/s]\titers: 300, epoch: 9 | loss: 0.2725943\n",
      "\tspeed: 0.0459s/iter; left time: 332.1790s\n",
      "397it [00:19, 21.19it/s]\titers: 400, epoch: 9 | loss: 0.3125853\n",
      "\tspeed: 0.0480s/iter; left time: 342.1198s\n",
      "499it [00:23, 21.19it/s]\titers: 500, epoch: 9 | loss: 0.2465193\n",
      "\tspeed: 0.0437s/iter; left time: 307.1876s\n",
      "598it [00:28, 20.00it/s]\titers: 600, epoch: 9 | loss: 0.2563796\n",
      "\tspeed: 0.0475s/iter; left time: 329.4982s\n",
      "697it [00:33, 20.48it/s]\titers: 700, epoch: 9 | loss: 0.3062128\n",
      "\tspeed: 0.0502s/iter; left time: 343.0219s\n",
      "798it [00:38, 19.81it/s]\titers: 800, epoch: 9 | loss: 0.1679011\n",
      "\tspeed: 0.0490s/iter; left time: 329.5344s\n",
      "899it [00:42, 21.04it/s]\titers: 900, epoch: 9 | loss: 0.2823606\n",
      "\tspeed: 0.0482s/iter; left time: 319.4853s\n",
      "999it [00:47, 19.97it/s]\titers: 1000, epoch: 9 | loss: 0.2486612\n",
      "\tspeed: 0.0497s/iter; left time: 324.8969s\n",
      "1099it [00:53, 19.86it/s]\titers: 1100, epoch: 9 | loss: 0.2816679\n",
      "\tspeed: 0.0505s/iter; left time: 324.8751s\n",
      "1198it [00:58, 20.45it/s]\titers: 1200, epoch: 9 | loss: 0.4455756\n",
      "\tspeed: 0.0513s/iter; left time: 324.8918s\n",
      "1299it [01:02, 25.79it/s]\titers: 1300, epoch: 9 | loss: 0.5901271\n",
      "\tspeed: 0.0408s/iter; left time: 254.0769s\n",
      "1399it [01:07, 20.32it/s]\titers: 1400, epoch: 9 | loss: 0.2027962\n",
      "\tspeed: 0.0485s/iter; left time: 297.2910s\n",
      "1498it [01:12, 19.76it/s]\titers: 1500, epoch: 9 | loss: 0.2655527\n",
      "\tspeed: 0.0511s/iter; left time: 308.2946s\n",
      "1598it [01:17, 20.08it/s]\titers: 1600, epoch: 9 | loss: 0.3382596\n",
      "\tspeed: 0.0497s/iter; left time: 294.7743s\n",
      "1698it [01:22, 18.41it/s]\titers: 1700, epoch: 9 | loss: 0.2737886\n",
      "\tspeed: 0.0519s/iter; left time: 302.3528s\n",
      "1797it [01:27, 19.66it/s]\titers: 1800, epoch: 9 | loss: 0.4017577\n",
      "\tspeed: 0.0517s/iter; left time: 296.3614s\n",
      "1899it [01:32, 20.79it/s]\titers: 1900, epoch: 9 | loss: 0.2776239\n",
      "\tspeed: 0.0489s/iter; left time: 275.2311s\n",
      "1998it [01:37, 20.12it/s]\titers: 2000, epoch: 9 | loss: 0.1964203\n",
      "\tspeed: 0.0484s/iter; left time: 267.9413s\n",
      "2097it [01:42, 20.25it/s]\titers: 2100, epoch: 9 | loss: 0.2677019\n",
      "\tspeed: 0.0511s/iter; left time: 277.5615s\n",
      "2199it [01:47, 23.40it/s]\titers: 2200, epoch: 9 | loss: 0.1595493\n",
      "\tspeed: 0.0473s/iter; left time: 252.1521s\n",
      "2298it [01:50, 27.52it/s]\titers: 2300, epoch: 9 | loss: 0.1916599\n",
      "\tspeed: 0.0368s/iter; left time: 192.3084s\n",
      "2397it [01:54, 27.19it/s]\titers: 2400, epoch: 9 | loss: 0.2173805\n",
      "\tspeed: 0.0367s/iter; left time: 188.4590s\n",
      "2499it [01:58, 23.81it/s]\titers: 2500, epoch: 9 | loss: 0.2299462\n",
      "\tspeed: 0.0378s/iter; left time: 190.1064s\n",
      "2598it [02:02, 27.32it/s]\titers: 2600, epoch: 9 | loss: 0.1971519\n",
      "\tspeed: 0.0382s/iter; left time: 188.4613s\n",
      "2697it [02:05, 27.84it/s]\titers: 2700, epoch: 9 | loss: 0.3081047\n",
      "\tspeed: 0.0370s/iter; left time: 178.9160s\n",
      "2799it [02:09, 27.65it/s]\titers: 2800, epoch: 9 | loss: 0.2252719\n",
      "\tspeed: 0.0360s/iter; left time: 170.1578s\n",
      "2898it [02:13, 21.04it/s]\titers: 2900, epoch: 9 | loss: 0.2207107\n",
      "\tspeed: 0.0430s/iter; left time: 199.3611s\n",
      "2998it [02:18, 20.97it/s]\titers: 3000, epoch: 9 | loss: 0.2741799\n",
      "\tspeed: 0.0475s/iter; left time: 215.2740s\n",
      "3099it [02:23, 21.48it/s]\titers: 3100, epoch: 9 | loss: 0.2624743\n",
      "\tspeed: 0.0478s/iter; left time: 211.9831s\n",
      "3198it [02:27, 21.43it/s]\titers: 3200, epoch: 9 | loss: 0.3671949\n",
      "\tspeed: 0.0469s/iter; left time: 203.0407s\n",
      "3297it [02:32, 21.11it/s]\titers: 3300, epoch: 9 | loss: 0.4108158\n",
      "\tspeed: 0.0472s/iter; left time: 199.7667s\n",
      "3397it [02:37, 19.04it/s]\titers: 3400, epoch: 9 | loss: 0.3032409\n",
      "\tspeed: 0.0502s/iter; left time: 207.5606s\n",
      "3498it [02:42, 21.19it/s]\titers: 3500, epoch: 9 | loss: 0.3279886\n",
      "\tspeed: 0.0472s/iter; left time: 190.1387s\n",
      "3597it [02:46, 21.26it/s]\titers: 3600, epoch: 9 | loss: 0.2641124\n",
      "\tspeed: 0.0472s/iter; left time: 185.4518s\n",
      "3699it [02:52, 19.24it/s]\titers: 3700, epoch: 9 | loss: 0.2115594\n",
      "\tspeed: 0.0529s/iter; left time: 202.6749s\n",
      "3765it [02:55, 21.42it/s]\n",
      "Epoch: 9 cost time: 175.78775358200073\n",
      "810it [00:18, 44.60it/s]\n",
      "807it [00:18, 44.68it/s]\n",
      "Epoch: 9 | Train Loss: 0.3078297 Vali Loss: 0.3715478 Test Loss: 0.4544242 MAE Loss: 0.4413584\n",
      "lr = 0.0005782215\n",
      "98it [00:05, 20.49it/s]\titers: 100, epoch: 10 | loss: 0.2440642\n",
      "\tspeed: 0.4611s/iter; left time: 1690.4033s\n",
      "198it [00:10, 18.75it/s]\titers: 200, epoch: 10 | loss: 0.2456951\n",
      "\tspeed: 0.0508s/iter; left time: 181.2130s\n",
      "299it [00:16, 16.75it/s]\titers: 300, epoch: 10 | loss: 0.4275633\n",
      "\tspeed: 0.0571s/iter; left time: 197.8642s\n",
      "398it [00:20, 19.65it/s]\titers: 400, epoch: 10 | loss: 0.3124236\n",
      "\tspeed: 0.0499s/iter; left time: 167.8328s\n",
      "499it [00:26, 18.82it/s]\titers: 500, epoch: 10 | loss: 0.3608543\n",
      "\tspeed: 0.0520s/iter; left time: 169.6971s\n",
      "598it [00:31, 18.83it/s]\titers: 600, epoch: 10 | loss: 0.2916918\n",
      "\tspeed: 0.0563s/iter; left time: 178.1282s\n",
      "698it [00:36, 19.80it/s]\titers: 700, epoch: 10 | loss: 0.4221830\n",
      "\tspeed: 0.0519s/iter; left time: 159.2734s\n",
      "798it [00:41, 21.07it/s]\titers: 800, epoch: 10 | loss: 0.1877646\n",
      "\tspeed: 0.0490s/iter; left time: 145.1963s\n",
      "897it [00:46, 20.93it/s]\titers: 900, epoch: 10 | loss: 0.2650401\n",
      "\tspeed: 0.0477s/iter; left time: 136.8025s\n",
      "998it [00:51, 18.27it/s]\titers: 1000, epoch: 10 | loss: 0.2981644\n",
      "\tspeed: 0.0509s/iter; left time: 140.7337s\n",
      "1097it [00:56, 20.92it/s]\titers: 1100, epoch: 10 | loss: 0.2430556\n",
      "\tspeed: 0.0473s/iter; left time: 125.9905s\n",
      "1199it [01:00, 24.66it/s]\titers: 1200, epoch: 10 | loss: 0.2154697\n",
      "\tspeed: 0.0425s/iter; left time: 109.0328s\n",
      "1298it [01:04, 24.02it/s]\titers: 1300, epoch: 10 | loss: 0.1716341\n",
      "\tspeed: 0.0425s/iter; left time: 104.7664s\n",
      "1397it [01:09, 21.16it/s]\titers: 1400, epoch: 10 | loss: 0.4797420\n",
      "\tspeed: 0.0457s/iter; left time: 108.1160s\n",
      "1498it [01:14, 20.97it/s]\titers: 1500, epoch: 10 | loss: 0.2266493\n",
      "\tspeed: 0.0481s/iter; left time: 109.0207s\n",
      "1597it [01:18, 27.21it/s]\titers: 1600, epoch: 10 | loss: 0.2267359\n",
      "\tspeed: 0.0437s/iter; left time: 94.7149s\n",
      "1699it [01:22, 26.79it/s]\titers: 1700, epoch: 10 | loss: 0.4768562\n",
      "\tspeed: 0.0369s/iter; left time: 76.3260s\n",
      "1798it [01:27, 18.57it/s]\titers: 1800, epoch: 10 | loss: 0.4119195\n",
      "\tspeed: 0.0479s/iter; left time: 94.2515s\n",
      "1899it [01:32, 21.39it/s]\titers: 1900, epoch: 10 | loss: 0.2874663\n",
      "\tspeed: 0.0477s/iter; left time: 89.0469s\n",
      "1998it [01:36, 20.95it/s]\titers: 2000, epoch: 10 | loss: 0.3070314\n",
      "\tspeed: 0.0472s/iter; left time: 83.3069s\n",
      "2097it [01:41, 21.01it/s]\titers: 2100, epoch: 10 | loss: 0.1895691\n",
      "\tspeed: 0.0475s/iter; left time: 79.0555s\n",
      "2197it [01:46, 21.23it/s]\titers: 2200, epoch: 10 | loss: 0.3342938\n",
      "\tspeed: 0.0489s/iter; left time: 76.6476s\n",
      "2298it [01:51, 21.24it/s]\titers: 2300, epoch: 10 | loss: 0.1965497\n",
      "\tspeed: 0.0478s/iter; left time: 70.0648s\n",
      "2397it [01:55, 21.04it/s]\titers: 2400, epoch: 10 | loss: 0.2242428\n",
      "\tspeed: 0.0474s/iter; left time: 64.7221s\n",
      "2499it [02:00, 20.78it/s]\titers: 2500, epoch: 10 | loss: 0.2465717\n",
      "\tspeed: 0.0479s/iter; left time: 60.6908s\n",
      "2599it [02:05, 21.36it/s]\titers: 2600, epoch: 10 | loss: 0.1841516\n",
      "\tspeed: 0.0484s/iter; left time: 56.4208s\n",
      "2698it [02:10, 21.34it/s]\titers: 2700, epoch: 10 | loss: 0.3883455\n",
      "\tspeed: 0.0477s/iter; left time: 50.8751s\n",
      "2797it [02:14, 20.98it/s]\titers: 2800, epoch: 10 | loss: 0.2909786\n",
      "\tspeed: 0.0473s/iter; left time: 45.6642s\n",
      "2899it [02:19, 17.78it/s]\titers: 2900, epoch: 10 | loss: 0.3305136\n",
      "\tspeed: 0.0489s/iter; left time: 42.3234s\n",
      "2997it [02:24, 20.91it/s]\titers: 3000, epoch: 10 | loss: 0.3906245\n",
      "\tspeed: 0.0500s/iter; left time: 38.3041s\n",
      "3099it [02:29, 21.30it/s]\titers: 3100, epoch: 10 | loss: 0.4345736\n",
      "\tspeed: 0.0469s/iter; left time: 31.2521s\n",
      "3198it [02:34, 20.88it/s]\titers: 3200, epoch: 10 | loss: 0.2772962\n",
      "\tspeed: 0.0472s/iter; left time: 26.6893s\n",
      "3297it [02:39, 21.25it/s]\titers: 3300, epoch: 10 | loss: 0.2467601\n",
      "\tspeed: 0.0484s/iter; left time: 22.5409s\n",
      "3399it [02:43, 21.24it/s]\titers: 3400, epoch: 10 | loss: 0.2804783\n",
      "\tspeed: 0.0478s/iter; left time: 17.4899s\n",
      "3498it [02:48, 21.22it/s]\titers: 3500, epoch: 10 | loss: 0.3329879\n",
      "\tspeed: 0.0469s/iter; left time: 12.4780s\n",
      "3597it [02:53, 21.12it/s]\titers: 3600, epoch: 10 | loss: 0.2088789\n",
      "\tspeed: 0.0471s/iter; left time: 7.8167s\n",
      "3698it [02:58, 20.99it/s]\titers: 3700, epoch: 10 | loss: 0.2641986\n",
      "\tspeed: 0.0486s/iter; left time: 3.2051s\n",
      "3765it [03:01, 20.75it/s]\n",
      "Epoch: 10 cost time: 181.4452724456787\n",
      "810it [00:18, 43.47it/s]\n",
      "807it [00:17, 44.88it/s]\n",
      "Epoch: 10 | Train Loss: 0.3051014 Vali Loss: 0.3621393 Test Loss: 0.4520630 MAE Loss: 0.4392797\n",
      "lr = 0.0005000050\n",
      "Total time: 35.74961925347646 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same but medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 01:48:31,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:48:32,846] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:48:32,846] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:48:32,846] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:48:33,757] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:48:33,757] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:48:34,760] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:48:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:48:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:48:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:48:34,762] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:48:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:48:34,762] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:48:34,762] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:48:34,763] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:48:34,763] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:48:35,014] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:48:35,015] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,015] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.67 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,247] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:48:35,248] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,248] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.67 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,248] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.73 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6c62b06a10>\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:11,  9.48it/s]\titers: 100, epoch: 1 | loss: 0.3093423\n",
      "\tspeed: 0.1584s/iter; left time: 5946.8943s\n",
      "199it [00:22,  9.01it/s]\titers: 200, epoch: 1 | loss: 0.2864971\n",
      "\tspeed: 0.1088s/iter; left time: 4074.6686s\n",
      "299it [00:34,  9.46it/s]\titers: 300, epoch: 1 | loss: 0.3281956\n",
      "\tspeed: 0.1127s/iter; left time: 4210.5223s\n",
      "399it [00:44,  9.10it/s]\titers: 400, epoch: 1 | loss: 0.2650904\n",
      "\tspeed: 0.1072s/iter; left time: 3991.9999s\n",
      "499it [00:56,  9.73it/s]\titers: 500, epoch: 1 | loss: 0.5327372\n",
      "\tspeed: 0.1122s/iter; left time: 4169.3313s\n",
      "599it [01:06,  9.20it/s]\titers: 600, epoch: 1 | loss: 0.4221294\n",
      "\tspeed: 0.1087s/iter; left time: 4028.9816s\n",
      "698it [01:17,  9.21it/s]\titers: 700, epoch: 1 | loss: 0.2700348\n",
      "\tspeed: 0.1081s/iter; left time: 3995.3631s\n",
      "799it [01:28,  9.62it/s]\titers: 800, epoch: 1 | loss: 0.1736799\n",
      "\tspeed: 0.1114s/iter; left time: 4103.4003s\n",
      "899it [01:39,  9.13it/s]\titers: 900, epoch: 1 | loss: 0.2950753\n",
      "\tspeed: 0.1092s/iter; left time: 4012.7293s\n",
      "999it [01:50,  9.60it/s]\titers: 1000, epoch: 1 | loss: 0.2127067\n",
      "\tspeed: 0.1071s/iter; left time: 3925.3058s\n",
      "1099it [02:01,  7.74it/s]\titers: 1100, epoch: 1 | loss: 0.2738011\n",
      "\tspeed: 0.1085s/iter; left time: 3966.7339s\n",
      "1199it [02:12,  9.47it/s]\titers: 1200, epoch: 1 | loss: 0.2650603\n",
      "\tspeed: 0.1072s/iter; left time: 3906.5220s\n",
      "1299it [02:22,  9.52it/s]\titers: 1300, epoch: 1 | loss: 0.2692506\n",
      "\tspeed: 0.1090s/iter; left time: 3960.5764s\n",
      "1399it [02:33,  9.11it/s]\titers: 1400, epoch: 1 | loss: 0.3322053\n",
      "\tspeed: 0.1071s/iter; left time: 3881.7457s\n",
      "1499it [02:44,  9.21it/s]\titers: 1500, epoch: 1 | loss: 0.4773281\n",
      "\tspeed: 0.1112s/iter; left time: 4018.2073s\n",
      "1599it [02:55,  9.46it/s]\titers: 1600, epoch: 1 | loss: 0.2954048\n",
      "\tspeed: 0.1119s/iter; left time: 4034.9733s\n",
      "1699it [03:06,  9.14it/s]\titers: 1700, epoch: 1 | loss: 0.2433645\n",
      "\tspeed: 0.1081s/iter; left time: 3884.9978s\n",
      "1799it [03:17,  9.23it/s]\titers: 1800, epoch: 1 | loss: 0.3445834\n",
      "\tspeed: 0.1100s/iter; left time: 3943.7320s\n",
      "1899it [03:28,  9.62it/s]\titers: 1900, epoch: 1 | loss: 0.3814037\n",
      "\tspeed: 0.1054s/iter; left time: 3768.5342s\n",
      "1999it [03:38, 10.13it/s]\titers: 2000, epoch: 1 | loss: 0.2499830\n",
      "\tspeed: 0.1025s/iter; left time: 3654.7135s\n",
      "2099it [03:48,  9.24it/s]\titers: 2100, epoch: 1 | loss: 0.3895558\n",
      "\tspeed: 0.1018s/iter; left time: 3619.6134s\n",
      "2199it [03:59,  9.91it/s]\titers: 2200, epoch: 1 | loss: 0.1822312\n",
      "\tspeed: 0.1024s/iter; left time: 3628.8298s\n",
      "2299it [04:09,  9.79it/s]\titers: 2300, epoch: 1 | loss: 0.3100661\n",
      "\tspeed: 0.1024s/iter; left time: 3619.9211s\n",
      "2399it [04:19,  9.92it/s]\titers: 2400, epoch: 1 | loss: 0.2622257\n",
      "\tspeed: 0.1015s/iter; left time: 3579.0270s\n",
      "2499it [04:30,  9.30it/s]\titers: 2500, epoch: 1 | loss: 0.2354961\n",
      "\tspeed: 0.1068s/iter; left time: 3754.3658s\n",
      "2598it [04:40,  9.84it/s]\titers: 2600, epoch: 1 | loss: 0.1916121\n",
      "\tspeed: 0.1053s/iter; left time: 3689.8174s\n",
      "2699it [04:50,  9.93it/s]\titers: 2700, epoch: 1 | loss: 0.1694384\n",
      "\tspeed: 0.1028s/iter; left time: 3591.6183s\n",
      "2799it [05:00,  9.83it/s]\titers: 2800, epoch: 1 | loss: 0.1786753\n",
      "\tspeed: 0.1003s/iter; left time: 3497.2293s\n",
      "2899it [05:11,  9.99it/s]\titers: 2900, epoch: 1 | loss: 0.3141781\n",
      "\tspeed: 0.1036s/iter; left time: 3601.2490s\n",
      "2999it [05:21,  9.59it/s]\titers: 3000, epoch: 1 | loss: 0.2984454\n",
      "\tspeed: 0.1018s/iter; left time: 3528.7325s\n",
      "3099it [05:31,  9.91it/s]\titers: 3100, epoch: 1 | loss: 0.2226067\n",
      "\tspeed: 0.1012s/iter; left time: 3495.2641s\n",
      "3199it [05:42,  9.50it/s]\titers: 3200, epoch: 1 | loss: 0.6298969\n",
      "\tspeed: 0.1047s/iter; left time: 3606.6730s\n",
      "3299it [05:52,  9.61it/s]\titers: 3300, epoch: 1 | loss: 0.4334720\n",
      "\tspeed: 0.1028s/iter; left time: 3529.7041s\n",
      "3399it [06:03,  8.81it/s]\titers: 3400, epoch: 1 | loss: 0.2399489\n",
      "\tspeed: 0.1113s/iter; left time: 3812.3927s\n",
      "3499it [06:14,  9.52it/s]\titers: 3500, epoch: 1 | loss: 0.3380310\n",
      "\tspeed: 0.1087s/iter; left time: 3710.7799s\n",
      "3599it [06:25,  9.38it/s]\titers: 3600, epoch: 1 | loss: 0.4184629\n",
      "\tspeed: 0.1088s/iter; left time: 3704.9598s\n",
      "3699it [06:36,  8.23it/s]\titers: 3700, epoch: 1 | loss: 0.2152787\n",
      "\tspeed: 0.1085s/iter; left time: 3683.8254s\n",
      "3765it [06:43,  9.34it/s]\n",
      "Epoch: 1 cost time: 403.2825710773468\n",
      "810it [00:41, 19.64it/s]\n",
      "807it [00:40, 19.79it/s]\n",
      "Epoch: 1 | Train Loss: 0.3339224 Vali Loss: 0.3933200 Test Loss: 0.4867423 MAE Loss: 0.4654253\n",
      "lr = 0.0009938442\n",
      "99it [00:10,  9.75it/s]\titers: 100, epoch: 2 | loss: 0.3026230\n",
      "\tspeed: 1.0596s/iter; left time: 35800.3769s\n",
      "199it [00:21,  9.75it/s]\titers: 200, epoch: 2 | loss: 0.6705697\n",
      "\tspeed: 0.1094s/iter; left time: 3685.7311s\n",
      "299it [00:32,  8.00it/s]\titers: 300, epoch: 2 | loss: 0.3486599\n",
      "\tspeed: 0.1070s/iter; left time: 3593.1762s\n",
      "399it [00:42,  9.70it/s]\titers: 400, epoch: 2 | loss: 0.2858748\n",
      "\tspeed: 0.1036s/iter; left time: 3468.8140s\n",
      "499it [00:53,  8.56it/s]\titers: 500, epoch: 2 | loss: 0.2096060\n",
      "\tspeed: 0.1101s/iter; left time: 3675.0399s\n",
      "599it [01:03,  9.84it/s]\titers: 600, epoch: 2 | loss: 0.5453781\n",
      "\tspeed: 0.1036s/iter; left time: 3447.8249s\n",
      "699it [01:14,  9.73it/s]\titers: 700, epoch: 2 | loss: 0.5345441\n",
      "\tspeed: 0.1089s/iter; left time: 3615.4011s\n",
      "799it [01:25,  9.32it/s]\titers: 800, epoch: 2 | loss: 0.2707790\n",
      "\tspeed: 0.1051s/iter; left time: 3476.6797s\n",
      "899it [01:36,  9.73it/s]\titers: 900, epoch: 2 | loss: 0.2026536\n",
      "\tspeed: 0.1080s/iter; left time: 3563.1702s\n",
      "999it [01:46,  9.34it/s]\titers: 1000, epoch: 2 | loss: 0.3182488\n",
      "\tspeed: 0.1078s/iter; left time: 3543.4688s\n",
      "1099it [01:57,  9.78it/s]\titers: 1100, epoch: 2 | loss: 0.2403988\n",
      "\tspeed: 0.1050s/iter; left time: 3440.9071s\n",
      "1199it [02:08,  9.70it/s]\titers: 1200, epoch: 2 | loss: 0.2817720\n",
      "\tspeed: 0.1072s/iter; left time: 3504.6224s\n",
      "1299it [02:18,  9.51it/s]\titers: 1300, epoch: 2 | loss: 0.1941828\n",
      "\tspeed: 0.1044s/iter; left time: 3401.5516s\n",
      "1399it [02:29, 10.03it/s]\titers: 1400, epoch: 2 | loss: 0.3358688\n",
      "\tspeed: 0.1075s/iter; left time: 3493.1088s\n",
      "1499it [02:39,  9.48it/s]\titers: 1500, epoch: 2 | loss: 0.4084879\n",
      "\tspeed: 0.1037s/iter; left time: 3359.9955s\n",
      "1599it [02:50,  9.58it/s]\titers: 1600, epoch: 2 | loss: 0.3015815\n",
      "\tspeed: 0.1049s/iter; left time: 3386.8216s\n",
      "1699it [03:00,  7.68it/s]\titers: 1700, epoch: 2 | loss: 0.1584121\n",
      "\tspeed: 0.1044s/iter; left time: 3361.2192s\n",
      "1799it [03:11,  8.99it/s]\titers: 1800, epoch: 2 | loss: 0.3174228\n",
      "\tspeed: 0.1113s/iter; left time: 3572.3644s\n",
      "1898it [03:22,  9.57it/s]\titers: 1900, epoch: 2 | loss: 0.5479672\n",
      "\tspeed: 0.1100s/iter; left time: 3517.3226s\n",
      "1999it [03:33,  8.98it/s]\titers: 2000, epoch: 2 | loss: 0.2074919\n",
      "\tspeed: 0.1093s/iter; left time: 3484.0727s\n",
      "2099it [03:44,  8.51it/s]\titers: 2100, epoch: 2 | loss: 0.3709853\n",
      "\tspeed: 0.1109s/iter; left time: 3526.5575s\n",
      "2198it [03:55,  9.56it/s]\titers: 2200, epoch: 2 | loss: 0.2229371\n",
      "\tspeed: 0.1036s/iter; left time: 3283.5040s\n",
      "2299it [04:05,  9.82it/s]\titers: 2300, epoch: 2 | loss: 0.4249352\n",
      "\tspeed: 0.1070s/iter; left time: 3380.7852s\n",
      "2399it [04:16,  9.38it/s]\titers: 2400, epoch: 2 | loss: 0.1989166\n",
      "\tspeed: 0.1028s/iter; left time: 3237.2893s\n",
      "2499it [04:26,  9.58it/s]\titers: 2500, epoch: 2 | loss: 0.3395654\n",
      "\tspeed: 0.1027s/iter; left time: 3224.4578s\n",
      "2599it [04:37,  7.79it/s]\titers: 2600, epoch: 2 | loss: 0.3081344\n",
      "\tspeed: 0.1083s/iter; left time: 3387.8909s\n",
      "2699it [04:47,  9.70it/s]\titers: 2700, epoch: 2 | loss: 0.2423075\n",
      "\tspeed: 0.1036s/iter; left time: 3229.7875s\n",
      "2799it [04:58,  9.79it/s]\titers: 2800, epoch: 2 | loss: 0.2690123\n",
      "\tspeed: 0.1069s/iter; left time: 3324.4085s\n",
      "2899it [05:08,  9.59it/s]\titers: 2900, epoch: 2 | loss: 0.2901224\n",
      "\tspeed: 0.1040s/iter; left time: 3222.4379s\n",
      "2998it [05:19, 10.01it/s]\titers: 3000, epoch: 2 | loss: 0.3037252\n",
      "\tspeed: 0.1065s/iter; left time: 3288.2516s\n",
      "3098it [05:28, 10.10it/s]\titers: 3100, epoch: 2 | loss: 0.3903669\n",
      "\tspeed: 0.0970s/iter; left time: 2987.7573s\n",
      "3199it [05:39,  9.65it/s]\titers: 3200, epoch: 2 | loss: 0.4314175\n",
      "\tspeed: 0.1032s/iter; left time: 3167.6665s\n",
      "3299it [05:49,  7.80it/s]\titers: 3300, epoch: 2 | loss: 0.3700314\n",
      "\tspeed: 0.1048s/iter; left time: 3204.6503s\n",
      "3398it [06:00,  9.60it/s]\titers: 3400, epoch: 2 | loss: 0.4604722\n",
      "\tspeed: 0.1066s/iter; left time: 3249.2283s\n",
      "3498it [06:10, 10.50it/s]\titers: 3500, epoch: 2 | loss: 0.3726371\n",
      "\tspeed: 0.0992s/iter; left time: 3014.9430s\n",
      "3598it [06:20, 10.35it/s]\titers: 3600, epoch: 2 | loss: 0.2676335\n",
      "\tspeed: 0.0988s/iter; left time: 2991.4927s\n",
      "3699it [06:30,  9.82it/s]\titers: 3700, epoch: 2 | loss: 0.4028404\n",
      "\tspeed: 0.1020s/iter; left time: 3077.6406s\n",
      "3765it [06:37,  9.48it/s]\n",
      "Epoch: 2 cost time: 397.1639528274536\n",
      "810it [00:38, 21.10it/s]\n",
      "807it [00:37, 21.50it/s]\n",
      "Epoch: 2 | Train Loss: 0.3257510 Vali Loss: 0.4141207 Test Loss: 0.5072606 MAE Loss: 0.4774968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:11,  9.53it/s]\titers: 100, epoch: 3 | loss: 0.3383845\n",
      "\tspeed: 0.9421s/iter; left time: 28282.3833s\n",
      "199it [00:22,  8.06it/s]\titers: 200, epoch: 3 | loss: 0.3268642\n",
      "\tspeed: 0.1080s/iter; left time: 3230.3864s\n",
      "299it [00:33,  9.34it/s]\titers: 300, epoch: 3 | loss: 0.4416980\n",
      "\tspeed: 0.1099s/iter; left time: 3278.1821s\n",
      "399it [00:44,  7.40it/s]\titers: 400, epoch: 3 | loss: 0.2697511\n",
      "\tspeed: 0.1147s/iter; left time: 3410.1332s\n",
      "499it [00:55,  9.33it/s]\titers: 500, epoch: 3 | loss: 0.3242953\n",
      "\tspeed: 0.1063s/iter; left time: 3147.7233s\n",
      "599it [01:06,  9.15it/s]\titers: 600, epoch: 3 | loss: 0.3206148\n",
      "\tspeed: 0.1104s/iter; left time: 3258.2496s\n",
      "699it [01:17,  9.06it/s]\titers: 700, epoch: 3 | loss: 0.5695320\n",
      "\tspeed: 0.1109s/iter; left time: 3262.9177s\n",
      "799it [01:28,  9.27it/s]\titers: 800, epoch: 3 | loss: 0.4981947\n",
      "\tspeed: 0.1146s/iter; left time: 3360.6864s\n",
      "899it [01:40,  6.84it/s]\titers: 900, epoch: 3 | loss: 0.3123422\n",
      "\tspeed: 0.1114s/iter; left time: 3256.2875s\n",
      "999it [01:50,  9.65it/s]\titers: 1000, epoch: 3 | loss: 0.1778338\n",
      "\tspeed: 0.1049s/iter; left time: 3054.6220s\n",
      "1099it [02:01,  8.98it/s]\titers: 1100, epoch: 3 | loss: 0.5068719\n",
      "\tspeed: 0.1078s/iter; left time: 3129.7124s\n",
      "1199it [02:11,  9.76it/s]\titers: 1200, epoch: 3 | loss: 0.4546197\n",
      "\tspeed: 0.1040s/iter; left time: 3007.6559s\n",
      "1299it [02:22,  9.88it/s]\titers: 1300, epoch: 3 | loss: 0.3733933\n",
      "\tspeed: 0.1059s/iter; left time: 3051.2828s\n",
      "1399it [02:32,  9.61it/s]\titers: 1400, epoch: 3 | loss: 0.3663713\n",
      "\tspeed: 0.1043s/iter; left time: 2996.4174s\n",
      "1499it [02:43,  9.22it/s]\titers: 1500, epoch: 3 | loss: 0.2073531\n",
      "\tspeed: 0.1078s/iter; left time: 3084.4813s\n",
      "1599it [02:53,  9.47it/s]\titers: 1600, epoch: 3 | loss: 0.2994351\n",
      "\tspeed: 0.1037s/iter; left time: 2957.2193s\n",
      "1699it [03:04,  8.94it/s]\titers: 1700, epoch: 3 | loss: 0.3227765\n",
      "\tspeed: 0.1095s/iter; left time: 3112.4007s\n",
      "1798it [03:14,  9.72it/s]\titers: 1800, epoch: 3 | loss: 0.1974620\n",
      "\tspeed: 0.1011s/iter; left time: 2862.2583s\n",
      "1899it [03:25,  9.64it/s]\titers: 1900, epoch: 3 | loss: 0.4105817\n",
      "\tspeed: 0.1032s/iter; left time: 2912.1915s\n",
      "1999it [03:36,  9.57it/s]\titers: 2000, epoch: 3 | loss: 0.3660118\n",
      "\tspeed: 0.1090s/iter; left time: 3064.2632s\n",
      "2098it [03:46,  9.23it/s]\titers: 2100, epoch: 3 | loss: 0.4231451\n",
      "\tspeed: 0.1045s/iter; left time: 2928.1176s\n",
      "2198it [03:57,  9.49it/s]\titers: 2200, epoch: 3 | loss: 0.2297770\n",
      "\tspeed: 0.1044s/iter; left time: 2914.9079s\n",
      "2299it [04:07,  9.47it/s]\titers: 2300, epoch: 3 | loss: 0.2101880\n",
      "\tspeed: 0.1041s/iter; left time: 2894.8797s\n",
      "2399it [04:18,  8.91it/s]\titers: 2400, epoch: 3 | loss: 0.4476412\n",
      "\tspeed: 0.1099s/iter; left time: 3046.2710s\n",
      "2499it [04:29,  9.39it/s]\titers: 2500, epoch: 3 | loss: 0.2514104\n",
      "\tspeed: 0.1061s/iter; left time: 2931.0728s\n",
      "2599it [04:39,  9.38it/s]\titers: 2600, epoch: 3 | loss: 0.7028185\n",
      "\tspeed: 0.1077s/iter; left time: 2964.6940s\n",
      "2699it [04:50,  7.76it/s]\titers: 2700, epoch: 3 | loss: 0.4084406\n",
      "\tspeed: 0.1079s/iter; left time: 2959.1886s\n",
      "2799it [05:01,  9.63it/s]\titers: 2800, epoch: 3 | loss: 0.2733059\n",
      "\tspeed: 0.1063s/iter; left time: 2904.1495s\n",
      "2898it [05:12,  9.50it/s]\titers: 2900, epoch: 3 | loss: 0.3173958\n",
      "\tspeed: 0.1100s/iter; left time: 2995.0001s\n",
      "2999it [05:22,  9.57it/s]\titers: 3000, epoch: 3 | loss: 0.3915953\n",
      "\tspeed: 0.1059s/iter; left time: 2870.7663s\n",
      "3099it [05:33,  9.55it/s]\titers: 3100, epoch: 3 | loss: 0.2433289\n",
      "\tspeed: 0.1078s/iter; left time: 2913.6327s\n",
      "3199it [05:44,  9.62it/s]\titers: 3200, epoch: 3 | loss: 0.4921427\n",
      "\tspeed: 0.1043s/iter; left time: 2806.5776s\n",
      "3298it [05:55,  9.65it/s]\titers: 3300, epoch: 3 | loss: 0.1721545\n",
      "\tspeed: 0.1111s/iter; left time: 2980.9524s\n",
      "3399it [06:05,  8.50it/s]\titers: 3400, epoch: 3 | loss: 0.5224946\n",
      "\tspeed: 0.1062s/iter; left time: 2838.4068s\n",
      "3499it [06:16,  9.55it/s]\titers: 3500, epoch: 3 | loss: 0.2213157\n",
      "\tspeed: 0.1042s/iter; left time: 2774.0132s\n",
      "3599it [06:26,  9.64it/s]\titers: 3600, epoch: 3 | loss: 0.1954922\n",
      "\tspeed: 0.1020s/iter; left time: 2705.3499s\n",
      "3698it [06:36, 10.16it/s]\titers: 3700, epoch: 3 | loss: 0.2193892\n",
      "\tspeed: 0.1031s/iter; left time: 2722.8698s\n",
      "3765it [06:43,  9.33it/s]\n",
      "Epoch: 3 cost time: 403.5474615097046\n",
      "810it [00:38, 21.23it/s]\n",
      "807it [00:37, 21.29it/s]\n",
      "Epoch: 3 | Train Loss: 0.3365060 Vali Loss: 0.4064021 Test Loss: 0.4940262 MAE Loss: 0.4583008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:10,  9.65it/s]\titers: 100, epoch: 4 | loss: 0.3006406\n",
      "\tspeed: 0.9365s/iter; left time: 24589.2484s\n",
      "199it [00:21,  8.70it/s]\titers: 200, epoch: 4 | loss: 0.2440619\n",
      "\tspeed: 0.1068s/iter; left time: 2792.8925s\n",
      "299it [00:31,  9.70it/s]\titers: 300, epoch: 4 | loss: 0.4133818\n",
      "\tspeed: 0.1041s/iter; left time: 2712.2798s\n",
      "399it [00:42,  8.95it/s]\titers: 400, epoch: 4 | loss: 0.6025497\n",
      "\tspeed: 0.1078s/iter; left time: 2797.0879s\n",
      "499it [00:53,  9.20it/s]\titers: 500, epoch: 4 | loss: 0.3256566\n",
      "\tspeed: 0.1092s/iter; left time: 2822.5117s\n",
      "599it [01:04,  9.16it/s]\titers: 600, epoch: 4 | loss: 0.2037105\n",
      "\tspeed: 0.1096s/iter; left time: 2823.0682s\n",
      "699it [01:15,  9.24it/s]\titers: 700, epoch: 4 | loss: 0.3724228\n",
      "\tspeed: 0.1109s/iter; left time: 2845.2889s\n",
      "799it [01:26,  9.66it/s]\titers: 800, epoch: 4 | loss: 0.2472870\n",
      "\tspeed: 0.1092s/iter; left time: 2790.6920s\n",
      "899it [01:37,  9.60it/s]\titers: 900, epoch: 4 | loss: 0.3435126\n",
      "\tspeed: 0.1139s/iter; left time: 2899.5130s\n",
      "999it [01:48,  9.30it/s]\titers: 1000, epoch: 4 | loss: 0.4202377\n",
      "\tspeed: 0.1068s/iter; left time: 2707.3878s\n",
      "1099it [01:59,  9.06it/s]\titers: 1100, epoch: 4 | loss: 0.2549579\n",
      "\tspeed: 0.1110s/iter; left time: 2804.1028s\n",
      "1199it [02:10,  9.30it/s]\titers: 1200, epoch: 4 | loss: 0.2879125\n",
      "\tspeed: 0.1065s/iter; left time: 2678.8811s\n",
      "1299it [02:21,  9.06it/s]\titers: 1300, epoch: 4 | loss: 0.1979164\n",
      "\tspeed: 0.1111s/iter; left time: 2784.7450s\n",
      "1399it [02:32,  9.31it/s]\titers: 1400, epoch: 4 | loss: 0.2354831\n",
      "\tspeed: 0.1082s/iter; left time: 2700.0427s\n",
      "1499it [02:43,  8.98it/s]\titers: 1500, epoch: 4 | loss: 0.5307850\n",
      "\tspeed: 0.1117s/iter; left time: 2777.6061s\n",
      "1599it [02:54,  9.06it/s]\titers: 1600, epoch: 4 | loss: 0.3924909\n",
      "\tspeed: 0.1135s/iter; left time: 2809.7371s\n",
      "1698it [03:05,  9.14it/s]\titers: 1700, epoch: 4 | loss: 0.1585459\n",
      "\tspeed: 0.1101s/iter; left time: 2713.7867s\n",
      "1799it [03:17,  9.12it/s]\titers: 1800, epoch: 4 | loss: 0.2648713\n",
      "\tspeed: 0.1132s/iter; left time: 2779.7125s\n",
      "1899it [03:27,  9.37it/s]\titers: 1900, epoch: 4 | loss: 0.1933755\n",
      "\tspeed: 0.1091s/iter; left time: 2668.2363s\n",
      "1999it [03:39,  9.54it/s]\titers: 2000, epoch: 4 | loss: 0.2984614\n",
      "\tspeed: 0.1121s/iter; left time: 2729.1897s\n",
      "2099it [03:49,  7.91it/s]\titers: 2100, epoch: 4 | loss: 0.2081639\n",
      "\tspeed: 0.1069s/iter; left time: 2593.6631s\n",
      "2199it [04:00,  9.94it/s]\titers: 2200, epoch: 4 | loss: 0.2385168\n",
      "\tspeed: 0.1053s/iter; left time: 2543.4003s\n",
      "2299it [04:10,  9.71it/s]\titers: 2300, epoch: 4 | loss: 0.2389357\n",
      "\tspeed: 0.1049s/iter; left time: 2522.4361s\n",
      "2399it [04:21,  9.99it/s]\titers: 2400, epoch: 4 | loss: 0.4422472\n",
      "\tspeed: 0.1036s/iter; left time: 2482.7354s\n",
      "2499it [04:31,  9.41it/s]\titers: 2500, epoch: 4 | loss: 0.3745276\n",
      "\tspeed: 0.1060s/iter; left time: 2529.1474s\n",
      "2598it [04:42,  9.53it/s]\titers: 2600, epoch: 4 | loss: 0.1556063\n",
      "\tspeed: 0.1086s/iter; left time: 2580.9266s\n",
      "2699it [04:53,  9.79it/s]\titers: 2700, epoch: 4 | loss: 0.2270570\n",
      "\tspeed: 0.1075s/iter; left time: 2542.4833s\n",
      "2799it [05:03,  9.71it/s]\titers: 2800, epoch: 4 | loss: 0.5380667\n",
      "\tspeed: 0.1033s/iter; left time: 2432.7690s\n",
      "2899it [05:14,  9.85it/s]\titers: 2900, epoch: 4 | loss: 0.2240163\n",
      "\tspeed: 0.1068s/iter; left time: 2504.2984s\n",
      "2998it [05:24, 10.11it/s]\titers: 3000, epoch: 4 | loss: 0.4558466\n",
      "\tspeed: 0.0999s/iter; left time: 2334.0007s\n",
      "3099it [05:34,  9.57it/s]\titers: 3100, epoch: 4 | loss: 0.1970499\n",
      "\tspeed: 0.1016s/iter; left time: 2363.7400s\n",
      "3198it [05:44,  9.35it/s]\titers: 3200, epoch: 4 | loss: 0.1851226\n",
      "\tspeed: 0.1040s/iter; left time: 2408.6476s\n",
      "3299it [05:55,  9.65it/s]\titers: 3300, epoch: 4 | loss: 0.2274571\n",
      "\tspeed: 0.1058s/iter; left time: 2438.7342s\n",
      "3399it [06:05,  9.86it/s]\titers: 3400, epoch: 4 | loss: 0.1840156\n",
      "\tspeed: 0.1034s/iter; left time: 2374.1294s\n",
      "3499it [06:15,  9.93it/s]\titers: 3500, epoch: 4 | loss: 0.2138825\n",
      "\tspeed: 0.0990s/iter; left time: 2261.7788s\n",
      "3598it [06:25, 10.08it/s]\titers: 3600, epoch: 4 | loss: 0.5029134\n",
      "\tspeed: 0.0998s/iter; left time: 2271.5586s\n",
      "3698it [06:35, 10.10it/s]\titers: 3700, epoch: 4 | loss: 0.3877670\n",
      "\tspeed: 0.0984s/iter; left time: 2228.2400s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 4 cost time: 402.32713747024536\n",
      "810it [00:38, 21.00it/s]\n",
      "807it [00:37, 21.24it/s]\n",
      "Epoch: 4 | Train Loss: 0.3288738 Vali Loss: 0.3850609 Test Loss: 0.4727391 MAE Loss: 0.4528556\n",
      "lr = 0.0009045095\n",
      "98it [00:10,  9.57it/s]\titers: 100, epoch: 5 | loss: 0.3697329\n",
      "\tspeed: 0.9807s/iter; left time: 22056.6805s\n",
      "199it [00:21,  9.60it/s]\titers: 200, epoch: 5 | loss: 0.1628610\n",
      "\tspeed: 0.1065s/iter; left time: 2384.8409s\n",
      "299it [00:32,  9.61it/s]\titers: 300, epoch: 5 | loss: 0.2121016\n",
      "\tspeed: 0.1060s/iter; left time: 2362.1967s\n",
      "399it [00:42,  9.66it/s]\titers: 400, epoch: 5 | loss: 0.1544528\n",
      "\tspeed: 0.1031s/iter; left time: 2288.6718s\n",
      "499it [00:52,  9.25it/s]\titers: 500, epoch: 5 | loss: 0.4195973\n",
      "\tspeed: 0.1057s/iter; left time: 2334.4984s\n",
      "599it [01:03,  9.66it/s]\titers: 600, epoch: 5 | loss: 0.2264196\n",
      "\tspeed: 0.1032s/iter; left time: 2268.7560s\n",
      "699it [01:13,  9.81it/s]\titers: 700, epoch: 5 | loss: 0.2859807\n",
      "\tspeed: 0.1069s/iter; left time: 2340.1122s\n",
      "798it [01:24,  9.52it/s]\titers: 800, epoch: 5 | loss: 0.2172444\n",
      "\tspeed: 0.1025s/iter; left time: 2233.7452s\n",
      "899it [01:35,  8.97it/s]\titers: 900, epoch: 5 | loss: 0.3640499\n",
      "\tspeed: 0.1096s/iter; left time: 2377.9766s\n",
      "999it [01:46,  8.50it/s]\titers: 1000, epoch: 5 | loss: 0.2475604\n",
      "\tspeed: 0.1088s/iter; left time: 2350.1354s\n",
      "1099it [01:56,  9.10it/s]\titers: 1100, epoch: 5 | loss: 0.2546253\n",
      "\tspeed: 0.1085s/iter; left time: 2330.7301s\n",
      "1199it [02:07,  8.29it/s]\titers: 1200, epoch: 5 | loss: 0.3203272\n",
      "\tspeed: 0.1079s/iter; left time: 2307.9205s\n",
      "1298it [02:18,  9.42it/s]\titers: 1300, epoch: 5 | loss: 0.1788185\n",
      "\tspeed: 0.1053s/iter; left time: 2241.1018s\n",
      "1399it [02:28,  9.24it/s]\titers: 1400, epoch: 5 | loss: 0.3036068\n",
      "\tspeed: 0.1065s/iter; left time: 2255.9854s\n",
      "1499it [02:39,  9.68it/s]\titers: 1500, epoch: 5 | loss: 0.3591381\n",
      "\tspeed: 0.1041s/iter; left time: 2195.8683s\n",
      "1599it [02:49,  9.65it/s]\titers: 1600, epoch: 5 | loss: 0.2231094\n",
      "\tspeed: 0.1061s/iter; left time: 2228.0437s\n",
      "1699it [03:00,  9.67it/s]\titers: 1700, epoch: 5 | loss: 0.1675793\n",
      "\tspeed: 0.1033s/iter; left time: 2157.3278s\n",
      "1798it [03:10,  9.75it/s]\titers: 1800, epoch: 5 | loss: 0.2167388\n",
      "\tspeed: 0.1071s/iter; left time: 2226.6393s\n",
      "1899it [03:21,  6.53it/s]\titers: 1900, epoch: 5 | loss: 0.1690843\n",
      "\tspeed: 0.1084s/iter; left time: 2243.0477s\n",
      "1998it [03:32,  9.55it/s]\titers: 2000, epoch: 5 | loss: 0.2814294\n",
      "\tspeed: 0.1053s/iter; left time: 2168.9499s\n",
      "2099it [03:43,  9.60it/s]\titers: 2100, epoch: 5 | loss: 0.2111902\n",
      "\tspeed: 0.1071s/iter; left time: 2194.5880s\n",
      "2199it [03:53,  9.88it/s]\titers: 2200, epoch: 5 | loss: 0.2084986\n",
      "\tspeed: 0.1034s/iter; left time: 2107.7322s\n",
      "2299it [04:03,  8.05it/s]\titers: 2300, epoch: 5 | loss: 0.3536089\n",
      "\tspeed: 0.1065s/iter; left time: 2161.1423s\n",
      "2398it [04:14,  9.70it/s]\titers: 2400, epoch: 5 | loss: 0.2249711\n",
      "\tspeed: 0.1032s/iter; left time: 2084.4123s\n",
      "2499it [04:25,  9.16it/s]\titers: 2500, epoch: 5 | loss: 0.3869133\n",
      "\tspeed: 0.1077s/iter; left time: 2163.0574s\n",
      "2598it [04:35,  9.51it/s]\titers: 2600, epoch: 5 | loss: 0.2205029\n",
      "\tspeed: 0.1082s/iter; left time: 2163.9587s\n",
      "2699it [04:47,  9.33it/s]\titers: 2700, epoch: 5 | loss: 0.2206600\n",
      "\tspeed: 0.1118s/iter; left time: 2224.6232s\n",
      "2799it [04:58,  7.88it/s]\titers: 2800, epoch: 5 | loss: 0.1981445\n",
      "\tspeed: 0.1092s/iter; left time: 2161.3167s\n",
      "2899it [05:09,  9.16it/s]\titers: 2900, epoch: 5 | loss: 0.4340478\n",
      "\tspeed: 0.1124s/iter; left time: 2213.1588s\n",
      "2999it [05:20,  8.14it/s]\titers: 3000, epoch: 5 | loss: 0.1314150\n",
      "\tspeed: 0.1132s/iter; left time: 2216.9487s\n",
      "3099it [05:31,  9.29it/s]\titers: 3100, epoch: 5 | loss: 0.8493554\n",
      "\tspeed: 0.1071s/iter; left time: 2086.5402s\n",
      "3198it [05:41, 10.25it/s]\titers: 3200, epoch: 5 | loss: 0.3208412\n",
      "\tspeed: 0.1043s/iter; left time: 2021.6738s\n",
      "3299it [05:52,  9.47it/s]\titers: 3300, epoch: 5 | loss: 0.5492241\n",
      "\tspeed: 0.1039s/iter; left time: 2005.1032s\n",
      "3399it [06:02,  9.68it/s]\titers: 3400, epoch: 5 | loss: 0.1734876\n",
      "\tspeed: 0.1070s/iter; left time: 2052.7945s\n",
      "3498it [06:13,  9.86it/s]\titers: 3500, epoch: 5 | loss: 0.4444863\n",
      "\tspeed: 0.1029s/iter; left time: 1964.3687s\n",
      "3599it [06:23,  9.59it/s]\titers: 3600, epoch: 5 | loss: 0.2006109\n",
      "\tspeed: 0.1014s/iter; left time: 1926.1800s\n",
      "3698it [06:33, 10.16it/s]\titers: 3700, epoch: 5 | loss: 0.2729193\n",
      "\tspeed: 0.1027s/iter; left time: 1940.2358s\n",
      "3765it [06:40,  9.41it/s]\n",
      "Epoch: 5 cost time: 400.11252617836\n",
      "810it [00:38, 21.25it/s]\n",
      "807it [00:38, 21.07it/s]\n",
      "Epoch: 5 | Train Loss: 0.3146382 Vali Loss: 0.3828572 Test Loss: 0.4580813 MAE Loss: 0.4429606\n",
      "lr = 0.0008535549\n",
      "98it [00:10,  9.67it/s]\titers: 100, epoch: 6 | loss: 0.3527882\n",
      "\tspeed: 0.9767s/iter; left time: 18290.2537s\n",
      "199it [00:21,  9.60it/s]\titers: 200, epoch: 6 | loss: 0.4540844\n",
      "\tspeed: 0.1065s/iter; left time: 1983.9355s\n",
      "299it [00:32,  9.55it/s]\titers: 300, epoch: 6 | loss: 0.2982931\n",
      "\tspeed: 0.1045s/iter; left time: 1935.2531s\n",
      "399it [00:42,  9.65it/s]\titers: 400, epoch: 6 | loss: 0.2235317\n",
      "\tspeed: 0.1048s/iter; left time: 1930.3456s\n",
      "499it [00:52,  9.67it/s]\titers: 500, epoch: 6 | loss: 0.3145299\n",
      "\tspeed: 0.1050s/iter; left time: 1923.4370s\n",
      "599it [01:03,  8.76it/s]\titers: 600, epoch: 6 | loss: 0.1592099\n",
      "\tspeed: 0.1061s/iter; left time: 1932.8868s\n",
      "699it [01:13,  9.73it/s]\titers: 700, epoch: 6 | loss: 0.2417821\n",
      "\tspeed: 0.1027s/iter; left time: 1861.6354s\n",
      "799it [01:24,  9.70it/s]\titers: 800, epoch: 6 | loss: 0.2456377\n",
      "\tspeed: 0.1032s/iter; left time: 1860.3074s\n",
      "899it [01:34,  9.48it/s]\titers: 900, epoch: 6 | loss: 0.2679962\n",
      "\tspeed: 0.1034s/iter; left time: 1852.6825s\n",
      "999it [01:45,  9.88it/s]\titers: 1000, epoch: 6 | loss: 0.2351329\n",
      "\tspeed: 0.1056s/iter; left time: 1882.7089s\n",
      "1099it [01:55,  7.43it/s]\titers: 1100, epoch: 6 | loss: 0.2918243\n",
      "\tspeed: 0.1068s/iter; left time: 1893.6354s\n",
      "1199it [02:06,  9.66it/s]\titers: 1200, epoch: 6 | loss: 0.3308031\n",
      "\tspeed: 0.1065s/iter; left time: 1877.8160s\n",
      "1298it [02:16,  9.39it/s]\titers: 1300, epoch: 6 | loss: 0.2857048\n",
      "\tspeed: 0.1063s/iter; left time: 1863.6819s\n",
      "1399it [02:27,  9.54it/s]\titers: 1400, epoch: 6 | loss: 0.4260607\n",
      "\tspeed: 0.1049s/iter; left time: 1828.4893s\n",
      "1499it [02:38,  9.22it/s]\titers: 1500, epoch: 6 | loss: 0.3776047\n",
      "\tspeed: 0.1086s/iter; left time: 1882.2114s\n",
      "1599it [02:49,  9.31it/s]\titers: 1600, epoch: 6 | loss: 0.4883596\n",
      "\tspeed: 0.1100s/iter; left time: 1895.5811s\n",
      "1698it [03:00,  9.14it/s]\titers: 1700, epoch: 6 | loss: 0.1718704\n",
      "\tspeed: 0.1141s/iter; left time: 1954.2993s\n",
      "1799it [03:11,  9.49it/s]\titers: 1800, epoch: 6 | loss: 0.2323518\n",
      "\tspeed: 0.1038s/iter; left time: 1767.7985s\n",
      "1899it [03:21,  9.34it/s]\titers: 1900, epoch: 6 | loss: 0.2103265\n",
      "\tspeed: 0.1072s/iter; left time: 1815.0085s\n",
      "1999it [03:33,  8.73it/s]\titers: 2000, epoch: 6 | loss: 0.5393614\n",
      "\tspeed: 0.1149s/iter; left time: 1932.9169s\n",
      "2099it [03:44,  9.49it/s]\titers: 2100, epoch: 6 | loss: 0.3311533\n",
      "\tspeed: 0.1074s/iter; left time: 1796.4609s\n",
      "2199it [03:55,  8.68it/s]\titers: 2200, epoch: 6 | loss: 0.3651102\n",
      "\tspeed: 0.1154s/iter; left time: 1918.7244s\n",
      "2299it [04:06,  9.08it/s]\titers: 2300, epoch: 6 | loss: 0.2251655\n",
      "\tspeed: 0.1123s/iter; left time: 1856.3010s\n",
      "2399it [04:18,  9.59it/s]\titers: 2400, epoch: 6 | loss: 0.5597059\n",
      "\tspeed: 0.1138s/iter; left time: 1868.6022s\n",
      "2499it [04:28, 10.11it/s]\titers: 2500, epoch: 6 | loss: 0.3596122\n",
      "\tspeed: 0.1000s/iter; left time: 1633.2772s\n",
      "2598it [04:38, 10.31it/s]\titers: 2600, epoch: 6 | loss: 0.2383562\n",
      "\tspeed: 0.1000s/iter; left time: 1622.0284s\n",
      "2699it [04:48, 10.48it/s]\titers: 2700, epoch: 6 | loss: 0.3861879\n",
      "\tspeed: 0.0974s/iter; left time: 1571.4211s\n",
      "2798it [04:58, 10.04it/s]\titers: 2800, epoch: 6 | loss: 0.4158143\n",
      "\tspeed: 0.1052s/iter; left time: 1685.9160s\n",
      "2899it [05:08,  9.14it/s]\titers: 2900, epoch: 6 | loss: 0.3263055\n",
      "\tspeed: 0.1035s/iter; left time: 1648.5936s\n",
      "2999it [05:19,  9.25it/s]\titers: 3000, epoch: 6 | loss: 0.3912396\n",
      "\tspeed: 0.1075s/iter; left time: 1701.9287s\n",
      "3099it [05:30,  9.56it/s]\titers: 3100, epoch: 6 | loss: 0.3799257\n",
      "\tspeed: 0.1083s/iter; left time: 1702.4882s\n",
      "3199it [05:40,  9.78it/s]\titers: 3200, epoch: 6 | loss: 0.2861125\n",
      "\tspeed: 0.1045s/iter; left time: 1632.4576s\n",
      "3299it [05:51,  9.73it/s]\titers: 3300, epoch: 6 | loss: 0.3709390\n",
      "\tspeed: 0.1059s/iter; left time: 1643.9071s\n",
      "3398it [06:01,  9.53it/s]\titers: 3400, epoch: 6 | loss: 0.3677102\n",
      "\tspeed: 0.1038s/iter; left time: 1600.8728s\n",
      "3499it [06:12,  9.44it/s]\titers: 3500, epoch: 6 | loss: 0.2940361\n",
      "\tspeed: 0.1077s/iter; left time: 1650.2003s\n",
      "3599it [06:23,  7.96it/s]\titers: 3600, epoch: 6 | loss: 0.2552347\n",
      "\tspeed: 0.1071s/iter; left time: 1631.0413s\n",
      "3699it [06:33,  9.48it/s]\titers: 3700, epoch: 6 | loss: 0.4274861\n",
      "\tspeed: 0.1055s/iter; left time: 1596.2979s\n",
      "3765it [06:40,  9.39it/s]\n",
      "Epoch: 6 cost time: 400.92169427871704\n",
      "810it [00:38, 21.22it/s]\n",
      "807it [00:37, 21.33it/s]\n",
      "Epoch: 6 | Train Loss: 0.3144608 Vali Loss: 0.3866889 Test Loss: 0.4698494 MAE Loss: 0.4478628\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:10,  9.69it/s]\titers: 100, epoch: 7 | loss: 0.2766097\n",
      "\tspeed: 0.9393s/iter; left time: 14053.4931s\n",
      "198it [00:21,  9.66it/s]\titers: 200, epoch: 7 | loss: 0.2215559\n",
      "\tspeed: 0.1050s/iter; left time: 1560.6977s\n",
      "299it [00:32,  9.49it/s]\titers: 300, epoch: 7 | loss: 0.2655707\n",
      "\tspeed: 0.1074s/iter; left time: 1584.6198s\n",
      "398it [00:42, 10.44it/s]\titers: 400, epoch: 7 | loss: 0.3384075\n",
      "\tspeed: 0.1034s/iter; left time: 1516.3137s\n",
      "498it [00:52, 10.28it/s]\titers: 500, epoch: 7 | loss: 0.2274809\n",
      "\tspeed: 0.0973s/iter; left time: 1417.0023s\n",
      "599it [01:02, 10.15it/s]\titers: 600, epoch: 7 | loss: 0.5672334\n",
      "\tspeed: 0.1004s/iter; left time: 1451.3940s\n",
      "699it [01:11, 10.20it/s]\titers: 700, epoch: 7 | loss: 0.2923414\n",
      "\tspeed: 0.0975s/iter; left time: 1400.5236s\n",
      "799it [01:22,  9.71it/s]\titers: 800, epoch: 7 | loss: 0.2110776\n",
      "\tspeed: 0.1020s/iter; left time: 1454.9960s\n",
      "899it [01:32, 10.21it/s]\titers: 900, epoch: 7 | loss: 0.2511860\n",
      "\tspeed: 0.1035s/iter; left time: 1465.1328s\n",
      "999it [01:42,  9.58it/s]\titers: 1000, epoch: 7 | loss: 0.2923205\n",
      "\tspeed: 0.1031s/iter; left time: 1449.4838s\n",
      "1099it [01:53,  9.43it/s]\titers: 1100, epoch: 7 | loss: 0.4265242\n",
      "\tspeed: 0.1060s/iter; left time: 1480.1346s\n",
      "1199it [02:03,  9.85it/s]\titers: 1200, epoch: 7 | loss: 0.2488056\n",
      "\tspeed: 0.1030s/iter; left time: 1427.2138s\n",
      "1298it [02:14,  9.72it/s]\titers: 1300, epoch: 7 | loss: 0.4552926\n",
      "\tspeed: 0.1067s/iter; left time: 1468.6090s\n",
      "1399it [02:24,  9.72it/s]\titers: 1400, epoch: 7 | loss: 0.2100385\n",
      "\tspeed: 0.1022s/iter; left time: 1395.9238s\n",
      "1499it [02:35,  9.72it/s]\titers: 1500, epoch: 7 | loss: 0.1981146\n",
      "\tspeed: 0.1057s/iter; left time: 1433.1419s\n",
      "1599it [02:45,  8.09it/s]\titers: 1600, epoch: 7 | loss: 0.1996202\n",
      "\tspeed: 0.1041s/iter; left time: 1401.9463s\n",
      "1699it [02:56,  9.66it/s]\titers: 1700, epoch: 7 | loss: 0.4045314\n",
      "\tspeed: 0.1046s/iter; left time: 1397.3142s\n",
      "1799it [03:06,  9.82it/s]\titers: 1800, epoch: 7 | loss: 0.4244358\n",
      "\tspeed: 0.1072s/iter; left time: 1422.2228s\n",
      "1899it [03:17,  9.79it/s]\titers: 1900, epoch: 7 | loss: 0.3827047\n",
      "\tspeed: 0.1038s/iter; left time: 1366.4658s\n",
      "1999it [03:27,  9.56it/s]\titers: 2000, epoch: 7 | loss: 0.2950183\n",
      "\tspeed: 0.1064s/iter; left time: 1390.0204s\n",
      "2099it [03:38, 10.01it/s]\titers: 2100, epoch: 7 | loss: 0.2155664\n",
      "\tspeed: 0.1031s/iter; left time: 1336.0705s\n",
      "2199it [03:48,  9.76it/s]\titers: 2200, epoch: 7 | loss: 0.2658345\n",
      "\tspeed: 0.1070s/iter; left time: 1375.6107s\n",
      "2299it [03:59,  7.94it/s]\titers: 2300, epoch: 7 | loss: 0.3027633\n",
      "\tspeed: 0.1045s/iter; left time: 1334.0831s\n",
      "2399it [04:09, 10.13it/s]\titers: 2400, epoch: 7 | loss: 0.1367843\n",
      "\tspeed: 0.1027s/iter; left time: 1300.5635s\n",
      "2499it [04:19,  9.97it/s]\titers: 2500, epoch: 7 | loss: 0.2204079\n",
      "\tspeed: 0.0997s/iter; left time: 1252.8228s\n",
      "2599it [04:29, 10.26it/s]\titers: 2600, epoch: 7 | loss: 0.2870556\n",
      "\tspeed: 0.0984s/iter; left time: 1226.1897s\n",
      "2699it [04:39,  9.50it/s]\titers: 2700, epoch: 7 | loss: 0.3269806\n",
      "\tspeed: 0.1030s/iter; left time: 1272.6501s\n",
      "2798it [04:49,  9.52it/s]\titers: 2800, epoch: 7 | loss: 0.2898161\n",
      "\tspeed: 0.1039s/iter; left time: 1274.0178s\n",
      "2899it [05:00,  9.64it/s]\titers: 2900, epoch: 7 | loss: 0.2370246\n",
      "\tspeed: 0.1069s/iter; left time: 1300.5794s\n",
      "2998it [05:10,  9.78it/s]\titers: 3000, epoch: 7 | loss: 0.2406136\n",
      "\tspeed: 0.1029s/iter; left time: 1240.6607s\n",
      "3099it [05:21,  9.56it/s]\titers: 3100, epoch: 7 | loss: 0.2754480\n",
      "\tspeed: 0.1060s/iter; left time: 1267.2683s\n",
      "3199it [05:32,  9.22it/s]\titers: 3200, epoch: 7 | loss: 0.2271497\n",
      "\tspeed: 0.1043s/iter; left time: 1236.9959s\n",
      "3299it [05:42,  9.70it/s]\titers: 3300, epoch: 7 | loss: 0.2487942\n",
      "\tspeed: 0.1047s/iter; left time: 1231.4371s\n",
      "3399it [05:53,  9.64it/s]\titers: 3400, epoch: 7 | loss: 0.4404836\n",
      "\tspeed: 0.1057s/iter; left time: 1232.6984s\n",
      "3499it [06:03,  9.51it/s]\titers: 3500, epoch: 7 | loss: 0.3071925\n",
      "\tspeed: 0.1037s/iter; left time: 1198.5147s\n",
      "3599it [06:14,  9.95it/s]\titers: 3600, epoch: 7 | loss: 0.3677044\n",
      "\tspeed: 0.1067s/iter; left time: 1222.7271s\n",
      "3699it [06:24,  9.81it/s]\titers: 3700, epoch: 7 | loss: 0.1839146\n",
      "\tspeed: 0.1022s/iter; left time: 1161.3444s\n",
      "3765it [06:31,  9.61it/s]\n",
      "Epoch: 7 cost time: 391.9281368255615\n",
      "810it [00:38, 21.17it/s]\n",
      "807it [00:37, 21.36it/s]\n",
      "Epoch: 7 | Train Loss: 0.3154384 Vali Loss: 0.3861398 Test Loss: 0.4686438 MAE Loss: 0.4534865\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:11,  8.41it/s]\titers: 100, epoch: 8 | loss: 0.3832764\n",
      "\tspeed: 0.9560s/iter; left time: 10703.4860s\n",
      "199it [00:22,  9.70it/s]\titers: 200, epoch: 8 | loss: 0.1886065\n",
      "\tspeed: 0.1028s/iter; left time: 1140.7303s\n",
      "299it [00:32,  9.80it/s]\titers: 300, epoch: 8 | loss: 0.4559154\n",
      "\tspeed: 0.1051s/iter; left time: 1155.9730s\n",
      "399it [00:43,  8.64it/s]\titers: 400, epoch: 8 | loss: 0.3812473\n",
      "\tspeed: 0.1046s/iter; left time: 1139.2307s\n",
      "499it [00:53,  9.66it/s]\titers: 500, epoch: 8 | loss: 0.3267179\n",
      "\tspeed: 0.1042s/iter; left time: 1124.9120s\n",
      "598it [01:03,  9.69it/s]\titers: 600, epoch: 8 | loss: 0.2668023\n",
      "\tspeed: 0.1048s/iter; left time: 1120.4212s\n",
      "699it [01:14,  9.60it/s]\titers: 700, epoch: 8 | loss: 0.2609872\n",
      "\tspeed: 0.1044s/iter; left time: 1106.2763s\n",
      "799it [01:25,  9.40it/s]\titers: 800, epoch: 8 | loss: 0.1738905\n",
      "\tspeed: 0.1084s/iter; left time: 1137.2608s\n",
      "899it [01:35,  9.65it/s]\titers: 900, epoch: 8 | loss: 0.3560578\n",
      "\tspeed: 0.1056s/iter; left time: 1097.8498s\n",
      "999it [01:46,  9.45it/s]\titers: 1000, epoch: 8 | loss: 0.3271933\n",
      "\tspeed: 0.1106s/iter; left time: 1138.6926s\n",
      "1098it [01:57,  9.45it/s]\titers: 1100, epoch: 8 | loss: 0.1889334\n",
      "\tspeed: 0.1041s/iter; left time: 1061.5199s\n",
      "1199it [02:08,  9.75it/s]\titers: 1200, epoch: 8 | loss: 0.1721085\n",
      "\tspeed: 0.1110s/iter; left time: 1120.8325s\n",
      "1299it [02:19,  8.06it/s]\titers: 1300, epoch: 8 | loss: 0.1364835\n",
      "\tspeed: 0.1072s/iter; left time: 1071.5019s\n",
      "1399it [02:29,  9.49it/s]\titers: 1400, epoch: 8 | loss: 0.2132577\n",
      "\tspeed: 0.1042s/iter; left time: 1031.5919s\n",
      "1499it [02:40,  9.60it/s]\titers: 1500, epoch: 8 | loss: 0.2948199\n",
      "\tspeed: 0.1067s/iter; left time: 1045.4131s\n",
      "1599it [02:50,  9.64it/s]\titers: 1600, epoch: 8 | loss: 0.2719065\n",
      "\tspeed: 0.1041s/iter; left time: 1008.9411s\n",
      "1698it [03:01,  9.47it/s]\titers: 1700, epoch: 8 | loss: 0.5983642\n",
      "\tspeed: 0.1068s/iter; left time: 1024.6048s\n",
      "1799it [03:11,  9.59it/s]\titers: 1800, epoch: 8 | loss: 0.2435260\n",
      "\tspeed: 0.1052s/iter; left time: 998.6127s\n",
      "1898it [03:22,  9.67it/s]\titers: 1900, epoch: 8 | loss: 0.5071118\n",
      "\tspeed: 0.1068s/iter; left time: 1003.1613s\n",
      "1999it [03:32,  9.66it/s]\titers: 2000, epoch: 8 | loss: 0.2458218\n",
      "\tspeed: 0.1032s/iter; left time: 959.0613s\n",
      "2099it [03:43,  9.82it/s]\titers: 2100, epoch: 8 | loss: 0.2351027\n",
      "\tspeed: 0.1075s/iter; left time: 988.6236s\n",
      "2199it [03:53,  8.70it/s]\titers: 2200, epoch: 8 | loss: 0.3429770\n",
      "\tspeed: 0.1032s/iter; left time: 938.8874s\n",
      "2299it [04:04,  9.50it/s]\titers: 2300, epoch: 8 | loss: 0.3239320\n",
      "\tspeed: 0.1049s/iter; left time: 943.3134s\n",
      "2399it [04:15,  9.47it/s]\titers: 2400, epoch: 8 | loss: 0.2651787\n",
      "\tspeed: 0.1081s/iter; left time: 962.1000s\n",
      "2499it [04:25,  9.17it/s]\titers: 2500, epoch: 8 | loss: 0.2158675\n",
      "\tspeed: 0.1077s/iter; left time: 947.3929s\n",
      "2599it [04:36,  9.78it/s]\titers: 2600, epoch: 8 | loss: 0.3791750\n",
      "\tspeed: 0.1078s/iter; left time: 937.1172s\n",
      "2698it [04:46,  9.74it/s]\titers: 2700, epoch: 8 | loss: 0.2922384\n",
      "\tspeed: 0.1036s/iter; left time: 890.8047s\n",
      "2799it [04:57,  9.55it/s]\titers: 2800, epoch: 8 | loss: 0.3538107\n",
      "\tspeed: 0.1061s/iter; left time: 901.3016s\n",
      "2899it [05:08,  8.72it/s]\titers: 2900, epoch: 8 | loss: 0.2782777\n",
      "\tspeed: 0.1041s/iter; left time: 873.8480s\n",
      "2999it [05:18,  9.67it/s]\titers: 3000, epoch: 8 | loss: 0.3099686\n",
      "\tspeed: 0.1043s/iter; left time: 865.3465s\n",
      "3099it [05:29,  9.86it/s]\titers: 3100, epoch: 8 | loss: 0.5087923\n",
      "\tspeed: 0.1048s/iter; left time: 858.8735s\n",
      "3199it [05:39,  9.60it/s]\titers: 3200, epoch: 8 | loss: 0.2369916\n",
      "\tspeed: 0.1015s/iter; left time: 821.6928s\n",
      "3299it [05:50,  8.63it/s]\titers: 3300, epoch: 8 | loss: 0.2496143\n",
      "\tspeed: 0.1090s/iter; left time: 871.9151s\n",
      "3399it [06:00,  9.70it/s]\titers: 3400, epoch: 8 | loss: 0.1929604\n",
      "\tspeed: 0.1028s/iter; left time: 811.7157s\n",
      "3498it [06:10,  9.76it/s]\titers: 3500, epoch: 8 | loss: 0.3483635\n",
      "\tspeed: 0.1065s/iter; left time: 830.5807s\n",
      "3599it [06:21,  9.79it/s]\titers: 3600, epoch: 8 | loss: 0.3154856\n",
      "\tspeed: 0.1032s/iter; left time: 794.1908s\n",
      "3699it [06:31,  9.81it/s]\titers: 3700, epoch: 8 | loss: 0.2141601\n",
      "\tspeed: 0.1057s/iter; left time: 802.5324s\n",
      "3765it [06:38,  9.44it/s]\n",
      "Epoch: 8 cost time: 398.6782970428467\n",
      "810it [00:38, 20.95it/s]\n",
      "807it [00:37, 21.45it/s]\n",
      "Epoch: 8 | Train Loss: 0.3081620 Vali Loss: 0.3698395 Test Loss: 0.4500522 MAE Loss: 0.4384237\n",
      "lr = 0.0006545120\n",
      "99it [00:10,  9.47it/s]\titers: 100, epoch: 9 | loss: 0.4172454\n",
      "\tspeed: 0.9732s/iter; left time: 7231.6675s\n",
      "198it [00:21,  9.68it/s]\titers: 200, epoch: 9 | loss: 0.2407860\n",
      "\tspeed: 0.1055s/iter; left time: 773.5456s\n",
      "299it [00:31,  8.85it/s]\titers: 300, epoch: 9 | loss: 0.7410207\n",
      "\tspeed: 0.1065s/iter; left time: 770.2217s\n",
      "399it [00:42,  9.78it/s]\titers: 400, epoch: 9 | loss: 0.3043884\n",
      "\tspeed: 0.1034s/iter; left time: 737.1353s\n",
      "499it [00:52, 10.15it/s]\titers: 500, epoch: 9 | loss: 0.2168303\n",
      "\tspeed: 0.1042s/iter; left time: 732.5906s\n",
      "599it [01:02, 10.30it/s]\titers: 600, epoch: 9 | loss: 0.2391678\n",
      "\tspeed: 0.0984s/iter; left time: 682.0614s\n",
      "698it [01:12, 10.10it/s]\titers: 700, epoch: 9 | loss: 0.3864079\n",
      "\tspeed: 0.1004s/iter; left time: 685.9758s\n",
      "798it [01:22, 10.19it/s]\titers: 800, epoch: 9 | loss: 0.3468738\n",
      "\tspeed: 0.0976s/iter; left time: 656.9957s\n",
      "898it [01:32, 10.33it/s]\titers: 900, epoch: 9 | loss: 0.2983672\n",
      "\tspeed: 0.1002s/iter; left time: 664.5568s\n",
      "998it [01:41, 10.15it/s]\titers: 1000, epoch: 9 | loss: 0.4912311\n",
      "\tspeed: 0.0980s/iter; left time: 639.9150s\n",
      "1099it [01:51, 10.48it/s]\titers: 1100, epoch: 9 | loss: 0.2415686\n",
      "\tspeed: 0.0991s/iter; left time: 637.0319s\n",
      "1198it [02:01,  9.29it/s]\titers: 1200, epoch: 9 | loss: 0.2453928\n",
      "\tspeed: 0.0995s/iter; left time: 630.0571s\n",
      "1299it [02:12,  9.93it/s]\titers: 1300, epoch: 9 | loss: 0.3458133\n",
      "\tspeed: 0.1038s/iter; left time: 646.9191s\n",
      "1399it [02:22,  9.76it/s]\titers: 1400, epoch: 9 | loss: 0.4955222\n",
      "\tspeed: 0.1055s/iter; left time: 646.6042s\n",
      "1499it [02:33,  9.74it/s]\titers: 1500, epoch: 9 | loss: 0.6986639\n",
      "\tspeed: 0.1041s/iter; left time: 627.5466s\n",
      "1599it [02:45,  8.88it/s]\titers: 1600, epoch: 9 | loss: 0.3215896\n",
      "\tspeed: 0.1244s/iter; left time: 737.8703s\n",
      "1699it [02:56,  9.79it/s]\titers: 1700, epoch: 9 | loss: 0.2229681\n",
      "\tspeed: 0.1052s/iter; left time: 613.5362s\n",
      "1798it [03:06, 10.16it/s]\titers: 1800, epoch: 9 | loss: 0.1331144\n",
      "\tspeed: 0.1041s/iter; left time: 596.6073s\n",
      "1899it [03:16,  9.80it/s]\titers: 1900, epoch: 9 | loss: 0.1843282\n",
      "\tspeed: 0.1024s/iter; left time: 576.8526s\n",
      "1999it [03:27,  9.84it/s]\titers: 2000, epoch: 9 | loss: 0.2304826\n",
      "\tspeed: 0.1066s/iter; left time: 589.5561s\n",
      "2099it [03:37,  7.93it/s]\titers: 2100, epoch: 9 | loss: 0.2355656\n",
      "\tspeed: 0.1043s/iter; left time: 566.6198s\n",
      "2199it [03:48,  9.89it/s]\titers: 2200, epoch: 9 | loss: 0.3708421\n",
      "\tspeed: 0.1055s/iter; left time: 562.3546s\n",
      "2299it [03:59,  9.63it/s]\titers: 2300, epoch: 9 | loss: 0.1615562\n",
      "\tspeed: 0.1075s/iter; left time: 562.4153s\n",
      "2399it [04:09,  9.74it/s]\titers: 2400, epoch: 9 | loss: 0.2267844\n",
      "\tspeed: 0.1038s/iter; left time: 532.7161s\n",
      "2498it [04:20,  9.65it/s]\titers: 2500, epoch: 9 | loss: 0.3005913\n",
      "\tspeed: 0.1064s/iter; left time: 535.2934s\n",
      "2599it [04:30,  9.64it/s]\titers: 2600, epoch: 9 | loss: 0.3416082\n",
      "\tspeed: 0.1034s/iter; left time: 509.8112s\n",
      "2699it [04:41,  8.87it/s]\titers: 2700, epoch: 9 | loss: 0.2608914\n",
      "\tspeed: 0.1103s/iter; left time: 533.0795s\n",
      "2799it [04:52,  9.71it/s]\titers: 2800, epoch: 9 | loss: 0.2637911\n",
      "\tspeed: 0.1037s/iter; left time: 490.4766s\n",
      "2898it [05:02, 10.31it/s]\titers: 2900, epoch: 9 | loss: 0.5400911\n",
      "\tspeed: 0.1009s/iter; left time: 467.2591s\n",
      "2999it [05:12,  9.35it/s]\titers: 3000, epoch: 9 | loss: 0.3736081\n",
      "\tspeed: 0.0998s/iter; left time: 452.1764s\n",
      "3099it [05:22, 10.24it/s]\titers: 3100, epoch: 9 | loss: 0.1216166\n",
      "\tspeed: 0.0988s/iter; left time: 437.8249s\n",
      "3199it [05:31,  9.88it/s]\titers: 3200, epoch: 9 | loss: 0.1708410\n",
      "\tspeed: 0.0998s/iter; left time: 432.1336s\n",
      "3299it [05:42,  8.97it/s]\titers: 3300, epoch: 9 | loss: 0.3920317\n",
      "\tspeed: 0.1040s/iter; left time: 440.1644s\n",
      "3399it [05:53,  9.42it/s]\titers: 3400, epoch: 9 | loss: 0.3019211\n",
      "\tspeed: 0.1107s/iter; left time: 457.1223s\n",
      "3499it [06:04,  9.93it/s]\titers: 3500, epoch: 9 | loss: 0.2480297\n",
      "\tspeed: 0.1057s/iter; left time: 425.8761s\n",
      "3599it [06:14,  9.99it/s]\titers: 3600, epoch: 9 | loss: 0.1873797\n",
      "\tspeed: 0.1035s/iter; left time: 406.9306s\n",
      "3699it [06:24,  9.28it/s]\titers: 3700, epoch: 9 | loss: 0.2981409\n",
      "\tspeed: 0.0976s/iter; left time: 373.7836s\n",
      "3765it [06:31,  9.61it/s]\n",
      "Epoch: 9 cost time: 391.5813522338867\n",
      "810it [00:38, 21.16it/s]\n",
      "807it [00:37, 21.29it/s]\n",
      "Epoch: 9 | Train Loss: 0.3077733 Vali Loss: 0.3734228 Test Loss: 0.4564576 MAE Loss: 0.4407051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "98it [00:10,  9.56it/s]\titers: 100, epoch: 10 | loss: 0.2235445\n",
      "\tspeed: 0.9477s/iter; left time: 3474.2043s\n",
      "199it [00:21,  9.70it/s]\titers: 200, epoch: 10 | loss: 0.2402189\n",
      "\tspeed: 0.1042s/iter; left time: 371.6368s\n",
      "299it [00:32,  8.73it/s]\titers: 300, epoch: 10 | loss: 0.5548694\n",
      "\tspeed: 0.1063s/iter; left time: 368.4635s\n",
      "399it [00:42,  9.57it/s]\titers: 400, epoch: 10 | loss: 0.3081375\n",
      "\tspeed: 0.1037s/iter; left time: 348.9831s\n",
      "499it [00:52, 10.40it/s]\titers: 500, epoch: 10 | loss: 0.1438293\n",
      "\tspeed: 0.1054s/iter; left time: 344.2893s\n",
      "599it [01:02, 10.12it/s]\titers: 600, epoch: 10 | loss: 0.1651071\n",
      "\tspeed: 0.0975s/iter; left time: 308.7098s\n",
      "699it [01:12, 10.48it/s]\titers: 700, epoch: 10 | loss: 0.3478526\n",
      "\tspeed: 0.1019s/iter; left time: 312.3460s\n",
      "799it [01:23,  8.42it/s]\titers: 800, epoch: 10 | loss: 0.4412026\n",
      "\tspeed: 0.1038s/iter; left time: 307.8485s\n",
      "899it [01:33,  9.69it/s]\titers: 900, epoch: 10 | loss: 0.2612309\n",
      "\tspeed: 0.1036s/iter; left time: 296.7759s\n",
      "999it [01:44,  9.77it/s]\titers: 1000, epoch: 10 | loss: 0.4381417\n",
      "\tspeed: 0.1086s/iter; left time: 300.3090s\n",
      "1099it [01:54,  9.91it/s]\titers: 1100, epoch: 10 | loss: 0.1829154\n",
      "\tspeed: 0.1035s/iter; left time: 275.9823s\n",
      "1199it [02:05,  9.77it/s]\titers: 1200, epoch: 10 | loss: 0.1931322\n",
      "\tspeed: 0.1072s/iter; left time: 274.9729s\n",
      "1299it [02:15,  9.69it/s]\titers: 1300, epoch: 10 | loss: 0.3105976\n",
      "\tspeed: 0.1022s/iter; left time: 252.0209s\n",
      "1399it [02:26,  9.71it/s]\titers: 1400, epoch: 10 | loss: 0.3464423\n",
      "\tspeed: 0.1061s/iter; left time: 251.1273s\n",
      "1499it [02:36,  8.35it/s]\titers: 1500, epoch: 10 | loss: 0.2159579\n",
      "\tspeed: 0.1048s/iter; left time: 237.3680s\n",
      "1599it [02:47,  9.70it/s]\titers: 1600, epoch: 10 | loss: 0.2101147\n",
      "\tspeed: 0.1037s/iter; left time: 224.7141s\n",
      "1699it [02:57,  9.72it/s]\titers: 1700, epoch: 10 | loss: 0.2680765\n",
      "\tspeed: 0.1052s/iter; left time: 217.3551s\n",
      "1799it [03:08,  9.65it/s]\titers: 1800, epoch: 10 | loss: 0.3047492\n",
      "\tspeed: 0.1038s/iter; left time: 204.0131s\n",
      "1898it [03:18,  9.58it/s]\titers: 1900, epoch: 10 | loss: 0.3055594\n",
      "\tspeed: 0.1056s/iter; left time: 197.0826s\n",
      "1999it [03:29,  9.58it/s]\titers: 2000, epoch: 10 | loss: 0.2841032\n",
      "\tspeed: 0.1032s/iter; left time: 182.1843s\n",
      "2099it [03:39,  9.62it/s]\titers: 2100, epoch: 10 | loss: 0.1702823\n",
      "\tspeed: 0.1064s/iter; left time: 177.2616s\n",
      "2199it [03:50,  9.57it/s]\titers: 2200, epoch: 10 | loss: 0.2562758\n",
      "\tspeed: 0.1043s/iter; left time: 163.3920s\n",
      "2299it [04:00,  9.53it/s]\titers: 2300, epoch: 10 | loss: 0.2052799\n",
      "\tspeed: 0.1074s/iter; left time: 157.3759s\n",
      "2399it [04:11,  9.37it/s]\titers: 2400, epoch: 10 | loss: 0.3252999\n",
      "\tspeed: 0.1075s/iter; left time: 146.8542s\n",
      "2498it [04:21,  9.70it/s]\titers: 2500, epoch: 10 | loss: 0.2862371\n",
      "\tspeed: 0.1037s/iter; left time: 131.2815s\n",
      "2598it [04:32,  9.07it/s]\titers: 2600, epoch: 10 | loss: 0.3570297\n",
      "\tspeed: 0.1063s/iter; left time: 123.9402s\n",
      "2699it [04:42,  9.47it/s]\titers: 2700, epoch: 10 | loss: 0.3802657\n",
      "\tspeed: 0.1032s/iter; left time: 109.9757s\n",
      "2799it [04:53,  9.81it/s]\titers: 2800, epoch: 10 | loss: 0.2016282\n",
      "\tspeed: 0.1062s/iter; left time: 102.6062s\n",
      "2899it [05:03,  9.52it/s]\titers: 2900, epoch: 10 | loss: 0.1697121\n",
      "\tspeed: 0.1028s/iter; left time: 89.0158s\n",
      "2998it [05:13, 10.10it/s]\titers: 3000, epoch: 10 | loss: 0.1719423\n",
      "\tspeed: 0.1020s/iter; left time: 78.1295s\n",
      "3098it [05:23,  9.66it/s]\titers: 3100, epoch: 10 | loss: 0.2578464\n",
      "\tspeed: 0.0979s/iter; left time: 65.1740s\n",
      "3199it [05:33, 10.08it/s]\titers: 3200, epoch: 10 | loss: 0.5257652\n",
      "\tspeed: 0.1004s/iter; left time: 56.8479s\n",
      "3299it [05:43, 10.30it/s]\titers: 3300, epoch: 10 | loss: 0.2391298\n",
      "\tspeed: 0.1000s/iter; left time: 46.5836s\n",
      "3399it [05:53, 10.32it/s]\titers: 3400, epoch: 10 | loss: 0.2701829\n",
      "\tspeed: 0.0980s/iter; left time: 35.8851s\n",
      "3499it [06:03,  8.63it/s]\titers: 3500, epoch: 10 | loss: 0.2347176\n",
      "\tspeed: 0.1007s/iter; left time: 26.7815s\n",
      "3599it [06:13,  9.98it/s]\titers: 3600, epoch: 10 | loss: 0.5563565\n",
      "\tspeed: 0.0973s/iter; left time: 16.1568s\n",
      "3698it [06:23,  9.86it/s]\titers: 3700, epoch: 10 | loss: 0.1695818\n",
      "\tspeed: 0.1005s/iter; left time: 6.6339s\n",
      "3765it [06:29,  9.65it/s]\n",
      "Epoch: 10 cost time: 389.96201753616333\n",
      "810it [00:38, 21.27it/s]\n",
      "807it [00:38, 21.04it/s]\n",
      "Epoch: 10 | Train Loss: 0.3064355 Vali Loss: 0.3727824 Test Loss: 0.4499831 MAE Loss: 0.4320601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0005000050\n",
      "Total time: 79.78484623829523 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input 512, medium, COS, lr 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 03:08:19,084] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 03:08:19,915] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 03:08:19,915] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 03:08:19,916] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 03:08:20,800] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 03:08:20,800] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 03:08:22,011] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 03:08:22,012] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 03:08:22,012] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 03:08:22,013] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 03:08:22,013] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 03:08:22,013] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 03:08:22,273] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 03:08:22,274] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,274] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 117.82 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,395] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 03:08:22,396] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,396] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 117.93 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,396] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 03:08:22,504] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 03:08:22,505] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,505] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 118.01 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 03:08:22,506] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc834602850>\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.74it/s]\titers: 100, epoch: 1 | loss: 0.6284837\n",
      "\tspeed: 0.1825s/iter; left time: 6758.5335s\n",
      "199it [00:27,  7.66it/s]\titers: 200, epoch: 1 | loss: 0.5352426\n",
      "\tspeed: 0.1329s/iter; left time: 4908.0318s\n",
      "299it [00:40,  7.62it/s]\titers: 300, epoch: 1 | loss: 0.4914316\n",
      "\tspeed: 0.1304s/iter; left time: 4802.2571s\n",
      "399it [00:54,  7.66it/s]\titers: 400, epoch: 1 | loss: 0.2820175\n",
      "\tspeed: 0.1336s/iter; left time: 4906.3689s\n",
      "499it [01:07,  7.69it/s]\titers: 500, epoch: 1 | loss: 0.2728907\n",
      "\tspeed: 0.1328s/iter; left time: 4864.8639s\n",
      "599it [01:20,  7.51it/s]\titers: 600, epoch: 1 | loss: 0.3732491\n",
      "\tspeed: 0.1304s/iter; left time: 4763.9140s\n",
      "699it [01:33,  7.57it/s]\titers: 700, epoch: 1 | loss: 0.4083984\n",
      "\tspeed: 0.1313s/iter; left time: 4783.2062s\n",
      "799it [01:46,  7.57it/s]\titers: 800, epoch: 1 | loss: 0.2888259\n",
      "\tspeed: 0.1337s/iter; left time: 4858.1393s\n",
      "899it [02:00,  6.07it/s]\titers: 900, epoch: 1 | loss: 0.4882275\n",
      "\tspeed: 0.1347s/iter; left time: 4880.3047s\n",
      "999it [02:13,  6.74it/s]\titers: 1000, epoch: 1 | loss: 0.4720700\n",
      "\tspeed: 0.1318s/iter; left time: 4763.1939s\n",
      "1099it [02:26,  7.57it/s]\titers: 1100, epoch: 1 | loss: 0.2710172\n",
      "\tspeed: 0.1337s/iter; left time: 4815.7645s\n",
      "1199it [02:40,  7.70it/s]\titers: 1200, epoch: 1 | loss: 0.3366533\n",
      "\tspeed: 0.1330s/iter; left time: 4777.9649s\n",
      "1299it [02:53,  7.54it/s]\titers: 1300, epoch: 1 | loss: 0.4391926\n",
      "\tspeed: 0.1318s/iter; left time: 4720.8618s\n",
      "1399it [03:06,  7.67it/s]\titers: 1400, epoch: 1 | loss: 0.2492006\n",
      "\tspeed: 0.1329s/iter; left time: 4750.3584s\n",
      "1499it [03:19,  7.65it/s]\titers: 1500, epoch: 1 | loss: 0.2428142\n",
      "\tspeed: 0.1336s/iter; left time: 4758.6254s\n",
      "1599it [03:33,  7.41it/s]\titers: 1600, epoch: 1 | loss: 0.4292324\n",
      "\tspeed: 0.1334s/iter; left time: 4738.6990s\n",
      "1699it [03:46,  7.44it/s]\titers: 1700, epoch: 1 | loss: 0.4312639\n",
      "\tspeed: 0.1314s/iter; left time: 4654.7521s\n",
      "1799it [03:59,  7.63it/s]\titers: 1800, epoch: 1 | loss: 0.6051976\n",
      "\tspeed: 0.1326s/iter; left time: 4685.7490s\n",
      "1899it [04:12,  7.76it/s]\titers: 1900, epoch: 1 | loss: 0.2817806\n",
      "\tspeed: 0.1326s/iter; left time: 4672.3742s\n",
      "1999it [04:26,  7.62it/s]\titers: 2000, epoch: 1 | loss: 0.3776010\n",
      "\tspeed: 0.1333s/iter; left time: 4683.4772s\n",
      "2099it [04:39,  6.72it/s]\titers: 2100, epoch: 1 | loss: 0.2727109\n",
      "\tspeed: 0.1322s/iter; left time: 4630.2796s\n",
      "2199it [04:52,  7.68it/s]\titers: 2200, epoch: 1 | loss: 0.4344987\n",
      "\tspeed: 0.1321s/iter; left time: 4615.1725s\n",
      "2299it [05:06,  7.70it/s]\titers: 2300, epoch: 1 | loss: 0.4113905\n",
      "\tspeed: 0.1328s/iter; left time: 4626.6593s\n",
      "2399it [05:19,  7.58it/s]\titers: 2400, epoch: 1 | loss: 0.2870833\n",
      "\tspeed: 0.1336s/iter; left time: 4638.4309s\n",
      "2499it [05:32,  7.70it/s]\titers: 2500, epoch: 1 | loss: 0.3584269\n",
      "\tspeed: 0.1306s/iter; left time: 4524.3395s\n",
      "2599it [05:45,  7.79it/s]\titers: 2600, epoch: 1 | loss: 0.2931449\n",
      "\tspeed: 0.1320s/iter; left time: 4557.8968s\n",
      "2699it [05:58,  7.30it/s]\titers: 2700, epoch: 1 | loss: 0.3084987\n",
      "\tspeed: 0.1319s/iter; left time: 4542.7686s\n",
      "2799it [06:11,  7.76it/s]\titers: 2800, epoch: 1 | loss: 0.3998558\n",
      "\tspeed: 0.1296s/iter; left time: 4448.9414s\n",
      "2899it [06:24,  7.73it/s]\titers: 2900, epoch: 1 | loss: 0.2582986\n",
      "\tspeed: 0.1319s/iter; left time: 4513.3672s\n",
      "2999it [06:38,  7.51it/s]\titers: 3000, epoch: 1 | loss: 0.3260675\n",
      "\tspeed: 0.1337s/iter; left time: 4563.8411s\n",
      "3099it [06:51,  7.52it/s]\titers: 3100, epoch: 1 | loss: 0.2262339\n",
      "\tspeed: 0.1350s/iter; left time: 4592.6461s\n",
      "3199it [07:05,  7.44it/s]\titers: 3200, epoch: 1 | loss: 0.2288827\n",
      "\tspeed: 0.1344s/iter; left time: 4559.3638s\n",
      "3299it [07:18,  7.54it/s]\titers: 3300, epoch: 1 | loss: 0.4653212\n",
      "\tspeed: 0.1348s/iter; left time: 4561.2596s\n",
      "3399it [07:32,  7.36it/s]\titers: 3400, epoch: 1 | loss: 0.5665098\n",
      "\tspeed: 0.1347s/iter; left time: 4542.2462s\n",
      "3499it [07:45,  7.02it/s]\titers: 3500, epoch: 1 | loss: 0.3672006\n",
      "\tspeed: 0.1353s/iter; left time: 4549.9972s\n",
      "3599it [07:59,  7.60it/s]\titers: 3600, epoch: 1 | loss: 0.2720945\n",
      "\tspeed: 0.1353s/iter; left time: 4537.0406s\n",
      "3699it [08:12,  7.25it/s]\titers: 3700, epoch: 1 | loss: 0.2639223\n",
      "\tspeed: 0.1371s/iter; left time: 4581.8765s\n",
      "3713it [08:14,  7.50it/s]\n",
      "Epoch: 1 cost time: 494.9174425601959\n",
      "810it [00:52, 15.51it/s]\n",
      "807it [00:51, 15.80it/s]\n",
      "Epoch: 1 | Train Loss: 0.3539966 Vali Loss: 0.4033258 Test Loss: 0.5074162 MAE Loss: 0.4763052\n",
      "lr = 0.0009938442\n",
      "99it [00:13,  7.75it/s]\titers: 100, epoch: 2 | loss: 0.3767157\n",
      "\tspeed: 1.2266s/iter; left time: 40868.5269s\n",
      "199it [00:26,  7.83it/s]\titers: 200, epoch: 2 | loss: 0.4751770\n",
      "\tspeed: 0.1318s/iter; left time: 4377.4247s\n",
      "299it [00:39,  7.91it/s]\titers: 300, epoch: 2 | loss: 0.4254152\n",
      "\tspeed: 0.1301s/iter; left time: 4310.1532s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 2 | loss: 0.6282481\n",
      "\tspeed: 0.1293s/iter; left time: 4269.4003s\n",
      "499it [01:05,  7.98it/s]\titers: 500, epoch: 2 | loss: 0.2911870\n",
      "\tspeed: 0.1288s/iter; left time: 4238.8766s\n",
      "599it [01:18,  7.62it/s]\titers: 600, epoch: 2 | loss: 0.4708160\n",
      "\tspeed: 0.1301s/iter; left time: 4269.1307s\n",
      "699it [01:31,  7.77it/s]\titers: 700, epoch: 2 | loss: 0.3043123\n",
      "\tspeed: 0.1278s/iter; left time: 4182.9421s\n",
      "799it [01:44,  8.01it/s]\titers: 800, epoch: 2 | loss: 0.4478506\n",
      "\tspeed: 0.1300s/iter; left time: 4240.3812s\n",
      "899it [01:57,  7.87it/s]\titers: 900, epoch: 2 | loss: 0.3069436\n",
      "\tspeed: 0.1298s/iter; left time: 4221.0939s\n",
      "999it [02:09,  7.07it/s]\titers: 1000, epoch: 2 | loss: 0.3549146\n",
      "\tspeed: 0.1300s/iter; left time: 4214.1144s\n",
      "1099it [02:22,  7.76it/s]\titers: 1100, epoch: 2 | loss: 0.3372775\n",
      "\tspeed: 0.1290s/iter; left time: 4168.1278s\n",
      "1199it [02:36,  7.82it/s]\titers: 1200, epoch: 2 | loss: 0.5666034\n",
      "\tspeed: 0.1316s/iter; left time: 4238.8931s\n",
      "1299it [02:48,  7.43it/s]\titers: 1300, epoch: 2 | loss: 0.2821845\n",
      "\tspeed: 0.1292s/iter; left time: 4150.2258s\n",
      "1399it [03:02,  7.47it/s]\titers: 1400, epoch: 2 | loss: 0.2186523\n",
      "\tspeed: 0.1317s/iter; left time: 4217.9144s\n",
      "1499it [03:15,  7.73it/s]\titers: 1500, epoch: 2 | loss: 0.6387949\n",
      "\tspeed: 0.1322s/iter; left time: 4220.0501s\n",
      "1599it [03:28,  7.83it/s]\titers: 1600, epoch: 2 | loss: 0.3126513\n",
      "\tspeed: 0.1308s/iter; left time: 4161.4719s\n",
      "1699it [03:41,  7.91it/s]\titers: 1700, epoch: 2 | loss: 0.4256271\n",
      "\tspeed: 0.1288s/iter; left time: 4084.1310s\n",
      "1799it [03:54,  7.88it/s]\titers: 1800, epoch: 2 | loss: 0.2084496\n",
      "\tspeed: 0.1299s/iter; left time: 4106.5499s\n",
      "1899it [04:07,  7.50it/s]\titers: 1900, epoch: 2 | loss: 0.3614881\n",
      "\tspeed: 0.1307s/iter; left time: 4119.0550s\n",
      "1999it [04:20,  7.72it/s]\titers: 2000, epoch: 2 | loss: 0.2827127\n",
      "\tspeed: 0.1277s/iter; left time: 4010.8100s\n",
      "2099it [04:33,  7.76it/s]\titers: 2100, epoch: 2 | loss: 0.4691244\n",
      "\tspeed: 0.1297s/iter; left time: 4061.1959s\n",
      "2199it [04:46,  8.00it/s]\titers: 2200, epoch: 2 | loss: 0.4235355\n",
      "\tspeed: 0.1311s/iter; left time: 4091.5665s\n",
      "2299it [04:59,  7.80it/s]\titers: 2300, epoch: 2 | loss: 0.3109887\n",
      "\tspeed: 0.1303s/iter; left time: 4055.4639s\n",
      "2399it [05:12,  7.80it/s]\titers: 2400, epoch: 2 | loss: 0.5009397\n",
      "\tspeed: 0.1284s/iter; left time: 3984.0013s\n",
      "2499it [05:25,  7.73it/s]\titers: 2500, epoch: 2 | loss: 0.2803027\n",
      "\tspeed: 0.1295s/iter; left time: 4004.7365s\n",
      "2599it [05:37,  7.87it/s]\titers: 2600, epoch: 2 | loss: 0.3870358\n",
      "\tspeed: 0.1288s/iter; left time: 3969.7501s\n",
      "2699it [05:50,  7.88it/s]\titers: 2700, epoch: 2 | loss: 0.2980010\n",
      "\tspeed: 0.1280s/iter; left time: 3931.4102s\n",
      "2799it [06:03,  7.90it/s]\titers: 2800, epoch: 2 | loss: 0.4731279\n",
      "\tspeed: 0.1297s/iter; left time: 3970.0222s\n",
      "2899it [06:16,  7.90it/s]\titers: 2900, epoch: 2 | loss: 0.3358819\n",
      "\tspeed: 0.1296s/iter; left time: 3956.4440s\n",
      "2999it [06:29,  7.31it/s]\titers: 3000, epoch: 2 | loss: 0.2284171\n",
      "\tspeed: 0.1277s/iter; left time: 3884.4715s\n",
      "3099it [06:42,  7.90it/s]\titers: 3100, epoch: 2 | loss: 0.3610570\n",
      "\tspeed: 0.1287s/iter; left time: 3901.1419s\n",
      "3199it [06:55,  7.97it/s]\titers: 3200, epoch: 2 | loss: 0.3276180\n",
      "\tspeed: 0.1301s/iter; left time: 3931.5115s\n",
      "3299it [07:08,  7.72it/s]\titers: 3300, epoch: 2 | loss: 0.2031095\n",
      "\tspeed: 0.1279s/iter; left time: 3852.2568s\n",
      "3399it [07:20,  7.78it/s]\titers: 3400, epoch: 2 | loss: 0.2928004\n",
      "\tspeed: 0.1284s/iter; left time: 3854.6565s\n",
      "3499it [07:33,  7.88it/s]\titers: 3500, epoch: 2 | loss: 0.3029553\n",
      "\tspeed: 0.1302s/iter; left time: 3895.4882s\n",
      "3599it [07:47,  7.87it/s]\titers: 3600, epoch: 2 | loss: 0.2909013\n",
      "\tspeed: 0.1304s/iter; left time: 3888.8744s\n",
      "3699it [07:59,  6.24it/s]\titers: 3700, epoch: 2 | loss: 0.1638605\n",
      "\tspeed: 0.1301s/iter; left time: 3866.8603s\n",
      "3713it [08:01,  7.70it/s]\n",
      "Epoch: 2 cost time: 481.89586758613586\n",
      "810it [00:48, 16.65it/s]\n",
      "807it [00:48, 16.70it/s]\n",
      "Epoch: 2 | Train Loss: 0.3426453 Vali Loss: 0.4419988 Test Loss: 0.5359442 MAE Loss: 0.4935539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:13,  7.70it/s]\titers: 100, epoch: 3 | loss: 0.5224727\n",
      "\tspeed: 1.1222s/iter; left time: 33221.9927s\n",
      "199it [00:26,  7.86it/s]\titers: 200, epoch: 3 | loss: 0.2085290\n",
      "\tspeed: 0.1287s/iter; left time: 3797.0288s\n",
      "299it [00:39,  7.81it/s]\titers: 300, epoch: 3 | loss: 0.3238280\n",
      "\tspeed: 0.1309s/iter; left time: 3849.7742s\n",
      "399it [00:52,  7.82it/s]\titers: 400, epoch: 3 | loss: 0.6686686\n",
      "\tspeed: 0.1290s/iter; left time: 3781.6329s\n",
      "499it [01:05,  7.88it/s]\titers: 500, epoch: 3 | loss: 0.3294648\n",
      "\tspeed: 0.1294s/iter; left time: 3778.8103s\n",
      "599it [01:18,  7.80it/s]\titers: 600, epoch: 3 | loss: 0.3629559\n",
      "\tspeed: 0.1297s/iter; left time: 3774.0650s\n",
      "699it [01:31,  7.93it/s]\titers: 700, epoch: 3 | loss: 0.3475680\n",
      "\tspeed: 0.1297s/iter; left time: 3761.5347s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 3 | loss: 1.0025202\n",
      "\tspeed: 0.1285s/iter; left time: 3713.5177s\n",
      "899it [01:56,  7.88it/s]\titers: 900, epoch: 3 | loss: 0.5751390\n",
      "\tspeed: 0.1296s/iter; left time: 3731.7946s\n",
      "999it [02:09,  7.84it/s]\titers: 1000, epoch: 3 | loss: 0.3736329\n",
      "\tspeed: 0.1298s/iter; left time: 3725.5384s\n",
      "1099it [02:22,  7.10it/s]\titers: 1100, epoch: 3 | loss: 0.2845280\n",
      "\tspeed: 0.1286s/iter; left time: 3679.9374s\n",
      "1199it [02:35,  7.87it/s]\titers: 1200, epoch: 3 | loss: 0.2719593\n",
      "\tspeed: 0.1293s/iter; left time: 3685.0346s\n",
      "1299it [02:48,  7.83it/s]\titers: 1300, epoch: 3 | loss: 0.2924204\n",
      "\tspeed: 0.1304s/iter; left time: 3703.9041s\n",
      "1399it [03:01,  7.73it/s]\titers: 1400, epoch: 3 | loss: 0.4612133\n",
      "\tspeed: 0.1291s/iter; left time: 3654.3062s\n",
      "1499it [03:14,  7.91it/s]\titers: 1500, epoch: 3 | loss: 0.1913575\n",
      "\tspeed: 0.1285s/iter; left time: 3625.3737s\n",
      "1599it [03:27,  7.79it/s]\titers: 1600, epoch: 3 | loss: 0.7234213\n",
      "\tspeed: 0.1306s/iter; left time: 3669.8067s\n",
      "1699it [03:40,  7.74it/s]\titers: 1700, epoch: 3 | loss: 0.4735206\n",
      "\tspeed: 0.1311s/iter; left time: 3670.5548s\n",
      "1799it [03:53,  7.68it/s]\titers: 1800, epoch: 3 | loss: 0.2808116\n",
      "\tspeed: 0.1287s/iter; left time: 3592.2362s\n",
      "1899it [04:06,  7.77it/s]\titers: 1900, epoch: 3 | loss: 0.3126731\n",
      "\tspeed: 0.1331s/iter; left time: 3700.0253s\n",
      "1999it [04:20,  7.63it/s]\titers: 2000, epoch: 3 | loss: 0.2936290\n",
      "\tspeed: 0.1333s/iter; left time: 3693.9308s\n",
      "2099it [04:32,  7.82it/s]\titers: 2100, epoch: 3 | loss: 0.3481406\n",
      "\tspeed: 0.1289s/iter; left time: 3557.2027s\n",
      "2199it [04:46,  7.89it/s]\titers: 2200, epoch: 3 | loss: 0.2055496\n",
      "\tspeed: 0.1307s/iter; left time: 3594.6466s\n",
      "2299it [04:59,  7.61it/s]\titers: 2300, epoch: 3 | loss: 0.2287608\n",
      "\tspeed: 0.1317s/iter; left time: 3609.6501s\n",
      "2399it [05:11,  7.83it/s]\titers: 2400, epoch: 3 | loss: 0.2860211\n",
      "\tspeed: 0.1271s/iter; left time: 3469.2007s\n",
      "2499it [05:24,  7.91it/s]\titers: 2500, epoch: 3 | loss: 0.3091559\n",
      "\tspeed: 0.1297s/iter; left time: 3528.4626s\n",
      "2599it [05:37,  6.18it/s]\titers: 2600, epoch: 3 | loss: 0.3608786\n",
      "\tspeed: 0.1297s/iter; left time: 3515.5358s\n",
      "2699it [05:50,  7.86it/s]\titers: 2700, epoch: 3 | loss: 0.2663588\n",
      "\tspeed: 0.1278s/iter; left time: 3451.4829s\n",
      "2799it [06:03,  7.71it/s]\titers: 2800, epoch: 3 | loss: 0.3184358\n",
      "\tspeed: 0.1305s/iter; left time: 3511.9522s\n",
      "2899it [06:16,  7.72it/s]\titers: 2900, epoch: 3 | loss: 0.2107174\n",
      "\tspeed: 0.1299s/iter; left time: 3483.0505s\n",
      "2999it [06:29,  7.64it/s]\titers: 3000, epoch: 3 | loss: 0.3653926\n",
      "\tspeed: 0.1278s/iter; left time: 3412.7191s\n",
      "3099it [06:42,  7.83it/s]\titers: 3100, epoch: 3 | loss: 0.3442631\n",
      "\tspeed: 0.1285s/iter; left time: 3419.4389s\n",
      "3199it [06:55,  7.94it/s]\titers: 3200, epoch: 3 | loss: 0.2078412\n",
      "\tspeed: 0.1289s/iter; left time: 3416.8147s\n",
      "3299it [07:07,  7.57it/s]\titers: 3300, epoch: 3 | loss: 0.2802461\n",
      "\tspeed: 0.1272s/iter; left time: 3359.8345s\n",
      "3399it [07:20,  7.89it/s]\titers: 3400, epoch: 3 | loss: 0.3181832\n",
      "\tspeed: 0.1273s/iter; left time: 3349.9316s\n",
      "3499it [07:33,  7.91it/s]\titers: 3500, epoch: 3 | loss: 0.3222934\n",
      "\tspeed: 0.1280s/iter; left time: 3354.7279s\n",
      "3599it [07:46,  7.90it/s]\titers: 3600, epoch: 3 | loss: 0.1407734\n",
      "\tspeed: 0.1271s/iter; left time: 3316.7924s\n",
      "3699it [07:58,  7.75it/s]\titers: 3700, epoch: 3 | loss: 0.6066621\n",
      "\tspeed: 0.1278s/iter; left time: 3322.1774s\n",
      "3713it [08:00,  7.72it/s]\n",
      "Epoch: 3 cost time: 480.8268074989319\n",
      "810it [00:48, 16.72it/s]\n",
      "807it [00:48, 16.70it/s]\n",
      "Epoch: 3 | Train Loss: 0.3307373 Vali Loss: 0.4145984 Test Loss: 0.5158148 MAE Loss: 0.4856396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:13,  7.51it/s]\titers: 100, epoch: 4 | loss: 0.3085895\n",
      "\tspeed: 1.1182s/iter; left time: 28953.1088s\n",
      "199it [00:26,  7.87it/s]\titers: 200, epoch: 4 | loss: 0.3190602\n",
      "\tspeed: 0.1305s/iter; left time: 3366.6959s\n",
      "299it [00:39,  7.81it/s]\titers: 300, epoch: 4 | loss: 0.3972897\n",
      "\tspeed: 0.1298s/iter; left time: 3335.2319s\n",
      "399it [00:52,  7.62it/s]\titers: 400, epoch: 4 | loss: 0.6874273\n",
      "\tspeed: 0.1296s/iter; left time: 3317.5713s\n",
      "499it [01:04,  7.76it/s]\titers: 500, epoch: 4 | loss: 0.1665531\n",
      "\tspeed: 0.1292s/iter; left time: 3293.8501s\n",
      "599it [01:18,  7.70it/s]\titers: 600, epoch: 4 | loss: 0.3449117\n",
      "\tspeed: 0.1308s/iter; left time: 3321.0708s\n",
      "699it [01:30,  7.40it/s]\titers: 700, epoch: 4 | loss: 0.4637513\n",
      "\tspeed: 0.1286s/iter; left time: 3253.0285s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 4 | loss: 0.3791815\n",
      "\tspeed: 0.1284s/iter; left time: 3235.0704s\n",
      "899it [01:56,  7.85it/s]\titers: 900, epoch: 4 | loss: 0.3098664\n",
      "\tspeed: 0.1319s/iter; left time: 3309.7433s\n",
      "999it [02:10,  7.68it/s]\titers: 1000, epoch: 4 | loss: 0.3481237\n",
      "\tspeed: 0.1320s/iter; left time: 3298.2259s\n",
      "1099it [02:22,  7.76it/s]\titers: 1100, epoch: 4 | loss: 0.2980776\n",
      "\tspeed: 0.1283s/iter; left time: 3192.8146s\n",
      "1199it [02:35,  7.78it/s]\titers: 1200, epoch: 4 | loss: 0.4521514\n",
      "\tspeed: 0.1302s/iter; left time: 3227.6695s\n",
      "1299it [02:48,  7.89it/s]\titers: 1300, epoch: 4 | loss: 0.4708442\n",
      "\tspeed: 0.1299s/iter; left time: 3207.9989s\n",
      "1399it [03:01,  7.94it/s]\titers: 1400, epoch: 4 | loss: 0.3791539\n",
      "\tspeed: 0.1285s/iter; left time: 3160.4429s\n",
      "1499it [03:14,  7.83it/s]\titers: 1500, epoch: 4 | loss: 0.3401311\n",
      "\tspeed: 0.1304s/iter; left time: 3193.4302s\n",
      "1599it [03:27,  8.04it/s]\titers: 1600, epoch: 4 | loss: 0.3305887\n",
      "\tspeed: 0.1294s/iter; left time: 3156.2043s\n",
      "1699it [03:40,  7.83it/s]\titers: 1700, epoch: 4 | loss: 0.3038333\n",
      "\tspeed: 0.1285s/iter; left time: 3120.7782s\n",
      "1799it [03:53,  7.69it/s]\titers: 1800, epoch: 4 | loss: 0.2486874\n",
      "\tspeed: 0.1287s/iter; left time: 3113.7273s\n",
      "1899it [04:06,  7.85it/s]\titers: 1900, epoch: 4 | loss: 0.4243304\n",
      "\tspeed: 0.1299s/iter; left time: 3128.6855s\n",
      "1999it [04:19,  7.01it/s]\titers: 2000, epoch: 4 | loss: 0.2149484\n",
      "\tspeed: 0.1296s/iter; left time: 3109.3499s\n",
      "2099it [04:32,  7.79it/s]\titers: 2100, epoch: 4 | loss: 0.3770129\n",
      "\tspeed: 0.1273s/iter; left time: 3040.4074s\n",
      "2199it [04:45,  7.82it/s]\titers: 2200, epoch: 4 | loss: 0.1947407\n",
      "\tspeed: 0.1293s/iter; left time: 3076.9328s\n",
      "2299it [04:58,  7.89it/s]\titers: 2300, epoch: 4 | loss: 0.2886204\n",
      "\tspeed: 0.1309s/iter; left time: 3101.3148s\n",
      "2399it [05:11,  6.82it/s]\titers: 2400, epoch: 4 | loss: 0.2057156\n",
      "\tspeed: 0.1292s/iter; left time: 3048.7349s\n",
      "2499it [05:24,  7.90it/s]\titers: 2500, epoch: 4 | loss: 0.2986284\n",
      "\tspeed: 0.1299s/iter; left time: 3051.4168s\n",
      "2599it [05:37,  7.90it/s]\titers: 2600, epoch: 4 | loss: 0.3845401\n",
      "\tspeed: 0.1311s/iter; left time: 3065.9263s\n",
      "2699it [05:50,  7.85it/s]\titers: 2700, epoch: 4 | loss: 0.2046233\n",
      "\tspeed: 0.1283s/iter; left time: 2987.9317s\n",
      "2799it [06:02,  7.86it/s]\titers: 2800, epoch: 4 | loss: 0.5872942\n",
      "\tspeed: 0.1280s/iter; left time: 2967.4331s\n",
      "2899it [06:15,  7.95it/s]\titers: 2900, epoch: 4 | loss: 0.2787766\n",
      "\tspeed: 0.1280s/iter; left time: 2954.9400s\n",
      "2999it [06:28,  7.84it/s]\titers: 3000, epoch: 4 | loss: 0.3276455\n",
      "\tspeed: 0.1278s/iter; left time: 2938.9111s\n",
      "3099it [06:41,  7.95it/s]\titers: 3100, epoch: 4 | loss: 0.2882536\n",
      "\tspeed: 0.1272s/iter; left time: 2912.6387s\n",
      "3199it [06:54,  8.04it/s]\titers: 3200, epoch: 4 | loss: 0.3190152\n",
      "\tspeed: 0.1290s/iter; left time: 2940.3293s\n",
      "3299it [07:06,  7.83it/s]\titers: 3300, epoch: 4 | loss: 0.2534955\n",
      "\tspeed: 0.1284s/iter; left time: 2912.5527s\n",
      "3399it [07:19,  7.49it/s]\titers: 3400, epoch: 4 | loss: 0.2013041\n",
      "\tspeed: 0.1267s/iter; left time: 2862.8180s\n",
      "3499it [07:32,  7.91it/s]\titers: 3500, epoch: 4 | loss: 0.3635070\n",
      "\tspeed: 0.1283s/iter; left time: 2884.7892s\n",
      "3599it [07:45,  7.81it/s]\titers: 3600, epoch: 4 | loss: 0.3619284\n",
      "\tspeed: 0.1299s/iter; left time: 2909.0581s\n",
      "3699it [07:58,  7.77it/s]\titers: 3700, epoch: 4 | loss: 0.1722519\n",
      "\tspeed: 0.1289s/iter; left time: 2874.1823s\n",
      "3713it [08:00,  7.73it/s]\n",
      "Epoch: 4 cost time: 480.4098255634308\n",
      "810it [00:48, 16.82it/s]\n",
      "807it [00:48, 16.50it/s]\n",
      "Epoch: 4 | Train Loss: 0.3298674 Vali Loss: 0.3902555 Test Loss: 0.4786931 MAE Loss: 0.4599794\n",
      "lr = 0.0009045095\n",
      "99it [00:13,  7.92it/s]\titers: 100, epoch: 5 | loss: 0.2062469\n",
      "\tspeed: 1.1639s/iter; left time: 25814.7147s\n",
      "199it [00:26,  7.70it/s]\titers: 200, epoch: 5 | loss: 0.2092327\n",
      "\tspeed: 0.1285s/iter; left time: 2838.1422s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 5 | loss: 0.3449670\n",
      "\tspeed: 0.1288s/iter; left time: 2830.2166s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 5 | loss: 0.3249771\n",
      "\tspeed: 0.1317s/iter; left time: 2881.0262s\n",
      "499it [01:05,  7.79it/s]\titers: 500, epoch: 5 | loss: 0.1315668\n",
      "\tspeed: 0.1296s/iter; left time: 2823.3163s\n",
      "599it [01:18,  7.73it/s]\titers: 600, epoch: 5 | loss: 0.2624253\n",
      "\tspeed: 0.1288s/iter; left time: 2792.2911s\n",
      "699it [01:31,  7.84it/s]\titers: 700, epoch: 5 | loss: 0.3038742\n",
      "\tspeed: 0.1304s/iter; left time: 2814.2567s\n",
      "799it [01:44,  7.06it/s]\titers: 800, epoch: 5 | loss: 0.3684295\n",
      "\tspeed: 0.1302s/iter; left time: 2797.4030s\n",
      "899it [01:56,  7.56it/s]\titers: 900, epoch: 5 | loss: 0.4144670\n",
      "\tspeed: 0.1270s/iter; left time: 2715.9057s\n",
      "999it [02:09,  7.81it/s]\titers: 1000, epoch: 5 | loss: 0.3208720\n",
      "\tspeed: 0.1291s/iter; left time: 2747.1078s\n",
      "1099it [02:22,  7.97it/s]\titers: 1100, epoch: 5 | loss: 0.3457694\n",
      "\tspeed: 0.1294s/iter; left time: 2740.8900s\n",
      "1199it [02:35,  7.88it/s]\titers: 1200, epoch: 5 | loss: 0.3169947\n",
      "\tspeed: 0.1284s/iter; left time: 2705.9622s\n",
      "1299it [02:48,  7.74it/s]\titers: 1300, epoch: 5 | loss: 0.1993393\n",
      "\tspeed: 0.1291s/iter; left time: 2709.2905s\n",
      "1399it [03:01,  7.85it/s]\titers: 1400, epoch: 5 | loss: 0.1898936\n",
      "\tspeed: 0.1296s/iter; left time: 2706.8976s\n",
      "1499it [03:14,  7.89it/s]\titers: 1500, epoch: 5 | loss: 0.1944701\n",
      "\tspeed: 0.1286s/iter; left time: 2672.7828s\n",
      "1599it [03:27,  7.99it/s]\titers: 1600, epoch: 5 | loss: 0.2967289\n",
      "\tspeed: 0.1272s/iter; left time: 2629.8862s\n",
      "1699it [03:39,  7.92it/s]\titers: 1700, epoch: 5 | loss: 0.2972065\n",
      "\tspeed: 0.1282s/iter; left time: 2638.7958s\n",
      "1799it [03:52,  7.94it/s]\titers: 1800, epoch: 5 | loss: 0.2943450\n",
      "\tspeed: 0.1293s/iter; left time: 2647.0468s\n",
      "1899it [04:05,  7.69it/s]\titers: 1900, epoch: 5 | loss: 0.3562803\n",
      "\tspeed: 0.1287s/iter; left time: 2621.8298s\n",
      "1999it [04:18,  7.74it/s]\titers: 2000, epoch: 5 | loss: 0.2711124\n",
      "\tspeed: 0.1288s/iter; left time: 2611.6762s\n",
      "2099it [04:31,  7.84it/s]\titers: 2100, epoch: 5 | loss: 0.3655235\n",
      "\tspeed: 0.1297s/iter; left time: 2617.1938s\n",
      "2199it [04:44,  7.87it/s]\titers: 2200, epoch: 5 | loss: 0.2359903\n",
      "\tspeed: 0.1303s/iter; left time: 2617.1788s\n",
      "2299it [04:57,  7.65it/s]\titers: 2300, epoch: 5 | loss: 0.5608481\n",
      "\tspeed: 0.1295s/iter; left time: 2587.4068s\n",
      "2399it [05:10,  7.77it/s]\titers: 2400, epoch: 5 | loss: 0.3043300\n",
      "\tspeed: 0.1289s/iter; left time: 2562.4152s\n",
      "2499it [05:23,  7.93it/s]\titers: 2500, epoch: 5 | loss: 0.3357579\n",
      "\tspeed: 0.1292s/iter; left time: 2555.5241s\n",
      "2599it [05:36,  6.55it/s]\titers: 2600, epoch: 5 | loss: 0.4537764\n",
      "\tspeed: 0.1300s/iter; left time: 2558.2860s\n",
      "2699it [05:48,  7.81it/s]\titers: 2700, epoch: 5 | loss: 0.2674872\n",
      "\tspeed: 0.1265s/iter; left time: 2476.2457s\n",
      "2799it [06:01,  7.88it/s]\titers: 2800, epoch: 5 | loss: 0.2827784\n",
      "\tspeed: 0.1286s/iter; left time: 2504.9350s\n",
      "2899it [06:14,  7.86it/s]\titers: 2900, epoch: 5 | loss: 0.3093247\n",
      "\tspeed: 0.1284s/iter; left time: 2488.0927s\n",
      "2999it [06:27,  7.49it/s]\titers: 3000, epoch: 5 | loss: 0.3517567\n",
      "\tspeed: 0.1272s/iter; left time: 2452.1209s\n",
      "3099it [06:40,  7.82it/s]\titers: 3100, epoch: 5 | loss: 0.3229257\n",
      "\tspeed: 0.1280s/iter; left time: 2454.3884s\n",
      "3199it [06:53,  7.79it/s]\titers: 3200, epoch: 5 | loss: 0.3408239\n",
      "\tspeed: 0.1306s/iter; left time: 2491.7868s\n",
      "3299it [07:06,  7.57it/s]\titers: 3300, epoch: 5 | loss: 0.3052003\n",
      "\tspeed: 0.1288s/iter; left time: 2444.1325s\n",
      "3399it [07:18,  7.83it/s]\titers: 3400, epoch: 5 | loss: 0.3453138\n",
      "\tspeed: 0.1289s/iter; left time: 2432.7699s\n",
      "3499it [07:31,  7.77it/s]\titers: 3500, epoch: 5 | loss: 0.4115940\n",
      "\tspeed: 0.1302s/iter; left time: 2445.2985s\n",
      "3599it [07:44,  7.71it/s]\titers: 3600, epoch: 5 | loss: 0.4233800\n",
      "\tspeed: 0.1286s/iter; left time: 2401.7575s\n",
      "3699it [07:57,  7.65it/s]\titers: 3700, epoch: 5 | loss: 0.2183217\n",
      "\tspeed: 0.1309s/iter; left time: 2431.9265s\n",
      "3713it [07:59,  7.74it/s]\n",
      "Epoch: 5 cost time: 479.80248856544495\n",
      "810it [00:48, 16.59it/s]\n",
      "807it [00:48, 16.62it/s]\n",
      "Epoch: 5 | Train Loss: 0.3223494 Vali Loss: 0.3899679 Test Loss: 0.5002480 MAE Loss: 0.4720434\n",
      "lr = 0.0008535549\n",
      "99it [00:13,  7.90it/s]\titers: 100, epoch: 6 | loss: 0.3981171\n",
      "\tspeed: 1.1652s/iter; left time: 21515.9685s\n",
      "199it [00:26,  7.80it/s]\titers: 200, epoch: 6 | loss: 0.2415454\n",
      "\tspeed: 0.1302s/iter; left time: 2391.0793s\n",
      "299it [00:39,  7.84it/s]\titers: 300, epoch: 6 | loss: 0.4251336\n",
      "\tspeed: 0.1305s/iter; left time: 2384.4531s\n",
      "399it [00:51,  6.97it/s]\titers: 400, epoch: 6 | loss: 0.2379706\n",
      "\tspeed: 0.1285s/iter; left time: 2334.1756s\n",
      "499it [01:04,  7.98it/s]\titers: 500, epoch: 6 | loss: 0.2679409\n",
      "\tspeed: 0.1290s/iter; left time: 2330.0865s\n",
      "599it [01:17,  7.79it/s]\titers: 600, epoch: 6 | loss: 0.4484220\n",
      "\tspeed: 0.1301s/iter; left time: 2337.4122s\n",
      "699it [01:30,  7.91it/s]\titers: 700, epoch: 6 | loss: 0.4534326\n",
      "\tspeed: 0.1306s/iter; left time: 2332.5761s\n",
      "799it [01:43,  7.79it/s]\titers: 800, epoch: 6 | loss: 0.4298534\n",
      "\tspeed: 0.1290s/iter; left time: 2291.8798s\n",
      "899it [01:56,  7.71it/s]\titers: 900, epoch: 6 | loss: 0.4534819\n",
      "\tspeed: 0.1317s/iter; left time: 2325.7789s\n",
      "999it [02:10,  7.61it/s]\titers: 1000, epoch: 6 | loss: 0.2164369\n",
      "\tspeed: 0.1316s/iter; left time: 2311.7164s\n",
      "1099it [02:23,  7.64it/s]\titers: 1100, epoch: 6 | loss: 0.2568227\n",
      "\tspeed: 0.1322s/iter; left time: 2309.7600s\n",
      "1199it [02:36,  7.54it/s]\titers: 1200, epoch: 6 | loss: 0.3906294\n",
      "\tspeed: 0.1334s/iter; left time: 2317.1080s\n",
      "1299it [02:49,  7.92it/s]\titers: 1300, epoch: 6 | loss: 0.3052442\n",
      "\tspeed: 0.1307s/iter; left time: 2256.9674s\n",
      "1399it [03:02,  7.83it/s]\titers: 1400, epoch: 6 | loss: 0.2060187\n",
      "\tspeed: 0.1284s/iter; left time: 2204.4717s\n",
      "1499it [03:15,  7.97it/s]\titers: 1500, epoch: 6 | loss: 0.2281263\n",
      "\tspeed: 0.1312s/iter; left time: 2239.5127s\n",
      "1599it [03:28,  7.96it/s]\titers: 1600, epoch: 6 | loss: 0.1834518\n",
      "\tspeed: 0.1310s/iter; left time: 2222.3549s\n",
      "1699it [03:41,  7.69it/s]\titers: 1700, epoch: 6 | loss: 0.4229937\n",
      "\tspeed: 0.1309s/iter; left time: 2208.4349s\n",
      "1799it [03:54,  7.91it/s]\titers: 1800, epoch: 6 | loss: 0.3029844\n",
      "\tspeed: 0.1284s/iter; left time: 2152.1588s\n",
      "1899it [04:08,  7.85it/s]\titers: 1900, epoch: 6 | loss: 0.3882581\n",
      "\tspeed: 0.1338s/iter; left time: 2230.5745s\n",
      "1999it [04:21,  7.81it/s]\titers: 2000, epoch: 6 | loss: 0.2055421\n",
      "\tspeed: 0.1320s/iter; left time: 2186.9107s\n",
      "2099it [04:34,  6.73it/s]\titers: 2100, epoch: 6 | loss: 0.3976897\n",
      "\tspeed: 0.1298s/iter; left time: 2137.3712s\n",
      "2199it [04:47,  7.85it/s]\titers: 2200, epoch: 6 | loss: 0.1607098\n",
      "\tspeed: 0.1288s/iter; left time: 2108.6785s\n",
      "2299it [05:00,  7.63it/s]\titers: 2300, epoch: 6 | loss: 0.2873370\n",
      "\tspeed: 0.1327s/iter; left time: 2157.9190s\n",
      "2399it [05:13,  7.54it/s]\titers: 2400, epoch: 6 | loss: 0.2190129\n",
      "\tspeed: 0.1322s/iter; left time: 2137.3461s\n",
      "2499it [05:26,  7.60it/s]\titers: 2500, epoch: 6 | loss: 0.5059695\n",
      "\tspeed: 0.1314s/iter; left time: 2110.3991s\n",
      "2599it [05:40,  7.71it/s]\titers: 2600, epoch: 6 | loss: 0.2571782\n",
      "\tspeed: 0.1326s/iter; left time: 2117.3160s\n",
      "2699it [05:53,  7.68it/s]\titers: 2700, epoch: 6 | loss: 0.3782385\n",
      "\tspeed: 0.1299s/iter; left time: 2060.4116s\n",
      "2799it [06:06,  7.74it/s]\titers: 2800, epoch: 6 | loss: 0.4393087\n",
      "\tspeed: 0.1293s/iter; left time: 2039.2107s\n",
      "2899it [06:19,  7.81it/s]\titers: 2900, epoch: 6 | loss: 0.3307942\n",
      "\tspeed: 0.1328s/iter; left time: 2080.4202s\n",
      "2999it [06:32,  7.82it/s]\titers: 3000, epoch: 6 | loss: 0.3004380\n",
      "\tspeed: 0.1286s/iter; left time: 2002.4571s\n",
      "3099it [06:44,  7.89it/s]\titers: 3100, epoch: 6 | loss: 0.3270711\n",
      "\tspeed: 0.1281s/iter; left time: 1980.8992s\n",
      "3199it [06:58,  7.72it/s]\titers: 3200, epoch: 6 | loss: 0.2833447\n",
      "\tspeed: 0.1312s/iter; left time: 2016.2186s\n",
      "3299it [07:11,  7.88it/s]\titers: 3300, epoch: 6 | loss: 0.1918054\n",
      "\tspeed: 0.1316s/iter; left time: 2008.5078s\n",
      "3399it [07:24,  6.86it/s]\titers: 3400, epoch: 6 | loss: 0.3671283\n",
      "\tspeed: 0.1282s/iter; left time: 1944.1188s\n",
      "3499it [07:36,  7.86it/s]\titers: 3500, epoch: 6 | loss: 0.1911821\n",
      "\tspeed: 0.1285s/iter; left time: 1936.4761s\n",
      "3599it [07:49,  7.76it/s]\titers: 3600, epoch: 6 | loss: 0.3678643\n",
      "\tspeed: 0.1297s/iter; left time: 1940.8470s\n",
      "3699it [08:02,  7.84it/s]\titers: 3700, epoch: 6 | loss: 0.5699005\n",
      "\tspeed: 0.1279s/iter; left time: 1900.6644s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 6 cost time: 484.68526124954224\n",
      "810it [00:48, 16.87it/s]\n",
      "807it [00:48, 16.55it/s]\n",
      "Epoch: 6 | Train Loss: 0.3198384 Vali Loss: 0.3886737 Test Loss: 0.4846429 MAE Loss: 0.4600995\n",
      "lr = 0.0007938947\n",
      "99it [00:13,  7.85it/s]\titers: 100, epoch: 7 | loss: 0.2265851\n",
      "\tspeed: 1.1605s/iter; left time: 17120.6246s\n",
      "199it [00:26,  7.73it/s]\titers: 200, epoch: 7 | loss: 0.2100025\n",
      "\tspeed: 0.1293s/iter; left time: 1895.2212s\n",
      "299it [00:39,  7.86it/s]\titers: 300, epoch: 7 | loss: 0.5523100\n",
      "\tspeed: 0.1285s/iter; left time: 1870.5693s\n",
      "399it [00:52,  7.77it/s]\titers: 400, epoch: 7 | loss: 0.4162106\n",
      "\tspeed: 0.1316s/iter; left time: 1902.3327s\n",
      "499it [01:05,  7.99it/s]\titers: 500, epoch: 7 | loss: 0.3099052\n",
      "\tspeed: 0.1306s/iter; left time: 1874.0942s\n",
      "599it [01:18,  7.78it/s]\titers: 600, epoch: 7 | loss: 0.1792604\n",
      "\tspeed: 0.1275s/iter; left time: 1817.4460s\n",
      "699it [01:31,  7.80it/s]\titers: 700, epoch: 7 | loss: 0.2216137\n",
      "\tspeed: 0.1296s/iter; left time: 1833.6153s\n",
      "799it [01:44,  7.91it/s]\titers: 800, epoch: 7 | loss: 0.4571757\n",
      "\tspeed: 0.1317s/iter; left time: 1850.3749s\n",
      "899it [01:57,  7.67it/s]\titers: 900, epoch: 7 | loss: 0.2167834\n",
      "\tspeed: 0.1290s/iter; left time: 1799.6207s\n",
      "999it [02:10,  7.92it/s]\titers: 1000, epoch: 7 | loss: 0.2711854\n",
      "\tspeed: 0.1281s/iter; left time: 1775.1611s\n",
      "1099it [02:22,  7.81it/s]\titers: 1100, epoch: 7 | loss: 0.3673321\n",
      "\tspeed: 0.1291s/iter; left time: 1774.9210s\n",
      "1199it [02:36,  7.91it/s]\titers: 1200, epoch: 7 | loss: 0.3153488\n",
      "\tspeed: 0.1316s/iter; left time: 1796.4371s\n",
      "1299it [02:49,  7.24it/s]\titers: 1300, epoch: 7 | loss: 0.2096113\n",
      "\tspeed: 0.1301s/iter; left time: 1763.3571s\n",
      "1399it [03:01,  7.94it/s]\titers: 1400, epoch: 7 | loss: 0.5648524\n",
      "\tspeed: 0.1279s/iter; left time: 1720.7785s\n",
      "1499it [03:14,  7.73it/s]\titers: 1500, epoch: 7 | loss: 0.1719721\n",
      "\tspeed: 0.1299s/iter; left time: 1734.2475s\n",
      "1599it [03:28,  7.84it/s]\titers: 1600, epoch: 7 | loss: 0.6261527\n",
      "\tspeed: 0.1316s/iter; left time: 1744.2192s\n",
      "1699it [03:40,  7.70it/s]\titers: 1700, epoch: 7 | loss: 0.4650384\n",
      "\tspeed: 0.1275s/iter; left time: 1677.0732s\n",
      "1799it [03:54,  7.87it/s]\titers: 1800, epoch: 7 | loss: 0.5716541\n",
      "\tspeed: 0.1319s/iter; left time: 1721.9950s\n",
      "1899it [04:07,  7.77it/s]\titers: 1900, epoch: 7 | loss: 0.3695265\n",
      "\tspeed: 0.1319s/iter; left time: 1707.8587s\n",
      "1999it [04:20,  7.81it/s]\titers: 2000, epoch: 7 | loss: 0.4043526\n",
      "\tspeed: 0.1283s/iter; left time: 1648.5378s\n",
      "2099it [04:33,  7.90it/s]\titers: 2100, epoch: 7 | loss: 0.2021791\n",
      "\tspeed: 0.1305s/iter; left time: 1663.7812s\n",
      "2199it [04:46,  7.82it/s]\titers: 2200, epoch: 7 | loss: 0.2972278\n",
      "\tspeed: 0.1320s/iter; left time: 1670.7707s\n",
      "2299it [04:59,  6.82it/s]\titers: 2300, epoch: 7 | loss: 0.3575771\n",
      "\tspeed: 0.1327s/iter; left time: 1665.2835s\n",
      "2399it [05:12,  7.67it/s]\titers: 2400, epoch: 7 | loss: 0.2037572\n",
      "\tspeed: 0.1291s/iter; left time: 1607.7650s\n",
      "2499it [05:25,  7.75it/s]\titers: 2500, epoch: 7 | loss: 0.1965705\n",
      "\tspeed: 0.1315s/iter; left time: 1624.1397s\n",
      "2599it [05:38,  7.47it/s]\titers: 2600, epoch: 7 | loss: 0.3151780\n",
      "\tspeed: 0.1317s/iter; left time: 1613.1828s\n",
      "2699it [05:58,  5.72it/s]\titers: 2700, epoch: 7 | loss: 0.2034536\n",
      "\tspeed: 0.1955s/iter; left time: 2376.5054s\n",
      "2799it [06:14,  7.87it/s]\titers: 2800, epoch: 7 | loss: 0.2483424\n",
      "\tspeed: 0.1607s/iter; left time: 1936.7520s\n",
      "2899it [06:32,  7.50it/s]\titers: 2900, epoch: 7 | loss: 0.2180000\n",
      "\tspeed: 0.1771s/iter; left time: 2117.1396s\n",
      "2999it [06:48,  7.76it/s]\titers: 3000, epoch: 7 | loss: 0.4697379\n",
      "\tspeed: 0.1616s/iter; left time: 1916.0038s\n",
      "3099it [07:06,  4.15it/s]\titers: 3100, epoch: 7 | loss: 0.2891927\n",
      "\tspeed: 0.1776s/iter; left time: 2087.4338s\n",
      "3199it [07:22,  3.66it/s]\titers: 3200, epoch: 7 | loss: 0.2120788\n",
      "\tspeed: 0.1681s/iter; left time: 1959.1010s\n",
      "3299it [07:39,  7.95it/s]\titers: 3300, epoch: 7 | loss: 0.2999848\n",
      "\tspeed: 0.1686s/iter; left time: 1947.7734s\n",
      "3399it [07:55,  8.03it/s]\titers: 3400, epoch: 7 | loss: 0.2691816\n",
      "\tspeed: 0.1602s/iter; left time: 1834.6933s\n",
      "3499it [08:12,  4.37it/s]\titers: 3500, epoch: 7 | loss: 0.1904802\n",
      "\tspeed: 0.1658s/iter; left time: 1882.1558s\n",
      "3599it [08:29,  7.99it/s]\titers: 3600, epoch: 7 | loss: 0.3413115\n",
      "\tspeed: 0.1718s/iter; left time: 1933.1138s\n",
      "3699it [08:47,  7.54it/s]\titers: 3700, epoch: 7 | loss: 0.3261745\n",
      "\tspeed: 0.1767s/iter; left time: 1970.5429s\n",
      "3713it [08:49,  7.02it/s]\n",
      "Epoch: 7 cost time: 529.0069010257721\n",
      "810it [01:03, 12.79it/s]\n",
      "807it [01:03, 12.74it/s]\n",
      "Epoch: 7 | Train Loss: 0.3178822 Vali Loss: 0.4026718 Test Loss: 0.5029341 MAE Loss: 0.4814337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:16,  7.80it/s]\titers: 100, epoch: 8 | loss: 0.1936937\n",
      "\tspeed: 1.4497s/iter; left time: 16004.8470s\n",
      "199it [00:32,  7.90it/s]\titers: 200, epoch: 8 | loss: 0.3481279\n",
      "\tspeed: 0.1602s/iter; left time: 1752.4219s\n",
      "299it [00:50,  5.17it/s]\titers: 300, epoch: 8 | loss: 0.2465445\n",
      "\tspeed: 0.1776s/iter; left time: 1925.0643s\n",
      "399it [01:06,  7.67it/s]\titers: 400, epoch: 8 | loss: 0.3907549\n",
      "\tspeed: 0.1601s/iter; left time: 1719.3119s\n",
      "499it [01:23,  4.24it/s]\titers: 500, epoch: 8 | loss: 0.2190004\n",
      "\tspeed: 0.1766s/iter; left time: 1879.2375s\n",
      "599it [01:39,  7.77it/s]\titers: 600, epoch: 8 | loss: 0.3313726\n",
      "\tspeed: 0.1601s/iter; left time: 1687.7808s\n",
      "699it [01:55,  7.81it/s]\titers: 700, epoch: 8 | loss: 0.5199006\n",
      "\tspeed: 0.1603s/iter; left time: 1673.2073s\n",
      "799it [02:11,  7.69it/s]\titers: 800, epoch: 8 | loss: 0.4603224\n",
      "\tspeed: 0.1615s/iter; left time: 1669.4008s\n",
      "899it [02:29,  7.81it/s]\titers: 900, epoch: 8 | loss: 0.3747466\n",
      "\tspeed: 0.1761s/iter; left time: 1802.9596s\n",
      "999it [02:46,  4.16it/s]\titers: 1000, epoch: 8 | loss: 0.3959230\n",
      "\tspeed: 0.1659s/iter; left time: 1681.7440s\n",
      "1099it [03:03,  7.25it/s]\titers: 1100, epoch: 8 | loss: 0.3026269\n",
      "\tspeed: 0.1708s/iter; left time: 1714.4424s\n",
      "1199it [03:19,  7.93it/s]\titers: 1200, epoch: 8 | loss: 0.2920355\n",
      "\tspeed: 0.1606s/iter; left time: 1596.8015s\n",
      "1299it [03:36,  5.94it/s]\titers: 1300, epoch: 8 | loss: 0.5332096\n",
      "\tspeed: 0.1767s/iter; left time: 1738.8630s\n",
      "1399it [03:52,  7.81it/s]\titers: 1400, epoch: 8 | loss: 0.3614319\n",
      "\tspeed: 0.1597s/iter; left time: 1555.1866s\n",
      "1499it [04:08,  7.90it/s]\titers: 1500, epoch: 8 | loss: 0.1590936\n",
      "\tspeed: 0.1600s/iter; left time: 1542.6985s\n",
      "1599it [04:25,  6.78it/s]\titers: 1600, epoch: 8 | loss: 0.3205967\n",
      "\tspeed: 0.1627s/iter; left time: 1552.0248s\n",
      "1699it [04:42,  7.60it/s]\titers: 1700, epoch: 8 | loss: 0.2919439\n",
      "\tspeed: 0.1761s/iter; left time: 1662.2957s\n",
      "1799it [04:59,  4.31it/s]\titers: 1800, epoch: 8 | loss: 0.1961195\n",
      "\tspeed: 0.1658s/iter; left time: 1548.5392s\n",
      "1899it [05:16,  7.74it/s]\titers: 1900, epoch: 8 | loss: 0.2501426\n",
      "\tspeed: 0.1717s/iter; left time: 1586.8218s\n",
      "1999it [05:32,  7.78it/s]\titers: 2000, epoch: 8 | loss: 0.4652239\n",
      "\tspeed: 0.1607s/iter; left time: 1468.4399s\n",
      "2099it [05:48,  7.85it/s]\titers: 2100, epoch: 8 | loss: 0.3647101\n",
      "\tspeed: 0.1615s/iter; left time: 1460.3492s\n",
      "2199it [06:06,  3.16it/s]\titers: 2200, epoch: 8 | loss: 0.3905986\n",
      "\tspeed: 0.1746s/iter; left time: 1561.3123s\n",
      "2299it [06:22,  7.96it/s]\titers: 2300, epoch: 8 | loss: 0.2619036\n",
      "\tspeed: 0.1612s/iter; left time: 1424.8560s\n",
      "2399it [06:40,  3.16it/s]\titers: 2400, epoch: 8 | loss: 0.2907792\n",
      "\tspeed: 0.1769s/iter; left time: 1546.2383s\n",
      "2499it [06:56,  7.00it/s]\titers: 2500, epoch: 8 | loss: 0.3323463\n",
      "\tspeed: 0.1604s/iter; left time: 1386.1326s\n",
      "2599it [07:12,  7.81it/s]\titers: 2600, epoch: 8 | loss: 0.1633468\n",
      "\tspeed: 0.1601s/iter; left time: 1367.4884s\n",
      "2699it [07:28,  7.80it/s]\titers: 2700, epoch: 8 | loss: 0.3098654\n",
      "\tspeed: 0.1604s/iter; left time: 1353.6409s\n",
      "2799it [07:45,  7.86it/s]\titers: 2800, epoch: 8 | loss: 0.1567122\n",
      "\tspeed: 0.1765s/iter; left time: 1472.2065s\n",
      "2899it [08:01,  7.87it/s]\titers: 2900, epoch: 8 | loss: 0.3251747\n",
      "\tspeed: 0.1606s/iter; left time: 1323.5757s\n",
      "2999it [08:17,  7.84it/s]\titers: 3000, epoch: 8 | loss: 0.3707897\n",
      "\tspeed: 0.1610s/iter; left time: 1310.9310s\n",
      "3099it [08:35,  7.12it/s]\titers: 3100, epoch: 8 | loss: 0.5539950\n",
      "\tspeed: 0.1761s/iter; left time: 1415.7535s\n",
      "3199it [08:51,  7.91it/s]\titers: 3200, epoch: 8 | loss: 0.2189280\n",
      "\tspeed: 0.1599s/iter; left time: 1269.8108s\n",
      "3299it [09:09,  3.17it/s]\titers: 3300, epoch: 8 | loss: 0.4177049\n",
      "\tspeed: 0.1768s/iter; left time: 1385.7510s\n",
      "3399it [09:25,  7.67it/s]\titers: 3400, epoch: 8 | loss: 0.2371941\n",
      "\tspeed: 0.1604s/iter; left time: 1241.7680s\n",
      "3499it [09:41,  7.93it/s]\titers: 3500, epoch: 8 | loss: 0.3518778\n",
      "\tspeed: 0.1600s/iter; left time: 1222.5921s\n",
      "3599it [09:57,  7.89it/s]\titers: 3600, epoch: 8 | loss: 0.2310055\n",
      "\tspeed: 0.1601s/iter; left time: 1207.1333s\n",
      "3699it [10:15,  5.64it/s]\titers: 3700, epoch: 8 | loss: 0.2773418\n",
      "\tspeed: 0.1776s/iter; left time: 1321.5845s\n",
      "3713it [10:16,  6.02it/s]\n",
      "Epoch: 8 cost time: 616.9081826210022\n",
      "810it [01:01, 13.15it/s]\n",
      "807it [01:02, 12.96it/s]\n",
      "Epoch: 8 | Train Loss: 0.3127520 Vali Loss: 0.3726595 Test Loss: 0.4752736 MAE Loss: 0.4556114\n",
      "lr = 0.0006545120\n",
      "99it [00:18,  6.47it/s]\titers: 100, epoch: 9 | loss: 0.2628272\n",
      "\tspeed: 1.4736s/iter; left time: 10797.3625s\n",
      "199it [00:34,  7.90it/s]\titers: 200, epoch: 9 | loss: 0.3388748\n",
      "\tspeed: 0.1599s/iter; left time: 1155.6492s\n",
      "299it [00:50,  7.82it/s]\titers: 300, epoch: 9 | loss: 0.2200371\n",
      "\tspeed: 0.1605s/iter; left time: 1144.1664s\n",
      "399it [01:07,  3.32it/s]\titers: 400, epoch: 9 | loss: 0.2471333\n",
      "\tspeed: 0.1725s/iter; left time: 1212.0049s\n",
      "499it [01:23,  6.52it/s]\titers: 500, epoch: 9 | loss: 0.2086286\n",
      "\tspeed: 0.1645s/iter; left time: 1139.2523s\n",
      "599it [01:39,  8.02it/s]\titers: 600, epoch: 9 | loss: 0.2185426\n",
      "\tspeed: 0.1598s/iter; left time: 1090.9307s\n",
      "699it [01:57,  3.18it/s]\titers: 700, epoch: 9 | loss: 0.2660626\n",
      "\tspeed: 0.1762s/iter; left time: 1185.0198s\n",
      "799it [02:13,  4.69it/s]\titers: 800, epoch: 9 | loss: 0.3809134\n",
      "\tspeed: 0.1616s/iter; left time: 1070.8380s\n",
      "899it [02:29,  7.93it/s]\titers: 900, epoch: 9 | loss: 0.2144846\n",
      "\tspeed: 0.1603s/iter; left time: 1046.2685s\n",
      "999it [02:45,  7.88it/s]\titers: 1000, epoch: 9 | loss: 0.3710669\n",
      "\tspeed: 0.1606s/iter; left time: 1031.9545s\n",
      "1099it [03:03,  7.77it/s]\titers: 1100, epoch: 9 | loss: 0.3881444\n",
      "\tspeed: 0.1768s/iter; left time: 1118.6652s\n",
      "1199it [03:19,  7.96it/s]\titers: 1200, epoch: 9 | loss: 0.1951334\n",
      "\tspeed: 0.1610s/iter; left time: 1002.4101s\n",
      "1299it [03:35,  7.83it/s]\titers: 1300, epoch: 9 | loss: 0.1992106\n",
      "\tspeed: 0.1604s/iter; left time: 982.7264s\n",
      "1399it [03:51,  4.55it/s]\titers: 1400, epoch: 9 | loss: 0.3933530\n",
      "\tspeed: 0.1647s/iter; left time: 992.3875s\n",
      "1499it [04:09,  4.44it/s]\titers: 1500, epoch: 9 | loss: 0.4240173\n",
      "\tspeed: 0.1723s/iter; left time: 1021.4244s\n",
      "1599it [04:25,  7.88it/s]\titers: 1600, epoch: 9 | loss: 0.2480144\n",
      "\tspeed: 0.1599s/iter; left time: 931.6150s\n",
      "1699it [04:41,  7.93it/s]\titers: 1700, epoch: 9 | loss: 0.2983743\n",
      "\tspeed: 0.1609s/iter; left time: 921.5593s\n",
      "1799it [04:58,  3.26it/s]\titers: 1800, epoch: 9 | loss: 0.3400280\n",
      "\tspeed: 0.1747s/iter; left time: 982.7688s\n",
      "1899it [05:15,  7.76it/s]\titers: 1900, epoch: 9 | loss: 0.1634814\n",
      "\tspeed: 0.1638s/iter; left time: 905.1555s\n",
      "1999it [05:31,  7.89it/s]\titers: 2000, epoch: 9 | loss: 0.4274901\n",
      "\tspeed: 0.1613s/iter; left time: 875.3299s\n",
      "2099it [05:47,  7.90it/s]\titers: 2100, epoch: 9 | loss: 0.2724287\n",
      "\tspeed: 0.1603s/iter; left time: 854.0704s\n",
      "2199it [06:04,  4.54it/s]\titers: 2200, epoch: 9 | loss: 0.3248950\n",
      "\tspeed: 0.1767s/iter; left time: 923.8101s\n",
      "2299it [06:20,  7.84it/s]\titers: 2300, epoch: 9 | loss: 0.5053042\n",
      "\tspeed: 0.1598s/iter; left time: 819.4681s\n",
      "2399it [06:37,  3.54it/s]\titers: 2400, epoch: 9 | loss: 0.2094833\n",
      "\tspeed: 0.1699s/iter; left time: 854.1963s\n",
      "2499it [06:54,  7.71it/s]\titers: 2500, epoch: 9 | loss: 0.2380140\n",
      "\tspeed: 0.1689s/iter; left time: 832.0038s\n",
      "2599it [07:10,  7.89it/s]\titers: 2600, epoch: 9 | loss: 0.2187919\n",
      "\tspeed: 0.1601s/iter; left time: 772.6694s\n",
      "2699it [07:26,  7.91it/s]\titers: 2700, epoch: 9 | loss: 0.1760520\n",
      "\tspeed: 0.1605s/iter; left time: 758.7391s\n",
      "2799it [07:44,  3.22it/s]\titers: 2800, epoch: 9 | loss: 0.4936087\n",
      "\tspeed: 0.1745s/iter; left time: 807.3472s\n",
      "2899it [08:00,  7.88it/s]\titers: 2900, epoch: 9 | loss: 0.3552023\n",
      "\tspeed: 0.1629s/iter; left time: 737.5330s\n",
      "2999it [08:18,  3.25it/s]\titers: 3000, epoch: 9 | loss: 0.3080100\n",
      "\tspeed: 0.1766s/iter; left time: 781.6089s\n",
      "3099it [08:34,  7.35it/s]\titers: 3100, epoch: 9 | loss: 0.3906256\n",
      "\tspeed: 0.1619s/iter; left time: 700.3686s\n",
      "3199it [08:50,  7.67it/s]\titers: 3200, epoch: 9 | loss: 0.3656609\n",
      "\tspeed: 0.1599s/iter; left time: 675.7984s\n",
      "3299it [09:06,  7.89it/s]\titers: 3300, epoch: 9 | loss: 0.3032006\n",
      "\tspeed: 0.1606s/iter; left time: 662.8936s\n",
      "3399it [09:23,  3.24it/s]\titers: 3400, epoch: 9 | loss: 0.3217273\n",
      "\tspeed: 0.1744s/iter; left time: 702.2125s\n",
      "3499it [09:40,  8.06it/s]\titers: 3500, epoch: 9 | loss: 0.2078187\n",
      "\tspeed: 0.1625s/iter; left time: 638.0813s\n",
      "3599it [09:56,  7.86it/s]\titers: 3600, epoch: 9 | loss: 0.2604896\n",
      "\tspeed: 0.1602s/iter; left time: 613.1821s\n",
      "3699it [10:12,  7.92it/s]\titers: 3700, epoch: 9 | loss: 0.3178231\n",
      "\tspeed: 0.1604s/iter; left time: 597.9816s\n",
      "3713it [10:14,  6.04it/s]\n",
      "Epoch: 9 cost time: 614.6166231632233\n",
      "810it [01:02, 12.93it/s]\n",
      "807it [01:02, 12.97it/s]\n",
      "Epoch: 9 | Train Loss: 0.3058381 Vali Loss: 0.3785458 Test Loss: 0.4643720 MAE Loss: 0.4581837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:16,  7.88it/s]\titers: 100, epoch: 10 | loss: 0.2262759\n",
      "\tspeed: 1.4374s/iter; left time: 5194.7168s\n",
      "199it [00:34,  7.65it/s]\titers: 200, epoch: 10 | loss: 0.4223031\n",
      "\tspeed: 0.1772s/iter; left time: 622.6074s\n",
      "299it [00:50,  7.90it/s]\titers: 300, epoch: 10 | loss: 0.3500025\n",
      "\tspeed: 0.1619s/iter; left time: 552.5803s\n",
      "399it [01:06,  7.74it/s]\titers: 400, epoch: 10 | loss: 0.2686449\n",
      "\tspeed: 0.1622s/iter; left time: 537.4179s\n",
      "499it [01:23,  3.32it/s]\titers: 500, epoch: 10 | loss: 0.3244149\n",
      "\tspeed: 0.1743s/iter; left time: 560.1771s\n",
      "599it [01:40,  7.83it/s]\titers: 600, epoch: 10 | loss: 0.2174947\n",
      "\tspeed: 0.1645s/iter; left time: 512.2369s\n",
      "699it [01:56,  7.76it/s]\titers: 700, epoch: 10 | loss: 0.2414598\n",
      "\tspeed: 0.1619s/iter; left time: 487.8523s\n",
      "799it [02:14,  7.55it/s]\titers: 800, epoch: 10 | loss: 0.2375075\n",
      "\tspeed: 0.1784s/iter; left time: 519.7394s\n",
      "899it [02:30,  7.85it/s]\titers: 900, epoch: 10 | loss: 0.3952787\n",
      "\tspeed: 0.1609s/iter; left time: 452.7128s\n",
      "999it [02:46,  7.68it/s]\titers: 1000, epoch: 10 | loss: 0.3944128\n",
      "\tspeed: 0.1614s/iter; left time: 438.0993s\n",
      "1099it [03:02,  7.81it/s]\titers: 1100, epoch: 10 | loss: 0.1583472\n",
      "\tspeed: 0.1615s/iter; left time: 422.1788s\n",
      "1199it [03:20,  7.76it/s]\titers: 1200, epoch: 10 | loss: 0.3862383\n",
      "\tspeed: 0.1780s/iter; left time: 447.5933s\n",
      "1299it [03:37,  4.21it/s]\titers: 1300, epoch: 10 | loss: 0.2872093\n",
      "\tspeed: 0.1675s/iter; left time: 404.3623s\n",
      "1399it [03:54,  6.80it/s]\titers: 1400, epoch: 10 | loss: 0.3244129\n",
      "\tspeed: 0.1722s/iter; left time: 398.5571s\n",
      "1499it [04:10,  7.64it/s]\titers: 1500, epoch: 10 | loss: 0.6322581\n",
      "\tspeed: 0.1610s/iter; left time: 356.4014s\n",
      "1599it [04:26,  7.81it/s]\titers: 1600, epoch: 10 | loss: 0.3227021\n",
      "\tspeed: 0.1604s/iter; left time: 339.0974s\n",
      "1699it [04:44,  5.54it/s]\titers: 1700, epoch: 10 | loss: 0.1612948\n",
      "\tspeed: 0.1782s/iter; left time: 358.9472s\n",
      "1799it [05:00,  7.81it/s]\titers: 1800, epoch: 10 | loss: 0.5255820\n",
      "\tspeed: 0.1616s/iter; left time: 309.2098s\n",
      "1899it [05:16,  6.72it/s]\titers: 1900, epoch: 10 | loss: 0.4663216\n",
      "\tspeed: 0.1633s/iter; left time: 296.2506s\n",
      "1999it [05:33,  6.45it/s]\titers: 2000, epoch: 10 | loss: 0.2521797\n",
      "\tspeed: 0.1617s/iter; left time: 277.1406s\n",
      "2099it [05:50,  7.83it/s]\titers: 2100, epoch: 10 | loss: 0.3337621\n",
      "\tspeed: 0.1757s/iter; left time: 283.5797s\n",
      "2199it [06:06,  6.79it/s]\titers: 2200, epoch: 10 | loss: 0.4249370\n",
      "\tspeed: 0.1625s/iter; left time: 245.9759s\n",
      "2299it [06:24,  8.00it/s]\titers: 2300, epoch: 10 | loss: 0.2716905\n",
      "\tspeed: 0.1754s/iter; left time: 248.0646s\n",
      "2399it [06:40,  7.92it/s]\titers: 2400, epoch: 10 | loss: 0.2343171\n",
      "\tspeed: 0.1612s/iter; left time: 211.8517s\n",
      "2499it [06:56,  7.76it/s]\titers: 2500, epoch: 10 | loss: 0.2048771\n",
      "\tspeed: 0.1619s/iter; left time: 196.6038s\n",
      "2599it [07:14,  7.74it/s]\titers: 2600, epoch: 10 | loss: 0.7223256\n",
      "\tspeed: 0.1777s/iter; left time: 197.9930s\n",
      "2699it [07:30,  7.78it/s]\titers: 2700, epoch: 10 | loss: 0.2624083\n",
      "\tspeed: 0.1612s/iter; left time: 163.4652s\n",
      "2799it [07:48,  3.66it/s]\titers: 2800, epoch: 10 | loss: 0.2136997\n",
      "\tspeed: 0.1784s/iter; left time: 163.0185s\n",
      "2899it [08:04,  6.68it/s]\titers: 2900, epoch: 10 | loss: 0.3243578\n",
      "\tspeed: 0.1619s/iter; left time: 131.7625s\n",
      "2999it [08:20,  7.90it/s]\titers: 3000, epoch: 10 | loss: 0.2444431\n",
      "\tspeed: 0.1605s/iter; left time: 114.6203s\n",
      "3099it [08:37,  3.70it/s]\titers: 3100, epoch: 10 | loss: 0.5657013\n",
      "\tspeed: 0.1695s/iter; left time: 104.0767s\n",
      "3199it [08:54,  6.83it/s]\titers: 3200, epoch: 10 | loss: 0.1933448\n",
      "\tspeed: 0.1704s/iter; left time: 87.5894s\n",
      "3299it [09:10,  7.76it/s]\titers: 3300, epoch: 10 | loss: 0.4643233\n",
      "\tspeed: 0.1614s/iter; left time: 66.8053s\n",
      "3399it [09:27,  6.78it/s]\titers: 3400, epoch: 10 | loss: 0.2606220\n",
      "\tspeed: 0.1627s/iter; left time: 51.0721s\n",
      "3499it [09:44,  6.71it/s]\titers: 3500, epoch: 10 | loss: 0.3533718\n",
      "\tspeed: 0.1744s/iter; left time: 37.3228s\n",
      "3599it [10:00,  6.40it/s]\titers: 3600, epoch: 10 | loss: 0.1801219\n",
      "\tspeed: 0.1638s/iter; left time: 18.6722s\n",
      "3699it [10:18,  6.00it/s]\titers: 3700, epoch: 10 | loss: 0.1827157\n",
      "\tspeed: 0.1758s/iter; left time: 2.4617s\n",
      "3713it [10:20,  5.98it/s]\n",
      "Epoch: 10 cost time: 620.4689009189606\n",
      "810it [01:02, 12.93it/s]\n",
      "807it [01:01, 13.04it/s]\n",
      "Epoch: 10 | Train Loss: 0.3102723 Vali Loss: 0.3692426 Test Loss: 0.4556622 MAE Loss: 0.4397559\n",
      "lr = 0.0005000050\n",
      "Total time: 106.95236794948578 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 16:16:17,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 16:16:18,175] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 16:16:18,175] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 16:16:18,175] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 16:16:19,121] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 16:16:19,121] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 16:16:20,439] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 16:16:20,440] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 16:16:20,440] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 16:16:20,441] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 16:16:20,441] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 16:16:20,441] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 16:16:20,765] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 16:16:20,765] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:20,766] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.73 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.73 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:20,895] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 16:16:21,024] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 16:16:21,025] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:21,025] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.78 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 16:16:21,026] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f32921e4fd0>\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.74it/s]\titers: 100, epoch: 1 | loss: 0.6284837\n",
      "\tspeed: 0.1876s/iter; left time: 13915.7058s\n",
      "199it [00:27,  7.41it/s]\titers: 200, epoch: 1 | loss: 0.5352426\n",
      "\tspeed: 0.1343s/iter; left time: 9947.9736s\n",
      "299it [00:41,  7.67it/s]\titers: 300, epoch: 1 | loss: 0.4914316\n",
      "\tspeed: 0.1336s/iter; left time: 9880.1304s\n",
      "399it [00:54,  7.43it/s]\titers: 400, epoch: 1 | loss: 0.2820175\n",
      "\tspeed: 0.1337s/iter; left time: 9874.2349s\n",
      "499it [01:08,  7.34it/s]\titers: 500, epoch: 1 | loss: 0.2728907\n",
      "\tspeed: 0.1356s/iter; left time: 10000.4083s\n",
      "599it [01:21,  6.21it/s]\titers: 600, epoch: 1 | loss: 0.3732491\n",
      "\tspeed: 0.1360s/iter; left time: 10015.1694s\n",
      "699it [01:35,  7.25it/s]\titers: 700, epoch: 1 | loss: 0.4083984\n",
      "\tspeed: 0.1348s/iter; left time: 9917.8573s\n",
      "799it [01:48,  7.55it/s]\titers: 800, epoch: 1 | loss: 0.2888259\n",
      "\tspeed: 0.1361s/iter; left time: 9996.9018s\n",
      "899it [02:02,  6.72it/s]\titers: 900, epoch: 1 | loss: 0.4882275\n",
      "\tspeed: 0.1370s/iter; left time: 10048.0103s\n",
      "999it [02:15,  6.58it/s]\titers: 1000, epoch: 1 | loss: 0.4720700\n",
      "\tspeed: 0.1349s/iter; left time: 9880.6875s\n",
      "1099it [02:29,  7.26it/s]\titers: 1100, epoch: 1 | loss: 0.2710172\n",
      "\tspeed: 0.1366s/iter; left time: 9996.8565s\n",
      "1199it [02:43,  7.65it/s]\titers: 1200, epoch: 1 | loss: 0.3366533\n",
      "\tspeed: 0.1362s/iter; left time: 9948.7259s\n",
      "1299it [02:56,  7.18it/s]\titers: 1300, epoch: 1 | loss: 0.4391926\n",
      "\tspeed: 0.1335s/iter; left time: 9742.0886s\n",
      "1399it [03:09,  7.69it/s]\titers: 1400, epoch: 1 | loss: 0.2492006\n",
      "\tspeed: 0.1317s/iter; left time: 9596.5261s\n",
      "1499it [03:23,  7.59it/s]\titers: 1500, epoch: 1 | loss: 0.2428142\n",
      "\tspeed: 0.1356s/iter; left time: 9864.3843s\n",
      "1599it [03:36,  7.52it/s]\titers: 1600, epoch: 1 | loss: 0.4292324\n",
      "\tspeed: 0.1347s/iter; left time: 9790.6208s\n",
      "1699it [03:50,  7.53it/s]\titers: 1700, epoch: 1 | loss: 0.4312639\n",
      "\tspeed: 0.1338s/iter; left time: 9711.9058s\n",
      "1799it [04:03,  7.47it/s]\titers: 1800, epoch: 1 | loss: 0.6051976\n",
      "\tspeed: 0.1339s/iter; left time: 9703.7280s\n",
      "1899it [04:17,  7.68it/s]\titers: 1900, epoch: 1 | loss: 0.2817806\n",
      "\tspeed: 0.1366s/iter; left time: 9886.5703s\n",
      "1999it [04:30,  7.52it/s]\titers: 2000, epoch: 1 | loss: 0.3776010\n",
      "\tspeed: 0.1361s/iter; left time: 9834.5234s\n",
      "2099it [04:44,  6.98it/s]\titers: 2100, epoch: 1 | loss: 0.2727109\n",
      "\tspeed: 0.1354s/iter; left time: 9772.2686s\n",
      "2199it [04:58,  7.57it/s]\titers: 2200, epoch: 1 | loss: 0.4344987\n",
      "\tspeed: 0.1376s/iter; left time: 9912.8875s\n",
      "2299it [05:11,  7.70it/s]\titers: 2300, epoch: 1 | loss: 0.4113905\n",
      "\tspeed: 0.1360s/iter; left time: 9789.4647s\n",
      "2399it [05:24,  7.68it/s]\titers: 2400, epoch: 1 | loss: 0.2870833\n",
      "\tspeed: 0.1320s/iter; left time: 9482.6861s\n",
      "2499it [05:38,  7.67it/s]\titers: 2500, epoch: 1 | loss: 0.3584269\n",
      "\tspeed: 0.1306s/iter; left time: 9372.8803s\n",
      "2599it [05:51,  7.60it/s]\titers: 2600, epoch: 1 | loss: 0.2931449\n",
      "\tspeed: 0.1324s/iter; left time: 9486.9149s\n",
      "2699it [06:05,  7.69it/s]\titers: 2700, epoch: 1 | loss: 0.3084987\n",
      "\tspeed: 0.1373s/iter; left time: 9826.7383s\n",
      "2799it [06:18,  7.37it/s]\titers: 2800, epoch: 1 | loss: 0.3998558\n",
      "\tspeed: 0.1339s/iter; left time: 9565.4951s\n",
      "2899it [06:31,  7.62it/s]\titers: 2900, epoch: 1 | loss: 0.2582986\n",
      "\tspeed: 0.1308s/iter; left time: 9334.5554s\n",
      "2999it [06:45,  7.31it/s]\titers: 3000, epoch: 1 | loss: 0.3260675\n",
      "\tspeed: 0.1381s/iter; left time: 9838.7775s\n",
      "3099it [06:59,  7.34it/s]\titers: 3100, epoch: 1 | loss: 0.2262339\n",
      "\tspeed: 0.1382s/iter; left time: 9831.0693s\n",
      "3199it [07:12,  6.60it/s]\titers: 3200, epoch: 1 | loss: 0.2288827\n",
      "\tspeed: 0.1349s/iter; left time: 9585.7569s\n",
      "3299it [07:25,  7.53it/s]\titers: 3300, epoch: 1 | loss: 0.4653212\n",
      "\tspeed: 0.1331s/iter; left time: 9443.4561s\n",
      "3399it [07:39,  7.60it/s]\titers: 3400, epoch: 1 | loss: 0.5665098\n",
      "\tspeed: 0.1357s/iter; left time: 9614.1041s\n",
      "3499it [07:53,  7.68it/s]\titers: 3500, epoch: 1 | loss: 0.3672006\n",
      "\tspeed: 0.1385s/iter; left time: 9801.5900s\n",
      "3599it [08:06,  7.45it/s]\titers: 3600, epoch: 1 | loss: 0.2720945\n",
      "\tspeed: 0.1342s/iter; left time: 9480.4788s\n",
      "3699it [08:19,  7.27it/s]\titers: 3700, epoch: 1 | loss: 0.2639223\n",
      "\tspeed: 0.1324s/iter; left time: 9339.1803s\n",
      "3713it [08:22,  7.40it/s]\n",
      "Epoch: 1 cost time: 502.0084307193756\n",
      "810it [00:52, 15.44it/s]\n",
      "807it [00:52, 15.45it/s]\n",
      "Epoch: 1 | Train Loss: 0.3539966 Vali Loss: 0.4033258 Test Loss: 0.5074162 MAE Loss: 0.4763052\n",
      "lr = 0.0009938442\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 2 | loss: 0.3767157\n",
      "\tspeed: 1.2354s/iter; left time: 87031.8176s\n",
      "199it [00:26,  7.85it/s]\titers: 200, epoch: 2 | loss: 0.4751770\n",
      "\tspeed: 0.1316s/iter; left time: 9256.6548s\n",
      "299it [00:39,  7.73it/s]\titers: 300, epoch: 2 | loss: 0.4254152\n",
      "\tspeed: 0.1290s/iter; left time: 9064.9641s\n",
      "399it [00:52,  7.67it/s]\titers: 400, epoch: 2 | loss: 0.6282481\n",
      "\tspeed: 0.1332s/iter; left time: 9342.7318s\n",
      "499it [01:05,  7.97it/s]\titers: 500, epoch: 2 | loss: 0.2911870\n",
      "\tspeed: 0.1269s/iter; left time: 8888.6148s\n",
      "599it [01:18,  7.58it/s]\titers: 600, epoch: 2 | loss: 0.4708160\n",
      "\tspeed: 0.1299s/iter; left time: 9087.4770s\n",
      "699it [01:31,  7.83it/s]\titers: 700, epoch: 2 | loss: 0.3043123\n",
      "\tspeed: 0.1324s/iter; left time: 9249.2041s\n",
      "799it [01:45,  7.93it/s]\titers: 800, epoch: 2 | loss: 0.4478506\n",
      "\tspeed: 0.1348s/iter; left time: 9404.4022s\n",
      "899it [01:57,  7.97it/s]\titers: 900, epoch: 2 | loss: 0.3069436\n",
      "\tspeed: 0.1269s/iter; left time: 8840.5351s\n",
      "999it [02:11,  7.77it/s]\titers: 1000, epoch: 2 | loss: 0.3549146\n",
      "\tspeed: 0.1310s/iter; left time: 9113.6516s\n",
      "1099it [02:24,  7.71it/s]\titers: 1100, epoch: 2 | loss: 0.3372775\n",
      "\tspeed: 0.1324s/iter; left time: 9192.5102s\n",
      "1199it [02:37,  6.40it/s]\titers: 1200, epoch: 2 | loss: 0.5666034\n",
      "\tspeed: 0.1324s/iter; left time: 9184.4587s\n",
      "1299it [02:50,  7.79it/s]\titers: 1300, epoch: 2 | loss: 0.2821845\n",
      "\tspeed: 0.1305s/iter; left time: 9039.8004s\n",
      "1399it [03:03,  7.75it/s]\titers: 1400, epoch: 2 | loss: 0.2186523\n",
      "\tspeed: 0.1331s/iter; left time: 9203.5185s\n",
      "1499it [03:17,  7.75it/s]\titers: 1500, epoch: 2 | loss: 0.6387949\n",
      "\tspeed: 0.1340s/iter; left time: 9252.3968s\n",
      "1599it [03:30,  7.17it/s]\titers: 1600, epoch: 2 | loss: 0.3126513\n",
      "\tspeed: 0.1293s/iter; left time: 8916.6711s\n",
      "1699it [03:43,  7.99it/s]\titers: 1700, epoch: 2 | loss: 0.4256271\n",
      "\tspeed: 0.1298s/iter; left time: 8938.4403s\n",
      "1799it [03:56,  7.81it/s]\titers: 1800, epoch: 2 | loss: 0.2084496\n",
      "\tspeed: 0.1307s/iter; left time: 8984.3558s\n",
      "1899it [04:09,  7.77it/s]\titers: 1900, epoch: 2 | loss: 0.3614881\n",
      "\tspeed: 0.1323s/iter; left time: 9082.5856s\n",
      "1999it [04:22,  7.99it/s]\titers: 2000, epoch: 2 | loss: 0.2827127\n",
      "\tspeed: 0.1271s/iter; left time: 8709.2345s\n",
      "2099it [04:35,  7.87it/s]\titers: 2100, epoch: 2 | loss: 0.4691244\n",
      "\tspeed: 0.1321s/iter; left time: 9041.1273s\n",
      "2199it [04:48,  8.05it/s]\titers: 2200, epoch: 2 | loss: 0.4235355\n",
      "\tspeed: 0.1309s/iter; left time: 8948.4373s\n",
      "2299it [05:01,  6.64it/s]\titers: 2300, epoch: 2 | loss: 0.3109887\n",
      "\tspeed: 0.1309s/iter; left time: 8931.5205s\n",
      "2399it [05:14,  7.88it/s]\titers: 2400, epoch: 2 | loss: 0.5009397\n",
      "\tspeed: 0.1284s/iter; left time: 8746.8135s\n",
      "2499it [05:27,  7.90it/s]\titers: 2500, epoch: 2 | loss: 0.2803027\n",
      "\tspeed: 0.1278s/iter; left time: 8698.1500s\n",
      "2599it [05:39,  7.96it/s]\titers: 2600, epoch: 2 | loss: 0.3870358\n",
      "\tspeed: 0.1268s/iter; left time: 8615.2595s\n",
      "2699it [05:52,  7.92it/s]\titers: 2700, epoch: 2 | loss: 0.2980010\n",
      "\tspeed: 0.1270s/iter; left time: 8617.2763s\n",
      "2799it [06:05,  8.03it/s]\titers: 2800, epoch: 2 | loss: 0.4731279\n",
      "\tspeed: 0.1276s/iter; left time: 8644.1447s\n",
      "2899it [06:17,  7.88it/s]\titers: 2900, epoch: 2 | loss: 0.3358819\n",
      "\tspeed: 0.1252s/iter; left time: 8467.8203s\n",
      "2999it [06:30,  7.93it/s]\titers: 3000, epoch: 2 | loss: 0.2284171\n",
      "\tspeed: 0.1288s/iter; left time: 8697.1577s\n",
      "3099it [06:43,  7.96it/s]\titers: 3100, epoch: 2 | loss: 0.3610570\n",
      "\tspeed: 0.1283s/iter; left time: 8652.1581s\n",
      "3199it [06:56,  7.57it/s]\titers: 3200, epoch: 2 | loss: 0.3276180\n",
      "\tspeed: 0.1316s/iter; left time: 8862.7783s\n",
      "3299it [07:09,  7.66it/s]\titers: 3300, epoch: 2 | loss: 0.2031095\n",
      "\tspeed: 0.1294s/iter; left time: 8703.4038s\n",
      "3399it [07:22,  7.71it/s]\titers: 3400, epoch: 2 | loss: 0.2928004\n",
      "\tspeed: 0.1336s/iter; left time: 8969.3977s\n",
      "3499it [07:36,  7.85it/s]\titers: 3500, epoch: 2 | loss: 0.3029553\n",
      "\tspeed: 0.1327s/iter; left time: 8899.8084s\n",
      "3599it [07:49,  7.24it/s]\titers: 3600, epoch: 2 | loss: 0.2909013\n",
      "\tspeed: 0.1296s/iter; left time: 8676.4067s\n",
      "3699it [08:02,  7.70it/s]\titers: 3700, epoch: 2 | loss: 0.1638605\n",
      "\tspeed: 0.1294s/iter; left time: 8650.1459s\n",
      "3713it [08:04,  7.67it/s]\n",
      "Epoch: 2 cost time: 484.02700996398926\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:48, 16.56it/s]\n",
      "Epoch: 2 | Train Loss: 0.3426453 Vali Loss: 0.4419988 Test Loss: 0.5359442 MAE Loss: 0.4935539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:18,  6.85it/s]\titers: 100, epoch: 3 | loss: 0.5224727\n",
      "\tspeed: 1.1759s/iter; left time: 78471.1245s\n",
      "199it [00:35,  7.05it/s]\titers: 200, epoch: 3 | loss: 0.2085290\n",
      "\tspeed: 0.1765s/iter; left time: 11760.4065s\n",
      "299it [00:51,  7.92it/s]\titers: 300, epoch: 3 | loss: 0.3238280\n",
      "\tspeed: 0.1599s/iter; left time: 10638.3345s\n",
      "399it [01:09,  3.34it/s]\titers: 400, epoch: 3 | loss: 0.6686686\n",
      "\tspeed: 0.1750s/iter; left time: 11628.7958s\n",
      "499it [01:25,  7.93it/s]\titers: 500, epoch: 3 | loss: 0.3294648\n",
      "\tspeed: 0.1660s/iter; left time: 11010.4714s\n",
      "599it [01:43,  7.66it/s]\titers: 600, epoch: 3 | loss: 0.3629559\n",
      "\tspeed: 0.1771s/iter; left time: 11729.1922s\n",
      "699it [02:01,  5.33it/s]\titers: 700, epoch: 3 | loss: 0.3475680\n",
      "\tspeed: 0.1786s/iter; left time: 11813.5674s\n",
      "799it [02:17,  6.82it/s]\titers: 800, epoch: 3 | loss: 1.0025202\n",
      "\tspeed: 0.1620s/iter; left time: 10695.7079s\n",
      "899it [02:33,  7.83it/s]\titers: 900, epoch: 3 | loss: 0.5751390\n",
      "\tspeed: 0.1618s/iter; left time: 10669.4735s\n",
      "999it [02:51,  7.69it/s]\titers: 1000, epoch: 3 | loss: 0.3736329\n",
      "\tspeed: 0.1779s/iter; left time: 11711.1436s\n",
      "1099it [03:09,  6.92it/s]\titers: 1100, epoch: 3 | loss: 0.2845280\n",
      "\tspeed: 0.1777s/iter; left time: 11678.9447s\n",
      "1199it [03:25,  7.81it/s]\titers: 1200, epoch: 3 | loss: 0.2719593\n",
      "\tspeed: 0.1610s/iter; left time: 10567.4903s\n",
      "1299it [03:41,  7.76it/s]\titers: 1300, epoch: 3 | loss: 0.2924204\n",
      "\tspeed: 0.1615s/iter; left time: 10585.9738s\n",
      "1399it [03:59,  3.18it/s]\titers: 1400, epoch: 3 | loss: 0.4612133\n",
      "\tspeed: 0.1780s/iter; left time: 11646.2157s\n",
      "1499it [04:17,  4.33it/s]\titers: 1500, epoch: 3 | loss: 0.1913575\n",
      "\tspeed: 0.1789s/iter; left time: 11685.1920s\n",
      "1599it [04:33,  7.88it/s]\titers: 1600, epoch: 3 | loss: 0.7234213\n",
      "\tspeed: 0.1601s/iter; left time: 10442.6105s\n",
      "1699it [04:49,  7.98it/s]\titers: 1700, epoch: 3 | loss: 0.4735206\n",
      "\tspeed: 0.1597s/iter; left time: 10401.0815s\n",
      "1799it [05:06,  3.34it/s]\titers: 1800, epoch: 3 | loss: 0.2808116\n",
      "\tspeed: 0.1726s/iter; left time: 11223.3976s\n",
      "1899it [05:23,  5.19it/s]\titers: 1900, epoch: 3 | loss: 0.3126731\n",
      "\tspeed: 0.1665s/iter; left time: 10811.8993s\n",
      "1999it [05:40,  7.85it/s]\titers: 2000, epoch: 3 | loss: 0.2936290\n",
      "\tspeed: 0.1723s/iter; left time: 11169.8051s\n",
      "2099it [05:56,  7.98it/s]\titers: 2100, epoch: 3 | loss: 0.3481406\n",
      "\tspeed: 0.1601s/iter; left time: 10361.0314s\n",
      "2199it [06:12,  7.02it/s]\titers: 2200, epoch: 3 | loss: 0.2055496\n",
      "\tspeed: 0.1620s/iter; left time: 10471.4823s\n",
      "2299it [06:29,  3.39it/s]\titers: 2300, epoch: 3 | loss: 0.2287608\n",
      "\tspeed: 0.1691s/iter; left time: 10914.8780s\n",
      "2399it [06:46,  7.65it/s]\titers: 2400, epoch: 3 | loss: 0.2860211\n",
      "\tspeed: 0.1638s/iter; left time: 10555.2478s\n",
      "2499it [07:03,  4.61it/s]\titers: 2500, epoch: 3 | loss: 0.3091559\n",
      "\tspeed: 0.1795s/iter; left time: 11547.5902s\n",
      "2599it [07:19,  7.73it/s]\titers: 2600, epoch: 3 | loss: 0.3608786\n",
      "\tspeed: 0.1592s/iter; left time: 10224.3207s\n",
      "2699it [07:35,  7.99it/s]\titers: 2700, epoch: 3 | loss: 0.2663588\n",
      "\tspeed: 0.1596s/iter; left time: 10237.0679s\n",
      "2799it [07:53,  3.22it/s]\titers: 2800, epoch: 3 | loss: 0.3184358\n",
      "\tspeed: 0.1756s/iter; left time: 11244.9298s\n",
      "2899it [08:09,  7.89it/s]\titers: 2900, epoch: 3 | loss: 0.2107174\n",
      "\tspeed: 0.1598s/iter; left time: 10217.5892s\n",
      "2999it [08:26,  3.25it/s]\titers: 3000, epoch: 3 | loss: 0.3653926\n",
      "\tspeed: 0.1737s/iter; left time: 11087.9408s\n",
      "3099it [08:43,  7.78it/s]\titers: 3100, epoch: 3 | loss: 0.3442631\n",
      "\tspeed: 0.1626s/iter; left time: 10365.8649s\n",
      "3199it [09:00,  3.57it/s]\titers: 3200, epoch: 3 | loss: 0.2078412\n",
      "\tspeed: 0.1714s/iter; left time: 10904.0258s\n",
      "3299it [09:16,  8.00it/s]\titers: 3300, epoch: 3 | loss: 0.2802461\n",
      "\tspeed: 0.1643s/iter; left time: 10441.6303s\n",
      "3399it [09:32,  7.93it/s]\titers: 3400, epoch: 3 | loss: 0.3181832\n",
      "\tspeed: 0.1590s/iter; left time: 10087.2003s\n",
      "3499it [09:48,  7.93it/s]\titers: 3500, epoch: 3 | loss: 0.3222934\n",
      "\tspeed: 0.1590s/iter; left time: 10067.3045s\n",
      "3599it [10:06,  7.14it/s]\titers: 3600, epoch: 3 | loss: 0.1407734\n",
      "\tspeed: 0.1765s/iter; left time: 11162.1196s\n",
      "3699it [10:22,  4.85it/s]\titers: 3700, epoch: 3 | loss: 0.6066621\n",
      "\tspeed: 0.1642s/iter; left time: 10364.7122s\n",
      "3713it [10:25,  5.94it/s]\n",
      "Epoch: 3 cost time: 625.6101150512695\n",
      "810it [01:02, 12.94it/s]\n",
      "807it [01:03, 12.79it/s]\n",
      "Epoch: 3 | Train Loss: 0.3307373 Vali Loss: 0.4145984 Test Loss: 0.5158148 MAE Loss: 0.4856396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:16,  7.91it/s]\titers: 100, epoch: 4 | loss: 0.3085895\n",
      "\tspeed: 1.4526s/iter; left time: 91542.8712s\n",
      "199it [00:34,  3.17it/s]\titers: 200, epoch: 4 | loss: 0.3190602\n",
      "\tspeed: 0.1768s/iter; left time: 11125.0141s\n",
      "299it [00:50,  7.72it/s]\titers: 300, epoch: 4 | loss: 0.3972897\n",
      "\tspeed: 0.1613s/iter; left time: 10133.4762s\n",
      "399it [01:06,  7.72it/s]\titers: 400, epoch: 4 | loss: 0.6874273\n",
      "\tspeed: 0.1601s/iter; left time: 10040.4261s\n",
      "499it [01:22,  7.80it/s]\titers: 500, epoch: 4 | loss: 0.1665531\n",
      "\tspeed: 0.1605s/iter; left time: 10051.9121s\n",
      "599it [01:39,  7.48it/s]\titers: 600, epoch: 4 | loss: 0.3449117\n",
      "\tspeed: 0.1771s/iter; left time: 11070.9815s\n",
      "699it [01:56,  3.78it/s]\titers: 700, epoch: 4 | loss: 0.4637513\n",
      "\tspeed: 0.1681s/iter; left time: 10493.0736s\n",
      "799it [02:13,  3.35it/s]\titers: 800, epoch: 4 | loss: 0.3791815\n",
      "\tspeed: 0.1653s/iter; left time: 10300.8781s\n",
      "899it [02:29,  7.98it/s]\titers: 900, epoch: 4 | loss: 0.3098664\n",
      "\tspeed: 0.1629s/iter; left time: 10133.1336s\n",
      "999it [02:45,  7.82it/s]\titers: 1000, epoch: 4 | loss: 0.3481237\n",
      "\tspeed: 0.1599s/iter; left time: 9935.8547s\n",
      "1099it [03:03,  3.17it/s]\titers: 1100, epoch: 4 | loss: 0.2980776\n",
      "\tspeed: 0.1763s/iter; left time: 10936.7920s\n",
      "1199it [03:19,  7.76it/s]\titers: 1200, epoch: 4 | loss: 0.4521514\n",
      "\tspeed: 0.1594s/iter; left time: 9867.7863s\n",
      "1299it [03:34,  8.06it/s]\titers: 1300, epoch: 4 | loss: 0.4708442\n",
      "\tspeed: 0.1589s/iter; left time: 9820.7229s\n",
      "1399it [03:50,  8.02it/s]\titers: 1400, epoch: 4 | loss: 0.3791539\n",
      "\tspeed: 0.1598s/iter; left time: 9861.9848s\n",
      "1499it [04:08,  7.62it/s]\titers: 1500, epoch: 4 | loss: 0.3401311\n",
      "\tspeed: 0.1767s/iter; left time: 10888.9815s\n",
      "1599it [04:24,  8.07it/s]\titers: 1600, epoch: 4 | loss: 0.3305887\n",
      "\tspeed: 0.1593s/iter; left time: 9801.7008s\n",
      "1699it [04:42,  3.20it/s]\titers: 1700, epoch: 4 | loss: 0.3038333\n",
      "\tspeed: 0.1786s/iter; left time: 10970.0495s\n",
      "1799it [04:58,  5.73it/s]\titers: 1800, epoch: 4 | loss: 0.2486874\n",
      "\tspeed: 0.1621s/iter; left time: 9942.0597s\n",
      "1899it [05:14,  7.85it/s]\titers: 1900, epoch: 4 | loss: 0.4243304\n",
      "\tspeed: 0.1609s/iter; left time: 9847.7676s\n",
      "1999it [05:32,  7.81it/s]\titers: 2000, epoch: 4 | loss: 0.2149484\n",
      "\tspeed: 0.1775s/iter; left time: 10849.3953s\n",
      "2099it [05:48,  7.87it/s]\titers: 2100, epoch: 4 | loss: 0.3770129\n",
      "\tspeed: 0.1600s/iter; left time: 9766.5620s\n",
      "2199it [06:04,  7.90it/s]\titers: 2200, epoch: 4 | loss: 0.1947407\n",
      "\tspeed: 0.1602s/iter; left time: 9762.2845s\n",
      "2299it [06:22,  6.41it/s]\titers: 2300, epoch: 4 | loss: 0.2886204\n",
      "\tspeed: 0.1775s/iter; left time: 10796.5014s\n",
      "2399it [06:38,  7.94it/s]\titers: 2400, epoch: 4 | loss: 0.2057156\n",
      "\tspeed: 0.1604s/iter; left time: 9742.1178s\n",
      "2499it [06:55,  3.39it/s]\titers: 2500, epoch: 4 | loss: 0.2986284\n",
      "\tspeed: 0.1718s/iter; left time: 10417.7064s\n",
      "2599it [07:11,  7.65it/s]\titers: 2600, epoch: 4 | loss: 0.3845401\n",
      "\tspeed: 0.1645s/iter; left time: 9954.8857s\n",
      "2699it [07:27,  7.79it/s]\titers: 2700, epoch: 4 | loss: 0.2046233\n",
      "\tspeed: 0.1602s/iter; left time: 9678.0164s\n",
      "2799it [07:43,  7.91it/s]\titers: 2800, epoch: 4 | loss: 0.5872942\n",
      "\tspeed: 0.1598s/iter; left time: 9640.7367s\n",
      "2899it [08:00,  5.27it/s]\titers: 2900, epoch: 4 | loss: 0.2787766\n",
      "\tspeed: 0.1629s/iter; left time: 9812.0477s\n",
      "2999it [08:17,  7.69it/s]\titers: 3000, epoch: 4 | loss: 0.3276455\n",
      "\tspeed: 0.1759s/iter; left time: 10577.9545s\n",
      "3099it [08:34,  7.84it/s]\titers: 3100, epoch: 4 | loss: 0.2882536\n",
      "\tspeed: 0.1627s/iter; left time: 9765.2681s\n",
      "3199it [08:50,  7.74it/s]\titers: 3200, epoch: 4 | loss: 0.3190152\n",
      "\tspeed: 0.1634s/iter; left time: 9792.2205s\n",
      "3299it [09:08,  7.74it/s]\titers: 3300, epoch: 4 | loss: 0.2534955\n",
      "\tspeed: 0.1777s/iter; left time: 10631.2351s\n",
      "3399it [09:24,  7.90it/s]\titers: 3400, epoch: 4 | loss: 0.2013041\n",
      "\tspeed: 0.1597s/iter; left time: 9538.1898s\n",
      "3499it [09:41,  4.20it/s]\titers: 3500, epoch: 4 | loss: 0.3635070\n",
      "\tspeed: 0.1763s/iter; left time: 10510.9046s\n",
      "3599it [09:57,  7.55it/s]\titers: 3600, epoch: 4 | loss: 0.3619284\n",
      "\tspeed: 0.1605s/iter; left time: 9550.5720s\n",
      "3699it [10:13,  7.92it/s]\titers: 3700, epoch: 4 | loss: 0.1722519\n",
      "\tspeed: 0.1598s/iter; left time: 9493.9337s\n",
      "3713it [10:16,  6.02it/s]\n",
      "Epoch: 4 cost time: 616.487078666687\n",
      "810it [01:02, 12.94it/s]\n",
      "807it [01:01, 13.15it/s]\n",
      "Epoch: 4 | Train Loss: 0.3298674 Vali Loss: 0.3902555 Test Loss: 0.4786931 MAE Loss: 0.4599794\n",
      "lr = 0.0009045095\n",
      "99it [00:17,  3.42it/s]\titers: 100, epoch: 5 | loss: 0.2062469\n",
      "\tspeed: 1.4749s/iter; left time: 87472.6921s\n",
      "199it [00:33,  7.95it/s]\titers: 200, epoch: 5 | loss: 0.2092327\n",
      "\tspeed: 0.1648s/iter; left time: 9760.0556s\n",
      "299it [00:51,  5.12it/s]\titers: 300, epoch: 5 | loss: 0.3449670\n",
      "\tspeed: 0.1766s/iter; left time: 10436.2987s\n",
      "399it [01:07,  7.97it/s]\titers: 400, epoch: 5 | loss: 0.3249771\n",
      "\tspeed: 0.1598s/iter; left time: 9428.9798s\n",
      "499it [01:23,  7.87it/s]\titers: 500, epoch: 5 | loss: 0.1315668\n",
      "\tspeed: 0.1597s/iter; left time: 9408.0825s\n",
      "599it [01:39,  7.88it/s]\titers: 600, epoch: 5 | loss: 0.2624253\n",
      "\tspeed: 0.1591s/iter; left time: 9359.2569s\n",
      "699it [01:56,  3.23it/s]\titers: 700, epoch: 5 | loss: 0.3038742\n",
      "\tspeed: 0.1756s/iter; left time: 10309.6072s\n",
      "799it [02:12,  7.81it/s]\titers: 800, epoch: 5 | loss: 0.3684295\n",
      "\tspeed: 0.1607s/iter; left time: 9419.5264s\n",
      "899it [02:28,  7.97it/s]\titers: 900, epoch: 5 | loss: 0.4144670\n",
      "\tspeed: 0.1592s/iter; left time: 9317.5061s\n",
      "999it [02:44,  7.90it/s]\titers: 1000, epoch: 5 | loss: 0.3208720\n",
      "\tspeed: 0.1600s/iter; left time: 9346.3959s\n",
      "1099it [03:02,  6.88it/s]\titers: 1100, epoch: 5 | loss: 0.3457694\n",
      "\tspeed: 0.1757s/iter; left time: 10247.4172s\n",
      "1199it [03:18,  7.96it/s]\titers: 1200, epoch: 5 | loss: 0.3169947\n",
      "\tspeed: 0.1603s/iter; left time: 9330.1545s\n",
      "1299it [03:35,  3.16it/s]\titers: 1300, epoch: 5 | loss: 0.1993393\n",
      "\tspeed: 0.1761s/iter; left time: 10233.5726s\n",
      "1399it [03:51,  6.70it/s]\titers: 1400, epoch: 5 | loss: 0.1898936\n",
      "\tspeed: 0.1595s/iter; left time: 9253.9140s\n",
      "1499it [04:07,  4.98it/s]\titers: 1500, epoch: 5 | loss: 0.1944701\n",
      "\tspeed: 0.1595s/iter; left time: 9234.1909s\n",
      "1599it [04:23,  8.06it/s]\titers: 1600, epoch: 5 | loss: 0.2967289\n",
      "\tspeed: 0.1588s/iter; left time: 9180.1303s\n",
      "1699it [04:40,  4.03it/s]\titers: 1700, epoch: 5 | loss: 0.2972065\n",
      "\tspeed: 0.1657s/iter; left time: 9563.4352s\n",
      "1799it [04:57,  8.00it/s]\titers: 1800, epoch: 5 | loss: 0.2943450\n",
      "\tspeed: 0.1695s/iter; left time: 9764.2437s\n",
      "1899it [05:13,  7.83it/s]\titers: 1900, epoch: 5 | loss: 0.3562803\n",
      "\tspeed: 0.1603s/iter; left time: 9219.3087s\n",
      "1999it [05:29,  7.87it/s]\titers: 2000, epoch: 5 | loss: 0.2711124\n",
      "\tspeed: 0.1599s/iter; left time: 9179.1367s\n",
      "2099it [05:46,  5.51it/s]\titers: 2100, epoch: 5 | loss: 0.3655235\n",
      "\tspeed: 0.1759s/iter; left time: 10078.7581s\n",
      "2199it [06:02,  7.33it/s]\titers: 2200, epoch: 5 | loss: 0.2359903\n",
      "\tspeed: 0.1601s/iter; left time: 9159.1422s\n",
      "2299it [06:18,  7.84it/s]\titers: 2300, epoch: 5 | loss: 0.5608481\n",
      "\tspeed: 0.1595s/iter; left time: 9111.2330s\n",
      "2399it [06:34,  7.94it/s]\titers: 2400, epoch: 5 | loss: 0.3043300\n",
      "\tspeed: 0.1596s/iter; left time: 9097.9746s\n",
      "2499it [06:51,  3.29it/s]\titers: 2500, epoch: 5 | loss: 0.3357579\n",
      "\tspeed: 0.1727s/iter; left time: 9830.3465s\n",
      "2599it [07:08,  7.88it/s]\titers: 2600, epoch: 5 | loss: 0.4537764\n",
      "\tspeed: 0.1632s/iter; left time: 9269.7316s\n",
      "2699it [07:26,  4.68it/s]\titers: 2700, epoch: 5 | loss: 0.2674872\n",
      "\tspeed: 0.1771s/iter; left time: 10042.0639s\n",
      "2799it [07:42,  7.73it/s]\titers: 2800, epoch: 5 | loss: 0.2827784\n",
      "\tspeed: 0.1598s/iter; left time: 9046.1901s\n",
      "2899it [07:58,  7.90it/s]\titers: 2900, epoch: 5 | loss: 0.3093247\n",
      "\tspeed: 0.1595s/iter; left time: 9015.0581s\n",
      "2999it [08:13,  7.89it/s]\titers: 3000, epoch: 5 | loss: 0.3517567\n",
      "\tspeed: 0.1593s/iter; left time: 8987.5907s\n",
      "3099it [08:31,  7.00it/s]\titers: 3100, epoch: 5 | loss: 0.3229257\n",
      "\tspeed: 0.1769s/iter; left time: 9959.9333s\n",
      "3199it [08:47,  7.90it/s]\titers: 3200, epoch: 5 | loss: 0.3408239\n",
      "\tspeed: 0.1599s/iter; left time: 8987.6888s\n",
      "3299it [09:03,  8.00it/s]\titers: 3300, epoch: 5 | loss: 0.3052003\n",
      "\tspeed: 0.1610s/iter; left time: 9035.2123s\n",
      "3399it [09:19,  7.85it/s]\titers: 3400, epoch: 5 | loss: 0.3453138\n",
      "\tspeed: 0.1598s/iter; left time: 8948.6346s\n",
      "3499it [09:37,  7.81it/s]\titers: 3500, epoch: 5 | loss: 0.4115940\n",
      "\tspeed: 0.1769s/iter; left time: 9892.8208s\n",
      "3599it [09:53,  7.93it/s]\titers: 3600, epoch: 5 | loss: 0.4233800\n",
      "\tspeed: 0.1590s/iter; left time: 8874.2877s\n",
      "3699it [10:10,  7.32it/s]\titers: 3700, epoch: 5 | loss: 0.2183217\n",
      "\tspeed: 0.1763s/iter; left time: 9823.1006s\n",
      "3713it [10:12,  6.06it/s]\n",
      "Epoch: 5 cost time: 612.7998220920563\n",
      "810it [01:01, 13.22it/s]\n",
      "807it [01:01, 13.12it/s]\n",
      "Epoch: 5 | Train Loss: 0.3223494 Vali Loss: 0.3899679 Test Loss: 0.5002480 MAE Loss: 0.4720434\n",
      "lr = 0.0008535549\n",
      "99it [00:16,  3.71it/s]\titers: 100, epoch: 6 | loss: 0.3981171\n",
      "\tspeed: 1.4497s/iter; left time: 80598.3957s\n",
      "199it [00:33,  3.71it/s]\titers: 200, epoch: 6 | loss: 0.2415454\n",
      "\tspeed: 0.1689s/iter; left time: 9373.7112s\n",
      "299it [00:49,  6.22it/s]\titers: 300, epoch: 6 | loss: 0.4251336\n",
      "\tspeed: 0.1597s/iter; left time: 8845.8571s\n",
      "399it [01:05,  7.46it/s]\titers: 400, epoch: 6 | loss: 0.2379706\n",
      "\tspeed: 0.1607s/iter; left time: 8884.1520s\n",
      "499it [01:22,  3.40it/s]\titers: 500, epoch: 6 | loss: 0.2679409\n",
      "\tspeed: 0.1705s/iter; left time: 9411.8526s\n",
      "599it [01:39,  7.46it/s]\titers: 600, epoch: 6 | loss: 0.4484220\n",
      "\tspeed: 0.1650s/iter; left time: 9089.1034s\n",
      "699it [01:55,  8.04it/s]\titers: 700, epoch: 6 | loss: 0.4534326\n",
      "\tspeed: 0.1594s/iter; left time: 8765.9907s\n",
      "799it [02:11,  7.86it/s]\titers: 800, epoch: 6 | loss: 0.4298534\n",
      "\tspeed: 0.1590s/iter; left time: 8728.9859s\n",
      "899it [02:29,  7.94it/s]\titers: 900, epoch: 6 | loss: 0.4534819\n",
      "\tspeed: 0.1766s/iter; left time: 9674.5915s\n",
      "999it [02:45,  3.97it/s]\titers: 1000, epoch: 6 | loss: 0.2164369\n",
      "\tspeed: 0.1676s/iter; left time: 9167.4563s\n",
      "1099it [03:02,  7.15it/s]\titers: 1100, epoch: 6 | loss: 0.2568227\n",
      "\tspeed: 0.1704s/iter; left time: 9302.2156s\n",
      "1199it [03:18,  7.84it/s]\titers: 1200, epoch: 6 | loss: 0.3906294\n",
      "\tspeed: 0.1595s/iter; left time: 8691.4124s\n",
      "1299it [03:34,  7.94it/s]\titers: 1300, epoch: 6 | loss: 0.3052442\n",
      "\tspeed: 0.1596s/iter; left time: 8682.9470s\n",
      "1399it [03:52,  7.81it/s]\titers: 1400, epoch: 6 | loss: 0.2060187\n",
      "\tspeed: 0.1770s/iter; left time: 9610.3462s\n",
      "1499it [04:08,  7.95it/s]\titers: 1500, epoch: 6 | loss: 0.2281263\n",
      "\tspeed: 0.1596s/iter; left time: 8648.0252s\n",
      "1599it [04:24,  5.21it/s]\titers: 1600, epoch: 6 | loss: 0.1834518\n",
      "\tspeed: 0.1631s/iter; left time: 8823.0301s\n",
      "1699it [04:41,  3.43it/s]\titers: 1700, epoch: 6 | loss: 0.4229937\n",
      "\tspeed: 0.1672s/iter; left time: 9028.4465s\n",
      "1799it [04:58,  3.46it/s]\titers: 1800, epoch: 6 | loss: 0.3029844\n",
      "\tspeed: 0.1762s/iter; left time: 9493.9423s\n",
      "1899it [05:15,  7.02it/s]\titers: 1900, epoch: 6 | loss: 0.3882581\n",
      "\tspeed: 0.1659s/iter; left time: 8925.1278s\n",
      "1999it [05:31,  8.04it/s]\titers: 2000, epoch: 6 | loss: 0.2055421\n",
      "\tspeed: 0.1603s/iter; left time: 8606.3734s\n",
      "2099it [05:47,  8.05it/s]\titers: 2100, epoch: 6 | loss: 0.3976897\n",
      "\tspeed: 0.1599s/iter; left time: 8571.7885s\n",
      "2199it [06:05,  6.58it/s]\titers: 2200, epoch: 6 | loss: 0.1607098\n",
      "\tspeed: 0.1755s/iter; left time: 9389.6446s\n",
      "2299it [06:21,  3.93it/s]\titers: 2300, epoch: 6 | loss: 0.2873370\n",
      "\tspeed: 0.1665s/iter; left time: 8889.4087s\n",
      "2399it [06:38,  7.86it/s]\titers: 2400, epoch: 6 | loss: 0.2190129\n",
      "\tspeed: 0.1689s/iter; left time: 9000.2203s\n",
      "2499it [06:54,  7.87it/s]\titers: 2500, epoch: 6 | loss: 0.5059695\n",
      "\tspeed: 0.1598s/iter; left time: 8502.0240s\n",
      "2599it [07:11,  3.47it/s]\titers: 2600, epoch: 6 | loss: 0.2571782\n",
      "\tspeed: 0.1706s/iter; left time: 9059.8871s\n",
      "2699it [07:29,  3.21it/s]\titers: 2700, epoch: 6 | loss: 0.3782385\n",
      "\tspeed: 0.1794s/iter; left time: 9504.9728s\n",
      "2799it [07:45,  7.74it/s]\titers: 2800, epoch: 6 | loss: 0.4393087\n",
      "\tspeed: 0.1617s/iter; left time: 8554.1814s\n",
      "2899it [08:01,  7.91it/s]\titers: 2900, epoch: 6 | loss: 0.3307942\n",
      "\tspeed: 0.1598s/iter; left time: 8436.1197s\n",
      "2999it [08:17,  7.96it/s]\titers: 3000, epoch: 6 | loss: 0.3004380\n",
      "\tspeed: 0.1605s/iter; left time: 8455.9151s\n",
      "3099it [08:36,  3.60it/s]\titers: 3100, epoch: 6 | loss: 0.3270711\n",
      "\tspeed: 0.1843s/iter; left time: 9692.2653s\n",
      "3199it [08:51,  7.86it/s]\titers: 3200, epoch: 6 | loss: 0.2833447\n",
      "\tspeed: 0.1503s/iter; left time: 7889.2977s\n",
      "3299it [09:03,  8.05it/s]\titers: 3300, epoch: 6 | loss: 0.1918054\n",
      "\tspeed: 0.1257s/iter; left time: 6586.9386s\n",
      "3399it [09:16,  7.82it/s]\titers: 3400, epoch: 6 | loss: 0.3671283\n",
      "\tspeed: 0.1277s/iter; left time: 6678.1502s\n",
      "3499it [09:29,  7.34it/s]\titers: 3500, epoch: 6 | loss: 0.1911821\n",
      "\tspeed: 0.1295s/iter; left time: 6760.8940s\n",
      "3599it [09:42,  7.74it/s]\titers: 3600, epoch: 6 | loss: 0.3678643\n",
      "\tspeed: 0.1273s/iter; left time: 6632.4934s\n",
      "3699it [09:55,  7.86it/s]\titers: 3700, epoch: 6 | loss: 0.5699005\n",
      "\tspeed: 0.1284s/iter; left time: 6676.4397s\n",
      "3713it [09:57,  6.22it/s]\n",
      "Epoch: 6 cost time: 597.1113939285278\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:48, 16.52it/s]\n",
      "Epoch: 6 | Train Loss: 0.3198384 Vali Loss: 0.3886737 Test Loss: 0.4846429 MAE Loss: 0.4600995\n",
      "lr = 0.0007938947\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 7 | loss: 0.2265851\n",
      "\tspeed: 1.1590s/iter; left time: 60133.9246s\n",
      "199it [00:26,  7.48it/s]\titers: 200, epoch: 7 | loss: 0.2100025\n",
      "\tspeed: 0.1332s/iter; left time: 6895.9622s\n",
      "299it [00:39,  7.85it/s]\titers: 300, epoch: 7 | loss: 0.5523100\n",
      "\tspeed: 0.1289s/iter; left time: 6663.0723s\n",
      "399it [00:53,  7.63it/s]\titers: 400, epoch: 7 | loss: 0.4162106\n",
      "\tspeed: 0.1330s/iter; left time: 6862.7439s\n",
      "499it [01:06,  7.78it/s]\titers: 500, epoch: 7 | loss: 0.3099052\n",
      "\tspeed: 0.1316s/iter; left time: 6776.9242s\n",
      "599it [01:19,  7.30it/s]\titers: 600, epoch: 7 | loss: 0.1792604\n",
      "\tspeed: 0.1306s/iter; left time: 6709.8898s\n",
      "699it [01:32,  7.88it/s]\titers: 700, epoch: 7 | loss: 0.2216137\n",
      "\tspeed: 0.1287s/iter; left time: 6602.6147s\n",
      "799it [01:45,  7.97it/s]\titers: 800, epoch: 7 | loss: 0.4571757\n",
      "\tspeed: 0.1297s/iter; left time: 6638.7903s\n",
      "899it [01:57,  7.65it/s]\titers: 900, epoch: 7 | loss: 0.2167834\n",
      "\tspeed: 0.1271s/iter; left time: 6494.0746s\n",
      "999it [02:10,  8.00it/s]\titers: 1000, epoch: 7 | loss: 0.2711854\n",
      "\tspeed: 0.1276s/iter; left time: 6504.6479s\n",
      "1099it [02:23,  7.84it/s]\titers: 1100, epoch: 7 | loss: 0.3673321\n",
      "\tspeed: 0.1286s/iter; left time: 6543.5676s\n",
      "1199it [02:36,  7.50it/s]\titers: 1200, epoch: 7 | loss: 0.3153488\n",
      "\tspeed: 0.1319s/iter; left time: 6700.7263s\n",
      "1299it [02:49,  7.88it/s]\titers: 1300, epoch: 7 | loss: 0.2096113\n",
      "\tspeed: 0.1278s/iter; left time: 6476.7992s\n",
      "1399it [03:02,  7.85it/s]\titers: 1400, epoch: 7 | loss: 0.5648524\n",
      "\tspeed: 0.1303s/iter; left time: 6589.1690s\n",
      "1499it [03:15,  7.29it/s]\titers: 1500, epoch: 7 | loss: 0.1719721\n",
      "\tspeed: 0.1297s/iter; left time: 6547.8810s\n",
      "1599it [03:28,  7.93it/s]\titers: 1600, epoch: 7 | loss: 0.6261527\n",
      "\tspeed: 0.1282s/iter; left time: 6459.5033s\n",
      "1699it [03:41,  7.69it/s]\titers: 1700, epoch: 7 | loss: 0.4650384\n",
      "\tspeed: 0.1320s/iter; left time: 6637.0661s\n",
      "1799it [03:54,  6.81it/s]\titers: 1800, epoch: 7 | loss: 0.5716541\n",
      "\tspeed: 0.1313s/iter; left time: 6589.4724s\n",
      "1899it [04:07,  7.76it/s]\titers: 1900, epoch: 7 | loss: 0.3695265\n",
      "\tspeed: 0.1274s/iter; left time: 6382.7734s\n",
      "1999it [04:20,  7.44it/s]\titers: 2000, epoch: 7 | loss: 0.4043526\n",
      "\tspeed: 0.1310s/iter; left time: 6546.8440s\n",
      "2099it [04:33,  7.55it/s]\titers: 2100, epoch: 7 | loss: 0.2021791\n",
      "\tspeed: 0.1323s/iter; left time: 6601.0589s\n",
      "2199it [04:46,  7.94it/s]\titers: 2200, epoch: 7 | loss: 0.2972278\n",
      "\tspeed: 0.1285s/iter; left time: 6398.9046s\n",
      "2299it [04:59,  7.67it/s]\titers: 2300, epoch: 7 | loss: 0.3575771\n",
      "\tspeed: 0.1329s/iter; left time: 6600.5495s\n",
      "2399it [05:13,  7.83it/s]\titers: 2400, epoch: 7 | loss: 0.2037572\n",
      "\tspeed: 0.1324s/iter; left time: 6565.4608s\n",
      "2499it [05:26,  7.86it/s]\titers: 2500, epoch: 7 | loss: 0.1965705\n",
      "\tspeed: 0.1309s/iter; left time: 6479.5562s\n",
      "2599it [05:38,  7.86it/s]\titers: 2600, epoch: 7 | loss: 0.3151780\n",
      "\tspeed: 0.1281s/iter; left time: 6324.4644s\n",
      "2699it [05:52,  7.85it/s]\titers: 2700, epoch: 7 | loss: 0.2034536\n",
      "\tspeed: 0.1323s/iter; left time: 6520.5107s\n",
      "2799it [06:05,  7.88it/s]\titers: 2800, epoch: 7 | loss: 0.2483424\n",
      "\tspeed: 0.1302s/iter; left time: 6405.4563s\n",
      "2899it [06:17,  7.95it/s]\titers: 2900, epoch: 7 | loss: 0.2180000\n",
      "\tspeed: 0.1274s/iter; left time: 6254.1374s\n",
      "2999it [06:31,  7.75it/s]\titers: 3000, epoch: 7 | loss: 0.4697379\n",
      "\tspeed: 0.1318s/iter; left time: 6458.3909s\n",
      "3099it [06:44,  7.93it/s]\titers: 3100, epoch: 7 | loss: 0.2891927\n",
      "\tspeed: 0.1291s/iter; left time: 6311.8378s\n",
      "3199it [06:56,  7.80it/s]\titers: 3200, epoch: 7 | loss: 0.2120788\n",
      "\tspeed: 0.1287s/iter; left time: 6279.7677s\n",
      "3299it [07:10,  7.81it/s]\titers: 3300, epoch: 7 | loss: 0.2999848\n",
      "\tspeed: 0.1312s/iter; left time: 6387.3773s\n",
      "3399it [07:23,  7.98it/s]\titers: 3400, epoch: 7 | loss: 0.2691816\n",
      "\tspeed: 0.1301s/iter; left time: 6320.5846s\n",
      "3499it [07:36,  7.63it/s]\titers: 3500, epoch: 7 | loss: 0.1904802\n",
      "\tspeed: 0.1305s/iter; left time: 6324.9169s\n",
      "3599it [07:49,  7.75it/s]\titers: 3600, epoch: 7 | loss: 0.3413115\n",
      "\tspeed: 0.1330s/iter; left time: 6434.3642s\n",
      "3699it [08:02,  7.89it/s]\titers: 3700, epoch: 7 | loss: 0.3261745\n",
      "\tspeed: 0.1336s/iter; left time: 6450.8191s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 7 cost time: 484.6030158996582\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:49, 16.44it/s]\n",
      "Epoch: 7 | Train Loss: 0.3178822 Vali Loss: 0.4026718 Test Loss: 0.5029341 MAE Loss: 0.4814337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:13,  7.62it/s]\titers: 100, epoch: 8 | loss: 0.1936937\n",
      "\tspeed: 1.1304s/iter; left time: 54451.4699s\n",
      "199it [00:26,  7.55it/s]\titers: 200, epoch: 8 | loss: 0.3481279\n",
      "\tspeed: 0.1299s/iter; left time: 6243.8612s\n",
      "299it [00:39,  7.77it/s]\titers: 300, epoch: 8 | loss: 0.2465445\n",
      "\tspeed: 0.1336s/iter; left time: 6410.0930s\n",
      "399it [00:52,  7.66it/s]\titers: 400, epoch: 8 | loss: 0.3907549\n",
      "\tspeed: 0.1311s/iter; left time: 6274.9684s\n",
      "499it [01:05,  7.80it/s]\titers: 500, epoch: 8 | loss: 0.2190004\n",
      "\tspeed: 0.1321s/iter; left time: 6308.1225s\n",
      "599it [01:18,  7.76it/s]\titers: 600, epoch: 8 | loss: 0.3313726\n",
      "\tspeed: 0.1291s/iter; left time: 6153.4880s\n",
      "699it [01:32,  7.72it/s]\titers: 700, epoch: 8 | loss: 0.5199006\n",
      "\tspeed: 0.1320s/iter; left time: 6281.4071s\n",
      "799it [01:45,  7.77it/s]\titers: 800, epoch: 8 | loss: 0.4603224\n",
      "\tspeed: 0.1295s/iter; left time: 6147.0396s\n",
      "899it [01:57,  8.05it/s]\titers: 900, epoch: 8 | loss: 0.3747466\n",
      "\tspeed: 0.1282s/iter; left time: 6072.7396s\n",
      "999it [02:10,  8.14it/s]\titers: 1000, epoch: 8 | loss: 0.3959230\n",
      "\tspeed: 0.1289s/iter; left time: 6091.9026s\n",
      "1099it [02:23,  7.13it/s]\titers: 1100, epoch: 8 | loss: 0.3026269\n",
      "\tspeed: 0.1268s/iter; left time: 5981.9211s\n",
      "1199it [02:36,  7.92it/s]\titers: 1200, epoch: 8 | loss: 0.2920355\n",
      "\tspeed: 0.1282s/iter; left time: 6034.3071s\n",
      "1299it [02:49,  7.87it/s]\titers: 1300, epoch: 8 | loss: 0.5332096\n",
      "\tspeed: 0.1298s/iter; left time: 6096.9731s\n",
      "1399it [03:02,  6.55it/s]\titers: 1400, epoch: 8 | loss: 0.3614319\n",
      "\tspeed: 0.1302s/iter; left time: 6101.2353s\n",
      "1499it [03:15,  7.78it/s]\titers: 1500, epoch: 8 | loss: 0.1590936\n",
      "\tspeed: 0.1286s/iter; left time: 6014.1734s\n",
      "1599it [03:28,  7.81it/s]\titers: 1600, epoch: 8 | loss: 0.3205967\n",
      "\tspeed: 0.1325s/iter; left time: 6183.4313s\n",
      "1699it [03:41,  6.90it/s]\titers: 1700, epoch: 8 | loss: 0.2919439\n",
      "\tspeed: 0.1298s/iter; left time: 6045.3835s\n",
      "1799it [03:54,  7.87it/s]\titers: 1800, epoch: 8 | loss: 0.1961195\n",
      "\tspeed: 0.1288s/iter; left time: 5986.3663s\n",
      "1899it [04:07,  7.78it/s]\titers: 1900, epoch: 8 | loss: 0.2501426\n",
      "\tspeed: 0.1328s/iter; left time: 6157.0688s\n",
      "1999it [04:20,  6.16it/s]\titers: 2000, epoch: 8 | loss: 0.4652239\n",
      "\tspeed: 0.1309s/iter; left time: 6055.9857s\n",
      "2099it [04:33,  7.86it/s]\titers: 2100, epoch: 8 | loss: 0.3647101\n",
      "\tspeed: 0.1298s/iter; left time: 5990.8541s\n",
      "2199it [04:46,  7.72it/s]\titers: 2200, epoch: 8 | loss: 0.3905986\n",
      "\tspeed: 0.1318s/iter; left time: 6072.0517s\n",
      "2299it [04:59,  7.61it/s]\titers: 2300, epoch: 8 | loss: 0.2619036\n",
      "\tspeed: 0.1313s/iter; left time: 6037.6951s\n",
      "2399it [05:12,  7.84it/s]\titers: 2400, epoch: 8 | loss: 0.2907792\n",
      "\tspeed: 0.1285s/iter; left time: 5892.4569s\n",
      "2499it [05:25,  8.01it/s]\titers: 2500, epoch: 8 | loss: 0.3323463\n",
      "\tspeed: 0.1313s/iter; left time: 6008.2418s\n",
      "2599it [05:39,  6.29it/s]\titers: 2600, epoch: 8 | loss: 0.1633468\n",
      "\tspeed: 0.1320s/iter; left time: 6029.1540s\n",
      "2699it [05:51,  7.66it/s]\titers: 2700, epoch: 8 | loss: 0.3098654\n",
      "\tspeed: 0.1279s/iter; left time: 5828.4606s\n",
      "2799it [06:04,  7.81it/s]\titers: 2800, epoch: 8 | loss: 0.1567122\n",
      "\tspeed: 0.1301s/iter; left time: 5917.6665s\n",
      "2899it [06:17,  7.29it/s]\titers: 2900, epoch: 8 | loss: 0.3251747\n",
      "\tspeed: 0.1301s/iter; left time: 5903.3621s\n",
      "2999it [06:30,  7.81it/s]\titers: 3000, epoch: 8 | loss: 0.3707897\n",
      "\tspeed: 0.1270s/iter; left time: 5748.5596s\n",
      "3099it [06:43,  8.04it/s]\titers: 3100, epoch: 8 | loss: 0.5539950\n",
      "\tspeed: 0.1283s/iter; left time: 5795.8474s\n",
      "3199it [06:56,  7.61it/s]\titers: 3200, epoch: 8 | loss: 0.2189280\n",
      "\tspeed: 0.1316s/iter; left time: 5929.4858s\n",
      "3299it [07:09,  7.62it/s]\titers: 3300, epoch: 8 | loss: 0.4177049\n",
      "\tspeed: 0.1312s/iter; left time: 5898.2675s\n",
      "3399it [07:22,  7.87it/s]\titers: 3400, epoch: 8 | loss: 0.2371941\n",
      "\tspeed: 0.1327s/iter; left time: 5953.2572s\n",
      "3499it [07:35,  7.84it/s]\titers: 3500, epoch: 8 | loss: 0.3518778\n",
      "\tspeed: 0.1304s/iter; left time: 5837.8332s\n",
      "3599it [07:49,  7.67it/s]\titers: 3600, epoch: 8 | loss: 0.2310055\n",
      "\tspeed: 0.1307s/iter; left time: 5838.1202s\n",
      "3699it [08:01,  7.75it/s]\titers: 3700, epoch: 8 | loss: 0.2773418\n",
      "\tspeed: 0.1293s/iter; left time: 5764.2123s\n",
      "3713it [08:03,  7.67it/s]\n",
      "Epoch: 8 cost time: 483.83397150039673\n",
      "810it [00:48, 16.69it/s]\n",
      "807it [00:48, 16.53it/s]\n",
      "Epoch: 8 | Train Loss: 0.3127520 Vali Loss: 0.3726595 Test Loss: 0.4752736 MAE Loss: 0.4556114\n",
      "lr = 0.0006545120\n",
      "99it [00:13,  7.72it/s]\titers: 100, epoch: 9 | loss: 0.2628272\n",
      "\tspeed: 1.1500s/iter; left time: 51124.4471s\n",
      "199it [00:26,  7.84it/s]\titers: 200, epoch: 9 | loss: 0.3388748\n",
      "\tspeed: 0.1301s/iter; left time: 5770.9124s\n",
      "299it [00:39,  7.61it/s]\titers: 300, epoch: 9 | loss: 0.2200371\n",
      "\tspeed: 0.1299s/iter; left time: 5750.8353s\n",
      "399it [00:52,  7.71it/s]\titers: 400, epoch: 9 | loss: 0.2471333\n",
      "\tspeed: 0.1284s/iter; left time: 5671.2795s\n",
      "499it [01:05,  7.73it/s]\titers: 500, epoch: 9 | loss: 0.2086286\n",
      "\tspeed: 0.1314s/iter; left time: 5787.6475s\n",
      "599it [01:18,  6.80it/s]\titers: 600, epoch: 9 | loss: 0.2185426\n",
      "\tspeed: 0.1332s/iter; left time: 5854.2293s\n",
      "699it [01:31,  7.37it/s]\titers: 700, epoch: 9 | loss: 0.2660626\n",
      "\tspeed: 0.1302s/iter; left time: 5712.1031s\n",
      "799it [01:45,  7.79it/s]\titers: 800, epoch: 9 | loss: 0.3809134\n",
      "\tspeed: 0.1358s/iter; left time: 5941.6482s\n",
      "899it [01:58,  7.43it/s]\titers: 900, epoch: 9 | loss: 0.2144846\n",
      "\tspeed: 0.1350s/iter; left time: 5894.7358s\n",
      "999it [02:11,  7.27it/s]\titers: 1000, epoch: 9 | loss: 0.3710669\n",
      "\tspeed: 0.1340s/iter; left time: 5838.8126s\n",
      "1099it [02:25,  7.60it/s]\titers: 1100, epoch: 9 | loss: 0.3881444\n",
      "\tspeed: 0.1309s/iter; left time: 5687.9321s\n",
      "1199it [02:38,  7.78it/s]\titers: 1200, epoch: 9 | loss: 0.1951334\n",
      "\tspeed: 0.1324s/iter; left time: 5738.7300s\n",
      "1299it [02:51,  7.57it/s]\titers: 1300, epoch: 9 | loss: 0.1992106\n",
      "\tspeed: 0.1313s/iter; left time: 5680.2175s\n",
      "1399it [03:04,  6.15it/s]\titers: 1400, epoch: 9 | loss: 0.3933530\n",
      "\tspeed: 0.1325s/iter; left time: 5716.5602s\n",
      "1499it [03:17,  7.86it/s]\titers: 1500, epoch: 9 | loss: 0.4240173\n",
      "\tspeed: 0.1290s/iter; left time: 5556.1867s\n",
      "1599it [03:30,  7.88it/s]\titers: 1600, epoch: 9 | loss: 0.2480144\n",
      "\tspeed: 0.1307s/iter; left time: 5613.7809s\n",
      "1699it [03:43,  7.92it/s]\titers: 1700, epoch: 9 | loss: 0.2983743\n",
      "\tspeed: 0.1261s/iter; left time: 5403.6111s\n",
      "1799it [03:56,  7.78it/s]\titers: 1800, epoch: 9 | loss: 0.3400280\n",
      "\tspeed: 0.1284s/iter; left time: 5489.5114s\n",
      "1899it [04:09,  7.73it/s]\titers: 1900, epoch: 9 | loss: 0.1634814\n",
      "\tspeed: 0.1305s/iter; left time: 5565.7552s\n",
      "1999it [04:22,  7.83it/s]\titers: 2000, epoch: 9 | loss: 0.4274901\n",
      "\tspeed: 0.1288s/iter; left time: 5481.3031s\n",
      "2099it [04:35,  7.86it/s]\titers: 2100, epoch: 9 | loss: 0.2724287\n",
      "\tspeed: 0.1302s/iter; left time: 5529.7662s\n",
      "2199it [04:48,  7.88it/s]\titers: 2200, epoch: 9 | loss: 0.3248950\n",
      "\tspeed: 0.1301s/iter; left time: 5508.6458s\n",
      "2299it [05:00,  7.65it/s]\titers: 2300, epoch: 9 | loss: 0.5053042\n",
      "\tspeed: 0.1287s/iter; left time: 5437.3247s\n",
      "2399it [05:13,  7.83it/s]\titers: 2400, epoch: 9 | loss: 0.2094833\n",
      "\tspeed: 0.1292s/iter; left time: 5447.7039s\n",
      "2499it [05:26,  7.07it/s]\titers: 2500, epoch: 9 | loss: 0.2380140\n",
      "\tspeed: 0.1299s/iter; left time: 5465.3030s\n",
      "2599it [05:39,  7.90it/s]\titers: 2600, epoch: 9 | loss: 0.2187919\n",
      "\tspeed: 0.1285s/iter; left time: 5391.9227s\n",
      "2699it [05:52,  7.83it/s]\titers: 2700, epoch: 9 | loss: 0.1760520\n",
      "\tspeed: 0.1304s/iter; left time: 5457.8236s\n",
      "2799it [06:05,  7.40it/s]\titers: 2800, epoch: 9 | loss: 0.4936087\n",
      "\tspeed: 0.1280s/iter; left time: 5346.9478s\n",
      "2899it [06:18,  7.75it/s]\titers: 2900, epoch: 9 | loss: 0.3552023\n",
      "\tspeed: 0.1311s/iter; left time: 5459.7563s\n",
      "2999it [06:31,  8.14it/s]\titers: 3000, epoch: 9 | loss: 0.3080100\n",
      "\tspeed: 0.1288s/iter; left time: 5352.4616s\n",
      "3099it [06:44,  7.83it/s]\titers: 3100, epoch: 9 | loss: 0.3906256\n",
      "\tspeed: 0.1261s/iter; left time: 5227.9863s\n",
      "3199it [06:56,  7.98it/s]\titers: 3200, epoch: 9 | loss: 0.3656609\n",
      "\tspeed: 0.1264s/iter; left time: 5225.5108s\n",
      "3299it [07:09,  7.90it/s]\titers: 3300, epoch: 9 | loss: 0.3032006\n",
      "\tspeed: 0.1286s/iter; left time: 5305.0685s\n",
      "3399it [07:22,  7.83it/s]\titers: 3400, epoch: 9 | loss: 0.3217273\n",
      "\tspeed: 0.1294s/iter; left time: 5324.1779s\n",
      "3499it [07:35,  8.01it/s]\titers: 3500, epoch: 9 | loss: 0.2078187\n",
      "\tspeed: 0.1268s/iter; left time: 5207.8928s\n",
      "3599it [07:48,  7.92it/s]\titers: 3600, epoch: 9 | loss: 0.2604896\n",
      "\tspeed: 0.1302s/iter; left time: 5334.0637s\n",
      "3699it [08:01,  7.89it/s]\titers: 3700, epoch: 9 | loss: 0.3178231\n",
      "\tspeed: 0.1291s/iter; left time: 5275.2265s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 9 cost time: 483.153706073761\n",
      "810it [00:47, 16.89it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 9 | Train Loss: 0.3058381 Vali Loss: 0.3785458 Test Loss: 0.4643720 MAE Loss: 0.4581837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:13,  7.88it/s]\titers: 100, epoch: 10 | loss: 0.2262759\n",
      "\tspeed: 1.1134s/iter; left time: 45366.0471s\n",
      "199it [00:26,  7.90it/s]\titers: 200, epoch: 10 | loss: 0.4223031\n",
      "\tspeed: 0.1310s/iter; left time: 5325.4521s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 10 | loss: 0.3500025\n",
      "\tspeed: 0.1310s/iter; left time: 5309.2464s\n",
      "399it [00:51,  7.87it/s]\titers: 400, epoch: 10 | loss: 0.2686449\n",
      "\tspeed: 0.1269s/iter; left time: 5133.6761s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 10 | loss: 0.3244149\n",
      "\tspeed: 0.1293s/iter; left time: 5215.2839s\n",
      "599it [01:17,  7.66it/s]\titers: 600, epoch: 10 | loss: 0.2174947\n",
      "\tspeed: 0.1296s/iter; left time: 5213.6200s\n",
      "699it [01:30,  7.81it/s]\titers: 700, epoch: 10 | loss: 0.2414598\n",
      "\tspeed: 0.1269s/iter; left time: 5096.2261s\n",
      "799it [01:43,  7.85it/s]\titers: 800, epoch: 10 | loss: 0.2375075\n",
      "\tspeed: 0.1303s/iter; left time: 5216.3621s\n",
      "899it [01:56,  6.47it/s]\titers: 900, epoch: 10 | loss: 0.3952787\n",
      "\tspeed: 0.1302s/iter; left time: 5200.6778s\n",
      "999it [02:09,  7.72it/s]\titers: 1000, epoch: 10 | loss: 0.3944128\n",
      "\tspeed: 0.1274s/iter; left time: 5075.0013s\n",
      "1099it [02:22,  7.85it/s]\titers: 1100, epoch: 10 | loss: 0.1583472\n",
      "\tspeed: 0.1298s/iter; left time: 5160.2243s\n",
      "1199it [02:35,  7.68it/s]\titers: 1200, epoch: 10 | loss: 0.3862383\n",
      "\tspeed: 0.1315s/iter; left time: 5214.3048s\n",
      "1299it [02:48,  7.71it/s]\titers: 1300, epoch: 10 | loss: 0.2872093\n",
      "\tspeed: 0.1321s/iter; left time: 5222.6327s\n",
      "1399it [03:01,  7.69it/s]\titers: 1400, epoch: 10 | loss: 0.3244129\n",
      "\tspeed: 0.1333s/iter; left time: 5257.8564s\n",
      "1499it [03:15,  7.62it/s]\titers: 1500, epoch: 10 | loss: 0.6322581\n",
      "\tspeed: 0.1322s/iter; left time: 5201.9276s\n",
      "1599it [03:28,  6.21it/s]\titers: 1600, epoch: 10 | loss: 0.3227021\n",
      "\tspeed: 0.1320s/iter; left time: 5180.4430s\n",
      "1699it [03:41,  7.82it/s]\titers: 1700, epoch: 10 | loss: 0.1612948\n",
      "\tspeed: 0.1309s/iter; left time: 5124.5768s\n",
      "1799it [03:54,  7.52it/s]\titers: 1800, epoch: 10 | loss: 0.5255820\n",
      "\tspeed: 0.1342s/iter; left time: 5238.1576s\n",
      "1899it [04:07,  7.86it/s]\titers: 1900, epoch: 10 | loss: 0.4663216\n",
      "\tspeed: 0.1285s/iter; left time: 5002.6393s\n",
      "1999it [04:20,  7.74it/s]\titers: 2000, epoch: 10 | loss: 0.2521797\n",
      "\tspeed: 0.1321s/iter; left time: 5131.0726s\n",
      "2099it [04:33,  7.86it/s]\titers: 2100, epoch: 10 | loss: 0.3337621\n",
      "\tspeed: 0.1303s/iter; left time: 5048.0179s\n",
      "2199it [04:46,  7.86it/s]\titers: 2200, epoch: 10 | loss: 0.4249370\n",
      "\tspeed: 0.1296s/iter; left time: 5006.3465s\n",
      "2299it [04:59,  7.96it/s]\titers: 2300, epoch: 10 | loss: 0.2716905\n",
      "\tspeed: 0.1285s/iter; left time: 4951.7710s\n",
      "2399it [05:12,  7.96it/s]\titers: 2400, epoch: 10 | loss: 0.2343171\n",
      "\tspeed: 0.1305s/iter; left time: 5016.4483s\n",
      "2499it [05:25,  6.64it/s]\titers: 2500, epoch: 10 | loss: 0.2048771\n",
      "\tspeed: 0.1299s/iter; left time: 4979.7063s\n",
      "2599it [05:38,  7.73it/s]\titers: 2600, epoch: 10 | loss: 0.7223256\n",
      "\tspeed: 0.1296s/iter; left time: 4957.9676s\n",
      "2699it [05:51,  7.88it/s]\titers: 2700, epoch: 10 | loss: 0.2624083\n",
      "\tspeed: 0.1307s/iter; left time: 4987.0147s\n",
      "2799it [06:04,  7.35it/s]\titers: 2800, epoch: 10 | loss: 0.2136997\n",
      "\tspeed: 0.1303s/iter; left time: 4956.8213s\n",
      "2899it [06:17,  7.83it/s]\titers: 2900, epoch: 10 | loss: 0.3243578\n",
      "\tspeed: 0.1284s/iter; left time: 4873.8017s\n",
      "2999it [06:30,  8.06it/s]\titers: 3000, epoch: 10 | loss: 0.2444431\n",
      "\tspeed: 0.1311s/iter; left time: 4962.9081s\n",
      "3099it [06:43,  7.29it/s]\titers: 3100, epoch: 10 | loss: 0.5657013\n",
      "\tspeed: 0.1303s/iter; left time: 4919.2540s\n",
      "3199it [06:56,  7.87it/s]\titers: 3200, epoch: 10 | loss: 0.1933448\n",
      "\tspeed: 0.1296s/iter; left time: 4879.9794s\n",
      "3299it [07:09,  7.92it/s]\titers: 3300, epoch: 10 | loss: 0.4643233\n",
      "\tspeed: 0.1310s/iter; left time: 4917.0145s\n",
      "3399it [07:22,  7.56it/s]\titers: 3400, epoch: 10 | loss: 0.2606220\n",
      "\tspeed: 0.1297s/iter; left time: 4858.1817s\n",
      "3499it [07:35,  7.63it/s]\titers: 3500, epoch: 10 | loss: 0.3533718\n",
      "\tspeed: 0.1283s/iter; left time: 4791.3079s\n",
      "3599it [07:49,  7.90it/s]\titers: 3600, epoch: 10 | loss: 0.1801219\n",
      "\tspeed: 0.1327s/iter; left time: 4940.6256s\n",
      "3699it [08:01,  6.97it/s]\titers: 3700, epoch: 10 | loss: 0.1827157\n",
      "\tspeed: 0.1273s/iter; left time: 4728.8132s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 10 cost time: 483.7591094970703\n",
      "810it [00:48, 16.82it/s]\n",
      "807it [00:48, 16.59it/s]\n",
      "Epoch: 10 | Train Loss: 0.3102723 Vali Loss: 0.3692426 Test Loss: 0.4556622 MAE Loss: 0.4397559\n",
      "lr = 0.0005000050\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 11 | loss: 0.2129110\n",
      "\tspeed: 1.1518s/iter; left time: 42653.6751s\n",
      "199it [00:26,  7.93it/s]\titers: 200, epoch: 11 | loss: 0.2160179\n",
      "\tspeed: 0.1312s/iter; left time: 4844.9970s\n",
      "299it [00:39,  7.96it/s]\titers: 300, epoch: 11 | loss: 0.3672554\n",
      "\tspeed: 0.1297s/iter; left time: 4778.7015s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 11 | loss: 0.1934277\n",
      "\tspeed: 0.1279s/iter; left time: 4698.5955s\n",
      "499it [01:04,  7.87it/s]\titers: 500, epoch: 11 | loss: 0.3040694\n",
      "\tspeed: 0.1291s/iter; left time: 4730.7069s\n",
      "599it [01:17,  7.95it/s]\titers: 600, epoch: 11 | loss: 0.2192571\n",
      "\tspeed: 0.1273s/iter; left time: 4651.0085s\n",
      "699it [01:30,  7.74it/s]\titers: 700, epoch: 11 | loss: 0.2925890\n",
      "\tspeed: 0.1276s/iter; left time: 4649.6643s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 11 | loss: 0.2212382\n",
      "\tspeed: 0.1279s/iter; left time: 4647.6951s\n",
      "899it [01:56,  6.28it/s]\titers: 900, epoch: 11 | loss: 0.2900137\n",
      "\tspeed: 0.1295s/iter; left time: 4693.1083s\n",
      "999it [02:09,  7.77it/s]\titers: 1000, epoch: 11 | loss: 0.2751674\n",
      "\tspeed: 0.1309s/iter; left time: 4728.7479s\n",
      "1099it [02:22,  7.75it/s]\titers: 1100, epoch: 11 | loss: 0.2574169\n",
      "\tspeed: 0.1340s/iter; left time: 4826.5211s\n",
      "1199it [02:35,  7.91it/s]\titers: 1200, epoch: 11 | loss: 0.2747743\n",
      "\tspeed: 0.1330s/iter; left time: 4779.9813s\n",
      "1299it [02:49,  7.44it/s]\titers: 1300, epoch: 11 | loss: 0.3564970\n",
      "\tspeed: 0.1335s/iter; left time: 4783.8734s\n",
      "1399it [03:02,  7.74it/s]\titers: 1400, epoch: 11 | loss: 0.5411083\n",
      "\tspeed: 0.1317s/iter; left time: 4704.9062s\n",
      "1499it [03:15,  7.72it/s]\titers: 1500, epoch: 11 | loss: 0.2462977\n",
      "\tspeed: 0.1324s/iter; left time: 4717.7038s\n",
      "1599it [03:29,  7.79it/s]\titers: 1600, epoch: 11 | loss: 0.2471355\n",
      "\tspeed: 0.1335s/iter; left time: 4742.9347s\n",
      "1699it [03:42,  7.44it/s]\titers: 1700, epoch: 11 | loss: 0.1639506\n",
      "\tspeed: 0.1300s/iter; left time: 4605.1258s\n",
      "1799it [03:55,  7.80it/s]\titers: 1800, epoch: 11 | loss: 0.2586036\n",
      "\tspeed: 0.1327s/iter; left time: 4688.0089s\n",
      "1899it [04:08,  7.68it/s]\titers: 1900, epoch: 11 | loss: 0.3037385\n",
      "\tspeed: 0.1334s/iter; left time: 4698.7780s\n",
      "1999it [04:21,  7.78it/s]\titers: 2000, epoch: 11 | loss: 0.1892585\n",
      "\tspeed: 0.1313s/iter; left time: 4612.6265s\n",
      "2099it [04:34,  7.79it/s]\titers: 2100, epoch: 11 | loss: 0.4631732\n",
      "\tspeed: 0.1280s/iter; left time: 4485.5432s\n",
      "2199it [04:47,  8.09it/s]\titers: 2200, epoch: 11 | loss: 0.2377860\n",
      "\tspeed: 0.1309s/iter; left time: 4571.2328s\n",
      "2299it [05:00,  7.84it/s]\titers: 2300, epoch: 11 | loss: 0.3413148\n",
      "\tspeed: 0.1283s/iter; left time: 4470.0003s\n",
      "2399it [05:13,  7.86it/s]\titers: 2400, epoch: 11 | loss: 0.3775562\n",
      "\tspeed: 0.1273s/iter; left time: 4422.1625s\n",
      "2499it [05:26,  7.90it/s]\titers: 2500, epoch: 11 | loss: 0.3154799\n",
      "\tspeed: 0.1303s/iter; left time: 4512.7993s\n",
      "2599it [05:39,  7.90it/s]\titers: 2600, epoch: 11 | loss: 0.1894463\n",
      "\tspeed: 0.1301s/iter; left time: 4491.3173s\n",
      "2699it [05:52,  7.77it/s]\titers: 2700, epoch: 11 | loss: 0.3944624\n",
      "\tspeed: 0.1281s/iter; left time: 4409.5140s\n",
      "2799it [06:05,  7.69it/s]\titers: 2800, epoch: 11 | loss: 0.2589108\n",
      "\tspeed: 0.1311s/iter; left time: 4501.1055s\n",
      "2899it [06:17,  7.75it/s]\titers: 2900, epoch: 11 | loss: 0.1958744\n",
      "\tspeed: 0.1277s/iter; left time: 4371.3311s\n",
      "2999it [06:30,  7.76it/s]\titers: 3000, epoch: 11 | loss: 0.1716838\n",
      "\tspeed: 0.1289s/iter; left time: 4400.5202s\n",
      "3099it [06:44,  7.58it/s]\titers: 3100, epoch: 11 | loss: 0.3659455\n",
      "\tspeed: 0.1318s/iter; left time: 4485.8658s\n",
      "3199it [06:57,  7.67it/s]\titers: 3200, epoch: 11 | loss: 0.3893860\n",
      "\tspeed: 0.1315s/iter; left time: 4460.9065s\n",
      "3299it [07:10,  7.57it/s]\titers: 3300, epoch: 11 | loss: 0.1999049\n",
      "\tspeed: 0.1307s/iter; left time: 4422.7002s\n",
      "3399it [07:23,  7.50it/s]\titers: 3400, epoch: 11 | loss: 0.2926213\n",
      "\tspeed: 0.1352s/iter; left time: 4559.5938s\n",
      "3499it [07:37,  7.85it/s]\titers: 3500, epoch: 11 | loss: 0.3677039\n",
      "\tspeed: 0.1323s/iter; left time: 4449.8691s\n",
      "3599it [07:50,  6.42it/s]\titers: 3600, epoch: 11 | loss: 0.5320395\n",
      "\tspeed: 0.1315s/iter; left time: 4408.8302s\n",
      "3699it [08:03,  7.90it/s]\titers: 3700, epoch: 11 | loss: 0.2099393\n",
      "\tspeed: 0.1309s/iter; left time: 4376.9844s\n",
      "3713it [08:05,  7.65it/s]\n",
      "Epoch: 11 cost time: 485.1285970211029\n",
      "810it [00:48, 16.76it/s]\n",
      "807it [00:47, 16.83it/s]\n",
      "Epoch: 11 | Train Loss: 0.3060894 Vali Loss: 0.3763532 Test Loss: 0.4703912 MAE Loss: 0.4487230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0004217885\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 12 | loss: 0.4451583\n",
      "\tspeed: 1.1181s/iter; left time: 37253.6590s\n",
      "199it [00:26,  7.91it/s]\titers: 200, epoch: 12 | loss: 0.3723551\n",
      "\tspeed: 0.1290s/iter; left time: 4284.2554s\n",
      "299it [00:39,  7.97it/s]\titers: 300, epoch: 12 | loss: 0.7867625\n",
      "\tspeed: 0.1272s/iter; left time: 4213.1953s\n",
      "399it [00:52,  8.01it/s]\titers: 400, epoch: 12 | loss: 0.4089924\n",
      "\tspeed: 0.1292s/iter; left time: 4265.0037s\n",
      "499it [01:04,  7.96it/s]\titers: 500, epoch: 12 | loss: 0.2734602\n",
      "\tspeed: 0.1268s/iter; left time: 4174.6290s\n",
      "599it [01:17,  8.01it/s]\titers: 600, epoch: 12 | loss: 0.3724054\n",
      "\tspeed: 0.1277s/iter; left time: 4189.3415s\n",
      "699it [01:30,  7.92it/s]\titers: 700, epoch: 12 | loss: 0.2675925\n",
      "\tspeed: 0.1309s/iter; left time: 4281.7743s\n",
      "799it [01:43,  7.97it/s]\titers: 800, epoch: 12 | loss: 0.4542611\n",
      "\tspeed: 0.1304s/iter; left time: 4253.6951s\n",
      "899it [01:56,  7.86it/s]\titers: 900, epoch: 12 | loss: 0.3660057\n",
      "\tspeed: 0.1288s/iter; left time: 4189.7509s\n",
      "999it [02:09,  7.96it/s]\titers: 1000, epoch: 12 | loss: 0.2336639\n",
      "\tspeed: 0.1314s/iter; left time: 4258.5665s\n",
      "1099it [02:22,  7.78it/s]\titers: 1100, epoch: 12 | loss: 0.2432279\n",
      "\tspeed: 0.1304s/iter; left time: 4214.3380s\n",
      "1199it [02:35,  7.81it/s]\titers: 1200, epoch: 12 | loss: 0.2511365\n",
      "\tspeed: 0.1281s/iter; left time: 4127.3664s\n",
      "1299it [02:48,  7.76it/s]\titers: 1300, epoch: 12 | loss: 0.2882995\n",
      "\tspeed: 0.1306s/iter; left time: 4194.4716s\n",
      "1399it [03:01,  7.76it/s]\titers: 1400, epoch: 12 | loss: 0.2748743\n",
      "\tspeed: 0.1289s/iter; left time: 4127.4515s\n",
      "1499it [03:14,  7.89it/s]\titers: 1500, epoch: 12 | loss: 0.2179293\n",
      "\tspeed: 0.1297s/iter; left time: 4138.7008s\n",
      "1599it [03:27,  7.69it/s]\titers: 1600, epoch: 12 | loss: 0.2599665\n",
      "\tspeed: 0.1319s/iter; left time: 4196.8211s\n",
      "1699it [03:40,  7.90it/s]\titers: 1700, epoch: 12 | loss: 0.2231337\n",
      "\tspeed: 0.1309s/iter; left time: 4150.8066s\n",
      "1799it [03:53,  7.99it/s]\titers: 1800, epoch: 12 | loss: 0.5538921\n",
      "\tspeed: 0.1310s/iter; left time: 4140.5646s\n",
      "1899it [04:06,  7.90it/s]\titers: 1900, epoch: 12 | loss: 0.2112475\n",
      "\tspeed: 0.1295s/iter; left time: 4080.3184s\n",
      "1999it [04:19,  7.98it/s]\titers: 2000, epoch: 12 | loss: 0.4534957\n",
      "\tspeed: 0.1311s/iter; left time: 4119.9882s\n",
      "2099it [04:32,  7.83it/s]\titers: 2100, epoch: 12 | loss: 0.3825724\n",
      "\tspeed: 0.1281s/iter; left time: 4012.9954s\n",
      "2199it [04:45,  7.84it/s]\titers: 2200, epoch: 12 | loss: 0.3424095\n",
      "\tspeed: 0.1301s/iter; left time: 4062.5791s\n",
      "2299it [04:58,  7.89it/s]\titers: 2300, epoch: 12 | loss: 0.3868873\n",
      "\tspeed: 0.1297s/iter; left time: 4036.9453s\n",
      "2399it [05:11,  7.82it/s]\titers: 2400, epoch: 12 | loss: 0.1467975\n",
      "\tspeed: 0.1287s/iter; left time: 3992.4494s\n",
      "2499it [05:24,  7.91it/s]\titers: 2500, epoch: 12 | loss: 0.3604757\n",
      "\tspeed: 0.1293s/iter; left time: 3996.6577s\n",
      "2599it [05:37,  7.48it/s]\titers: 2600, epoch: 12 | loss: 0.2767126\n",
      "\tspeed: 0.1280s/iter; left time: 3943.4171s\n",
      "2699it [05:50,  7.74it/s]\titers: 2700, epoch: 12 | loss: 0.3347688\n",
      "\tspeed: 0.1305s/iter; left time: 4007.5343s\n",
      "2799it [06:03,  7.66it/s]\titers: 2800, epoch: 12 | loss: 0.2294650\n",
      "\tspeed: 0.1330s/iter; left time: 4073.3134s\n",
      "2899it [06:16,  7.16it/s]\titers: 2900, epoch: 12 | loss: 0.3583461\n",
      "\tspeed: 0.1326s/iter; left time: 4046.6202s\n",
      "2999it [06:29,  7.57it/s]\titers: 3000, epoch: 12 | loss: 0.1683756\n",
      "\tspeed: 0.1294s/iter; left time: 3936.0762s\n",
      "3099it [06:43,  7.67it/s]\titers: 3100, epoch: 12 | loss: 0.3235675\n",
      "\tspeed: 0.1332s/iter; left time: 4038.0278s\n",
      "3199it [06:56,  7.80it/s]\titers: 3200, epoch: 12 | loss: 0.2619195\n",
      "\tspeed: 0.1307s/iter; left time: 3950.0211s\n",
      "3299it [07:08,  7.85it/s]\titers: 3300, epoch: 12 | loss: 0.4199897\n",
      "\tspeed: 0.1270s/iter; left time: 3825.8208s\n",
      "3399it [07:21,  7.90it/s]\titers: 3400, epoch: 12 | loss: 0.4128708\n",
      "\tspeed: 0.1290s/iter; left time: 3872.3080s\n",
      "3499it [07:34,  7.90it/s]\titers: 3500, epoch: 12 | loss: 0.2648334\n",
      "\tspeed: 0.1309s/iter; left time: 3915.0784s\n",
      "3599it [07:47,  7.56it/s]\titers: 3600, epoch: 12 | loss: 0.1982488\n",
      "\tspeed: 0.1289s/iter; left time: 3843.7286s\n",
      "3699it [08:00,  7.96it/s]\titers: 3700, epoch: 12 | loss: 0.2565594\n",
      "\tspeed: 0.1320s/iter; left time: 3921.8288s\n",
      "3713it [08:02,  7.69it/s]\n",
      "Epoch: 12 cost time: 482.8574950695038\n",
      "810it [00:48, 16.71it/s]\n",
      "807it [00:48, 16.73it/s]\n",
      "Epoch: 12 | Train Loss: 0.3065538 Vali Loss: 0.3683239 Test Loss: 0.4609763 MAE Loss: 0.4485395\n",
      "lr = 0.0003454980\n",
      "99it [00:13,  7.93it/s]\titers: 100, epoch: 13 | loss: 0.3363740\n",
      "\tspeed: 1.1565s/iter; left time: 34238.7882s\n",
      "199it [00:26,  7.98it/s]\titers: 200, epoch: 13 | loss: 0.3640074\n",
      "\tspeed: 0.1281s/iter; left time: 3780.8571s\n",
      "299it [00:39,  7.86it/s]\titers: 300, epoch: 13 | loss: 0.2458785\n",
      "\tspeed: 0.1281s/iter; left time: 3765.4629s\n",
      "399it [00:51,  7.97it/s]\titers: 400, epoch: 13 | loss: 0.2756783\n",
      "\tspeed: 0.1291s/iter; left time: 3784.0502s\n",
      "499it [01:04,  6.60it/s]\titers: 500, epoch: 13 | loss: 0.2335281\n",
      "\tspeed: 0.1289s/iter; left time: 3764.1565s\n",
      "599it [01:17,  8.02it/s]\titers: 600, epoch: 13 | loss: 0.6429272\n",
      "\tspeed: 0.1288s/iter; left time: 3749.9148s\n",
      "699it [01:30,  7.76it/s]\titers: 700, epoch: 13 | loss: 0.5281091\n",
      "\tspeed: 0.1317s/iter; left time: 3819.6806s\n",
      "799it [01:44,  6.56it/s]\titers: 800, epoch: 13 | loss: 0.1731703\n",
      "\tspeed: 0.1321s/iter; left time: 3818.3824s\n",
      "899it [01:56,  7.75it/s]\titers: 900, epoch: 13 | loss: 0.2627284\n",
      "\tspeed: 0.1285s/iter; left time: 3701.5099s\n",
      "999it [02:10,  7.86it/s]\titers: 1000, epoch: 13 | loss: 0.1809685\n",
      "\tspeed: 0.1321s/iter; left time: 3792.7349s\n",
      "1099it [02:23,  7.62it/s]\titers: 1100, epoch: 13 | loss: 0.4497292\n",
      "\tspeed: 0.1342s/iter; left time: 3837.4096s\n",
      "1199it [02:36,  7.35it/s]\titers: 1200, epoch: 13 | loss: 0.2162245\n",
      "\tspeed: 0.1330s/iter; left time: 3790.8714s\n",
      "1299it [02:50,  7.74it/s]\titers: 1300, epoch: 13 | loss: 0.2238567\n",
      "\tspeed: 0.1314s/iter; left time: 3733.0806s\n",
      "1399it [03:03,  7.84it/s]\titers: 1400, epoch: 13 | loss: 0.2818368\n",
      "\tspeed: 0.1295s/iter; left time: 3666.7009s\n",
      "1499it [03:15,  7.71it/s]\titers: 1500, epoch: 13 | loss: 0.3685950\n",
      "\tspeed: 0.1293s/iter; left time: 3647.4809s\n",
      "1599it [03:28,  7.87it/s]\titers: 1600, epoch: 13 | loss: 0.3698236\n",
      "\tspeed: 0.1297s/iter; left time: 3646.1547s\n",
      "1699it [03:41,  7.90it/s]\titers: 1700, epoch: 13 | loss: 0.2485504\n",
      "\tspeed: 0.1297s/iter; left time: 3632.2469s\n",
      "1799it [03:54,  7.77it/s]\titers: 1800, epoch: 13 | loss: 0.2669769\n",
      "\tspeed: 0.1300s/iter; left time: 3627.2914s\n",
      "1899it [04:07,  7.89it/s]\titers: 1900, epoch: 13 | loss: 0.4667847\n",
      "\tspeed: 0.1283s/iter; left time: 3566.4209s\n",
      "1999it [04:20,  7.74it/s]\titers: 2000, epoch: 13 | loss: 0.2173596\n",
      "\tspeed: 0.1326s/iter; left time: 3673.8088s\n",
      "2099it [04:34,  7.87it/s]\titers: 2100, epoch: 13 | loss: 0.2209276\n",
      "\tspeed: 0.1314s/iter; left time: 3628.1962s\n",
      "2199it [04:47,  7.89it/s]\titers: 2200, epoch: 13 | loss: 0.4442954\n",
      "\tspeed: 0.1290s/iter; left time: 3548.7188s\n",
      "2299it [05:00,  7.78it/s]\titers: 2300, epoch: 13 | loss: 0.3759520\n",
      "\tspeed: 0.1313s/iter; left time: 3597.7875s\n",
      "2399it [05:13,  7.61it/s]\titers: 2400, epoch: 13 | loss: 0.5501200\n",
      "\tspeed: 0.1327s/iter; left time: 3623.4260s\n",
      "2499it [05:26,  7.36it/s]\titers: 2500, epoch: 13 | loss: 0.4024843\n",
      "\tspeed: 0.1328s/iter; left time: 3612.0721s\n",
      "2599it [05:39,  7.72it/s]\titers: 2600, epoch: 13 | loss: 0.1932005\n",
      "\tspeed: 0.1312s/iter; left time: 3556.2496s\n",
      "2699it [05:53,  7.83it/s]\titers: 2700, epoch: 13 | loss: 0.2030459\n",
      "\tspeed: 0.1321s/iter; left time: 3568.3088s\n",
      "2799it [06:06,  7.63it/s]\titers: 2800, epoch: 13 | loss: 0.2934235\n",
      "\tspeed: 0.1317s/iter; left time: 3544.6409s\n",
      "2899it [06:18,  7.90it/s]\titers: 2900, epoch: 13 | loss: 0.4285493\n",
      "\tspeed: 0.1278s/iter; left time: 3426.1214s\n",
      "2999it [06:32,  7.68it/s]\titers: 3000, epoch: 13 | loss: 0.3863086\n",
      "\tspeed: 0.1331s/iter; left time: 3555.2962s\n",
      "3099it [06:45,  7.75it/s]\titers: 3100, epoch: 13 | loss: 0.3603980\n",
      "\tspeed: 0.1337s/iter; left time: 3557.0455s\n",
      "3199it [06:58,  7.58it/s]\titers: 3200, epoch: 13 | loss: 0.2137440\n",
      "\tspeed: 0.1287s/iter; left time: 3412.0791s\n",
      "3299it [07:11,  7.78it/s]\titers: 3300, epoch: 13 | loss: 0.2188578\n",
      "\tspeed: 0.1285s/iter; left time: 3393.0224s\n",
      "3399it [07:24,  7.79it/s]\titers: 3400, epoch: 13 | loss: 0.3768244\n",
      "\tspeed: 0.1313s/iter; left time: 3452.8826s\n",
      "3499it [07:37,  7.79it/s]\titers: 3500, epoch: 13 | loss: 0.2691181\n",
      "\tspeed: 0.1278s/iter; left time: 3348.5358s\n",
      "3599it [07:50,  7.96it/s]\titers: 3600, epoch: 13 | loss: 0.1857215\n",
      "\tspeed: 0.1283s/iter; left time: 3348.0581s\n",
      "3699it [08:03,  7.67it/s]\titers: 3700, epoch: 13 | loss: 0.2113648\n",
      "\tspeed: 0.1303s/iter; left time: 3389.0673s\n",
      "3713it [08:05,  7.66it/s]\n",
      "Epoch: 13 cost time: 485.0195662975311\n",
      "810it [00:49, 16.38it/s]\n",
      "807it [00:50, 16.11it/s]\n",
      "Epoch: 13 | Train Loss: 0.3022796 Vali Loss: 0.3618374 Test Loss: 0.4513295 MAE Loss: 0.4417399\n",
      "lr = 0.0002730120\n",
      "99it [00:13,  7.89it/s]\titers: 100, epoch: 14 | loss: 0.4755971\n",
      "\tspeed: 1.1775s/iter; left time: 30486.9808s\n",
      "199it [00:26,  7.68it/s]\titers: 200, epoch: 14 | loss: 0.4937988\n",
      "\tspeed: 0.1322s/iter; left time: 3409.8632s\n",
      "299it [00:39,  7.50it/s]\titers: 300, epoch: 14 | loss: 0.1939005\n",
      "\tspeed: 0.1346s/iter; left time: 3457.1361s\n",
      "399it [00:53,  7.95it/s]\titers: 400, epoch: 14 | loss: 0.5124890\n",
      "\tspeed: 0.1323s/iter; left time: 3386.0505s\n",
      "499it [01:06,  7.93it/s]\titers: 500, epoch: 14 | loss: 0.2696610\n",
      "\tspeed: 0.1304s/iter; left time: 3324.0154s\n",
      "599it [01:19,  7.62it/s]\titers: 600, epoch: 14 | loss: 0.2908652\n",
      "\tspeed: 0.1303s/iter; left time: 3307.7081s\n",
      "699it [01:32,  7.65it/s]\titers: 700, epoch: 14 | loss: 0.1846792\n",
      "\tspeed: 0.1310s/iter; left time: 3313.9933s\n",
      "799it [01:44,  7.86it/s]\titers: 800, epoch: 14 | loss: 0.2378728\n",
      "\tspeed: 0.1277s/iter; left time: 3216.1648s\n",
      "899it [01:58,  7.92it/s]\titers: 900, epoch: 14 | loss: 0.2225063\n",
      "\tspeed: 0.1313s/iter; left time: 3295.0650s\n",
      "999it [02:11,  7.15it/s]\titers: 1000, epoch: 14 | loss: 0.3362010\n",
      "\tspeed: 0.1315s/iter; left time: 3285.6730s\n",
      "1099it [02:24,  7.73it/s]\titers: 1100, epoch: 14 | loss: 0.2668234\n",
      "\tspeed: 0.1288s/iter; left time: 3206.0033s\n",
      "1199it [02:37,  7.89it/s]\titers: 1200, epoch: 14 | loss: 0.3582336\n",
      "\tspeed: 0.1321s/iter; left time: 3276.0256s\n",
      "1299it [02:50,  7.83it/s]\titers: 1300, epoch: 14 | loss: 0.2051454\n",
      "\tspeed: 0.1336s/iter; left time: 3298.8086s\n",
      "1399it [03:03,  6.23it/s]\titers: 1400, epoch: 14 | loss: 0.2071019\n",
      "\tspeed: 0.1330s/iter; left time: 3270.7416s\n",
      "1499it [03:16,  7.84it/s]\titers: 1500, epoch: 14 | loss: 0.2094268\n",
      "\tspeed: 0.1298s/iter; left time: 3178.7678s\n",
      "1599it [03:30,  7.75it/s]\titers: 1600, epoch: 14 | loss: 0.2260860\n",
      "\tspeed: 0.1319s/iter; left time: 3217.2032s\n",
      "1699it [03:43,  7.82it/s]\titers: 1700, epoch: 14 | loss: 0.2423266\n",
      "\tspeed: 0.1322s/iter; left time: 3210.7010s\n",
      "1799it [03:56,  7.64it/s]\titers: 1800, epoch: 14 | loss: 0.2314711\n",
      "\tspeed: 0.1302s/iter; left time: 3150.6853s\n",
      "1899it [04:09,  7.81it/s]\titers: 1900, epoch: 14 | loss: 0.5312371\n",
      "\tspeed: 0.1329s/iter; left time: 3202.4768s\n",
      "1999it [04:22,  7.63it/s]\titers: 2000, epoch: 14 | loss: 0.1695830\n",
      "\tspeed: 0.1297s/iter; left time: 3112.7563s\n",
      "2099it [04:35,  7.61it/s]\titers: 2100, epoch: 14 | loss: 0.2617297\n",
      "\tspeed: 0.1309s/iter; left time: 3127.1634s\n",
      "2199it [04:48,  7.56it/s]\titers: 2200, epoch: 14 | loss: 0.2946777\n",
      "\tspeed: 0.1323s/iter; left time: 3146.9614s\n",
      "2299it [05:02,  7.83it/s]\titers: 2300, epoch: 14 | loss: 0.3260429\n",
      "\tspeed: 0.1308s/iter; left time: 3099.9737s\n",
      "2399it [05:15,  7.69it/s]\titers: 2400, epoch: 14 | loss: 0.5888684\n",
      "\tspeed: 0.1298s/iter; left time: 3061.2641s\n",
      "2499it [05:28,  7.82it/s]\titers: 2500, epoch: 14 | loss: 0.4731840\n",
      "\tspeed: 0.1317s/iter; left time: 3093.0598s\n",
      "2599it [05:41,  7.59it/s]\titers: 2600, epoch: 14 | loss: 0.4229459\n",
      "\tspeed: 0.1321s/iter; left time: 3090.3311s\n",
      "2699it [05:54,  7.71it/s]\titers: 2700, epoch: 14 | loss: 0.2471594\n",
      "\tspeed: 0.1282s/iter; left time: 2985.8733s\n",
      "2799it [06:07,  7.96it/s]\titers: 2800, epoch: 14 | loss: 0.3193118\n",
      "\tspeed: 0.1336s/iter; left time: 3097.5424s\n",
      "2899it [06:20,  7.74it/s]\titers: 2900, epoch: 14 | loss: 0.4108343\n",
      "\tspeed: 0.1299s/iter; left time: 2998.6096s\n",
      "2999it [06:33,  7.21it/s]\titers: 3000, epoch: 14 | loss: 0.1736975\n",
      "\tspeed: 0.1301s/iter; left time: 2990.8089s\n",
      "3099it [06:46,  7.71it/s]\titers: 3100, epoch: 14 | loss: 0.2235859\n",
      "\tspeed: 0.1313s/iter; left time: 3004.7416s\n",
      "3199it [07:00,  7.74it/s]\titers: 3200, epoch: 14 | loss: 0.2457025\n",
      "\tspeed: 0.1336s/iter; left time: 3045.2450s\n",
      "3299it [07:13,  7.49it/s]\titers: 3300, epoch: 14 | loss: 0.2814765\n",
      "\tspeed: 0.1310s/iter; left time: 2972.3766s\n",
      "3399it [07:26,  7.71it/s]\titers: 3400, epoch: 14 | loss: 0.2147318\n",
      "\tspeed: 0.1297s/iter; left time: 2930.3769s\n",
      "3499it [07:39,  7.83it/s]\titers: 3500, epoch: 14 | loss: 0.2412813\n",
      "\tspeed: 0.1317s/iter; left time: 2961.4606s\n",
      "3599it [07:52,  6.91it/s]\titers: 3600, epoch: 14 | loss: 0.2531735\n",
      "\tspeed: 0.1317s/iter; left time: 2949.5234s\n",
      "3699it [08:05,  7.80it/s]\titers: 3700, epoch: 14 | loss: 0.1618023\n",
      "\tspeed: 0.1295s/iter; left time: 2887.5022s\n",
      "3713it [08:07,  7.62it/s]\n",
      "Epoch: 14 cost time: 487.2845046520233\n",
      "810it [00:48, 16.62it/s]\n",
      "807it [00:49, 16.15it/s]\n",
      "Epoch: 14 | Train Loss: 0.2987254 Vali Loss: 0.3576874 Test Loss: 0.4430876 MAE Loss: 0.4305773\n",
      "lr = 0.0002061153\n",
      "99it [00:13,  7.75it/s]\titers: 100, epoch: 15 | loss: 0.2353320\n",
      "\tspeed: 1.1769s/iter; left time: 26101.9068s\n",
      "199it [00:26,  7.49it/s]\titers: 200, epoch: 15 | loss: 0.3292054\n",
      "\tspeed: 0.1325s/iter; left time: 2926.4512s\n",
      "299it [00:39,  6.96it/s]\titers: 300, epoch: 15 | loss: 0.3044077\n",
      "\tspeed: 0.1289s/iter; left time: 2833.9186s\n",
      "399it [00:52,  7.92it/s]\titers: 400, epoch: 15 | loss: 0.3659534\n",
      "\tspeed: 0.1304s/iter; left time: 2852.9828s\n",
      "499it [01:06,  7.74it/s]\titers: 500, epoch: 15 | loss: 0.1894791\n",
      "\tspeed: 0.1342s/iter; left time: 2921.9719s\n",
      "599it [01:19,  7.00it/s]\titers: 600, epoch: 15 | loss: 0.3411899\n",
      "\tspeed: 0.1307s/iter; left time: 2832.8850s\n",
      "699it [01:32,  7.92it/s]\titers: 700, epoch: 15 | loss: 0.1325692\n",
      "\tspeed: 0.1293s/iter; left time: 2789.9447s\n",
      "799it [01:45,  7.92it/s]\titers: 800, epoch: 15 | loss: 0.2170790\n",
      "\tspeed: 0.1290s/iter; left time: 2769.8560s\n",
      "899it [01:57,  6.80it/s]\titers: 900, epoch: 15 | loss: 0.3053609\n",
      "\tspeed: 0.1282s/iter; left time: 2740.6307s\n",
      "999it [02:10,  7.87it/s]\titers: 1000, epoch: 15 | loss: 0.2961984\n",
      "\tspeed: 0.1313s/iter; left time: 2792.8887s\n",
      "1099it [02:24,  7.86it/s]\titers: 1100, epoch: 15 | loss: 0.3711877\n",
      "\tspeed: 0.1317s/iter; left time: 2790.0513s\n",
      "1199it [02:37,  7.76it/s]\titers: 1200, epoch: 15 | loss: 0.2997461\n",
      "\tspeed: 0.1307s/iter; left time: 2754.0577s\n",
      "1299it [02:50,  7.71it/s]\titers: 1300, epoch: 15 | loss: 0.3191172\n",
      "\tspeed: 0.1305s/iter; left time: 2737.6555s\n",
      "1399it [03:03,  7.85it/s]\titers: 1400, epoch: 15 | loss: 0.4231580\n",
      "\tspeed: 0.1296s/iter; left time: 2705.6100s\n",
      "1499it [03:16,  7.59it/s]\titers: 1500, epoch: 15 | loss: 0.1601920\n",
      "\tspeed: 0.1302s/iter; left time: 2704.4343s\n",
      "1599it [03:29,  7.79it/s]\titers: 1600, epoch: 15 | loss: 0.3274886\n",
      "\tspeed: 0.1292s/iter; left time: 2672.2863s\n",
      "1699it [03:42,  7.69it/s]\titers: 1700, epoch: 15 | loss: 0.2691060\n",
      "\tspeed: 0.1325s/iter; left time: 2727.0206s\n",
      "1799it [03:55,  7.88it/s]\titers: 1800, epoch: 15 | loss: 0.2709500\n",
      "\tspeed: 0.1327s/iter; left time: 2717.6164s\n",
      "1899it [04:08,  7.10it/s]\titers: 1900, epoch: 15 | loss: 0.3565255\n",
      "\tspeed: 0.1308s/iter; left time: 2665.6166s\n",
      "1999it [04:21,  7.68it/s]\titers: 2000, epoch: 15 | loss: 0.3223369\n",
      "\tspeed: 0.1307s/iter; left time: 2650.5786s\n",
      "2099it [04:34,  7.70it/s]\titers: 2100, epoch: 15 | loss: 0.2985791\n",
      "\tspeed: 0.1309s/iter; left time: 2640.6604s\n",
      "2199it [04:47,  7.60it/s]\titers: 2200, epoch: 15 | loss: 0.2233403\n",
      "\tspeed: 0.1298s/iter; left time: 2605.5311s\n",
      "2299it [05:00,  7.91it/s]\titers: 2300, epoch: 15 | loss: 0.3149113\n",
      "\tspeed: 0.1298s/iter; left time: 2592.7437s\n",
      "2399it [05:14,  7.83it/s]\titers: 2400, epoch: 15 | loss: 0.2272493\n",
      "\tspeed: 0.1326s/iter; left time: 2636.6394s\n",
      "2499it [05:27,  6.52it/s]\titers: 2500, epoch: 15 | loss: 0.2959761\n",
      "\tspeed: 0.1340s/iter; left time: 2650.4106s\n",
      "2599it [05:40,  7.84it/s]\titers: 2600, epoch: 15 | loss: 0.3312805\n",
      "\tspeed: 0.1293s/iter; left time: 2543.5266s\n",
      "2699it [05:53,  7.32it/s]\titers: 2700, epoch: 15 | loss: 0.1984944\n",
      "\tspeed: 0.1328s/iter; left time: 2601.0290s\n",
      "2799it [06:07,  7.32it/s]\titers: 2800, epoch: 15 | loss: 0.2295475\n",
      "\tspeed: 0.1333s/iter; left time: 2597.0366s\n",
      "2899it [06:19,  7.78it/s]\titers: 2900, epoch: 15 | loss: 0.1922981\n",
      "\tspeed: 0.1287s/iter; left time: 2493.5818s\n",
      "2999it [06:33,  7.77it/s]\titers: 3000, epoch: 15 | loss: 0.1390029\n",
      "\tspeed: 0.1328s/iter; left time: 2560.7462s\n",
      "3099it [06:46,  7.75it/s]\titers: 3100, epoch: 15 | loss: 0.2850018\n",
      "\tspeed: 0.1310s/iter; left time: 2512.9950s\n",
      "3199it [06:59,  7.61it/s]\titers: 3200, epoch: 15 | loss: 0.4715592\n",
      "\tspeed: 0.1317s/iter; left time: 2513.3104s\n",
      "3299it [07:12,  7.85it/s]\titers: 3300, epoch: 15 | loss: 0.2396106\n",
      "\tspeed: 0.1308s/iter; left time: 2482.6258s\n",
      "3399it [07:25,  7.80it/s]\titers: 3400, epoch: 15 | loss: 0.2126822\n",
      "\tspeed: 0.1298s/iter; left time: 2449.5793s\n",
      "3499it [07:38,  7.43it/s]\titers: 3500, epoch: 15 | loss: 0.1733334\n",
      "\tspeed: 0.1320s/iter; left time: 2479.1866s\n",
      "3599it [07:51,  6.86it/s]\titers: 3600, epoch: 15 | loss: 0.3623030\n",
      "\tspeed: 0.1296s/iter; left time: 2420.3746s\n",
      "3699it [08:04,  7.75it/s]\titers: 3700, epoch: 15 | loss: 0.2445326\n",
      "\tspeed: 0.1312s/iter; left time: 2438.1293s\n",
      "3713it [08:06,  7.63it/s]\n",
      "Epoch: 15 cost time: 486.7254321575165\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:49, 16.28it/s]\n",
      "Epoch: 15 | Train Loss: 0.2904040 Vali Loss: 0.3497226 Test Loss: 0.4324299 MAE Loss: 0.4276436\n",
      "lr = 0.0001464551\n",
      "99it [00:13,  7.47it/s]\titers: 100, epoch: 16 | loss: 0.1861260\n",
      "\tspeed: 1.1669s/iter; left time: 21547.8971s\n",
      "199it [00:26,  7.77it/s]\titers: 200, epoch: 16 | loss: 0.1767844\n",
      "\tspeed: 0.1306s/iter; left time: 2398.8192s\n",
      "299it [00:40,  7.62it/s]\titers: 300, epoch: 16 | loss: 0.1695202\n",
      "\tspeed: 0.1361s/iter; left time: 2485.1061s\n",
      "399it [00:53,  7.89it/s]\titers: 400, epoch: 16 | loss: 0.1533292\n",
      "\tspeed: 0.1341s/iter; left time: 2436.6311s\n",
      "499it [01:06,  7.81it/s]\titers: 500, epoch: 16 | loss: 0.3388799\n",
      "\tspeed: 0.1320s/iter; left time: 2383.9700s\n",
      "599it [01:19,  7.89it/s]\titers: 600, epoch: 16 | loss: 0.3582064\n",
      "\tspeed: 0.1306s/iter; left time: 2346.8012s\n",
      "699it [01:33,  7.84it/s]\titers: 700, epoch: 16 | loss: 0.6211451\n",
      "\tspeed: 0.1340s/iter; left time: 2394.3304s\n",
      "799it [01:46,  7.82it/s]\titers: 800, epoch: 16 | loss: 0.4362165\n",
      "\tspeed: 0.1335s/iter; left time: 2371.2231s\n",
      "899it [01:59,  7.07it/s]\titers: 900, epoch: 16 | loss: 0.2294557\n",
      "\tspeed: 0.1310s/iter; left time: 2314.7693s\n",
      "999it [02:12,  7.75it/s]\titers: 1000, epoch: 16 | loss: 0.3457487\n",
      "\tspeed: 0.1333s/iter; left time: 2341.2381s\n",
      "1099it [02:26,  7.44it/s]\titers: 1100, epoch: 16 | loss: 0.2124871\n",
      "\tspeed: 0.1373s/iter; left time: 2397.9776s\n",
      "1199it [02:39,  7.78it/s]\titers: 1200, epoch: 16 | loss: 0.3403161\n",
      "\tspeed: 0.1293s/iter; left time: 2246.0756s\n",
      "1299it [02:52,  7.99it/s]\titers: 1300, epoch: 16 | loss: 0.1891805\n",
      "\tspeed: 0.1304s/iter; left time: 2251.1429s\n",
      "1399it [03:05,  8.02it/s]\titers: 1400, epoch: 16 | loss: 0.2910257\n",
      "\tspeed: 0.1286s/iter; left time: 2208.2694s\n",
      "1499it [03:18,  7.98it/s]\titers: 1500, epoch: 16 | loss: 0.3099553\n",
      "\tspeed: 0.1283s/iter; left time: 2189.0190s\n",
      "1599it [03:31,  7.92it/s]\titers: 1600, epoch: 16 | loss: 0.2545178\n",
      "\tspeed: 0.1298s/iter; left time: 2202.6214s\n",
      "1699it [03:44,  8.02it/s]\titers: 1700, epoch: 16 | loss: 0.5039687\n",
      "\tspeed: 0.1293s/iter; left time: 2180.2458s\n",
      "1799it [03:57,  7.51it/s]\titers: 1800, epoch: 16 | loss: 0.3732177\n",
      "\tspeed: 0.1294s/iter; left time: 2169.7061s\n",
      "1899it [04:09,  7.95it/s]\titers: 1900, epoch: 16 | loss: 0.1803452\n",
      "\tspeed: 0.1260s/iter; left time: 2099.2757s\n",
      "1999it [04:22,  7.95it/s]\titers: 2000, epoch: 16 | loss: 0.1640476\n",
      "\tspeed: 0.1305s/iter; left time: 2161.5992s\n",
      "2099it [04:35,  8.03it/s]\titers: 2100, epoch: 16 | loss: 0.2665240\n",
      "\tspeed: 0.1288s/iter; left time: 2121.1819s\n",
      "2199it [04:48,  7.79it/s]\titers: 2200, epoch: 16 | loss: 0.3570365\n",
      "\tspeed: 0.1277s/iter; left time: 2089.3825s\n",
      "2299it [05:01,  7.88it/s]\titers: 2300, epoch: 16 | loss: 0.4647745\n",
      "\tspeed: 0.1280s/iter; left time: 2081.2615s\n",
      "2399it [05:14,  7.78it/s]\titers: 2400, epoch: 16 | loss: 0.1857308\n",
      "\tspeed: 0.1287s/iter; left time: 2080.7052s\n",
      "2499it [05:27,  7.82it/s]\titers: 2500, epoch: 16 | loss: 0.2017089\n",
      "\tspeed: 0.1285s/iter; left time: 2063.7977s\n",
      "2599it [05:39,  7.91it/s]\titers: 2600, epoch: 16 | loss: 0.4566964\n",
      "\tspeed: 0.1271s/iter; left time: 2029.3354s\n",
      "2699it [05:52,  7.85it/s]\titers: 2700, epoch: 16 | loss: 0.2925663\n",
      "\tspeed: 0.1305s/iter; left time: 2070.5098s\n",
      "2799it [06:05,  7.95it/s]\titers: 2800, epoch: 16 | loss: 0.2202639\n",
      "\tspeed: 0.1303s/iter; left time: 2054.0940s\n",
      "2899it [06:18,  7.24it/s]\titers: 2900, epoch: 16 | loss: 0.3928232\n",
      "\tspeed: 0.1281s/iter; left time: 2006.9880s\n",
      "2999it [06:31,  7.94it/s]\titers: 3000, epoch: 16 | loss: 0.3039874\n",
      "\tspeed: 0.1284s/iter; left time: 1998.6201s\n",
      "3099it [06:44,  8.01it/s]\titers: 3100, epoch: 16 | loss: 0.2731483\n",
      "\tspeed: 0.1284s/iter; left time: 1985.6006s\n",
      "3199it [06:57,  7.85it/s]\titers: 3200, epoch: 16 | loss: 0.4619856\n",
      "\tspeed: 0.1270s/iter; left time: 1951.5617s\n",
      "3299it [07:09,  7.94it/s]\titers: 3300, epoch: 16 | loss: 0.1495067\n",
      "\tspeed: 0.1283s/iter; left time: 1959.3258s\n",
      "3399it [07:22,  8.01it/s]\titers: 3400, epoch: 16 | loss: 0.2597162\n",
      "\tspeed: 0.1305s/iter; left time: 1979.7944s\n",
      "3499it [07:35,  7.83it/s]\titers: 3500, epoch: 16 | loss: 0.2072920\n",
      "\tspeed: 0.1289s/iter; left time: 1942.2016s\n",
      "3599it [07:48,  7.06it/s]\titers: 3600, epoch: 16 | loss: 0.2320128\n",
      "\tspeed: 0.1274s/iter; left time: 1906.1780s\n",
      "3699it [08:01,  7.47it/s]\titers: 3700, epoch: 16 | loss: 0.2333990\n",
      "\tspeed: 0.1286s/iter; left time: 1911.5070s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 16 cost time: 483.26137375831604\n",
      "810it [00:48, 16.73it/s]\n",
      "807it [00:48, 16.69it/s]\n",
      "Epoch: 16 | Train Loss: 0.2896346 Vali Loss: 0.3507182 Test Loss: 0.4344943 MAE Loss: 0.4307301\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000955005\n",
      "99it [00:13,  7.86it/s]\titers: 100, epoch: 17 | loss: 0.2886153\n",
      "\tspeed: 1.1176s/iter; left time: 16488.6253s\n",
      "199it [00:25,  7.91it/s]\titers: 200, epoch: 17 | loss: 0.1521192\n",
      "\tspeed: 0.1272s/iter; left time: 1864.0853s\n",
      "299it [00:38,  7.85it/s]\titers: 300, epoch: 17 | loss: 0.1269865\n",
      "\tspeed: 0.1306s/iter; left time: 1901.3037s\n",
      "399it [00:51,  7.95it/s]\titers: 400, epoch: 17 | loss: 0.3803651\n",
      "\tspeed: 0.1270s/iter; left time: 1836.1327s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 17 | loss: 0.2037760\n",
      "\tspeed: 0.1274s/iter; left time: 1828.3165s\n",
      "599it [01:17,  7.61it/s]\titers: 600, epoch: 17 | loss: 0.3450657\n",
      "\tspeed: 0.1301s/iter; left time: 1853.7242s\n",
      "699it [01:30,  7.69it/s]\titers: 700, epoch: 17 | loss: 0.2402654\n",
      "\tspeed: 0.1290s/iter; left time: 1825.5258s\n",
      "799it [01:42,  7.58it/s]\titers: 800, epoch: 17 | loss: 0.2436413\n",
      "\tspeed: 0.1276s/iter; left time: 1792.6871s\n",
      "899it [01:55,  7.68it/s]\titers: 900, epoch: 17 | loss: 0.2765182\n",
      "\tspeed: 0.1301s/iter; left time: 1814.7131s\n",
      "999it [02:08,  7.98it/s]\titers: 1000, epoch: 17 | loss: 0.2652180\n",
      "\tspeed: 0.1298s/iter; left time: 1797.8715s\n",
      "1099it [02:21,  7.92it/s]\titers: 1100, epoch: 17 | loss: 0.3413520\n",
      "\tspeed: 0.1288s/iter; left time: 1771.8964s\n",
      "1199it [02:34,  7.95it/s]\titers: 1200, epoch: 17 | loss: 0.1930054\n",
      "\tspeed: 0.1280s/iter; left time: 1747.6868s\n",
      "1299it [02:47,  8.10it/s]\titers: 1300, epoch: 17 | loss: 0.4490595\n",
      "\tspeed: 0.1285s/iter; left time: 1741.6409s\n",
      "1399it [03:00,  7.86it/s]\titers: 1400, epoch: 17 | loss: 0.6068544\n",
      "\tspeed: 0.1292s/iter; left time: 1738.5577s\n",
      "1499it [03:13,  7.82it/s]\titers: 1500, epoch: 17 | loss: 0.2249237\n",
      "\tspeed: 0.1286s/iter; left time: 1717.4378s\n",
      "1599it [03:26,  7.84it/s]\titers: 1600, epoch: 17 | loss: 0.2344005\n",
      "\tspeed: 0.1294s/iter; left time: 1714.6548s\n",
      "1699it [03:39,  7.77it/s]\titers: 1700, epoch: 17 | loss: 0.2375891\n",
      "\tspeed: 0.1312s/iter; left time: 1725.0304s\n",
      "1799it [03:52,  7.77it/s]\titers: 1800, epoch: 17 | loss: 0.3281684\n",
      "\tspeed: 0.1279s/iter; left time: 1669.7394s\n",
      "1899it [04:05,  7.36it/s]\titers: 1900, epoch: 17 | loss: 0.3739150\n",
      "\tspeed: 0.1321s/iter; left time: 1711.4503s\n",
      "1999it [04:18,  7.97it/s]\titers: 2000, epoch: 17 | loss: 0.2851160\n",
      "\tspeed: 0.1299s/iter; left time: 1669.0053s\n",
      "2099it [04:31,  7.83it/s]\titers: 2100, epoch: 17 | loss: 0.3748374\n",
      "\tspeed: 0.1279s/iter; left time: 1631.2669s\n",
      "2199it [04:44,  7.62it/s]\titers: 2200, epoch: 17 | loss: 0.2040289\n",
      "\tspeed: 0.1301s/iter; left time: 1646.1764s\n",
      "2299it [04:56,  8.01it/s]\titers: 2300, epoch: 17 | loss: 0.2245248\n",
      "\tspeed: 0.1291s/iter; left time: 1620.8617s\n",
      "2399it [05:09,  7.94it/s]\titers: 2400, epoch: 17 | loss: 0.2705359\n",
      "\tspeed: 0.1280s/iter; left time: 1593.5619s\n",
      "2499it [05:22,  7.57it/s]\titers: 2500, epoch: 17 | loss: 0.3253122\n",
      "\tspeed: 0.1263s/iter; left time: 1560.1805s\n",
      "2599it [05:35,  7.56it/s]\titers: 2600, epoch: 17 | loss: 0.1431143\n",
      "\tspeed: 0.1289s/iter; left time: 1579.8357s\n",
      "2699it [05:48,  7.83it/s]\titers: 2700, epoch: 17 | loss: 0.1145093\n",
      "\tspeed: 0.1305s/iter; left time: 1586.2359s\n",
      "2799it [06:01,  7.64it/s]\titers: 2800, epoch: 17 | loss: 0.4969672\n",
      "\tspeed: 0.1283s/iter; left time: 1546.7589s\n",
      "2899it [06:13,  7.96it/s]\titers: 2900, epoch: 17 | loss: 0.5124037\n",
      "\tspeed: 0.1277s/iter; left time: 1526.5471s\n",
      "2999it [06:26,  8.04it/s]\titers: 3000, epoch: 17 | loss: 0.5197293\n",
      "\tspeed: 0.1287s/iter; left time: 1525.5053s\n",
      "3099it [06:39,  7.88it/s]\titers: 3100, epoch: 17 | loss: 0.2230427\n",
      "\tspeed: 0.1277s/iter; left time: 1500.4461s\n",
      "3199it [06:52,  8.00it/s]\titers: 3200, epoch: 17 | loss: 0.4513548\n",
      "\tspeed: 0.1284s/iter; left time: 1496.1837s\n",
      "3299it [07:05,  7.89it/s]\titers: 3300, epoch: 17 | loss: 0.3612390\n",
      "\tspeed: 0.1295s/iter; left time: 1496.5267s\n",
      "3399it [07:18,  7.79it/s]\titers: 3400, epoch: 17 | loss: 0.2907190\n",
      "\tspeed: 0.1295s/iter; left time: 1482.6471s\n",
      "3499it [07:31,  7.71it/s]\titers: 3500, epoch: 17 | loss: 0.2137356\n",
      "\tspeed: 0.1276s/iter; left time: 1448.2261s\n",
      "3599it [07:43,  7.76it/s]\titers: 3600, epoch: 17 | loss: 0.1934652\n",
      "\tspeed: 0.1279s/iter; left time: 1439.7937s\n",
      "3699it [07:56,  7.90it/s]\titers: 3700, epoch: 17 | loss: 0.4378054\n",
      "\tspeed: 0.1284s/iter; left time: 1431.7193s\n",
      "3713it [07:58,  7.76it/s]\n",
      "Epoch: 17 cost time: 478.550164937973\n",
      "810it [00:47, 16.89it/s]\n",
      "807it [00:48, 16.75it/s]\n",
      "Epoch: 17 | Train Loss: 0.2851446 Vali Loss: 0.3439783 Test Loss: 0.4263099 MAE Loss: 0.4231231\n",
      "lr = 0.0000545062\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 18 | loss: 0.3329677\n",
      "\tspeed: 1.1441s/iter; left time: 12630.8337s\n",
      "199it [00:25,  7.88it/s]\titers: 200, epoch: 18 | loss: 0.2575828\n",
      "\tspeed: 0.1286s/iter; left time: 1407.1362s\n",
      "299it [00:38,  7.88it/s]\titers: 300, epoch: 18 | loss: 0.1765651\n",
      "\tspeed: 0.1273s/iter; left time: 1379.4930s\n",
      "399it [00:51,  7.93it/s]\titers: 400, epoch: 18 | loss: 0.2640049\n",
      "\tspeed: 0.1278s/iter; left time: 1373.0121s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 18 | loss: 0.3224196\n",
      "\tspeed: 0.1291s/iter; left time: 1373.8698s\n",
      "599it [01:17,  7.78it/s]\titers: 600, epoch: 18 | loss: 0.1794068\n",
      "\tspeed: 0.1281s/iter; left time: 1350.3175s\n",
      "699it [01:29,  7.60it/s]\titers: 700, epoch: 18 | loss: 0.3325299\n",
      "\tspeed: 0.1259s/iter; left time: 1314.5621s\n",
      "799it [01:42,  8.04it/s]\titers: 800, epoch: 18 | loss: 0.2906775\n",
      "\tspeed: 0.1290s/iter; left time: 1333.3985s\n",
      "899it [01:55,  7.83it/s]\titers: 900, epoch: 18 | loss: 0.4680055\n",
      "\tspeed: 0.1288s/iter; left time: 1318.9278s\n",
      "999it [02:08,  7.82it/s]\titers: 1000, epoch: 18 | loss: 0.2280695\n",
      "\tspeed: 0.1277s/iter; left time: 1295.1997s\n",
      "1099it [02:21,  7.73it/s]\titers: 1100, epoch: 18 | loss: 0.3151264\n",
      "\tspeed: 0.1283s/iter; left time: 1288.5462s\n",
      "1199it [02:33,  8.00it/s]\titers: 1200, epoch: 18 | loss: 0.1943336\n",
      "\tspeed: 0.1279s/iter; left time: 1271.1642s\n",
      "1299it [02:46,  6.42it/s]\titers: 1300, epoch: 18 | loss: 0.4807726\n",
      "\tspeed: 0.1280s/iter; left time: 1259.8359s\n",
      "1399it [02:59,  7.58it/s]\titers: 1400, epoch: 18 | loss: 0.1760294\n",
      "\tspeed: 0.1269s/iter; left time: 1235.8635s\n",
      "1499it [03:12,  7.99it/s]\titers: 1500, epoch: 18 | loss: 0.2912110\n",
      "\tspeed: 0.1282s/iter; left time: 1235.5841s\n",
      "1599it [03:25,  8.08it/s]\titers: 1600, epoch: 18 | loss: 0.4577796\n",
      "\tspeed: 0.1282s/iter; left time: 1222.9742s\n",
      "1699it [03:37,  7.68it/s]\titers: 1700, epoch: 18 | loss: 0.1651925\n",
      "\tspeed: 0.1273s/iter; left time: 1201.3672s\n",
      "1799it [03:50,  8.07it/s]\titers: 1800, epoch: 18 | loss: 0.1767547\n",
      "\tspeed: 0.1277s/iter; left time: 1192.8318s\n",
      "1899it [04:03,  8.00it/s]\titers: 1900, epoch: 18 | loss: 0.5720109\n",
      "\tspeed: 0.1293s/iter; left time: 1194.3509s\n",
      "1999it [04:16,  7.25it/s]\titers: 2000, epoch: 18 | loss: 0.2140196\n",
      "\tspeed: 0.1285s/iter; left time: 1174.5562s\n",
      "2099it [04:29,  7.82it/s]\titers: 2100, epoch: 18 | loss: 0.2658590\n",
      "\tspeed: 0.1279s/iter; left time: 1156.5780s\n",
      "2199it [04:42,  7.64it/s]\titers: 2200, epoch: 18 | loss: 0.3156388\n",
      "\tspeed: 0.1311s/iter; left time: 1171.7019s\n",
      "2299it [04:55,  7.97it/s]\titers: 2300, epoch: 18 | loss: 0.2038364\n",
      "\tspeed: 0.1295s/iter; left time: 1144.5797s\n",
      "2399it [05:07,  7.50it/s]\titers: 2400, epoch: 18 | loss: 0.2096113\n",
      "\tspeed: 0.1286s/iter; left time: 1123.5941s\n",
      "2499it [05:21,  7.58it/s]\titers: 2500, epoch: 18 | loss: 0.1682891\n",
      "\tspeed: 0.1314s/iter; left time: 1135.6233s\n",
      "2599it [05:34,  7.69it/s]\titers: 2600, epoch: 18 | loss: 0.4195050\n",
      "\tspeed: 0.1296s/iter; left time: 1106.5708s\n",
      "2699it [05:47,  7.32it/s]\titers: 2700, epoch: 18 | loss: 0.1885891\n",
      "\tspeed: 0.1309s/iter; left time: 1104.8437s\n",
      "2799it [05:59,  7.41it/s]\titers: 2800, epoch: 18 | loss: 0.2885799\n",
      "\tspeed: 0.1272s/iter; left time: 1060.9185s\n",
      "2899it [06:12,  7.97it/s]\titers: 2900, epoch: 18 | loss: 0.1885973\n",
      "\tspeed: 0.1292s/iter; left time: 1064.3687s\n",
      "2999it [06:25,  8.02it/s]\titers: 3000, epoch: 18 | loss: 0.3157410\n",
      "\tspeed: 0.1279s/iter; left time: 1040.9552s\n",
      "3099it [06:38,  7.81it/s]\titers: 3100, epoch: 18 | loss: 0.1815318\n",
      "\tspeed: 0.1281s/iter; left time: 1029.9836s\n",
      "3199it [06:51,  7.46it/s]\titers: 3200, epoch: 18 | loss: 0.2727541\n",
      "\tspeed: 0.1277s/iter; left time: 1014.2258s\n",
      "3299it [07:04,  8.01it/s]\titers: 3300, epoch: 18 | loss: 0.2843535\n",
      "\tspeed: 0.1295s/iter; left time: 1014.8999s\n",
      "3399it [07:17,  7.86it/s]\titers: 3400, epoch: 18 | loss: 0.1880093\n",
      "\tspeed: 0.1288s/iter; left time: 996.5449s\n",
      "3499it [07:29,  7.68it/s]\titers: 3500, epoch: 18 | loss: 0.2316481\n",
      "\tspeed: 0.1264s/iter; left time: 965.6923s\n",
      "3599it [07:42,  7.92it/s]\titers: 3600, epoch: 18 | loss: 0.2278130\n",
      "\tspeed: 0.1284s/iter; left time: 968.1911s\n",
      "3699it [07:55,  7.89it/s]\titers: 3700, epoch: 18 | loss: 0.3258895\n",
      "\tspeed: 0.1287s/iter; left time: 957.3414s\n",
      "3713it [07:57,  7.78it/s]\n",
      "Epoch: 18 cost time: 477.18381214141846\n",
      "810it [00:48, 16.79it/s]\n",
      "807it [00:47, 16.82it/s]\n",
      "Epoch: 18 | Train Loss: 0.2818938 Vali Loss: 0.3431476 Test Loss: 0.4251187 MAE Loss: 0.4230486\n",
      "lr = 0.0000244815\n",
      "99it [00:13,  7.96it/s]\titers: 100, epoch: 19 | loss: 0.3231862\n",
      "\tspeed: 1.1480s/iter; left time: 8411.2409s\n",
      "199it [00:25,  7.70it/s]\titers: 200, epoch: 19 | loss: 0.2902018\n",
      "\tspeed: 0.1287s/iter; left time: 929.9664s\n",
      "299it [00:38,  7.91it/s]\titers: 300, epoch: 19 | loss: 0.3231234\n",
      "\tspeed: 0.1285s/iter; left time: 916.0933s\n",
      "399it [00:51,  7.58it/s]\titers: 400, epoch: 19 | loss: 0.2864132\n",
      "\tspeed: 0.1259s/iter; left time: 884.3783s\n",
      "499it [01:04,  7.63it/s]\titers: 500, epoch: 19 | loss: 0.2952008\n",
      "\tspeed: 0.1289s/iter; left time: 892.8428s\n",
      "599it [01:17,  8.02it/s]\titers: 600, epoch: 19 | loss: 0.2018728\n",
      "\tspeed: 0.1335s/iter; left time: 911.5230s\n",
      "699it [01:30,  7.59it/s]\titers: 700, epoch: 19 | loss: 0.4377728\n",
      "\tspeed: 0.1274s/iter; left time: 857.0629s\n",
      "799it [01:43,  7.96it/s]\titers: 800, epoch: 19 | loss: 0.3378433\n",
      "\tspeed: 0.1276s/iter; left time: 845.9074s\n",
      "899it [01:56,  7.90it/s]\titers: 900, epoch: 19 | loss: 0.2063994\n",
      "\tspeed: 0.1287s/iter; left time: 839.7220s\n",
      "999it [02:08,  7.91it/s]\titers: 1000, epoch: 19 | loss: 0.3694931\n",
      "\tspeed: 0.1275s/iter; left time: 819.2119s\n",
      "1099it [02:21,  7.99it/s]\titers: 1100, epoch: 19 | loss: 0.3364376\n",
      "\tspeed: 0.1278s/iter; left time: 808.6942s\n",
      "1199it [02:34,  8.02it/s]\titers: 1200, epoch: 19 | loss: 0.3416563\n",
      "\tspeed: 0.1291s/iter; left time: 804.1307s\n",
      "1299it [02:47,  7.97it/s]\titers: 1300, epoch: 19 | loss: 0.1821789\n",
      "\tspeed: 0.1286s/iter; left time: 787.9134s\n",
      "1399it [03:00,  7.68it/s]\titers: 1400, epoch: 19 | loss: 0.2529828\n",
      "\tspeed: 0.1275s/iter; left time: 768.5814s\n",
      "1499it [03:12,  8.01it/s]\titers: 1500, epoch: 19 | loss: 0.3169283\n",
      "\tspeed: 0.1277s/iter; left time: 756.7978s\n",
      "1599it [03:25,  7.89it/s]\titers: 1600, epoch: 19 | loss: 0.4366460\n",
      "\tspeed: 0.1290s/iter; left time: 751.6298s\n",
      "1699it [03:38,  6.69it/s]\titers: 1700, epoch: 19 | loss: 0.2569892\n",
      "\tspeed: 0.1297s/iter; left time: 742.5425s\n",
      "1799it [03:51,  7.84it/s]\titers: 1800, epoch: 19 | loss: 0.2051529\n",
      "\tspeed: 0.1267s/iter; left time: 712.7902s\n",
      "1899it [04:04,  7.88it/s]\titers: 1900, epoch: 19 | loss: 0.3925875\n",
      "\tspeed: 0.1303s/iter; left time: 720.0739s\n",
      "1999it [04:17,  8.01it/s]\titers: 2000, epoch: 19 | loss: 0.2824491\n",
      "\tspeed: 0.1284s/iter; left time: 696.9412s\n",
      "2099it [04:30,  7.91it/s]\titers: 2100, epoch: 19 | loss: 0.1650740\n",
      "\tspeed: 0.1276s/iter; left time: 679.6337s\n",
      "2199it [04:42,  7.66it/s]\titers: 2200, epoch: 19 | loss: 0.2945198\n",
      "\tspeed: 0.1283s/iter; left time: 670.3964s\n",
      "2299it [04:55,  7.92it/s]\titers: 2300, epoch: 19 | loss: 0.5822414\n",
      "\tspeed: 0.1288s/iter; left time: 660.3531s\n",
      "2399it [05:08,  6.94it/s]\titers: 2400, epoch: 19 | loss: 0.2541802\n",
      "\tspeed: 0.1296s/iter; left time: 651.2677s\n",
      "2499it [05:21,  7.19it/s]\titers: 2500, epoch: 19 | loss: 0.3122996\n",
      "\tspeed: 0.1311s/iter; left time: 645.8778s\n",
      "2599it [05:34,  8.07it/s]\titers: 2600, epoch: 19 | loss: 0.3651050\n",
      "\tspeed: 0.1285s/iter; left time: 620.0868s\n",
      "2699it [05:47,  7.67it/s]\titers: 2700, epoch: 19 | loss: 0.1750141\n",
      "\tspeed: 0.1307s/iter; left time: 617.6676s\n",
      "2799it [06:00,  7.69it/s]\titers: 2800, epoch: 19 | loss: 0.3191998\n",
      "\tspeed: 0.1302s/iter; left time: 602.3877s\n",
      "2899it [06:13,  7.76it/s]\titers: 2900, epoch: 19 | loss: 0.2538366\n",
      "\tspeed: 0.1294s/iter; left time: 585.9877s\n",
      "2999it [06:26,  7.80it/s]\titers: 3000, epoch: 19 | loss: 0.2005800\n",
      "\tspeed: 0.1293s/iter; left time: 572.5579s\n",
      "3099it [06:39,  7.65it/s]\titers: 3100, epoch: 19 | loss: 0.2404605\n",
      "\tspeed: 0.1309s/iter; left time: 566.5372s\n",
      "3199it [06:52,  7.72it/s]\titers: 3200, epoch: 19 | loss: 0.3099367\n",
      "\tspeed: 0.1312s/iter; left time: 554.7385s\n",
      "3299it [07:05,  7.72it/s]\titers: 3300, epoch: 19 | loss: 0.5230960\n",
      "\tspeed: 0.1293s/iter; left time: 533.4299s\n",
      "3399it [07:18,  7.95it/s]\titers: 3400, epoch: 19 | loss: 0.3983754\n",
      "\tspeed: 0.1323s/iter; left time: 532.6848s\n",
      "3499it [07:31,  7.80it/s]\titers: 3500, epoch: 19 | loss: 0.3132668\n",
      "\tspeed: 0.1290s/iter; left time: 506.4156s\n",
      "3599it [07:44,  7.60it/s]\titers: 3600, epoch: 19 | loss: 0.2824549\n",
      "\tspeed: 0.1291s/iter; left time: 494.2350s\n",
      "3699it [07:57,  7.92it/s]\titers: 3700, epoch: 19 | loss: 0.3821140\n",
      "\tspeed: 0.1296s/iter; left time: 483.1581s\n",
      "3713it [07:59,  7.74it/s]\n",
      "Epoch: 19 cost time: 479.59899163246155\n",
      "810it [00:48, 16.73it/s]\n",
      "807it [00:48, 16.54it/s]\n",
      "Epoch: 19 | Train Loss: 0.2808887 Vali Loss: 0.3445619 Test Loss: 0.4261527 MAE Loss: 0.4264147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000061658\n",
      "99it [00:13,  7.70it/s]\titers: 100, epoch: 20 | loss: 0.2526909\n",
      "\tspeed: 1.1239s/iter; left time: 4061.5981s\n",
      "199it [00:26,  7.70it/s]\titers: 200, epoch: 20 | loss: 0.2030843\n",
      "\tspeed: 0.1307s/iter; left time: 459.1413s\n",
      "299it [00:39,  8.03it/s]\titers: 300, epoch: 20 | loss: 0.2638560\n",
      "\tspeed: 0.1314s/iter; left time: 448.4845s\n",
      "399it [00:52,  7.86it/s]\titers: 400, epoch: 20 | loss: 0.2450883\n",
      "\tspeed: 0.1300s/iter; left time: 430.9079s\n",
      "499it [01:05,  7.75it/s]\titers: 500, epoch: 20 | loss: 0.2361744\n",
      "\tspeed: 0.1282s/iter; left time: 412.1153s\n",
      "599it [01:18,  7.96it/s]\titers: 600, epoch: 20 | loss: 0.1980131\n",
      "\tspeed: 0.1292s/iter; left time: 402.3029s\n",
      "699it [01:31,  7.97it/s]\titers: 700, epoch: 20 | loss: 0.3825595\n",
      "\tspeed: 0.1289s/iter; left time: 388.5415s\n",
      "799it [01:43,  7.83it/s]\titers: 800, epoch: 20 | loss: 0.1336034\n",
      "\tspeed: 0.1277s/iter; left time: 372.1399s\n",
      "899it [01:56,  7.60it/s]\titers: 900, epoch: 20 | loss: 0.3303688\n",
      "\tspeed: 0.1287s/iter; left time: 362.0651s\n",
      "999it [02:09,  7.95it/s]\titers: 1000, epoch: 20 | loss: 0.2278752\n",
      "\tspeed: 0.1307s/iter; left time: 354.7756s\n",
      "1099it [02:22,  7.88it/s]\titers: 1100, epoch: 20 | loss: 0.1569596\n",
      "\tspeed: 0.1291s/iter; left time: 337.5476s\n",
      "1199it [02:35,  7.89it/s]\titers: 1200, epoch: 20 | loss: 0.2233342\n",
      "\tspeed: 0.1280s/iter; left time: 321.8290s\n",
      "1299it [02:48,  7.76it/s]\titers: 1300, epoch: 20 | loss: 0.3263616\n",
      "\tspeed: 0.1284s/iter; left time: 309.8561s\n",
      "1399it [03:01,  7.90it/s]\titers: 1400, epoch: 20 | loss: 0.3985030\n",
      "\tspeed: 0.1307s/iter; left time: 302.4910s\n",
      "1499it [03:14,  7.16it/s]\titers: 1500, epoch: 20 | loss: 0.2953323\n",
      "\tspeed: 0.1302s/iter; left time: 288.3417s\n",
      "1599it [03:27,  7.81it/s]\titers: 1600, epoch: 20 | loss: 0.4013351\n",
      "\tspeed: 0.1279s/iter; left time: 270.4134s\n",
      "1699it [03:40,  7.72it/s]\titers: 1700, epoch: 20 | loss: 0.1585270\n",
      "\tspeed: 0.1304s/iter; left time: 262.5846s\n",
      "1799it [03:53,  7.37it/s]\titers: 1800, epoch: 20 | loss: 0.2059319\n",
      "\tspeed: 0.1320s/iter; left time: 252.6315s\n",
      "1899it [04:06,  7.88it/s]\titers: 1900, epoch: 20 | loss: 0.1659470\n",
      "\tspeed: 0.1282s/iter; left time: 232.6291s\n",
      "1999it [04:19,  7.92it/s]\titers: 2000, epoch: 20 | loss: 0.3189528\n",
      "\tspeed: 0.1278s/iter; left time: 219.0644s\n",
      "2099it [04:31,  7.79it/s]\titers: 2100, epoch: 20 | loss: 0.3272199\n",
      "\tspeed: 0.1291s/iter; left time: 208.3164s\n",
      "2199it [04:44,  7.93it/s]\titers: 2200, epoch: 20 | loss: 0.1735636\n",
      "\tspeed: 0.1286s/iter; left time: 194.7156s\n",
      "2299it [04:57,  7.83it/s]\titers: 2300, epoch: 20 | loss: 0.2227974\n",
      "\tspeed: 0.1292s/iter; left time: 182.6533s\n",
      "2399it [05:10,  7.63it/s]\titers: 2400, epoch: 20 | loss: 0.2269403\n",
      "\tspeed: 0.1276s/iter; left time: 167.6395s\n",
      "2499it [05:23,  7.92it/s]\titers: 2500, epoch: 20 | loss: 0.3882084\n",
      "\tspeed: 0.1297s/iter; left time: 157.4350s\n",
      "2599it [05:36,  7.60it/s]\titers: 2600, epoch: 20 | loss: 0.2199817\n",
      "\tspeed: 0.1293s/iter; left time: 144.0565s\n",
      "2699it [05:49,  7.43it/s]\titers: 2700, epoch: 20 | loss: 0.2882137\n",
      "\tspeed: 0.1281s/iter; left time: 129.9079s\n",
      "2799it [06:02,  7.90it/s]\titers: 2800, epoch: 20 | loss: 0.2681598\n",
      "\tspeed: 0.1288s/iter; left time: 117.7404s\n",
      "2899it [06:15,  7.82it/s]\titers: 2900, epoch: 20 | loss: 0.2051983\n",
      "\tspeed: 0.1296s/iter; left time: 105.4827s\n",
      "2999it [06:27,  7.71it/s]\titers: 3000, epoch: 20 | loss: 0.2666871\n",
      "\tspeed: 0.1292s/iter; left time: 92.2643s\n",
      "3099it [06:40,  7.88it/s]\titers: 3100, epoch: 20 | loss: 0.1687871\n",
      "\tspeed: 0.1287s/iter; left time: 79.0008s\n",
      "3199it [06:53,  7.90it/s]\titers: 3200, epoch: 20 | loss: 0.2888637\n",
      "\tspeed: 0.1291s/iter; left time: 66.3527s\n",
      "3299it [07:06,  7.61it/s]\titers: 3300, epoch: 20 | loss: 0.2770034\n",
      "\tspeed: 0.1299s/iter; left time: 53.7666s\n",
      "3399it [07:19,  7.40it/s]\titers: 3400, epoch: 20 | loss: 0.1920416\n",
      "\tspeed: 0.1285s/iter; left time: 40.3379s\n",
      "3499it [07:32,  7.90it/s]\titers: 3500, epoch: 20 | loss: 0.2849917\n",
      "\tspeed: 0.1289s/iter; left time: 27.5749s\n",
      "3599it [07:45,  7.72it/s]\titers: 3600, epoch: 20 | loss: 0.4497917\n",
      "\tspeed: 0.1298s/iter; left time: 14.7965s\n",
      "3699it [07:58,  7.82it/s]\titers: 3700, epoch: 20 | loss: 0.3295776\n",
      "\tspeed: 0.1286s/iter; left time: 1.8002s\n",
      "3713it [08:00,  7.73it/s]\n",
      "Epoch: 20 cost time: 480.29611682891846\n",
      "810it [00:48, 16.77it/s]\n",
      "807it [00:48, 16.67it/s]\n",
      "Epoch: 20 | Train Loss: 0.2792270 Vali Loss: 0.3419906 Test Loss: 0.4223526 MAE Loss: 0.4208767\n",
      "lr = 0.0000000100\n",
      "Total time: 204.96061081091563 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small, 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 20:07:53,719] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 20:07:54,569] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 20:07:54,569] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 20:07:54,569] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 20:07:55,484] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 20:07:55,484] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 20:07:56,098] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 20:07:56,099] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 20:07:56,100] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 20:07:56,101] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 20:07:56,101] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 20:07:56,101] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.28 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.32 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,526] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 20:07:56,636] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 20:07:56,637] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,637] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.56 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3fff48eb10>\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 20:07:56,640] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:08, 13.94it/s]\titers: 100, epoch: 1 | loss: 0.6932486\n",
      "\tspeed: 0.1181s/iter; left time: 8755.9334s\n",
      "199it [00:15, 13.86it/s]\titers: 200, epoch: 1 | loss: 0.2162637\n",
      "\tspeed: 0.0711s/iter; left time: 5264.7337s\n",
      "299it [00:23, 14.06it/s]\titers: 300, epoch: 1 | loss: 0.3769366\n",
      "\tspeed: 0.0778s/iter; left time: 5754.1582s\n",
      "399it [00:31, 13.91it/s]\titers: 400, epoch: 1 | loss: 0.2745434\n",
      "\tspeed: 0.0779s/iter; left time: 5750.2392s\n",
      "499it [00:38, 13.70it/s]\titers: 500, epoch: 1 | loss: 0.4847790\n",
      "\tspeed: 0.0724s/iter; left time: 5343.8528s\n",
      "599it [00:45, 14.14it/s]\titers: 600, epoch: 1 | loss: 0.4859864\n",
      "\tspeed: 0.0735s/iter; left time: 5411.7245s\n",
      "699it [00:52, 14.11it/s]\titers: 700, epoch: 1 | loss: 0.4851586\n",
      "\tspeed: 0.0715s/iter; left time: 5262.9484s\n",
      "799it [00:59, 14.26it/s]\titers: 800, epoch: 1 | loss: 0.4660286\n",
      "\tspeed: 0.0717s/iter; left time: 5263.6896s\n",
      "899it [01:07, 13.54it/s]\titers: 900, epoch: 1 | loss: 0.2512229\n",
      "\tspeed: 0.0728s/iter; left time: 5342.1663s\n",
      "999it [01:14, 13.10it/s]\titers: 1000, epoch: 1 | loss: 0.5408119\n",
      "\tspeed: 0.0719s/iter; left time: 5263.9904s\n",
      "1099it [01:21, 13.91it/s]\titers: 1100, epoch: 1 | loss: 0.4881727\n",
      "\tspeed: 0.0736s/iter; left time: 5387.0057s\n",
      "1199it [01:28, 13.44it/s]\titers: 1200, epoch: 1 | loss: 0.4563959\n",
      "\tspeed: 0.0714s/iter; left time: 5215.7678s\n",
      "1299it [01:36, 14.05it/s]\titers: 1300, epoch: 1 | loss: 0.2801948\n",
      "\tspeed: 0.0722s/iter; left time: 5266.4093s\n",
      "1399it [01:43, 13.21it/s]\titers: 1400, epoch: 1 | loss: 0.3749747\n",
      "\tspeed: 0.0731s/iter; left time: 5323.2823s\n",
      "1499it [01:50, 12.80it/s]\titers: 1500, epoch: 1 | loss: 0.1778722\n",
      "\tspeed: 0.0736s/iter; left time: 5357.3353s\n",
      "1599it [01:58, 13.53it/s]\titers: 1600, epoch: 1 | loss: 0.2050066\n",
      "\tspeed: 0.0728s/iter; left time: 5286.5128s\n",
      "1699it [02:05, 14.14it/s]\titers: 1700, epoch: 1 | loss: 0.4777356\n",
      "\tspeed: 0.0715s/iter; left time: 5185.1173s\n",
      "1799it [02:12, 13.94it/s]\titers: 1800, epoch: 1 | loss: 0.5995959\n",
      "\tspeed: 0.0735s/iter; left time: 5327.5210s\n",
      "1899it [02:19, 13.78it/s]\titers: 1900, epoch: 1 | loss: 0.3243000\n",
      "\tspeed: 0.0713s/iter; left time: 5157.0747s\n",
      "1999it [02:27, 13.52it/s]\titers: 2000, epoch: 1 | loss: 0.2054642\n",
      "\tspeed: 0.0726s/iter; left time: 5249.2268s\n",
      "2099it [02:34, 14.16it/s]\titers: 2100, epoch: 1 | loss: 0.7944400\n",
      "\tspeed: 0.0740s/iter; left time: 5339.1311s\n",
      "2199it [02:41, 11.54it/s]\titers: 2200, epoch: 1 | loss: 0.2168330\n",
      "\tspeed: 0.0743s/iter; left time: 5351.3410s\n",
      "2299it [02:49, 13.15it/s]\titers: 2300, epoch: 1 | loss: 0.2408096\n",
      "\tspeed: 0.0758s/iter; left time: 5452.7007s\n",
      "2399it [02:56, 14.19it/s]\titers: 2400, epoch: 1 | loss: 0.2905696\n",
      "\tspeed: 0.0711s/iter; left time: 5107.7679s\n",
      "2499it [03:03, 14.12it/s]\titers: 2500, epoch: 1 | loss: 0.2873078\n",
      "\tspeed: 0.0726s/iter; left time: 5210.1054s\n",
      "2599it [03:11, 14.15it/s]\titers: 2600, epoch: 1 | loss: 0.2829672\n",
      "\tspeed: 0.0725s/iter; left time: 5194.4198s\n",
      "2699it [03:18, 12.65it/s]\titers: 2700, epoch: 1 | loss: 0.3935815\n",
      "\tspeed: 0.0732s/iter; left time: 5239.4984s\n",
      "2799it [03:25, 14.06it/s]\titers: 2800, epoch: 1 | loss: 0.2103565\n",
      "\tspeed: 0.0736s/iter; left time: 5258.0972s\n",
      "2899it [03:32, 14.16it/s]\titers: 2900, epoch: 1 | loss: 0.3417163\n",
      "\tspeed: 0.0711s/iter; left time: 5075.5540s\n",
      "2999it [03:40, 12.34it/s]\titers: 3000, epoch: 1 | loss: 0.2578327\n",
      "\tspeed: 0.0737s/iter; left time: 5252.8160s\n",
      "3099it [03:47, 14.15it/s]\titers: 3100, epoch: 1 | loss: 0.3924931\n",
      "\tspeed: 0.0713s/iter; left time: 5074.5802s\n",
      "3199it [03:54, 13.48it/s]\titers: 3200, epoch: 1 | loss: 0.3727626\n",
      "\tspeed: 0.0736s/iter; left time: 5231.0557s\n",
      "3299it [04:01, 14.12it/s]\titers: 3300, epoch: 1 | loss: 0.4639084\n",
      "\tspeed: 0.0717s/iter; left time: 5088.2382s\n",
      "3399it [04:08, 14.02it/s]\titers: 3400, epoch: 1 | loss: 0.4539699\n",
      "\tspeed: 0.0705s/iter; left time: 4998.9704s\n",
      "3499it [04:16, 13.92it/s]\titers: 3500, epoch: 1 | loss: 0.3433972\n",
      "\tspeed: 0.0725s/iter; left time: 5130.9374s\n",
      "3599it [04:23, 13.73it/s]\titers: 3600, epoch: 1 | loss: 0.3567059\n",
      "\tspeed: 0.0719s/iter; left time: 5077.6738s\n",
      "3699it [04:30, 13.75it/s]\titers: 3700, epoch: 1 | loss: 0.4630506\n",
      "\tspeed: 0.0717s/iter; left time: 5062.1838s\n",
      "3713it [04:31, 13.67it/s]\n",
      "Epoch: 1 cost time: 271.54762840270996\n",
      "810it [00:30, 26.99it/s]\n",
      "807it [00:30, 26.66it/s]\n",
      "Epoch: 1 | Train Loss: 0.3603586 Vali Loss: 0.3968324 Test Loss: 0.4883537 MAE Loss: 0.4657121\n",
      "lr = 0.0009938442\n",
      "99it [00:07, 14.17it/s]\titers: 100, epoch: 2 | loss: 0.4103872\n",
      "\tspeed: 0.7068s/iter; left time: 49792.5831s\n",
      "199it [00:14, 13.89it/s]\titers: 200, epoch: 2 | loss: 0.2962865\n",
      "\tspeed: 0.0718s/iter; left time: 5049.1423s\n",
      "299it [00:21, 14.04it/s]\titers: 300, epoch: 2 | loss: 0.4552098\n",
      "\tspeed: 0.0706s/iter; left time: 4962.6590s\n",
      "399it [00:28, 15.58it/s]\titers: 400, epoch: 2 | loss: 0.1380480\n",
      "\tspeed: 0.0709s/iter; left time: 4972.7531s\n",
      "499it [00:35, 14.56it/s]\titers: 500, epoch: 2 | loss: 0.2856549\n",
      "\tspeed: 0.0701s/iter; left time: 4912.2785s\n",
      "599it [00:42, 14.17it/s]\titers: 600, epoch: 2 | loss: 0.3516709\n",
      "\tspeed: 0.0713s/iter; left time: 4987.1275s\n",
      "699it [00:50, 15.01it/s]\titers: 700, epoch: 2 | loss: 0.4588235\n",
      "\tspeed: 0.0709s/iter; left time: 4954.9512s\n",
      "799it [00:57, 12.75it/s]\titers: 800, epoch: 2 | loss: 0.3512471\n",
      "\tspeed: 0.0704s/iter; left time: 4912.5360s\n",
      "899it [01:04, 14.16it/s]\titers: 900, epoch: 2 | loss: 0.2884502\n",
      "\tspeed: 0.0728s/iter; left time: 5072.1880s\n",
      "999it [01:11, 15.03it/s]\titers: 1000, epoch: 2 | loss: 0.3002308\n",
      "\tspeed: 0.0701s/iter; left time: 4872.1912s\n",
      "1099it [01:18, 14.18it/s]\titers: 1100, epoch: 2 | loss: 0.1781139\n",
      "\tspeed: 0.0719s/iter; left time: 4992.2088s\n",
      "1199it [01:25, 14.21it/s]\titers: 1200, epoch: 2 | loss: 0.2972357\n",
      "\tspeed: 0.0720s/iter; left time: 4996.2337s\n",
      "1299it [01:32, 14.17it/s]\titers: 1300, epoch: 2 | loss: 0.3384142\n",
      "\tspeed: 0.0682s/iter; left time: 4720.1978s\n",
      "1399it [01:39, 14.33it/s]\titers: 1400, epoch: 2 | loss: 0.4042118\n",
      "\tspeed: 0.0714s/iter; left time: 4935.3640s\n",
      "1499it [01:46, 13.73it/s]\titers: 1500, epoch: 2 | loss: 0.2262840\n",
      "\tspeed: 0.0709s/iter; left time: 4894.4761s\n",
      "1599it [01:54, 13.49it/s]\titers: 1600, epoch: 2 | loss: 0.2712517\n",
      "\tspeed: 0.0735s/iter; left time: 5069.0067s\n",
      "1699it [02:01, 14.12it/s]\titers: 1700, epoch: 2 | loss: 0.3201418\n",
      "\tspeed: 0.0705s/iter; left time: 4855.0481s\n",
      "1799it [02:08, 15.04it/s]\titers: 1800, epoch: 2 | loss: 0.3149760\n",
      "\tspeed: 0.0710s/iter; left time: 4879.1876s\n",
      "1899it [02:15, 13.61it/s]\titers: 1900, epoch: 2 | loss: 0.3865437\n",
      "\tspeed: 0.0696s/iter; left time: 4774.6309s\n",
      "1999it [02:22, 13.86it/s]\titers: 2000, epoch: 2 | loss: 0.2544391\n",
      "\tspeed: 0.0710s/iter; left time: 4863.9549s\n",
      "2099it [02:29, 13.72it/s]\titers: 2100, epoch: 2 | loss: 0.5642318\n",
      "\tspeed: 0.0718s/iter; left time: 4914.0728s\n",
      "2199it [02:36, 14.34it/s]\titers: 2200, epoch: 2 | loss: 0.3639329\n",
      "\tspeed: 0.0706s/iter; left time: 4826.9559s\n",
      "2299it [02:43, 14.08it/s]\titers: 2300, epoch: 2 | loss: 0.3828222\n",
      "\tspeed: 0.0726s/iter; left time: 4957.6533s\n",
      "2399it [02:51, 14.17it/s]\titers: 2400, epoch: 2 | loss: 0.1834839\n",
      "\tspeed: 0.0718s/iter; left time: 4896.4174s\n",
      "2499it [02:58, 14.11it/s]\titers: 2500, epoch: 2 | loss: 0.3763536\n",
      "\tspeed: 0.0704s/iter; left time: 4793.7179s\n",
      "2599it [03:05, 14.05it/s]\titers: 2600, epoch: 2 | loss: 0.4121595\n",
      "\tspeed: 0.0730s/iter; left time: 4957.9522s\n",
      "2699it [03:12, 14.17it/s]\titers: 2700, epoch: 2 | loss: 0.5046951\n",
      "\tspeed: 0.0705s/iter; left time: 4780.9266s\n",
      "2799it [03:19, 14.19it/s]\titers: 2800, epoch: 2 | loss: 0.3165244\n",
      "\tspeed: 0.0729s/iter; left time: 4935.8615s\n",
      "2899it [03:26, 14.79it/s]\titers: 2900, epoch: 2 | loss: 0.5156003\n",
      "\tspeed: 0.0711s/iter; left time: 4808.6299s\n",
      "2999it [03:33, 14.14it/s]\titers: 3000, epoch: 2 | loss: 0.3766225\n",
      "\tspeed: 0.0712s/iter; left time: 4807.5557s\n",
      "3099it [03:41, 13.97it/s]\titers: 3100, epoch: 2 | loss: 0.2918439\n",
      "\tspeed: 0.0714s/iter; left time: 4812.4627s\n",
      "3199it [03:48, 14.14it/s]\titers: 3200, epoch: 2 | loss: 0.2761501\n",
      "\tspeed: 0.0704s/iter; left time: 4743.9385s\n",
      "3299it [03:55, 13.99it/s]\titers: 3300, epoch: 2 | loss: 0.3070646\n",
      "\tspeed: 0.0737s/iter; left time: 4955.4849s\n",
      "3399it [04:02, 14.23it/s]\titers: 3400, epoch: 2 | loss: 0.2999128\n",
      "\tspeed: 0.0698s/iter; left time: 4690.1686s\n",
      "3499it [04:09, 14.13it/s]\titers: 3500, epoch: 2 | loss: 0.3372339\n",
      "\tspeed: 0.0718s/iter; left time: 4814.2464s\n",
      "3599it [04:16, 14.14it/s]\titers: 3600, epoch: 2 | loss: 0.6030918\n",
      "\tspeed: 0.0716s/iter; left time: 4795.9377s\n",
      "3699it [04:23, 14.20it/s]\titers: 3700, epoch: 2 | loss: 0.2646025\n",
      "\tspeed: 0.0707s/iter; left time: 4723.7463s\n",
      "3713it [04:25, 14.01it/s]\n",
      "Epoch: 2 cost time: 265.0349464416504\n",
      "810it [00:27, 29.43it/s]\n",
      "807it [00:27, 29.71it/s]\n",
      "Epoch: 2 | Train Loss: 0.3255689 Vali Loss: 0.4044774 Test Loss: 0.4940924 MAE Loss: 0.4781854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:07, 14.27it/s]\titers: 100, epoch: 3 | loss: 0.2158741\n",
      "\tspeed: 0.6330s/iter; left time: 42244.4830s\n",
      "199it [00:14, 13.53it/s]\titers: 200, epoch: 3 | loss: 0.2994398\n",
      "\tspeed: 0.0705s/iter; left time: 4698.0326s\n",
      "299it [00:21, 14.14it/s]\titers: 300, epoch: 3 | loss: 0.2349110\n",
      "\tspeed: 0.0717s/iter; left time: 4768.9636s\n",
      "399it [00:28, 14.05it/s]\titers: 400, epoch: 3 | loss: 0.2036653\n",
      "\tspeed: 0.0706s/iter; left time: 4690.6742s\n",
      "499it [00:35, 14.13it/s]\titers: 500, epoch: 3 | loss: 0.2923087\n",
      "\tspeed: 0.0707s/iter; left time: 4690.2104s\n",
      "599it [00:42, 14.15it/s]\titers: 600, epoch: 3 | loss: 0.4084447\n",
      "\tspeed: 0.0712s/iter; left time: 4712.8124s\n",
      "699it [00:50, 12.74it/s]\titers: 700, epoch: 3 | loss: 0.2335312\n",
      "\tspeed: 0.0724s/iter; left time: 4788.3050s\n",
      "799it [00:57, 14.50it/s]\titers: 800, epoch: 3 | loss: 0.4835654\n",
      "\tspeed: 0.0722s/iter; left time: 4768.5624s\n",
      "899it [01:04, 14.12it/s]\titers: 900, epoch: 3 | loss: 0.2760869\n",
      "\tspeed: 0.0704s/iter; left time: 4642.4693s\n",
      "999it [01:11, 13.18it/s]\titers: 1000, epoch: 3 | loss: 0.3622765\n",
      "\tspeed: 0.0734s/iter; left time: 4830.9563s\n",
      "1099it [01:18, 16.18it/s]\titers: 1100, epoch: 3 | loss: 0.2895743\n",
      "\tspeed: 0.0665s/iter; left time: 4373.3885s\n",
      "1199it [01:25, 13.37it/s]\titers: 1200, epoch: 3 | loss: 0.2582735\n",
      "\tspeed: 0.0687s/iter; left time: 4506.4055s\n",
      "1299it [01:32, 14.18it/s]\titers: 1300, epoch: 3 | loss: 0.4120094\n",
      "\tspeed: 0.0713s/iter; left time: 4671.6275s\n",
      "1399it [01:39, 14.18it/s]\titers: 1400, epoch: 3 | loss: 0.2673759\n",
      "\tspeed: 0.0706s/iter; left time: 4620.8445s\n",
      "1499it [01:46, 13.65it/s]\titers: 1500, epoch: 3 | loss: 0.3413921\n",
      "\tspeed: 0.0709s/iter; left time: 4631.7181s\n",
      "1599it [01:53, 14.17it/s]\titers: 1600, epoch: 3 | loss: 0.5834995\n",
      "\tspeed: 0.0705s/iter; left time: 4601.8796s\n",
      "1699it [02:00, 13.88it/s]\titers: 1700, epoch: 3 | loss: 0.2681298\n",
      "\tspeed: 0.0740s/iter; left time: 4819.9182s\n",
      "1799it [02:07, 16.13it/s]\titers: 1800, epoch: 3 | loss: 0.3280468\n",
      "\tspeed: 0.0701s/iter; left time: 4557.3736s\n",
      "1899it [02:14, 14.26it/s]\titers: 1900, epoch: 3 | loss: 0.3379025\n",
      "\tspeed: 0.0676s/iter; left time: 4392.1088s\n",
      "1999it [02:21, 16.11it/s]\titers: 2000, epoch: 3 | loss: 0.2398708\n",
      "\tspeed: 0.0721s/iter; left time: 4673.8878s\n",
      "2099it [02:28, 13.96it/s]\titers: 2100, epoch: 3 | loss: 0.4052865\n",
      "\tspeed: 0.0700s/iter; left time: 4528.7827s\n",
      "2199it [02:36, 14.19it/s]\titers: 2200, epoch: 3 | loss: 0.4468919\n",
      "\tspeed: 0.0709s/iter; left time: 4585.3982s\n",
      "2299it [02:43, 13.72it/s]\titers: 2300, epoch: 3 | loss: 0.2328262\n",
      "\tspeed: 0.0717s/iter; left time: 4630.1345s\n",
      "2399it [02:50, 14.61it/s]\titers: 2400, epoch: 3 | loss: 0.4020664\n",
      "\tspeed: 0.0707s/iter; left time: 4558.1292s\n",
      "2499it [02:57, 13.58it/s]\titers: 2500, epoch: 3 | loss: 0.2348269\n",
      "\tspeed: 0.0713s/iter; left time: 4589.4890s\n",
      "2599it [03:04, 14.09it/s]\titers: 2600, epoch: 3 | loss: 0.1938243\n",
      "\tspeed: 0.0708s/iter; left time: 4550.5957s\n",
      "2699it [03:11, 13.46it/s]\titers: 2700, epoch: 3 | loss: 0.3673901\n",
      "\tspeed: 0.0721s/iter; left time: 4625.5976s\n",
      "2799it [03:18, 14.12it/s]\titers: 2800, epoch: 3 | loss: 0.2743841\n",
      "\tspeed: 0.0709s/iter; left time: 4542.2297s\n",
      "2899it [03:25, 14.06it/s]\titers: 2900, epoch: 3 | loss: 0.3674475\n",
      "\tspeed: 0.0705s/iter; left time: 4510.2430s\n",
      "2999it [03:33, 14.14it/s]\titers: 3000, epoch: 3 | loss: 0.4020359\n",
      "\tspeed: 0.0725s/iter; left time: 4628.6259s\n",
      "3099it [03:40, 14.18it/s]\titers: 3100, epoch: 3 | loss: 0.4316165\n",
      "\tspeed: 0.0704s/iter; left time: 4488.1587s\n",
      "3199it [03:47, 14.08it/s]\titers: 3200, epoch: 3 | loss: 0.2782803\n",
      "\tspeed: 0.0718s/iter; left time: 4566.5390s\n",
      "3299it [03:54, 13.96it/s]\titers: 3300, epoch: 3 | loss: 0.5212505\n",
      "\tspeed: 0.0716s/iter; left time: 4546.3564s\n",
      "3399it [04:01, 13.95it/s]\titers: 3400, epoch: 3 | loss: 0.4546598\n",
      "\tspeed: 0.0694s/iter; left time: 4401.6936s\n",
      "3499it [04:08, 14.20it/s]\titers: 3500, epoch: 3 | loss: 0.2816445\n",
      "\tspeed: 0.0742s/iter; left time: 4702.3578s\n",
      "3599it [04:15, 14.35it/s]\titers: 3600, epoch: 3 | loss: 0.3583716\n",
      "\tspeed: 0.0706s/iter; left time: 4467.0832s\n",
      "3699it [04:23, 12.67it/s]\titers: 3700, epoch: 3 | loss: 0.4355737\n",
      "\tspeed: 0.0743s/iter; left time: 4689.7929s\n",
      "3713it [04:24, 14.04it/s]\n",
      "Epoch: 3 cost time: 264.42951941490173\n",
      "810it [00:26, 30.54it/s]\n",
      "807it [00:27, 29.77it/s]\n",
      "Epoch: 3 | Train Loss: 0.3301399 Vali Loss: 0.4071151 Test Loss: 0.5216547 MAE Loss: 0.4878996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:06, 16.29it/s]\titers: 100, epoch: 4 | loss: 0.3422665\n",
      "\tspeed: 0.6166s/iter; left time: 38858.8373s\n",
      "199it [00:13, 14.23it/s]\titers: 200, epoch: 4 | loss: 0.3514585\n",
      "\tspeed: 0.0700s/iter; left time: 4402.7278s\n",
      "299it [00:21, 14.15it/s]\titers: 300, epoch: 4 | loss: 0.3818747\n",
      "\tspeed: 0.0716s/iter; left time: 4500.6906s\n",
      "399it [00:28, 13.77it/s]\titers: 400, epoch: 4 | loss: 0.2806220\n",
      "\tspeed: 0.0708s/iter; left time: 4442.0999s\n",
      "499it [00:35, 14.23it/s]\titers: 500, epoch: 4 | loss: 0.2576785\n",
      "\tspeed: 0.0729s/iter; left time: 4562.7243s\n",
      "599it [00:42, 14.16it/s]\titers: 600, epoch: 4 | loss: 0.3208332\n",
      "\tspeed: 0.0708s/iter; left time: 4424.0847s\n",
      "699it [00:49, 15.94it/s]\titers: 700, epoch: 4 | loss: 0.2212766\n",
      "\tspeed: 0.0687s/iter; left time: 4287.1163s\n",
      "799it [00:56, 14.16it/s]\titers: 800, epoch: 4 | loss: 0.4491027\n",
      "\tspeed: 0.0700s/iter; left time: 4363.6098s\n",
      "899it [01:03, 12.24it/s]\titers: 900, epoch: 4 | loss: 0.2682408\n",
      "\tspeed: 0.0728s/iter; left time: 4530.5636s\n",
      "999it [01:10, 14.11it/s]\titers: 1000, epoch: 4 | loss: 0.2410987\n",
      "\tspeed: 0.0723s/iter; left time: 4492.0098s\n",
      "1099it [01:17, 14.26it/s]\titers: 1100, epoch: 4 | loss: 0.3213558\n",
      "\tspeed: 0.0705s/iter; left time: 4375.5616s\n",
      "1199it [01:25, 13.83it/s]\titers: 1200, epoch: 4 | loss: 0.3673171\n",
      "\tspeed: 0.0739s/iter; left time: 4577.0001s\n",
      "1299it [01:32, 15.64it/s]\titers: 1300, epoch: 4 | loss: 0.4325978\n",
      "\tspeed: 0.0695s/iter; left time: 4297.8891s\n",
      "1399it [01:39, 14.11it/s]\titers: 1400, epoch: 4 | loss: 0.3647960\n",
      "\tspeed: 0.0731s/iter; left time: 4512.1389s\n",
      "1499it [01:46, 14.29it/s]\titers: 1500, epoch: 4 | loss: 0.3088050\n",
      "\tspeed: 0.0715s/iter; left time: 4408.7367s\n",
      "1599it [01:53, 14.59it/s]\titers: 1600, epoch: 4 | loss: 0.1894979\n",
      "\tspeed: 0.0702s/iter; left time: 4320.6656s\n",
      "1699it [02:01, 14.17it/s]\titers: 1700, epoch: 4 | loss: 0.3767528\n",
      "\tspeed: 0.0737s/iter; left time: 4526.6445s\n",
      "1799it [02:08, 14.11it/s]\titers: 1800, epoch: 4 | loss: 0.3783594\n",
      "\tspeed: 0.0705s/iter; left time: 4325.8765s\n",
      "1899it [02:15, 15.28it/s]\titers: 1900, epoch: 4 | loss: 0.2802714\n",
      "\tspeed: 0.0708s/iter; left time: 4335.7825s\n",
      "1999it [02:22, 14.18it/s]\titers: 2000, epoch: 4 | loss: 0.1866409\n",
      "\tspeed: 0.0711s/iter; left time: 4346.8655s\n",
      "2099it [02:29, 14.87it/s]\titers: 2100, epoch: 4 | loss: 0.2393479\n",
      "\tspeed: 0.0711s/iter; left time: 4338.5902s\n",
      "2199it [02:36, 14.33it/s]\titers: 2200, epoch: 4 | loss: 0.7834582\n",
      "\tspeed: 0.0740s/iter; left time: 4510.0663s\n",
      "2299it [02:43, 15.12it/s]\titers: 2300, epoch: 4 | loss: 0.3821228\n",
      "\tspeed: 0.0707s/iter; left time: 4300.8728s\n",
      "2399it [02:51, 14.14it/s]\titers: 2400, epoch: 4 | loss: 0.2741475\n",
      "\tspeed: 0.0709s/iter; left time: 4305.1271s\n",
      "2499it [02:58, 14.00it/s]\titers: 2500, epoch: 4 | loss: 0.1827663\n",
      "\tspeed: 0.0715s/iter; left time: 4331.6562s\n",
      "2599it [03:05, 14.15it/s]\titers: 2600, epoch: 4 | loss: 0.4768053\n",
      "\tspeed: 0.0692s/iter; left time: 4188.0802s\n",
      "2699it [03:12, 16.27it/s]\titers: 2700, epoch: 4 | loss: 0.5026925\n",
      "\tspeed: 0.0697s/iter; left time: 4213.0636s\n",
      "2799it [03:18, 14.12it/s]\titers: 2800, epoch: 4 | loss: 0.2714068\n",
      "\tspeed: 0.0688s/iter; left time: 4148.3590s\n",
      "2899it [03:26, 14.10it/s]\titers: 2900, epoch: 4 | loss: 0.3935429\n",
      "\tspeed: 0.0711s/iter; left time: 4279.8787s\n",
      "2999it [03:33, 14.07it/s]\titers: 3000, epoch: 4 | loss: 0.3613620\n",
      "\tspeed: 0.0755s/iter; left time: 4538.7040s\n",
      "3099it [03:40, 12.17it/s]\titers: 3100, epoch: 4 | loss: 0.2979709\n",
      "\tspeed: 0.0723s/iter; left time: 4338.7401s\n",
      "3199it [03:48, 14.10it/s]\titers: 3200, epoch: 4 | loss: 0.3801350\n",
      "\tspeed: 0.0756s/iter; left time: 4529.4220s\n",
      "3299it [03:55, 13.23it/s]\titers: 3300, epoch: 4 | loss: 0.1832873\n",
      "\tspeed: 0.0674s/iter; left time: 4033.1897s\n",
      "3399it [04:02, 12.51it/s]\titers: 3400, epoch: 4 | loss: 0.3181505\n",
      "\tspeed: 0.0745s/iter; left time: 4451.0548s\n",
      "3499it [04:09, 13.97it/s]\titers: 3500, epoch: 4 | loss: 0.2727686\n",
      "\tspeed: 0.0730s/iter; left time: 4351.9271s\n",
      "3599it [04:17, 14.25it/s]\titers: 3600, epoch: 4 | loss: 0.2692441\n",
      "\tspeed: 0.0718s/iter; left time: 4271.0512s\n",
      "3699it [04:24, 12.77it/s]\titers: 3700, epoch: 4 | loss: 0.3386483\n",
      "\tspeed: 0.0746s/iter; left time: 4433.0866s\n",
      "3713it [04:25, 13.98it/s]\n",
      "Epoch: 4 cost time: 265.6598780155182\n",
      "810it [00:26, 30.42it/s]\n",
      "807it [00:26, 29.99it/s]\n",
      "Epoch: 4 | Train Loss: 0.3307268 Vali Loss: 0.4089147 Test Loss: 0.5126240 MAE Loss: 0.4891933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "lr = 0.0009045095\n",
      "99it [00:07, 13.38it/s]\titers: 100, epoch: 5 | loss: 0.2200186\n",
      "\tspeed: 0.6264s/iter; left time: 37151.5280s\n",
      "199it [00:15, 13.96it/s]\titers: 200, epoch: 5 | loss: 0.3128289\n",
      "\tspeed: 0.0759s/iter; left time: 4491.0090s\n",
      "299it [00:22, 14.11it/s]\titers: 300, epoch: 5 | loss: 0.3600637\n",
      "\tspeed: 0.0709s/iter; left time: 4193.7178s\n",
      "399it [00:29, 14.14it/s]\titers: 400, epoch: 5 | loss: 0.2711596\n",
      "\tspeed: 0.0716s/iter; left time: 4226.8659s\n",
      "499it [00:36, 14.06it/s]\titers: 500, epoch: 5 | loss: 0.3120309\n",
      "\tspeed: 0.0722s/iter; left time: 4251.9013s\n",
      "599it [00:44, 11.90it/s]\titers: 600, epoch: 5 | loss: 0.3725851\n",
      "\tspeed: 0.0736s/iter; left time: 4326.1998s\n",
      "699it [00:51, 13.34it/s]\titers: 700, epoch: 5 | loss: 0.2512808\n",
      "\tspeed: 0.0761s/iter; left time: 4465.3336s\n",
      "799it [00:59, 14.30it/s]\titers: 800, epoch: 5 | loss: 0.4038743\n",
      "\tspeed: 0.0725s/iter; left time: 4250.8212s\n",
      "899it [01:06, 13.15it/s]\titers: 900, epoch: 5 | loss: 0.2295453\n",
      "\tspeed: 0.0717s/iter; left time: 4194.2090s\n",
      "999it [01:13, 13.07it/s]\titers: 1000, epoch: 5 | loss: 0.2616349\n",
      "\tspeed: 0.0749s/iter; left time: 4377.5030s\n",
      "1099it [01:21, 14.08it/s]\titers: 1100, epoch: 5 | loss: 0.3075055\n",
      "\tspeed: 0.0731s/iter; left time: 4263.6396s\n",
      "1199it [01:28, 13.90it/s]\titers: 1200, epoch: 5 | loss: 0.2475507\n",
      "\tspeed: 0.0702s/iter; left time: 4085.7629s\n",
      "1299it [01:35, 14.09it/s]\titers: 1300, epoch: 5 | loss: 0.3084032\n",
      "\tspeed: 0.0730s/iter; left time: 4241.8795s\n",
      "1399it [01:42, 14.09it/s]\titers: 1400, epoch: 5 | loss: 0.3613304\n",
      "\tspeed: 0.0717s/iter; left time: 4160.3172s\n",
      "1499it [01:49, 15.05it/s]\titers: 1500, epoch: 5 | loss: 0.5281095\n",
      "\tspeed: 0.0700s/iter; left time: 4051.8204s\n",
      "1599it [01:56, 14.08it/s]\titers: 1600, epoch: 5 | loss: 0.3851665\n",
      "\tspeed: 0.0725s/iter; left time: 4190.1136s\n",
      "1699it [02:03, 14.12it/s]\titers: 1700, epoch: 5 | loss: 0.3251232\n",
      "\tspeed: 0.0705s/iter; left time: 4066.3305s\n",
      "1799it [02:11, 14.11it/s]\titers: 1800, epoch: 5 | loss: 0.3338038\n",
      "\tspeed: 0.0718s/iter; left time: 4138.6878s\n",
      "1899it [02:18, 14.19it/s]\titers: 1900, epoch: 5 | loss: 0.2854664\n",
      "\tspeed: 0.0719s/iter; left time: 4133.7278s\n",
      "1999it [02:25, 13.93it/s]\titers: 2000, epoch: 5 | loss: 0.3313590\n",
      "\tspeed: 0.0708s/iter; left time: 4065.8758s\n",
      "2099it [02:32, 14.69it/s]\titers: 2100, epoch: 5 | loss: 0.2955469\n",
      "\tspeed: 0.0719s/iter; left time: 4123.2720s\n",
      "2199it [02:39, 13.76it/s]\titers: 2200, epoch: 5 | loss: 0.2825411\n",
      "\tspeed: 0.0706s/iter; left time: 4036.2201s\n",
      "2299it [02:46, 11.50it/s]\titers: 2300, epoch: 5 | loss: 0.3070060\n",
      "\tspeed: 0.0702s/iter; left time: 4009.8286s\n",
      "2399it [02:53, 14.12it/s]\titers: 2400, epoch: 5 | loss: 0.3994337\n",
      "\tspeed: 0.0712s/iter; left time: 4056.6590s\n",
      "2499it [03:00, 13.57it/s]\titers: 2500, epoch: 5 | loss: 0.5860846\n",
      "\tspeed: 0.0714s/iter; left time: 4066.1314s\n",
      "2599it [03:08, 14.16it/s]\titers: 2600, epoch: 5 | loss: 0.2350308\n",
      "\tspeed: 0.0713s/iter; left time: 4052.0721s\n",
      "2699it [03:15, 14.20it/s]\titers: 2700, epoch: 5 | loss: 0.3490719\n",
      "\tspeed: 0.0702s/iter; left time: 3982.8872s\n",
      "2799it [03:22, 13.42it/s]\titers: 2800, epoch: 5 | loss: 0.1919007\n",
      "\tspeed: 0.0737s/iter; left time: 4174.8290s\n",
      "2899it [03:29, 14.04it/s]\titers: 2900, epoch: 5 | loss: 0.2227861\n",
      "\tspeed: 0.0690s/iter; left time: 3896.6402s\n",
      "2999it [03:36, 14.47it/s]\titers: 3000, epoch: 5 | loss: 0.6617911\n",
      "\tspeed: 0.0702s/iter; left time: 3959.7955s\n",
      "3099it [03:43, 13.89it/s]\titers: 3100, epoch: 5 | loss: 0.1727385\n",
      "\tspeed: 0.0718s/iter; left time: 4041.6040s\n",
      "3199it [03:50, 14.05it/s]\titers: 3200, epoch: 5 | loss: 0.5968987\n",
      "\tspeed: 0.0707s/iter; left time: 3973.5387s\n",
      "3299it [03:57, 15.94it/s]\titers: 3300, epoch: 5 | loss: 0.1983649\n",
      "\tspeed: 0.0713s/iter; left time: 3997.9511s\n",
      "3399it [04:04, 14.13it/s]\titers: 3400, epoch: 5 | loss: 0.2769464\n",
      "\tspeed: 0.0712s/iter; left time: 3989.1589s\n",
      "3499it [04:11, 13.16it/s]\titers: 3500, epoch: 5 | loss: 0.5170779\n",
      "\tspeed: 0.0716s/iter; left time: 4004.5365s\n",
      "3599it [04:19, 14.16it/s]\titers: 3600, epoch: 5 | loss: 0.3743671\n",
      "\tspeed: 0.0725s/iter; left time: 4043.8769s\n",
      "3699it [04:26, 14.10it/s]\titers: 3700, epoch: 5 | loss: 0.3560854\n",
      "\tspeed: 0.0701s/iter; left time: 3902.5343s\n",
      "3713it [04:27, 13.89it/s]\n",
      "Epoch: 5 cost time: 267.31482553482056\n",
      "810it [00:26, 30.03it/s]\n",
      "807it [00:26, 30.26it/s]\n",
      "Epoch: 5 | Train Loss: 0.3192967 Vali Loss: 0.3761173 Test Loss: 0.4595560 MAE Loss: 0.4551590\n",
      "lr = 0.0008535549\n",
      "99it [00:07, 14.19it/s]\titers: 100, epoch: 6 | loss: 0.1860293\n",
      "\tspeed: 0.6373s/iter; left time: 35429.9409s\n",
      "199it [00:14, 14.07it/s]\titers: 200, epoch: 6 | loss: 0.2454493\n",
      "\tspeed: 0.0705s/iter; left time: 3914.8299s\n",
      "299it [00:21, 14.16it/s]\titers: 300, epoch: 6 | loss: 0.3210287\n",
      "\tspeed: 0.0734s/iter; left time: 4066.0830s\n",
      "399it [00:28, 14.19it/s]\titers: 400, epoch: 6 | loss: 0.2927970\n",
      "\tspeed: 0.0699s/iter; left time: 3864.9611s\n",
      "499it [00:36, 14.13it/s]\titers: 500, epoch: 6 | loss: 0.2482518\n",
      "\tspeed: 0.0730s/iter; left time: 4029.6487s\n",
      "599it [00:43, 14.94it/s]\titers: 600, epoch: 6 | loss: 0.4101483\n",
      "\tspeed: 0.0712s/iter; left time: 3920.3870s\n",
      "699it [00:50, 12.12it/s]\titers: 700, epoch: 6 | loss: 0.3217023\n",
      "\tspeed: 0.0735s/iter; left time: 4039.7933s\n",
      "799it [00:57, 14.10it/s]\titers: 800, epoch: 6 | loss: 0.4144844\n",
      "\tspeed: 0.0725s/iter; left time: 3979.7865s\n",
      "899it [01:04, 14.10it/s]\titers: 900, epoch: 6 | loss: 0.2522916\n",
      "\tspeed: 0.0710s/iter; left time: 3891.6067s\n",
      "999it [01:12, 14.58it/s]\titers: 1000, epoch: 6 | loss: 0.4159895\n",
      "\tspeed: 0.0751s/iter; left time: 4107.3747s\n",
      "1099it [01:19, 14.03it/s]\titers: 1100, epoch: 6 | loss: 0.2766317\n",
      "\tspeed: 0.0702s/iter; left time: 3831.0945s\n",
      "1199it [01:26, 12.33it/s]\titers: 1200, epoch: 6 | loss: 0.2994572\n",
      "\tspeed: 0.0719s/iter; left time: 3919.0284s\n",
      "1299it [01:33, 14.14it/s]\titers: 1300, epoch: 6 | loss: 0.4543957\n",
      "\tspeed: 0.0718s/iter; left time: 3905.0724s\n",
      "1399it [01:40, 14.45it/s]\titers: 1400, epoch: 6 | loss: 0.2617683\n",
      "\tspeed: 0.0702s/iter; left time: 3812.9142s\n",
      "1499it [01:48, 14.19it/s]\titers: 1500, epoch: 6 | loss: 0.2228992\n",
      "\tspeed: 0.0735s/iter; left time: 3982.1452s\n",
      "1599it [01:55, 14.22it/s]\titers: 1600, epoch: 6 | loss: 0.1778523\n",
      "\tspeed: 0.0709s/iter; left time: 3833.4459s\n",
      "1699it [02:02, 13.00it/s]\titers: 1700, epoch: 6 | loss: 0.2138749\n",
      "\tspeed: 0.0733s/iter; left time: 3960.4102s\n",
      "1799it [02:10, 14.80it/s]\titers: 1800, epoch: 6 | loss: 0.2465591\n",
      "\tspeed: 0.0736s/iter; left time: 3968.9537s\n",
      "1899it [02:17, 13.15it/s]\titers: 1900, epoch: 6 | loss: 0.2328664\n",
      "\tspeed: 0.0726s/iter; left time: 3907.6928s\n",
      "1999it [02:25, 13.25it/s]\titers: 2000, epoch: 6 | loss: 0.2968273\n",
      "\tspeed: 0.0779s/iter; left time: 4181.1333s\n",
      "2099it [02:32, 14.12it/s]\titers: 2100, epoch: 6 | loss: 0.1951512\n",
      "\tspeed: 0.0745s/iter; left time: 3994.2988s\n",
      "2199it [02:40, 12.69it/s]\titers: 2200, epoch: 6 | loss: 0.4058631\n",
      "\tspeed: 0.0766s/iter; left time: 4099.4590s\n",
      "2299it [02:47, 14.11it/s]\titers: 2300, epoch: 6 | loss: 0.2320084\n",
      "\tspeed: 0.0708s/iter; left time: 3782.2742s\n",
      "2399it [02:54, 13.00it/s]\titers: 2400, epoch: 6 | loss: 0.2369453\n",
      "\tspeed: 0.0723s/iter; left time: 3855.8885s\n",
      "2499it [03:01, 14.31it/s]\titers: 2500, epoch: 6 | loss: 0.5147319\n",
      "\tspeed: 0.0717s/iter; left time: 3812.7344s\n",
      "2599it [03:08, 14.14it/s]\titers: 2600, epoch: 6 | loss: 0.4054409\n",
      "\tspeed: 0.0704s/iter; left time: 3735.4990s\n",
      "2699it [03:16, 14.14it/s]\titers: 2700, epoch: 6 | loss: 0.3702884\n",
      "\tspeed: 0.0735s/iter; left time: 3895.9390s\n",
      "2799it [03:23, 14.15it/s]\titers: 2800, epoch: 6 | loss: 0.1985116\n",
      "\tspeed: 0.0705s/iter; left time: 3731.3534s\n",
      "2899it [03:30, 14.07it/s]\titers: 2900, epoch: 6 | loss: 0.3785993\n",
      "\tspeed: 0.0725s/iter; left time: 3825.7130s\n",
      "2999it [03:37, 14.21it/s]\titers: 3000, epoch: 6 | loss: 0.3012078\n",
      "\tspeed: 0.0719s/iter; left time: 3786.9615s\n",
      "3099it [03:44, 12.83it/s]\titers: 3100, epoch: 6 | loss: 0.2047989\n",
      "\tspeed: 0.0711s/iter; left time: 3742.1866s\n",
      "3199it [03:51, 14.14it/s]\titers: 3200, epoch: 6 | loss: 0.2314112\n",
      "\tspeed: 0.0716s/iter; left time: 3757.7268s\n",
      "3299it [03:58, 14.12it/s]\titers: 3300, epoch: 6 | loss: 0.3803727\n",
      "\tspeed: 0.0701s/iter; left time: 3671.1715s\n",
      "3399it [04:06, 12.95it/s]\titers: 3400, epoch: 6 | loss: 0.3245858\n",
      "\tspeed: 0.0731s/iter; left time: 3824.8549s\n",
      "3499it [04:13, 14.37it/s]\titers: 3500, epoch: 6 | loss: 0.3491633\n",
      "\tspeed: 0.0705s/iter; left time: 3678.6578s\n",
      "3599it [04:20, 13.59it/s]\titers: 3600, epoch: 6 | loss: 0.2510218\n",
      "\tspeed: 0.0728s/iter; left time: 3792.3211s\n",
      "3699it [04:27, 14.76it/s]\titers: 3700, epoch: 6 | loss: 0.2699304\n",
      "\tspeed: 0.0715s/iter; left time: 3717.4258s\n",
      "3713it [04:28, 13.82it/s]\n",
      "Epoch: 6 cost time: 268.693071603775\n",
      "810it [00:26, 30.43it/s]\n",
      "807it [00:26, 30.25it/s]\n",
      "Epoch: 6 | Train Loss: 0.3218480 Vali Loss: 0.4051345 Test Loss: 0.5067619 MAE Loss: 0.4886023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:07, 13.86it/s]\titers: 100, epoch: 7 | loss: 0.2478699\n",
      "\tspeed: 0.6198s/iter; left time: 32158.9321s\n",
      "199it [00:14, 14.10it/s]\titers: 200, epoch: 7 | loss: 0.4338553\n",
      "\tspeed: 0.0718s/iter; left time: 3719.3658s\n",
      "299it [00:21, 14.17it/s]\titers: 300, epoch: 7 | loss: 0.2661629\n",
      "\tspeed: 0.0705s/iter; left time: 3644.4657s\n",
      "399it [00:29, 13.76it/s]\titers: 400, epoch: 7 | loss: 0.3163179\n",
      "\tspeed: 0.0724s/iter; left time: 3733.0546s\n",
      "499it [00:36, 14.14it/s]\titers: 500, epoch: 7 | loss: 0.4007315\n",
      "\tspeed: 0.0712s/iter; left time: 3663.8397s\n",
      "599it [00:43, 14.00it/s]\titers: 600, epoch: 7 | loss: 0.2280969\n",
      "\tspeed: 0.0720s/iter; left time: 3699.5437s\n",
      "699it [00:50, 13.76it/s]\titers: 700, epoch: 7 | loss: 0.2925421\n",
      "\tspeed: 0.0718s/iter; left time: 3681.7702s\n",
      "799it [00:57, 15.59it/s]\titers: 800, epoch: 7 | loss: 0.2265948\n",
      "\tspeed: 0.0682s/iter; left time: 3489.6426s\n",
      "899it [01:04, 14.09it/s]\titers: 900, epoch: 7 | loss: 0.3741530\n",
      "\tspeed: 0.0719s/iter; left time: 3672.1621s\n",
      "999it [01:11, 14.14it/s]\titers: 1000, epoch: 7 | loss: 0.2658457\n",
      "\tspeed: 0.0702s/iter; left time: 3578.1585s\n",
      "1099it [01:18, 14.14it/s]\titers: 1100, epoch: 7 | loss: 0.3171934\n",
      "\tspeed: 0.0721s/iter; left time: 3667.3643s\n",
      "1199it [01:25, 14.33it/s]\titers: 1200, epoch: 7 | loss: 0.2551041\n",
      "\tspeed: 0.0703s/iter; left time: 3571.7648s\n",
      "1299it [01:32, 13.10it/s]\titers: 1300, epoch: 7 | loss: 0.5774506\n",
      "\tspeed: 0.0711s/iter; left time: 3604.6622s\n",
      "1399it [01:40, 14.09it/s]\titers: 1400, epoch: 7 | loss: 0.4140573\n",
      "\tspeed: 0.0731s/iter; left time: 3698.3644s\n",
      "1499it [01:47, 14.08it/s]\titers: 1500, epoch: 7 | loss: 0.4509597\n",
      "\tspeed: 0.0711s/iter; left time: 3589.5879s\n",
      "1599it [01:54, 14.60it/s]\titers: 1600, epoch: 7 | loss: 0.4527910\n",
      "\tspeed: 0.0693s/iter; left time: 3493.9320s\n",
      "1699it [02:01, 14.31it/s]\titers: 1700, epoch: 7 | loss: 0.2497097\n",
      "\tspeed: 0.0689s/iter; left time: 3466.6613s\n",
      "1799it [02:08, 11.98it/s]\titers: 1800, epoch: 7 | loss: 0.2073758\n",
      "\tspeed: 0.0725s/iter; left time: 3640.6730s\n",
      "1899it [02:15, 15.90it/s]\titers: 1900, epoch: 7 | loss: 0.3928856\n",
      "\tspeed: 0.0716s/iter; left time: 3588.0548s\n",
      "1999it [02:22, 14.40it/s]\titers: 2000, epoch: 7 | loss: 0.2590439\n",
      "\tspeed: 0.0646s/iter; left time: 3231.3398s\n",
      "2099it [02:28, 15.47it/s]\titers: 2100, epoch: 7 | loss: 0.2495854\n",
      "\tspeed: 0.0675s/iter; left time: 3366.2429s\n",
      "2199it [02:35, 14.14it/s]\titers: 2200, epoch: 7 | loss: 0.2702341\n",
      "\tspeed: 0.0707s/iter; left time: 3518.3920s\n",
      "2299it [02:42, 14.77it/s]\titers: 2300, epoch: 7 | loss: 0.3073743\n",
      "\tspeed: 0.0689s/iter; left time: 3420.9966s\n",
      "2399it [02:49, 14.12it/s]\titers: 2400, epoch: 7 | loss: 0.2895714\n",
      "\tspeed: 0.0724s/iter; left time: 3588.7822s\n",
      "2499it [02:56, 15.85it/s]\titers: 2500, epoch: 7 | loss: 0.3369277\n",
      "\tspeed: 0.0682s/iter; left time: 3375.1814s\n",
      "2599it [03:03, 15.99it/s]\titers: 2600, epoch: 7 | loss: 0.3677252\n",
      "\tspeed: 0.0701s/iter; left time: 3462.5944s\n",
      "2699it [03:10, 14.16it/s]\titers: 2700, epoch: 7 | loss: 0.1809392\n",
      "\tspeed: 0.0652s/iter; left time: 3213.1562s\n",
      "2799it [03:17, 14.01it/s]\titers: 2800, epoch: 7 | loss: 0.3356314\n",
      "\tspeed: 0.0712s/iter; left time: 3499.9747s\n",
      "2899it [03:24, 13.68it/s]\titers: 2900, epoch: 7 | loss: 0.2481166\n",
      "\tspeed: 0.0678s/iter; left time: 3328.5903s\n",
      "2999it [03:31, 14.56it/s]\titers: 3000, epoch: 7 | loss: 0.6404238\n",
      "\tspeed: 0.0680s/iter; left time: 3331.7002s\n",
      "3099it [03:38, 14.00it/s]\titers: 3100, epoch: 7 | loss: 0.2369842\n",
      "\tspeed: 0.0706s/iter; left time: 3450.9935s\n",
      "3199it [03:45, 14.30it/s]\titers: 3200, epoch: 7 | loss: 0.3639956\n",
      "\tspeed: 0.0714s/iter; left time: 3482.1464s\n",
      "3299it [03:52, 14.12it/s]\titers: 3300, epoch: 7 | loss: 0.5726178\n",
      "\tspeed: 0.0679s/iter; left time: 3305.6712s\n",
      "3399it [03:59, 13.59it/s]\titers: 3400, epoch: 7 | loss: 0.2654776\n",
      "\tspeed: 0.0730s/iter; left time: 3548.6674s\n",
      "3499it [04:06, 14.11it/s]\titers: 3500, epoch: 7 | loss: 0.4411390\n",
      "\tspeed: 0.0707s/iter; left time: 3429.8538s\n",
      "3599it [04:13, 14.10it/s]\titers: 3600, epoch: 7 | loss: 0.2713261\n",
      "\tspeed: 0.0711s/iter; left time: 3440.7764s\n",
      "3699it [04:20, 14.75it/s]\titers: 3700, epoch: 7 | loss: 0.2794026\n",
      "\tspeed: 0.0714s/iter; left time: 3449.5770s\n",
      "3713it [04:21, 14.19it/s]\n",
      "Epoch: 7 cost time: 261.6957426071167\n",
      "810it [00:26, 30.49it/s]\n",
      "807it [00:27, 29.89it/s]\n",
      "Epoch: 7 | Train Loss: 0.3176838 Vali Loss: 0.3900327 Test Loss: 0.4882854 MAE Loss: 0.4639982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:07, 12.64it/s]\titers: 100, epoch: 8 | loss: 0.5770047\n",
      "\tspeed: 0.6220s/iter; left time: 29959.8957s\n",
      "199it [00:14, 14.15it/s]\titers: 200, epoch: 8 | loss: 0.3267495\n",
      "\tspeed: 0.0707s/iter; left time: 3400.4030s\n",
      "299it [00:21, 14.22it/s]\titers: 300, epoch: 8 | loss: 0.1608692\n",
      "\tspeed: 0.0662s/iter; left time: 3176.8439s\n",
      "399it [00:28, 13.74it/s]\titers: 400, epoch: 8 | loss: 0.3844922\n",
      "\tspeed: 0.0727s/iter; left time: 3481.4675s\n",
      "499it [00:35, 14.03it/s]\titers: 500, epoch: 8 | loss: 0.2413089\n",
      "\tspeed: 0.0684s/iter; left time: 3268.0623s\n",
      "599it [00:42, 13.13it/s]\titers: 600, epoch: 8 | loss: 0.3362294\n",
      "\tspeed: 0.0715s/iter; left time: 3408.0008s\n",
      "699it [00:49, 13.21it/s]\titers: 700, epoch: 8 | loss: 0.1503156\n",
      "\tspeed: 0.0720s/iter; left time: 3427.1033s\n",
      "799it [00:56, 14.03it/s]\titers: 800, epoch: 8 | loss: 0.3333311\n",
      "\tspeed: 0.0692s/iter; left time: 3286.9807s\n",
      "899it [01:03, 14.17it/s]\titers: 900, epoch: 8 | loss: 0.4224862\n",
      "\tspeed: 0.0720s/iter; left time: 3411.0513s\n",
      "999it [01:11, 13.30it/s]\titers: 1000, epoch: 8 | loss: 0.3393056\n",
      "\tspeed: 0.0738s/iter; left time: 3488.9897s\n",
      "1099it [01:18, 14.07it/s]\titers: 1100, epoch: 8 | loss: 0.2967793\n",
      "\tspeed: 0.0721s/iter; left time: 3400.2359s\n",
      "1199it [01:25, 13.72it/s]\titers: 1200, epoch: 8 | loss: 0.6526562\n",
      "\tspeed: 0.0728s/iter; left time: 3428.6160s\n",
      "1299it [01:32, 14.10it/s]\titers: 1300, epoch: 8 | loss: 0.7756191\n",
      "\tspeed: 0.0720s/iter; left time: 3380.1344s\n",
      "1399it [01:40, 14.11it/s]\titers: 1400, epoch: 8 | loss: 0.2002395\n",
      "\tspeed: 0.0715s/iter; left time: 3351.6458s\n",
      "1499it [01:47, 15.62it/s]\titers: 1500, epoch: 8 | loss: 0.4000432\n",
      "\tspeed: 0.0711s/iter; left time: 3326.9779s\n",
      "1599it [01:54, 13.62it/s]\titers: 1600, epoch: 8 | loss: 0.2911925\n",
      "\tspeed: 0.0702s/iter; left time: 3278.4588s\n",
      "1699it [02:01, 14.02it/s]\titers: 1700, epoch: 8 | loss: 0.2495515\n",
      "\tspeed: 0.0720s/iter; left time: 3352.5311s\n",
      "1799it [02:08, 14.20it/s]\titers: 1800, epoch: 8 | loss: 0.2866145\n",
      "\tspeed: 0.0704s/iter; left time: 3270.4524s\n",
      "1899it [02:15, 14.06it/s]\titers: 1900, epoch: 8 | loss: 0.2690101\n",
      "\tspeed: 0.0716s/iter; left time: 3319.6581s\n",
      "1999it [02:22, 14.19it/s]\titers: 2000, epoch: 8 | loss: 0.2248492\n",
      "\tspeed: 0.0718s/iter; left time: 3320.2415s\n",
      "2099it [02:29, 14.52it/s]\titers: 2100, epoch: 8 | loss: 0.5944342\n",
      "\tspeed: 0.0699s/iter; left time: 3229.3515s\n",
      "2199it [02:36, 14.12it/s]\titers: 2200, epoch: 8 | loss: 0.2263105\n",
      "\tspeed: 0.0706s/iter; left time: 3251.6026s\n",
      "2299it [02:43, 14.16it/s]\titers: 2300, epoch: 8 | loss: 0.2574092\n",
      "\tspeed: 0.0700s/iter; left time: 3219.5631s\n",
      "2399it [02:50, 12.79it/s]\titers: 2400, epoch: 8 | loss: 0.3529392\n",
      "\tspeed: 0.0721s/iter; left time: 3305.0570s\n",
      "2499it [02:58, 14.12it/s]\titers: 2500, epoch: 8 | loss: 0.2122550\n",
      "\tspeed: 0.0711s/iter; left time: 3253.7079s\n",
      "2599it [03:05, 12.68it/s]\titers: 2600, epoch: 8 | loss: 0.2878301\n",
      "\tspeed: 0.0720s/iter; left time: 3290.1310s\n",
      "2699it [03:12, 14.10it/s]\titers: 2700, epoch: 8 | loss: 0.3256881\n",
      "\tspeed: 0.0719s/iter; left time: 3276.4107s\n",
      "2799it [03:19, 14.20it/s]\titers: 2800, epoch: 8 | loss: 0.2976313\n",
      "\tspeed: 0.0706s/iter; left time: 3208.3851s\n",
      "2899it [03:26, 13.34it/s]\titers: 2900, epoch: 8 | loss: 0.3020608\n",
      "\tspeed: 0.0726s/iter; left time: 3292.8836s\n",
      "2999it [03:33, 14.03it/s]\titers: 3000, epoch: 8 | loss: 0.6040528\n",
      "\tspeed: 0.0717s/iter; left time: 3244.1567s\n",
      "3099it [03:41, 13.97it/s]\titers: 3100, epoch: 8 | loss: 0.4602436\n",
      "\tspeed: 0.0710s/iter; left time: 3206.0016s\n",
      "3199it [03:48, 14.13it/s]\titers: 3200, epoch: 8 | loss: 0.2723779\n",
      "\tspeed: 0.0736s/iter; left time: 3318.8349s\n",
      "3299it [03:55, 14.38it/s]\titers: 3300, epoch: 8 | loss: 0.3347049\n",
      "\tspeed: 0.0704s/iter; left time: 3165.4586s\n",
      "3399it [04:02, 13.56it/s]\titers: 3400, epoch: 8 | loss: 0.3249944\n",
      "\tspeed: 0.0711s/iter; left time: 3188.7205s\n",
      "3499it [04:09, 14.12it/s]\titers: 3500, epoch: 8 | loss: 0.3546934\n",
      "\tspeed: 0.0725s/iter; left time: 3243.6312s\n",
      "3599it [04:16, 14.16it/s]\titers: 3600, epoch: 8 | loss: 0.2438684\n",
      "\tspeed: 0.0705s/iter; left time: 3149.8152s\n",
      "3699it [04:24, 14.18it/s]\titers: 3700, epoch: 8 | loss: 0.5086076\n",
      "\tspeed: 0.0724s/iter; left time: 3226.2807s\n",
      "3713it [04:25, 14.00it/s]\n",
      "Epoch: 8 cost time: 265.24969029426575\n",
      "810it [00:27, 29.85it/s]\n",
      "807it [00:26, 30.13it/s]\n",
      "Epoch: 8 | Train Loss: 0.3167600 Vali Loss: 0.3786555 Test Loss: 0.4712922 MAE Loss: 0.4615780\n",
      "EarlyStopping counter: 3 out of 10\n",
      "lr = 0.0006545120\n",
      "99it [00:07, 14.45it/s]\titers: 100, epoch: 9 | loss: 0.2055838\n",
      "\tspeed: 0.6250s/iter; left time: 27783.7068s\n",
      "199it [00:14, 14.00it/s]\titers: 200, epoch: 9 | loss: 0.4382360\n",
      "\tspeed: 0.0715s/iter; left time: 3172.5954s\n",
      "299it [00:21, 14.00it/s]\titers: 300, epoch: 9 | loss: 0.2477795\n",
      "\tspeed: 0.0713s/iter; left time: 3153.8063s\n",
      "399it [00:28, 14.39it/s]\titers: 400, epoch: 9 | loss: 0.2436704\n",
      "\tspeed: 0.0701s/iter; left time: 3094.1295s\n",
      "499it [00:35, 13.89it/s]\titers: 500, epoch: 9 | loss: 0.2715870\n",
      "\tspeed: 0.0726s/iter; left time: 3197.9471s\n",
      "599it [00:42, 14.09it/s]\titers: 600, epoch: 9 | loss: 0.2231630\n",
      "\tspeed: 0.0704s/iter; left time: 3093.7989s\n",
      "699it [00:50, 14.12it/s]\titers: 700, epoch: 9 | loss: 0.1860436\n",
      "\tspeed: 0.0719s/iter; left time: 3153.8865s\n",
      "799it [00:57, 14.24it/s]\titers: 800, epoch: 9 | loss: 0.3048641\n",
      "\tspeed: 0.0712s/iter; left time: 3113.5801s\n",
      "899it [01:04, 13.23it/s]\titers: 900, epoch: 9 | loss: 0.2116062\n",
      "\tspeed: 0.0710s/iter; left time: 3098.2645s\n",
      "999it [01:11, 14.11it/s]\titers: 1000, epoch: 9 | loss: 0.4252240\n",
      "\tspeed: 0.0726s/iter; left time: 3163.7562s\n",
      "1099it [01:18, 14.15it/s]\titers: 1100, epoch: 9 | loss: 0.3475896\n",
      "\tspeed: 0.0705s/iter; left time: 3064.3892s\n",
      "1199it [01:25, 12.35it/s]\titers: 1200, epoch: 9 | loss: 0.2482909\n",
      "\tspeed: 0.0729s/iter; left time: 3160.3898s\n",
      "1299it [01:33, 14.62it/s]\titers: 1300, epoch: 9 | loss: 0.3578586\n",
      "\tspeed: 0.0709s/iter; left time: 3067.9247s\n",
      "1399it [01:40, 14.09it/s]\titers: 1400, epoch: 9 | loss: 0.5017953\n",
      "\tspeed: 0.0724s/iter; left time: 3125.9325s\n",
      "1499it [01:47, 14.14it/s]\titers: 1500, epoch: 9 | loss: 0.2505350\n",
      "\tspeed: 0.0717s/iter; left time: 3086.7532s\n",
      "1599it [01:54, 13.19it/s]\titers: 1600, epoch: 9 | loss: 0.3136218\n",
      "\tspeed: 0.0713s/iter; left time: 3064.3773s\n",
      "1699it [02:02, 13.12it/s]\titers: 1700, epoch: 9 | loss: 0.2684740\n",
      "\tspeed: 0.0746s/iter; left time: 3197.8552s\n",
      "1799it [02:09, 14.09it/s]\titers: 1800, epoch: 9 | loss: 0.2982276\n",
      "\tspeed: 0.0706s/iter; left time: 3017.1105s\n",
      "1899it [02:16, 13.38it/s]\titers: 1900, epoch: 9 | loss: 0.6690124\n",
      "\tspeed: 0.0711s/iter; left time: 3030.8845s\n",
      "1999it [02:23, 13.25it/s]\titers: 2000, epoch: 9 | loss: 0.3351339\n",
      "\tspeed: 0.0705s/iter; left time: 2999.7427s\n",
      "2099it [02:30, 13.80it/s]\titers: 2100, epoch: 9 | loss: 0.2604609\n",
      "\tspeed: 0.0708s/iter; left time: 3004.0921s\n",
      "2199it [02:37, 13.60it/s]\titers: 2200, epoch: 9 | loss: 0.3689049\n",
      "\tspeed: 0.0727s/iter; left time: 3078.5910s\n",
      "2299it [02:44, 14.16it/s]\titers: 2300, epoch: 9 | loss: 0.3088582\n",
      "\tspeed: 0.0708s/iter; left time: 2993.2270s\n",
      "2399it [02:51, 13.38it/s]\titers: 2400, epoch: 9 | loss: 0.3777398\n",
      "\tspeed: 0.0716s/iter; left time: 3017.0458s\n",
      "2499it [02:59, 14.16it/s]\titers: 2500, epoch: 9 | loss: 0.2721376\n",
      "\tspeed: 0.0721s/iter; left time: 3033.5271s\n",
      "2599it [03:06, 13.89it/s]\titers: 2600, epoch: 9 | loss: 0.3252808\n",
      "\tspeed: 0.0709s/iter; left time: 2976.0346s\n",
      "2699it [03:13, 14.24it/s]\titers: 2700, epoch: 9 | loss: 0.3464783\n",
      "\tspeed: 0.0716s/iter; left time: 2995.9078s\n",
      "2799it [03:20, 14.17it/s]\titers: 2800, epoch: 9 | loss: 0.2026952\n",
      "\tspeed: 0.0715s/iter; left time: 2987.6863s\n",
      "2899it [03:27, 13.52it/s]\titers: 2900, epoch: 9 | loss: 0.3048419\n",
      "\tspeed: 0.0711s/iter; left time: 2961.1921s\n",
      "2999it [03:34, 14.10it/s]\titers: 3000, epoch: 9 | loss: 0.3719063\n",
      "\tspeed: 0.0731s/iter; left time: 3038.8357s\n",
      "3099it [03:42, 13.86it/s]\titers: 3100, epoch: 9 | loss: 0.6094643\n",
      "\tspeed: 0.0752s/iter; left time: 3117.3929s\n",
      "3199it [03:49, 14.16it/s]\titers: 3200, epoch: 9 | loss: 0.2338102\n",
      "\tspeed: 0.0713s/iter; left time: 2948.5991s\n",
      "3299it [03:56, 14.15it/s]\titers: 3300, epoch: 9 | loss: 0.3370678\n",
      "\tspeed: 0.0714s/iter; left time: 2946.8397s\n",
      "3399it [04:03, 13.65it/s]\titers: 3400, epoch: 9 | loss: 0.2784171\n",
      "\tspeed: 0.0708s/iter; left time: 2912.8042s\n",
      "3499it [04:10, 14.17it/s]\titers: 3500, epoch: 9 | loss: 0.4160938\n",
      "\tspeed: 0.0717s/iter; left time: 2944.9028s\n",
      "3599it [04:18, 14.12it/s]\titers: 3600, epoch: 9 | loss: 0.1992202\n",
      "\tspeed: 0.0709s/iter; left time: 2905.4227s\n",
      "3699it [04:25, 14.16it/s]\titers: 3700, epoch: 9 | loss: 0.1777645\n",
      "\tspeed: 0.0718s/iter; left time: 2934.4138s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 9 cost time: 266.3497133255005\n",
      "810it [00:26, 30.64it/s]\n",
      "807it [00:26, 30.14it/s]\n",
      "Epoch: 9 | Train Loss: 0.3193015 Vali Loss: 0.3908932 Test Loss: 0.4891208 MAE Loss: 0.4701705\n",
      "EarlyStopping counter: 4 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:07, 14.83it/s]\titers: 100, epoch: 10 | loss: 0.6328828\n",
      "\tspeed: 0.6179s/iter; left time: 25176.3457s\n",
      "199it [00:14, 14.11it/s]\titers: 200, epoch: 10 | loss: 0.2557484\n",
      "\tspeed: 0.0715s/iter; left time: 2906.3487s\n",
      "299it [00:21, 14.13it/s]\titers: 300, epoch: 10 | loss: 0.3946822\n",
      "\tspeed: 0.0717s/iter; left time: 2908.3313s\n",
      "399it [00:28, 14.32it/s]\titers: 400, epoch: 10 | loss: 0.2857973\n",
      "\tspeed: 0.0705s/iter; left time: 2850.9153s\n",
      "499it [00:35, 14.05it/s]\titers: 500, epoch: 10 | loss: 0.2762298\n",
      "\tspeed: 0.0725s/iter; left time: 2924.3895s\n",
      "599it [00:43, 14.13it/s]\titers: 600, epoch: 10 | loss: 0.2609059\n",
      "\tspeed: 0.0707s/iter; left time: 2843.4045s\n",
      "699it [00:50, 14.23it/s]\titers: 700, epoch: 10 | loss: 0.5183377\n",
      "\tspeed: 0.0713s/iter; left time: 2862.1845s\n",
      "799it [00:57, 14.93it/s]\titers: 800, epoch: 10 | loss: 0.3327874\n",
      "\tspeed: 0.0700s/iter; left time: 2802.5244s\n",
      "899it [01:04, 14.09it/s]\titers: 900, epoch: 10 | loss: 0.2915243\n",
      "\tspeed: 0.0688s/iter; left time: 2747.7177s\n",
      "999it [01:11, 14.09it/s]\titers: 1000, epoch: 10 | loss: 0.4116774\n",
      "\tspeed: 0.0731s/iter; left time: 2913.7742s\n",
      "1099it [01:18, 14.77it/s]\titers: 1100, epoch: 10 | loss: 0.3381758\n",
      "\tspeed: 0.0701s/iter; left time: 2788.0224s\n",
      "1199it [01:25, 13.17it/s]\titers: 1200, epoch: 10 | loss: 0.4430414\n",
      "\tspeed: 0.0754s/iter; left time: 2990.5337s\n",
      "1299it [01:33, 13.36it/s]\titers: 1300, epoch: 10 | loss: 0.3568830\n",
      "\tspeed: 0.0726s/iter; left time: 2872.6648s\n",
      "1399it [01:41, 10.96it/s]\titers: 1400, epoch: 10 | loss: 0.3547076\n",
      "\tspeed: 0.0786s/iter; left time: 3099.6525s\n",
      "1499it [01:48, 14.06it/s]\titers: 1500, epoch: 10 | loss: 0.3370391\n",
      "\tspeed: 0.0720s/iter; left time: 2831.3749s\n",
      "1599it [01:55, 14.11it/s]\titers: 1600, epoch: 10 | loss: 0.5297878\n",
      "\tspeed: 0.0708s/iter; left time: 2778.9718s\n",
      "1699it [02:02, 13.25it/s]\titers: 1700, epoch: 10 | loss: 0.3545569\n",
      "\tspeed: 0.0763s/iter; left time: 2985.1371s\n",
      "1799it [02:10, 14.17it/s]\titers: 1800, epoch: 10 | loss: 0.3164133\n",
      "\tspeed: 0.0727s/iter; left time: 2840.0181s\n",
      "1899it [02:17, 13.23it/s]\titers: 1900, epoch: 10 | loss: 0.1621146\n",
      "\tspeed: 0.0752s/iter; left time: 2928.9422s\n",
      "1999it [02:25, 13.42it/s]\titers: 2000, epoch: 10 | loss: 0.3638330\n",
      "\tspeed: 0.0762s/iter; left time: 2959.0439s\n",
      "2099it [02:32, 11.10it/s]\titers: 2100, epoch: 10 | loss: 0.3622330\n",
      "\tspeed: 0.0729s/iter; left time: 2824.3133s\n",
      "2199it [02:40, 13.42it/s]\titers: 2200, epoch: 10 | loss: 0.3698464\n",
      "\tspeed: 0.0773s/iter; left time: 2987.4829s\n",
      "2299it [02:47, 13.21it/s]\titers: 2300, epoch: 10 | loss: 0.2250059\n",
      "\tspeed: 0.0684s/iter; left time: 2634.7856s\n",
      "2399it [02:54, 14.14it/s]\titers: 2400, epoch: 10 | loss: 0.2350701\n",
      "\tspeed: 0.0711s/iter; left time: 2732.8648s\n",
      "2499it [03:01, 14.17it/s]\titers: 2500, epoch: 10 | loss: 0.3937078\n",
      "\tspeed: 0.0718s/iter; left time: 2752.2378s\n",
      "2599it [03:08, 13.33it/s]\titers: 2600, epoch: 10 | loss: 0.2359046\n",
      "\tspeed: 0.0713s/iter; left time: 2724.9641s\n",
      "2699it [03:15, 14.42it/s]\titers: 2700, epoch: 10 | loss: 0.2048412\n",
      "\tspeed: 0.0714s/iter; left time: 2724.0245s\n",
      "2799it [03:22, 15.42it/s]\titers: 2800, epoch: 10 | loss: 0.2506647\n",
      "\tspeed: 0.0694s/iter; left time: 2642.0220s\n",
      "2899it [03:29, 12.13it/s]\titers: 2900, epoch: 10 | loss: 0.4791837\n",
      "\tspeed: 0.0723s/iter; left time: 2741.8931s\n",
      "2999it [03:37, 14.15it/s]\titers: 3000, epoch: 10 | loss: 0.4039135\n",
      "\tspeed: 0.0705s/iter; left time: 2668.5627s\n",
      "3099it [03:44, 13.08it/s]\titers: 3100, epoch: 10 | loss: 0.1761593\n",
      "\tspeed: 0.0714s/iter; left time: 2695.0147s\n",
      "3199it [03:51, 14.18it/s]\titers: 3200, epoch: 10 | loss: 0.1721474\n",
      "\tspeed: 0.0717s/iter; left time: 2700.8959s\n",
      "3299it [03:58, 14.16it/s]\titers: 3300, epoch: 10 | loss: 0.3097329\n",
      "\tspeed: 0.0707s/iter; left time: 2654.4925s\n",
      "3399it [04:05, 13.42it/s]\titers: 3400, epoch: 10 | loss: 0.5163501\n",
      "\tspeed: 0.0699s/iter; left time: 2617.2819s\n",
      "3499it [04:12, 14.15it/s]\titers: 3500, epoch: 10 | loss: 0.2257713\n",
      "\tspeed: 0.0699s/iter; left time: 2608.6481s\n",
      "3599it [04:19, 12.54it/s]\titers: 3600, epoch: 10 | loss: 0.3606421\n",
      "\tspeed: 0.0714s/iter; left time: 2658.4921s\n",
      "3699it [04:26, 13.97it/s]\titers: 3700, epoch: 10 | loss: 0.3611962\n",
      "\tspeed: 0.0747s/iter; left time: 2776.3617s\n",
      "3713it [04:28, 13.85it/s]\n",
      "Epoch: 10 cost time: 268.0211503505707\n",
      "810it [00:26, 30.14it/s]\n",
      "807it [00:26, 30.21it/s]\n",
      "Epoch: 10 | Train Loss: 0.3041269 Vali Loss: 0.3780959 Test Loss: 0.4662771 MAE Loss: 0.4537774\n",
      "EarlyStopping counter: 5 out of 10\n",
      "lr = 0.0005000050\n",
      "99it [00:07, 12.95it/s]\titers: 100, epoch: 11 | loss: 0.2315817\n",
      "\tspeed: 0.6202s/iter; left time: 22968.3211s\n",
      "199it [00:14, 14.25it/s]\titers: 200, epoch: 11 | loss: 0.3358840\n",
      "\tspeed: 0.0717s/iter; left time: 2649.3456s\n",
      "299it [00:21, 16.01it/s]\titers: 300, epoch: 11 | loss: 0.2364494\n",
      "\tspeed: 0.0663s/iter; left time: 2441.9352s\n",
      "399it [00:27, 14.18it/s]\titers: 400, epoch: 11 | loss: 0.4483358\n",
      "\tspeed: 0.0679s/iter; left time: 2494.9273s\n",
      "499it [00:34, 14.12it/s]\titers: 500, epoch: 11 | loss: 0.3491395\n",
      "\tspeed: 0.0703s/iter; left time: 2576.8821s\n",
      "599it [00:42, 14.16it/s]\titers: 600, epoch: 11 | loss: 0.2113983\n",
      "\tspeed: 0.0708s/iter; left time: 2584.9807s\n",
      "699it [00:49, 14.18it/s]\titers: 700, epoch: 11 | loss: 0.2449994\n",
      "\tspeed: 0.0735s/iter; left time: 2677.7167s\n",
      "799it [00:56, 14.20it/s]\titers: 800, epoch: 11 | loss: 0.4927401\n",
      "\tspeed: 0.0705s/iter; left time: 2563.1043s\n",
      "899it [01:03, 13.84it/s]\titers: 900, epoch: 11 | loss: 0.2359479\n",
      "\tspeed: 0.0715s/iter; left time: 2591.3214s\n",
      "999it [01:10, 13.97it/s]\titers: 1000, epoch: 11 | loss: 0.2809621\n",
      "\tspeed: 0.0711s/iter; left time: 2569.3585s\n",
      "1099it [01:17, 12.64it/s]\titers: 1100, epoch: 11 | loss: 0.2099049\n",
      "\tspeed: 0.0726s/iter; left time: 2614.8144s\n",
      "1199it [01:25, 14.26it/s]\titers: 1200, epoch: 11 | loss: 0.2824244\n",
      "\tspeed: 0.0721s/iter; left time: 2590.8751s\n",
      "1299it [01:32, 14.15it/s]\titers: 1300, epoch: 11 | loss: 0.1849677\n",
      "\tspeed: 0.0706s/iter; left time: 2529.4055s\n",
      "1399it [01:39, 14.38it/s]\titers: 1400, epoch: 11 | loss: 0.2756193\n",
      "\tspeed: 0.0713s/iter; left time: 2548.0961s\n",
      "1499it [01:46, 14.77it/s]\titers: 1500, epoch: 11 | loss: 0.2333716\n",
      "\tspeed: 0.0711s/iter; left time: 2534.4682s\n",
      "1599it [01:53, 13.04it/s]\titers: 1600, epoch: 11 | loss: 0.2342457\n",
      "\tspeed: 0.0704s/iter; left time: 2501.8235s\n",
      "1699it [02:00, 14.14it/s]\titers: 1700, epoch: 11 | loss: 0.4024353\n",
      "\tspeed: 0.0719s/iter; left time: 2546.4560s\n",
      "1799it [02:07, 14.12it/s]\titers: 1800, epoch: 11 | loss: 0.3037993\n",
      "\tspeed: 0.0709s/iter; left time: 2504.2494s\n",
      "1899it [02:14, 14.06it/s]\titers: 1900, epoch: 11 | loss: 0.3815071\n",
      "\tspeed: 0.0723s/iter; left time: 2547.8257s\n",
      "1999it [02:22, 14.12it/s]\titers: 2000, epoch: 11 | loss: 0.2112320\n",
      "\tspeed: 0.0715s/iter; left time: 2510.9753s\n",
      "2099it [02:29, 13.47it/s]\titers: 2100, epoch: 11 | loss: 0.1788025\n",
      "\tspeed: 0.0715s/iter; left time: 2506.0588s\n",
      "2199it [02:36, 13.84it/s]\titers: 2200, epoch: 11 | loss: 0.1849326\n",
      "\tspeed: 0.0717s/iter; left time: 2503.0087s\n",
      "2299it [02:43, 14.15it/s]\titers: 2300, epoch: 11 | loss: 0.3742796\n",
      "\tspeed: 0.0706s/iter; left time: 2459.7960s\n",
      "2399it [02:50, 13.52it/s]\titers: 2400, epoch: 11 | loss: 0.3149775\n",
      "\tspeed: 0.0735s/iter; left time: 2554.2686s\n",
      "2499it [02:57, 14.86it/s]\titers: 2500, epoch: 11 | loss: 0.1865861\n",
      "\tspeed: 0.0692s/iter; left time: 2398.1694s\n",
      "2599it [03:04, 13.85it/s]\titers: 2600, epoch: 11 | loss: 0.3147987\n",
      "\tspeed: 0.0695s/iter; left time: 2401.4450s\n",
      "2699it [03:11, 13.91it/s]\titers: 2700, epoch: 11 | loss: 0.2902370\n",
      "\tspeed: 0.0721s/iter; left time: 2483.6910s\n",
      "2799it [03:19, 14.15it/s]\titers: 2800, epoch: 11 | loss: 0.2377849\n",
      "\tspeed: 0.0703s/iter; left time: 2414.7641s\n",
      "2899it [03:26, 13.74it/s]\titers: 2900, epoch: 11 | loss: 0.2783045\n",
      "\tspeed: 0.0733s/iter; left time: 2509.6821s\n",
      "2999it [03:33, 14.54it/s]\titers: 3000, epoch: 11 | loss: 0.2602543\n",
      "\tspeed: 0.0702s/iter; left time: 2394.9345s\n",
      "3099it [03:40, 15.44it/s]\titers: 3100, epoch: 11 | loss: 0.2794184\n",
      "\tspeed: 0.0697s/iter; left time: 2372.8130s\n",
      "3199it [03:47, 15.45it/s]\titers: 3200, epoch: 11 | loss: 0.2061066\n",
      "\tspeed: 0.0692s/iter; left time: 2348.7258s\n",
      "3299it [03:53, 14.21it/s]\titers: 3300, epoch: 11 | loss: 0.2921207\n",
      "\tspeed: 0.0668s/iter; left time: 2260.5866s\n",
      "3399it [04:01, 13.58it/s]\titers: 3400, epoch: 11 | loss: 0.1485655\n",
      "\tspeed: 0.0721s/iter; left time: 2433.2517s\n",
      "3499it [04:08, 14.37it/s]\titers: 3500, epoch: 11 | loss: 0.2519857\n",
      "\tspeed: 0.0701s/iter; left time: 2357.0921s\n",
      "3599it [04:15, 13.69it/s]\titers: 3600, epoch: 11 | loss: 0.3005330\n",
      "\tspeed: 0.0691s/iter; left time: 2317.5827s\n",
      "3699it [04:22, 14.09it/s]\titers: 3700, epoch: 11 | loss: 0.3009367\n",
      "\tspeed: 0.0721s/iter; left time: 2411.6534s\n",
      "3713it [04:23, 14.10it/s]\n",
      "Epoch: 11 cost time: 263.3467803001404\n",
      "810it [00:26, 30.39it/s]\n",
      "807it [00:26, 30.25it/s]\n",
      "Epoch: 11 | Train Loss: 0.2995192 Vali Loss: 0.3645885 Test Loss: 0.4439737 MAE Loss: 0.4471173\n",
      "lr = 0.0004217885\n",
      "99it [00:07, 14.10it/s]\titers: 100, epoch: 12 | loss: 0.1509874\n",
      "\tspeed: 0.6444s/iter; left time: 21469.2977s\n",
      "199it [00:14, 14.44it/s]\titers: 200, epoch: 12 | loss: 0.3394450\n",
      "\tspeed: 0.0712s/iter; left time: 2366.5357s\n",
      "299it [00:21, 14.07it/s]\titers: 300, epoch: 12 | loss: 0.3195904\n",
      "\tspeed: 0.0707s/iter; left time: 2340.1540s\n",
      "399it [00:28, 13.78it/s]\titers: 400, epoch: 12 | loss: 0.2724038\n",
      "\tspeed: 0.0724s/iter; left time: 2390.1700s\n",
      "499it [00:35, 14.55it/s]\titers: 500, epoch: 12 | loss: 0.3184952\n",
      "\tspeed: 0.0701s/iter; left time: 2307.7439s\n",
      "599it [00:42, 14.45it/s]\titers: 600, epoch: 12 | loss: 0.2330701\n",
      "\tspeed: 0.0707s/iter; left time: 2321.4936s\n",
      "699it [00:50, 13.86it/s]\titers: 700, epoch: 12 | loss: 0.2266781\n",
      "\tspeed: 0.0717s/iter; left time: 2345.6875s\n",
      "799it [00:57, 14.13it/s]\titers: 800, epoch: 12 | loss: 0.5447848\n",
      "\tspeed: 0.0700s/iter; left time: 2284.0424s\n",
      "899it [01:04, 14.97it/s]\titers: 900, epoch: 12 | loss: 0.2503325\n",
      "\tspeed: 0.0717s/iter; left time: 2332.2793s\n",
      "999it [01:11, 14.92it/s]\titers: 1000, epoch: 12 | loss: 0.1742527\n",
      "\tspeed: 0.0710s/iter; left time: 2301.1240s\n",
      "1099it [01:18, 14.10it/s]\titers: 1100, epoch: 12 | loss: 0.5025838\n",
      "\tspeed: 0.0698s/iter; left time: 2256.8195s\n",
      "1199it [01:25, 14.12it/s]\titers: 1200, epoch: 12 | loss: 0.2415927\n",
      "\tspeed: 0.0726s/iter; left time: 2338.8603s\n",
      "1299it [01:32, 14.23it/s]\titers: 1300, epoch: 12 | loss: 0.2686547\n",
      "\tspeed: 0.0705s/iter; left time: 2264.4871s\n",
      "1399it [01:39, 14.03it/s]\titers: 1400, epoch: 12 | loss: 0.3864858\n",
      "\tspeed: 0.0728s/iter; left time: 2331.5438s\n",
      "1499it [01:47, 14.67it/s]\titers: 1500, epoch: 12 | loss: 0.2925336\n",
      "\tspeed: 0.0715s/iter; left time: 2281.1115s\n",
      "1599it [01:54, 13.88it/s]\titers: 1600, epoch: 12 | loss: 0.3702458\n",
      "\tspeed: 0.0706s/iter; left time: 2246.6705s\n",
      "1699it [02:01, 14.00it/s]\titers: 1700, epoch: 12 | loss: 0.3332889\n",
      "\tspeed: 0.0723s/iter; left time: 2293.3709s\n",
      "1799it [02:07, 14.20it/s]\titers: 1800, epoch: 12 | loss: 0.2772009\n",
      "\tspeed: 0.0670s/iter; left time: 2117.4783s\n",
      "1899it [02:15, 13.90it/s]\titers: 1900, epoch: 12 | loss: 0.1514916\n",
      "\tspeed: 0.0719s/iter; left time: 2264.8682s\n",
      "1999it [02:22, 14.12it/s]\titers: 2000, epoch: 12 | loss: 0.1765492\n",
      "\tspeed: 0.0716s/iter; left time: 2251.0956s\n",
      "2099it [02:29, 13.90it/s]\titers: 2100, epoch: 12 | loss: 0.2332756\n",
      "\tspeed: 0.0711s/iter; left time: 2228.1686s\n",
      "2199it [02:36, 14.23it/s]\titers: 2200, epoch: 12 | loss: 0.1891710\n",
      "\tspeed: 0.0708s/iter; left time: 2209.2309s\n",
      "2299it [02:43, 14.09it/s]\titers: 2300, epoch: 12 | loss: 0.2998321\n",
      "\tspeed: 0.0707s/iter; left time: 2201.1985s\n",
      "2399it [02:50, 14.63it/s]\titers: 2400, epoch: 12 | loss: 0.3815722\n",
      "\tspeed: 0.0708s/iter; left time: 2196.1653s\n",
      "2499it [02:57, 14.15it/s]\titers: 2500, epoch: 12 | loss: 0.4097457\n",
      "\tspeed: 0.0716s/iter; left time: 2213.0084s\n",
      "2599it [03:04, 13.77it/s]\titers: 2600, epoch: 12 | loss: 0.2603845\n",
      "\tspeed: 0.0698s/iter; left time: 2150.7414s\n",
      "2699it [03:12, 14.06it/s]\titers: 2700, epoch: 12 | loss: 0.2863677\n",
      "\tspeed: 0.0725s/iter; left time: 2225.9671s\n",
      "2799it [03:19, 14.13it/s]\titers: 2800, epoch: 12 | loss: 0.3533033\n",
      "\tspeed: 0.0709s/iter; left time: 2171.8869s\n",
      "2899it [03:26, 14.08it/s]\titers: 2900, epoch: 12 | loss: 0.2120877\n",
      "\tspeed: 0.0714s/iter; left time: 2180.4203s\n",
      "2999it [03:33, 14.18it/s]\titers: 3000, epoch: 12 | loss: 0.3545184\n",
      "\tspeed: 0.0720s/iter; left time: 2189.3695s\n",
      "3099it [03:40, 13.44it/s]\titers: 3100, epoch: 12 | loss: 0.3811266\n",
      "\tspeed: 0.0713s/iter; left time: 2162.5116s\n",
      "3199it [03:49, 14.04it/s]\titers: 3200, epoch: 12 | loss: 0.3707130\n",
      "\tspeed: 0.0866s/iter; left time: 2618.1840s\n",
      "3299it [03:56, 14.14it/s]\titers: 3300, epoch: 12 | loss: 0.2778952\n",
      "\tspeed: 0.0708s/iter; left time: 2133.8312s\n",
      "3399it [04:03, 14.20it/s]\titers: 3400, epoch: 12 | loss: 0.2310287\n",
      "\tspeed: 0.0709s/iter; left time: 2128.6905s\n",
      "3499it [04:11, 13.04it/s]\titers: 3500, epoch: 12 | loss: 0.2008852\n",
      "\tspeed: 0.0754s/iter; left time: 2255.2510s\n",
      "3599it [04:18, 14.10it/s]\titers: 3600, epoch: 12 | loss: 0.2930796\n",
      "\tspeed: 0.0718s/iter; left time: 2140.2136s\n",
      "3699it [04:25, 14.19it/s]\titers: 3700, epoch: 12 | loss: 0.3361859\n",
      "\tspeed: 0.0724s/iter; left time: 2150.6966s\n",
      "3713it [04:26, 13.93it/s]\n",
      "Epoch: 12 cost time: 266.4823911190033\n",
      "810it [00:27, 29.97it/s]\n",
      "807it [00:26, 30.06it/s]\n",
      "Epoch: 12 | Train Loss: 0.2928803 Vali Loss: 0.3491664 Test Loss: 0.4295338 MAE Loss: 0.4290132\n",
      "lr = 0.0003454980\n",
      "99it [00:07, 14.17it/s]\titers: 100, epoch: 13 | loss: 0.2500547\n",
      "\tspeed: 0.6383s/iter; left time: 18897.5582s\n",
      "199it [00:14, 14.14it/s]\titers: 200, epoch: 13 | loss: 0.3289737\n",
      "\tspeed: 0.0711s/iter; left time: 2096.7974s\n",
      "299it [00:21, 14.16it/s]\titers: 300, epoch: 13 | loss: 0.4403877\n",
      "\tspeed: 0.0715s/iter; left time: 2102.3192s\n",
      "399it [00:28, 14.13it/s]\titers: 400, epoch: 13 | loss: 0.3743571\n",
      "\tspeed: 0.0711s/iter; left time: 2083.5347s\n",
      "499it [00:35, 14.06it/s]\titers: 500, epoch: 13 | loss: 0.2266241\n",
      "\tspeed: 0.0677s/iter; left time: 1977.3900s\n",
      "599it [00:42, 14.01it/s]\titers: 600, epoch: 13 | loss: 0.2079357\n",
      "\tspeed: 0.0706s/iter; left time: 2054.5959s\n",
      "699it [00:49, 14.06it/s]\titers: 700, epoch: 13 | loss: 0.2082679\n",
      "\tspeed: 0.0717s/iter; left time: 2078.9222s\n",
      "799it [00:56, 15.24it/s]\titers: 800, epoch: 13 | loss: 0.2345156\n",
      "\tspeed: 0.0701s/iter; left time: 2027.0753s\n",
      "899it [01:03, 14.15it/s]\titers: 900, epoch: 13 | loss: 0.2828797\n",
      "\tspeed: 0.0686s/iter; left time: 1974.9482s\n",
      "999it [01:11, 13.24it/s]\titers: 1000, epoch: 13 | loss: 0.2040381\n",
      "\tspeed: 0.0758s/iter; left time: 2175.1066s\n",
      "1099it [01:18, 13.96it/s]\titers: 1100, epoch: 13 | loss: 0.1817234\n",
      "\tspeed: 0.0713s/iter; left time: 2038.2601s\n",
      "1199it [01:25, 14.23it/s]\titers: 1200, epoch: 13 | loss: 0.3184826\n",
      "\tspeed: 0.0714s/iter; left time: 2034.9236s\n",
      "1299it [01:32, 14.21it/s]\titers: 1300, epoch: 13 | loss: 0.3097099\n",
      "\tspeed: 0.0718s/iter; left time: 2040.3713s\n",
      "1399it [01:39, 14.19it/s]\titers: 1400, epoch: 13 | loss: 0.1641601\n",
      "\tspeed: 0.0704s/iter; left time: 1993.8599s\n",
      "1499it [01:46, 12.40it/s]\titers: 1500, epoch: 13 | loss: 0.1698398\n",
      "\tspeed: 0.0709s/iter; left time: 2000.3224s\n",
      "1599it [01:53, 14.14it/s]\titers: 1600, epoch: 13 | loss: 0.1701911\n",
      "\tspeed: 0.0706s/iter; left time: 1983.7027s\n",
      "1699it [02:00, 13.22it/s]\titers: 1700, epoch: 13 | loss: 0.3833731\n",
      "\tspeed: 0.0709s/iter; left time: 1986.9018s\n",
      "1799it [02:08, 14.63it/s]\titers: 1800, epoch: 13 | loss: 0.3531256\n",
      "\tspeed: 0.0715s/iter; left time: 1996.5815s\n",
      "1899it [02:15, 14.12it/s]\titers: 1900, epoch: 13 | loss: 0.3888091\n",
      "\tspeed: 0.0706s/iter; left time: 1961.7786s\n",
      "1999it [02:22, 14.13it/s]\titers: 2000, epoch: 13 | loss: 0.1712952\n",
      "\tspeed: 0.0713s/iter; left time: 1974.2570s\n",
      "2099it [02:29, 14.23it/s]\titers: 2100, epoch: 13 | loss: 0.3548581\n",
      "\tspeed: 0.0718s/iter; left time: 1981.9483s\n",
      "2199it [02:36, 12.55it/s]\titers: 2200, epoch: 13 | loss: 0.2814353\n",
      "\tspeed: 0.0702s/iter; left time: 1930.2656s\n",
      "2299it [02:43, 13.81it/s]\titers: 2300, epoch: 13 | loss: 0.2541613\n",
      "\tspeed: 0.0729s/iter; left time: 1997.0025s\n",
      "2399it [02:50, 13.61it/s]\titers: 2400, epoch: 13 | loss: 0.1366356\n",
      "\tspeed: 0.0727s/iter; left time: 1984.0631s\n",
      "2499it [02:58, 14.07it/s]\titers: 2500, epoch: 13 | loss: 0.4193524\n",
      "\tspeed: 0.0717s/iter; left time: 1950.1163s\n",
      "2599it [03:05, 14.30it/s]\titers: 2600, epoch: 13 | loss: 0.2318483\n",
      "\tspeed: 0.0716s/iter; left time: 1939.3724s\n",
      "2699it [03:12, 14.47it/s]\titers: 2700, epoch: 13 | loss: 0.3280040\n",
      "\tspeed: 0.0706s/iter; left time: 1905.3874s\n",
      "2799it [03:19, 14.33it/s]\titers: 2800, epoch: 13 | loss: 0.1456751\n",
      "\tspeed: 0.0731s/iter; left time: 1966.2104s\n",
      "2899it [03:26, 14.41it/s]\titers: 2900, epoch: 13 | loss: 0.5170210\n",
      "\tspeed: 0.0704s/iter; left time: 1888.1756s\n",
      "2999it [03:33, 14.10it/s]\titers: 3000, epoch: 13 | loss: 0.2727808\n",
      "\tspeed: 0.0707s/iter; left time: 1886.8994s\n",
      "3099it [03:40, 14.05it/s]\titers: 3100, epoch: 13 | loss: 0.3808917\n",
      "\tspeed: 0.0713s/iter; left time: 1895.6229s\n",
      "3199it [03:47, 13.84it/s]\titers: 3200, epoch: 13 | loss: 0.4237591\n",
      "\tspeed: 0.0703s/iter; left time: 1862.4158s\n",
      "3299it [03:55, 14.15it/s]\titers: 3300, epoch: 13 | loss: 0.3806382\n",
      "\tspeed: 0.0717s/iter; left time: 1893.1565s\n",
      "3399it [04:02, 14.16it/s]\titers: 3400, epoch: 13 | loss: 0.1700326\n",
      "\tspeed: 0.0707s/iter; left time: 1860.2651s\n",
      "3499it [04:09, 13.94it/s]\titers: 3500, epoch: 13 | loss: 0.1937704\n",
      "\tspeed: 0.0731s/iter; left time: 1914.9228s\n",
      "3599it [04:16, 13.81it/s]\titers: 3600, epoch: 13 | loss: 0.2143539\n",
      "\tspeed: 0.0726s/iter; left time: 1895.4044s\n",
      "3699it [04:24, 12.57it/s]\titers: 3700, epoch: 13 | loss: 0.1635020\n",
      "\tspeed: 0.0752s/iter; left time: 1956.2442s\n",
      "3713it [04:25, 13.98it/s]\n",
      "Epoch: 13 cost time: 265.5321087837219\n",
      "810it [00:27, 29.99it/s]\n",
      "807it [00:26, 30.27it/s]\n",
      "Epoch: 13 | Train Loss: 0.2857190 Vali Loss: 0.3522942 Test Loss: 0.4258270 MAE Loss: 0.4285729\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0002730120\n",
      "99it [00:07, 14.11it/s]\titers: 100, epoch: 14 | loss: 0.1415872\n",
      "\tspeed: 0.6247s/iter; left time: 16174.3113s\n",
      "199it [00:14, 12.09it/s]\titers: 200, epoch: 14 | loss: 0.3726557\n",
      "\tspeed: 0.0734s/iter; left time: 1892.5391s\n",
      "299it [00:22, 13.80it/s]\titers: 300, epoch: 14 | loss: 0.1997793\n",
      "\tspeed: 0.0766s/iter; left time: 1967.0124s\n",
      "399it [00:29, 14.16it/s]\titers: 400, epoch: 14 | loss: 0.2242292\n",
      "\tspeed: 0.0707s/iter; left time: 1809.9619s\n",
      "499it [00:37, 12.37it/s]\titers: 500, epoch: 14 | loss: 0.2321423\n",
      "\tspeed: 0.0759s/iter; left time: 1935.0658s\n",
      "599it [00:44, 14.28it/s]\titers: 600, epoch: 14 | loss: 0.2901591\n",
      "\tspeed: 0.0705s/iter; left time: 1790.7014s\n",
      "699it [00:51, 14.25it/s]\titers: 700, epoch: 14 | loss: 0.3365245\n",
      "\tspeed: 0.0716s/iter; left time: 1812.1030s\n",
      "799it [00:58, 14.21it/s]\titers: 800, epoch: 14 | loss: 0.2503560\n",
      "\tspeed: 0.0716s/iter; left time: 1804.9550s\n",
      "899it [01:05, 14.12it/s]\titers: 900, epoch: 14 | loss: 0.1625718\n",
      "\tspeed: 0.0716s/iter; left time: 1795.5543s\n",
      "999it [01:12, 13.74it/s]\titers: 1000, epoch: 14 | loss: 0.3779067\n",
      "\tspeed: 0.0727s/iter; left time: 1817.0992s\n",
      "1099it [01:20, 14.15it/s]\titers: 1100, epoch: 14 | loss: 0.4091911\n",
      "\tspeed: 0.0710s/iter; left time: 1766.9448s\n",
      "1199it [01:27, 14.33it/s]\titers: 1200, epoch: 14 | loss: 0.3242282\n",
      "\tspeed: 0.0709s/iter; left time: 1756.9423s\n",
      "1299it [01:33, 14.10it/s]\titers: 1300, epoch: 14 | loss: 0.1593705\n",
      "\tspeed: 0.0660s/iter; left time: 1629.8097s\n",
      "1399it [01:40, 14.18it/s]\titers: 1400, epoch: 14 | loss: 0.2169230\n",
      "\tspeed: 0.0675s/iter; left time: 1659.0202s\n",
      "1499it [01:47, 11.75it/s]\titers: 1500, epoch: 14 | loss: 0.1868869\n",
      "\tspeed: 0.0730s/iter; left time: 1788.4081s\n",
      "1599it [01:54, 14.12it/s]\titers: 1600, epoch: 14 | loss: 0.2463919\n",
      "\tspeed: 0.0649s/iter; left time: 1583.6194s\n",
      "1699it [02:01, 12.35it/s]\titers: 1700, epoch: 14 | loss: 0.2685658\n",
      "\tspeed: 0.0750s/iter; left time: 1822.1770s\n",
      "1799it [02:08, 14.72it/s]\titers: 1800, epoch: 14 | loss: 0.3146133\n",
      "\tspeed: 0.0717s/iter; left time: 1733.9604s\n",
      "1899it [02:15, 14.11it/s]\titers: 1900, epoch: 14 | loss: 0.2438359\n",
      "\tspeed: 0.0705s/iter; left time: 1698.7160s\n",
      "1999it [02:23, 13.49it/s]\titers: 2000, epoch: 14 | loss: 0.3774941\n",
      "\tspeed: 0.0724s/iter; left time: 1737.4126s\n",
      "2099it [02:30, 14.16it/s]\titers: 2100, epoch: 14 | loss: 0.1291581\n",
      "\tspeed: 0.0708s/iter; left time: 1692.1527s\n",
      "2199it [02:37, 13.83it/s]\titers: 2200, epoch: 14 | loss: 0.1385535\n",
      "\tspeed: 0.0720s/iter; left time: 1713.2081s\n",
      "2299it [02:44, 14.20it/s]\titers: 2300, epoch: 14 | loss: 0.3594226\n",
      "\tspeed: 0.0713s/iter; left time: 1690.1842s\n",
      "2399it [02:52, 14.10it/s]\titers: 2400, epoch: 14 | loss: 0.1384499\n",
      "\tspeed: 0.0756s/iter; left time: 1782.9678s\n",
      "2499it [02:59, 14.13it/s]\titers: 2500, epoch: 14 | loss: 0.2154482\n",
      "\tspeed: 0.0708s/iter; left time: 1662.1393s\n",
      "2599it [03:06, 14.12it/s]\titers: 2600, epoch: 14 | loss: 0.2900347\n",
      "\tspeed: 0.0718s/iter; left time: 1680.0744s\n",
      "2699it [03:13, 14.37it/s]\titers: 2700, epoch: 14 | loss: 0.3648814\n",
      "\tspeed: 0.0708s/iter; left time: 1650.0492s\n",
      "2799it [03:20, 14.17it/s]\titers: 2800, epoch: 14 | loss: 0.2247330\n",
      "\tspeed: 0.0726s/iter; left time: 1684.1493s\n",
      "2899it [03:27, 14.46it/s]\titers: 2900, epoch: 14 | loss: 0.1582369\n",
      "\tspeed: 0.0706s/iter; left time: 1631.4358s\n",
      "2999it [03:35, 14.16it/s]\titers: 3000, epoch: 14 | loss: 0.2606623\n",
      "\tspeed: 0.0718s/iter; left time: 1650.0448s\n",
      "3099it [03:42, 14.15it/s]\titers: 3100, epoch: 14 | loss: 0.1796550\n",
      "\tspeed: 0.0714s/iter; left time: 1633.4689s\n",
      "3199it [03:49, 14.24it/s]\titers: 3200, epoch: 14 | loss: 0.1905132\n",
      "\tspeed: 0.0703s/iter; left time: 1602.1653s\n",
      "3299it [03:56, 14.38it/s]\titers: 3300, epoch: 14 | loss: 0.2390756\n",
      "\tspeed: 0.0731s/iter; left time: 1658.3199s\n",
      "3399it [04:03, 13.84it/s]\titers: 3400, epoch: 14 | loss: 0.2047181\n",
      "\tspeed: 0.0710s/iter; left time: 1604.9379s\n",
      "3499it [04:10, 14.38it/s]\titers: 3500, epoch: 14 | loss: 0.4570910\n",
      "\tspeed: 0.0713s/iter; left time: 1603.5419s\n",
      "3599it [04:17, 14.44it/s]\titers: 3600, epoch: 14 | loss: 0.3326656\n",
      "\tspeed: 0.0695s/iter; left time: 1555.8251s\n",
      "3699it [04:24, 14.16it/s]\titers: 3700, epoch: 14 | loss: 0.4978660\n",
      "\tspeed: 0.0709s/iter; left time: 1579.7417s\n",
      "3713it [04:25, 13.97it/s]\n",
      "Epoch: 14 cost time: 265.8192241191864\n",
      "810it [00:30, 26.49it/s]\n",
      "807it [00:26, 30.05it/s]\n",
      "Epoch: 14 | Train Loss: 0.2815254 Vali Loss: 0.3473715 Test Loss: 0.4298393 MAE Loss: 0.4306547\n",
      "lr = 0.0002061153\n",
      "99it [00:07, 12.51it/s]\titers: 100, epoch: 15 | loss: 0.2852388\n",
      "\tspeed: 0.6820s/iter; left time: 15126.4852s\n",
      "199it [00:14, 14.35it/s]\titers: 200, epoch: 15 | loss: 0.2945589\n",
      "\tspeed: 0.0706s/iter; left time: 1557.8939s\n",
      "299it [00:21, 14.29it/s]\titers: 300, epoch: 15 | loss: 0.3102703\n",
      "\tspeed: 0.0705s/iter; left time: 1549.4757s\n",
      "399it [00:28, 14.01it/s]\titers: 400, epoch: 15 | loss: 0.2265408\n",
      "\tspeed: 0.0712s/iter; left time: 1557.9586s\n",
      "499it [00:35, 13.93it/s]\titers: 500, epoch: 15 | loss: 0.2774400\n",
      "\tspeed: 0.0716s/iter; left time: 1558.3881s\n",
      "599it [00:42, 14.14it/s]\titers: 600, epoch: 15 | loss: 0.2331572\n",
      "\tspeed: 0.0704s/iter; left time: 1525.9834s\n",
      "699it [00:50, 14.15it/s]\titers: 700, epoch: 15 | loss: 0.3521843\n",
      "\tspeed: 0.0715s/iter; left time: 1542.2400s\n",
      "799it [00:57, 14.13it/s]\titers: 800, epoch: 15 | loss: 0.2242591\n",
      "\tspeed: 0.0717s/iter; left time: 1539.2591s\n",
      "899it [01:04, 14.34it/s]\titers: 900, epoch: 15 | loss: 0.3982336\n",
      "\tspeed: 0.0697s/iter; left time: 1490.2392s\n",
      "999it [01:11, 14.18it/s]\titers: 1000, epoch: 15 | loss: 0.1443637\n",
      "\tspeed: 0.0723s/iter; left time: 1538.0897s\n",
      "1099it [01:18, 14.01it/s]\titers: 1100, epoch: 15 | loss: 0.4453093\n",
      "\tspeed: 0.0712s/iter; left time: 1507.8481s\n",
      "1199it [01:25, 14.19it/s]\titers: 1200, epoch: 15 | loss: 0.2708587\n",
      "\tspeed: 0.0709s/iter; left time: 1495.1990s\n",
      "1299it [01:32, 13.86it/s]\titers: 1300, epoch: 15 | loss: 0.1108242\n",
      "\tspeed: 0.0740s/iter; left time: 1553.2372s\n",
      "1399it [01:40, 13.79it/s]\titers: 1400, epoch: 15 | loss: 0.1267032\n",
      "\tspeed: 0.0715s/iter; left time: 1493.2097s\n",
      "1499it [01:47, 13.08it/s]\titers: 1500, epoch: 15 | loss: 0.4226899\n",
      "\tspeed: 0.0710s/iter; left time: 1474.7860s\n",
      "1599it [01:54, 14.15it/s]\titers: 1600, epoch: 15 | loss: 0.2651436\n",
      "\tspeed: 0.0720s/iter; left time: 1489.1996s\n",
      "1699it [02:01, 14.16it/s]\titers: 1700, epoch: 15 | loss: 0.6496507\n",
      "\tspeed: 0.0703s/iter; left time: 1445.9538s\n",
      "1799it [02:08, 14.03it/s]\titers: 1800, epoch: 15 | loss: 0.2868510\n",
      "\tspeed: 0.0717s/iter; left time: 1468.2332s\n",
      "1899it [02:15, 13.73it/s]\titers: 1900, epoch: 15 | loss: 0.1607992\n",
      "\tspeed: 0.0720s/iter; left time: 1466.6574s\n",
      "1999it [02:22, 14.01it/s]\titers: 2000, epoch: 15 | loss: 0.2209032\n",
      "\tspeed: 0.0672s/iter; left time: 1362.8965s\n",
      "2099it [02:29, 14.17it/s]\titers: 2100, epoch: 15 | loss: 0.2851955\n",
      "\tspeed: 0.0741s/iter; left time: 1494.2890s\n",
      "2199it [02:37, 14.18it/s]\titers: 2200, epoch: 15 | loss: 0.2628145\n",
      "\tspeed: 0.0719s/iter; left time: 1442.8267s\n",
      "2299it [02:44, 14.13it/s]\titers: 2300, epoch: 15 | loss: 0.1971958\n",
      "\tspeed: 0.0708s/iter; left time: 1413.5740s\n",
      "2399it [02:51, 12.78it/s]\titers: 2400, epoch: 15 | loss: 0.2070485\n",
      "\tspeed: 0.0727s/iter; left time: 1445.9400s\n",
      "2499it [02:58, 14.69it/s]\titers: 2500, epoch: 15 | loss: 0.2627920\n",
      "\tspeed: 0.0702s/iter; left time: 1388.2625s\n",
      "2599it [03:05, 14.20it/s]\titers: 2600, epoch: 15 | loss: 0.2176888\n",
      "\tspeed: 0.0705s/iter; left time: 1387.7861s\n",
      "2699it [03:12, 13.90it/s]\titers: 2700, epoch: 15 | loss: 0.2749127\n",
      "\tspeed: 0.0728s/iter; left time: 1424.9465s\n",
      "2799it [03:19, 14.13it/s]\titers: 2800, epoch: 15 | loss: 0.2533981\n",
      "\tspeed: 0.0705s/iter; left time: 1372.4999s\n",
      "2899it [03:27, 14.07it/s]\titers: 2900, epoch: 15 | loss: 0.4910263\n",
      "\tspeed: 0.0714s/iter; left time: 1383.0317s\n",
      "2999it [03:34, 13.87it/s]\titers: 3000, epoch: 15 | loss: 0.4446198\n",
      "\tspeed: 0.0721s/iter; left time: 1389.5355s\n",
      "3099it [03:41, 13.38it/s]\titers: 3100, epoch: 15 | loss: 0.1879049\n",
      "\tspeed: 0.0695s/iter; left time: 1333.0306s\n",
      "3199it [03:48, 14.07it/s]\titers: 3200, epoch: 15 | loss: 0.2714720\n",
      "\tspeed: 0.0722s/iter; left time: 1376.9614s\n",
      "3299it [03:55, 13.52it/s]\titers: 3300, epoch: 15 | loss: 0.2499533\n",
      "\tspeed: 0.0750s/iter; left time: 1423.3510s\n",
      "3399it [04:03, 12.08it/s]\titers: 3400, epoch: 15 | loss: 0.3669249\n",
      "\tspeed: 0.0734s/iter; left time: 1386.5623s\n",
      "3499it [04:10, 15.92it/s]\titers: 3500, epoch: 15 | loss: 0.2670145\n",
      "\tspeed: 0.0736s/iter; left time: 1382.9946s\n",
      "3599it [04:17, 13.71it/s]\titers: 3600, epoch: 15 | loss: 0.2108040\n",
      "\tspeed: 0.0733s/iter; left time: 1369.9499s\n",
      "3699it [04:25, 12.14it/s]\titers: 3700, epoch: 15 | loss: 0.3302063\n",
      "\tspeed: 0.0726s/iter; left time: 1349.6748s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 15 cost time: 266.32483172416687\n",
      "810it [00:28, 28.69it/s]\n",
      "807it [00:27, 28.84it/s]\n",
      "Epoch: 15 | Train Loss: 0.2765293 Vali Loss: 0.3472695 Test Loss: 0.4232479 MAE Loss: 0.4269224\n",
      "lr = 0.0001464551\n",
      "99it [00:07, 13.22it/s]\titers: 100, epoch: 16 | loss: 0.2020161\n",
      "\tspeed: 0.6677s/iter; left time: 12329.2829s\n",
      "199it [00:14, 14.28it/s]\titers: 200, epoch: 16 | loss: 0.2949465\n",
      "\tspeed: 0.0720s/iter; left time: 1322.1263s\n",
      "299it [00:21, 14.28it/s]\titers: 300, epoch: 16 | loss: 0.1851370\n",
      "\tspeed: 0.0708s/iter; left time: 1294.0234s\n",
      "399it [00:29, 14.21it/s]\titers: 400, epoch: 16 | loss: 0.1348809\n",
      "\tspeed: 0.0736s/iter; left time: 1337.0965s\n",
      "499it [00:36, 14.05it/s]\titers: 500, epoch: 16 | loss: 0.2194290\n",
      "\tspeed: 0.0708s/iter; left time: 1279.9519s\n",
      "599it [00:43, 12.26it/s]\titers: 600, epoch: 16 | loss: 0.1609053\n",
      "\tspeed: 0.0758s/iter; left time: 1362.1767s\n",
      "699it [00:50, 16.04it/s]\titers: 700, epoch: 16 | loss: 0.2201415\n",
      "\tspeed: 0.0671s/iter; left time: 1199.4789s\n",
      "799it [00:57, 11.22it/s]\titers: 800, epoch: 16 | loss: 0.1854500\n",
      "\tspeed: 0.0705s/iter; left time: 1252.7707s\n",
      "899it [01:04, 15.61it/s]\titers: 900, epoch: 16 | loss: 0.3085216\n",
      "\tspeed: 0.0717s/iter; left time: 1266.8955s\n",
      "999it [01:11, 14.16it/s]\titers: 1000, epoch: 16 | loss: 0.1788992\n",
      "\tspeed: 0.0694s/iter; left time: 1219.5491s\n",
      "1099it [01:18, 14.45it/s]\titers: 1100, epoch: 16 | loss: 0.1909116\n",
      "\tspeed: 0.0678s/iter; left time: 1183.6383s\n",
      "1199it [01:25, 14.09it/s]\titers: 1200, epoch: 16 | loss: 0.4690150\n",
      "\tspeed: 0.0719s/iter; left time: 1247.7998s\n",
      "1299it [01:32, 11.88it/s]\titers: 1300, epoch: 16 | loss: 0.1999692\n",
      "\tspeed: 0.0721s/iter; left time: 1245.6674s\n",
      "1399it [01:40, 14.26it/s]\titers: 1400, epoch: 16 | loss: 0.2140208\n",
      "\tspeed: 0.0717s/iter; left time: 1230.5630s\n",
      "1499it [01:47, 15.23it/s]\titers: 1500, epoch: 16 | loss: 0.2056334\n",
      "\tspeed: 0.0698s/iter; left time: 1190.7839s\n",
      "1599it [01:54, 11.54it/s]\titers: 1600, epoch: 16 | loss: 0.1058935\n",
      "\tspeed: 0.0729s/iter; left time: 1236.2800s\n",
      "1699it [02:01, 14.36it/s]\titers: 1700, epoch: 16 | loss: 0.3025618\n",
      "\tspeed: 0.0706s/iter; left time: 1191.5024s\n",
      "1799it [02:08, 13.56it/s]\titers: 1800, epoch: 16 | loss: 0.2963597\n",
      "\tspeed: 0.0737s/iter; left time: 1235.8914s\n",
      "1899it [02:16, 14.18it/s]\titers: 1900, epoch: 16 | loss: 0.2280244\n",
      "\tspeed: 0.0719s/iter; left time: 1197.9145s\n",
      "1999it [02:23, 14.15it/s]\titers: 2000, epoch: 16 | loss: 0.2398469\n",
      "\tspeed: 0.0703s/iter; left time: 1164.7272s\n",
      "2099it [02:30, 13.94it/s]\titers: 2100, epoch: 16 | loss: 0.2779323\n",
      "\tspeed: 0.0714s/iter; left time: 1176.0180s\n",
      "2199it [02:37, 14.11it/s]\titers: 2200, epoch: 16 | loss: 0.2129690\n",
      "\tspeed: 0.0707s/iter; left time: 1157.7480s\n",
      "2299it [02:44, 15.68it/s]\titers: 2300, epoch: 16 | loss: 0.2281235\n",
      "\tspeed: 0.0699s/iter; left time: 1136.9740s\n",
      "2399it [02:50, 14.19it/s]\titers: 2400, epoch: 16 | loss: 0.2684809\n",
      "\tspeed: 0.0662s/iter; left time: 1069.8623s\n",
      "2499it [02:57, 14.18it/s]\titers: 2500, epoch: 16 | loss: 0.3272431\n",
      "\tspeed: 0.0707s/iter; left time: 1136.2152s\n",
      "2599it [03:05, 12.62it/s]\titers: 2600, epoch: 16 | loss: 0.3226390\n",
      "\tspeed: 0.0750s/iter; left time: 1197.5399s\n",
      "2699it [03:12, 12.85it/s]\titers: 2700, epoch: 16 | loss: 0.3296982\n",
      "\tspeed: 0.0729s/iter; left time: 1156.8568s\n",
      "2799it [03:20, 11.95it/s]\titers: 2800, epoch: 16 | loss: 0.1943063\n",
      "\tspeed: 0.0733s/iter; left time: 1156.1464s\n",
      "2899it [03:27, 14.19it/s]\titers: 2900, epoch: 16 | loss: 0.3767173\n",
      "\tspeed: 0.0739s/iter; left time: 1157.5080s\n",
      "2999it [03:34, 13.71it/s]\titers: 3000, epoch: 16 | loss: 0.1849061\n",
      "\tspeed: 0.0745s/iter; left time: 1159.6154s\n",
      "3099it [03:42, 14.12it/s]\titers: 3100, epoch: 16 | loss: 0.2574348\n",
      "\tspeed: 0.0725s/iter; left time: 1120.9268s\n",
      "3199it [03:49, 14.10it/s]\titers: 3200, epoch: 16 | loss: 0.6203088\n",
      "\tspeed: 0.0717s/iter; left time: 1102.2683s\n",
      "3299it [03:56, 12.09it/s]\titers: 3300, epoch: 16 | loss: 0.1819046\n",
      "\tspeed: 0.0731s/iter; left time: 1115.4952s\n",
      "3399it [04:03, 14.15it/s]\titers: 3400, epoch: 16 | loss: 0.2000389\n",
      "\tspeed: 0.0723s/iter; left time: 1096.1722s\n",
      "3499it [04:10, 14.09it/s]\titers: 3500, epoch: 16 | loss: 0.3431151\n",
      "\tspeed: 0.0708s/iter; left time: 1066.0556s\n",
      "3599it [04:18, 13.64it/s]\titers: 3600, epoch: 16 | loss: 0.3790014\n",
      "\tspeed: 0.0731s/iter; left time: 1093.6068s\n",
      "3699it [04:25, 14.08it/s]\titers: 3700, epoch: 16 | loss: 0.2359140\n",
      "\tspeed: 0.0709s/iter; left time: 1053.5201s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 16 cost time: 266.38344049453735\n",
      "810it [00:27, 29.91it/s]\n",
      "807it [00:26, 30.10it/s]\n",
      "Epoch: 16 | Train Loss: 0.2730362 Vali Loss: 0.3435258 Test Loss: 0.4203814 MAE Loss: 0.4198538\n",
      "lr = 0.0000955005\n",
      "99it [00:07, 13.89it/s]\titers: 100, epoch: 17 | loss: 0.1640527\n",
      "\tspeed: 0.6434s/iter; left time: 9492.2560s\n",
      "199it [00:14, 13.94it/s]\titers: 200, epoch: 17 | loss: 0.2565632\n",
      "\tspeed: 0.0710s/iter; left time: 1039.7335s\n",
      "299it [00:21, 12.61it/s]\titers: 300, epoch: 17 | loss: 0.2054514\n",
      "\tspeed: 0.0721s/iter; left time: 1049.3338s\n",
      "399it [00:28, 14.15it/s]\titers: 400, epoch: 17 | loss: 0.2421706\n",
      "\tspeed: 0.0719s/iter; left time: 1038.8073s\n",
      "499it [00:35, 15.75it/s]\titers: 500, epoch: 17 | loss: 0.2484227\n",
      "\tspeed: 0.0692s/iter; left time: 992.7476s\n",
      "599it [00:43, 13.47it/s]\titers: 600, epoch: 17 | loss: 0.3249735\n",
      "\tspeed: 0.0710s/iter; left time: 1012.2464s\n",
      "699it [00:50, 14.27it/s]\titers: 700, epoch: 17 | loss: 0.3014257\n",
      "\tspeed: 0.0704s/iter; left time: 996.5399s\n",
      "799it [00:57, 15.74it/s]\titers: 800, epoch: 17 | loss: 0.4434174\n",
      "\tspeed: 0.0697s/iter; left time: 979.6321s\n",
      "899it [01:03, 14.09it/s]\titers: 900, epoch: 17 | loss: 0.2459723\n",
      "\tspeed: 0.0668s/iter; left time: 931.8527s\n",
      "999it [01:10, 13.82it/s]\titers: 1000, epoch: 17 | loss: 0.2611732\n",
      "\tspeed: 0.0707s/iter; left time: 979.8444s\n",
      "1099it [01:17, 14.15it/s]\titers: 1100, epoch: 17 | loss: 0.3641392\n",
      "\tspeed: 0.0719s/iter; left time: 988.6241s\n",
      "1199it [01:25, 13.95it/s]\titers: 1200, epoch: 17 | loss: 0.5401652\n",
      "\tspeed: 0.0717s/iter; left time: 979.5378s\n",
      "1299it [01:32, 14.15it/s]\titers: 1300, epoch: 17 | loss: 0.2258662\n",
      "\tspeed: 0.0706s/iter; left time: 956.2947s\n",
      "1399it [01:39, 14.09it/s]\titers: 1400, epoch: 17 | loss: 0.4497410\n",
      "\tspeed: 0.0732s/iter; left time: 984.3799s\n",
      "1499it [01:46, 14.07it/s]\titers: 1500, epoch: 17 | loss: 0.1883235\n",
      "\tspeed: 0.0711s/iter; left time: 949.4421s\n",
      "1599it [01:53, 14.20it/s]\titers: 1600, epoch: 17 | loss: 0.1766431\n",
      "\tspeed: 0.0731s/iter; left time: 969.1876s\n",
      "1699it [02:01, 14.00it/s]\titers: 1700, epoch: 17 | loss: 0.2800076\n",
      "\tspeed: 0.0720s/iter; left time: 947.3799s\n",
      "1799it [02:08, 14.09it/s]\titers: 1800, epoch: 17 | loss: 0.2221693\n",
      "\tspeed: 0.0713s/iter; left time: 930.6308s\n",
      "1899it [02:15, 13.98it/s]\titers: 1900, epoch: 17 | loss: 0.2821738\n",
      "\tspeed: 0.0726s/iter; left time: 940.8874s\n",
      "1999it [02:22, 14.18it/s]\titers: 2000, epoch: 17 | loss: 0.1933572\n",
      "\tspeed: 0.0706s/iter; left time: 907.1788s\n",
      "2099it [02:29, 14.95it/s]\titers: 2100, epoch: 17 | loss: 0.2550882\n",
      "\tspeed: 0.0724s/iter; left time: 923.8579s\n",
      "2199it [02:37, 14.27it/s]\titers: 2200, epoch: 17 | loss: 0.3099648\n",
      "\tspeed: 0.0718s/iter; left time: 908.9712s\n",
      "2299it [02:44, 14.18it/s]\titers: 2300, epoch: 17 | loss: 0.2622376\n",
      "\tspeed: 0.0747s/iter; left time: 937.9557s\n",
      "2399it [02:51, 14.34it/s]\titers: 2400, epoch: 17 | loss: 0.2911693\n",
      "\tspeed: 0.0721s/iter; left time: 897.9677s\n",
      "2499it [02:58, 14.14it/s]\titers: 2500, epoch: 17 | loss: 0.2848457\n",
      "\tspeed: 0.0705s/iter; left time: 871.4083s\n",
      "2599it [03:05, 12.59it/s]\titers: 2600, epoch: 17 | loss: 0.1373540\n",
      "\tspeed: 0.0724s/iter; left time: 887.5626s\n",
      "2699it [03:15, 10.27it/s]\titers: 2700, epoch: 17 | loss: 0.3808969\n",
      "\tspeed: 0.0967s/iter; left time: 1175.5653s\n",
      "2799it [03:23, 13.30it/s]\titers: 2800, epoch: 17 | loss: 0.3286078\n",
      "\tspeed: 0.0763s/iter; left time: 919.4191s\n",
      "2899it [03:30, 14.26it/s]\titers: 2900, epoch: 17 | loss: 0.2710432\n",
      "\tspeed: 0.0725s/iter; left time: 866.6581s\n",
      "2999it [03:37, 14.13it/s]\titers: 3000, epoch: 17 | loss: 0.2120618\n",
      "\tspeed: 0.0705s/iter; left time: 836.0145s\n",
      "3099it [03:44, 13.79it/s]\titers: 3100, epoch: 17 | loss: 0.2421237\n",
      "\tspeed: 0.0716s/iter; left time: 841.5532s\n",
      "3199it [03:51, 13.44it/s]\titers: 3200, epoch: 17 | loss: 0.3240352\n",
      "\tspeed: 0.0718s/iter; left time: 836.2547s\n",
      "3299it [03:58, 14.08it/s]\titers: 3300, epoch: 17 | loss: 0.2677674\n",
      "\tspeed: 0.0703s/iter; left time: 812.6366s\n",
      "3399it [04:05, 14.82it/s]\titers: 3400, epoch: 17 | loss: 0.2419178\n",
      "\tspeed: 0.0699s/iter; left time: 800.6305s\n",
      "3499it [04:13, 14.03it/s]\titers: 3500, epoch: 17 | loss: 0.3133871\n",
      "\tspeed: 0.0725s/iter; left time: 823.3669s\n",
      "3599it [04:20, 14.32it/s]\titers: 3600, epoch: 17 | loss: 0.5323966\n",
      "\tspeed: 0.0710s/iter; left time: 798.9455s\n",
      "3699it [04:27, 14.51it/s]\titers: 3700, epoch: 17 | loss: 0.3406528\n",
      "\tspeed: 0.0712s/iter; left time: 793.8341s\n",
      "3713it [04:28, 13.83it/s]\n",
      "Epoch: 17 cost time: 268.47436451911926\n",
      "810it [00:26, 30.05it/s]\n",
      "807it [00:26, 30.44it/s]\n",
      "Epoch: 17 | Train Loss: 0.2700421 Vali Loss: 0.3400391 Test Loss: 0.4160352 MAE Loss: 0.4166830\n",
      "lr = 0.0000545062\n",
      "99it [00:07, 14.12it/s]\titers: 100, epoch: 18 | loss: 0.3171934\n",
      "\tspeed: 0.6371s/iter; left time: 7033.9441s\n",
      "199it [00:14, 14.15it/s]\titers: 200, epoch: 18 | loss: 0.1833807\n",
      "\tspeed: 0.0714s/iter; left time: 780.9932s\n",
      "299it [00:22, 14.08it/s]\titers: 300, epoch: 18 | loss: 0.1346787\n",
      "\tspeed: 0.0742s/iter; left time: 804.2939s\n",
      "399it [00:29, 14.28it/s]\titers: 400, epoch: 18 | loss: 0.3923603\n",
      "\tspeed: 0.0709s/iter; left time: 761.8342s\n",
      "499it [00:36, 14.02it/s]\titers: 500, epoch: 18 | loss: 0.1583522\n",
      "\tspeed: 0.0733s/iter; left time: 780.1489s\n",
      "599it [00:43, 14.58it/s]\titers: 600, epoch: 18 | loss: 0.3503875\n",
      "\tspeed: 0.0718s/iter; left time: 756.4285s\n",
      "699it [00:50, 13.21it/s]\titers: 700, epoch: 18 | loss: 0.3783064\n",
      "\tspeed: 0.0711s/iter; left time: 742.7562s\n",
      "799it [00:58, 12.68it/s]\titers: 800, epoch: 18 | loss: 0.2059459\n",
      "\tspeed: 0.0743s/iter; left time: 768.5243s\n",
      "898it [01:07, 11.37it/s]\titers: 900, epoch: 18 | loss: 0.2104725\n",
      "\tspeed: 0.0934s/iter; left time: 956.6168s\n",
      "998it [01:15, 14.12it/s]\titers: 1000, epoch: 18 | loss: 0.2512944\n",
      "\tspeed: 0.0808s/iter; left time: 819.4730s\n",
      "1098it [01:22, 14.02it/s]\titers: 1100, epoch: 18 | loss: 0.4875512\n",
      "\tspeed: 0.0717s/iter; left time: 719.4262s\n",
      "1199it [01:30, 14.05it/s]\titers: 1200, epoch: 18 | loss: 0.3160571\n",
      "\tspeed: 0.0752s/iter; left time: 747.0066s\n",
      "1299it [01:37, 14.29it/s]\titers: 1300, epoch: 18 | loss: 0.4352148\n",
      "\tspeed: 0.0721s/iter; left time: 709.2237s\n",
      "1399it [01:44, 14.48it/s]\titers: 1400, epoch: 18 | loss: 0.2360902\n",
      "\tspeed: 0.0710s/iter; left time: 691.9889s\n",
      "1499it [01:51, 12.18it/s]\titers: 1500, epoch: 18 | loss: 0.2842156\n",
      "\tspeed: 0.0735s/iter; left time: 708.7495s\n",
      "1599it [01:59, 14.12it/s]\titers: 1600, epoch: 18 | loss: 0.3081040\n",
      "\tspeed: 0.0707s/iter; left time: 674.1794s\n",
      "1699it [02:06, 14.07it/s]\titers: 1700, epoch: 18 | loss: 0.1965987\n",
      "\tspeed: 0.0714s/iter; left time: 673.9922s\n",
      "1799it [02:13, 14.13it/s]\titers: 1800, epoch: 18 | loss: 0.3155457\n",
      "\tspeed: 0.0733s/iter; left time: 684.2618s\n",
      "1899it [02:20, 14.78it/s]\titers: 1900, epoch: 18 | loss: 0.2459525\n",
      "\tspeed: 0.0709s/iter; left time: 654.8524s\n",
      "1999it [02:27, 13.56it/s]\titers: 2000, epoch: 18 | loss: 0.2038857\n",
      "\tspeed: 0.0728s/iter; left time: 665.7990s\n",
      "2099it [02:35, 14.19it/s]\titers: 2100, epoch: 18 | loss: 0.1858789\n",
      "\tspeed: 0.0727s/iter; left time: 657.2816s\n",
      "2199it [02:42, 14.07it/s]\titers: 2200, epoch: 18 | loss: 0.3386445\n",
      "\tspeed: 0.0715s/iter; left time: 639.1112s\n",
      "2299it [02:49, 14.13it/s]\titers: 2300, epoch: 18 | loss: 0.2114703\n",
      "\tspeed: 0.0725s/iter; left time: 640.5781s\n",
      "2399it [02:57, 12.99it/s]\titers: 2400, epoch: 18 | loss: 0.3746703\n",
      "\tspeed: 0.0774s/iter; left time: 676.5977s\n",
      "2499it [03:04, 14.33it/s]\titers: 2500, epoch: 18 | loss: 0.1676080\n",
      "\tspeed: 0.0711s/iter; left time: 614.2327s\n",
      "2599it [03:11, 14.51it/s]\titers: 2600, epoch: 18 | loss: 0.1944087\n",
      "\tspeed: 0.0686s/iter; left time: 586.0570s\n",
      "2699it [03:18, 14.08it/s]\titers: 2700, epoch: 18 | loss: 0.4498771\n",
      "\tspeed: 0.0748s/iter; left time: 631.4720s\n",
      "2799it [03:26, 13.92it/s]\titers: 2800, epoch: 18 | loss: 0.1481468\n",
      "\tspeed: 0.0753s/iter; left time: 627.8141s\n",
      "2899it [03:34, 13.62it/s]\titers: 2900, epoch: 18 | loss: 0.2155235\n",
      "\tspeed: 0.0791s/iter; left time: 652.1688s\n",
      "2999it [03:41, 15.09it/s]\titers: 3000, epoch: 18 | loss: 0.2635684\n",
      "\tspeed: 0.0705s/iter; left time: 574.1496s\n",
      "3099it [03:48, 12.87it/s]\titers: 3100, epoch: 18 | loss: 0.3060077\n",
      "\tspeed: 0.0775s/iter; left time: 622.8654s\n",
      "3199it [03:56, 14.11it/s]\titers: 3200, epoch: 18 | loss: 0.1600410\n",
      "\tspeed: 0.0708s/iter; left time: 562.3723s\n",
      "3299it [04:03, 14.01it/s]\titers: 3300, epoch: 18 | loss: 0.1447030\n",
      "\tspeed: 0.0720s/iter; left time: 564.3887s\n",
      "3399it [04:11, 13.13it/s]\titers: 3400, epoch: 18 | loss: 0.3035178\n",
      "\tspeed: 0.0792s/iter; left time: 613.2628s\n",
      "3499it [04:18, 14.22it/s]\titers: 3500, epoch: 18 | loss: 0.2496608\n",
      "\tspeed: 0.0717s/iter; left time: 547.9156s\n",
      "3599it [04:25, 14.11it/s]\titers: 3600, epoch: 18 | loss: 0.4928241\n",
      "\tspeed: 0.0751s/iter; left time: 566.1162s\n",
      "3699it [04:32, 14.18it/s]\titers: 3700, epoch: 18 | loss: 0.3123909\n",
      "\tspeed: 0.0685s/iter; left time: 509.4965s\n",
      "3713it [04:33, 13.56it/s]\n",
      "Epoch: 18 cost time: 273.76011872291565\n",
      "810it [00:28, 28.50it/s]\n",
      "807it [00:28, 28.68it/s]\n",
      "Epoch: 18 | Train Loss: 0.2671667 Vali Loss: 0.3431970 Test Loss: 0.4182879 MAE Loss: 0.4214019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000244815\n",
      "99it [00:07, 14.14it/s]\titers: 100, epoch: 19 | loss: 0.2765492\n",
      "\tspeed: 0.6512s/iter; left time: 4771.3491s\n",
      "198it [00:15, 14.27it/s]\titers: 200, epoch: 19 | loss: 0.2169117\n",
      "\tspeed: 0.0768s/iter; left time: 554.7980s\n",
      "298it [00:22, 13.84it/s]\titers: 300, epoch: 19 | loss: 0.2999817\n",
      "\tspeed: 0.0710s/iter; left time: 506.1294s\n",
      "399it [00:29, 14.09it/s]\titers: 400, epoch: 19 | loss: 0.1898630\n",
      "\tspeed: 0.0770s/iter; left time: 541.3909s\n",
      "499it [00:37, 14.25it/s]\titers: 500, epoch: 19 | loss: 0.3765214\n",
      "\tspeed: 0.0708s/iter; left time: 490.3359s\n",
      "599it [00:44, 14.25it/s]\titers: 600, epoch: 19 | loss: 0.2427113\n",
      "\tspeed: 0.0745s/iter; left time: 508.3603s\n",
      "699it [00:51, 15.65it/s]\titers: 700, epoch: 19 | loss: 0.2246418\n",
      "\tspeed: 0.0698s/iter; left time: 469.5133s\n",
      "799it [00:58, 13.93it/s]\titers: 800, epoch: 19 | loss: 0.5571246\n",
      "\tspeed: 0.0741s/iter; left time: 491.2941s\n",
      "899it [01:06, 13.99it/s]\titers: 900, epoch: 19 | loss: 0.1534219\n",
      "\tspeed: 0.0732s/iter; left time: 477.7612s\n",
      "999it [01:13, 14.15it/s]\titers: 1000, epoch: 19 | loss: 0.3163153\n",
      "\tspeed: 0.0748s/iter; left time: 480.5569s\n",
      "1099it [01:20, 13.49it/s]\titers: 1100, epoch: 19 | loss: 0.3593818\n",
      "\tspeed: 0.0716s/iter; left time: 452.7463s\n",
      "1199it [01:28, 14.09it/s]\titers: 1200, epoch: 19 | loss: 0.2577397\n",
      "\tspeed: 0.0756s/iter; left time: 470.8791s\n",
      "1299it [01:35, 14.42it/s]\titers: 1300, epoch: 19 | loss: 0.3132360\n",
      "\tspeed: 0.0708s/iter; left time: 434.0518s\n",
      "1399it [01:43, 11.84it/s]\titers: 1400, epoch: 19 | loss: 0.3073771\n",
      "\tspeed: 0.0769s/iter; left time: 463.6571s\n",
      "1499it [01:50, 13.81it/s]\titers: 1500, epoch: 19 | loss: 0.1983021\n",
      "\tspeed: 0.0711s/iter; left time: 421.4856s\n",
      "1599it [01:57, 11.82it/s]\titers: 1600, epoch: 19 | loss: 0.1767408\n",
      "\tspeed: 0.0755s/iter; left time: 439.8685s\n",
      "1699it [02:04, 14.11it/s]\titers: 1700, epoch: 19 | loss: 0.1988638\n",
      "\tspeed: 0.0719s/iter; left time: 411.5204s\n",
      "1798it [02:12, 11.99it/s]\titers: 1800, epoch: 19 | loss: 0.2384618\n",
      "\tspeed: 0.0756s/iter; left time: 425.5778s\n",
      "1898it [02:20, 13.03it/s]\titers: 1900, epoch: 19 | loss: 0.3995284\n",
      "\tspeed: 0.0752s/iter; left time: 415.7409s\n",
      "1998it [02:27, 14.09it/s]\titers: 2000, epoch: 19 | loss: 0.2984046\n",
      "\tspeed: 0.0709s/iter; left time: 384.6563s\n",
      "2098it [02:34, 14.35it/s]\titers: 2100, epoch: 19 | loss: 0.3472441\n",
      "\tspeed: 0.0754s/iter; left time: 401.5361s\n",
      "2198it [02:41, 14.57it/s]\titers: 2200, epoch: 19 | loss: 0.1168213\n",
      "\tspeed: 0.0713s/iter; left time: 372.6271s\n",
      "2298it [02:49, 14.10it/s]\titers: 2300, epoch: 19 | loss: 0.1935789\n",
      "\tspeed: 0.0742s/iter; left time: 380.5897s\n",
      "2398it [02:56, 13.87it/s]\titers: 2400, epoch: 19 | loss: 0.1908798\n",
      "\tspeed: 0.0734s/iter; left time: 368.8829s\n",
      "2498it [03:03, 10.96it/s]\titers: 2500, epoch: 19 | loss: 0.3685527\n",
      "\tspeed: 0.0733s/iter; left time: 361.0765s\n",
      "2598it [03:11, 14.08it/s]\titers: 2600, epoch: 19 | loss: 0.1834503\n",
      "\tspeed: 0.0719s/iter; left time: 346.8741s\n",
      "2698it [03:18, 13.74it/s]\titers: 2700, epoch: 19 | loss: 0.2304170\n",
      "\tspeed: 0.0736s/iter; left time: 348.1322s\n",
      "2798it [03:25, 14.43it/s]\titers: 2800, epoch: 19 | loss: 0.4333939\n",
      "\tspeed: 0.0725s/iter; left time: 335.4842s\n",
      "2898it [03:32, 14.29it/s]\titers: 2900, epoch: 19 | loss: 0.2429963\n",
      "\tspeed: 0.0727s/iter; left time: 329.1005s\n",
      "2998it [03:40, 13.89it/s]\titers: 3000, epoch: 19 | loss: 0.2365280\n",
      "\tspeed: 0.0749s/iter; left time: 331.4123s\n",
      "3098it [03:47, 13.97it/s]\titers: 3100, epoch: 19 | loss: 0.1644711\n",
      "\tspeed: 0.0726s/iter; left time: 313.9583s\n",
      "3198it [03:55, 14.28it/s]\titers: 3200, epoch: 19 | loss: 0.1599708\n",
      "\tspeed: 0.0754s/iter; left time: 318.6220s\n",
      "3298it [04:02, 14.20it/s]\titers: 3300, epoch: 19 | loss: 0.2976720\n",
      "\tspeed: 0.0705s/iter; left time: 290.9809s\n",
      "3398it [04:09, 13.27it/s]\titers: 3400, epoch: 19 | loss: 0.3369531\n",
      "\tspeed: 0.0769s/iter; left time: 309.7013s\n",
      "3498it [04:17, 14.10it/s]\titers: 3500, epoch: 19 | loss: 0.1798500\n",
      "\tspeed: 0.0710s/iter; left time: 278.7136s\n",
      "3598it [04:24, 14.00it/s]\titers: 3600, epoch: 19 | loss: 0.3012286\n",
      "\tspeed: 0.0725s/iter; left time: 277.2695s\n",
      "3698it [04:31, 14.02it/s]\titers: 3700, epoch: 19 | loss: 0.1916632\n",
      "\tspeed: 0.0743s/iter; left time: 276.9338s\n",
      "3713it [04:32, 13.61it/s]\n",
      "Epoch: 19 cost time: 272.845965385437\n",
      "810it [00:27, 29.03it/s]\n",
      "807it [00:27, 29.58it/s]\n",
      "Epoch: 19 | Train Loss: 0.2659731 Vali Loss: 0.3390222 Test Loss: 0.4134638 MAE Loss: 0.4165031\n",
      "lr = 0.0000061658\n",
      "99it [00:07, 14.18it/s]\titers: 100, epoch: 20 | loss: 0.2028809\n",
      "\tspeed: 0.6568s/iter; left time: 2373.6171s\n",
      "199it [00:14, 14.04it/s]\titers: 200, epoch: 20 | loss: 0.2550098\n",
      "\tspeed: 0.0718s/iter; left time: 252.4395s\n",
      "299it [00:22, 13.52it/s]\titers: 300, epoch: 20 | loss: 0.3964863\n",
      "\tspeed: 0.0720s/iter; left time: 245.8937s\n",
      "399it [00:29, 14.08it/s]\titers: 400, epoch: 20 | loss: 0.2367971\n",
      "\tspeed: 0.0746s/iter; left time: 247.1169s\n",
      "499it [00:37, 14.13it/s]\titers: 500, epoch: 20 | loss: 0.1902281\n",
      "\tspeed: 0.0753s/iter; left time: 242.0656s\n",
      "599it [00:44, 14.10it/s]\titers: 600, epoch: 20 | loss: 0.3067628\n",
      "\tspeed: 0.0723s/iter; left time: 224.9950s\n",
      "699it [00:51, 14.10it/s]\titers: 700, epoch: 20 | loss: 0.4380533\n",
      "\tspeed: 0.0756s/iter; left time: 227.9318s\n",
      "799it [00:58, 14.22it/s]\titers: 800, epoch: 20 | loss: 0.2823110\n",
      "\tspeed: 0.0707s/iter; left time: 206.0789s\n",
      "899it [01:06, 11.94it/s]\titers: 900, epoch: 20 | loss: 0.1910501\n",
      "\tspeed: 0.0746s/iter; left time: 209.9286s\n",
      "999it [01:13, 14.08it/s]\titers: 1000, epoch: 20 | loss: 0.1359421\n",
      "\tspeed: 0.0723s/iter; left time: 196.3057s\n",
      "1099it [01:20, 14.19it/s]\titers: 1100, epoch: 20 | loss: 0.2254554\n",
      "\tspeed: 0.0718s/iter; left time: 187.7094s\n",
      "1199it [01:28, 14.11it/s]\titers: 1200, epoch: 20 | loss: 0.2320993\n",
      "\tspeed: 0.0758s/iter; left time: 190.4880s\n",
      "1299it [01:35, 14.10it/s]\titers: 1300, epoch: 20 | loss: 0.2081875\n",
      "\tspeed: 0.0706s/iter; left time: 170.3367s\n",
      "1399it [01:42, 12.83it/s]\titers: 1400, epoch: 20 | loss: 0.2950242\n",
      "\tspeed: 0.0727s/iter; left time: 168.2256s\n",
      "1499it [01:50, 15.84it/s]\titers: 1500, epoch: 20 | loss: 0.3131588\n",
      "\tspeed: 0.0732s/iter; left time: 162.1144s\n",
      "1599it [01:57, 14.25it/s]\titers: 1600, epoch: 20 | loss: 0.2728341\n",
      "\tspeed: 0.0693s/iter; left time: 146.5281s\n",
      "1699it [02:04, 12.25it/s]\titers: 1700, epoch: 20 | loss: 0.2262768\n",
      "\tspeed: 0.0735s/iter; left time: 148.0730s\n",
      "1799it [02:11, 14.00it/s]\titers: 1800, epoch: 20 | loss: 0.3804431\n",
      "\tspeed: 0.0742s/iter; left time: 142.0803s\n",
      "1899it [02:19, 14.04it/s]\titers: 1900, epoch: 20 | loss: 0.3351625\n",
      "\tspeed: 0.0728s/iter; left time: 132.1080s\n",
      "1999it [02:26, 14.13it/s]\titers: 2000, epoch: 20 | loss: 0.1908536\n",
      "\tspeed: 0.0728s/iter; left time: 124.7771s\n",
      "2099it [02:33, 14.04it/s]\titers: 2100, epoch: 20 | loss: 0.1543461\n",
      "\tspeed: 0.0741s/iter; left time: 119.6177s\n",
      "2199it [02:40, 13.95it/s]\titers: 2200, epoch: 20 | loss: 0.2040936\n",
      "\tspeed: 0.0714s/iter; left time: 108.1165s\n",
      "2299it [02:48,  9.30it/s]\titers: 2300, epoch: 20 | loss: 0.5196315\n",
      "\tspeed: 0.0747s/iter; left time: 105.6437s\n",
      "2399it [02:55, 14.04it/s]\titers: 2400, epoch: 20 | loss: 0.3994785\n",
      "\tspeed: 0.0718s/iter; left time: 94.3495s\n",
      "2499it [03:02, 14.20it/s]\titers: 2500, epoch: 20 | loss: 0.3272019\n",
      "\tspeed: 0.0719s/iter; left time: 87.2352s\n",
      "2599it [03:10, 13.76it/s]\titers: 2600, epoch: 20 | loss: 0.2275440\n",
      "\tspeed: 0.0755s/iter; left time: 84.0681s\n",
      "2699it [03:17, 13.18it/s]\titers: 2700, epoch: 20 | loss: 0.3621648\n",
      "\tspeed: 0.0716s/iter; left time: 72.5927s\n",
      "2799it [03:24, 13.16it/s]\titers: 2800, epoch: 20 | loss: 0.2244433\n",
      "\tspeed: 0.0684s/iter; left time: 62.5500s\n",
      "2899it [03:31, 14.11it/s]\titers: 2900, epoch: 20 | loss: 0.1791323\n",
      "\tspeed: 0.0741s/iter; left time: 60.2810s\n",
      "2999it [03:38, 14.09it/s]\titers: 3000, epoch: 20 | loss: 0.3702236\n",
      "\tspeed: 0.0717s/iter; left time: 51.1586s\n",
      "3099it [03:46, 14.32it/s]\titers: 3100, epoch: 20 | loss: 0.2150385\n",
      "\tspeed: 0.0736s/iter; left time: 45.2068s\n",
      "3199it [03:53, 15.08it/s]\titers: 3200, epoch: 20 | loss: 0.2343135\n",
      "\tspeed: 0.0712s/iter; left time: 36.5863s\n",
      "3299it [04:00, 14.13it/s]\titers: 3300, epoch: 20 | loss: 0.2327813\n",
      "\tspeed: 0.0753s/iter; left time: 31.1713s\n",
      "3399it [04:07, 13.40it/s]\titers: 3400, epoch: 20 | loss: 0.2484347\n",
      "\tspeed: 0.0712s/iter; left time: 22.3719s\n",
      "3499it [04:14, 12.40it/s]\titers: 3500, epoch: 20 | loss: 0.4114945\n",
      "\tspeed: 0.0694s/iter; left time: 14.8462s\n",
      "3599it [04:21, 15.97it/s]\titers: 3600, epoch: 20 | loss: 0.4327282\n",
      "\tspeed: 0.0663s/iter; left time: 7.5538s\n",
      "3699it [04:28, 13.91it/s]\titers: 3700, epoch: 20 | loss: 0.1714645\n",
      "\tspeed: 0.0684s/iter; left time: 0.9580s\n",
      "3713it [04:29, 13.78it/s]\n",
      "Epoch: 20 cost time: 269.4710817337036\n",
      "810it [00:27, 29.07it/s]\n",
      "807it [00:27, 28.82it/s]\n",
      "Epoch: 20 | Train Loss: 0.2655603 Vali Loss: 0.3383641 Test Loss: 0.4129862 MAE Loss: 0.4151682\n",
      "lr = 0.0000000100\n",
      "Total time: 107.90661646922429 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "[2024-05-03 15:44:30,610] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 15:44:31,493] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 15:44:31,493] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 15:44:31,493] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 15:44:32,485] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-03 15:44:32,486] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 15:44:33,736] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 15:44:33,738] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 15:44:33,738] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 15:44:33,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 15:44:33,740] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 15:44:33,740] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 15:44:34,329] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 15:44:34,331] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,331] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.33 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,569] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 15:44:34,570] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,571] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.34 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,571] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 15:44:34,813] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 15:44:34,814] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,815] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.33 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 15:44:34,817] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5903c8c6d0>\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:24,  4.19it/s]\titers: 100, epoch: 1 | loss: 0.7356012\n",
      "\tspeed: 0.2908s/iter; left time: 1066.1519s\n",
      "199it [00:58,  3.10it/s]\titers: 200, epoch: 1 | loss: 0.5691991\n",
      "\tspeed: 0.3444s/iter; left time: 1228.1985s\n",
      "299it [01:32,  2.10it/s]\titers: 300, epoch: 1 | loss: 0.4520031\n",
      "\tspeed: 0.3429s/iter; left time: 1188.5837s\n",
      "399it [02:06,  2.39it/s]\titers: 400, epoch: 1 | loss: 0.6152174\n",
      "\tspeed: 0.3344s/iter; left time: 1125.4562s\n",
      "499it [02:39,  3.45it/s]\titers: 500, epoch: 1 | loss: 0.4286653\n",
      "\tspeed: 0.3363s/iter; left time: 1098.4060s\n",
      "599it [03:12,  3.34it/s]\titers: 600, epoch: 1 | loss: 0.2725918\n",
      "\tspeed: 0.3255s/iter; left time: 1030.4073s\n",
      "699it [03:46,  2.90it/s]\titers: 700, epoch: 1 | loss: 0.3188488\n",
      "\tspeed: 0.3411s/iter; left time: 1045.8324s\n",
      "799it [04:17,  3.43it/s]\titers: 800, epoch: 1 | loss: 0.5181361\n",
      "\tspeed: 0.3103s/iter; left time: 920.4743s\n",
      "899it [04:49,  3.36it/s]\titers: 900, epoch: 1 | loss: 0.1869062\n",
      "\tspeed: 0.3193s/iter; left time: 914.9958s\n",
      "999it [05:21,  2.09it/s]\titers: 1000, epoch: 1 | loss: 0.2172682\n",
      "\tspeed: 0.3165s/iter; left time: 875.3748s\n",
      "1099it [05:55,  3.02it/s]\titers: 1100, epoch: 1 | loss: 0.2820303\n",
      "\tspeed: 0.3483s/iter; left time: 928.5558s\n",
      "1199it [06:27,  2.91it/s]\titers: 1200, epoch: 1 | loss: 0.4319468\n",
      "\tspeed: 0.3125s/iter; left time: 801.8844s\n",
      "1299it [07:02,  2.85it/s]\titers: 1300, epoch: 1 | loss: 0.3310315\n",
      "\tspeed: 0.3570s/iter; left time: 880.3170s\n",
      "1399it [07:35,  2.92it/s]\titers: 1400, epoch: 1 | loss: 0.3464009\n",
      "\tspeed: 0.3294s/iter; left time: 779.4637s\n",
      "1499it [08:07,  3.00it/s]\titers: 1500, epoch: 1 | loss: 0.2595419\n",
      "\tspeed: 0.3195s/iter; left time: 724.0822s\n",
      "1599it [08:44,  2.77it/s]\titers: 1600, epoch: 1 | loss: 0.3122485\n",
      "\tspeed: 0.3714s/iter; left time: 804.4426s\n",
      "1699it [09:18,  2.33it/s]\titers: 1700, epoch: 1 | loss: 0.3014346\n",
      "\tspeed: 0.3356s/iter; left time: 693.3138s\n",
      "1799it [09:50,  3.38it/s]\titers: 1800, epoch: 1 | loss: 0.3493429\n",
      "\tspeed: 0.3214s/iter; left time: 631.9039s\n",
      "1899it [10:20,  3.62it/s]\titers: 1900, epoch: 1 | loss: 0.3084237\n",
      "\tspeed: 0.3020s/iter; left time: 563.6075s\n",
      "1999it [10:49,  3.60it/s]\titers: 2000, epoch: 1 | loss: 0.2826749\n",
      "\tspeed: 0.2837s/iter; left time: 500.9693s\n",
      "2099it [11:18,  3.05it/s]\titers: 2100, epoch: 1 | loss: 0.4879281\n",
      "\tspeed: 0.2969s/iter; left time: 494.6857s\n",
      "2199it [11:47,  3.41it/s]\titers: 2200, epoch: 1 | loss: 0.2046579\n",
      "\tspeed: 0.2897s/iter; left time: 453.7468s\n",
      "2299it [12:16,  4.14it/s]\titers: 2300, epoch: 1 | loss: 0.1233690\n",
      "\tspeed: 0.2890s/iter; left time: 423.7306s\n",
      "2399it [12:51,  3.40it/s]\titers: 2400, epoch: 1 | loss: 0.2604498\n",
      "\tspeed: 0.3438s/iter; left time: 469.6103s\n",
      "2499it [13:25,  3.11it/s]\titers: 2500, epoch: 1 | loss: 0.2310107\n",
      "\tspeed: 0.3405s/iter; left time: 431.0967s\n",
      "2599it [13:58,  2.98it/s]\titers: 2600, epoch: 1 | loss: 0.2021242\n",
      "\tspeed: 0.3349s/iter; left time: 390.4528s\n",
      "2699it [14:29,  3.37it/s]\titers: 2700, epoch: 1 | loss: 0.1879779\n",
      "\tspeed: 0.3108s/iter; left time: 331.2782s\n",
      "2799it [15:00,  3.76it/s]\titers: 2800, epoch: 1 | loss: 0.4332197\n",
      "\tspeed: 0.3074s/iter; left time: 296.9775s\n",
      "2899it [15:31,  3.10it/s]\titers: 2900, epoch: 1 | loss: 0.1966374\n",
      "\tspeed: 0.3056s/iter; left time: 264.6117s\n",
      "2999it [16:01,  2.53it/s]\titers: 3000, epoch: 1 | loss: 0.1856316\n",
      "\tspeed: 0.3012s/iter; left time: 230.6993s\n",
      "3099it [16:35,  3.33it/s]\titers: 3100, epoch: 1 | loss: 0.3469718\n",
      "\tspeed: 0.3414s/iter; left time: 227.3795s\n",
      "3199it [17:11,  3.12it/s]\titers: 3200, epoch: 1 | loss: 0.5812799\n",
      "\tspeed: 0.3665s/iter; left time: 207.4195s\n",
      "3299it [17:46,  3.17it/s]\titers: 3300, epoch: 1 | loss: 0.2726511\n",
      "\tspeed: 0.3405s/iter; left time: 158.6874s\n",
      "3399it [18:18,  3.11it/s]\titers: 3400, epoch: 1 | loss: 0.5794476\n",
      "\tspeed: 0.3238s/iter; left time: 118.5144s\n",
      "3499it [18:49,  3.54it/s]\titers: 3500, epoch: 1 | loss: 0.3040229\n",
      "\tspeed: 0.3134s/iter; left time: 83.3695s\n",
      "3599it [19:22,  2.81it/s]\titers: 3600, epoch: 1 | loss: 0.3292978\n",
      "\tspeed: 0.3332s/iter; left time: 55.3053s\n",
      "3699it [19:57,  2.28it/s]\titers: 3700, epoch: 1 | loss: 0.2165164\n",
      "\tspeed: 0.3475s/iter; left time: 22.9338s\n",
      "3765it [20:18,  3.09it/s]\n",
      "Epoch: 1 cost time: 1218.1102845668793\n",
      "810it [02:00,  6.70it/s]\n",
      "807it [02:14,  6.00it/s]\n",
      "Epoch: 1 | Train Loss: 0.3600279 Vali Loss: 0.3258024 Test Loss: 0.3997062 MAE Loss: 0.4031630\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 25.003564433256784 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A100 80GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-03 18:41:03,815] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 18:41:04,703] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 18:41:04,703] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 18:41:04,703] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 18:41:05,580] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 18:41:05,580] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 18:41:06,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 18:41:06,480] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 18:41:06,480] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 18:41:06,481] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 18:41:06,481] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 18:41:06,482] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 18:41:06,753] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 18:41:06,753] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,754] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.06 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,877] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 18:41:06,878] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,878] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.1 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,878] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 18:41:06,994] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 18:41:06,995] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,995] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.1 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 18:41:06,996] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbb408b32d0>\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:08, 12.12it/s]\titers: 100, epoch: 1 | loss: 0.7344609\n",
      "\tspeed: 0.1206s/iter; left time: 9068.2232s\n",
      "199it [00:15, 13.18it/s]\titers: 200, epoch: 1 | loss: 0.5534266\n",
      "\tspeed: 0.0735s/iter; left time: 5521.3202s\n",
      "299it [00:23, 12.82it/s]\titers: 300, epoch: 1 | loss: 0.3374816\n",
      "\tspeed: 0.0777s/iter; left time: 5827.0684s\n",
      "399it [00:31, 13.43it/s]\titers: 400, epoch: 1 | loss: 0.5920237\n",
      "\tspeed: 0.0780s/iter; left time: 5843.9775s\n",
      "498it [00:39, 13.87it/s]\titers: 500, epoch: 1 | loss: 0.3636857\n",
      "\tspeed: 0.0794s/iter; left time: 5935.7716s\n",
      "598it [00:46, 12.71it/s]\titers: 600, epoch: 1 | loss: 0.2869768\n",
      "\tspeed: 0.0736s/iter; left time: 5500.4722s\n",
      "698it [00:54, 13.53it/s]\titers: 700, epoch: 1 | loss: 0.2821769\n",
      "\tspeed: 0.0765s/iter; left time: 5703.9659s\n",
      "798it [01:01, 14.61it/s]\titers: 800, epoch: 1 | loss: 0.4466472\n",
      "\tspeed: 0.0697s/iter; left time: 5191.4872s\n",
      "898it [01:08, 15.17it/s]\titers: 900, epoch: 1 | loss: 0.1720697\n",
      "\tspeed: 0.0700s/iter; left time: 5206.3678s\n",
      "998it [01:15, 14.37it/s]\titers: 1000, epoch: 1 | loss: 0.2217325\n",
      "\tspeed: 0.0726s/iter; left time: 5391.9281s\n",
      "1098it [01:22, 14.70it/s]\titers: 1100, epoch: 1 | loss: 0.2706838\n",
      "\tspeed: 0.0701s/iter; left time: 5197.9634s\n",
      "1198it [01:29, 12.70it/s]\titers: 1200, epoch: 1 | loss: 0.4562358\n",
      "\tspeed: 0.0743s/iter; left time: 5504.2786s\n",
      "1298it [01:37, 12.66it/s]\titers: 1300, epoch: 1 | loss: 0.3683525\n",
      "\tspeed: 0.0810s/iter; left time: 5991.9219s\n",
      "1398it [01:45, 13.17it/s]\titers: 1400, epoch: 1 | loss: 0.3831846\n",
      "\tspeed: 0.0760s/iter; left time: 5614.9376s\n",
      "1498it [01:53, 12.52it/s]\titers: 1500, epoch: 1 | loss: 0.2239503\n",
      "\tspeed: 0.0791s/iter; left time: 5836.1271s\n",
      "1598it [02:01, 13.40it/s]\titers: 1600, epoch: 1 | loss: 0.3337799\n",
      "\tspeed: 0.0780s/iter; left time: 5747.6152s\n",
      "1698it [02:08, 12.99it/s]\titers: 1700, epoch: 1 | loss: 0.2691672\n",
      "\tspeed: 0.0748s/iter; left time: 5505.1997s\n",
      "1798it [02:16, 13.31it/s]\titers: 1800, epoch: 1 | loss: 0.3767647\n",
      "\tspeed: 0.0792s/iter; left time: 5823.2407s\n",
      "1898it [02:24, 12.68it/s]\titers: 1900, epoch: 1 | loss: 0.3214819\n",
      "\tspeed: 0.0743s/iter; left time: 5455.7107s\n",
      "1998it [02:31, 13.07it/s]\titers: 2000, epoch: 1 | loss: 0.3014286\n",
      "\tspeed: 0.0773s/iter; left time: 5663.9153s\n",
      "2098it [02:39, 14.14it/s]\titers: 2100, epoch: 1 | loss: 0.4911543\n",
      "\tspeed: 0.0783s/iter; left time: 5734.0535s\n",
      "2198it [02:46, 15.47it/s]\titers: 2200, epoch: 1 | loss: 0.2055287\n",
      "\tspeed: 0.0673s/iter; left time: 4922.6746s\n",
      "2298it [02:53, 10.47it/s]\titers: 2300, epoch: 1 | loss: 0.1426944\n",
      "\tspeed: 0.0738s/iter; left time: 5387.3839s\n",
      "2398it [03:00, 14.54it/s]\titers: 2400, epoch: 1 | loss: 0.2317778\n",
      "\tspeed: 0.0676s/iter; left time: 4924.8447s\n",
      "2498it [03:07, 15.03it/s]\titers: 2500, epoch: 1 | loss: 0.2468895\n",
      "\tspeed: 0.0686s/iter; left time: 4995.6702s\n",
      "2598it [03:14, 14.17it/s]\titers: 2600, epoch: 1 | loss: 0.2311681\n",
      "\tspeed: 0.0706s/iter; left time: 5135.9480s\n",
      "2698it [03:21, 14.30it/s]\titers: 2700, epoch: 1 | loss: 0.1829604\n",
      "\tspeed: 0.0669s/iter; left time: 4857.7140s\n",
      "2798it [03:28, 15.19it/s]\titers: 2800, epoch: 1 | loss: 0.4374384\n",
      "\tspeed: 0.0705s/iter; left time: 5114.5406s\n",
      "2898it [03:35, 14.98it/s]\titers: 2900, epoch: 1 | loss: 0.2059190\n",
      "\tspeed: 0.0753s/iter; left time: 5454.7268s\n",
      "2998it [03:42, 14.35it/s]\titers: 3000, epoch: 1 | loss: 0.2148284\n",
      "\tspeed: 0.0686s/iter; left time: 4961.4937s\n",
      "3098it [03:49, 15.10it/s]\titers: 3100, epoch: 1 | loss: 0.3376509\n",
      "\tspeed: 0.0660s/iter; left time: 4762.4497s\n",
      "3198it [03:56, 14.17it/s]\titers: 3200, epoch: 1 | loss: 0.5711665\n",
      "\tspeed: 0.0744s/iter; left time: 5360.8125s\n",
      "3298it [04:03, 16.24it/s]\titers: 3300, epoch: 1 | loss: 0.2519772\n",
      "\tspeed: 0.0663s/iter; left time: 4772.4071s\n",
      "3398it [04:10, 13.77it/s]\titers: 3400, epoch: 1 | loss: 0.5514895\n",
      "\tspeed: 0.0735s/iter; left time: 5286.6557s\n",
      "3498it [04:17, 14.17it/s]\titers: 3500, epoch: 1 | loss: 0.3255207\n",
      "\tspeed: 0.0695s/iter; left time: 4987.5832s\n",
      "3598it [04:24, 14.36it/s]\titers: 3600, epoch: 1 | loss: 0.3368211\n",
      "\tspeed: 0.0677s/iter; left time: 4855.0338s\n",
      "3698it [04:31, 14.05it/s]\titers: 3700, epoch: 1 | loss: 0.2395910\n",
      "\tspeed: 0.0752s/iter; left time: 5386.6931s\n",
      "3765it [04:36, 13.61it/s]\n",
      "Epoch: 1 cost time: 276.5777759552002\n",
      "810it [00:26, 30.82it/s]\n",
      "807it [00:26, 30.58it/s]\n",
      "Epoch: 1 | Train Loss: 0.3455458 Vali Loss: 0.3314827 Test Loss: 0.4090656 MAE Loss: 0.4084324\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:06, 15.31it/s]\titers: 100, epoch: 2 | loss: 0.2133331\n",
      "\tspeed: 0.6680s/iter; left time: 47722.7565s\n",
      "199it [00:13, 14.86it/s]\titers: 200, epoch: 2 | loss: 0.3633168\n",
      "\tspeed: 0.0684s/iter; left time: 4878.6151s\n",
      "299it [00:20, 16.78it/s]\titers: 300, epoch: 2 | loss: 0.2297406\n",
      "\tspeed: 0.0682s/iter; left time: 4855.7457s\n",
      "399it [00:26, 14.99it/s]\titers: 400, epoch: 2 | loss: 0.2786470\n",
      "\tspeed: 0.0633s/iter; left time: 4506.1030s\n",
      "499it [00:33, 15.79it/s]\titers: 500, epoch: 2 | loss: 0.1391118\n",
      "\tspeed: 0.0654s/iter; left time: 4643.3850s\n",
      "599it [00:40, 14.26it/s]\titers: 600, epoch: 2 | loss: 0.2329213\n",
      "\tspeed: 0.0696s/iter; left time: 4934.1914s\n",
      "698it [00:46, 19.73it/s]\titers: 700, epoch: 2 | loss: 0.3461939\n",
      "\tspeed: 0.0646s/iter; left time: 4577.8259s\n",
      "799it [00:51, 19.57it/s]\titers: 800, epoch: 2 | loss: 0.4934967\n",
      "\tspeed: 0.0510s/iter; left time: 3604.6537s\n",
      "899it [00:58, 16.36it/s]\titers: 900, epoch: 2 | loss: 0.2556140\n",
      "\tspeed: 0.0614s/iter; left time: 4335.2765s\n",
      "999it [01:04, 19.71it/s]\titers: 1000, epoch: 2 | loss: 0.2170373\n",
      "\tspeed: 0.0598s/iter; left time: 4218.7536s\n",
      "1099it [01:09, 19.59it/s]\titers: 1100, epoch: 2 | loss: 0.1909031\n",
      "\tspeed: 0.0507s/iter; left time: 3571.8803s\n",
      "1199it [01:16, 10.68it/s]\titers: 1200, epoch: 2 | loss: 0.3276211\n",
      "\tspeed: 0.0694s/iter; left time: 4881.9351s\n",
      "1299it [01:22, 16.40it/s]\titers: 1300, epoch: 2 | loss: 0.6224858\n",
      "\tspeed: 0.0633s/iter; left time: 4447.6846s\n",
      "1399it [01:28, 15.88it/s]\titers: 1400, epoch: 2 | loss: 0.3547138\n",
      "\tspeed: 0.0650s/iter; left time: 4561.6783s\n",
      "1499it [01:34, 15.80it/s]\titers: 1500, epoch: 2 | loss: 0.2847526\n",
      "\tspeed: 0.0573s/iter; left time: 4009.9011s\n",
      "1599it [01:41, 15.53it/s]\titers: 1600, epoch: 2 | loss: 0.1720620\n",
      "\tspeed: 0.0663s/iter; left time: 4633.9506s\n",
      "1699it [01:47, 15.20it/s]\titers: 1700, epoch: 2 | loss: 0.2632230\n",
      "\tspeed: 0.0657s/iter; left time: 4586.9384s\n",
      "1799it [01:54, 14.44it/s]\titers: 1800, epoch: 2 | loss: 0.2095311\n",
      "\tspeed: 0.0676s/iter; left time: 4714.7681s\n",
      "1899it [02:01, 14.20it/s]\titers: 1900, epoch: 2 | loss: 0.2062538\n",
      "\tspeed: 0.0718s/iter; left time: 5000.3535s\n",
      "1999it [02:08, 15.12it/s]\titers: 2000, epoch: 2 | loss: 0.1903376\n",
      "\tspeed: 0.0687s/iter; left time: 4779.3092s\n",
      "2099it [02:15, 10.60it/s]\titers: 2100, epoch: 2 | loss: 0.3051968\n",
      "\tspeed: 0.0693s/iter; left time: 4811.1060s\n",
      "2199it [02:22, 15.05it/s]\titers: 2200, epoch: 2 | loss: 0.2243668\n",
      "\tspeed: 0.0677s/iter; left time: 4696.3468s\n",
      "2299it [02:28, 15.54it/s]\titers: 2300, epoch: 2 | loss: 0.2801064\n",
      "\tspeed: 0.0656s/iter; left time: 4544.0293s\n",
      "2399it [02:34, 17.37it/s]\titers: 2400, epoch: 2 | loss: 0.1785705\n",
      "\tspeed: 0.0518s/iter; left time: 3582.5709s\n",
      "2499it [02:41, 15.06it/s]\titers: 2500, epoch: 2 | loss: 0.4827907\n",
      "\tspeed: 0.0701s/iter; left time: 4838.7578s\n",
      "2599it [02:47, 15.65it/s]\titers: 2600, epoch: 2 | loss: 0.1959589\n",
      "\tspeed: 0.0622s/iter; left time: 4286.1951s\n",
      "2699it [02:54, 11.96it/s]\titers: 2700, epoch: 2 | loss: 0.2637077\n",
      "\tspeed: 0.0678s/iter; left time: 4669.8012s\n",
      "2799it [03:00, 15.49it/s]\titers: 2800, epoch: 2 | loss: 0.4255023\n",
      "\tspeed: 0.0652s/iter; left time: 4480.5772s\n",
      "2899it [03:07, 16.34it/s]\titers: 2900, epoch: 2 | loss: 0.3513686\n",
      "\tspeed: 0.0646s/iter; left time: 4430.6122s\n",
      "2999it [03:13, 14.43it/s]\titers: 3000, epoch: 2 | loss: 0.1681190\n",
      "\tspeed: 0.0649s/iter; left time: 4444.7811s\n",
      "3099it [03:20, 15.79it/s]\titers: 3100, epoch: 2 | loss: 0.1524097\n",
      "\tspeed: 0.0646s/iter; left time: 4418.4245s\n",
      "3199it [03:26, 16.37it/s]\titers: 3200, epoch: 2 | loss: 0.2961035\n",
      "\tspeed: 0.0619s/iter; left time: 4233.2126s\n",
      "3299it [03:32, 15.42it/s]\titers: 3300, epoch: 2 | loss: 0.1931553\n",
      "\tspeed: 0.0646s/iter; left time: 4409.4368s\n",
      "3399it [03:39, 14.49it/s]\titers: 3400, epoch: 2 | loss: 0.2171213\n",
      "\tspeed: 0.0698s/iter; left time: 4755.0487s\n",
      "3497it [03:46, 16.57it/s]\titers: 3500, epoch: 2 | loss: 0.4232988\n",
      "\tspeed: 0.0653s/iter; left time: 4442.7707s\n",
      "3598it [03:51, 19.67it/s]\titers: 3600, epoch: 2 | loss: 0.1783781\n",
      "\tspeed: 0.0508s/iter; left time: 3454.1217s\n",
      "3699it [03:57, 15.94it/s]\titers: 3700, epoch: 2 | loss: 0.2112690\n",
      "\tspeed: 0.0605s/iter; left time: 4105.3207s\n",
      "3765it [04:01, 15.59it/s]\n",
      "Epoch: 2 cost time: 241.5614116191864\n",
      "810it [00:23, 34.53it/s]\n",
      "807it [00:23, 34.31it/s]\n",
      "Epoch: 2 | Train Loss: 0.2716841 Vali Loss: 0.3368949 Test Loss: 0.4269623 MAE Loss: 0.4148688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:07, 16.41it/s]\titers: 100, epoch: 3 | loss: 0.2494262\n",
      "\tspeed: 0.5860s/iter; left time: 39653.4451s\n",
      "199it [00:13, 15.50it/s]\titers: 200, epoch: 3 | loss: 0.4260388\n",
      "\tspeed: 0.0637s/iter; left time: 4306.1997s\n",
      "299it [00:19, 15.33it/s]\titers: 300, epoch: 3 | loss: 0.1500765\n",
      "\tspeed: 0.0629s/iter; left time: 4245.3254s\n",
      "399it [00:26, 17.07it/s]\titers: 400, epoch: 3 | loss: 0.3129734\n",
      "\tspeed: 0.0668s/iter; left time: 4498.2295s\n",
      "499it [00:33, 13.81it/s]\titers: 500, epoch: 3 | loss: 0.1419590\n",
      "\tspeed: 0.0651s/iter; left time: 4378.1604s\n",
      "599it [00:39, 16.76it/s]\titers: 600, epoch: 3 | loss: 0.1678801\n",
      "\tspeed: 0.0649s/iter; left time: 4361.9441s\n",
      "699it [00:46, 15.84it/s]\titers: 700, epoch: 3 | loss: 0.2609751\n",
      "\tspeed: 0.0711s/iter; left time: 4770.2796s\n",
      "799it [00:53, 15.60it/s]\titers: 800, epoch: 3 | loss: 0.3131287\n",
      "\tspeed: 0.0647s/iter; left time: 4330.0893s\n",
      "899it [00:59, 13.96it/s]\titers: 900, epoch: 3 | loss: 0.2596065\n",
      "\tspeed: 0.0650s/iter; left time: 4343.3395s\n",
      "999it [01:06, 14.10it/s]\titers: 1000, epoch: 3 | loss: 0.4696178\n",
      "\tspeed: 0.0725s/iter; left time: 4839.0961s\n",
      "1099it [01:14, 13.48it/s]\titers: 1100, epoch: 3 | loss: 0.1118183\n",
      "\tspeed: 0.0709s/iter; left time: 4727.5424s\n",
      "1199it [01:21, 13.66it/s]\titers: 1200, epoch: 3 | loss: 0.1599149\n",
      "\tspeed: 0.0695s/iter; left time: 4625.8446s\n",
      "1299it [01:28, 16.09it/s]\titers: 1300, epoch: 3 | loss: 0.2614858\n",
      "\tspeed: 0.0711s/iter; left time: 4727.6956s\n",
      "1399it [01:34, 15.24it/s]\titers: 1400, epoch: 3 | loss: 0.3105979\n",
      "\tspeed: 0.0657s/iter; left time: 4362.4998s\n",
      "1499it [01:41, 18.21it/s]\titers: 1500, epoch: 3 | loss: 0.1588375\n",
      "\tspeed: 0.0629s/iter; left time: 4167.9447s\n",
      "1598it [01:46, 15.91it/s]\titers: 1600, epoch: 3 | loss: 0.2056118\n",
      "\tspeed: 0.0533s/iter; left time: 3528.8559s\n",
      "1699it [01:52, 16.02it/s]\titers: 1700, epoch: 3 | loss: 0.1775197\n",
      "\tspeed: 0.0635s/iter; left time: 4198.6742s\n",
      "1799it [01:59, 15.21it/s]\titers: 1800, epoch: 3 | loss: 0.3883937\n",
      "\tspeed: 0.0653s/iter; left time: 4309.7467s\n",
      "1899it [02:05, 15.02it/s]\titers: 1900, epoch: 3 | loss: 0.1765780\n",
      "\tspeed: 0.0652s/iter; left time: 4295.7623s\n",
      "1999it [02:12, 13.50it/s]\titers: 2000, epoch: 3 | loss: 0.3559508\n",
      "\tspeed: 0.0710s/iter; left time: 4668.2619s\n",
      "2099it [02:18, 18.56it/s]\titers: 2100, epoch: 3 | loss: 0.2184572\n",
      "\tspeed: 0.0595s/iter; left time: 3909.5610s\n",
      "2199it [02:25, 14.88it/s]\titers: 2200, epoch: 3 | loss: 0.2784693\n",
      "\tspeed: 0.0643s/iter; left time: 4214.5104s\n",
      "2299it [02:32, 15.98it/s]\titers: 2300, epoch: 3 | loss: 0.3075760\n",
      "\tspeed: 0.0680s/iter; left time: 4449.3812s\n",
      "2399it [02:38, 14.67it/s]\titers: 2400, epoch: 3 | loss: 0.4369825\n",
      "\tspeed: 0.0678s/iter; left time: 4433.3824s\n",
      "2499it [02:45, 14.99it/s]\titers: 2500, epoch: 3 | loss: 0.2119672\n",
      "\tspeed: 0.0660s/iter; left time: 4307.3455s\n",
      "2599it [02:52, 14.88it/s]\titers: 2600, epoch: 3 | loss: 0.2304634\n",
      "\tspeed: 0.0704s/iter; left time: 4588.5023s\n",
      "2699it [02:59, 15.20it/s]\titers: 2700, epoch: 3 | loss: 0.1034780\n",
      "\tspeed: 0.0660s/iter; left time: 4293.1820s\n",
      "2799it [03:05, 16.31it/s]\titers: 2800, epoch: 3 | loss: 0.1633217\n",
      "\tspeed: 0.0635s/iter; left time: 4128.3998s\n",
      "2899it [03:11, 14.01it/s]\titers: 2900, epoch: 3 | loss: 0.2074667\n",
      "\tspeed: 0.0654s/iter; left time: 4243.4041s\n",
      "2999it [03:18, 17.22it/s]\titers: 3000, epoch: 3 | loss: 0.1936255\n",
      "\tspeed: 0.0632s/iter; left time: 4095.9958s\n",
      "3099it [03:24, 15.94it/s]\titers: 3100, epoch: 3 | loss: 0.3537498\n",
      "\tspeed: 0.0617s/iter; left time: 3989.7609s\n",
      "3199it [03:30, 15.09it/s]\titers: 3200, epoch: 3 | loss: 0.2398289\n",
      "\tspeed: 0.0620s/iter; left time: 4003.6273s\n",
      "3299it [03:36, 17.54it/s]\titers: 3300, epoch: 3 | loss: 0.2424933\n",
      "\tspeed: 0.0567s/iter; left time: 3654.9959s\n",
      "3399it [03:42, 16.26it/s]\titers: 3400, epoch: 3 | loss: 0.2064747\n",
      "\tspeed: 0.0616s/iter; left time: 3965.0968s\n",
      "3499it [03:48, 15.55it/s]\titers: 3500, epoch: 3 | loss: 0.2138335\n",
      "\tspeed: 0.0626s/iter; left time: 4024.4716s\n",
      "3599it [03:55, 14.83it/s]\titers: 3600, epoch: 3 | loss: 0.1495813\n",
      "\tspeed: 0.0660s/iter; left time: 4234.8543s\n",
      "3699it [04:01, 15.43it/s]\titers: 3700, epoch: 3 | loss: 0.1738549\n",
      "\tspeed: 0.0654s/iter; left time: 4188.2539s\n",
      "3765it [04:06, 15.30it/s]\n",
      "Epoch: 3 cost time: 246.12982082366943\n",
      "810it [00:23, 34.64it/s]\n",
      "807it [00:23, 34.87it/s]\n",
      "Epoch: 3 | Train Loss: 0.2576268 Vali Loss: 0.2999316 Test Loss: 0.3649445 MAE Loss: 0.3680021\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:06, 16.54it/s]\titers: 100, epoch: 4 | loss: 0.1314902\n",
      "\tspeed: 0.5937s/iter; left time: 37940.5125s\n",
      "199it [00:12, 15.41it/s]\titers: 200, epoch: 4 | loss: 0.2942722\n",
      "\tspeed: 0.0640s/iter; left time: 4084.9053s\n",
      "299it [00:19, 15.91it/s]\titers: 300, epoch: 4 | loss: 0.2316074\n",
      "\tspeed: 0.0664s/iter; left time: 4228.6559s\n",
      "399it [00:26, 16.07it/s]\titers: 400, epoch: 4 | loss: 0.1880004\n",
      "\tspeed: 0.0651s/iter; left time: 4139.9121s\n",
      "499it [00:32, 19.49it/s]\titers: 500, epoch: 4 | loss: 0.2408332\n",
      "\tspeed: 0.0591s/iter; left time: 3755.1291s\n",
      "599it [00:38, 15.82it/s]\titers: 600, epoch: 4 | loss: 0.2508964\n",
      "\tspeed: 0.0666s/iter; left time: 4220.4954s\n",
      "699it [00:45, 16.33it/s]\titers: 700, epoch: 4 | loss: 0.1975549\n",
      "\tspeed: 0.0639s/iter; left time: 4045.0349s\n",
      "799it [00:51, 15.88it/s]\titers: 800, epoch: 4 | loss: 0.2421163\n",
      "\tspeed: 0.0633s/iter; left time: 4004.0765s\n",
      "899it [00:58, 15.64it/s]\titers: 900, epoch: 4 | loss: 0.2278664\n",
      "\tspeed: 0.0674s/iter; left time: 4252.3354s\n",
      "999it [01:04, 15.14it/s]\titers: 1000, epoch: 4 | loss: 0.2228788\n",
      "\tspeed: 0.0637s/iter; left time: 4013.4850s\n",
      "1099it [01:11, 15.79it/s]\titers: 1100, epoch: 4 | loss: 0.1800691\n",
      "\tspeed: 0.0653s/iter; left time: 4105.5595s\n",
      "1199it [01:17, 13.53it/s]\titers: 1200, epoch: 4 | loss: 0.1924494\n",
      "\tspeed: 0.0665s/iter; left time: 4178.0438s\n",
      "1299it [01:24, 15.72it/s]\titers: 1300, epoch: 4 | loss: 0.3029090\n",
      "\tspeed: 0.0642s/iter; left time: 4027.5513s\n",
      "1399it [01:30, 15.26it/s]\titers: 1400, epoch: 4 | loss: 0.2870390\n",
      "\tspeed: 0.0648s/iter; left time: 4059.2200s\n",
      "1499it [01:37, 14.41it/s]\titers: 1500, epoch: 4 | loss: 0.3282450\n",
      "\tspeed: 0.0659s/iter; left time: 4116.6629s\n",
      "1599it [01:44, 14.14it/s]\titers: 1600, epoch: 4 | loss: 0.2599825\n",
      "\tspeed: 0.0757s/iter; left time: 4724.4752s\n",
      "1699it [01:51, 15.58it/s]\titers: 1700, epoch: 4 | loss: 0.2064519\n",
      "\tspeed: 0.0682s/iter; left time: 4250.7221s\n",
      "1799it [01:58, 15.20it/s]\titers: 1800, epoch: 4 | loss: 0.2098617\n",
      "\tspeed: 0.0679s/iter; left time: 4225.7750s\n",
      "1899it [02:04, 16.10it/s]\titers: 1900, epoch: 4 | loss: 0.2606903\n",
      "\tspeed: 0.0629s/iter; left time: 3903.7190s\n",
      "1999it [02:11, 16.06it/s]\titers: 2000, epoch: 4 | loss: 0.2206062\n",
      "\tspeed: 0.0640s/iter; left time: 3971.1712s\n",
      "2099it [02:17, 16.15it/s]\titers: 2100, epoch: 4 | loss: 0.2280117\n",
      "\tspeed: 0.0667s/iter; left time: 4130.7004s\n",
      "2199it [02:24, 15.78it/s]\titers: 2200, epoch: 4 | loss: 0.2723797\n",
      "\tspeed: 0.0630s/iter; left time: 3891.6316s\n",
      "2299it [02:30, 15.35it/s]\titers: 2300, epoch: 4 | loss: 0.1497230\n",
      "\tspeed: 0.0637s/iter; left time: 3931.9107s\n",
      "2399it [02:37, 15.06it/s]\titers: 2400, epoch: 4 | loss: 0.1706560\n",
      "\tspeed: 0.0663s/iter; left time: 4084.4851s\n",
      "2499it [02:43, 15.64it/s]\titers: 2500, epoch: 4 | loss: 0.1892076\n",
      "\tspeed: 0.0636s/iter; left time: 3909.9513s\n",
      "2599it [02:49, 15.88it/s]\titers: 2600, epoch: 4 | loss: 0.2370274\n",
      "\tspeed: 0.0641s/iter; left time: 3938.8264s\n",
      "2699it [02:56, 12.37it/s]\titers: 2700, epoch: 4 | loss: 0.2875415\n",
      "\tspeed: 0.0679s/iter; left time: 4165.3309s\n",
      "2799it [03:02, 15.29it/s]\titers: 2800, epoch: 4 | loss: 0.2479535\n",
      "\tspeed: 0.0621s/iter; left time: 3798.7946s\n",
      "2899it [03:09, 14.78it/s]\titers: 2900, epoch: 4 | loss: 0.2013184\n",
      "\tspeed: 0.0637s/iter; left time: 3892.7349s\n",
      "2999it [03:15, 13.07it/s]\titers: 3000, epoch: 4 | loss: 0.1513206\n",
      "\tspeed: 0.0671s/iter; left time: 4092.1526s\n",
      "3099it [03:22, 14.97it/s]\titers: 3100, epoch: 4 | loss: 0.3568746\n",
      "\tspeed: 0.0691s/iter; left time: 4206.1438s\n",
      "3199it [03:29, 13.66it/s]\titers: 3200, epoch: 4 | loss: 0.1830495\n",
      "\tspeed: 0.0672s/iter; left time: 4083.2868s\n",
      "3299it [03:36, 15.14it/s]\titers: 3300, epoch: 4 | loss: 0.3516821\n",
      "\tspeed: 0.0656s/iter; left time: 3979.9890s\n",
      "3399it [03:42, 15.11it/s]\titers: 3400, epoch: 4 | loss: 0.5220647\n",
      "\tspeed: 0.0659s/iter; left time: 3992.2192s\n",
      "3499it [03:49, 15.42it/s]\titers: 3500, epoch: 4 | loss: 0.2608746\n",
      "\tspeed: 0.0651s/iter; left time: 3935.9462s\n",
      "3599it [03:55, 14.04it/s]\titers: 3600, epoch: 4 | loss: 0.2053786\n",
      "\tspeed: 0.0658s/iter; left time: 3977.1193s\n",
      "3699it [04:01, 16.45it/s]\titers: 3700, epoch: 4 | loss: 0.1342290\n",
      "\tspeed: 0.0626s/iter; left time: 3773.4069s\n",
      "3765it [04:06, 15.29it/s]\n",
      "Epoch: 4 cost time: 246.20728754997253\n",
      "810it [00:22, 35.51it/s]\n",
      "807it [00:23, 34.74it/s]\n",
      "Epoch: 4 | Train Loss: 0.2499129 Vali Loss: 0.2966581 Test Loss: 0.3651407 MAE Loss: 0.3743777\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "99it [00:06, 15.01it/s]\titers: 100, epoch: 5 | loss: 0.1123981\n",
      "\tspeed: 0.6003s/iter; left time: 36102.1822s\n",
      "199it [00:13, 15.01it/s]\titers: 200, epoch: 5 | loss: 0.2107955\n",
      "\tspeed: 0.0664s/iter; left time: 3985.2155s\n",
      "299it [00:20, 16.05it/s]\titers: 300, epoch: 5 | loss: 0.1289533\n",
      "\tspeed: 0.0662s/iter; left time: 3966.7769s\n",
      "399it [00:26, 16.10it/s]\titers: 400, epoch: 5 | loss: 0.3781210\n",
      "\tspeed: 0.0637s/iter; left time: 3812.7839s\n",
      "499it [00:32, 15.53it/s]\titers: 500, epoch: 5 | loss: 0.1776559\n",
      "\tspeed: 0.0644s/iter; left time: 3846.8740s\n",
      "599it [00:39, 14.91it/s]\titers: 600, epoch: 5 | loss: 0.2202805\n",
      "\tspeed: 0.0664s/iter; left time: 3960.3258s\n",
      "699it [00:45, 15.75it/s]\titers: 700, epoch: 5 | loss: 0.2922030\n",
      "\tspeed: 0.0596s/iter; left time: 3546.9424s\n",
      "799it [00:53, 15.40it/s]\titers: 800, epoch: 5 | loss: 0.2109923\n",
      "\tspeed: 0.0846s/iter; left time: 5031.2240s\n",
      "899it [01:00, 14.63it/s]\titers: 900, epoch: 5 | loss: 0.4018222\n",
      "\tspeed: 0.0700s/iter; left time: 4152.5433s\n",
      "999it [01:07, 15.47it/s]\titers: 1000, epoch: 5 | loss: 0.2406776\n",
      "\tspeed: 0.0657s/iter; left time: 3890.9067s\n",
      "1099it [01:14, 15.13it/s]\titers: 1100, epoch: 5 | loss: 0.2309297\n",
      "\tspeed: 0.0665s/iter; left time: 3934.6147s\n",
      "1199it [01:21, 15.59it/s]\titers: 1200, epoch: 5 | loss: 0.3776409\n",
      "\tspeed: 0.0701s/iter; left time: 4139.0200s\n",
      "1299it [01:27, 15.24it/s]\titers: 1300, epoch: 5 | loss: 0.2000230\n",
      "\tspeed: 0.0653s/iter; left time: 3846.7009s\n",
      "1399it [01:34, 15.08it/s]\titers: 1400, epoch: 5 | loss: 0.2622741\n",
      "\tspeed: 0.0661s/iter; left time: 3886.5529s\n",
      "1499it [01:41, 14.77it/s]\titers: 1500, epoch: 5 | loss: 0.2484586\n",
      "\tspeed: 0.0682s/iter; left time: 4003.3188s\n",
      "1599it [01:47, 15.26it/s]\titers: 1600, epoch: 5 | loss: 0.2005717\n",
      "\tspeed: 0.0651s/iter; left time: 3817.8295s\n",
      "1699it [01:54, 15.16it/s]\titers: 1700, epoch: 5 | loss: 0.2261216\n",
      "\tspeed: 0.0657s/iter; left time: 3845.4225s\n",
      "1799it [02:00, 13.32it/s]\titers: 1800, epoch: 5 | loss: 0.2542133\n",
      "\tspeed: 0.0684s/iter; left time: 3997.0259s\n",
      "1899it [02:07, 14.86it/s]\titers: 1900, epoch: 5 | loss: 0.1634717\n",
      "\tspeed: 0.0641s/iter; left time: 3739.2104s\n",
      "1999it [02:13, 15.08it/s]\titers: 2000, epoch: 5 | loss: 0.3553766\n",
      "\tspeed: 0.0660s/iter; left time: 3842.4089s\n",
      "2099it [02:20, 16.35it/s]\titers: 2100, epoch: 5 | loss: 0.1943088\n",
      "\tspeed: 0.0669s/iter; left time: 3889.5072s\n",
      "2199it [02:26, 15.22it/s]\titers: 2200, epoch: 5 | loss: 0.1610091\n",
      "\tspeed: 0.0630s/iter; left time: 3657.9664s\n",
      "2299it [02:33, 15.63it/s]\titers: 2300, epoch: 5 | loss: 0.1404839\n",
      "\tspeed: 0.0632s/iter; left time: 3661.9216s\n",
      "2399it [02:40, 13.98it/s]\titers: 2400, epoch: 5 | loss: 0.2060732\n",
      "\tspeed: 0.0716s/iter; left time: 4140.8351s\n",
      "2499it [02:47, 14.63it/s]\titers: 2500, epoch: 5 | loss: 0.3878875\n",
      "\tspeed: 0.0688s/iter; left time: 3972.9248s\n",
      "2598it [02:54, 12.67it/s]\titers: 2600, epoch: 5 | loss: 0.2119254\n",
      "\tspeed: 0.0741s/iter; left time: 4273.9516s\n",
      "2698it [03:01, 14.03it/s]\titers: 2700, epoch: 5 | loss: 0.2229400\n",
      "\tspeed: 0.0703s/iter; left time: 4043.4403s\n",
      "2798it [03:08, 15.16it/s]\titers: 2800, epoch: 5 | loss: 0.3755247\n",
      "\tspeed: 0.0646s/iter; left time: 3710.9907s\n",
      "2898it [03:14, 15.79it/s]\titers: 2900, epoch: 5 | loss: 0.1882057\n",
      "\tspeed: 0.0678s/iter; left time: 3885.1253s\n",
      "2998it [03:21, 15.44it/s]\titers: 3000, epoch: 5 | loss: 0.2404755\n",
      "\tspeed: 0.0647s/iter; left time: 3705.8081s\n",
      "3098it [03:27, 15.21it/s]\titers: 3100, epoch: 5 | loss: 0.1888831\n",
      "\tspeed: 0.0646s/iter; left time: 3692.9255s\n",
      "3198it [03:34, 13.36it/s]\titers: 3200, epoch: 5 | loss: 0.2706753\n",
      "\tspeed: 0.0644s/iter; left time: 3672.8977s\n",
      "3298it [03:40, 15.88it/s]\titers: 3300, epoch: 5 | loss: 0.3557244\n",
      "\tspeed: 0.0640s/iter; left time: 3643.3547s\n",
      "3398it [03:47, 15.77it/s]\titers: 3400, epoch: 5 | loss: 0.4302408\n",
      "\tspeed: 0.0636s/iter; left time: 3613.8811s\n",
      "3498it [03:53, 12.40it/s]\titers: 3500, epoch: 5 | loss: 0.3061902\n",
      "\tspeed: 0.0667s/iter; left time: 3783.3020s\n",
      "3598it [04:00, 15.12it/s]\titers: 3600, epoch: 5 | loss: 0.2078661\n",
      "\tspeed: 0.0649s/iter; left time: 3673.4077s\n",
      "3698it [04:06, 17.15it/s]\titers: 3700, epoch: 5 | loss: 0.2266775\n",
      "\tspeed: 0.0630s/iter; left time: 3560.1871s\n",
      "3765it [04:10, 15.02it/s]\n",
      "Epoch: 5 cost time: 250.65710639953613\n",
      "810it [00:23, 34.37it/s]\n",
      "807it [00:23, 33.99it/s]\n",
      "Epoch: 5 | Train Loss: 0.2455455 Vali Loss: 0.2894572 Test Loss: 0.3574075 MAE Loss: 0.3616647\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:06, 15.29it/s]\titers: 100, epoch: 6 | loss: 0.4155045\n",
      "\tspeed: 0.6014s/iter; left time: 33903.4173s\n",
      "199it [00:13, 15.43it/s]\titers: 200, epoch: 6 | loss: 0.2151375\n",
      "\tspeed: 0.0682s/iter; left time: 3837.9299s\n",
      "299it [00:19, 15.99it/s]\titers: 300, epoch: 6 | loss: 0.2233660\n",
      "\tspeed: 0.0655s/iter; left time: 3679.2937s\n",
      "399it [00:26, 16.29it/s]\titers: 400, epoch: 6 | loss: 0.2370272\n",
      "\tspeed: 0.0633s/iter; left time: 3551.9772s\n",
      "499it [00:32, 15.14it/s]\titers: 500, epoch: 6 | loss: 0.3249427\n",
      "\tspeed: 0.0669s/iter; left time: 3743.2322s\n",
      "599it [00:39, 15.20it/s]\titers: 600, epoch: 6 | loss: 0.2057504\n",
      "\tspeed: 0.0668s/iter; left time: 3730.7064s\n",
      "699it [00:46, 15.13it/s]\titers: 700, epoch: 6 | loss: 0.2245868\n",
      "\tspeed: 0.0649s/iter; left time: 3621.5401s\n",
      "799it [00:53, 15.18it/s]\titers: 800, epoch: 6 | loss: 0.2150132\n",
      "\tspeed: 0.0714s/iter; left time: 3976.6183s\n",
      "899it [00:59, 14.95it/s]\titers: 900, epoch: 6 | loss: 0.2049391\n",
      "\tspeed: 0.0628s/iter; left time: 3492.0743s\n",
      "999it [01:05, 14.91it/s]\titers: 1000, epoch: 6 | loss: 0.2362233\n",
      "\tspeed: 0.0629s/iter; left time: 3486.7621s\n",
      "1099it [01:12, 16.07it/s]\titers: 1100, epoch: 6 | loss: 0.3349630\n",
      "\tspeed: 0.0661s/iter; left time: 3661.8807s\n",
      "1199it [01:19, 15.26it/s]\titers: 1200, epoch: 6 | loss: 0.2291597\n",
      "\tspeed: 0.0667s/iter; left time: 3689.0608s\n",
      "1299it [01:25, 15.16it/s]\titers: 1300, epoch: 6 | loss: 0.2673230\n",
      "\tspeed: 0.0649s/iter; left time: 3580.7492s\n",
      "1399it [01:32, 14.20it/s]\titers: 1400, epoch: 6 | loss: 0.4808021\n",
      "\tspeed: 0.0706s/iter; left time: 3889.1142s\n",
      "1499it [01:39, 14.34it/s]\titers: 1500, epoch: 6 | loss: 0.2465804\n",
      "\tspeed: 0.0685s/iter; left time: 3767.6201s\n",
      "1599it [01:46, 15.97it/s]\titers: 1600, epoch: 6 | loss: 0.2136759\n",
      "\tspeed: 0.0664s/iter; left time: 3641.5649s\n",
      "1699it [01:53, 14.10it/s]\titers: 1700, epoch: 6 | loss: 0.2059775\n",
      "\tspeed: 0.0704s/iter; left time: 3853.7615s\n",
      "1799it [01:59, 15.14it/s]\titers: 1800, epoch: 6 | loss: 0.2031878\n",
      "\tspeed: 0.0639s/iter; left time: 3494.8315s\n",
      "1899it [02:06, 15.29it/s]\titers: 1900, epoch: 6 | loss: 0.2569441\n",
      "\tspeed: 0.0656s/iter; left time: 3578.3720s\n",
      "1999it [02:12, 15.88it/s]\titers: 2000, epoch: 6 | loss: 0.2712336\n",
      "\tspeed: 0.0683s/iter; left time: 3720.0949s\n",
      "2099it [02:19, 15.25it/s]\titers: 2100, epoch: 6 | loss: 0.2789578\n",
      "\tspeed: 0.0651s/iter; left time: 3538.8900s\n",
      "2199it [02:25, 15.45it/s]\titers: 2200, epoch: 6 | loss: 0.4470836\n",
      "\tspeed: 0.0642s/iter; left time: 3485.7095s\n",
      "2299it [02:32, 15.94it/s]\titers: 2300, epoch: 6 | loss: 0.2961437\n",
      "\tspeed: 0.0702s/iter; left time: 3801.6925s\n",
      "2399it [02:39, 15.79it/s]\titers: 2400, epoch: 6 | loss: 0.2287057\n",
      "\tspeed: 0.0624s/iter; left time: 3374.0040s\n",
      "2499it [02:45, 15.36it/s]\titers: 2500, epoch: 6 | loss: 0.2533989\n",
      "\tspeed: 0.0651s/iter; left time: 3513.4286s\n",
      "2599it [02:52, 15.87it/s]\titers: 2600, epoch: 6 | loss: 0.3319125\n",
      "\tspeed: 0.0690s/iter; left time: 3717.7609s\n",
      "2699it [02:58, 15.86it/s]\titers: 2700, epoch: 6 | loss: 0.2754551\n",
      "\tspeed: 0.0640s/iter; left time: 3442.4326s\n",
      "2799it [03:05, 15.55it/s]\titers: 2800, epoch: 6 | loss: 0.2759766\n",
      "\tspeed: 0.0656s/iter; left time: 3518.8770s\n",
      "2899it [03:12, 15.89it/s]\titers: 2900, epoch: 6 | loss: 0.2929042\n",
      "\tspeed: 0.0691s/iter; left time: 3700.2190s\n",
      "2999it [03:18, 15.44it/s]\titers: 3000, epoch: 6 | loss: 0.2592451\n",
      "\tspeed: 0.0642s/iter; left time: 3431.4171s\n",
      "3099it [03:25, 15.54it/s]\titers: 3100, epoch: 6 | loss: 0.1958182\n",
      "\tspeed: 0.0647s/iter; left time: 3452.6918s\n",
      "3199it [03:31, 15.16it/s]\titers: 3200, epoch: 6 | loss: 0.2920388\n",
      "\tspeed: 0.0645s/iter; left time: 3436.8226s\n",
      "3299it [03:38, 15.59it/s]\titers: 3300, epoch: 6 | loss: 0.2211662\n",
      "\tspeed: 0.0638s/iter; left time: 3394.6524s\n",
      "3399it [03:44, 15.59it/s]\titers: 3400, epoch: 6 | loss: 0.1265130\n",
      "\tspeed: 0.0629s/iter; left time: 3339.1285s\n",
      "3499it [03:51, 10.86it/s]\titers: 3500, epoch: 6 | loss: 0.2550684\n",
      "\tspeed: 0.0693s/iter; left time: 3670.6221s\n",
      "3599it [03:58, 14.62it/s]\titers: 3600, epoch: 6 | loss: 0.1757974\n",
      "\tspeed: 0.0679s/iter; left time: 3589.4018s\n",
      "3699it [04:04, 15.36it/s]\titers: 3700, epoch: 6 | loss: 0.1225053\n",
      "\tspeed: 0.0682s/iter; left time: 3600.8768s\n",
      "3765it [04:09, 15.09it/s]\n",
      "Epoch: 6 cost time: 249.46359276771545\n",
      "810it [00:23, 34.96it/s]\n",
      "807it [00:23, 34.98it/s]\n",
      "Epoch: 6 | Train Loss: 0.2419333 Vali Loss: 0.2892111 Test Loss: 0.3571283 MAE Loss: 0.3614434\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:06, 15.13it/s]\titers: 100, epoch: 7 | loss: 0.3755708\n",
      "\tspeed: 0.5990s/iter; left time: 31515.4167s\n",
      "199it [00:13, 15.25it/s]\titers: 200, epoch: 7 | loss: 0.1756885\n",
      "\tspeed: 0.0632s/iter; left time: 3316.6107s\n",
      "299it [00:19, 15.38it/s]\titers: 300, epoch: 7 | loss: 0.2545287\n",
      "\tspeed: 0.0659s/iter; left time: 3456.3325s\n",
      "399it [00:26, 15.17it/s]\titers: 400, epoch: 7 | loss: 0.2934910\n",
      "\tspeed: 0.0660s/iter; left time: 3452.4453s\n",
      "499it [00:33, 14.13it/s]\titers: 500, epoch: 7 | loss: 0.1888867\n",
      "\tspeed: 0.0705s/iter; left time: 3679.6623s\n",
      "599it [00:40, 13.69it/s]\titers: 600, epoch: 7 | loss: 0.3608443\n",
      "\tspeed: 0.0704s/iter; left time: 3669.3634s\n",
      "699it [00:47, 16.61it/s]\titers: 700, epoch: 7 | loss: 0.2574110\n",
      "\tspeed: 0.0684s/iter; left time: 3555.0965s\n",
      "799it [00:54, 13.97it/s]\titers: 800, epoch: 7 | loss: 0.1950595\n",
      "\tspeed: 0.0695s/iter; left time: 3606.5328s\n",
      "899it [01:00, 15.78it/s]\titers: 900, epoch: 7 | loss: 0.2976969\n",
      "\tspeed: 0.0663s/iter; left time: 3435.4333s\n",
      "999it [01:07, 13.90it/s]\titers: 1000, epoch: 7 | loss: 0.1752623\n",
      "\tspeed: 0.0694s/iter; left time: 3591.1877s\n",
      "1099it [01:14, 15.67it/s]\titers: 1100, epoch: 7 | loss: 0.1814448\n",
      "\tspeed: 0.0712s/iter; left time: 3676.8496s\n",
      "1199it [01:21, 15.52it/s]\titers: 1200, epoch: 7 | loss: 0.1131182\n",
      "\tspeed: 0.0647s/iter; left time: 3332.7229s\n",
      "1299it [01:27, 15.87it/s]\titers: 1300, epoch: 7 | loss: 0.1894270\n",
      "\tspeed: 0.0635s/iter; left time: 3263.9715s\n",
      "1399it [01:34, 15.71it/s]\titers: 1400, epoch: 7 | loss: 0.1981000\n",
      "\tspeed: 0.0641s/iter; left time: 3290.7053s\n",
      "1499it [01:40, 16.30it/s]\titers: 1500, epoch: 7 | loss: 0.1791575\n",
      "\tspeed: 0.0630s/iter; left time: 3226.8126s\n",
      "1599it [01:46, 15.78it/s]\titers: 1600, epoch: 7 | loss: 0.1704624\n",
      "\tspeed: 0.0621s/iter; left time: 3173.2277s\n",
      "1699it [01:53, 16.18it/s]\titers: 1700, epoch: 7 | loss: 0.2538942\n",
      "\tspeed: 0.0661s/iter; left time: 3374.1756s\n",
      "1799it [01:59, 15.66it/s]\titers: 1800, epoch: 7 | loss: 0.1871732\n",
      "\tspeed: 0.0644s/iter; left time: 3276.2959s\n",
      "1899it [02:06, 15.22it/s]\titers: 1900, epoch: 7 | loss: 0.2823605\n",
      "\tspeed: 0.0644s/iter; left time: 3272.0371s\n",
      "1999it [02:12, 16.10it/s]\titers: 2000, epoch: 7 | loss: 0.4445322\n",
      "\tspeed: 0.0678s/iter; left time: 3439.4261s\n",
      "2099it [02:19, 15.72it/s]\titers: 2100, epoch: 7 | loss: 0.2962854\n",
      "\tspeed: 0.0631s/iter; left time: 3192.1028s\n",
      "2199it [02:25, 15.41it/s]\titers: 2200, epoch: 7 | loss: 0.2771426\n",
      "\tspeed: 0.0621s/iter; left time: 3136.5327s\n",
      "2299it [02:31, 16.05it/s]\titers: 2300, epoch: 7 | loss: 0.2426527\n",
      "\tspeed: 0.0650s/iter; left time: 3278.3331s\n",
      "2399it [02:38, 15.64it/s]\titers: 2400, epoch: 7 | loss: 0.3367086\n",
      "\tspeed: 0.0641s/iter; left time: 3223.0074s\n",
      "2499it [02:44, 15.41it/s]\titers: 2500, epoch: 7 | loss: 0.1935951\n",
      "\tspeed: 0.0640s/iter; left time: 3215.3658s\n",
      "2599it [02:51, 16.03it/s]\titers: 2600, epoch: 7 | loss: 0.1862796\n",
      "\tspeed: 0.0678s/iter; left time: 3398.5853s\n",
      "2699it [02:57, 15.53it/s]\titers: 2700, epoch: 7 | loss: 0.2568911\n",
      "\tspeed: 0.0631s/iter; left time: 3155.0619s\n",
      "2799it [03:04, 15.47it/s]\titers: 2800, epoch: 7 | loss: 0.3016179\n",
      "\tspeed: 0.0631s/iter; left time: 3147.5495s\n",
      "2899it [03:10, 15.38it/s]\titers: 2900, epoch: 7 | loss: 0.2567457\n",
      "\tspeed: 0.0677s/iter; left time: 3369.7859s\n",
      "2999it [03:17, 15.66it/s]\titers: 3000, epoch: 7 | loss: 0.2577315\n",
      "\tspeed: 0.0652s/iter; left time: 3240.7088s\n",
      "3099it [03:23, 15.49it/s]\titers: 3100, epoch: 7 | loss: 0.1764490\n",
      "\tspeed: 0.0631s/iter; left time: 3129.2517s\n",
      "3199it [03:30, 16.10it/s]\titers: 3200, epoch: 7 | loss: 0.2115007\n",
      "\tspeed: 0.0691s/iter; left time: 3421.9284s\n",
      "3299it [03:37, 15.35it/s]\titers: 3300, epoch: 7 | loss: 0.2941763\n",
      "\tspeed: 0.0644s/iter; left time: 3181.0613s\n",
      "3399it [03:43, 15.03it/s]\titers: 3400, epoch: 7 | loss: 0.1953549\n",
      "\tspeed: 0.0657s/iter; left time: 3240.0570s\n",
      "3499it [03:50, 15.65it/s]\titers: 3500, epoch: 7 | loss: 0.3348430\n",
      "\tspeed: 0.0690s/iter; left time: 3397.8274s\n",
      "3599it [03:56, 16.21it/s]\titers: 3600, epoch: 7 | loss: 0.2835595\n",
      "\tspeed: 0.0613s/iter; left time: 3010.4840s\n",
      "3699it [04:03, 15.29it/s]\titers: 3700, epoch: 7 | loss: 0.2593045\n",
      "\tspeed: 0.0643s/iter; left time: 3152.1821s\n",
      "3765it [04:07, 15.23it/s]\n",
      "Epoch: 7 cost time: 247.17385578155518\n",
      "810it [00:23, 34.50it/s]\n",
      "807it [00:22, 35.32it/s]\n",
      "Epoch: 7 | Train Loss: 0.2412956 Vali Loss: 0.2868791 Test Loss: 0.3543772 MAE Loss: 0.3594986\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:06, 19.83it/s]\titers: 100, epoch: 8 | loss: 0.2224935\n",
      "\tspeed: 0.5864s/iter; left time: 28642.0468s\n",
      "198it [00:11, 16.17it/s]\titers: 200, epoch: 8 | loss: 0.2044067\n",
      "\tspeed: 0.0590s/iter; left time: 2875.7838s\n",
      "298it [00:18, 15.66it/s]\titers: 300, epoch: 8 | loss: 0.1038597\n",
      "\tspeed: 0.0625s/iter; left time: 3040.1208s\n",
      "398it [00:24, 15.14it/s]\titers: 400, epoch: 8 | loss: 0.1543410\n",
      "\tspeed: 0.0647s/iter; left time: 3139.2949s\n",
      "497it [00:31, 19.39it/s]\titers: 500, epoch: 8 | loss: 0.2309961\n",
      "\tspeed: 0.0652s/iter; left time: 3160.0353s\n",
      "599it [00:36, 20.15it/s]\titers: 600, epoch: 8 | loss: 0.2914826\n",
      "\tspeed: 0.0505s/iter; left time: 2442.3531s\n",
      "698it [00:41, 20.09it/s]\titers: 700, epoch: 8 | loss: 0.3107494\n",
      "\tspeed: 0.0494s/iter; left time: 2384.7821s\n",
      "797it [00:46, 20.05it/s]\titers: 800, epoch: 8 | loss: 0.1408462\n",
      "\tspeed: 0.0499s/iter; left time: 2403.4868s\n",
      "899it [00:51, 17.64it/s]\titers: 900, epoch: 8 | loss: 0.2760729\n",
      "\tspeed: 0.0541s/iter; left time: 2600.2087s\n",
      "998it [00:57, 15.60it/s]\titers: 1000, epoch: 8 | loss: 0.1479827\n",
      "\tspeed: 0.0602s/iter; left time: 2886.6740s\n",
      "1098it [01:03, 15.73it/s]\titers: 1100, epoch: 8 | loss: 0.1647125\n",
      "\tspeed: 0.0629s/iter; left time: 3007.1734s\n",
      "1198it [01:10, 15.46it/s]\titers: 1200, epoch: 8 | loss: 0.3855052\n",
      "\tspeed: 0.0655s/iter; left time: 3127.0189s\n",
      "1298it [01:16, 16.37it/s]\titers: 1300, epoch: 8 | loss: 0.2248528\n",
      "\tspeed: 0.0619s/iter; left time: 2947.3665s\n",
      "1398it [01:22, 15.31it/s]\titers: 1400, epoch: 8 | loss: 0.1797119\n",
      "\tspeed: 0.0626s/iter; left time: 2978.6863s\n",
      "1498it [01:29, 16.02it/s]\titers: 1500, epoch: 8 | loss: 0.2034261\n",
      "\tspeed: 0.0649s/iter; left time: 3078.2126s\n",
      "1598it [01:35, 15.64it/s]\titers: 1600, epoch: 8 | loss: 0.3035041\n",
      "\tspeed: 0.0625s/iter; left time: 2958.9167s\n",
      "1698it [01:42, 15.56it/s]\titers: 1700, epoch: 8 | loss: 0.1762127\n",
      "\tspeed: 0.0640s/iter; left time: 3021.8044s\n",
      "1798it [01:48, 16.20it/s]\titers: 1800, epoch: 8 | loss: 0.3360490\n",
      "\tspeed: 0.0660s/iter; left time: 3112.5039s\n",
      "1898it [01:55, 15.63it/s]\titers: 1900, epoch: 8 | loss: 0.1874921\n",
      "\tspeed: 0.0636s/iter; left time: 2992.9954s\n",
      "1998it [02:01, 15.43it/s]\titers: 2000, epoch: 8 | loss: 0.1278186\n",
      "\tspeed: 0.0651s/iter; left time: 3056.1974s\n",
      "2098it [02:08, 16.54it/s]\titers: 2100, epoch: 8 | loss: 0.1297460\n",
      "\tspeed: 0.0684s/iter; left time: 3204.8639s\n",
      "2198it [02:14, 15.59it/s]\titers: 2200, epoch: 8 | loss: 0.2459786\n",
      "\tspeed: 0.0622s/iter; left time: 2908.9094s\n",
      "2298it [02:21, 15.54it/s]\titers: 2300, epoch: 8 | loss: 0.1471041\n",
      "\tspeed: 0.0642s/iter; left time: 2996.0878s\n",
      "2398it [02:27, 16.47it/s]\titers: 2400, epoch: 8 | loss: 0.4369275\n",
      "\tspeed: 0.0682s/iter; left time: 3173.0920s\n",
      "2498it [02:33, 16.49it/s]\titers: 2500, epoch: 8 | loss: 0.2633002\n",
      "\tspeed: 0.0607s/iter; left time: 2818.3451s\n",
      "2598it [02:40, 10.31it/s]\titers: 2600, epoch: 8 | loss: 0.3233567\n",
      "\tspeed: 0.0680s/iter; left time: 3153.3242s\n",
      "2698it [02:47, 16.02it/s]\titers: 2700, epoch: 8 | loss: 0.2161634\n",
      "\tspeed: 0.0629s/iter; left time: 2910.8849s\n",
      "2798it [02:53, 15.97it/s]\titers: 2800, epoch: 8 | loss: 0.2650145\n",
      "\tspeed: 0.0630s/iter; left time: 2906.1978s\n",
      "2898it [03:00, 10.23it/s]\titers: 2900, epoch: 8 | loss: 0.1921072\n",
      "\tspeed: 0.0694s/iter; left time: 3197.0158s\n",
      "2998it [03:06, 15.80it/s]\titers: 3000, epoch: 8 | loss: 0.1592651\n",
      "\tspeed: 0.0621s/iter; left time: 2853.0081s\n",
      "3098it [03:12, 15.57it/s]\titers: 3100, epoch: 8 | loss: 0.1788701\n",
      "\tspeed: 0.0633s/iter; left time: 2904.0992s\n",
      "3198it [03:19, 14.03it/s]\titers: 3200, epoch: 8 | loss: 0.3043209\n",
      "\tspeed: 0.0671s/iter; left time: 3070.9920s\n",
      "3298it [03:25, 15.57it/s]\titers: 3300, epoch: 8 | loss: 0.2385036\n",
      "\tspeed: 0.0640s/iter; left time: 2919.4134s\n",
      "3398it [03:32, 15.47it/s]\titers: 3400, epoch: 8 | loss: 0.1678842\n",
      "\tspeed: 0.0634s/iter; left time: 2888.2669s\n",
      "3499it [03:38, 19.65it/s]\titers: 3500, epoch: 8 | loss: 0.2638773\n",
      "\tspeed: 0.0575s/iter; left time: 2614.5690s\n",
      "3598it [03:43, 15.96it/s]\titers: 3600, epoch: 8 | loss: 0.2820717\n",
      "\tspeed: 0.0587s/iter; left time: 2659.7423s\n",
      "3698it [03:50, 15.55it/s]\titers: 3700, epoch: 8 | loss: 0.0960728\n",
      "\tspeed: 0.0631s/iter; left time: 2854.2053s\n",
      "3765it [03:54, 16.07it/s]\n",
      "Epoch: 8 cost time: 234.2793345451355\n",
      "810it [00:23, 34.72it/s]\n",
      "807it [00:23, 34.92it/s]\n",
      "Epoch: 8 | Train Loss: 0.2410483 Vali Loss: 0.2871329 Test Loss: 0.3549889 MAE Loss: 0.3607748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:06, 15.46it/s]\titers: 100, epoch: 9 | loss: 0.1438134\n",
      "\tspeed: 0.5739s/iter; left time: 25871.6682s\n",
      "199it [00:13, 15.25it/s]\titers: 200, epoch: 9 | loss: 0.3153541\n",
      "\tspeed: 0.0650s/iter; left time: 2925.7174s\n",
      "299it [00:19, 16.07it/s]\titers: 300, epoch: 9 | loss: 0.4425206\n",
      "\tspeed: 0.0665s/iter; left time: 2982.6772s\n",
      "399it [00:26, 15.60it/s]\titers: 400, epoch: 9 | loss: 0.1034750\n",
      "\tspeed: 0.0638s/iter; left time: 2857.0393s\n",
      "499it [00:32, 15.25it/s]\titers: 500, epoch: 9 | loss: 0.2935615\n",
      "\tspeed: 0.0647s/iter; left time: 2892.1706s\n",
      "599it [00:39, 14.23it/s]\titers: 600, epoch: 9 | loss: 0.2302960\n",
      "\tspeed: 0.0651s/iter; left time: 2902.7581s\n",
      "699it [00:45, 15.15it/s]\titers: 700, epoch: 9 | loss: 0.1624193\n",
      "\tspeed: 0.0639s/iter; left time: 2843.5966s\n",
      "799it [00:52, 15.12it/s]\titers: 800, epoch: 9 | loss: 0.1916170\n",
      "\tspeed: 0.0662s/iter; left time: 2936.2389s\n",
      "899it [00:59, 16.98it/s]\titers: 900, epoch: 9 | loss: 0.2105528\n",
      "\tspeed: 0.0680s/iter; left time: 3009.0126s\n",
      "999it [01:05, 16.76it/s]\titers: 1000, epoch: 9 | loss: 0.2711023\n",
      "\tspeed: 0.0618s/iter; left time: 2729.6510s\n",
      "1099it [01:11, 18.49it/s]\titers: 1100, epoch: 9 | loss: 0.2673998\n",
      "\tspeed: 0.0649s/iter; left time: 2859.5405s\n",
      "1198it [01:17, 19.43it/s]\titers: 1200, epoch: 9 | loss: 0.1544502\n",
      "\tspeed: 0.0606s/iter; left time: 2663.3371s\n",
      "1299it [01:23, 16.44it/s]\titers: 1300, epoch: 9 | loss: 0.1365122\n",
      "\tspeed: 0.0583s/iter; left time: 2559.8882s\n",
      "1399it [01:29, 14.89it/s]\titers: 1400, epoch: 9 | loss: 0.1936604\n",
      "\tspeed: 0.0626s/iter; left time: 2740.6103s\n",
      "1499it [01:37, 16.03it/s]\titers: 1500, epoch: 9 | loss: 0.2028575\n",
      "\tspeed: 0.0711s/iter; left time: 3106.3337s\n",
      "1599it [01:43, 15.04it/s]\titers: 1600, epoch: 9 | loss: 0.1639494\n",
      "\tspeed: 0.0692s/iter; left time: 3014.7167s\n",
      "1699it [01:50, 13.89it/s]\titers: 1700, epoch: 9 | loss: 0.5783395\n",
      "\tspeed: 0.0669s/iter; left time: 2907.8190s\n",
      "1799it [01:58, 13.65it/s]\titers: 1800, epoch: 9 | loss: 0.2934180\n",
      "\tspeed: 0.0750s/iter; left time: 3254.2576s\n",
      "1899it [02:04, 15.38it/s]\titers: 1900, epoch: 9 | loss: 0.1467383\n",
      "\tspeed: 0.0653s/iter; left time: 2824.6697s\n",
      "1999it [02:12, 14.26it/s]\titers: 2000, epoch: 9 | loss: 0.2441390\n",
      "\tspeed: 0.0744s/iter; left time: 3210.7164s\n",
      "2099it [02:18, 14.10it/s]\titers: 2100, epoch: 9 | loss: 0.1274403\n",
      "\tspeed: 0.0678s/iter; left time: 2923.0002s\n",
      "2199it [02:25, 15.28it/s]\titers: 2200, epoch: 9 | loss: 0.2353911\n",
      "\tspeed: 0.0660s/iter; left time: 2834.8758s\n",
      "2299it [02:32, 16.37it/s]\titers: 2300, epoch: 9 | loss: 0.1641532\n",
      "\tspeed: 0.0659s/iter; left time: 2827.1198s\n",
      "2399it [02:38, 15.62it/s]\titers: 2400, epoch: 9 | loss: 0.1710678\n",
      "\tspeed: 0.0639s/iter; left time: 2734.5670s\n",
      "2499it [02:44, 15.61it/s]\titers: 2500, epoch: 9 | loss: 0.1746087\n",
      "\tspeed: 0.0644s/iter; left time: 2747.0585s\n",
      "2599it [02:51, 13.59it/s]\titers: 2600, epoch: 9 | loss: 0.1394702\n",
      "\tspeed: 0.0693s/iter; left time: 2952.7911s\n",
      "2699it [02:58, 16.33it/s]\titers: 2700, epoch: 9 | loss: 0.1887179\n",
      "\tspeed: 0.0622s/iter; left time: 2643.9687s\n",
      "2799it [03:04, 15.59it/s]\titers: 2800, epoch: 9 | loss: 0.2198702\n",
      "\tspeed: 0.0597s/iter; left time: 2529.6325s\n",
      "2899it [03:10, 11.08it/s]\titers: 2900, epoch: 9 | loss: 0.3595637\n",
      "\tspeed: 0.0677s/iter; left time: 2860.7049s\n",
      "2999it [03:17, 16.45it/s]\titers: 3000, epoch: 9 | loss: 0.1445765\n",
      "\tspeed: 0.0629s/iter; left time: 2651.1238s\n",
      "3099it [03:23, 15.94it/s]\titers: 3100, epoch: 9 | loss: 0.3077244\n",
      "\tspeed: 0.0614s/iter; left time: 2585.7387s\n",
      "3199it [03:30, 14.99it/s]\titers: 3200, epoch: 9 | loss: 0.2367380\n",
      "\tspeed: 0.0690s/iter; left time: 2897.5253s\n",
      "3299it [03:36, 15.91it/s]\titers: 3300, epoch: 9 | loss: 0.1797716\n",
      "\tspeed: 0.0630s/iter; left time: 2640.2563s\n",
      "3399it [03:43, 15.26it/s]\titers: 3400, epoch: 9 | loss: 0.1403939\n",
      "\tspeed: 0.0664s/iter; left time: 2774.1000s\n",
      "3499it [03:50, 13.96it/s]\titers: 3500, epoch: 9 | loss: 0.2329953\n",
      "\tspeed: 0.0716s/iter; left time: 2983.4741s\n",
      "3599it [03:56, 15.57it/s]\titers: 3600, epoch: 9 | loss: 0.2639203\n",
      "\tspeed: 0.0630s/iter; left time: 2619.2415s\n",
      "3699it [04:02, 15.29it/s]\titers: 3700, epoch: 9 | loss: 0.1373141\n",
      "\tspeed: 0.0640s/iter; left time: 2654.0059s\n",
      "3765it [04:07, 15.23it/s]\n",
      "Epoch: 9 cost time: 247.23481607437134\n",
      "810it [00:22, 35.61it/s]\n",
      "807it [00:22, 35.51it/s]\n",
      "Epoch: 9 | Train Loss: 0.2405042 Vali Loss: 0.2867072 Test Loss: 0.3545933 MAE Loss: 0.3590756\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:06, 15.63it/s]\titers: 100, epoch: 10 | loss: 0.3972464\n",
      "\tspeed: 0.5851s/iter; left time: 24174.4506s\n",
      "199it [00:13, 15.66it/s]\titers: 200, epoch: 10 | loss: 0.2279532\n",
      "\tspeed: 0.0655s/iter; left time: 2698.5396s\n",
      "299it [00:19, 15.70it/s]\titers: 300, epoch: 10 | loss: 0.2912650\n",
      "\tspeed: 0.0632s/iter; left time: 2597.8381s\n",
      "398it [00:25, 15.24it/s]\titers: 400, epoch: 10 | loss: 0.1637478\n",
      "\tspeed: 0.0621s/iter; left time: 2548.1802s\n",
      "498it [00:32, 14.73it/s]\titers: 500, epoch: 10 | loss: 0.2050238\n",
      "\tspeed: 0.0670s/iter; left time: 2740.2560s\n",
      "598it [00:38, 14.92it/s]\titers: 600, epoch: 10 | loss: 0.1919203\n",
      "\tspeed: 0.0641s/iter; left time: 2616.1766s\n",
      "698it [00:45, 17.34it/s]\titers: 700, epoch: 10 | loss: 0.3335089\n",
      "\tspeed: 0.0634s/iter; left time: 2582.2856s\n",
      "798it [00:51, 15.70it/s]\titers: 800, epoch: 10 | loss: 0.1561195\n",
      "\tspeed: 0.0653s/iter; left time: 2652.2917s\n",
      "898it [00:58, 14.63it/s]\titers: 900, epoch: 10 | loss: 0.1851393\n",
      "\tspeed: 0.0665s/iter; left time: 2693.1382s\n",
      "998it [01:04, 15.18it/s]\titers: 1000, epoch: 10 | loss: 0.2193477\n",
      "\tspeed: 0.0614s/iter; left time: 2481.6750s\n",
      "1098it [01:11, 15.09it/s]\titers: 1100, epoch: 10 | loss: 0.1650451\n",
      "\tspeed: 0.0666s/iter; left time: 2686.8983s\n",
      "1198it [01:17, 15.77it/s]\titers: 1200, epoch: 10 | loss: 0.3965899\n",
      "\tspeed: 0.0636s/iter; left time: 2558.2610s\n",
      "1298it [01:23, 15.47it/s]\titers: 1300, epoch: 10 | loss: 0.1840114\n",
      "\tspeed: 0.0642s/iter; left time: 2574.8144s\n",
      "1398it [01:30, 14.18it/s]\titers: 1400, epoch: 10 | loss: 0.2338235\n",
      "\tspeed: 0.0653s/iter; left time: 2613.0050s\n",
      "1498it [01:36, 15.54it/s]\titers: 1500, epoch: 10 | loss: 0.2544596\n",
      "\tspeed: 0.0626s/iter; left time: 2496.8462s\n",
      "1598it [01:43, 15.77it/s]\titers: 1600, epoch: 10 | loss: 0.1930967\n",
      "\tspeed: 0.0643s/iter; left time: 2558.7457s\n",
      "1698it [01:49, 15.69it/s]\titers: 1700, epoch: 10 | loss: 0.1582661\n",
      "\tspeed: 0.0660s/iter; left time: 2622.6278s\n",
      "1798it [01:56, 16.29it/s]\titers: 1800, epoch: 10 | loss: 0.2678743\n",
      "\tspeed: 0.0641s/iter; left time: 2538.1102s\n",
      "1899it [02:02, 19.55it/s]\titers: 1900, epoch: 10 | loss: 0.2291739\n",
      "\tspeed: 0.0618s/iter; left time: 2440.9093s\n",
      "1997it [02:07, 19.57it/s]\titers: 2000, epoch: 10 | loss: 0.2255884\n",
      "\tspeed: 0.0539s/iter; left time: 2126.3717s\n",
      "2098it [02:13, 16.39it/s]\titers: 2100, epoch: 10 | loss: 0.4371972\n",
      "\tspeed: 0.0602s/iter; left time: 2368.4840s\n",
      "2198it [02:20, 14.71it/s]\titers: 2200, epoch: 10 | loss: 0.2235700\n",
      "\tspeed: 0.0641s/iter; left time: 2512.6893s\n",
      "2298it [02:26, 15.73it/s]\titers: 2300, epoch: 10 | loss: 0.5989801\n",
      "\tspeed: 0.0653s/iter; left time: 2555.5105s\n",
      "2398it [02:33, 15.67it/s]\titers: 2400, epoch: 10 | loss: 0.1996730\n",
      "\tspeed: 0.0685s/iter; left time: 2671.3600s\n",
      "2498it [02:40, 14.54it/s]\titers: 2500, epoch: 10 | loss: 0.1260048\n",
      "\tspeed: 0.0657s/iter; left time: 2558.4502s\n",
      "2598it [02:46, 15.26it/s]\titers: 2600, epoch: 10 | loss: 0.2941970\n",
      "\tspeed: 0.0657s/iter; left time: 2548.8015s\n",
      "2698it [02:53, 15.86it/s]\titers: 2700, epoch: 10 | loss: 0.2032500\n",
      "\tspeed: 0.0656s/iter; left time: 2538.8135s\n",
      "2798it [02:59, 15.72it/s]\titers: 2800, epoch: 10 | loss: 0.3878573\n",
      "\tspeed: 0.0631s/iter; left time: 2438.5119s\n",
      "2898it [03:06, 15.34it/s]\titers: 2900, epoch: 10 | loss: 0.3162101\n",
      "\tspeed: 0.0660s/iter; left time: 2542.5424s\n",
      "2998it [03:12, 16.01it/s]\titers: 3000, epoch: 10 | loss: 0.1755231\n",
      "\tspeed: 0.0684s/iter; left time: 2629.3100s\n",
      "3098it [03:19, 15.72it/s]\titers: 3100, epoch: 10 | loss: 0.5846490\n",
      "\tspeed: 0.0638s/iter; left time: 2444.5801s\n",
      "3198it [03:25, 15.15it/s]\titers: 3200, epoch: 10 | loss: 0.3587353\n",
      "\tspeed: 0.0652s/iter; left time: 2491.1610s\n",
      "3298it [03:32, 16.47it/s]\titers: 3300, epoch: 10 | loss: 0.3651359\n",
      "\tspeed: 0.0655s/iter; left time: 2496.0994s\n",
      "3398it [03:38, 16.39it/s]\titers: 3400, epoch: 10 | loss: 0.2639170\n",
      "\tspeed: 0.0617s/iter; left time: 2347.1396s\n",
      "3498it [03:44, 15.59it/s]\titers: 3500, epoch: 10 | loss: 0.1750275\n",
      "\tspeed: 0.0618s/iter; left time: 2342.6821s\n",
      "3598it [03:51, 14.97it/s]\titers: 3600, epoch: 10 | loss: 0.2482153\n",
      "\tspeed: 0.0676s/iter; left time: 2557.6929s\n",
      "3698it [03:57, 15.87it/s]\titers: 3700, epoch: 10 | loss: 0.3747338\n",
      "\tspeed: 0.0634s/iter; left time: 2392.0804s\n",
      "3765it [04:02, 15.54it/s]\n",
      "Epoch: 10 cost time: 242.3334138393402\n",
      "810it [00:23, 34.06it/s]\n",
      "807it [00:23, 34.65it/s]\n",
      "Epoch: 10 | Train Loss: 0.2407713 Vali Loss: 0.2868628 Test Loss: 0.3545096 MAE Loss: 0.3595430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "99it [00:07, 14.97it/s]\titers: 100, epoch: 11 | loss: 0.1523518\n",
      "\tspeed: 0.5877s/iter; left time: 22066.9629s\n",
      "199it [00:13, 15.41it/s]\titers: 200, epoch: 11 | loss: 0.1788480\n",
      "\tspeed: 0.0675s/iter; left time: 2527.8263s\n",
      "299it [00:20, 15.28it/s]\titers: 300, epoch: 11 | loss: 0.1941694\n",
      "\tspeed: 0.0676s/iter; left time: 2526.2513s\n",
      "399it [00:27, 13.98it/s]\titers: 400, epoch: 11 | loss: 0.2509474\n",
      "\tspeed: 0.0707s/iter; left time: 2632.8470s\n",
      "499it [00:34, 13.34it/s]\titers: 500, epoch: 11 | loss: 0.1987103\n",
      "\tspeed: 0.0689s/iter; left time: 2561.1591s\n",
      "599it [00:41, 15.92it/s]\titers: 600, epoch: 11 | loss: 0.2572412\n",
      "\tspeed: 0.0682s/iter; left time: 2525.7669s\n",
      "699it [00:48, 15.67it/s]\titers: 700, epoch: 11 | loss: 0.2392495\n",
      "\tspeed: 0.0721s/iter; left time: 2663.8116s\n",
      "799it [00:55, 15.00it/s]\titers: 800, epoch: 11 | loss: 0.1718923\n",
      "\tspeed: 0.0648s/iter; left time: 2386.9926s\n",
      "899it [01:01, 15.61it/s]\titers: 900, epoch: 11 | loss: 0.3663811\n",
      "\tspeed: 0.0650s/iter; left time: 2390.1987s\n",
      "999it [01:07, 19.64it/s]\titers: 1000, epoch: 11 | loss: 0.1906657\n",
      "\tspeed: 0.0630s/iter; left time: 2310.0655s\n",
      "1099it [01:14, 15.60it/s]\titers: 1100, epoch: 11 | loss: 0.1568315\n",
      "\tspeed: 0.0625s/iter; left time: 2283.6844s\n",
      "1199it [01:20, 15.72it/s]\titers: 1200, epoch: 11 | loss: 0.1380863\n",
      "\tspeed: 0.0656s/iter; left time: 2390.7856s\n",
      "1299it [01:27, 14.33it/s]\titers: 1300, epoch: 11 | loss: 0.3951476\n",
      "\tspeed: 0.0663s/iter; left time: 2408.4098s\n",
      "1399it [01:34, 15.32it/s]\titers: 1400, epoch: 11 | loss: 0.1509212\n",
      "\tspeed: 0.0668s/iter; left time: 2422.5927s\n",
      "1499it [01:40, 15.18it/s]\titers: 1500, epoch: 11 | loss: 0.2031958\n",
      "\tspeed: 0.0657s/iter; left time: 2374.9672s\n",
      "1599it [01:47, 15.31it/s]\titers: 1600, epoch: 11 | loss: 0.3048785\n",
      "\tspeed: 0.0696s/iter; left time: 2510.3946s\n",
      "1699it [01:54, 13.20it/s]\titers: 1700, epoch: 11 | loss: 0.2224412\n",
      "\tspeed: 0.0676s/iter; left time: 2431.9201s\n",
      "1799it [02:02, 11.70it/s]\titers: 1800, epoch: 11 | loss: 0.1976964\n",
      "\tspeed: 0.0780s/iter; left time: 2795.7843s\n",
      "1899it [02:08, 14.84it/s]\titers: 1900, epoch: 11 | loss: 0.2001353\n",
      "\tspeed: 0.0682s/iter; left time: 2438.6166s\n",
      "1999it [02:15, 15.55it/s]\titers: 2000, epoch: 11 | loss: 0.2133107\n",
      "\tspeed: 0.0642s/iter; left time: 2287.0985s\n",
      "2099it [02:22, 15.95it/s]\titers: 2100, epoch: 11 | loss: 0.3001105\n",
      "\tspeed: 0.0672s/iter; left time: 2388.9025s\n",
      "2199it [02:28, 19.35it/s]\titers: 2200, epoch: 11 | loss: 0.2117094\n",
      "\tspeed: 0.0614s/iter; left time: 2177.0739s\n",
      "2299it [02:33, 19.65it/s]\titers: 2300, epoch: 11 | loss: 0.1308386\n",
      "\tspeed: 0.0508s/iter; left time: 1796.1041s\n",
      "2399it [02:39, 14.85it/s]\titers: 2400, epoch: 11 | loss: 0.2182207\n",
      "\tspeed: 0.0617s/iter; left time: 2175.1240s\n",
      "2498it [02:45, 16.10it/s]\titers: 2500, epoch: 11 | loss: 0.2155576\n",
      "\tspeed: 0.0591s/iter; left time: 2078.1343s\n",
      "2598it [02:51, 15.52it/s]\titers: 2600, epoch: 11 | loss: 0.2568840\n",
      "\tspeed: 0.0638s/iter; left time: 2235.8221s\n",
      "2698it [02:58, 11.13it/s]\titers: 2700, epoch: 11 | loss: 0.1326563\n",
      "\tspeed: 0.0694s/iter; left time: 2424.6734s\n",
      "2798it [03:04, 16.19it/s]\titers: 2800, epoch: 11 | loss: 0.1121421\n",
      "\tspeed: 0.0626s/iter; left time: 2181.8454s\n",
      "2898it [03:11, 15.42it/s]\titers: 2900, epoch: 11 | loss: 0.1698917\n",
      "\tspeed: 0.0639s/iter; left time: 2219.6599s\n",
      "2998it [03:18, 13.92it/s]\titers: 3000, epoch: 11 | loss: 0.2847153\n",
      "\tspeed: 0.0697s/iter; left time: 2413.5913s\n",
      "3098it [03:24, 16.27it/s]\titers: 3100, epoch: 11 | loss: 0.2408329\n",
      "\tspeed: 0.0622s/iter; left time: 2147.3729s\n",
      "3198it [03:30, 15.70it/s]\titers: 3200, epoch: 11 | loss: 0.2004641\n",
      "\tspeed: 0.0636s/iter; left time: 2192.1488s\n",
      "3298it [03:37, 13.01it/s]\titers: 3300, epoch: 11 | loss: 0.3276578\n",
      "\tspeed: 0.0705s/iter; left time: 2421.8977s\n",
      "3398it [03:44, 16.37it/s]\titers: 3400, epoch: 11 | loss: 0.3011216\n",
      "\tspeed: 0.0621s/iter; left time: 2125.9751s\n",
      "3498it [03:50, 15.88it/s]\titers: 3500, epoch: 11 | loss: 0.3440614\n",
      "\tspeed: 0.0631s/iter; left time: 2156.3648s\n",
      "3598it [03:57, 15.49it/s]\titers: 3600, epoch: 11 | loss: 0.2644449\n",
      "\tspeed: 0.0686s/iter; left time: 2335.4309s\n",
      "3698it [04:04, 16.86it/s]\titers: 3700, epoch: 11 | loss: 0.1537652\n",
      "\tspeed: 0.0761s/iter; left time: 2582.4418s\n",
      "3765it [04:09, 15.11it/s]\n",
      "Epoch: 11 cost time: 249.10235953330994\n",
      "810it [00:22, 35.89it/s]\n",
      "807it [00:23, 34.86it/s]\n",
      "Epoch: 11 | Train Loss: 0.2403472 Vali Loss: 0.2866376 Test Loss: 0.3537605 MAE Loss: 0.3585937\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "99it [00:06, 17.46it/s]\titers: 100, epoch: 12 | loss: 0.3085007\n",
      "\tspeed: 0.5891s/iter; left time: 19904.7016s\n",
      "199it [00:13, 15.57it/s]\titers: 200, epoch: 12 | loss: 0.1332655\n",
      "\tspeed: 0.0639s/iter; left time: 2153.3090s\n",
      "299it [00:19, 15.22it/s]\titers: 300, epoch: 12 | loss: 0.1796459\n",
      "\tspeed: 0.0652s/iter; left time: 2188.2247s\n",
      "399it [00:26, 16.25it/s]\titers: 400, epoch: 12 | loss: 0.1470300\n",
      "\tspeed: 0.0632s/iter; left time: 2117.7317s\n",
      "499it [00:32, 15.79it/s]\titers: 500, epoch: 12 | loss: 0.2110700\n",
      "\tspeed: 0.0629s/iter; left time: 2100.0498s\n",
      "599it [00:39, 11.83it/s]\titers: 600, epoch: 12 | loss: 0.3484653\n",
      "\tspeed: 0.0667s/iter; left time: 2220.0102s\n",
      "699it [00:45, 16.48it/s]\titers: 700, epoch: 12 | loss: 0.1754405\n",
      "\tspeed: 0.0631s/iter; left time: 2093.6678s\n",
      "799it [00:51, 16.23it/s]\titers: 800, epoch: 12 | loss: 0.3128537\n",
      "\tspeed: 0.0617s/iter; left time: 2043.0322s\n",
      "899it [00:57, 15.86it/s]\titers: 900, epoch: 12 | loss: 0.2986689\n",
      "\tspeed: 0.0643s/iter; left time: 2120.2816s\n",
      "999it [01:04, 16.44it/s]\titers: 1000, epoch: 12 | loss: 0.1743185\n",
      "\tspeed: 0.0623s/iter; left time: 2049.9975s\n",
      "1099it [01:10, 15.84it/s]\titers: 1100, epoch: 12 | loss: 0.1906256\n",
      "\tspeed: 0.0626s/iter; left time: 2053.6793s\n",
      "1199it [01:16, 16.05it/s]\titers: 1200, epoch: 12 | loss: 0.2786244\n",
      "\tspeed: 0.0633s/iter; left time: 2070.4755s\n",
      "1299it [01:23, 14.73it/s]\titers: 1300, epoch: 12 | loss: 0.3473099\n",
      "\tspeed: 0.0653s/iter; left time: 2129.3729s\n",
      "1399it [01:30, 14.55it/s]\titers: 1400, epoch: 12 | loss: 0.2028490\n",
      "\tspeed: 0.0681s/iter; left time: 2213.5010s\n",
      "1499it [01:36, 15.55it/s]\titers: 1500, epoch: 12 | loss: 0.1583905\n",
      "\tspeed: 0.0677s/iter; left time: 2191.8800s\n",
      "1599it [01:43, 16.10it/s]\titers: 1600, epoch: 12 | loss: 0.2504120\n",
      "\tspeed: 0.0621s/iter; left time: 2003.3803s\n",
      "1699it [01:49, 15.25it/s]\titers: 1700, epoch: 12 | loss: 0.1546139\n",
      "\tspeed: 0.0635s/iter; left time: 2043.0444s\n",
      "1799it [01:55, 15.93it/s]\titers: 1800, epoch: 12 | loss: 0.1471218\n",
      "\tspeed: 0.0652s/iter; left time: 2091.2437s\n",
      "1899it [02:02, 15.04it/s]\titers: 1900, epoch: 12 | loss: 0.2878406\n",
      "\tspeed: 0.0632s/iter; left time: 2021.2574s\n",
      "1999it [02:08, 15.21it/s]\titers: 2000, epoch: 12 | loss: 0.1285395\n",
      "\tspeed: 0.0647s/iter; left time: 2063.3056s\n",
      "2099it [02:15, 14.82it/s]\titers: 2100, epoch: 12 | loss: 0.1859432\n",
      "\tspeed: 0.0654s/iter; left time: 2077.6319s\n",
      "2199it [02:21, 16.44it/s]\titers: 2200, epoch: 12 | loss: 0.2538866\n",
      "\tspeed: 0.0628s/iter; left time: 1989.7613s\n",
      "2299it [02:27, 14.00it/s]\titers: 2300, epoch: 12 | loss: 0.2070795\n",
      "\tspeed: 0.0640s/iter; left time: 2020.8613s\n",
      "2399it [02:34, 15.96it/s]\titers: 2400, epoch: 12 | loss: 0.3111381\n",
      "\tspeed: 0.0639s/iter; left time: 2012.2453s\n",
      "2499it [02:40, 15.54it/s]\titers: 2500, epoch: 12 | loss: 0.4293250\n",
      "\tspeed: 0.0629s/iter; left time: 1973.9704s\n",
      "2599it [02:47, 13.61it/s]\titers: 2600, epoch: 12 | loss: 0.2364888\n",
      "\tspeed: 0.0643s/iter; left time: 2012.3983s\n",
      "2699it [02:53, 16.04it/s]\titers: 2700, epoch: 12 | loss: 0.2943379\n",
      "\tspeed: 0.0638s/iter; left time: 1991.0521s\n",
      "2799it [02:59, 15.60it/s]\titers: 2800, epoch: 12 | loss: 0.2269082\n",
      "\tspeed: 0.0627s/iter; left time: 1947.5488s\n",
      "2899it [03:06, 14.71it/s]\titers: 2900, epoch: 12 | loss: 0.2235478\n",
      "\tspeed: 0.0635s/iter; left time: 1966.2835s\n",
      "2999it [03:12, 17.86it/s]\titers: 3000, epoch: 12 | loss: 0.5443007\n",
      "\tspeed: 0.0645s/iter; left time: 1993.5566s\n",
      "3099it [03:18, 15.50it/s]\titers: 3100, epoch: 12 | loss: 0.1725603\n",
      "\tspeed: 0.0608s/iter; left time: 1872.8980s\n",
      "3199it [03:25, 15.10it/s]\titers: 3200, epoch: 12 | loss: 0.2618819\n",
      "\tspeed: 0.0650s/iter; left time: 1993.1833s\n",
      "3299it [03:31, 16.47it/s]\titers: 3300, epoch: 12 | loss: 0.3100971\n",
      "\tspeed: 0.0660s/iter; left time: 2018.0569s\n",
      "3399it [03:37, 15.67it/s]\titers: 3400, epoch: 12 | loss: 0.2671025\n",
      "\tspeed: 0.0608s/iter; left time: 1853.8412s\n",
      "3499it [03:44, 14.79it/s]\titers: 3500, epoch: 12 | loss: 0.1404945\n",
      "\tspeed: 0.0630s/iter; left time: 1915.5331s\n",
      "3599it [03:50, 15.95it/s]\titers: 3600, epoch: 12 | loss: 0.2807010\n",
      "\tspeed: 0.0651s/iter; left time: 1971.7177s\n",
      "3698it [03:56, 16.29it/s]\titers: 3700, epoch: 12 | loss: 0.2870910\n",
      "\tspeed: 0.0564s/iter; left time: 1702.2502s\n",
      "3765it [03:59, 15.69it/s]\n",
      "Epoch: 12 cost time: 239.98393058776855\n",
      "810it [00:23, 33.94it/s]\n",
      "807it [00:22, 35.16it/s]\n",
      "Epoch: 12 | Train Loss: 0.2403952 Vali Loss: 0.2869440 Test Loss: 0.3544106 MAE Loss: 0.3595624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "99it [00:06, 16.04it/s]\titers: 100, epoch: 13 | loss: 0.2628521\n",
      "\tspeed: 0.5721s/iter; left time: 17174.1669s\n",
      "199it [00:12, 16.67it/s]\titers: 200, epoch: 13 | loss: 0.1684883\n",
      "\tspeed: 0.0640s/iter; left time: 1914.4460s\n",
      "298it [00:18, 15.98it/s]\titers: 300, epoch: 13 | loss: 0.3153008\n",
      "\tspeed: 0.0584s/iter; left time: 1741.9203s\n",
      "398it [00:24, 15.68it/s]\titers: 400, epoch: 13 | loss: 0.1417075\n",
      "\tspeed: 0.0613s/iter; left time: 1822.9501s\n",
      "498it [00:31, 15.95it/s]\titers: 500, epoch: 13 | loss: 0.1456744\n",
      "\tspeed: 0.0645s/iter; left time: 1911.0956s\n",
      "598it [00:37, 15.49it/s]\titers: 600, epoch: 13 | loss: 0.1803585\n",
      "\tspeed: 0.0636s/iter; left time: 1876.6041s\n",
      "698it [00:43, 15.70it/s]\titers: 700, epoch: 13 | loss: 0.3078794\n",
      "\tspeed: 0.0610s/iter; left time: 1795.8805s\n",
      "798it [00:50, 15.91it/s]\titers: 800, epoch: 13 | loss: 0.2227665\n",
      "\tspeed: 0.0652s/iter; left time: 1913.0315s\n",
      "898it [00:56, 15.93it/s]\titers: 900, epoch: 13 | loss: 0.2230606\n",
      "\tspeed: 0.0634s/iter; left time: 1853.5320s\n",
      "998it [01:03, 15.46it/s]\titers: 1000, epoch: 13 | loss: 0.1995756\n",
      "\tspeed: 0.0639s/iter; left time: 1859.9926s\n",
      "1098it [01:09, 15.62it/s]\titers: 1100, epoch: 13 | loss: 0.2893338\n",
      "\tspeed: 0.0665s/iter; left time: 1929.9095s\n",
      "1198it [01:15, 15.81it/s]\titers: 1200, epoch: 13 | loss: 0.2073116\n",
      "\tspeed: 0.0629s/iter; left time: 1818.6719s\n",
      "1298it [01:22, 16.46it/s]\titers: 1300, epoch: 13 | loss: 0.2569440\n",
      "\tspeed: 0.0621s/iter; left time: 1788.9370s\n",
      "1398it [01:28, 16.08it/s]\titers: 1400, epoch: 13 | loss: 0.2835281\n",
      "\tspeed: 0.0653s/iter; left time: 1875.7184s\n",
      "1498it [01:34, 19.56it/s]\titers: 1500, epoch: 13 | loss: 0.1431955\n",
      "\tspeed: 0.0559s/iter; left time: 1598.9745s\n",
      "1599it [01:39, 19.63it/s]\titers: 1600, epoch: 13 | loss: 0.1538688\n",
      "\tspeed: 0.0510s/iter; left time: 1453.2541s\n",
      "1698it [01:44, 19.38it/s]\titers: 1700, epoch: 13 | loss: 0.3327123\n",
      "\tspeed: 0.0532s/iter; left time: 1512.3464s\n",
      "1798it [01:49, 20.12it/s]\titers: 1800, epoch: 13 | loss: 0.2021110\n",
      "\tspeed: 0.0524s/iter; left time: 1484.4561s\n",
      "1899it [01:55, 16.25it/s]\titers: 1900, epoch: 13 | loss: 0.4123766\n",
      "\tspeed: 0.0589s/iter; left time: 1660.9804s\n",
      "1999it [02:02, 16.01it/s]\titers: 2000, epoch: 13 | loss: 0.2209519\n",
      "\tspeed: 0.0626s/iter; left time: 1759.4440s\n",
      "2099it [02:08, 16.20it/s]\titers: 2100, epoch: 13 | loss: 0.2995470\n",
      "\tspeed: 0.0682s/iter; left time: 1911.9626s\n",
      "2199it [02:15, 15.61it/s]\titers: 2200, epoch: 13 | loss: 0.1898121\n",
      "\tspeed: 0.0620s/iter; left time: 1729.9893s\n",
      "2299it [02:21, 15.50it/s]\titers: 2300, epoch: 13 | loss: 0.1993044\n",
      "\tspeed: 0.0635s/iter; left time: 1767.4364s\n",
      "2399it [02:28, 14.55it/s]\titers: 2400, epoch: 13 | loss: 0.2087336\n",
      "\tspeed: 0.0732s/iter; left time: 2028.3172s\n",
      "2499it [02:35, 16.07it/s]\titers: 2500, epoch: 13 | loss: 0.2090921\n",
      "\tspeed: 0.0679s/iter; left time: 1874.4330s\n",
      "2599it [02:42, 12.22it/s]\titers: 2600, epoch: 13 | loss: 0.2740145\n",
      "\tspeed: 0.0689s/iter; left time: 1895.8986s\n",
      "2699it [02:49, 14.11it/s]\titers: 2700, epoch: 13 | loss: 0.1732064\n",
      "\tspeed: 0.0722s/iter; left time: 1979.3265s\n",
      "2799it [02:56, 14.55it/s]\titers: 2800, epoch: 13 | loss: 0.1894887\n",
      "\tspeed: 0.0636s/iter; left time: 1737.1593s\n",
      "2899it [03:02, 17.15it/s]\titers: 2900, epoch: 13 | loss: 0.1692419\n",
      "\tspeed: 0.0684s/iter; left time: 1862.0000s\n",
      "2999it [03:09, 14.07it/s]\titers: 3000, epoch: 13 | loss: 0.2913737\n",
      "\tspeed: 0.0654s/iter; left time: 1773.4403s\n",
      "3099it [03:16, 13.51it/s]\titers: 3100, epoch: 13 | loss: 0.2039373\n",
      "\tspeed: 0.0683s/iter; left time: 1845.8429s\n",
      "3199it [03:23, 16.49it/s]\titers: 3200, epoch: 13 | loss: 0.4868638\n",
      "\tspeed: 0.0690s/iter; left time: 1856.8779s\n",
      "3299it [03:29, 16.48it/s]\titers: 3300, epoch: 13 | loss: 0.2281553\n",
      "\tspeed: 0.0622s/iter; left time: 1667.9792s\n",
      "3399it [03:35, 16.03it/s]\titers: 3400, epoch: 13 | loss: 0.2060827\n",
      "\tspeed: 0.0611s/iter; left time: 1631.9816s\n",
      "3499it [03:42, 15.61it/s]\titers: 3500, epoch: 13 | loss: 0.1951438\n",
      "\tspeed: 0.0670s/iter; left time: 1784.5781s\n",
      "3598it [03:47, 20.24it/s]\titers: 3600, epoch: 13 | loss: 0.1788611\n",
      "\tspeed: 0.0561s/iter; left time: 1486.6080s\n",
      "3699it [03:54, 15.17it/s]\titers: 3700, epoch: 13 | loss: 0.2662455\n",
      "\tspeed: 0.0641s/iter; left time: 1693.8779s\n",
      "3765it [03:58, 15.76it/s]\n",
      "Epoch: 13 cost time: 238.86319088935852\n",
      "810it [00:23, 34.80it/s]\n",
      "807it [00:22, 35.30it/s]\n",
      "Epoch: 13 | Train Loss: 0.2408106 Vali Loss: 0.2869270 Test Loss: 0.3545165 MAE Loss: 0.3596092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "99it [00:06, 15.38it/s]\titers: 100, epoch: 14 | loss: 0.2766951\n",
      "\tspeed: 0.5765s/iter; left time: 15136.1426s\n",
      "199it [00:12, 19.89it/s]\titers: 200, epoch: 14 | loss: 0.2088864\n",
      "\tspeed: 0.0601s/iter; left time: 1571.5559s\n",
      "298it [00:17, 19.79it/s]\titers: 300, epoch: 14 | loss: 0.2911074\n",
      "\tspeed: 0.0511s/iter; left time: 1330.1929s\n",
      "398it [00:22, 20.04it/s]\titers: 400, epoch: 14 | loss: 0.1669109\n",
      "\tspeed: 0.0503s/iter; left time: 1304.4077s\n",
      "498it [00:27, 19.60it/s]\titers: 500, epoch: 14 | loss: 0.2670271\n",
      "\tspeed: 0.0510s/iter; left time: 1318.0768s\n",
      "599it [00:35, 15.36it/s]\titers: 600, epoch: 14 | loss: 0.4604237\n",
      "\tspeed: 0.0711s/iter; left time: 1831.8506s\n",
      "699it [00:41, 16.26it/s]\titers: 700, epoch: 14 | loss: 0.3117603\n",
      "\tspeed: 0.0616s/iter; left time: 1580.0993s\n",
      "799it [00:48, 13.75it/s]\titers: 800, epoch: 14 | loss: 0.2060950\n",
      "\tspeed: 0.0669s/iter; left time: 1710.6157s\n",
      "899it [00:54, 15.88it/s]\titers: 900, epoch: 14 | loss: 0.3709309\n",
      "\tspeed: 0.0637s/iter; left time: 1621.2778s\n",
      "999it [00:59, 19.71it/s]\titers: 1000, epoch: 14 | loss: 0.2843518\n",
      "\tspeed: 0.0554s/iter; left time: 1404.5230s\n",
      "1099it [01:05, 16.33it/s]\titers: 1100, epoch: 14 | loss: 0.1702826\n",
      "\tspeed: 0.0518s/iter; left time: 1308.2513s\n",
      "1199it [01:11, 13.67it/s]\titers: 1200, epoch: 14 | loss: 0.2288027\n",
      "\tspeed: 0.0642s/iter; left time: 1615.4597s\n",
      "1299it [01:17, 16.41it/s]\titers: 1300, epoch: 14 | loss: 0.2078893\n",
      "\tspeed: 0.0609s/iter; left time: 1527.1616s\n",
      "1399it [01:23, 15.40it/s]\titers: 1400, epoch: 14 | loss: 0.1316809\n",
      "\tspeed: 0.0626s/iter; left time: 1562.6970s\n",
      "1499it [01:29, 18.29it/s]\titers: 1500, epoch: 14 | loss: 0.3166687\n",
      "\tspeed: 0.0584s/iter; left time: 1452.0059s\n",
      "1599it [01:34, 17.02it/s]\titers: 1600, epoch: 14 | loss: 0.1217285\n",
      "\tspeed: 0.0506s/iter; left time: 1252.8158s\n",
      "1699it [01:41, 15.75it/s]\titers: 1700, epoch: 14 | loss: 0.1879709\n",
      "\tspeed: 0.0631s/iter; left time: 1555.9349s\n",
      "1799it [01:47, 14.33it/s]\titers: 1800, epoch: 14 | loss: 0.2517678\n",
      "\tspeed: 0.0669s/iter; left time: 1643.2588s\n",
      "1899it [01:54, 15.62it/s]\titers: 1900, epoch: 14 | loss: 0.1492695\n",
      "\tspeed: 0.0623s/iter; left time: 1523.2686s\n",
      "1999it [02:00, 18.25it/s]\titers: 2000, epoch: 14 | loss: 0.1484565\n",
      "\tspeed: 0.0619s/iter; left time: 1506.7768s\n",
      "2099it [02:06, 18.92it/s]\titers: 2100, epoch: 14 | loss: 0.2174385\n",
      "\tspeed: 0.0600s/iter; left time: 1456.3091s\n",
      "2198it [02:11, 16.15it/s]\titers: 2200, epoch: 14 | loss: 0.2208518\n",
      "\tspeed: 0.0526s/iter; left time: 1271.4137s\n",
      "2298it [02:17, 19.80it/s]\titers: 2300, epoch: 14 | loss: 0.1313207\n",
      "\tspeed: 0.0584s/iter; left time: 1403.8238s\n",
      "2399it [02:22, 20.10it/s]\titers: 2400, epoch: 14 | loss: 0.1164559\n",
      "\tspeed: 0.0523s/iter; left time: 1253.0773s\n",
      "2497it [02:27, 20.38it/s]\titers: 2500, epoch: 14 | loss: 0.2819122\n",
      "\tspeed: 0.0504s/iter; left time: 1203.3475s\n",
      "2599it [02:32, 20.36it/s]\titers: 2600, epoch: 14 | loss: 0.2359000\n",
      "\tspeed: 0.0494s/iter; left time: 1172.4804s\n",
      "2698it [02:37, 15.49it/s]\titers: 2700, epoch: 14 | loss: 0.1793555\n",
      "\tspeed: 0.0521s/iter; left time: 1231.9161s\n",
      "2798it [02:44, 16.57it/s]\titers: 2800, epoch: 14 | loss: 0.5488445\n",
      "\tspeed: 0.0661s/iter; left time: 1555.9646s\n",
      "2898it [02:50, 15.57it/s]\titers: 2900, epoch: 14 | loss: 0.2586073\n",
      "\tspeed: 0.0634s/iter; left time: 1486.2684s\n",
      "2998it [02:57, 12.77it/s]\titers: 3000, epoch: 14 | loss: 0.3459770\n",
      "\tspeed: 0.0665s/iter; left time: 1554.0302s\n",
      "3098it [03:03, 15.87it/s]\titers: 3100, epoch: 14 | loss: 0.1972141\n",
      "\tspeed: 0.0633s/iter; left time: 1472.6145s\n",
      "3198it [03:09, 15.67it/s]\titers: 3200, epoch: 14 | loss: 0.2222412\n",
      "\tspeed: 0.0636s/iter; left time: 1472.4765s\n",
      "3298it [03:16, 14.12it/s]\titers: 3300, epoch: 14 | loss: 0.2366683\n",
      "\tspeed: 0.0654s/iter; left time: 1507.7605s\n",
      "3398it [03:22, 16.49it/s]\titers: 3400, epoch: 14 | loss: 0.5761340\n",
      "\tspeed: 0.0627s/iter; left time: 1438.7323s\n",
      "3498it [03:28, 16.48it/s]\titers: 3500, epoch: 14 | loss: 0.2705685\n",
      "\tspeed: 0.0608s/iter; left time: 1389.4950s\n",
      "3598it [03:35, 16.07it/s]\titers: 3600, epoch: 14 | loss: 0.3616163\n",
      "\tspeed: 0.0631s/iter; left time: 1434.9999s\n",
      "3698it [03:41, 16.28it/s]\titers: 3700, epoch: 14 | loss: 0.1656536\n",
      "\tspeed: 0.0630s/iter; left time: 1426.4998s\n",
      "3765it [03:45, 16.67it/s]\n",
      "Epoch: 14 cost time: 225.79718136787415\n",
      "810it [00:23, 34.61it/s]\n",
      "807it [00:23, 34.86it/s]\n",
      "Epoch: 14 | Train Loss: 0.2405387 Vali Loss: 0.2868419 Test Loss: 0.3544639 MAE Loss: 0.3595170\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "99it [00:06, 15.75it/s]\titers: 100, epoch: 15 | loss: 0.1462605\n",
      "\tspeed: 0.5774s/iter; left time: 12986.6269s\n",
      "199it [00:13, 15.68it/s]\titers: 200, epoch: 15 | loss: 0.5276050\n",
      "\tspeed: 0.0637s/iter; left time: 1426.3613s\n",
      "299it [00:19, 19.72it/s]\titers: 300, epoch: 15 | loss: 0.1919925\n",
      "\tspeed: 0.0623s/iter; left time: 1388.9755s\n",
      "398it [00:24, 16.40it/s]\titers: 400, epoch: 15 | loss: 0.1474142\n",
      "\tspeed: 0.0572s/iter; left time: 1268.9503s\n",
      "498it [00:31, 16.12it/s]\titers: 500, epoch: 15 | loss: 0.2179147\n",
      "\tspeed: 0.0609s/iter; left time: 1345.3732s\n",
      "598it [00:37, 16.41it/s]\titers: 600, epoch: 15 | loss: 0.1850785\n",
      "\tspeed: 0.0638s/iter; left time: 1402.7690s\n",
      "698it [00:43, 15.54it/s]\titers: 700, epoch: 15 | loss: 0.1606525\n",
      "\tspeed: 0.0628s/iter; left time: 1373.6975s\n",
      "798it [00:50, 15.67it/s]\titers: 800, epoch: 15 | loss: 0.3099542\n",
      "\tspeed: 0.0636s/iter; left time: 1385.2253s\n",
      "898it [00:56, 16.30it/s]\titers: 900, epoch: 15 | loss: 0.1873751\n",
      "\tspeed: 0.0644s/iter; left time: 1396.4146s\n",
      "998it [01:02, 15.70it/s]\titers: 1000, epoch: 15 | loss: 0.2166293\n",
      "\tspeed: 0.0639s/iter; left time: 1379.0261s\n",
      "1098it [01:09, 15.66it/s]\titers: 1100, epoch: 15 | loss: 0.3537371\n",
      "\tspeed: 0.0640s/iter; left time: 1374.7457s\n",
      "1198it [01:16, 14.52it/s]\titers: 1200, epoch: 15 | loss: 0.4045269\n",
      "\tspeed: 0.0674s/iter; left time: 1440.9448s\n",
      "1298it [01:21, 20.12it/s]\titers: 1300, epoch: 15 | loss: 0.2008556\n",
      "\tspeed: 0.0582s/iter; left time: 1239.4644s\n",
      "1398it [01:27, 15.77it/s]\titers: 1400, epoch: 15 | loss: 0.1684144\n",
      "\tspeed: 0.0599s/iter; left time: 1268.4408s\n",
      "1498it [01:34, 16.48it/s]\titers: 1500, epoch: 15 | loss: 0.1317047\n",
      "\tspeed: 0.0680s/iter; left time: 1433.4027s\n",
      "1598it [01:40, 15.32it/s]\titers: 1600, epoch: 15 | loss: 0.1608481\n",
      "\tspeed: 0.0623s/iter; left time: 1307.4586s\n",
      "1698it [01:47, 15.55it/s]\titers: 1700, epoch: 15 | loss: 0.1544187\n",
      "\tspeed: 0.0647s/iter; left time: 1351.1819s\n",
      "1798it [01:53, 16.51it/s]\titers: 1800, epoch: 15 | loss: 0.2390110\n",
      "\tspeed: 0.0660s/iter; left time: 1372.2738s\n",
      "1898it [02:00, 15.30it/s]\titers: 1900, epoch: 15 | loss: 0.2357488\n",
      "\tspeed: 0.0645s/iter; left time: 1333.9436s\n",
      "1998it [02:06, 15.12it/s]\titers: 2000, epoch: 15 | loss: 0.1244796\n",
      "\tspeed: 0.0625s/iter; left time: 1286.2211s\n",
      "2098it [02:12, 19.48it/s]\titers: 2100, epoch: 15 | loss: 0.5285318\n",
      "\tspeed: 0.0604s/iter; left time: 1237.6179s\n",
      "2199it [02:17, 19.67it/s]\titers: 2200, epoch: 15 | loss: 0.2301651\n",
      "\tspeed: 0.0523s/iter; left time: 1067.0166s\n",
      "2298it [02:23, 19.85it/s]\titers: 2300, epoch: 15 | loss: 0.2886354\n",
      "\tspeed: 0.0508s/iter; left time: 1030.3732s\n",
      "2399it [02:28, 16.71it/s]\titers: 2400, epoch: 15 | loss: 0.3394863\n",
      "\tspeed: 0.0573s/iter; left time: 1156.9102s\n",
      "2499it [02:35, 16.10it/s]\titers: 2500, epoch: 15 | loss: 0.1666542\n",
      "\tspeed: 0.0704s/iter; left time: 1414.0004s\n",
      "2599it [02:42, 15.88it/s]\titers: 2600, epoch: 15 | loss: 0.2026832\n",
      "\tspeed: 0.0633s/iter; left time: 1265.8226s\n",
      "2699it [02:48, 14.21it/s]\titers: 2700, epoch: 15 | loss: 0.2042899\n",
      "\tspeed: 0.0647s/iter; left time: 1287.3573s\n",
      "2799it [02:55, 15.71it/s]\titers: 2800, epoch: 15 | loss: 0.1342990\n",
      "\tspeed: 0.0682s/iter; left time: 1350.3095s\n",
      "2899it [03:02, 15.49it/s]\titers: 2900, epoch: 15 | loss: 0.2600103\n",
      "\tspeed: 0.0669s/iter; left time: 1317.2145s\n",
      "2999it [03:08, 16.00it/s]\titers: 3000, epoch: 15 | loss: 0.1590758\n",
      "\tspeed: 0.0627s/iter; left time: 1227.6285s\n",
      "3099it [03:14, 16.46it/s]\titers: 3100, epoch: 15 | loss: 0.1108824\n",
      "\tspeed: 0.0651s/iter; left time: 1268.2421s\n",
      "3199it [03:21, 16.07it/s]\titers: 3200, epoch: 15 | loss: 0.5454468\n",
      "\tspeed: 0.0609s/iter; left time: 1181.7447s\n",
      "3299it [03:27, 14.78it/s]\titers: 3300, epoch: 15 | loss: 0.2585146\n",
      "\tspeed: 0.0653s/iter; left time: 1260.1964s\n",
      "3399it [03:34, 15.98it/s]\titers: 3400, epoch: 15 | loss: 0.1515789\n",
      "\tspeed: 0.0672s/iter; left time: 1289.4534s\n",
      "3499it [03:40, 15.76it/s]\titers: 3500, epoch: 15 | loss: 0.2614948\n",
      "\tspeed: 0.0628s/iter; left time: 1198.9763s\n",
      "3599it [03:46, 15.54it/s]\titers: 3600, epoch: 15 | loss: 0.1294327\n",
      "\tspeed: 0.0637s/iter; left time: 1209.2498s\n",
      "3699it [03:53, 15.55it/s]\titers: 3700, epoch: 15 | loss: 0.2644349\n",
      "\tspeed: 0.0663s/iter; left time: 1253.1052s\n",
      "3765it [03:57, 15.83it/s]\n",
      "Epoch: 15 cost time: 237.804429769516\n",
      "810it [00:22, 35.45it/s]\n",
      "807it [00:22, 35.15it/s]\n",
      "Epoch: 15 | Train Loss: 0.2401748 Vali Loss: 0.2868109 Test Loss: 0.3544210 MAE Loss: 0.3594698\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.4414062499999998e-09\n",
      "99it [00:07, 14.13it/s]\titers: 100, epoch: 16 | loss: 0.1313339\n",
      "\tspeed: 0.5758s/iter; left time: 10782.0462s\n",
      "199it [00:14, 15.09it/s]\titers: 200, epoch: 16 | loss: 0.3213878\n",
      "\tspeed: 0.0737s/iter; left time: 1373.3754s\n",
      "299it [00:21, 15.32it/s]\titers: 300, epoch: 16 | loss: 0.1721865\n",
      "\tspeed: 0.0642s/iter; left time: 1189.5845s\n",
      "399it [00:27, 15.39it/s]\titers: 400, epoch: 16 | loss: 0.1876957\n",
      "\tspeed: 0.0657s/iter; left time: 1210.9384s\n",
      "499it [00:34, 16.09it/s]\titers: 500, epoch: 16 | loss: 0.1850105\n",
      "\tspeed: 0.0701s/iter; left time: 1284.4668s\n",
      "599it [00:41, 15.57it/s]\titers: 600, epoch: 16 | loss: 0.3622075\n",
      "\tspeed: 0.0647s/iter; left time: 1179.1533s\n",
      "699it [00:47, 10.32it/s]\titers: 700, epoch: 16 | loss: 0.2453377\n",
      "\tspeed: 0.0668s/iter; left time: 1211.5515s\n",
      "799it [00:54, 16.01it/s]\titers: 800, epoch: 16 | loss: 0.2593257\n",
      "\tspeed: 0.0680s/iter; left time: 1225.1445s\n",
      "899it [01:01, 15.45it/s]\titers: 900, epoch: 16 | loss: 0.2161812\n",
      "\tspeed: 0.0640s/iter; left time: 1146.7692s\n",
      "999it [01:07, 12.11it/s]\titers: 1000, epoch: 16 | loss: 0.2872171\n",
      "\tspeed: 0.0676s/iter; left time: 1205.1291s\n",
      "1099it [01:14, 16.11it/s]\titers: 1100, epoch: 16 | loss: 0.4407399\n",
      "\tspeed: 0.0620s/iter; left time: 1098.5607s\n",
      "1199it [01:20, 14.62it/s]\titers: 1200, epoch: 16 | loss: 0.5879644\n",
      "\tspeed: 0.0652s/iter; left time: 1148.8315s\n",
      "1299it [01:27, 13.95it/s]\titers: 1300, epoch: 16 | loss: 0.1737542\n",
      "\tspeed: 0.0720s/iter; left time: 1262.5919s\n",
      "1399it [01:34, 15.41it/s]\titers: 1400, epoch: 16 | loss: 0.2089980\n",
      "\tspeed: 0.0663s/iter; left time: 1155.6179s\n",
      "1499it [01:40, 15.34it/s]\titers: 1500, epoch: 16 | loss: 0.3415230\n",
      "\tspeed: 0.0623s/iter; left time: 1079.0407s\n",
      "1599it [01:47, 14.99it/s]\titers: 1600, epoch: 16 | loss: 0.3892488\n",
      "\tspeed: 0.0668s/iter; left time: 1150.0274s\n",
      "1699it [01:54, 14.51it/s]\titers: 1700, epoch: 16 | loss: 0.1921915\n",
      "\tspeed: 0.0716s/iter; left time: 1226.7704s\n",
      "1799it [02:00, 14.12it/s]\titers: 1800, epoch: 16 | loss: 0.2437634\n",
      "\tspeed: 0.0645s/iter; left time: 1098.3814s\n",
      "1898it [02:08, 13.78it/s]\titers: 1900, epoch: 16 | loss: 0.3115801\n",
      "\tspeed: 0.0755s/iter; left time: 1278.7168s\n",
      "1998it [02:15, 15.83it/s]\titers: 2000, epoch: 16 | loss: 0.2143061\n",
      "\tspeed: 0.0677s/iter; left time: 1139.5607s\n",
      "2098it [02:21, 14.98it/s]\titers: 2100, epoch: 16 | loss: 0.1305671\n",
      "\tspeed: 0.0671s/iter; left time: 1122.4326s\n",
      "2198it [02:28, 16.11it/s]\titers: 2200, epoch: 16 | loss: 0.2081653\n",
      "\tspeed: 0.0672s/iter; left time: 1116.5650s\n",
      "2298it [02:34, 17.39it/s]\titers: 2300, epoch: 16 | loss: 0.1036527\n",
      "\tspeed: 0.0627s/iter; left time: 1035.5890s\n",
      "2398it [02:41, 15.56it/s]\titers: 2400, epoch: 16 | loss: 0.2199027\n",
      "\tspeed: 0.0630s/iter; left time: 1035.4282s\n",
      "2498it [02:47, 14.32it/s]\titers: 2500, epoch: 16 | loss: 0.3010949\n",
      "\tspeed: 0.0658s/iter; left time: 1074.1468s\n",
      "2598it [02:54, 15.56it/s]\titers: 2600, epoch: 16 | loss: 0.1576370\n",
      "\tspeed: 0.0632s/iter; left time: 1024.6723s\n",
      "2698it [03:00, 17.16it/s]\titers: 2700, epoch: 16 | loss: 0.5059547\n",
      "\tspeed: 0.0614s/iter; left time: 990.4463s\n",
      "2798it [03:06, 16.48it/s]\titers: 2800, epoch: 16 | loss: 0.1300958\n",
      "\tspeed: 0.0652s/iter; left time: 1044.7375s\n",
      "2898it [03:12, 16.16it/s]\titers: 2900, epoch: 16 | loss: 0.2122274\n",
      "\tspeed: 0.0614s/iter; left time: 977.3613s\n",
      "2998it [03:19, 15.60it/s]\titers: 3000, epoch: 16 | loss: 0.2932600\n",
      "\tspeed: 0.0643s/iter; left time: 1017.0681s\n",
      "3098it [03:26, 15.86it/s]\titers: 3100, epoch: 16 | loss: 0.2845843\n",
      "\tspeed: 0.0682s/iter; left time: 1071.8985s\n",
      "3198it [03:32, 15.49it/s]\titers: 3200, epoch: 16 | loss: 0.3261687\n",
      "\tspeed: 0.0637s/iter; left time: 994.6048s\n",
      "3298it [03:39, 15.10it/s]\titers: 3300, epoch: 16 | loss: 0.2563445\n",
      "\tspeed: 0.0650s/iter; left time: 1009.3910s\n",
      "3398it [03:45, 16.09it/s]\titers: 3400, epoch: 16 | loss: 0.2358372\n",
      "\tspeed: 0.0659s/iter; left time: 1016.0734s\n",
      "3498it [03:51, 15.74it/s]\titers: 3500, epoch: 16 | loss: 0.3046217\n",
      "\tspeed: 0.0632s/iter; left time: 968.2229s\n",
      "3598it [03:58, 15.36it/s]\titers: 3600, epoch: 16 | loss: 0.2316809\n",
      "\tspeed: 0.0652s/iter; left time: 993.3186s\n",
      "3699it [04:04, 19.89it/s]\titers: 3700, epoch: 16 | loss: 0.1820514\n",
      "\tspeed: 0.0613s/iter; left time: 927.2645s\n",
      "3765it [04:08, 15.17it/s]\n",
      "Epoch: 16 cost time: 248.12830567359924\n",
      "810it [00:22, 35.67it/s]\n",
      "807it [00:23, 34.70it/s]\n",
      "Epoch: 16 | Train Loss: 0.2403181 Vali Loss: 0.2868069 Test Loss: 0.3544185 MAE Loss: 0.3594624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2207031249999999e-09\n",
      "99it [00:06, 13.65it/s]\titers: 100, epoch: 17 | loss: 0.1790431\n",
      "\tspeed: 0.5634s/iter; left time: 8428.9578s\n",
      "199it [00:13, 15.31it/s]\titers: 200, epoch: 17 | loss: 0.1973538\n",
      "\tspeed: 0.0635s/iter; left time: 943.7103s\n",
      "299it [00:19, 15.38it/s]\titers: 300, epoch: 17 | loss: 0.4148529\n",
      "\tspeed: 0.0658s/iter; left time: 971.7853s\n",
      "399it [00:25, 14.94it/s]\titers: 400, epoch: 17 | loss: 0.1595646\n",
      "\tspeed: 0.0633s/iter; left time: 927.7740s\n",
      "499it [00:32, 15.80it/s]\titers: 500, epoch: 17 | loss: 0.1112918\n",
      "\tspeed: 0.0677s/iter; left time: 986.2298s\n",
      "599it [00:38, 17.73it/s]\titers: 600, epoch: 17 | loss: 0.2874404\n",
      "\tspeed: 0.0569s/iter; left time: 823.4884s\n",
      "699it [00:44, 15.62it/s]\titers: 700, epoch: 17 | loss: 0.2976929\n",
      "\tspeed: 0.0638s/iter; left time: 916.5789s\n",
      "799it [00:51, 15.31it/s]\titers: 800, epoch: 17 | loss: 0.1485269\n",
      "\tspeed: 0.0666s/iter; left time: 949.6336s\n",
      "899it [00:57, 15.27it/s]\titers: 900, epoch: 17 | loss: 0.3525675\n",
      "\tspeed: 0.0647s/iter; left time: 916.6081s\n",
      "999it [01:04, 15.19it/s]\titers: 1000, epoch: 17 | loss: 0.4449722\n",
      "\tspeed: 0.0652s/iter; left time: 917.4601s\n",
      "1099it [01:11, 13.45it/s]\titers: 1100, epoch: 17 | loss: 0.2085751\n",
      "\tspeed: 0.0704s/iter; left time: 982.3371s\n",
      "1199it [01:17, 15.52it/s]\titers: 1200, epoch: 17 | loss: 0.2100131\n",
      "\tspeed: 0.0641s/iter; left time: 887.9361s\n",
      "1299it [01:24, 15.22it/s]\titers: 1300, epoch: 17 | loss: 0.1045809\n",
      "\tspeed: 0.0632s/iter; left time: 869.7244s\n",
      "1399it [01:30, 16.44it/s]\titers: 1400, epoch: 17 | loss: 0.2002374\n",
      "\tspeed: 0.0677s/iter; left time: 924.5435s\n",
      "1499it [01:37, 15.82it/s]\titers: 1500, epoch: 17 | loss: 0.2632557\n",
      "\tspeed: 0.0619s/iter; left time: 839.9856s\n",
      "1599it [01:43, 15.40it/s]\titers: 1600, epoch: 17 | loss: 0.3127479\n",
      "\tspeed: 0.0640s/iter; left time: 861.1251s\n",
      "1699it [01:50, 16.49it/s]\titers: 1700, epoch: 17 | loss: 0.1668860\n",
      "\tspeed: 0.0685s/iter; left time: 914.6919s\n",
      "1799it [01:56, 16.18it/s]\titers: 1800, epoch: 17 | loss: 0.6033255\n",
      "\tspeed: 0.0623s/iter; left time: 825.8519s\n",
      "1899it [02:03, 15.53it/s]\titers: 1900, epoch: 17 | loss: 0.1473853\n",
      "\tspeed: 0.0671s/iter; left time: 883.4749s\n",
      "1999it [02:10, 15.77it/s]\titers: 2000, epoch: 17 | loss: 0.1158464\n",
      "\tspeed: 0.0674s/iter; left time: 880.5383s\n",
      "2099it [02:16, 15.23it/s]\titers: 2100, epoch: 17 | loss: 0.2927096\n",
      "\tspeed: 0.0655s/iter; left time: 848.3202s\n",
      "2199it [02:23, 15.18it/s]\titers: 2200, epoch: 17 | loss: 0.3607923\n",
      "\tspeed: 0.0644s/iter; left time: 827.8231s\n",
      "2299it [02:29, 16.09it/s]\titers: 2300, epoch: 17 | loss: 0.1311593\n",
      "\tspeed: 0.0685s/iter; left time: 873.9121s\n",
      "2399it [02:36, 15.62it/s]\titers: 2400, epoch: 17 | loss: 0.1660731\n",
      "\tspeed: 0.0631s/iter; left time: 799.2774s\n",
      "2499it [02:43, 14.23it/s]\titers: 2500, epoch: 17 | loss: 0.3768957\n",
      "\tspeed: 0.0678s/iter; left time: 851.3255s\n",
      "2599it [02:49, 15.86it/s]\titers: 2600, epoch: 17 | loss: 0.2001093\n",
      "\tspeed: 0.0697s/iter; left time: 868.3254s\n",
      "2699it [02:56, 15.52it/s]\titers: 2700, epoch: 17 | loss: 0.2122296\n",
      "\tspeed: 0.0637s/iter; left time: 787.4555s\n",
      "2799it [03:02, 15.31it/s]\titers: 2800, epoch: 17 | loss: 0.3149003\n",
      "\tspeed: 0.0645s/iter; left time: 790.2580s\n",
      "2899it [03:09, 11.93it/s]\titers: 2900, epoch: 17 | loss: 0.2745255\n",
      "\tspeed: 0.0680s/iter; left time: 827.3266s\n",
      "2999it [03:16, 16.07it/s]\titers: 3000, epoch: 17 | loss: 0.2805024\n",
      "\tspeed: 0.0643s/iter; left time: 775.4582s\n",
      "3099it [03:22, 15.32it/s]\titers: 3100, epoch: 17 | loss: 0.2975344\n",
      "\tspeed: 0.0667s/iter; left time: 797.7861s\n",
      "3199it [03:29, 14.65it/s]\titers: 3200, epoch: 17 | loss: 0.6362581\n",
      "\tspeed: 0.0683s/iter; left time: 809.9340s\n",
      "3299it [03:35, 16.31it/s]\titers: 3300, epoch: 17 | loss: 0.1771577\n",
      "\tspeed: 0.0630s/iter; left time: 740.9614s\n",
      "3399it [03:42, 14.84it/s]\titers: 3400, epoch: 17 | loss: 0.2837758\n",
      "\tspeed: 0.0630s/iter; left time: 734.6957s\n",
      "3499it [03:48, 16.48it/s]\titers: 3500, epoch: 17 | loss: 0.2836261\n",
      "\tspeed: 0.0648s/iter; left time: 749.6250s\n",
      "3599it [03:55, 15.89it/s]\titers: 3600, epoch: 17 | loss: 0.2247824\n",
      "\tspeed: 0.0654s/iter; left time: 749.8967s\n",
      "3699it [04:01, 15.76it/s]\titers: 3700, epoch: 17 | loss: 0.1264317\n",
      "\tspeed: 0.0614s/iter; left time: 697.6756s\n",
      "3765it [04:05, 15.32it/s]\n",
      "Epoch: 17 cost time: 245.74307823181152\n",
      "810it [00:23, 34.59it/s]\n",
      "807it [00:23, 34.92it/s]\n",
      "Epoch: 17 | Train Loss: 0.2405716 Vali Loss: 0.2868028 Test Loss: 0.3544032 MAE Loss: 0.3594499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.103515624999999e-10\n",
      "99it [00:06, 16.05it/s]\titers: 100, epoch: 18 | loss: 0.1149401\n",
      "\tspeed: 0.5788s/iter; left time: 6480.0069s\n",
      "199it [00:13, 15.56it/s]\titers: 200, epoch: 18 | loss: 0.1628300\n",
      "\tspeed: 0.0632s/iter; left time: 701.7674s\n",
      "299it [00:19, 15.59it/s]\titers: 300, epoch: 18 | loss: 0.2268005\n",
      "\tspeed: 0.0653s/iter; left time: 718.4291s\n",
      "399it [00:25, 15.89it/s]\titers: 400, epoch: 18 | loss: 0.2319918\n",
      "\tspeed: 0.0630s/iter; left time: 686.5188s\n",
      "499it [00:32, 15.48it/s]\titers: 500, epoch: 18 | loss: 0.1197591\n",
      "\tspeed: 0.0638s/iter; left time: 688.7452s\n",
      "599it [00:39, 16.17it/s]\titers: 600, epoch: 18 | loss: 0.2221109\n",
      "\tspeed: 0.0683s/iter; left time: 731.0703s\n",
      "699it [00:45, 16.05it/s]\titers: 700, epoch: 18 | loss: 0.2205137\n",
      "\tspeed: 0.0619s/iter; left time: 655.8369s\n",
      "799it [00:51, 16.85it/s]\titers: 800, epoch: 18 | loss: 0.1459414\n",
      "\tspeed: 0.0629s/iter; left time: 660.5701s\n",
      "899it [00:57, 16.67it/s]\titers: 900, epoch: 18 | loss: 0.2054292\n",
      "\tspeed: 0.0630s/iter; left time: 655.3911s\n",
      "999it [01:04, 17.18it/s]\titers: 1000, epoch: 18 | loss: 0.2089355\n",
      "\tspeed: 0.0607s/iter; left time: 624.9189s\n",
      "1099it [01:10, 12.72it/s]\titers: 1100, epoch: 18 | loss: 0.1713609\n",
      "\tspeed: 0.0678s/iter; left time: 691.4805s\n",
      "1199it [01:17, 15.98it/s]\titers: 1200, epoch: 18 | loss: 0.4682534\n",
      "\tspeed: 0.0631s/iter; left time: 636.8155s\n",
      "1299it [01:23, 16.66it/s]\titers: 1300, epoch: 18 | loss: 0.2941119\n",
      "\tspeed: 0.0625s/iter; left time: 624.9661s\n",
      "1399it [01:29, 16.12it/s]\titers: 1400, epoch: 18 | loss: 0.1942298\n",
      "\tspeed: 0.0642s/iter; left time: 635.3361s\n",
      "1499it [01:36, 16.11it/s]\titers: 1500, epoch: 18 | loss: 0.1866525\n",
      "\tspeed: 0.0625s/iter; left time: 612.0513s\n",
      "1599it [01:42, 15.60it/s]\titers: 1600, epoch: 18 | loss: 0.3768480\n",
      "\tspeed: 0.0648s/iter; left time: 628.2806s\n",
      "1699it [01:49, 15.91it/s]\titers: 1700, epoch: 18 | loss: 0.1606815\n",
      "\tspeed: 0.0701s/iter; left time: 673.1404s\n",
      "1799it [01:55, 15.34it/s]\titers: 1800, epoch: 18 | loss: 0.3521737\n",
      "\tspeed: 0.0641s/iter; left time: 608.4239s\n",
      "1899it [02:02, 15.58it/s]\titers: 1900, epoch: 18 | loss: 0.3089982\n",
      "\tspeed: 0.0634s/iter; left time: 595.3571s\n",
      "1999it [02:09, 15.83it/s]\titers: 2000, epoch: 18 | loss: 0.1460445\n",
      "\tspeed: 0.0678s/iter; left time: 630.2742s\n",
      "2099it [02:15, 16.69it/s]\titers: 2100, epoch: 18 | loss: 0.5405850\n",
      "\tspeed: 0.0611s/iter; left time: 562.2953s\n",
      "2199it [02:21, 16.07it/s]\titers: 2200, epoch: 18 | loss: 0.2307949\n",
      "\tspeed: 0.0609s/iter; left time: 553.9159s\n",
      "2299it [02:28, 16.26it/s]\titers: 2300, epoch: 18 | loss: 0.2217308\n",
      "\tspeed: 0.0682s/iter; left time: 613.5980s\n",
      "2399it [02:34, 16.01it/s]\titers: 2400, epoch: 18 | loss: 0.2220411\n",
      "\tspeed: 0.0624s/iter; left time: 554.9882s\n",
      "2499it [02:40, 15.60it/s]\titers: 2500, epoch: 18 | loss: 0.2467567\n",
      "\tspeed: 0.0632s/iter; left time: 555.9493s\n",
      "2599it [02:47, 14.47it/s]\titers: 2600, epoch: 18 | loss: 0.1691185\n",
      "\tspeed: 0.0695s/iter; left time: 604.6580s\n",
      "2699it [02:53, 15.52it/s]\titers: 2700, epoch: 18 | loss: 0.1348142\n",
      "\tspeed: 0.0633s/iter; left time: 544.5244s\n",
      "2799it [03:00, 15.60it/s]\titers: 2800, epoch: 18 | loss: 0.2349158\n",
      "\tspeed: 0.0653s/iter; left time: 554.9023s\n",
      "2899it [03:07, 16.48it/s]\titers: 2900, epoch: 18 | loss: 0.1483360\n",
      "\tspeed: 0.0681s/iter; left time: 571.3621s\n",
      "2999it [03:13, 17.40it/s]\titers: 3000, epoch: 18 | loss: 0.1397166\n",
      "\tspeed: 0.0589s/iter; left time: 488.5158s\n",
      "3099it [03:19, 15.56it/s]\titers: 3100, epoch: 18 | loss: 0.3029978\n",
      "\tspeed: 0.0594s/iter; left time: 487.2321s\n",
      "3199it [03:25, 16.47it/s]\titers: 3200, epoch: 18 | loss: 0.1750781\n",
      "\tspeed: 0.0680s/iter; left time: 550.4932s\n",
      "3299it [03:32, 15.40it/s]\titers: 3300, epoch: 18 | loss: 0.4172933\n",
      "\tspeed: 0.0645s/iter; left time: 515.4113s\n",
      "3399it [03:38, 15.44it/s]\titers: 3400, epoch: 18 | loss: 0.1971476\n",
      "\tspeed: 0.0633s/iter; left time: 499.9471s\n",
      "3499it [03:45, 16.13it/s]\titers: 3500, epoch: 18 | loss: 0.2929800\n",
      "\tspeed: 0.0651s/iter; left time: 507.4652s\n",
      "3599it [03:51, 16.15it/s]\titers: 3600, epoch: 18 | loss: 0.1714748\n",
      "\tspeed: 0.0623s/iter; left time: 479.1743s\n",
      "3699it [03:57, 15.81it/s]\titers: 3700, epoch: 18 | loss: 0.1868517\n",
      "\tspeed: 0.0625s/iter; left time: 475.0227s\n",
      "3765it [04:02, 15.54it/s]\n",
      "Epoch: 18 cost time: 242.26519632339478\n",
      "810it [00:22, 35.51it/s]\n",
      "807it [00:23, 34.72it/s]\n",
      "Epoch: 18 | Train Loss: 0.2406514 Vali Loss: 0.2868585 Test Loss: 0.3544081 MAE Loss: 0.3594481\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.0517578124999997e-10\n",
      "99it [00:05, 19.87it/s]\titers: 100, epoch: 19 | loss: 0.2090819\n",
      "\tspeed: 0.5626s/iter; left time: 4180.6301s\n",
      "199it [00:11, 15.94it/s]\titers: 200, epoch: 19 | loss: 0.2616295\n",
      "\tspeed: 0.0630s/iter; left time: 461.8594s\n",
      "299it [00:18, 16.05it/s]\titers: 300, epoch: 19 | loss: 0.2658483\n",
      "\tspeed: 0.0627s/iter; left time: 453.4350s\n",
      "399it [00:24, 15.32it/s]\titers: 400, epoch: 19 | loss: 0.2658174\n",
      "\tspeed: 0.0641s/iter; left time: 456.7571s\n",
      "499it [00:30, 16.33it/s]\titers: 500, epoch: 19 | loss: 0.2875904\n",
      "\tspeed: 0.0639s/iter; left time: 449.5418s\n",
      "599it [00:37, 16.25it/s]\titers: 600, epoch: 19 | loss: 0.2721080\n",
      "\tspeed: 0.0624s/iter; left time: 432.4793s\n",
      "699it [00:43, 17.22it/s]\titers: 700, epoch: 19 | loss: 0.2358391\n",
      "\tspeed: 0.0599s/iter; left time: 409.2900s\n",
      "799it [00:49, 13.34it/s]\titers: 800, epoch: 19 | loss: 0.1202363\n",
      "\tspeed: 0.0618s/iter; left time: 416.0281s\n",
      "899it [00:55, 16.46it/s]\titers: 900, epoch: 19 | loss: 0.2020888\n",
      "\tspeed: 0.0625s/iter; left time: 414.1282s\n",
      "999it [01:01, 16.87it/s]\titers: 1000, epoch: 19 | loss: 0.2006921\n",
      "\tspeed: 0.0621s/iter; left time: 405.4709s\n",
      "1098it [01:07, 16.16it/s]\titers: 1100, epoch: 19 | loss: 0.3915307\n",
      "\tspeed: 0.0593s/iter; left time: 381.0447s\n",
      "1198it [01:13, 20.05it/s]\titers: 1200, epoch: 19 | loss: 0.3757917\n",
      "\tspeed: 0.0572s/iter; left time: 362.0411s\n",
      "1298it [01:18, 19.71it/s]\titers: 1300, epoch: 19 | loss: 0.1456084\n",
      "\tspeed: 0.0502s/iter; left time: 313.0388s\n",
      "1398it [01:23, 19.64it/s]\titers: 1400, epoch: 19 | loss: 0.1724416\n",
      "\tspeed: 0.0505s/iter; left time: 309.5885s\n",
      "1498it [01:28, 17.59it/s]\titers: 1500, epoch: 19 | loss: 0.1761060\n",
      "\tspeed: 0.0520s/iter; left time: 313.5855s\n",
      "1598it [01:34, 16.21it/s]\titers: 1600, epoch: 19 | loss: 0.2777399\n",
      "\tspeed: 0.0631s/iter; left time: 374.2022s\n",
      "1698it [01:41, 16.14it/s]\titers: 1700, epoch: 19 | loss: 0.2387632\n",
      "\tspeed: 0.0630s/iter; left time: 367.1734s\n",
      "1798it [01:47, 15.66it/s]\titers: 1800, epoch: 19 | loss: 0.2864440\n",
      "\tspeed: 0.0654s/iter; left time: 374.6850s\n",
      "1899it [01:53, 16.35it/s]\titers: 1900, epoch: 19 | loss: 0.1623599\n",
      "\tspeed: 0.0570s/iter; left time: 320.9203s\n",
      "1998it [01:58, 20.29it/s]\titers: 2000, epoch: 19 | loss: 0.3337181\n",
      "\tspeed: 0.0525s/iter; left time: 290.2373s\n",
      "2099it [02:03, 19.70it/s]\titers: 2100, epoch: 19 | loss: 0.6763064\n",
      "\tspeed: 0.0496s/iter; left time: 269.6358s\n",
      "2199it [02:10, 16.16it/s]\titers: 2200, epoch: 19 | loss: 0.1896386\n",
      "\tspeed: 0.0650s/iter; left time: 346.2746s\n",
      "2299it [02:16, 15.90it/s]\titers: 2300, epoch: 19 | loss: 0.4624285\n",
      "\tspeed: 0.0632s/iter; left time: 330.3554s\n",
      "2399it [02:23, 12.07it/s]\titers: 2400, epoch: 19 | loss: 0.2505639\n",
      "\tspeed: 0.0674s/iter; left time: 345.8125s\n",
      "2499it [02:29, 16.16it/s]\titers: 2500, epoch: 19 | loss: 0.2530861\n",
      "\tspeed: 0.0626s/iter; left time: 314.7892s\n",
      "2599it [02:36, 15.22it/s]\titers: 2600, epoch: 19 | loss: 0.1167460\n",
      "\tspeed: 0.0652s/iter; left time: 321.5864s\n",
      "2699it [02:42, 16.38it/s]\titers: 2700, epoch: 19 | loss: 0.1652538\n",
      "\tspeed: 0.0683s/iter; left time: 329.9452s\n",
      "2799it [02:49, 16.20it/s]\titers: 2800, epoch: 19 | loss: 0.3055148\n",
      "\tspeed: 0.0624s/iter; left time: 295.3427s\n",
      "2899it [02:55, 15.73it/s]\titers: 2900, epoch: 19 | loss: 0.2628029\n",
      "\tspeed: 0.0629s/iter; left time: 291.1325s\n",
      "2999it [03:01, 15.76it/s]\titers: 3000, epoch: 19 | loss: 0.3317397\n",
      "\tspeed: 0.0651s/iter; left time: 294.9468s\n",
      "3099it [03:08, 16.35it/s]\titers: 3100, epoch: 19 | loss: 0.1404723\n",
      "\tspeed: 0.0627s/iter; left time: 277.8383s\n",
      "3199it [03:14, 15.82it/s]\titers: 3200, epoch: 19 | loss: 0.1137830\n",
      "\tspeed: 0.0621s/iter; left time: 268.9004s\n",
      "3299it [03:20, 14.26it/s]\titers: 3300, epoch: 19 | loss: 0.1915501\n",
      "\tspeed: 0.0645s/iter; left time: 272.7928s\n",
      "3399it [03:26, 16.21it/s]\titers: 3400, epoch: 19 | loss: 0.2559881\n",
      "\tspeed: 0.0573s/iter; left time: 236.5577s\n",
      "3499it [03:32, 15.56it/s]\titers: 3500, epoch: 19 | loss: 0.1756145\n",
      "\tspeed: 0.0635s/iter; left time: 255.9236s\n",
      "3599it [03:39, 16.43it/s]\titers: 3600, epoch: 19 | loss: 0.1698450\n",
      "\tspeed: 0.0651s/iter; left time: 255.9606s\n",
      "3699it [03:45, 16.10it/s]\titers: 3700, epoch: 19 | loss: 0.2651412\n",
      "\tspeed: 0.0632s/iter; left time: 242.1870s\n",
      "3765it [03:49, 16.37it/s]\n",
      "Epoch: 19 cost time: 229.98932886123657\n",
      "810it [00:23, 34.75it/s]\n",
      "807it [00:23, 34.62it/s]\n",
      "Epoch: 19 | Train Loss: 0.2403287 Vali Loss: 0.2866571 Test Loss: 0.3543888 MAE Loss: 0.3594454\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5258789062499999e-10\n",
      "99it [00:06, 15.48it/s]\titers: 100, epoch: 20 | loss: 0.2254924\n",
      "\tspeed: 0.5777s/iter; left time: 2117.8446s\n",
      "199it [00:13, 14.75it/s]\titers: 200, epoch: 20 | loss: 0.3145793\n",
      "\tspeed: 0.0658s/iter; left time: 234.8082s\n",
      "299it [00:20, 14.12it/s]\titers: 300, epoch: 20 | loss: 0.1694066\n",
      "\tspeed: 0.0696s/iter; left time: 241.3214s\n",
      "399it [00:27, 15.50it/s]\titers: 400, epoch: 20 | loss: 0.4031621\n",
      "\tspeed: 0.0667s/iter; left time: 224.4888s\n",
      "499it [00:33, 16.38it/s]\titers: 500, epoch: 20 | loss: 0.1989420\n",
      "\tspeed: 0.0633s/iter; left time: 206.8768s\n",
      "599it [00:39, 16.00it/s]\titers: 600, epoch: 20 | loss: 0.1349097\n",
      "\tspeed: 0.0658s/iter; left time: 208.2322s\n",
      "699it [00:46, 17.15it/s]\titers: 700, epoch: 20 | loss: 0.2714568\n",
      "\tspeed: 0.0632s/iter; left time: 193.7351s\n",
      "799it [00:51, 17.52it/s]\titers: 800, epoch: 20 | loss: 0.2522634\n",
      "\tspeed: 0.0562s/iter; left time: 166.8249s\n",
      "899it [00:57, 20.17it/s]\titers: 900, epoch: 20 | loss: 0.1381346\n",
      "\tspeed: 0.0602s/iter; left time: 172.6660s\n",
      "997it [01:02, 20.38it/s]\titers: 1000, epoch: 20 | loss: 0.1926743\n",
      "\tspeed: 0.0503s/iter; left time: 139.0471s\n",
      "1099it [01:09, 15.26it/s]\titers: 1100, epoch: 20 | loss: 0.2487187\n",
      "\tspeed: 0.0635s/iter; left time: 169.1609s\n",
      "1199it [01:15, 15.66it/s]\titers: 1200, epoch: 20 | loss: 0.2510842\n",
      "\tspeed: 0.0668s/iter; left time: 171.4627s\n",
      "1299it [01:22, 16.16it/s]\titers: 1300, epoch: 20 | loss: 0.2946405\n",
      "\tspeed: 0.0631s/iter; left time: 155.5705s\n",
      "1399it [01:28, 15.71it/s]\titers: 1400, epoch: 20 | loss: 0.2021894\n",
      "\tspeed: 0.0632s/iter; left time: 149.4617s\n",
      "1498it [01:33, 14.76it/s]\titers: 1500, epoch: 20 | loss: 0.1626229\n",
      "\tspeed: 0.0548s/iter; left time: 124.0858s\n",
      "1598it [01:40, 15.21it/s]\titers: 1600, epoch: 20 | loss: 0.1667224\n",
      "\tspeed: 0.0634s/iter; left time: 137.3377s\n",
      "1698it [01:46, 16.21it/s]\titers: 1700, epoch: 20 | loss: 0.2986733\n",
      "\tspeed: 0.0591s/iter; left time: 122.1851s\n",
      "1798it [01:52, 15.98it/s]\titers: 1800, epoch: 20 | loss: 0.1473860\n",
      "\tspeed: 0.0658s/iter; left time: 129.3856s\n",
      "1898it [01:58, 18.14it/s]\titers: 1900, epoch: 20 | loss: 0.3267851\n",
      "\tspeed: 0.0606s/iter; left time: 112.9957s\n",
      "1998it [02:05, 15.24it/s]\titers: 2000, epoch: 20 | loss: 0.2409165\n",
      "\tspeed: 0.0614s/iter; left time: 108.3525s\n",
      "2098it [02:11, 15.79it/s]\titers: 2100, epoch: 20 | loss: 0.1143558\n",
      "\tspeed: 0.0652s/iter; left time: 108.6543s\n",
      "2198it [02:17, 15.77it/s]\titers: 2200, epoch: 20 | loss: 0.1900837\n",
      "\tspeed: 0.0632s/iter; left time: 99.0324s\n",
      "2298it [02:23, 15.60it/s]\titers: 2300, epoch: 20 | loss: 0.2480171\n",
      "\tspeed: 0.0602s/iter; left time: 88.2750s\n",
      "2398it [02:30, 16.00it/s]\titers: 2400, epoch: 20 | loss: 0.1445971\n",
      "\tspeed: 0.0646s/iter; left time: 88.1914s\n",
      "2498it [02:36, 16.40it/s]\titers: 2500, epoch: 20 | loss: 0.1870067\n",
      "\tspeed: 0.0623s/iter; left time: 78.8780s\n",
      "2598it [02:43, 15.23it/s]\titers: 2600, epoch: 20 | loss: 0.3986656\n",
      "\tspeed: 0.0657s/iter; left time: 76.6020s\n",
      "2698it [02:49, 13.92it/s]\titers: 2700, epoch: 20 | loss: 0.1321919\n",
      "\tspeed: 0.0659s/iter; left time: 70.2678s\n",
      "2798it [02:55, 16.19it/s]\titers: 2800, epoch: 20 | loss: 0.1658623\n",
      "\tspeed: 0.0621s/iter; left time: 60.0198s\n",
      "2898it [03:02, 16.02it/s]\titers: 2900, epoch: 20 | loss: 0.2688126\n",
      "\tspeed: 0.0625s/iter; left time: 54.1385s\n",
      "2998it [03:08, 15.91it/s]\titers: 3000, epoch: 20 | loss: 0.2802991\n",
      "\tspeed: 0.0680s/iter; left time: 52.0939s\n",
      "3098it [03:15, 15.98it/s]\titers: 3100, epoch: 20 | loss: 0.1629362\n",
      "\tspeed: 0.0631s/iter; left time: 42.0151s\n",
      "3198it [03:21, 15.73it/s]\titers: 3200, epoch: 20 | loss: 0.2844540\n",
      "\tspeed: 0.0643s/iter; left time: 36.4033s\n",
      "3298it [03:28, 15.29it/s]\titers: 3300, epoch: 20 | loss: 0.2217215\n",
      "\tspeed: 0.0663s/iter; left time: 30.8727s\n",
      "3398it [03:34, 16.11it/s]\titers: 3400, epoch: 20 | loss: 0.1736506\n",
      "\tspeed: 0.0630s/iter; left time: 23.0407s\n",
      "3498it [03:41, 15.60it/s]\titers: 3500, epoch: 20 | loss: 0.2384140\n",
      "\tspeed: 0.0636s/iter; left time: 16.9199s\n",
      "3598it [03:47, 11.66it/s]\titers: 3600, epoch: 20 | loss: 0.2056171\n",
      "\tspeed: 0.0684s/iter; left time: 11.3563s\n",
      "3698it [03:54, 15.64it/s]\titers: 3700, epoch: 20 | loss: 0.2011973\n",
      "\tspeed: 0.0629s/iter; left time: 4.1513s\n",
      "3765it [03:58, 15.79it/s]\n",
      "Epoch: 20 cost time: 238.41683316230774\n",
      "810it [00:25, 32.12it/s]\n",
      "807it [00:24, 32.92it/s]\n",
      "Epoch: 20 | Train Loss: 0.2400190 Vali Loss: 0.2867778 Test Loss: 0.3544127 MAE Loss: 0.3594607\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.629394531249999e-11\n",
      "Total time: 97.56099663972854 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-03 20:30:22,622] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 20:30:23,465] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 20:30:23,466] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 20:30:23,466] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 20:30:24,380] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 20:30:24,380] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 20:30:25,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 20:30:25,636] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 20:30:25,636] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 20:30:25,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 20:30:25,637] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 20:30:25,638] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 20:30:25,906] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 20:30:25,907] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:25,907] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.74 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,038] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 20:30:26,039] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:26,039] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.9 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,039] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 195.03 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8634786510>\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:12,  9.46it/s]\titers: 100, epoch: 1 | loss: 0.8720683\n",
      "\tspeed: 0.1636s/iter; left time: 12303.4216s\n",
      "199it [00:23,  8.97it/s]\titers: 200, epoch: 1 | loss: 0.5065026\n",
      "\tspeed: 0.1135s/iter; left time: 8524.8961s\n",
      "299it [00:34,  9.26it/s]\titers: 300, epoch: 1 | loss: 0.3391798\n",
      "\tspeed: 0.1091s/iter; left time: 8183.7724s\n",
      "399it [00:45,  9.33it/s]\titers: 400, epoch: 1 | loss: 0.3010673\n",
      "\tspeed: 0.1132s/iter; left time: 8479.5291s\n",
      "499it [00:56,  9.37it/s]\titers: 500, epoch: 1 | loss: 0.4299749\n",
      "\tspeed: 0.1078s/iter; left time: 8065.9695s\n",
      "599it [01:07,  8.89it/s]\titers: 600, epoch: 1 | loss: 0.3507005\n",
      "\tspeed: 0.1134s/iter; left time: 8469.3930s\n",
      "699it [01:18,  9.08it/s]\titers: 700, epoch: 1 | loss: 0.2531307\n",
      "\tspeed: 0.1095s/iter; left time: 8172.4255s\n",
      "799it [01:30,  8.72it/s]\titers: 800, epoch: 1 | loss: 0.2008217\n",
      "\tspeed: 0.1141s/iter; left time: 8502.8012s\n",
      "899it [01:41,  8.21it/s]\titers: 900, epoch: 1 | loss: 0.2658834\n",
      "\tspeed: 0.1124s/iter; left time: 8363.7715s\n",
      "999it [01:52,  8.97it/s]\titers: 1000, epoch: 1 | loss: 0.1754939\n",
      "\tspeed: 0.1115s/iter; left time: 8282.2753s\n",
      "1099it [02:04,  8.21it/s]\titers: 1100, epoch: 1 | loss: 0.1986075\n",
      "\tspeed: 0.1182s/iter; left time: 8772.2648s\n",
      "1199it [02:16,  9.00it/s]\titers: 1200, epoch: 1 | loss: 0.2600406\n",
      "\tspeed: 0.1180s/iter; left time: 8747.3023s\n",
      "1299it [02:27,  8.95it/s]\titers: 1300, epoch: 1 | loss: 0.2458196\n",
      "\tspeed: 0.1152s/iter; left time: 8528.0479s\n",
      "1399it [02:39,  8.41it/s]\titers: 1400, epoch: 1 | loss: 0.3013499\n",
      "\tspeed: 0.1122s/iter; left time: 8288.2482s\n",
      "1499it [02:51,  8.84it/s]\titers: 1500, epoch: 1 | loss: 0.4926764\n",
      "\tspeed: 0.1225s/iter; left time: 9039.4693s\n",
      "1599it [03:02,  8.28it/s]\titers: 1600, epoch: 1 | loss: 0.3098283\n",
      "\tspeed: 0.1134s/iter; left time: 8356.2305s\n",
      "1699it [03:13,  9.03it/s]\titers: 1700, epoch: 1 | loss: 0.2061113\n",
      "\tspeed: 0.1132s/iter; left time: 8330.0179s\n",
      "1799it [03:25,  9.18it/s]\titers: 1800, epoch: 1 | loss: 0.3247851\n",
      "\tspeed: 0.1162s/iter; left time: 8542.2291s\n",
      "1899it [03:36,  9.03it/s]\titers: 1900, epoch: 1 | loss: 0.3004698\n",
      "\tspeed: 0.1084s/iter; left time: 7957.6212s\n",
      "1999it [03:47,  8.83it/s]\titers: 2000, epoch: 1 | loss: 0.1845030\n",
      "\tspeed: 0.1138s/iter; left time: 8343.2680s\n",
      "2099it [03:59,  8.81it/s]\titers: 2100, epoch: 1 | loss: 0.3011261\n",
      "\tspeed: 0.1138s/iter; left time: 8328.5447s\n",
      "2199it [04:10,  9.10it/s]\titers: 2200, epoch: 1 | loss: 0.1491057\n",
      "\tspeed: 0.1111s/iter; left time: 8122.0984s\n",
      "2299it [04:21,  9.24it/s]\titers: 2300, epoch: 1 | loss: 0.2294417\n",
      "\tspeed: 0.1140s/iter; left time: 8323.7917s\n",
      "2399it [04:32,  9.12it/s]\titers: 2400, epoch: 1 | loss: 0.2654189\n",
      "\tspeed: 0.1083s/iter; left time: 7892.9086s\n",
      "2499it [04:43,  9.18it/s]\titers: 2500, epoch: 1 | loss: 0.2196381\n",
      "\tspeed: 0.1144s/iter; left time: 8329.2417s\n",
      "2599it [04:54,  8.94it/s]\titers: 2600, epoch: 1 | loss: 0.1637122\n",
      "\tspeed: 0.1089s/iter; left time: 7920.6450s\n",
      "2699it [05:05,  9.07it/s]\titers: 2700, epoch: 1 | loss: 0.1458107\n",
      "\tspeed: 0.1101s/iter; left time: 7995.7889s\n",
      "2799it [05:17,  8.89it/s]\titers: 2800, epoch: 1 | loss: 0.1363378\n",
      "\tspeed: 0.1120s/iter; left time: 8120.2840s\n",
      "2899it [05:28,  9.11it/s]\titers: 2900, epoch: 1 | loss: 0.2458407\n",
      "\tspeed: 0.1110s/iter; left time: 8038.7909s\n",
      "2999it [05:39,  9.23it/s]\titers: 3000, epoch: 1 | loss: 0.2506288\n",
      "\tspeed: 0.1136s/iter; left time: 8214.3023s\n",
      "3099it [05:50,  9.02it/s]\titers: 3100, epoch: 1 | loss: 0.2206718\n",
      "\tspeed: 0.1091s/iter; left time: 7877.9553s\n",
      "3199it [06:01,  9.42it/s]\titers: 3200, epoch: 1 | loss: 0.4658456\n",
      "\tspeed: 0.1131s/iter; left time: 8153.4297s\n",
      "3299it [06:12,  7.55it/s]\titers: 3300, epoch: 1 | loss: 0.3971891\n",
      "\tspeed: 0.1118s/iter; left time: 8051.2942s\n",
      "3399it [06:23,  9.34it/s]\titers: 3400, epoch: 1 | loss: 0.2191683\n",
      "\tspeed: 0.1087s/iter; left time: 7817.4710s\n",
      "3499it [06:35,  9.14it/s]\titers: 3500, epoch: 1 | loss: 0.2384708\n",
      "\tspeed: 0.1123s/iter; left time: 8062.8384s\n",
      "3599it [06:45,  9.18it/s]\titers: 3600, epoch: 1 | loss: 0.3434020\n",
      "\tspeed: 0.1080s/iter; left time: 7747.1486s\n",
      "3699it [06:57,  9.21it/s]\titers: 3700, epoch: 1 | loss: 0.1852512\n",
      "\tspeed: 0.1128s/iter; left time: 8074.5361s\n",
      "3765it [07:04,  8.87it/s]\n",
      "Epoch: 1 cost time: 424.3217496871948\n",
      "810it [00:42, 18.99it/s]\n",
      "807it [00:42, 18.84it/s]\n",
      "Epoch: 1 | Train Loss: 0.3143477 Vali Loss: 0.3187971 Test Loss: 0.3921895 MAE Loss: 0.3947553\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:11,  7.92it/s]\titers: 100, epoch: 2 | loss: 0.3257698\n",
      "\tspeed: 1.0843s/iter; left time: 77454.8621s\n",
      "199it [00:22,  9.32it/s]\titers: 200, epoch: 2 | loss: 0.5429347\n",
      "\tspeed: 0.1107s/iter; left time: 7895.1104s\n",
      "299it [00:34,  8.85it/s]\titers: 300, epoch: 2 | loss: 0.2926316\n",
      "\tspeed: 0.1130s/iter; left time: 8046.6881s\n",
      "399it [00:45,  9.20it/s]\titers: 400, epoch: 2 | loss: 0.1785531\n",
      "\tspeed: 0.1083s/iter; left time: 7705.4235s\n",
      "499it [00:56,  9.06it/s]\titers: 500, epoch: 2 | loss: 0.1654402\n",
      "\tspeed: 0.1122s/iter; left time: 7967.8893s\n",
      "599it [01:07,  8.92it/s]\titers: 600, epoch: 2 | loss: 0.4490877\n",
      "\tspeed: 0.1097s/iter; left time: 7782.5756s\n",
      "699it [01:18,  9.10it/s]\titers: 700, epoch: 2 | loss: 0.4413053\n",
      "\tspeed: 0.1089s/iter; left time: 7715.0955s\n",
      "799it [01:29,  9.10it/s]\titers: 800, epoch: 2 | loss: 0.2705620\n",
      "\tspeed: 0.1113s/iter; left time: 7870.3453s\n",
      "899it [01:40,  9.34it/s]\titers: 900, epoch: 2 | loss: 0.1858509\n",
      "\tspeed: 0.1088s/iter; left time: 7686.6553s\n",
      "999it [01:51,  9.20it/s]\titers: 1000, epoch: 2 | loss: 0.2500934\n",
      "\tspeed: 0.1122s/iter; left time: 7913.1936s\n",
      "1099it [02:02,  7.76it/s]\titers: 1100, epoch: 2 | loss: 0.2143093\n",
      "\tspeed: 0.1071s/iter; left time: 7540.2643s\n",
      "1199it [02:13,  9.09it/s]\titers: 1200, epoch: 2 | loss: 0.2532977\n",
      "\tspeed: 0.1109s/iter; left time: 7800.8538s\n",
      "1299it [02:24,  9.09it/s]\titers: 1300, epoch: 2 | loss: 0.1322539\n",
      "\tspeed: 0.1106s/iter; left time: 7769.8485s\n",
      "1399it [02:35,  9.59it/s]\titers: 1400, epoch: 2 | loss: 0.2507161\n",
      "\tspeed: 0.1092s/iter; left time: 7659.0549s\n",
      "1499it [02:46,  9.09it/s]\titers: 1500, epoch: 2 | loss: 0.3585689\n",
      "\tspeed: 0.1120s/iter; left time: 7844.4061s\n",
      "1599it [02:57,  9.25it/s]\titers: 1600, epoch: 2 | loss: 0.2483891\n",
      "\tspeed: 0.1067s/iter; left time: 7463.3288s\n",
      "1699it [03:08,  9.49it/s]\titers: 1700, epoch: 2 | loss: 0.1066617\n",
      "\tspeed: 0.1110s/iter; left time: 7754.5798s\n",
      "1799it [03:18,  9.23it/s]\titers: 1800, epoch: 2 | loss: 0.2496381\n",
      "\tspeed: 0.1071s/iter; left time: 7471.7465s\n",
      "1898it [03:30,  9.17it/s]\titers: 1900, epoch: 2 | loss: 0.4604181\n",
      "\tspeed: 0.1138s/iter; left time: 7924.5950s\n",
      "1999it [03:41,  8.26it/s]\titers: 2000, epoch: 2 | loss: 0.1519645\n",
      "\tspeed: 0.1113s/iter; left time: 7739.3280s\n",
      "2099it [03:52,  9.31it/s]\titers: 2100, epoch: 2 | loss: 0.3148130\n",
      "\tspeed: 0.1083s/iter; left time: 7518.1242s\n",
      "2199it [04:03,  9.30it/s]\titers: 2200, epoch: 2 | loss: 0.1887021\n",
      "\tspeed: 0.1111s/iter; left time: 7701.2827s\n",
      "2299it [04:14,  9.37it/s]\titers: 2300, epoch: 2 | loss: 0.3369347\n",
      "\tspeed: 0.1125s/iter; left time: 7786.1778s\n",
      "2399it [04:25,  9.32it/s]\titers: 2400, epoch: 2 | loss: 0.1767766\n",
      "\tspeed: 0.1087s/iter; left time: 7512.7573s\n",
      "2499it [04:36,  8.88it/s]\titers: 2500, epoch: 2 | loss: 0.2903088\n",
      "\tspeed: 0.1111s/iter; left time: 7672.8268s\n",
      "2599it [04:47,  9.62it/s]\titers: 2600, epoch: 2 | loss: 0.3526972\n",
      "\tspeed: 0.1055s/iter; left time: 7274.9783s\n",
      "2699it [04:58,  9.47it/s]\titers: 2700, epoch: 2 | loss: 0.1873801\n",
      "\tspeed: 0.1102s/iter; left time: 7588.7844s\n",
      "2799it [05:08,  9.45it/s]\titers: 2800, epoch: 2 | loss: 0.2074384\n",
      "\tspeed: 0.1056s/iter; left time: 7257.9629s\n",
      "2899it [05:20,  9.36it/s]\titers: 2900, epoch: 2 | loss: 0.2050084\n",
      "\tspeed: 0.1141s/iter; left time: 7829.3259s\n",
      "2999it [05:31,  9.38it/s]\titers: 3000, epoch: 2 | loss: 0.2550214\n",
      "\tspeed: 0.1097s/iter; left time: 7520.7710s\n",
      "3099it [05:41,  9.35it/s]\titers: 3100, epoch: 2 | loss: 0.3198403\n",
      "\tspeed: 0.1066s/iter; left time: 7294.6622s\n",
      "3199it [05:52,  9.66it/s]\titers: 3200, epoch: 2 | loss: 0.2663392\n",
      "\tspeed: 0.1085s/iter; left time: 7416.7765s\n",
      "3299it [06:03,  9.36it/s]\titers: 3300, epoch: 2 | loss: 0.3405620\n",
      "\tspeed: 0.1074s/iter; left time: 7331.7076s\n",
      "3398it [06:14,  9.73it/s]\titers: 3400, epoch: 2 | loss: 0.3583790\n",
      "\tspeed: 0.1110s/iter; left time: 7564.1220s\n",
      "3499it [06:24,  9.44it/s]\titers: 3500, epoch: 2 | loss: 0.2920292\n",
      "\tspeed: 0.1043s/iter; left time: 7098.0126s\n",
      "3599it [06:35,  9.72it/s]\titers: 3600, epoch: 2 | loss: 0.2104270\n",
      "\tspeed: 0.1097s/iter; left time: 7450.4318s\n",
      "3699it [06:46,  7.73it/s]\titers: 3700, epoch: 2 | loss: 0.3792321\n",
      "\tspeed: 0.1083s/iter; left time: 7349.7581s\n",
      "3765it [06:53,  9.10it/s]\n",
      "Epoch: 2 cost time: 413.9427099227905\n",
      "810it [00:39, 20.51it/s]\n",
      "807it [00:39, 20.41it/s]\n",
      "Epoch: 2 | Train Loss: 0.2646172 Vali Loss: 0.3105387 Test Loss: 0.3764460 MAE Loss: 0.3837782\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:11,  9.39it/s]\titers: 100, epoch: 3 | loss: 0.2978648\n",
      "\tspeed: 1.0150s/iter; left time: 68684.4952s\n",
      "198it [00:21,  9.29it/s]\titers: 200, epoch: 3 | loss: 0.2218207\n",
      "\tspeed: 0.1061s/iter; left time: 7167.2868s\n",
      "299it [00:32,  9.08it/s]\titers: 300, epoch: 3 | loss: 0.3516690\n",
      "\tspeed: 0.1105s/iter; left time: 7452.5027s\n",
      "399it [00:43,  7.90it/s]\titers: 400, epoch: 3 | loss: 0.2343934\n",
      "\tspeed: 0.1090s/iter; left time: 7341.7735s\n",
      "499it [00:54,  9.19it/s]\titers: 500, epoch: 3 | loss: 0.2358997\n",
      "\tspeed: 0.1056s/iter; left time: 7107.1061s\n",
      "599it [01:05,  8.76it/s]\titers: 600, epoch: 3 | loss: 0.3204251\n",
      "\tspeed: 0.1109s/iter; left time: 7451.1469s\n",
      "698it [01:15,  9.72it/s]\titers: 700, epoch: 3 | loss: 0.3975033\n",
      "\tspeed: 0.1051s/iter; left time: 7047.9663s\n",
      "799it [01:26,  9.77it/s]\titers: 800, epoch: 3 | loss: 0.3985476\n",
      "\tspeed: 0.1085s/iter; left time: 7264.2833s\n",
      "899it [01:37,  9.46it/s]\titers: 900, epoch: 3 | loss: 0.1841005\n",
      "\tspeed: 0.1056s/iter; left time: 7060.2783s\n",
      "999it [01:48,  9.67it/s]\titers: 1000, epoch: 3 | loss: 0.1552988\n",
      "\tspeed: 0.1081s/iter; left time: 7220.4931s\n",
      "1099it [01:58,  9.47it/s]\titers: 1100, epoch: 3 | loss: 0.4149681\n",
      "\tspeed: 0.1076s/iter; left time: 7171.3652s\n",
      "1199it [02:10,  9.38it/s]\titers: 1200, epoch: 3 | loss: 0.3466677\n",
      "\tspeed: 0.1154s/iter; left time: 7679.4795s\n",
      "1299it [02:21,  9.48it/s]\titers: 1300, epoch: 3 | loss: 0.2948653\n",
      "\tspeed: 0.1073s/iter; left time: 7129.8301s\n",
      "1399it [02:31,  8.94it/s]\titers: 1400, epoch: 3 | loss: 0.2601008\n",
      "\tspeed: 0.1084s/iter; left time: 7194.1815s\n",
      "1499it [02:42,  9.45it/s]\titers: 1500, epoch: 3 | loss: 0.1333135\n",
      "\tspeed: 0.1098s/iter; left time: 7275.1436s\n",
      "1599it [02:53,  9.38it/s]\titers: 1600, epoch: 3 | loss: 0.2863780\n",
      "\tspeed: 0.1098s/iter; left time: 7267.0489s\n",
      "1699it [03:04,  9.66it/s]\titers: 1700, epoch: 3 | loss: 0.2553263\n",
      "\tspeed: 0.1083s/iter; left time: 7156.7137s\n",
      "1798it [03:14,  9.49it/s]\titers: 1800, epoch: 3 | loss: 0.1366695\n",
      "\tspeed: 0.1042s/iter; left time: 6872.1585s\n",
      "1899it [03:25,  9.81it/s]\titers: 1900, epoch: 3 | loss: 0.3149875\n",
      "\tspeed: 0.1079s/iter; left time: 7104.7834s\n",
      "1999it [03:36, 10.20it/s]\titers: 2000, epoch: 3 | loss: 0.3165818\n",
      "\tspeed: 0.1023s/iter; left time: 6725.1720s\n",
      "2098it [03:46,  9.50it/s]\titers: 2100, epoch: 3 | loss: 0.2897106\n",
      "\tspeed: 0.1076s/iter; left time: 7064.9561s\n",
      "2198it [03:57,  9.60it/s]\titers: 2200, epoch: 3 | loss: 0.1993236\n",
      "\tspeed: 0.1045s/iter; left time: 6852.6157s\n",
      "2299it [04:08,  9.51it/s]\titers: 2300, epoch: 3 | loss: 0.1569899\n",
      "\tspeed: 0.1071s/iter; left time: 7013.1114s\n",
      "2399it [04:18,  9.56it/s]\titers: 2400, epoch: 3 | loss: 0.3033898\n",
      "\tspeed: 0.1048s/iter; left time: 6847.9465s\n",
      "2499it [04:29,  9.59it/s]\titers: 2500, epoch: 3 | loss: 0.1715891\n",
      "\tspeed: 0.1058s/iter; left time: 6904.3870s\n",
      "2599it [04:39,  9.52it/s]\titers: 2600, epoch: 3 | loss: 0.3647809\n",
      "\tspeed: 0.1035s/iter; left time: 6743.5573s\n",
      "2699it [04:50,  9.99it/s]\titers: 2700, epoch: 3 | loss: 0.3418826\n",
      "\tspeed: 0.1062s/iter; left time: 6911.5091s\n",
      "2799it [05:00,  7.71it/s]\titers: 2800, epoch: 3 | loss: 0.2294641\n",
      "\tspeed: 0.1065s/iter; left time: 6919.1507s\n",
      "2898it [05:11,  9.77it/s]\titers: 2900, epoch: 3 | loss: 0.2157331\n",
      "\tspeed: 0.1051s/iter; left time: 6817.3043s\n",
      "2999it [05:21,  9.45it/s]\titers: 3000, epoch: 3 | loss: 0.2310529\n",
      "\tspeed: 0.1068s/iter; left time: 6914.6336s\n",
      "3099it [05:32,  9.64it/s]\titers: 3100, epoch: 3 | loss: 0.1768773\n",
      "\tspeed: 0.1037s/iter; left time: 6707.1661s\n",
      "3199it [05:42, 10.08it/s]\titers: 3200, epoch: 3 | loss: 0.3301882\n",
      "\tspeed: 0.1035s/iter; left time: 6682.5204s\n",
      "3298it [05:52, 10.22it/s]\titers: 3300, epoch: 3 | loss: 0.1547895\n",
      "\tspeed: 0.1004s/iter; left time: 6473.2023s\n",
      "3399it [06:03,  9.70it/s]\titers: 3400, epoch: 3 | loss: 0.4457112\n",
      "\tspeed: 0.1095s/iter; left time: 7051.1109s\n",
      "3499it [06:14,  9.57it/s]\titers: 3500, epoch: 3 | loss: 0.1522036\n",
      "\tspeed: 0.1043s/iter; left time: 6705.0328s\n",
      "3599it [06:24,  9.18it/s]\titers: 3600, epoch: 3 | loss: 0.1718226\n",
      "\tspeed: 0.1093s/iter; left time: 7015.4024s\n",
      "3698it [06:35,  9.90it/s]\titers: 3700, epoch: 3 | loss: 0.1879304\n",
      "\tspeed: 0.1087s/iter; left time: 6965.1792s\n",
      "3765it [06:42,  9.35it/s]\n",
      "Epoch: 3 cost time: 402.868435382843\n",
      "810it [00:40, 20.09it/s]\n",
      "807it [00:38, 21.11it/s]\n",
      "Epoch: 3 | Train Loss: 0.2491981 Vali Loss: 0.2902947 Test Loss: 0.3629373 MAE Loss: 0.3664696\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:10, 10.09it/s]\titers: 100, epoch: 4 | loss: 0.2327871\n",
      "\tspeed: 0.9913s/iter; left time: 63349.0618s\n",
      "199it [00:21,  9.11it/s]\titers: 200, epoch: 4 | loss: 0.1827734\n",
      "\tspeed: 0.1115s/iter; left time: 7116.5084s\n",
      "299it [00:32,  9.54it/s]\titers: 300, epoch: 4 | loss: 0.3517460\n",
      "\tspeed: 0.1069s/iter; left time: 6810.1985s\n",
      "399it [00:43,  9.48it/s]\titers: 400, epoch: 4 | loss: 0.4774743\n",
      "\tspeed: 0.1098s/iter; left time: 6983.9928s\n",
      "499it [00:53,  9.62it/s]\titers: 500, epoch: 4 | loss: 0.2738291\n",
      "\tspeed: 0.1036s/iter; left time: 6580.8852s\n",
      "599it [01:04,  9.97it/s]\titers: 600, epoch: 4 | loss: 0.1376224\n",
      "\tspeed: 0.1049s/iter; left time: 6654.4427s\n",
      "699it [01:14,  8.21it/s]\titers: 700, epoch: 4 | loss: 0.1827113\n",
      "\tspeed: 0.1062s/iter; left time: 6720.2033s\n",
      "798it [01:25,  9.98it/s]\titers: 800, epoch: 4 | loss: 0.1716439\n",
      "\tspeed: 0.1072s/iter; left time: 6777.4699s\n",
      "899it [01:35,  8.65it/s]\titers: 900, epoch: 4 | loss: 0.2336449\n",
      "\tspeed: 0.1060s/iter; left time: 6686.3741s\n",
      "999it [01:46,  9.76it/s]\titers: 1000, epoch: 4 | loss: 0.2158545\n",
      "\tspeed: 0.1030s/iter; left time: 6489.3115s\n",
      "1099it [01:56,  9.23it/s]\titers: 1100, epoch: 4 | loss: 0.1309988\n",
      "\tspeed: 0.1064s/iter; left time: 6692.3619s\n",
      "1199it [02:07,  9.50it/s]\titers: 1200, epoch: 4 | loss: 0.1824656\n",
      "\tspeed: 0.1053s/iter; left time: 6616.2456s\n",
      "1299it [02:18,  9.54it/s]\titers: 1300, epoch: 4 | loss: 0.1274952\n",
      "\tspeed: 0.1070s/iter; left time: 6708.3829s\n",
      "1398it [02:28,  9.60it/s]\titers: 1400, epoch: 4 | loss: 0.2485512\n",
      "\tspeed: 0.1045s/iter; left time: 6542.6056s\n",
      "1499it [02:39,  9.46it/s]\titers: 1500, epoch: 4 | loss: 0.2532129\n",
      "\tspeed: 0.1078s/iter; left time: 6736.6199s\n",
      "1599it [02:49,  9.81it/s]\titers: 1600, epoch: 4 | loss: 0.2630502\n",
      "\tspeed: 0.1059s/iter; left time: 6609.9535s\n",
      "1698it [03:00,  9.90it/s]\titers: 1700, epoch: 4 | loss: 0.1064853\n",
      "\tspeed: 0.1090s/iter; left time: 6790.6147s\n",
      "1799it [03:11,  9.55it/s]\titers: 1800, epoch: 4 | loss: 0.2026107\n",
      "\tspeed: 0.1022s/iter; left time: 6355.0358s\n",
      "1899it [03:21,  9.45it/s]\titers: 1900, epoch: 4 | loss: 0.1402255\n",
      "\tspeed: 0.1085s/iter; left time: 6740.9178s\n",
      "1999it [03:32,  9.44it/s]\titers: 2000, epoch: 4 | loss: 0.2274337\n",
      "\tspeed: 0.1044s/iter; left time: 6475.5181s\n",
      "2099it [03:43,  9.64it/s]\titers: 2100, epoch: 4 | loss: 0.1340142\n",
      "\tspeed: 0.1078s/iter; left time: 6675.6959s\n",
      "2199it [03:53,  7.49it/s]\titers: 2200, epoch: 4 | loss: 0.1894352\n",
      "\tspeed: 0.1058s/iter; left time: 6539.2721s\n",
      "2299it [04:04,  9.68it/s]\titers: 2300, epoch: 4 | loss: 0.2004484\n",
      "\tspeed: 0.1069s/iter; left time: 6597.4261s\n",
      "2399it [04:14,  9.72it/s]\titers: 2400, epoch: 4 | loss: 0.5271217\n",
      "\tspeed: 0.1037s/iter; left time: 6390.3673s\n",
      "2499it [04:25,  9.54it/s]\titers: 2500, epoch: 4 | loss: 0.3280498\n",
      "\tspeed: 0.1050s/iter; left time: 6458.0568s\n",
      "2598it [04:35,  9.72it/s]\titers: 2600, epoch: 4 | loss: 0.1119976\n",
      "\tspeed: 0.1073s/iter; left time: 6591.5923s\n",
      "2699it [04:46,  9.19it/s]\titers: 2700, epoch: 4 | loss: 0.1604813\n",
      "\tspeed: 0.1054s/iter; left time: 6463.2969s\n",
      "2799it [04:57,  9.45it/s]\titers: 2800, epoch: 4 | loss: 0.4198509\n",
      "\tspeed: 0.1103s/iter; left time: 6753.6667s\n",
      "2899it [05:08,  9.69it/s]\titers: 2900, epoch: 4 | loss: 0.1755294\n",
      "\tspeed: 0.1057s/iter; left time: 6456.7716s\n",
      "2999it [05:18,  9.49it/s]\titers: 3000, epoch: 4 | loss: 0.3166817\n",
      "\tspeed: 0.1078s/iter; left time: 6574.4215s\n",
      "3099it [05:29,  9.31it/s]\titers: 3100, epoch: 4 | loss: 0.1173963\n",
      "\tspeed: 0.1039s/iter; left time: 6327.6517s\n",
      "3198it [05:40,  9.49it/s]\titers: 3200, epoch: 4 | loss: 0.1401283\n",
      "\tspeed: 0.1084s/iter; left time: 6591.3018s\n",
      "3299it [05:50,  8.94it/s]\titers: 3300, epoch: 4 | loss: 0.2136915\n",
      "\tspeed: 0.1049s/iter; left time: 6369.0707s\n",
      "3399it [06:01,  9.33it/s]\titers: 3400, epoch: 4 | loss: 0.1206224\n",
      "\tspeed: 0.1086s/iter; left time: 6584.1245s\n",
      "3499it [06:12,  8.36it/s]\titers: 3500, epoch: 4 | loss: 0.1457095\n",
      "\tspeed: 0.1140s/iter; left time: 6898.2944s\n",
      "3599it [06:23,  9.52it/s]\titers: 3600, epoch: 4 | loss: 0.3187863\n",
      "\tspeed: 0.1094s/iter; left time: 6608.7313s\n",
      "3699it [06:34,  9.15it/s]\titers: 3700, epoch: 4 | loss: 0.2756296\n",
      "\tspeed: 0.1102s/iter; left time: 6646.0507s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 4 cost time: 402.28674483299255\n",
      "810it [00:39, 20.40it/s]\n",
      "807it [00:38, 20.97it/s]\n",
      "Epoch: 4 | Train Loss: 0.2416328 Vali Loss: 0.2884408 Test Loss: 0.3517958 MAE Loss: 0.3653238\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "98it [00:11,  9.64it/s]\titers: 100, epoch: 5 | loss: 0.2478547\n",
      "\tspeed: 1.0030s/iter; left time: 60320.3544s\n",
      "199it [00:21,  9.19it/s]\titers: 200, epoch: 5 | loss: 0.1383682\n",
      "\tspeed: 0.1060s/iter; left time: 6364.5058s\n",
      "299it [00:33,  9.47it/s]\titers: 300, epoch: 5 | loss: 0.1529171\n",
      "\tspeed: 0.1160s/iter; left time: 6952.4690s\n",
      "399it [00:44,  8.23it/s]\titers: 400, epoch: 5 | loss: 0.1276615\n",
      "\tspeed: 0.1072s/iter; left time: 6415.3112s\n",
      "499it [00:54,  9.54it/s]\titers: 500, epoch: 5 | loss: 0.2939120\n",
      "\tspeed: 0.1049s/iter; left time: 6266.6093s\n",
      "599it [01:05,  9.66it/s]\titers: 600, epoch: 5 | loss: 0.1669849\n",
      "\tspeed: 0.1074s/iter; left time: 6404.3057s\n",
      "699it [01:15,  9.04it/s]\titers: 700, epoch: 5 | loss: 0.2098992\n",
      "\tspeed: 0.1051s/iter; left time: 6256.3082s\n",
      "799it [01:27,  8.07it/s]\titers: 800, epoch: 5 | loss: 0.1521538\n",
      "\tspeed: 0.1166s/iter; left time: 6928.7065s\n",
      "899it [01:38,  9.54it/s]\titers: 900, epoch: 5 | loss: 0.3411751\n",
      "\tspeed: 0.1080s/iter; left time: 6411.6337s\n",
      "999it [01:49,  9.42it/s]\titers: 1000, epoch: 5 | loss: 0.2953703\n",
      "\tspeed: 0.1089s/iter; left time: 6448.9994s\n",
      "1099it [01:59,  9.31it/s]\titers: 1100, epoch: 5 | loss: 0.1461303\n",
      "\tspeed: 0.1050s/iter; left time: 6209.9935s\n",
      "1199it [02:10,  9.26it/s]\titers: 1200, epoch: 5 | loss: 0.2113649\n",
      "\tspeed: 0.1089s/iter; left time: 6430.9100s\n",
      "1298it [02:21,  9.27it/s]\titers: 1300, epoch: 5 | loss: 0.1441561\n",
      "\tspeed: 0.1053s/iter; left time: 6208.3072s\n",
      "1399it [02:32,  9.44it/s]\titers: 1400, epoch: 5 | loss: 0.2450217\n",
      "\tspeed: 0.1117s/iter; left time: 6569.6076s\n",
      "1499it [02:43,  9.54it/s]\titers: 1500, epoch: 5 | loss: 0.2191112\n",
      "\tspeed: 0.1065s/iter; left time: 6256.0241s\n",
      "1599it [02:53,  9.62it/s]\titers: 1600, epoch: 5 | loss: 0.1568705\n",
      "\tspeed: 0.1064s/iter; left time: 6238.9224s\n",
      "1699it [03:04,  9.64it/s]\titers: 1700, epoch: 5 | loss: 0.0926042\n",
      "\tspeed: 0.1049s/iter; left time: 6140.2863s\n",
      "1798it [03:14,  9.66it/s]\titers: 1800, epoch: 5 | loss: 0.1626513\n",
      "\tspeed: 0.1071s/iter; left time: 6260.1090s\n",
      "1899it [03:25,  9.68it/s]\titers: 1900, epoch: 5 | loss: 0.1184558\n",
      "\tspeed: 0.1051s/iter; left time: 6133.3035s\n",
      "1998it [03:36,  9.38it/s]\titers: 2000, epoch: 5 | loss: 0.1913441\n",
      "\tspeed: 0.1087s/iter; left time: 6327.9669s\n",
      "2099it [03:46,  9.17it/s]\titers: 2100, epoch: 5 | loss: 0.0798915\n",
      "\tspeed: 0.1054s/iter; left time: 6129.9605s\n",
      "2199it [03:57,  9.54it/s]\titers: 2200, epoch: 5 | loss: 0.1707447\n",
      "\tspeed: 0.1064s/iter; left time: 6173.9485s\n",
      "2299it [04:08,  9.22it/s]\titers: 2300, epoch: 5 | loss: 0.1905618\n",
      "\tspeed: 0.1065s/iter; left time: 6171.9079s\n",
      "2398it [04:18,  9.59it/s]\titers: 2400, epoch: 5 | loss: 0.1451156\n",
      "\tspeed: 0.1069s/iter; left time: 6183.3265s\n",
      "2499it [04:29,  9.49it/s]\titers: 2500, epoch: 5 | loss: 0.1663814\n",
      "\tspeed: 0.1054s/iter; left time: 6085.9398s\n",
      "2598it [04:39,  9.46it/s]\titers: 2600, epoch: 5 | loss: 0.1278661\n",
      "\tspeed: 0.1070s/iter; left time: 6168.3899s\n",
      "2698it [04:50,  9.58it/s]\titers: 2700, epoch: 5 | loss: 0.1764272\n",
      "\tspeed: 0.1081s/iter; left time: 6218.2579s\n",
      "2799it [05:01,  9.60it/s]\titers: 2800, epoch: 5 | loss: 0.1719727\n",
      "\tspeed: 0.1038s/iter; left time: 5961.1469s\n",
      "2899it [05:12,  9.29it/s]\titers: 2900, epoch: 5 | loss: 0.4123531\n",
      "\tspeed: 0.1083s/iter; left time: 6209.4678s\n",
      "2999it [05:22,  9.50it/s]\titers: 3000, epoch: 5 | loss: 0.1176015\n",
      "\tspeed: 0.1043s/iter; left time: 5970.1939s\n",
      "3099it [05:33,  9.33it/s]\titers: 3100, epoch: 5 | loss: 0.6524203\n",
      "\tspeed: 0.1110s/iter; left time: 6341.6547s\n",
      "3199it [05:44,  9.13it/s]\titers: 3200, epoch: 5 | loss: 0.2427421\n",
      "\tspeed: 0.1084s/iter; left time: 6181.1839s\n",
      "3299it [05:55,  9.61it/s]\titers: 3300, epoch: 5 | loss: 0.4476039\n",
      "\tspeed: 0.1062s/iter; left time: 6047.3804s\n",
      "3399it [06:05,  9.23it/s]\titers: 3400, epoch: 5 | loss: 0.1180677\n",
      "\tspeed: 0.1046s/iter; left time: 5946.9910s\n",
      "3499it [06:16,  9.01it/s]\titers: 3500, epoch: 5 | loss: 0.2994959\n",
      "\tspeed: 0.1091s/iter; left time: 6191.3284s\n",
      "3599it [06:27,  7.67it/s]\titers: 3600, epoch: 5 | loss: 0.1675474\n",
      "\tspeed: 0.1107s/iter; left time: 6272.6382s\n",
      "3698it [06:38,  9.52it/s]\titers: 3700, epoch: 5 | loss: 0.2383050\n",
      "\tspeed: 0.1086s/iter; left time: 6140.0379s\n",
      "3765it [06:45,  9.28it/s]\n",
      "Epoch: 5 cost time: 405.56024527549744\n",
      "810it [00:39, 20.37it/s]\n",
      "807it [00:37, 21.25it/s]\n",
      "Epoch: 5 | Train Loss: 0.2372901 Vali Loss: 0.2835108 Test Loss: 0.3499868 MAE Loss: 0.3575151\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:10, 10.22it/s]\titers: 100, epoch: 6 | loss: 0.2878288\n",
      "\tspeed: 0.9848s/iter; left time: 55517.7716s\n",
      "199it [00:20,  9.53it/s]\titers: 200, epoch: 6 | loss: 0.4961921\n",
      "\tspeed: 0.1049s/iter; left time: 5903.4541s\n",
      "299it [00:30,  9.66it/s]\titers: 300, epoch: 6 | loss: 0.2105422\n",
      "\tspeed: 0.1025s/iter; left time: 5755.2556s\n",
      "399it [00:40, 10.07it/s]\titers: 400, epoch: 6 | loss: 0.1743765\n",
      "\tspeed: 0.0991s/iter; left time: 5559.0680s\n",
      "499it [00:51,  9.84it/s]\titers: 500, epoch: 6 | loss: 0.1949147\n",
      "\tspeed: 0.1042s/iter; left time: 5833.4118s\n",
      "599it [01:01,  9.42it/s]\titers: 600, epoch: 6 | loss: 0.1083930\n",
      "\tspeed: 0.1053s/iter; left time: 5882.0827s\n",
      "699it [01:12,  9.80it/s]\titers: 700, epoch: 6 | loss: 0.1878314\n",
      "\tspeed: 0.1090s/iter; left time: 6079.1164s\n",
      "799it [01:23,  9.68it/s]\titers: 800, epoch: 6 | loss: 0.1152903\n",
      "\tspeed: 0.1039s/iter; left time: 5786.1455s\n",
      "899it [01:34,  9.53it/s]\titers: 900, epoch: 6 | loss: 0.2227674\n",
      "\tspeed: 0.1097s/iter; left time: 6098.2023s\n",
      "999it [01:44,  9.29it/s]\titers: 1000, epoch: 6 | loss: 0.1907932\n",
      "\tspeed: 0.1039s/iter; left time: 5765.7965s\n",
      "1099it [01:54,  9.81it/s]\titers: 1100, epoch: 6 | loss: 0.1790158\n",
      "\tspeed: 0.1055s/iter; left time: 5840.9169s\n",
      "1199it [02:05,  8.85it/s]\titers: 1200, epoch: 6 | loss: 0.2772488\n",
      "\tspeed: 0.1060s/iter; left time: 5860.4896s\n",
      "1298it [02:16,  9.32it/s]\titers: 1300, epoch: 6 | loss: 0.2489044\n",
      "\tspeed: 0.1060s/iter; left time: 5846.5409s\n",
      "1399it [02:26,  9.51it/s]\titers: 1400, epoch: 6 | loss: 0.2973155\n",
      "\tspeed: 0.1062s/iter; left time: 5849.7735s\n",
      "1499it [02:37,  9.35it/s]\titers: 1500, epoch: 6 | loss: 0.2260058\n",
      "\tspeed: 0.1083s/iter; left time: 5951.9936s\n",
      "1599it [02:48,  8.99it/s]\titers: 1600, epoch: 6 | loss: 0.2973276\n",
      "\tspeed: 0.1105s/iter; left time: 6066.3321s\n",
      "1699it [02:59,  9.32it/s]\titers: 1700, epoch: 6 | loss: 0.1307759\n",
      "\tspeed: 0.1083s/iter; left time: 5932.2078s\n",
      "1799it [03:10,  8.97it/s]\titers: 1800, epoch: 6 | loss: 0.1549767\n",
      "\tspeed: 0.1108s/iter; left time: 6057.4518s\n",
      "1899it [03:21,  8.59it/s]\titers: 1900, epoch: 6 | loss: 0.1688714\n",
      "\tspeed: 0.1101s/iter; left time: 6009.3486s\n",
      "1999it [03:32,  9.58it/s]\titers: 2000, epoch: 6 | loss: 0.3452678\n",
      "\tspeed: 0.1054s/iter; left time: 5743.6534s\n",
      "2099it [03:42,  9.69it/s]\titers: 2100, epoch: 6 | loss: 0.2638007\n",
      "\tspeed: 0.1065s/iter; left time: 5792.2436s\n",
      "2199it [03:53,  9.76it/s]\titers: 2200, epoch: 6 | loss: 0.2849278\n",
      "\tspeed: 0.1046s/iter; left time: 5678.8956s\n",
      "2299it [04:03,  9.69it/s]\titers: 2300, epoch: 6 | loss: 0.1462020\n",
      "\tspeed: 0.1063s/iter; left time: 5761.6097s\n",
      "2399it [04:14,  9.46it/s]\titers: 2400, epoch: 6 | loss: 0.3516234\n",
      "\tspeed: 0.1039s/iter; left time: 5616.7188s\n",
      "2499it [04:25,  9.70it/s]\titers: 2500, epoch: 6 | loss: 0.2124246\n",
      "\tspeed: 0.1073s/iter; left time: 5790.1146s\n",
      "2599it [04:35,  9.61it/s]\titers: 2600, epoch: 6 | loss: 0.1399324\n",
      "\tspeed: 0.1035s/iter; left time: 5574.6019s\n",
      "2698it [04:46,  9.81it/s]\titers: 2700, epoch: 6 | loss: 0.2741902\n",
      "\tspeed: 0.1075s/iter; left time: 5782.2493s\n",
      "2798it [04:56,  9.44it/s]\titers: 2800, epoch: 6 | loss: 0.2097877\n",
      "\tspeed: 0.1071s/iter; left time: 5748.2906s\n",
      "2899it [05:07,  9.72it/s]\titers: 2900, epoch: 6 | loss: 0.2950759\n",
      "\tspeed: 0.1043s/iter; left time: 5586.0248s\n",
      "2999it [05:18,  9.78it/s]\titers: 3000, epoch: 6 | loss: 0.2340228\n",
      "\tspeed: 0.1084s/iter; left time: 5796.8100s\n",
      "3099it [05:28,  9.66it/s]\titers: 3100, epoch: 6 | loss: 0.2753986\n",
      "\tspeed: 0.1048s/iter; left time: 5595.4622s\n",
      "3199it [05:39,  9.59it/s]\titers: 3200, epoch: 6 | loss: 0.2271931\n",
      "\tspeed: 0.1084s/iter; left time: 5777.4290s\n",
      "3299it [05:49,  9.63it/s]\titers: 3300, epoch: 6 | loss: 0.2401093\n",
      "\tspeed: 0.1024s/iter; left time: 5443.6759s\n",
      "3398it [06:00,  9.56it/s]\titers: 3400, epoch: 6 | loss: 0.2277089\n",
      "\tspeed: 0.1082s/iter; left time: 5741.6426s\n",
      "3499it [06:11,  7.59it/s]\titers: 3500, epoch: 6 | loss: 0.1773320\n",
      "\tspeed: 0.1071s/iter; left time: 5674.4784s\n",
      "3599it [06:21,  9.72it/s]\titers: 3600, epoch: 6 | loss: 0.2196590\n",
      "\tspeed: 0.1047s/iter; left time: 5537.1965s\n",
      "3699it [06:32,  9.51it/s]\titers: 3700, epoch: 6 | loss: 0.3850082\n",
      "\tspeed: 0.1075s/iter; left time: 5670.8963s\n",
      "3765it [06:39,  9.43it/s]\n",
      "Epoch: 6 cost time: 399.38268995285034\n",
      "810it [00:38, 21.01it/s]\n",
      "807it [00:38, 21.18it/s]\n",
      "Epoch: 6 | Train Loss: 0.2355063 Vali Loss: 0.2831480 Test Loss: 0.3547814 MAE Loss: 0.3591193\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:11,  9.69it/s]\titers: 100, epoch: 7 | loss: 0.1825873\n",
      "\tspeed: 0.9871s/iter; left time: 51930.6914s\n",
      "198it [00:21,  9.57it/s]\titers: 200, epoch: 7 | loss: 0.1787469\n",
      "\tspeed: 0.1028s/iter; left time: 5398.3621s\n",
      "299it [00:32,  9.53it/s]\titers: 300, epoch: 7 | loss: 0.2098895\n",
      "\tspeed: 0.1078s/iter; left time: 5650.0891s\n",
      "399it [00:42,  7.07it/s]\titers: 400, epoch: 7 | loss: 0.2005446\n",
      "\tspeed: 0.1072s/iter; left time: 5608.4776s\n",
      "499it [00:53,  9.69it/s]\titers: 500, epoch: 7 | loss: 0.2577834\n",
      "\tspeed: 0.1046s/iter; left time: 5460.6343s\n",
      "599it [01:04,  9.61it/s]\titers: 600, epoch: 7 | loss: 0.4209492\n",
      "\tspeed: 0.1078s/iter; left time: 5617.2098s\n",
      "699it [01:14,  9.76it/s]\titers: 700, epoch: 7 | loss: 0.2408255\n",
      "\tspeed: 0.1046s/iter; left time: 5441.2551s\n",
      "799it [01:25,  9.63it/s]\titers: 800, epoch: 7 | loss: 0.1835321\n",
      "\tspeed: 0.1086s/iter; left time: 5636.5820s\n",
      "899it [01:35,  9.69it/s]\titers: 900, epoch: 7 | loss: 0.1966216\n",
      "\tspeed: 0.1033s/iter; left time: 5354.4035s\n",
      "999it [01:46,  9.54it/s]\titers: 1000, epoch: 7 | loss: 0.2130457\n",
      "\tspeed: 0.1084s/iter; left time: 5605.6590s\n",
      "1099it [01:57,  7.20it/s]\titers: 1100, epoch: 7 | loss: 0.2298835\n",
      "\tspeed: 0.1059s/iter; left time: 5467.5402s\n",
      "1199it [02:07,  9.78it/s]\titers: 1200, epoch: 7 | loss: 0.1886945\n",
      "\tspeed: 0.1053s/iter; left time: 5425.1909s\n",
      "1298it [02:18,  9.56it/s]\titers: 1300, epoch: 7 | loss: 0.5007377\n",
      "\tspeed: 0.1068s/iter; left time: 5492.8980s\n",
      "1399it [02:28,  9.48it/s]\titers: 1400, epoch: 7 | loss: 0.1594545\n",
      "\tspeed: 0.1045s/iter; left time: 5362.8243s\n",
      "1499it [02:39,  9.51it/s]\titers: 1500, epoch: 7 | loss: 0.1172540\n",
      "\tspeed: 0.1068s/iter; left time: 5468.0775s\n",
      "1598it [02:50,  9.62it/s]\titers: 1600, epoch: 7 | loss: 0.1343378\n",
      "\tspeed: 0.1050s/iter; left time: 5366.5141s\n",
      "1699it [03:00,  9.41it/s]\titers: 1700, epoch: 7 | loss: 0.3640646\n",
      "\tspeed: 0.1081s/iter; left time: 5513.4884s\n",
      "1799it [03:11,  9.52it/s]\titers: 1800, epoch: 7 | loss: 0.2789223\n",
      "\tspeed: 0.1027s/iter; left time: 5228.5404s\n",
      "1899it [03:22,  9.44it/s]\titers: 1900, epoch: 7 | loss: 0.2838268\n",
      "\tspeed: 0.1091s/iter; left time: 5544.3078s\n",
      "1999it [03:32,  9.10it/s]\titers: 2000, epoch: 7 | loss: 0.2160061\n",
      "\tspeed: 0.1071s/iter; left time: 5432.2292s\n",
      "2099it [03:43, 10.22it/s]\titers: 2100, epoch: 7 | loss: 0.1511686\n",
      "\tspeed: 0.1094s/iter; left time: 5539.3656s\n",
      "2199it [03:54,  7.75it/s]\titers: 2200, epoch: 7 | loss: 0.2368914\n",
      "\tspeed: 0.1073s/iter; left time: 5419.2347s\n",
      "2299it [04:05,  8.97it/s]\titers: 2300, epoch: 7 | loss: 0.1790831\n",
      "\tspeed: 0.1113s/iter; left time: 5612.8662s\n",
      "2399it [04:16,  7.03it/s]\titers: 2400, epoch: 7 | loss: 0.0987818\n",
      "\tspeed: 0.1135s/iter; left time: 5708.8493s\n",
      "2499it [04:27,  9.43it/s]\titers: 2500, epoch: 7 | loss: 0.2260060\n",
      "\tspeed: 0.1045s/iter; left time: 5244.9195s\n",
      "2599it [04:38,  9.70it/s]\titers: 2600, epoch: 7 | loss: 0.2190440\n",
      "\tspeed: 0.1097s/iter; left time: 5497.8238s\n",
      "2699it [04:48,  9.49it/s]\titers: 2700, epoch: 7 | loss: 0.1700542\n",
      "\tspeed: 0.1038s/iter; left time: 5190.4737s\n",
      "2798it [04:59,  9.70it/s]\titers: 2800, epoch: 7 | loss: 0.1898256\n",
      "\tspeed: 0.1091s/iter; left time: 5445.3317s\n",
      "2899it [05:10,  9.45it/s]\titers: 2900, epoch: 7 | loss: 0.2612721\n",
      "\tspeed: 0.1048s/iter; left time: 5217.9305s\n",
      "2998it [05:20,  9.02it/s]\titers: 3000, epoch: 7 | loss: 0.1626969\n",
      "\tspeed: 0.1092s/iter; left time: 5426.8441s\n",
      "3099it [05:31,  8.28it/s]\titers: 3100, epoch: 7 | loss: 0.1865934\n",
      "\tspeed: 0.1081s/iter; left time: 5364.7979s\n",
      "3199it [05:42,  9.52it/s]\titers: 3200, epoch: 7 | loss: 0.1596189\n",
      "\tspeed: 0.1049s/iter; left time: 5192.9703s\n",
      "3299it [05:53,  9.56it/s]\titers: 3300, epoch: 7 | loss: 0.1887575\n",
      "\tspeed: 0.1074s/iter; left time: 5304.5052s\n",
      "3399it [06:03,  9.48it/s]\titers: 3400, epoch: 7 | loss: 0.2988138\n",
      "\tspeed: 0.1072s/iter; left time: 5286.4007s\n",
      "3499it [06:14,  9.03it/s]\titers: 3500, epoch: 7 | loss: 0.2396412\n",
      "\tspeed: 0.1084s/iter; left time: 5335.1119s\n",
      "3599it [06:25,  9.76it/s]\titers: 3600, epoch: 7 | loss: 0.2243811\n",
      "\tspeed: 0.1051s/iter; left time: 5163.3953s\n",
      "3699it [06:36,  9.47it/s]\titers: 3700, epoch: 7 | loss: 0.1390385\n",
      "\tspeed: 0.1097s/iter; left time: 5378.1704s\n",
      "3765it [06:43,  9.34it/s]\n",
      "Epoch: 7 cost time: 403.27958273887634\n",
      "810it [00:38, 21.09it/s]\n",
      "807it [00:37, 21.26it/s]\n",
      "Epoch: 7 | Train Loss: 0.2349653 Vali Loss: 0.2790892 Test Loss: 0.3470574 MAE Loss: 0.3519578\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:10,  9.60it/s]\titers: 100, epoch: 8 | loss: 0.3506989\n",
      "\tspeed: 0.9742s/iter; left time: 47584.9162s\n",
      "199it [00:21,  9.28it/s]\titers: 200, epoch: 8 | loss: 0.1436247\n",
      "\tspeed: 0.1035s/iter; left time: 5047.3099s\n",
      "299it [00:31,  9.74it/s]\titers: 300, epoch: 8 | loss: 0.2360088\n",
      "\tspeed: 0.1051s/iter; left time: 5111.3325s\n",
      "399it [00:42,  9.74it/s]\titers: 400, epoch: 8 | loss: 0.2246222\n",
      "\tspeed: 0.1070s/iter; left time: 5193.1261s\n",
      "499it [00:52,  9.68it/s]\titers: 500, epoch: 8 | loss: 0.2638862\n",
      "\tspeed: 0.1043s/iter; left time: 5053.3993s\n",
      "598it [01:03,  9.68it/s]\titers: 600, epoch: 8 | loss: 0.2370474\n",
      "\tspeed: 0.1064s/iter; left time: 5141.9360s\n",
      "699it [01:13,  9.59it/s]\titers: 700, epoch: 8 | loss: 0.1567954\n",
      "\tspeed: 0.1031s/iter; left time: 4974.2034s\n",
      "799it [01:24,  9.45it/s]\titers: 800, epoch: 8 | loss: 0.1541171\n",
      "\tspeed: 0.1078s/iter; left time: 5192.3821s\n",
      "899it [01:35,  8.13it/s]\titers: 900, epoch: 8 | loss: 0.2944638\n",
      "\tspeed: 0.1063s/iter; left time: 5106.9767s\n",
      "999it [01:46,  9.52it/s]\titers: 1000, epoch: 8 | loss: 0.2044097\n",
      "\tspeed: 0.1086s/iter; left time: 5206.5203s\n",
      "1098it [01:56,  9.54it/s]\titers: 1100, epoch: 8 | loss: 0.1035955\n",
      "\tspeed: 0.1065s/iter; left time: 5095.2613s\n",
      "1199it [02:07,  9.87it/s]\titers: 1200, epoch: 8 | loss: 0.1289895\n",
      "\tspeed: 0.1049s/iter; left time: 5007.2069s\n",
      "1299it [02:18,  9.42it/s]\titers: 1300, epoch: 8 | loss: 0.1314626\n",
      "\tspeed: 0.1090s/iter; left time: 5193.0044s\n",
      "1399it [02:28,  9.51it/s]\titers: 1400, epoch: 8 | loss: 0.1493650\n",
      "\tspeed: 0.1034s/iter; left time: 4914.2520s\n",
      "1499it [02:39,  9.52it/s]\titers: 1500, epoch: 8 | loss: 0.2853166\n",
      "\tspeed: 0.1090s/iter; left time: 5169.8122s\n",
      "1599it [02:49,  9.52it/s]\titers: 1600, epoch: 8 | loss: 0.2085637\n",
      "\tspeed: 0.1031s/iter; left time: 4882.1221s\n",
      "1698it [03:00,  9.66it/s]\titers: 1700, epoch: 8 | loss: 0.3593288\n",
      "\tspeed: 0.1084s/iter; left time: 5122.4889s\n",
      "1799it [03:11,  7.35it/s]\titers: 1800, epoch: 8 | loss: 0.1689215\n",
      "\tspeed: 0.1094s/iter; left time: 5158.1945s\n",
      "1898it [03:21,  9.66it/s]\titers: 1900, epoch: 8 | loss: 0.3364297\n",
      "\tspeed: 0.1037s/iter; left time: 4880.7255s\n",
      "1999it [03:32,  7.52it/s]\titers: 2000, epoch: 8 | loss: 0.1890083\n",
      "\tspeed: 0.1063s/iter; left time: 4989.8657s\n",
      "2099it [03:42,  9.71it/s]\titers: 2100, epoch: 8 | loss: 0.1462867\n",
      "\tspeed: 0.1032s/iter; left time: 4833.4673s\n",
      "2199it [03:53,  9.79it/s]\titers: 2200, epoch: 8 | loss: 0.2131882\n",
      "\tspeed: 0.1068s/iter; left time: 4993.0659s\n",
      "2299it [04:03,  9.54it/s]\titers: 2300, epoch: 8 | loss: 0.3391059\n",
      "\tspeed: 0.1035s/iter; left time: 4826.4876s\n",
      "2399it [04:14,  9.76it/s]\titers: 2400, epoch: 8 | loss: 0.1930247\n",
      "\tspeed: 0.1077s/iter; left time: 5011.2657s\n",
      "2499it [04:25,  9.50it/s]\titers: 2500, epoch: 8 | loss: 0.1811646\n",
      "\tspeed: 0.1075s/iter; left time: 4991.2171s\n",
      "2599it [04:35,  9.55it/s]\titers: 2600, epoch: 8 | loss: 0.3426889\n",
      "\tspeed: 0.1048s/iter; left time: 4855.5459s\n",
      "2698it [04:46,  7.59it/s]\titers: 2700, epoch: 8 | loss: 0.2884260\n",
      "\tspeed: 0.1099s/iter; left time: 5081.8339s\n",
      "2799it [04:57,  9.52it/s]\titers: 2800, epoch: 8 | loss: 0.2787545\n",
      "\tspeed: 0.1035s/iter; left time: 4778.2179s\n",
      "2899it [05:07,  9.69it/s]\titers: 2900, epoch: 8 | loss: 0.2385738\n",
      "\tspeed: 0.1066s/iter; left time: 4906.6784s\n",
      "2999it [05:18,  8.76it/s]\titers: 3000, epoch: 8 | loss: 0.2332280\n",
      "\tspeed: 0.1059s/iter; left time: 4863.4971s\n",
      "3098it [05:28, 10.17it/s]\titers: 3100, epoch: 8 | loss: 0.4117592\n",
      "\tspeed: 0.1050s/iter; left time: 4815.2151s\n",
      "3199it [05:39,  8.99it/s]\titers: 3200, epoch: 8 | loss: 0.2709180\n",
      "\tspeed: 0.1024s/iter; left time: 4686.6122s\n",
      "3299it [05:49,  9.49it/s]\titers: 3300, epoch: 8 | loss: 0.1573088\n",
      "\tspeed: 0.1047s/iter; left time: 4779.3078s\n",
      "3399it [05:59,  9.69it/s]\titers: 3400, epoch: 8 | loss: 0.2022467\n",
      "\tspeed: 0.1009s/iter; left time: 4597.5796s\n",
      "3498it [06:10,  9.52it/s]\titers: 3500, epoch: 8 | loss: 0.2233892\n",
      "\tspeed: 0.1040s/iter; left time: 4725.3009s\n",
      "3599it [06:20,  9.68it/s]\titers: 3600, epoch: 8 | loss: 0.2437603\n",
      "\tspeed: 0.1066s/iter; left time: 4835.5807s\n",
      "3699it [06:31,  9.61it/s]\titers: 3700, epoch: 8 | loss: 0.1701473\n",
      "\tspeed: 0.1034s/iter; left time: 4679.0393s\n",
      "3765it [06:38,  9.45it/s]\n",
      "Epoch: 8 cost time: 398.3803572654724\n",
      "810it [00:38, 20.96it/s]\n",
      "807it [00:38, 20.96it/s]\n",
      "Epoch: 8 | Train Loss: 0.2336885 Vali Loss: 0.2808471 Test Loss: 0.3495025 MAE Loss: 0.3542536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:10,  9.35it/s]\titers: 100, epoch: 9 | loss: 0.3825790\n",
      "\tspeed: 0.9531s/iter; left time: 42968.6418s\n",
      "198it [00:21,  9.54it/s]\titers: 200, epoch: 9 | loss: 0.1725433\n",
      "\tspeed: 0.1077s/iter; left time: 4843.8722s\n",
      "299it [00:32,  7.87it/s]\titers: 300, epoch: 9 | loss: 0.4980379\n",
      "\tspeed: 0.1066s/iter; left time: 4783.7567s\n",
      "399it [00:42,  9.77it/s]\titers: 400, epoch: 9 | loss: 0.2820833\n",
      "\tspeed: 0.1046s/iter; left time: 4685.0990s\n",
      "499it [00:53,  8.60it/s]\titers: 500, epoch: 9 | loss: 0.1706389\n",
      "\tspeed: 0.1064s/iter; left time: 4752.4898s\n",
      "599it [01:03,  9.55it/s]\titers: 600, epoch: 9 | loss: 0.1779170\n",
      "\tspeed: 0.1037s/iter; left time: 4621.9437s\n",
      "699it [01:14,  9.67it/s]\titers: 700, epoch: 9 | loss: 0.2595640\n",
      "\tspeed: 0.1077s/iter; left time: 4788.6863s\n",
      "799it [01:25,  9.48it/s]\titers: 800, epoch: 9 | loss: 0.2967034\n",
      "\tspeed: 0.1057s/iter; left time: 4692.0544s\n",
      "899it [01:36,  9.60it/s]\titers: 900, epoch: 9 | loss: 0.2537479\n",
      "\tspeed: 0.1112s/iter; left time: 4924.3820s\n",
      "999it [01:46,  9.54it/s]\titers: 1000, epoch: 9 | loss: 0.3987970\n",
      "\tspeed: 0.1059s/iter; left time: 4677.3088s\n",
      "1099it [01:57,  9.76it/s]\titers: 1100, epoch: 9 | loss: 0.1572018\n",
      "\tspeed: 0.1073s/iter; left time: 4728.3657s\n",
      "1198it [02:07,  9.26it/s]\titers: 1200, epoch: 9 | loss: 0.1536233\n",
      "\tspeed: 0.1054s/iter; left time: 4633.7065s\n",
      "1299it [02:18, 10.02it/s]\titers: 1300, epoch: 9 | loss: 0.2235825\n",
      "\tspeed: 0.1057s/iter; left time: 4636.7308s\n",
      "1399it [02:28,  9.51it/s]\titers: 1400, epoch: 9 | loss: 0.3382436\n",
      "\tspeed: 0.1038s/iter; left time: 4542.8797s\n",
      "1499it [02:39,  9.61it/s]\titers: 1500, epoch: 9 | loss: 0.5567049\n",
      "\tspeed: 0.1065s/iter; left time: 4651.1950s\n",
      "1599it [02:49,  8.47it/s]\titers: 1600, epoch: 9 | loss: 0.2711269\n",
      "\tspeed: 0.1011s/iter; left time: 4406.6254s\n",
      "1699it [03:00,  9.43it/s]\titers: 1700, epoch: 9 | loss: 0.1396367\n",
      "\tspeed: 0.1089s/iter; left time: 4737.0533s\n",
      "1798it [03:11,  7.94it/s]\titers: 1800, epoch: 9 | loss: 0.0876262\n",
      "\tspeed: 0.1094s/iter; left time: 4745.9913s\n",
      "1899it [03:22,  9.80it/s]\titers: 1900, epoch: 9 | loss: 0.1658398\n",
      "\tspeed: 0.1048s/iter; left time: 4537.2197s\n",
      "1999it [03:32,  9.84it/s]\titers: 2000, epoch: 9 | loss: 0.1741202\n",
      "\tspeed: 0.1045s/iter; left time: 4514.2938s\n",
      "2099it [03:42,  9.57it/s]\titers: 2100, epoch: 9 | loss: 0.2029316\n",
      "\tspeed: 0.1050s/iter; left time: 4523.7842s\n",
      "2199it [03:53,  8.32it/s]\titers: 2200, epoch: 9 | loss: 0.2443927\n",
      "\tspeed: 0.1069s/iter; left time: 4593.1132s\n",
      "2299it [04:04,  9.51it/s]\titers: 2300, epoch: 9 | loss: 0.1655963\n",
      "\tspeed: 0.1045s/iter; left time: 4479.8366s\n",
      "2399it [04:14,  9.56it/s]\titers: 2400, epoch: 9 | loss: 0.1731331\n",
      "\tspeed: 0.1065s/iter; left time: 4554.6750s\n",
      "2498it [04:25,  9.53it/s]\titers: 2500, epoch: 9 | loss: 0.1904792\n",
      "\tspeed: 0.1044s/iter; left time: 4454.2786s\n",
      "2599it [04:36,  8.83it/s]\titers: 2600, epoch: 9 | loss: 0.2654003\n",
      "\tspeed: 0.1118s/iter; left time: 4759.0654s\n",
      "2699it [04:47,  7.47it/s]\titers: 2700, epoch: 9 | loss: 0.1814935\n",
      "\tspeed: 0.1093s/iter; left time: 4642.8090s\n",
      "2799it [04:58,  8.91it/s]\titers: 2800, epoch: 9 | loss: 0.1873304\n",
      "\tspeed: 0.1094s/iter; left time: 4634.6139s\n",
      "2899it [05:09,  9.48it/s]\titers: 2900, epoch: 9 | loss: 0.4009605\n",
      "\tspeed: 0.1107s/iter; left time: 4681.5403s\n",
      "2999it [05:20,  9.22it/s]\titers: 3000, epoch: 9 | loss: 0.2766252\n",
      "\tspeed: 0.1096s/iter; left time: 4622.5977s\n",
      "3099it [05:31,  9.45it/s]\titers: 3100, epoch: 9 | loss: 0.0845561\n",
      "\tspeed: 0.1105s/iter; left time: 4651.5161s\n",
      "3199it [05:42,  7.68it/s]\titers: 3200, epoch: 9 | loss: 0.1238977\n",
      "\tspeed: 0.1076s/iter; left time: 4518.3938s\n",
      "3299it [05:52,  9.66it/s]\titers: 3300, epoch: 9 | loss: 0.3404590\n",
      "\tspeed: 0.1046s/iter; left time: 4381.1668s\n",
      "3399it [06:03,  9.67it/s]\titers: 3400, epoch: 9 | loss: 0.2350450\n",
      "\tspeed: 0.1065s/iter; left time: 4449.9174s\n",
      "3499it [06:13,  9.90it/s]\titers: 3500, epoch: 9 | loss: 0.1866093\n",
      "\tspeed: 0.1051s/iter; left time: 4381.2601s\n",
      "3598it [06:23,  9.95it/s]\titers: 3600, epoch: 9 | loss: 0.1902752\n",
      "\tspeed: 0.1036s/iter; left time: 4306.3117s\n",
      "3699it [06:34,  9.33it/s]\titers: 3700, epoch: 9 | loss: 0.2562085\n",
      "\tspeed: 0.1085s/iter; left time: 4501.6013s\n",
      "3765it [06:42,  9.35it/s]\n",
      "Epoch: 9 cost time: 402.5866334438324\n",
      "810it [00:38, 21.19it/s]\n",
      "807it [00:37, 21.27it/s]\n",
      "Epoch: 9 | Train Loss: 0.2341588 Vali Loss: 0.2810043 Test Loss: 0.3491890 MAE Loss: 0.3547902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:11,  9.68it/s]\titers: 100, epoch: 10 | loss: 0.1723268\n",
      "\tspeed: 0.9517s/iter; left time: 39321.8994s\n",
      "199it [00:22,  8.76it/s]\titers: 200, epoch: 10 | loss: 0.2208683\n",
      "\tspeed: 0.1088s/iter; left time: 4482.7890s\n",
      "299it [00:32,  9.92it/s]\titers: 300, epoch: 10 | loss: 0.4449243\n",
      "\tspeed: 0.1082s/iter; left time: 4450.5838s\n",
      "399it [00:43,  9.68it/s]\titers: 400, epoch: 10 | loss: 0.2609064\n",
      "\tspeed: 0.1033s/iter; left time: 4236.9209s\n",
      "499it [00:54,  9.71it/s]\titers: 500, epoch: 10 | loss: 0.0984240\n",
      "\tspeed: 0.1088s/iter; left time: 4453.5563s\n",
      "598it [01:04,  9.22it/s]\titers: 600, epoch: 10 | loss: 0.1044388\n",
      "\tspeed: 0.1019s/iter; left time: 4159.3155s\n",
      "698it [01:14, 10.20it/s]\titers: 700, epoch: 10 | loss: 0.2919191\n",
      "\tspeed: 0.1034s/iter; left time: 4208.6553s\n",
      "799it [01:25,  8.82it/s]\titers: 800, epoch: 10 | loss: 0.2367166\n",
      "\tspeed: 0.1048s/iter; left time: 4257.2800s\n",
      "899it [01:35,  9.85it/s]\titers: 900, epoch: 10 | loss: 0.2438001\n",
      "\tspeed: 0.1053s/iter; left time: 4266.9489s\n",
      "999it [01:46,  9.49it/s]\titers: 1000, epoch: 10 | loss: 0.3405101\n",
      "\tspeed: 0.1098s/iter; left time: 4436.0965s\n",
      "1099it [01:57,  9.67it/s]\titers: 1100, epoch: 10 | loss: 0.1387934\n",
      "\tspeed: 0.1059s/iter; left time: 4268.2194s\n",
      "1199it [02:08,  9.45it/s]\titers: 1200, epoch: 10 | loss: 0.1498981\n",
      "\tspeed: 0.1113s/iter; left time: 4474.5353s\n",
      "1299it [02:19,  8.93it/s]\titers: 1300, epoch: 10 | loss: 0.2480242\n",
      "\tspeed: 0.1108s/iter; left time: 4445.2533s\n",
      "1399it [02:30,  9.52it/s]\titers: 1400, epoch: 10 | loss: 0.2578139\n",
      "\tspeed: 0.1065s/iter; left time: 4259.9175s\n",
      "1499it [02:40,  9.46it/s]\titers: 1500, epoch: 10 | loss: 0.1467920\n",
      "\tspeed: 0.1087s/iter; left time: 4338.6808s\n",
      "1599it [02:51,  9.51it/s]\titers: 1600, epoch: 10 | loss: 0.1537020\n",
      "\tspeed: 0.1038s/iter; left time: 4132.1258s\n",
      "1699it [03:02,  9.80it/s]\titers: 1700, epoch: 10 | loss: 0.1890868\n",
      "\tspeed: 0.1070s/iter; left time: 4248.8094s\n",
      "1799it [03:12,  9.41it/s]\titers: 1800, epoch: 10 | loss: 0.2270114\n",
      "\tspeed: 0.1038s/iter; left time: 4112.1507s\n",
      "1898it [03:23,  9.83it/s]\titers: 1900, epoch: 10 | loss: 0.2309489\n",
      "\tspeed: 0.1070s/iter; left time: 4227.3148s\n",
      "1999it [03:33,  9.42it/s]\titers: 2000, epoch: 10 | loss: 0.2096069\n",
      "\tspeed: 0.1067s/iter; left time: 4205.5740s\n",
      "2099it [03:44,  9.60it/s]\titers: 2100, epoch: 10 | loss: 0.1128602\n",
      "\tspeed: 0.1050s/iter; left time: 4126.9486s\n",
      "2199it [03:55,  9.55it/s]\titers: 2200, epoch: 10 | loss: 0.1700975\n",
      "\tspeed: 0.1091s/iter; left time: 4277.7295s\n",
      "2299it [04:05,  9.41it/s]\titers: 2300, epoch: 10 | loss: 0.1551427\n",
      "\tspeed: 0.1043s/iter; left time: 4080.1898s\n",
      "2399it [04:16,  9.52it/s]\titers: 2400, epoch: 10 | loss: 0.2703189\n",
      "\tspeed: 0.1081s/iter; left time: 4216.4743s\n",
      "2499it [04:26,  9.00it/s]\titers: 2500, epoch: 10 | loss: 0.2492352\n",
      "\tspeed: 0.1041s/iter; left time: 4051.7476s\n",
      "2599it [04:37,  9.81it/s]\titers: 2600, epoch: 10 | loss: 0.2253091\n",
      "\tspeed: 0.1055s/iter; left time: 4095.9945s\n",
      "2699it [04:48,  9.67it/s]\titers: 2700, epoch: 10 | loss: 0.2914334\n",
      "\tspeed: 0.1062s/iter; left time: 4110.9622s\n",
      "2799it [04:58,  9.80it/s]\titers: 2800, epoch: 10 | loss: 0.1950349\n",
      "\tspeed: 0.1047s/iter; left time: 4042.6593s\n",
      "2899it [05:09,  9.55it/s]\titers: 2900, epoch: 10 | loss: 0.1068291\n",
      "\tspeed: 0.1061s/iter; left time: 4086.8210s\n",
      "2999it [05:19,  9.64it/s]\titers: 3000, epoch: 10 | loss: 0.1239468\n",
      "\tspeed: 0.1036s/iter; left time: 3979.3154s\n",
      "3098it [05:29,  9.81it/s]\titers: 3100, epoch: 10 | loss: 0.2012846\n",
      "\tspeed: 0.1062s/iter; left time: 4068.1682s\n",
      "3199it [05:40,  9.38it/s]\titers: 3200, epoch: 10 | loss: 0.4415931\n",
      "\tspeed: 0.1053s/iter; left time: 4026.0304s\n",
      "3299it [05:51,  9.86it/s]\titers: 3300, epoch: 10 | loss: 0.1700503\n",
      "\tspeed: 0.1049s/iter; left time: 3998.3357s\n",
      "3399it [06:01,  9.37it/s]\titers: 3400, epoch: 10 | loss: 0.2265361\n",
      "\tspeed: 0.1041s/iter; left time: 3958.5381s\n",
      "3498it [06:11, 10.23it/s]\titers: 3500, epoch: 10 | loss: 0.1616457\n",
      "\tspeed: 0.0986s/iter; left time: 3738.1490s\n",
      "3599it [06:21,  9.99it/s]\titers: 3600, epoch: 10 | loss: 0.4349119\n",
      "\tspeed: 0.1006s/iter; left time: 3802.6790s\n",
      "3699it [06:31,  9.48it/s]\titers: 3700, epoch: 10 | loss: 0.1088503\n",
      "\tspeed: 0.1008s/iter; left time: 3803.5302s\n",
      "3765it [06:38,  9.45it/s]\n",
      "Epoch: 10 cost time: 398.6025242805481\n",
      "810it [00:38, 21.14it/s]\n",
      "807it [00:38, 21.20it/s]\n",
      "Epoch: 10 | Train Loss: 0.2338287 Vali Loss: 0.2807260 Test Loss: 0.3485084 MAE Loss: 0.3539550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "99it [00:10,  9.27it/s]\titers: 100, epoch: 11 | loss: 0.4864461\n",
      "\tspeed: 0.9445s/iter; left time: 35466.8045s\n",
      "199it [00:21,  9.20it/s]\titers: 200, epoch: 11 | loss: 0.1635980\n",
      "\tspeed: 0.1084s/iter; left time: 4059.2845s\n",
      "299it [00:32,  9.42it/s]\titers: 300, epoch: 11 | loss: 0.2338124\n",
      "\tspeed: 0.1069s/iter; left time: 3993.4392s\n",
      "399it [00:43,  8.97it/s]\titers: 400, epoch: 11 | loss: 0.2477203\n",
      "\tspeed: 0.1143s/iter; left time: 4258.3263s\n",
      "499it [00:55,  7.72it/s]\titers: 500, epoch: 11 | loss: 0.2224052\n",
      "\tspeed: 0.1121s/iter; left time: 4163.3418s\n",
      "599it [01:06,  8.96it/s]\titers: 600, epoch: 11 | loss: 0.1731232\n",
      "\tspeed: 0.1117s/iter; left time: 4139.7487s\n",
      "699it [01:17,  9.19it/s]\titers: 700, epoch: 11 | loss: 0.3543292\n",
      "\tspeed: 0.1104s/iter; left time: 4079.2972s\n",
      "799it [01:28,  9.11it/s]\titers: 800, epoch: 11 | loss: 0.1423600\n",
      "\tspeed: 0.1097s/iter; left time: 4042.9890s\n",
      "899it [01:39,  9.92it/s]\titers: 900, epoch: 11 | loss: 0.2840686\n",
      "\tspeed: 0.1095s/iter; left time: 4023.8818s\n",
      "998it [01:49, 10.21it/s]\titers: 1000, epoch: 11 | loss: 0.3593785\n",
      "\tspeed: 0.0997s/iter; left time: 3654.8080s\n",
      "1099it [01:59, 10.35it/s]\titers: 1100, epoch: 11 | loss: 0.2088745\n",
      "\tspeed: 0.1049s/iter; left time: 3833.9230s\n",
      "1198it [02:09, 10.01it/s]\titers: 1200, epoch: 11 | loss: 0.2125911\n",
      "\tspeed: 0.0989s/iter; left time: 3605.3922s\n",
      "1299it [02:19, 10.15it/s]\titers: 1300, epoch: 11 | loss: 0.2791885\n",
      "\tspeed: 0.1023s/iter; left time: 3717.6079s\n",
      "1399it [02:29,  9.91it/s]\titers: 1400, epoch: 11 | loss: 0.3497153\n",
      "\tspeed: 0.0994s/iter; left time: 3604.9283s\n",
      "1499it [02:40,  9.50it/s]\titers: 1500, epoch: 11 | loss: 0.2165293\n",
      "\tspeed: 0.1058s/iter; left time: 3826.1153s\n",
      "1599it [02:51,  9.51it/s]\titers: 1600, epoch: 11 | loss: 0.1766350\n",
      "\tspeed: 0.1078s/iter; left time: 3884.6602s\n",
      "1699it [03:02,  9.07it/s]\titers: 1700, epoch: 11 | loss: 0.2907978\n",
      "\tspeed: 0.1116s/iter; left time: 4010.7409s\n",
      "1799it [03:13,  9.32it/s]\titers: 1800, epoch: 11 | loss: 0.2214073\n",
      "\tspeed: 0.1125s/iter; left time: 4033.9085s\n",
      "1899it [03:24,  9.33it/s]\titers: 1900, epoch: 11 | loss: 0.2165587\n",
      "\tspeed: 0.1073s/iter; left time: 3834.4568s\n",
      "1999it [03:35,  7.66it/s]\titers: 2000, epoch: 11 | loss: 0.2333512\n",
      "\tspeed: 0.1106s/iter; left time: 3941.4764s\n",
      "2099it [03:45,  9.52it/s]\titers: 2100, epoch: 11 | loss: 0.1813310\n",
      "\tspeed: 0.1046s/iter; left time: 3718.4351s\n",
      "2199it [03:56,  9.52it/s]\titers: 2200, epoch: 11 | loss: 0.1433497\n",
      "\tspeed: 0.1111s/iter; left time: 3938.7020s\n",
      "2299it [04:07,  8.93it/s]\titers: 2300, epoch: 11 | loss: 0.1124350\n",
      "\tspeed: 0.1082s/iter; left time: 3825.0113s\n",
      "2399it [04:18,  9.61it/s]\titers: 2400, epoch: 11 | loss: 0.3049277\n",
      "\tspeed: 0.1120s/iter; left time: 3948.6067s\n",
      "2499it [04:29,  9.42it/s]\titers: 2500, epoch: 11 | loss: 0.1442997\n",
      "\tspeed: 0.1083s/iter; left time: 3806.8467s\n",
      "2599it [04:40,  9.62it/s]\titers: 2600, epoch: 11 | loss: 0.1332534\n",
      "\tspeed: 0.1047s/iter; left time: 3668.7147s\n",
      "2699it [04:50,  9.67it/s]\titers: 2700, epoch: 11 | loss: 0.6135613\n",
      "\tspeed: 0.1054s/iter; left time: 3682.9050s\n",
      "2799it [05:01,  9.69it/s]\titers: 2800, epoch: 11 | loss: 0.3236788\n",
      "\tspeed: 0.1042s/iter; left time: 3632.3348s\n",
      "2899it [05:11,  9.50it/s]\titers: 2900, epoch: 11 | loss: 0.3091466\n",
      "\tspeed: 0.1066s/iter; left time: 3705.7011s\n",
      "2998it [05:22,  9.60it/s]\titers: 3000, epoch: 11 | loss: 0.4900548\n",
      "\tspeed: 0.1037s/iter; left time: 3593.3714s\n",
      "3099it [05:32,  9.72it/s]\titers: 3100, epoch: 11 | loss: 0.2280794\n",
      "\tspeed: 0.1066s/iter; left time: 3682.2397s\n",
      "3199it [05:43,  9.51it/s]\titers: 3200, epoch: 11 | loss: 0.1335958\n",
      "\tspeed: 0.1053s/iter; left time: 3626.3814s\n",
      "3299it [05:53, 10.20it/s]\titers: 3300, epoch: 11 | loss: 0.1745294\n",
      "\tspeed: 0.1036s/iter; left time: 3560.2857s\n",
      "3398it [06:03,  9.80it/s]\titers: 3400, epoch: 11 | loss: 0.3373220\n",
      "\tspeed: 0.0985s/iter; left time: 3373.7783s\n",
      "3499it [06:13,  9.64it/s]\titers: 3500, epoch: 11 | loss: 0.1952699\n",
      "\tspeed: 0.1034s/iter; left time: 3532.2673s\n",
      "3599it [06:24,  8.86it/s]\titers: 3600, epoch: 11 | loss: 0.2437931\n",
      "\tspeed: 0.1073s/iter; left time: 3654.0190s\n",
      "3699it [06:35,  9.66it/s]\titers: 3700, epoch: 11 | loss: 0.1880078\n",
      "\tspeed: 0.1043s/iter; left time: 3541.6672s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 11 cost time: 402.2965576648712\n",
      "810it [00:38, 21.03it/s]\n",
      "807it [00:38, 20.84it/s]\n",
      "Epoch: 11 | Train Loss: 0.2340201 Vali Loss: 0.2806249 Test Loss: 0.3491499 MAE Loss: 0.3542873\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "99it [00:11,  9.05it/s]\titers: 100, epoch: 12 | loss: 0.2215275\n",
      "\tspeed: 0.9579s/iter; left time: 32363.9318s\n",
      "198it [00:21,  9.70it/s]\titers: 200, epoch: 12 | loss: 0.2778927\n",
      "\tspeed: 0.1075s/iter; left time: 3619.7474s\n",
      "299it [00:32,  8.84it/s]\titers: 300, epoch: 12 | loss: 0.2482912\n",
      "\tspeed: 0.1079s/iter; left time: 3624.9242s\n",
      "399it [00:43,  9.72it/s]\titers: 400, epoch: 12 | loss: 0.1680039\n",
      "\tspeed: 0.1073s/iter; left time: 3592.1223s\n",
      "499it [00:54,  9.55it/s]\titers: 500, epoch: 12 | loss: 0.1615561\n",
      "\tspeed: 0.1073s/iter; left time: 3581.4129s\n",
      "599it [01:04,  9.51it/s]\titers: 600, epoch: 12 | loss: 0.1828732\n",
      "\tspeed: 0.1049s/iter; left time: 3490.4000s\n",
      "699it [01:15,  9.56it/s]\titers: 700, epoch: 12 | loss: 0.1864735\n",
      "\tspeed: 0.1098s/iter; left time: 3643.7965s\n",
      "798it [01:25,  9.60it/s]\titers: 800, epoch: 12 | loss: 0.2307299\n",
      "\tspeed: 0.1035s/iter; left time: 3425.3803s\n",
      "899it [01:36,  9.96it/s]\titers: 900, epoch: 12 | loss: 0.3113188\n",
      "\tspeed: 0.1079s/iter; left time: 3557.9079s\n",
      "999it [01:47,  9.80it/s]\titers: 1000, epoch: 12 | loss: 0.2383570\n",
      "\tspeed: 0.1044s/iter; left time: 3432.8477s\n",
      "1099it [01:58,  9.37it/s]\titers: 1100, epoch: 12 | loss: 0.1591633\n",
      "\tspeed: 0.1085s/iter; left time: 3557.9697s\n",
      "1199it [02:09,  9.30it/s]\titers: 1200, epoch: 12 | loss: 0.4656069\n",
      "\tspeed: 0.1119s/iter; left time: 3658.5057s\n",
      "1299it [02:20,  9.22it/s]\titers: 1300, epoch: 12 | loss: 0.1292953\n",
      "\tspeed: 0.1093s/iter; left time: 3560.7673s\n",
      "1399it [02:31,  8.59it/s]\titers: 1400, epoch: 12 | loss: 0.1644338\n",
      "\tspeed: 0.1138s/iter; left time: 3697.3480s\n",
      "1499it [02:42,  9.05it/s]\titers: 1500, epoch: 12 | loss: 0.3327014\n",
      "\tspeed: 0.1096s/iter; left time: 3550.5242s\n",
      "1599it [02:53,  8.96it/s]\titers: 1600, epoch: 12 | loss: 0.4618825\n",
      "\tspeed: 0.1117s/iter; left time: 3605.0499s\n",
      "1699it [03:04,  9.17it/s]\titers: 1700, epoch: 12 | loss: 0.2019073\n",
      "\tspeed: 0.1090s/iter; left time: 3509.3451s\n",
      "1798it [03:15,  9.45it/s]\titers: 1800, epoch: 12 | loss: 0.5016454\n",
      "\tspeed: 0.1125s/iter; left time: 3609.6365s\n",
      "1899it [03:26,  8.68it/s]\titers: 1900, epoch: 12 | loss: 0.1364064\n",
      "\tspeed: 0.1089s/iter; left time: 3484.3390s\n",
      "1999it [03:37,  9.32it/s]\titers: 2000, epoch: 12 | loss: 0.2250724\n",
      "\tspeed: 0.1112s/iter; left time: 3546.3642s\n",
      "2099it [03:48,  8.60it/s]\titers: 2100, epoch: 12 | loss: 0.1591920\n",
      "\tspeed: 0.1080s/iter; left time: 3433.0556s\n",
      "2199it [03:59,  9.33it/s]\titers: 2200, epoch: 12 | loss: 0.2809311\n",
      "\tspeed: 0.1082s/iter; left time: 3427.1437s\n",
      "2299it [04:10,  9.18it/s]\titers: 2300, epoch: 12 | loss: 0.1750271\n",
      "\tspeed: 0.1106s/iter; left time: 3493.2171s\n",
      "2399it [04:21,  9.14it/s]\titers: 2400, epoch: 12 | loss: 0.0954402\n",
      "\tspeed: 0.1066s/iter; left time: 3356.3451s\n",
      "2499it [04:32,  9.18it/s]\titers: 2500, epoch: 12 | loss: 0.1508003\n",
      "\tspeed: 0.1106s/iter; left time: 3472.5678s\n",
      "2599it [04:43,  9.14it/s]\titers: 2600, epoch: 12 | loss: 0.1688677\n",
      "\tspeed: 0.1077s/iter; left time: 3369.4372s\n",
      "2699it [04:54,  8.34it/s]\titers: 2700, epoch: 12 | loss: 0.3628941\n",
      "\tspeed: 0.1116s/iter; left time: 3480.0537s\n",
      "2799it [05:04,  9.30it/s]\titers: 2800, epoch: 12 | loss: 0.1929711\n",
      "\tspeed: 0.1074s/iter; left time: 3337.3173s\n",
      "2899it [05:16,  9.12it/s]\titers: 2900, epoch: 12 | loss: 0.1826122\n",
      "\tspeed: 0.1128s/iter; left time: 3496.1765s\n",
      "2999it [05:27,  8.81it/s]\titers: 3000, epoch: 12 | loss: 0.3986395\n",
      "\tspeed: 0.1085s/iter; left time: 3351.2216s\n",
      "3099it [05:38,  9.56it/s]\titers: 3100, epoch: 12 | loss: 0.3112746\n",
      "\tspeed: 0.1134s/iter; left time: 3489.6549s\n",
      "3199it [05:49,  9.35it/s]\titers: 3200, epoch: 12 | loss: 0.2156391\n",
      "\tspeed: 0.1109s/iter; left time: 3402.8943s\n",
      "3299it [06:00,  9.35it/s]\titers: 3300, epoch: 12 | loss: 0.2692370\n",
      "\tspeed: 0.1072s/iter; left time: 3279.1939s\n",
      "3399it [06:11,  9.42it/s]\titers: 3400, epoch: 12 | loss: 0.1785697\n",
      "\tspeed: 0.1096s/iter; left time: 3339.9097s\n",
      "3499it [06:22,  9.23it/s]\titers: 3500, epoch: 12 | loss: 0.2638203\n",
      "\tspeed: 0.1091s/iter; left time: 3314.3730s\n",
      "3599it [06:33,  9.32it/s]\titers: 3600, epoch: 12 | loss: 0.3289876\n",
      "\tspeed: 0.1122s/iter; left time: 3398.2805s\n",
      "3699it [06:43,  9.43it/s]\titers: 3700, epoch: 12 | loss: 0.2729000\n",
      "\tspeed: 0.1048s/iter; left time: 3162.8303s\n",
      "3765it [06:51,  9.16it/s]\n",
      "Epoch: 12 cost time: 411.1880190372467\n",
      "810it [00:39, 20.45it/s]\n",
      "807it [00:39, 20.66it/s]\n",
      "Epoch: 12 | Train Loss: 0.2337841 Vali Loss: 0.2808911 Test Loss: 0.3492676 MAE Loss: 0.3543388\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "98it [00:11,  9.47it/s]\titers: 100, epoch: 13 | loss: 0.3362105\n",
      "\tspeed: 0.9760s/iter; left time: 29300.1547s\n",
      "199it [00:22,  9.65it/s]\titers: 200, epoch: 13 | loss: 0.1477616\n",
      "\tspeed: 0.1111s/iter; left time: 3324.5997s\n",
      "299it [00:33,  9.69it/s]\titers: 300, epoch: 13 | loss: 0.1589456\n",
      "\tspeed: 0.1066s/iter; left time: 3178.4128s\n",
      "399it [00:44,  9.35it/s]\titers: 400, epoch: 13 | loss: 0.1681641\n",
      "\tspeed: 0.1111s/iter; left time: 3303.1864s\n",
      "499it [00:54,  9.33it/s]\titers: 500, epoch: 13 | loss: 0.2840580\n",
      "\tspeed: 0.1055s/iter; left time: 3125.8846s\n",
      "599it [01:06,  9.15it/s]\titers: 600, epoch: 13 | loss: 0.1988679\n",
      "\tspeed: 0.1129s/iter; left time: 3333.3480s\n",
      "698it [01:16,  9.26it/s]\titers: 700, epoch: 13 | loss: 0.1428153\n",
      "\tspeed: 0.1062s/iter; left time: 3124.4401s\n",
      "799it [01:27,  9.48it/s]\titers: 800, epoch: 13 | loss: 0.2407028\n",
      "\tspeed: 0.1062s/iter; left time: 3115.2895s\n",
      "899it [01:38,  9.95it/s]\titers: 900, epoch: 13 | loss: 0.2220701\n",
      "\tspeed: 0.1078s/iter; left time: 3149.3804s\n",
      "999it [01:48,  9.64it/s]\titers: 1000, epoch: 13 | loss: 0.2569728\n",
      "\tspeed: 0.1068s/iter; left time: 3108.8771s\n",
      "1099it [01:59,  9.62it/s]\titers: 1100, epoch: 13 | loss: 0.2117180\n",
      "\tspeed: 0.1082s/iter; left time: 3138.8706s\n",
      "1199it [02:10,  9.46it/s]\titers: 1200, epoch: 13 | loss: 0.2115802\n",
      "\tspeed: 0.1047s/iter; left time: 3029.1695s\n",
      "1299it [02:20,  9.66it/s]\titers: 1300, epoch: 13 | loss: 0.2062632\n",
      "\tspeed: 0.1074s/iter; left time: 3096.6749s\n",
      "1399it [02:31,  9.82it/s]\titers: 1400, epoch: 13 | loss: 0.2595464\n",
      "\tspeed: 0.1075s/iter; left time: 3087.3412s\n",
      "1499it [02:42,  9.68it/s]\titers: 1500, epoch: 13 | loss: 0.4534394\n",
      "\tspeed: 0.1121s/iter; left time: 3209.2824s\n",
      "1599it [02:53,  9.25it/s]\titers: 1600, epoch: 13 | loss: 0.1993464\n",
      "\tspeed: 0.1071s/iter; left time: 3054.8149s\n",
      "1699it [03:04,  9.17it/s]\titers: 1700, epoch: 13 | loss: 0.2447704\n",
      "\tspeed: 0.1099s/iter; left time: 3123.6623s\n",
      "1799it [03:15,  9.31it/s]\titers: 1800, epoch: 13 | loss: 0.1824096\n",
      "\tspeed: 0.1073s/iter; left time: 3038.8471s\n",
      "1899it [03:26,  9.39it/s]\titers: 1900, epoch: 13 | loss: 0.3147148\n",
      "\tspeed: 0.1087s/iter; left time: 3068.4556s\n",
      "1999it [03:36,  8.39it/s]\titers: 2000, epoch: 13 | loss: 0.1745521\n",
      "\tspeed: 0.1078s/iter; left time: 3031.4979s\n",
      "2099it [03:47,  9.49it/s]\titers: 2100, epoch: 13 | loss: 0.1882442\n",
      "\tspeed: 0.1062s/iter; left time: 2975.5280s\n",
      "2199it [03:58,  9.51it/s]\titers: 2200, epoch: 13 | loss: 0.2789165\n",
      "\tspeed: 0.1059s/iter; left time: 2956.1652s\n",
      "2299it [04:08,  9.64it/s]\titers: 2300, epoch: 13 | loss: 0.1682907\n",
      "\tspeed: 0.1045s/iter; left time: 2907.7091s\n",
      "2399it [04:19,  9.79it/s]\titers: 2400, epoch: 13 | loss: 0.2113981\n",
      "\tspeed: 0.1063s/iter; left time: 2945.7863s\n",
      "2499it [04:30,  9.21it/s]\titers: 2500, epoch: 13 | loss: 0.2018636\n",
      "\tspeed: 0.1079s/iter; left time: 2978.9841s\n",
      "2599it [04:40,  9.64it/s]\titers: 2600, epoch: 13 | loss: 0.2715619\n",
      "\tspeed: 0.1088s/iter; left time: 2994.2637s\n",
      "2699it [04:51,  9.38it/s]\titers: 2700, epoch: 13 | loss: 0.1428440\n",
      "\tspeed: 0.1034s/iter; left time: 2836.2552s\n",
      "2799it [05:02,  9.05it/s]\titers: 2800, epoch: 13 | loss: 0.2531872\n",
      "\tspeed: 0.1091s/iter; left time: 2980.7858s\n",
      "2899it [05:13,  8.96it/s]\titers: 2900, epoch: 13 | loss: 0.1315245\n",
      "\tspeed: 0.1092s/iter; left time: 2972.8619s\n",
      "2999it [05:23, 10.18it/s]\titers: 3000, epoch: 13 | loss: 0.2280157\n",
      "\tspeed: 0.1077s/iter; left time: 2920.1001s\n",
      "3099it [05:34,  9.47it/s]\titers: 3100, epoch: 13 | loss: 0.2598972\n",
      "\tspeed: 0.1038s/iter; left time: 2803.9943s\n",
      "3199it [05:44,  9.61it/s]\titers: 3200, epoch: 13 | loss: 0.1496727\n",
      "\tspeed: 0.1051s/iter; left time: 2828.6015s\n",
      "3299it [05:55,  8.90it/s]\titers: 3300, epoch: 13 | loss: 0.3098501\n",
      "\tspeed: 0.1122s/iter; left time: 3010.1053s\n",
      "3399it [06:06,  9.61it/s]\titers: 3400, epoch: 13 | loss: 0.1922676\n",
      "\tspeed: 0.1046s/iter; left time: 2795.1129s\n",
      "3499it [06:17,  9.61it/s]\titers: 3500, epoch: 13 | loss: 0.1808806\n",
      "\tspeed: 0.1090s/iter; left time: 2900.9773s\n",
      "3598it [06:27,  9.31it/s]\titers: 3600, epoch: 13 | loss: 0.2485105\n",
      "\tspeed: 0.1047s/iter; left time: 2777.4688s\n",
      "3699it [06:38,  9.46it/s]\titers: 3700, epoch: 13 | loss: 0.3037823\n",
      "\tspeed: 0.1080s/iter; left time: 2852.2894s\n",
      "3765it [06:45,  9.28it/s]\n",
      "Epoch: 13 cost time: 405.6518449783325\n",
      "810it [00:43, 18.80it/s]\n",
      "807it [00:51, 15.73it/s]\n",
      "Epoch: 13 | Train Loss: 0.2333985 Vali Loss: 0.2808090 Test Loss: 0.3491333 MAE Loss: 0.3541619\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "99it [00:13,  9.66it/s]\titers: 100, epoch: 14 | loss: 0.3863677\n",
      "\tspeed: 1.1532s/iter; left time: 30279.2464s\n",
      "199it [00:28,  3.94it/s]\titers: 200, epoch: 14 | loss: 0.1034165\n",
      "\tspeed: 0.1451s/iter; left time: 3795.6949s\n",
      "299it [00:42,  9.06it/s]\titers: 300, epoch: 14 | loss: 0.3730589\n",
      "\tspeed: 0.1400s/iter; left time: 3648.4481s\n",
      "399it [00:55,  4.13it/s]\titers: 400, epoch: 14 | loss: 0.1873746\n",
      "\tspeed: 0.1285s/iter; left time: 3335.6276s\n",
      "499it [01:09,  3.66it/s]\titers: 500, epoch: 14 | loss: 0.1666247\n",
      "\tspeed: 0.1417s/iter; left time: 3663.8050s\n",
      "599it [01:22,  4.89it/s]\titers: 600, epoch: 14 | loss: 0.3071131\n",
      "\tspeed: 0.1359s/iter; left time: 3499.6694s\n",
      "699it [01:36,  9.39it/s]\titers: 700, epoch: 14 | loss: 0.1818582\n",
      "\tspeed: 0.1342s/iter; left time: 3442.3860s\n",
      "799it [01:49,  9.73it/s]\titers: 800, epoch: 14 | loss: 0.1756371\n",
      "\tspeed: 0.1355s/iter; left time: 3463.8570s\n",
      "899it [02:03,  9.71it/s]\titers: 900, epoch: 14 | loss: 0.3430182\n",
      "\tspeed: 0.1358s/iter; left time: 3456.9154s\n",
      "998it [02:16,  9.67it/s]\titers: 1000, epoch: 14 | loss: 0.3203391\n",
      "\tspeed: 0.1359s/iter; left time: 3445.3859s\n",
      "1099it [02:30,  9.62it/s]\titers: 1100, epoch: 14 | loss: 0.3448130\n",
      "\tspeed: 0.1354s/iter; left time: 3420.1075s\n",
      "1199it [02:45,  6.00it/s]\titers: 1200, epoch: 14 | loss: 0.1542165\n",
      "\tspeed: 0.1512s/iter; left time: 3804.2230s\n",
      "1298it [02:59,  9.69it/s]\titers: 1300, epoch: 14 | loss: 0.1624537\n",
      "\tspeed: 0.1353s/iter; left time: 3390.8495s\n",
      "1399it [03:12,  9.50it/s]\titers: 1400, epoch: 14 | loss: 0.3461871\n",
      "\tspeed: 0.1350s/iter; left time: 3369.2321s\n",
      "1499it [03:26,  9.51it/s]\titers: 1500, epoch: 14 | loss: 0.1170795\n",
      "\tspeed: 0.1355s/iter; left time: 3366.9063s\n",
      "1599it [03:39,  7.01it/s]\titers: 1600, epoch: 14 | loss: 0.1710199\n",
      "\tspeed: 0.1347s/iter; left time: 3333.7117s\n",
      "1698it [03:53,  9.55it/s]\titers: 1700, epoch: 14 | loss: 0.1746632\n",
      "\tspeed: 0.1347s/iter; left time: 3321.3781s\n",
      "1799it [04:06,  7.11it/s]\titers: 1800, epoch: 14 | loss: 0.3030184\n",
      "\tspeed: 0.1377s/iter; left time: 3381.9123s\n",
      "1899it [04:20,  9.54it/s]\titers: 1900, epoch: 14 | loss: 0.1916448\n",
      "\tspeed: 0.1330s/iter; left time: 3252.3349s\n",
      "1998it [04:33,  9.57it/s]\titers: 2000, epoch: 14 | loss: 0.2229933\n",
      "\tspeed: 0.1354s/iter; left time: 3298.0918s\n",
      "2099it [04:47,  9.79it/s]\titers: 2100, epoch: 14 | loss: 0.4312854\n",
      "\tspeed: 0.1355s/iter; left time: 3285.8830s\n",
      "2199it [05:00,  9.65it/s]\titers: 2200, epoch: 14 | loss: 0.2023392\n",
      "\tspeed: 0.1351s/iter; left time: 3263.6609s\n",
      "2299it [05:14,  6.63it/s]\titers: 2300, epoch: 14 | loss: 0.1697642\n",
      "\tspeed: 0.1379s/iter; left time: 3318.3009s\n",
      "2399it [05:28,  5.12it/s]\titers: 2400, epoch: 14 | loss: 0.4923284\n",
      "\tspeed: 0.1380s/iter; left time: 3305.4953s\n",
      "2498it [05:41,  9.69it/s]\titers: 2500, epoch: 14 | loss: 0.2669123\n",
      "\tspeed: 0.1300s/iter; left time: 3100.2532s\n",
      "2599it [05:55,  9.65it/s]\titers: 2600, epoch: 14 | loss: 0.2077136\n",
      "\tspeed: 0.1353s/iter; left time: 3215.1306s\n",
      "2699it [06:08,  9.54it/s]\titers: 2700, epoch: 14 | loss: 0.2082514\n",
      "\tspeed: 0.1352s/iter; left time: 3198.3769s\n",
      "2799it [06:22,  9.62it/s]\titers: 2800, epoch: 14 | loss: 0.1641709\n",
      "\tspeed: 0.1351s/iter; left time: 3183.1441s\n",
      "2899it [06:37,  7.71it/s]\titers: 2900, epoch: 14 | loss: 0.2350979\n",
      "\tspeed: 0.1513s/iter; left time: 3548.8944s\n",
      "2999it [06:50,  6.73it/s]\titers: 3000, epoch: 14 | loss: 0.1336308\n",
      "\tspeed: 0.1358s/iter; left time: 3171.0746s\n",
      "3098it [07:04,  6.86it/s]\titers: 3100, epoch: 14 | loss: 0.3312708\n",
      "\tspeed: 0.1357s/iter; left time: 3155.8169s\n",
      "3199it [07:17,  9.67it/s]\titers: 3200, epoch: 14 | loss: 0.1275646\n",
      "\tspeed: 0.1353s/iter; left time: 3133.0079s\n",
      "3298it [07:31,  9.76it/s]\titers: 3300, epoch: 14 | loss: 0.1126211\n",
      "\tspeed: 0.1346s/iter; left time: 3104.2625s\n",
      "3399it [07:44,  9.68it/s]\titers: 3400, epoch: 14 | loss: 0.3241873\n",
      "\tspeed: 0.1352s/iter; left time: 3102.8873s\n",
      "3499it [07:58,  9.67it/s]\titers: 3500, epoch: 14 | loss: 0.2679831\n",
      "\tspeed: 0.1349s/iter; left time: 3082.8838s\n",
      "3599it [08:11,  8.71it/s]\titers: 3600, epoch: 14 | loss: 0.0938485\n",
      "\tspeed: 0.1357s/iter; left time: 3087.7131s\n",
      "3698it [08:25,  9.37it/s]\titers: 3700, epoch: 14 | loss: 0.2314561\n",
      "\tspeed: 0.1356s/iter; left time: 3073.2758s\n",
      "3765it [08:33,  7.33it/s]\n",
      "Epoch: 14 cost time: 513.9695999622345\n",
      "810it [00:50, 16.16it/s]\n",
      "807it [00:49, 16.15it/s]\n",
      "Epoch: 14 | Train Loss: 0.2333696 Vali Loss: 0.2807267 Test Loss: 0.3491375 MAE Loss: 0.3542327\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "99it [00:13,  9.51it/s]\titers: 100, epoch: 15 | loss: 0.1975555\n",
      "\tspeed: 1.2253s/iter; left time: 27558.0101s\n",
      "199it [00:27,  9.78it/s]\titers: 200, epoch: 15 | loss: 0.4405577\n",
      "\tspeed: 0.1354s/iter; left time: 3030.7954s\n",
      "299it [00:40,  9.73it/s]\titers: 300, epoch: 15 | loss: 0.2479765\n",
      "\tspeed: 0.1347s/iter; left time: 3001.5713s\n",
      "399it [00:54,  9.65it/s]\titers: 400, epoch: 15 | loss: 0.2251632\n",
      "\tspeed: 0.1346s/iter; left time: 2986.8998s\n",
      "499it [01:07,  9.87it/s]\titers: 500, epoch: 15 | loss: 0.3850349\n",
      "\tspeed: 0.1348s/iter; left time: 2977.2059s\n",
      "599it [01:21,  9.63it/s]\titers: 600, epoch: 15 | loss: 0.1419098\n",
      "\tspeed: 0.1354s/iter; left time: 2976.9891s\n",
      "699it [01:34,  9.76it/s]\titers: 700, epoch: 15 | loss: 0.2665705\n",
      "\tspeed: 0.1351s/iter; left time: 2956.6515s\n",
      "798it [01:48,  9.72it/s]\titers: 800, epoch: 15 | loss: 0.2190610\n",
      "\tspeed: 0.1352s/iter; left time: 2945.2745s\n",
      "899it [02:01,  9.74it/s]\titers: 900, epoch: 15 | loss: 0.3130034\n",
      "\tspeed: 0.1357s/iter; left time: 2942.5844s\n",
      "999it [02:15,  9.64it/s]\titers: 1000, epoch: 15 | loss: 0.2516190\n",
      "\tspeed: 0.1353s/iter; left time: 2921.3778s\n",
      "1099it [02:29,  9.55it/s]\titers: 1100, epoch: 15 | loss: 0.2180743\n",
      "\tspeed: 0.1355s/iter; left time: 2911.1892s\n",
      "1199it [02:42,  9.73it/s]\titers: 1200, epoch: 15 | loss: 0.2685801\n",
      "\tspeed: 0.1356s/iter; left time: 2900.0863s\n",
      "1299it [02:56,  9.74it/s]\titers: 1300, epoch: 15 | loss: 0.1720230\n",
      "\tspeed: 0.1345s/iter; left time: 2863.4469s\n",
      "1399it [03:09,  9.41it/s]\titers: 1400, epoch: 15 | loss: 0.1908010\n",
      "\tspeed: 0.1362s/iter; left time: 2885.7574s\n",
      "1498it [03:23,  9.61it/s]\titers: 1500, epoch: 15 | loss: 0.3134522\n",
      "\tspeed: 0.1356s/iter; left time: 2860.3944s\n",
      "1599it [03:36,  9.73it/s]\titers: 1600, epoch: 15 | loss: 0.1826265\n",
      "\tspeed: 0.1344s/iter; left time: 2820.1739s\n",
      "1698it [03:50,  9.39it/s]\titers: 1700, epoch: 15 | loss: 0.1812316\n",
      "\tspeed: 0.1351s/iter; left time: 2822.0234s\n",
      "1798it [04:03,  6.17it/s]\titers: 1800, epoch: 15 | loss: 0.2817172\n",
      "\tspeed: 0.1373s/iter; left time: 2854.2767s\n",
      "1899it [04:17,  9.16it/s]\titers: 1900, epoch: 15 | loss: 0.3217671\n",
      "\tspeed: 0.1380s/iter; left time: 2855.0721s\n",
      "1999it [04:31,  9.48it/s]\titers: 2000, epoch: 15 | loss: 0.2408595\n",
      "\tspeed: 0.1371s/iter; left time: 2822.2509s\n",
      "2099it [04:45,  9.62it/s]\titers: 2100, epoch: 15 | loss: 0.2187961\n",
      "\tspeed: 0.1377s/iter; left time: 2820.7026s\n",
      "2199it [04:58,  9.67it/s]\titers: 2200, epoch: 15 | loss: 0.2327244\n",
      "\tspeed: 0.1372s/iter; left time: 2797.5762s\n",
      "2299it [05:12,  9.70it/s]\titers: 2300, epoch: 15 | loss: 0.1658186\n",
      "\tspeed: 0.1349s/iter; left time: 2736.3037s\n",
      "2399it [05:25,  9.77it/s]\titers: 2400, epoch: 15 | loss: 0.2931226\n",
      "\tspeed: 0.1349s/iter; left time: 2724.6072s\n",
      "2499it [05:39,  9.64it/s]\titers: 2500, epoch: 15 | loss: 0.3092394\n",
      "\tspeed: 0.1356s/iter; left time: 2723.9997s\n",
      "2599it [05:53,  6.70it/s]\titers: 2600, epoch: 15 | loss: 0.2860564\n",
      "\tspeed: 0.1390s/iter; left time: 2777.8900s\n",
      "2698it [06:06,  9.78it/s]\titers: 2700, epoch: 15 | loss: 0.1876989\n",
      "\tspeed: 0.1341s/iter; left time: 2667.5611s\n",
      "2799it [06:20,  9.75it/s]\titers: 2800, epoch: 15 | loss: 0.2462531\n",
      "\tspeed: 0.1353s/iter; left time: 2678.5323s\n",
      "2899it [06:33,  9.56it/s]\titers: 2900, epoch: 15 | loss: 0.3218998\n",
      "\tspeed: 0.1353s/iter; left time: 2663.6630s\n",
      "2999it [06:47,  9.45it/s]\titers: 3000, epoch: 15 | loss: 0.1877180\n",
      "\tspeed: 0.1389s/iter; left time: 2721.1926s\n",
      "3099it [07:01,  9.76it/s]\titers: 3100, epoch: 15 | loss: 0.2781151\n",
      "\tspeed: 0.1358s/iter; left time: 2647.5784s\n",
      "3199it [07:14,  9.12it/s]\titers: 3200, epoch: 15 | loss: 0.3083299\n",
      "\tspeed: 0.1354s/iter; left time: 2624.7191s\n",
      "3299it [07:28,  9.50it/s]\titers: 3300, epoch: 15 | loss: 0.1406376\n",
      "\tspeed: 0.1390s/iter; left time: 2681.1792s\n",
      "3399it [07:42,  9.48it/s]\titers: 3400, epoch: 15 | loss: 0.1498336\n",
      "\tspeed: 0.1383s/iter; left time: 2653.8699s\n",
      "3499it [07:56,  9.42it/s]\titers: 3500, epoch: 15 | loss: 0.1887756\n",
      "\tspeed: 0.1377s/iter; left time: 2629.0422s\n",
      "3599it [08:10,  9.41it/s]\titers: 3600, epoch: 15 | loss: 0.2406267\n",
      "\tspeed: 0.1382s/iter; left time: 2625.4771s\n",
      "3699it [08:23,  9.39it/s]\titers: 3700, epoch: 15 | loss: 0.1049828\n",
      "\tspeed: 0.1377s/iter; left time: 2601.2466s\n",
      "3765it [08:34,  7.32it/s]\n",
      "Epoch: 15 cost time: 514.0326642990112\n",
      "810it [00:48, 16.66it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 15 | Train Loss: 0.2335377 Vali Loss: 0.2807547 Test Loss: 0.3491512 MAE Loss: 0.3542560\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.4414062499999998e-09\n",
      "99it [00:13,  7.34it/s]\titers: 100, epoch: 16 | loss: 0.2052431\n",
      "\tspeed: 1.2101s/iter; left time: 22660.5528s\n",
      "199it [00:27, 10.03it/s]\titers: 200, epoch: 16 | loss: 0.1398610\n",
      "\tspeed: 0.1330s/iter; left time: 2477.8740s\n",
      "299it [00:40,  9.82it/s]\titers: 300, epoch: 16 | loss: 0.2716383\n",
      "\tspeed: 0.1358s/iter; left time: 2516.0479s\n",
      "399it [00:54,  9.88it/s]\titers: 400, epoch: 16 | loss: 0.1362100\n",
      "\tspeed: 0.1352s/iter; left time: 2490.5631s\n",
      "499it [01:07,  9.69it/s]\titers: 500, epoch: 16 | loss: 0.1250075\n",
      "\tspeed: 0.1346s/iter; left time: 2466.0865s\n",
      "599it [01:21,  9.19it/s]\titers: 600, epoch: 16 | loss: 0.3821145\n",
      "\tspeed: 0.1364s/iter; left time: 2486.5961s\n",
      "699it [01:35,  4.71it/s]\titers: 700, epoch: 16 | loss: 0.1484954\n",
      "\tspeed: 0.1476s/iter; left time: 2676.0752s\n",
      "799it [01:50,  3.86it/s]\titers: 800, epoch: 16 | loss: 0.2339084\n",
      "\tspeed: 0.1437s/iter; left time: 2590.1252s\n",
      "899it [02:02,  8.97it/s]\titers: 900, epoch: 16 | loss: 0.2846689\n",
      "\tspeed: 0.1240s/iter; left time: 2222.8790s\n",
      "998it [02:16,  9.64it/s]\titers: 1000, epoch: 16 | loss: 0.2870998\n",
      "\tspeed: 0.1344s/iter; left time: 2396.0349s\n",
      "1099it [02:29,  9.80it/s]\titers: 1100, epoch: 16 | loss: 0.1882836\n",
      "\tspeed: 0.1344s/iter; left time: 2381.8871s\n",
      "1199it [02:43,  9.60it/s]\titers: 1200, epoch: 16 | loss: 0.4896719\n",
      "\tspeed: 0.1348s/iter; left time: 2376.3598s\n",
      "1299it [02:56,  8.54it/s]\titers: 1300, epoch: 16 | loss: 0.1874782\n",
      "\tspeed: 0.1374s/iter; left time: 2407.9122s\n",
      "1399it [03:11,  3.97it/s]\titers: 1400, epoch: 16 | loss: 0.2069475\n",
      "\tspeed: 0.1452s/iter; left time: 2530.7711s\n",
      "1499it [03:23,  9.02it/s]\titers: 1500, epoch: 16 | loss: 0.1760991\n",
      "\tspeed: 0.1243s/iter; left time: 2153.3870s\n",
      "1599it [03:37,  9.34it/s]\titers: 1600, epoch: 16 | loss: 0.3296472\n",
      "\tspeed: 0.1337s/iter; left time: 2303.6156s\n",
      "1699it [03:51,  9.72it/s]\titers: 1700, epoch: 16 | loss: 0.1719277\n",
      "\tspeed: 0.1397s/iter; left time: 2392.4259s\n",
      "1799it [04:04,  9.75it/s]\titers: 1800, epoch: 16 | loss: 0.1191543\n",
      "\tspeed: 0.1356s/iter; left time: 2308.0709s\n",
      "1899it [04:18,  9.79it/s]\titers: 1900, epoch: 16 | loss: 0.1440190\n",
      "\tspeed: 0.1353s/iter; left time: 2289.9408s\n",
      "1999it [04:31,  9.89it/s]\titers: 2000, epoch: 16 | loss: 0.1751920\n",
      "\tspeed: 0.1348s/iter; left time: 2267.9932s\n",
      "2098it [04:45,  9.81it/s]\titers: 2100, epoch: 16 | loss: 0.1687019\n",
      "\tspeed: 0.1356s/iter; left time: 2268.6394s\n",
      "2198it [04:58,  6.33it/s]\titers: 2200, epoch: 16 | loss: 0.1841564\n",
      "\tspeed: 0.1353s/iter; left time: 2250.0900s\n",
      "2299it [05:12,  9.28it/s]\titers: 2300, epoch: 16 | loss: 0.2242603\n",
      "\tspeed: 0.1378s/iter; left time: 2277.9856s\n",
      "2399it [05:26,  7.91it/s]\titers: 2400, epoch: 16 | loss: 0.1329996\n",
      "\tspeed: 0.1363s/iter; left time: 2238.2521s\n",
      "2499it [05:39,  9.08it/s]\titers: 2500, epoch: 16 | loss: 0.2083606\n",
      "\tspeed: 0.1354s/iter; left time: 2211.1553s\n",
      "2599it [05:53,  9.57it/s]\titers: 2600, epoch: 16 | loss: 0.1550801\n",
      "\tspeed: 0.1352s/iter; left time: 2194.3410s\n",
      "2699it [06:06,  6.55it/s]\titers: 2700, epoch: 16 | loss: 0.2257742\n",
      "\tspeed: 0.1363s/iter; left time: 2197.9111s\n",
      "2799it [06:18,  6.91it/s]\titers: 2800, epoch: 16 | loss: 0.2924374\n",
      "\tspeed: 0.1203s/iter; left time: 1927.5931s\n",
      "2899it [06:33,  4.52it/s]\titers: 2900, epoch: 16 | loss: 0.2393765\n",
      "\tspeed: 0.1487s/iter; left time: 2367.8732s\n",
      "2999it [06:46,  5.05it/s]\titers: 3000, epoch: 16 | loss: 0.1276661\n",
      "\tspeed: 0.1251s/iter; left time: 1979.7278s\n",
      "3099it [07:00,  4.56it/s]\titers: 3100, epoch: 16 | loss: 0.2254440\n",
      "\tspeed: 0.1447s/iter; left time: 2275.0899s\n",
      "3199it [07:12, 10.09it/s]\titers: 3200, epoch: 16 | loss: 0.1343989\n",
      "\tspeed: 0.1191s/iter; left time: 1860.7809s\n",
      "3299it [07:26,  9.59it/s]\titers: 3300, epoch: 16 | loss: 0.4312514\n",
      "\tspeed: 0.1364s/iter; left time: 2117.9060s\n",
      "3399it [07:39,  9.62it/s]\titers: 3400, epoch: 16 | loss: 0.3534585\n",
      "\tspeed: 0.1348s/iter; left time: 2079.8800s\n",
      "3499it [07:53,  9.83it/s]\titers: 3500, epoch: 16 | loss: 0.3077425\n",
      "\tspeed: 0.1351s/iter; left time: 2071.2471s\n",
      "3599it [08:06,  9.45it/s]\titers: 3600, epoch: 16 | loss: 0.1545011\n",
      "\tspeed: 0.1358s/iter; left time: 2068.1232s\n",
      "3699it [08:20,  9.78it/s]\titers: 3700, epoch: 16 | loss: 0.4054082\n",
      "\tspeed: 0.1354s/iter; left time: 2048.3328s\n",
      "3765it [08:28,  7.40it/s]\n",
      "Epoch: 16 cost time: 508.87806272506714\n",
      "810it [00:50, 16.13it/s]\n",
      "807it [00:49, 16.25it/s]\n",
      "Epoch: 16 | Train Loss: 0.2334517 Vali Loss: 0.2807871 Test Loss: 0.3491733 MAE Loss: 0.3542686\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2207031249999999e-09\n",
      "99it [00:13,  9.81it/s]\titers: 100, epoch: 17 | loss: 0.1608212\n",
      "\tspeed: 1.2217s/iter; left time: 18278.1997s\n",
      "199it [00:27,  9.74it/s]\titers: 200, epoch: 17 | loss: 0.2550369\n",
      "\tspeed: 0.1352s/iter; left time: 2009.1105s\n",
      "299it [00:40,  9.55it/s]\titers: 300, epoch: 17 | loss: 0.1719689\n",
      "\tspeed: 0.1354s/iter; left time: 1998.2270s\n",
      "399it [00:54,  8.80it/s]\titers: 400, epoch: 17 | loss: 0.1944816\n",
      "\tspeed: 0.1349s/iter; left time: 1977.5843s\n",
      "499it [01:06,  5.77it/s]\titers: 500, epoch: 17 | loss: 0.2919102\n",
      "\tspeed: 0.1219s/iter; left time: 1774.3476s\n",
      "599it [01:21,  9.42it/s]\titers: 600, epoch: 17 | loss: 0.1946203\n",
      "\tspeed: 0.1470s/iter; left time: 2126.4269s\n",
      "699it [01:34,  8.15it/s]\titers: 700, epoch: 17 | loss: 0.3219073\n",
      "\tspeed: 0.1361s/iter; left time: 1953.8758s\n",
      "798it [01:48,  9.45it/s]\titers: 800, epoch: 17 | loss: 0.2349289\n",
      "\tspeed: 0.1351s/iter; left time: 1925.9545s\n",
      "899it [02:01,  8.00it/s]\titers: 900, epoch: 17 | loss: 0.4002778\n",
      "\tspeed: 0.1357s/iter; left time: 1922.2242s\n",
      "999it [02:13,  9.73it/s]\titers: 1000, epoch: 17 | loss: 0.2985493\n",
      "\tspeed: 0.1195s/iter; left time: 1679.9261s\n",
      "1099it [02:28,  6.95it/s]\titers: 1100, epoch: 17 | loss: 0.3871070\n",
      "\tspeed: 0.1510s/iter; left time: 2107.8553s\n",
      "1199it [02:42,  3.84it/s]\titers: 1200, epoch: 17 | loss: 0.2572240\n",
      "\tspeed: 0.1348s/iter; left time: 1867.9419s\n",
      "1299it [02:56,  5.64it/s]\titers: 1300, epoch: 17 | loss: 0.2535135\n",
      "\tspeed: 0.1357s/iter; left time: 1866.8248s\n",
      "1399it [03:09,  7.62it/s]\titers: 1400, epoch: 17 | loss: 0.2375524\n",
      "\tspeed: 0.1350s/iter; left time: 1843.9154s\n",
      "1499it [03:22,  4.28it/s]\titers: 1500, epoch: 17 | loss: 0.2001255\n",
      "\tspeed: 0.1273s/iter; left time: 1725.6899s\n",
      "1599it [03:34,  9.70it/s]\titers: 1600, epoch: 17 | loss: 0.2111700\n",
      "\tspeed: 0.1262s/iter; left time: 1698.4306s\n",
      "1699it [03:49,  4.27it/s]\titers: 1700, epoch: 17 | loss: 0.1585602\n",
      "\tspeed: 0.1511s/iter; left time: 2018.1972s\n",
      "1799it [04:02,  4.57it/s]\titers: 1800, epoch: 17 | loss: 0.2108273\n",
      "\tspeed: 0.1261s/iter; left time: 1672.2431s\n",
      "1899it [04:17,  6.63it/s]\titers: 1900, epoch: 17 | loss: 0.1510955\n",
      "\tspeed: 0.1449s/iter; left time: 1906.7937s\n",
      "1999it [04:29,  6.09it/s]\titers: 2000, epoch: 17 | loss: 0.2025328\n",
      "\tspeed: 0.1224s/iter; left time: 1598.7982s\n",
      "2099it [04:42,  9.88it/s]\titers: 2100, epoch: 17 | loss: 0.1961629\n",
      "\tspeed: 0.1323s/iter; left time: 1715.2052s\n",
      "2199it [04:57,  3.81it/s]\titers: 2200, epoch: 17 | loss: 0.4592136\n",
      "\tspeed: 0.1504s/iter; left time: 1934.8702s\n",
      "2298it [05:09,  9.75it/s]\titers: 2300, epoch: 17 | loss: 0.4834341\n",
      "\tspeed: 0.1192s/iter; left time: 1520.5181s\n",
      "2399it [05:23,  9.84it/s]\titers: 2400, epoch: 17 | loss: 0.2778184\n",
      "\tspeed: 0.1355s/iter; left time: 1716.0941s\n",
      "2498it [05:36,  9.82it/s]\titers: 2500, epoch: 17 | loss: 0.1481767\n",
      "\tspeed: 0.1353s/iter; left time: 1699.5720s\n",
      "2599it [05:50,  9.57it/s]\titers: 2600, epoch: 17 | loss: 0.1716279\n",
      "\tspeed: 0.1347s/iter; left time: 1679.0167s\n",
      "2699it [06:03,  9.58it/s]\titers: 2700, epoch: 17 | loss: 0.1564758\n",
      "\tspeed: 0.1338s/iter; left time: 1653.4616s\n",
      "2799it [06:16,  9.78it/s]\titers: 2800, epoch: 17 | loss: 0.1929457\n",
      "\tspeed: 0.1349s/iter; left time: 1654.5342s\n",
      "2899it [06:30,  9.82it/s]\titers: 2900, epoch: 17 | loss: 0.1140169\n",
      "\tspeed: 0.1352s/iter; left time: 1643.5850s\n",
      "2999it [06:44,  9.83it/s]\titers: 3000, epoch: 17 | loss: 0.3556680\n",
      "\tspeed: 0.1354s/iter; left time: 1633.6300s\n",
      "3099it [06:57,  9.79it/s]\titers: 3100, epoch: 17 | loss: 0.1539478\n",
      "\tspeed: 0.1345s/iter; left time: 1608.8967s\n",
      "3198it [07:10,  9.66it/s]\titers: 3200, epoch: 17 | loss: 0.3540530\n",
      "\tspeed: 0.1352s/iter; left time: 1603.9134s\n",
      "3299it [07:24,  9.41it/s]\titers: 3300, epoch: 17 | loss: 0.3375691\n",
      "\tspeed: 0.1343s/iter; left time: 1579.3432s\n",
      "3399it [07:37,  9.61it/s]\titers: 3400, epoch: 17 | loss: 0.2333136\n",
      "\tspeed: 0.1355s/iter; left time: 1579.8022s\n",
      "3498it [07:51,  9.67it/s]\titers: 3500, epoch: 17 | loss: 0.2489024\n",
      "\tspeed: 0.1360s/iter; left time: 1571.9402s\n",
      "3599it [08:05,  9.98it/s]\titers: 3600, epoch: 17 | loss: 0.5496481\n",
      "\tspeed: 0.1356s/iter; left time: 1554.3997s\n",
      "3699it [08:18,  9.79it/s]\titers: 3700, epoch: 17 | loss: 0.2607773\n",
      "\tspeed: 0.1343s/iter; left time: 1525.5402s\n",
      "3765it [08:26,  7.43it/s]\n",
      "Epoch: 17 cost time: 506.9613764286041\n",
      "810it [00:51, 15.66it/s]\n",
      "807it [00:49, 16.21it/s]\n",
      "Epoch: 17 | Train Loss: 0.2337719 Vali Loss: 0.2808656 Test Loss: 0.3491645 MAE Loss: 0.3542609\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Total time: 146.53452744086584 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-03 23:16:03,402] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:16:04,246] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 23:16:04,246] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:16:04,246] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 23:16:05,159] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 23:16:05,159] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 23:16:06,308] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 23:16:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 23:16:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 23:16:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 23:16:06,311] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 23:16:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 23:16:06,568] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 23:16:06,569] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,569] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 209.92 GB, percent = 27.8%\n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 210.56 GB, percent = 27.9%\n",
      "[2024-05-03 23:16:06,875] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 23:16:06,990] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 23:16:06,991] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,991] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 210.8 GB, percent = 27.9%\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2b91a64410>\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.90it/s]\titers: 100, epoch: 1 | loss: 0.9641595\n",
      "\tspeed: 0.1901s/iter; left time: 14096.9636s\n",
      "199it [00:28,  7.61it/s]\titers: 200, epoch: 1 | loss: 0.5187201\n",
      "\tspeed: 0.1342s/iter; left time: 9941.6416s\n",
      "299it [00:41,  7.69it/s]\titers: 300, epoch: 1 | loss: 0.4029001\n",
      "\tspeed: 0.1327s/iter; left time: 9815.0356s\n",
      "399it [00:54,  6.88it/s]\titers: 400, epoch: 1 | loss: 0.2808163\n",
      "\tspeed: 0.1322s/iter; left time: 9761.5748s\n",
      "499it [01:08,  7.58it/s]\titers: 500, epoch: 1 | loss: 0.1841253\n",
      "\tspeed: 0.1341s/iter; left time: 9890.6729s\n",
      "599it [01:21,  7.18it/s]\titers: 600, epoch: 1 | loss: 0.2845896\n",
      "\tspeed: 0.1355s/iter; left time: 9980.9429s\n",
      "699it [01:35,  7.15it/s]\titers: 700, epoch: 1 | loss: 0.3291208\n",
      "\tspeed: 0.1328s/iter; left time: 9766.7432s\n",
      "799it [01:48,  7.52it/s]\titers: 800, epoch: 1 | loss: 0.2157963\n",
      "\tspeed: 0.1338s/iter; left time: 9826.3813s\n",
      "899it [02:02,  7.14it/s]\titers: 900, epoch: 1 | loss: 0.3774287\n",
      "\tspeed: 0.1377s/iter; left time: 10098.9919s\n",
      "999it [02:15,  6.42it/s]\titers: 1000, epoch: 1 | loss: 0.2994530\n",
      "\tspeed: 0.1348s/iter; left time: 9878.4683s\n",
      "1099it [02:29,  7.42it/s]\titers: 1100, epoch: 1 | loss: 0.2394145\n",
      "\tspeed: 0.1343s/iter; left time: 9823.6066s\n",
      "1199it [02:42,  7.54it/s]\titers: 1200, epoch: 1 | loss: 0.2472853\n",
      "\tspeed: 0.1367s/iter; left time: 9989.1850s\n",
      "1299it [02:56,  7.48it/s]\titers: 1300, epoch: 1 | loss: 0.2571820\n",
      "\tspeed: 0.1353s/iter; left time: 9869.7256s\n",
      "1399it [03:09,  7.13it/s]\titers: 1400, epoch: 1 | loss: 0.2126374\n",
      "\tspeed: 0.1330s/iter; left time: 9688.5399s\n",
      "1499it [03:22,  7.56it/s]\titers: 1500, epoch: 1 | loss: 0.2242659\n",
      "\tspeed: 0.1323s/iter; left time: 9623.3073s\n",
      "1599it [03:36,  7.51it/s]\titers: 1600, epoch: 1 | loss: 0.3551038\n",
      "\tspeed: 0.1342s/iter; left time: 9754.2883s\n",
      "1699it [03:49,  7.33it/s]\titers: 1700, epoch: 1 | loss: 0.2962065\n",
      "\tspeed: 0.1332s/iter; left time: 9662.3525s\n",
      "1799it [04:02,  7.54it/s]\titers: 1800, epoch: 1 | loss: 0.3189642\n",
      "\tspeed: 0.1326s/iter; left time: 9606.1630s\n",
      "1899it [04:16,  7.62it/s]\titers: 1900, epoch: 1 | loss: 0.2609983\n",
      "\tspeed: 0.1335s/iter; left time: 9662.1350s\n",
      "1999it [04:29,  7.56it/s]\titers: 2000, epoch: 1 | loss: 0.3362970\n",
      "\tspeed: 0.1359s/iter; left time: 9823.6383s\n",
      "2099it [04:42,  7.63it/s]\titers: 2100, epoch: 1 | loss: 0.1997824\n",
      "\tspeed: 0.1317s/iter; left time: 9505.2096s\n",
      "2199it [04:56,  7.63it/s]\titers: 2200, epoch: 1 | loss: 0.2255914\n",
      "\tspeed: 0.1364s/iter; left time: 9832.5489s\n",
      "2299it [05:10,  7.73it/s]\titers: 2300, epoch: 1 | loss: 0.3413877\n",
      "\tspeed: 0.1358s/iter; left time: 9769.7333s\n",
      "2399it [05:23,  7.59it/s]\titers: 2400, epoch: 1 | loss: 0.2875497\n",
      "\tspeed: 0.1342s/iter; left time: 9640.8782s\n",
      "2499it [05:36,  7.62it/s]\titers: 2500, epoch: 1 | loss: 0.3320526\n",
      "\tspeed: 0.1317s/iter; left time: 9448.9760s\n",
      "2599it [05:50,  7.46it/s]\titers: 2600, epoch: 1 | loss: 0.1992021\n",
      "\tspeed: 0.1361s/iter; left time: 9754.5541s\n",
      "2699it [06:03,  7.74it/s]\titers: 2700, epoch: 1 | loss: 0.2342773\n",
      "\tspeed: 0.1354s/iter; left time: 9692.0353s\n",
      "2799it [06:17,  7.51it/s]\titers: 2800, epoch: 1 | loss: 0.1815586\n",
      "\tspeed: 0.1335s/iter; left time: 9537.4159s\n",
      "2899it [06:30,  7.63it/s]\titers: 2900, epoch: 1 | loss: 0.2151070\n",
      "\tspeed: 0.1326s/iter; left time: 9462.8863s\n",
      "2999it [06:44,  7.66it/s]\titers: 3000, epoch: 1 | loss: 0.2274868\n",
      "\tspeed: 0.1358s/iter; left time: 9680.2054s\n",
      "3099it [06:57,  6.48it/s]\titers: 3100, epoch: 1 | loss: 0.1735005\n",
      "\tspeed: 0.1362s/iter; left time: 9692.7038s\n",
      "3199it [07:10,  7.65it/s]\titers: 3200, epoch: 1 | loss: 0.1491423\n",
      "\tspeed: 0.1303s/iter; left time: 9260.9430s\n",
      "3299it [07:24,  7.32it/s]\titers: 3300, epoch: 1 | loss: 0.2412028\n",
      "\tspeed: 0.1351s/iter; left time: 9587.4681s\n",
      "3399it [07:37,  7.14it/s]\titers: 3400, epoch: 1 | loss: 0.3968665\n",
      "\tspeed: 0.1354s/iter; left time: 9594.9798s\n",
      "3499it [07:51,  7.65it/s]\titers: 3500, epoch: 1 | loss: 0.2387104\n",
      "\tspeed: 0.1334s/iter; left time: 9437.6668s\n",
      "3599it [08:04,  7.23it/s]\titers: 3600, epoch: 1 | loss: 0.2146533\n",
      "\tspeed: 0.1349s/iter; left time: 9535.3530s\n",
      "3699it [08:18,  7.44it/s]\titers: 3700, epoch: 1 | loss: 0.1906886\n",
      "\tspeed: 0.1360s/iter; left time: 9596.9117s\n",
      "3713it [08:20,  7.42it/s]\n",
      "Epoch: 1 cost time: 500.14733815193176\n",
      "810it [00:51, 15.65it/s]\n",
      "807it [00:51, 15.62it/s]\n",
      "Epoch: 1 | Train Loss: 0.2935759 Vali Loss: 0.3151243 Test Loss: 0.3966921 MAE Loss: 0.4009331\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:13,  7.67it/s]\titers: 100, epoch: 2 | loss: 0.2668546\n",
      "\tspeed: 1.2391s/iter; left time: 87289.6703s\n",
      "199it [00:26,  7.42it/s]\titers: 200, epoch: 2 | loss: 0.3243296\n",
      "\tspeed: 0.1322s/iter; left time: 9302.8708s\n",
      "299it [00:39,  7.56it/s]\titers: 300, epoch: 2 | loss: 0.2878442\n",
      "\tspeed: 0.1302s/iter; left time: 9144.6476s\n",
      "399it [00:53,  7.79it/s]\titers: 400, epoch: 2 | loss: 0.3907331\n",
      "\tspeed: 0.1324s/iter; left time: 9289.5052s\n",
      "499it [01:06,  7.84it/s]\titers: 500, epoch: 2 | loss: 0.2069688\n",
      "\tspeed: 0.1343s/iter; left time: 9407.2661s\n",
      "599it [01:19,  7.29it/s]\titers: 600, epoch: 2 | loss: 0.2945153\n",
      "\tspeed: 0.1307s/iter; left time: 9141.1951s\n",
      "699it [01:32,  7.60it/s]\titers: 700, epoch: 2 | loss: 0.2082459\n",
      "\tspeed: 0.1323s/iter; left time: 9238.9507s\n",
      "799it [01:46,  7.98it/s]\titers: 800, epoch: 2 | loss: 0.3093166\n",
      "\tspeed: 0.1330s/iter; left time: 9275.4029s\n",
      "899it [01:59,  7.73it/s]\titers: 900, epoch: 2 | loss: 0.1970092\n",
      "\tspeed: 0.1301s/iter; left time: 9061.1613s\n",
      "999it [02:12,  7.67it/s]\titers: 1000, epoch: 2 | loss: 0.3330566\n",
      "\tspeed: 0.1288s/iter; left time: 8957.2229s\n",
      "1099it [02:25,  7.75it/s]\titers: 1100, epoch: 2 | loss: 0.1897289\n",
      "\tspeed: 0.1330s/iter; left time: 9237.5728s\n",
      "1199it [02:38,  7.76it/s]\titers: 1200, epoch: 2 | loss: 0.4427165\n",
      "\tspeed: 0.1298s/iter; left time: 8999.9445s\n",
      "1299it [02:51,  7.72it/s]\titers: 1300, epoch: 2 | loss: 0.2237228\n",
      "\tspeed: 0.1300s/iter; left time: 9004.1973s\n",
      "1399it [03:04,  7.71it/s]\titers: 1400, epoch: 2 | loss: 0.1716717\n",
      "\tspeed: 0.1315s/iter; left time: 9094.9401s\n",
      "1499it [03:17,  7.72it/s]\titers: 1500, epoch: 2 | loss: 0.5217724\n",
      "\tspeed: 0.1303s/iter; left time: 8995.5274s\n",
      "1599it [03:30,  7.86it/s]\titers: 1600, epoch: 2 | loss: 0.2182254\n",
      "\tspeed: 0.1283s/iter; left time: 8847.8451s\n",
      "1699it [03:43,  8.01it/s]\titers: 1700, epoch: 2 | loss: 0.2576517\n",
      "\tspeed: 0.1322s/iter; left time: 9102.7865s\n",
      "1799it [03:56,  7.45it/s]\titers: 1800, epoch: 2 | loss: 0.1207245\n",
      "\tspeed: 0.1297s/iter; left time: 8914.8277s\n",
      "1899it [04:09,  7.73it/s]\titers: 1900, epoch: 2 | loss: 0.2838496\n",
      "\tspeed: 0.1308s/iter; left time: 8978.4981s\n",
      "1999it [04:22,  7.83it/s]\titers: 2000, epoch: 2 | loss: 0.2352560\n",
      "\tspeed: 0.1326s/iter; left time: 9089.6573s\n",
      "2099it [04:35,  7.77it/s]\titers: 2100, epoch: 2 | loss: 0.2004760\n",
      "\tspeed: 0.1296s/iter; left time: 8874.0426s\n",
      "2199it [04:48,  7.98it/s]\titers: 2200, epoch: 2 | loss: 0.3143178\n",
      "\tspeed: 0.1290s/iter; left time: 8817.1081s\n",
      "2299it [05:02,  7.93it/s]\titers: 2300, epoch: 2 | loss: 0.2416739\n",
      "\tspeed: 0.1338s/iter; left time: 9128.8448s\n",
      "2399it [05:15,  7.74it/s]\titers: 2400, epoch: 2 | loss: 0.4222754\n",
      "\tspeed: 0.1310s/iter; left time: 8929.5252s\n",
      "2499it [05:28,  7.69it/s]\titers: 2500, epoch: 2 | loss: 0.1435327\n",
      "\tspeed: 0.1305s/iter; left time: 8878.6645s\n",
      "2599it [05:41,  7.63it/s]\titers: 2600, epoch: 2 | loss: 0.2831287\n",
      "\tspeed: 0.1341s/iter; left time: 9110.4733s\n",
      "2699it [05:55,  7.34it/s]\titers: 2700, epoch: 2 | loss: 0.2098521\n",
      "\tspeed: 0.1337s/iter; left time: 9068.2377s\n",
      "2799it [06:08,  7.65it/s]\titers: 2800, epoch: 2 | loss: 0.2984158\n",
      "\tspeed: 0.1311s/iter; left time: 8883.9049s\n",
      "2899it [06:21,  7.83it/s]\titers: 2900, epoch: 2 | loss: 0.2197979\n",
      "\tspeed: 0.1353s/iter; left time: 9153.0203s\n",
      "2999it [06:35,  6.34it/s]\titers: 3000, epoch: 2 | loss: 0.1694328\n",
      "\tspeed: 0.1346s/iter; left time: 9090.2800s\n",
      "3099it [06:48,  7.80it/s]\titers: 3100, epoch: 2 | loss: 0.2197636\n",
      "\tspeed: 0.1301s/iter; left time: 8772.4604s\n",
      "3199it [07:01,  7.44it/s]\titers: 3200, epoch: 2 | loss: 0.2478591\n",
      "\tspeed: 0.1330s/iter; left time: 8957.9047s\n",
      "3299it [07:14,  6.86it/s]\titers: 3300, epoch: 2 | loss: 0.1612138\n",
      "\tspeed: 0.1338s/iter; left time: 8996.9980s\n",
      "3399it [07:28,  7.68it/s]\titers: 3400, epoch: 2 | loss: 0.1399053\n",
      "\tspeed: 0.1316s/iter; left time: 8838.2709s\n",
      "3499it [07:41,  7.69it/s]\titers: 3500, epoch: 2 | loss: 0.1988449\n",
      "\tspeed: 0.1349s/iter; left time: 9042.2084s\n",
      "3599it [07:54,  7.79it/s]\titers: 3600, epoch: 2 | loss: 0.1694340\n",
      "\tspeed: 0.1325s/iter; left time: 8872.4572s\n",
      "3699it [08:07,  7.64it/s]\titers: 3700, epoch: 2 | loss: 0.1109314\n",
      "\tspeed: 0.1295s/iter; left time: 8658.8483s\n",
      "3713it [08:09,  7.58it/s]\n",
      "Epoch: 2 cost time: 489.6390595436096\n",
      "810it [00:48, 16.55it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 2 | Train Loss: 0.2395417 Vali Loss: 0.2934191 Test Loss: 0.3401946 MAE Loss: 0.3558949\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:13,  7.76it/s]\titers: 100, epoch: 3 | loss: 0.2172087\n",
      "\tspeed: 1.1628s/iter; left time: 77599.2643s\n",
      "199it [00:26,  7.82it/s]\titers: 200, epoch: 3 | loss: 0.1346914\n",
      "\tspeed: 0.1311s/iter; left time: 8732.9475s\n",
      "299it [00:39,  7.66it/s]\titers: 300, epoch: 3 | loss: 0.2193775\n",
      "\tspeed: 0.1307s/iter; left time: 8693.5844s\n",
      "399it [00:52,  7.76it/s]\titers: 400, epoch: 3 | loss: 0.4463703\n",
      "\tspeed: 0.1304s/iter; left time: 8660.1707s\n",
      "499it [01:05,  7.78it/s]\titers: 500, epoch: 3 | loss: 0.1829557\n",
      "\tspeed: 0.1334s/iter; left time: 8849.0088s\n",
      "599it [01:18,  7.71it/s]\titers: 600, epoch: 3 | loss: 0.2435770\n",
      "\tspeed: 0.1295s/iter; left time: 8577.6722s\n",
      "699it [01:31,  7.80it/s]\titers: 700, epoch: 3 | loss: 0.2425336\n",
      "\tspeed: 0.1303s/iter; left time: 8617.8318s\n",
      "799it [01:44,  7.85it/s]\titers: 800, epoch: 3 | loss: 0.4156528\n",
      "\tspeed: 0.1299s/iter; left time: 8580.8410s\n",
      "899it [01:57,  7.72it/s]\titers: 900, epoch: 3 | loss: 0.4306667\n",
      "\tspeed: 0.1289s/iter; left time: 8500.6631s\n",
      "999it [02:10,  7.85it/s]\titers: 1000, epoch: 3 | loss: 0.2407355\n",
      "\tspeed: 0.1288s/iter; left time: 8479.3888s\n",
      "1099it [02:23,  7.86it/s]\titers: 1100, epoch: 3 | loss: 0.2281860\n",
      "\tspeed: 0.1312s/iter; left time: 8627.5827s\n",
      "1199it [02:36,  7.14it/s]\titers: 1200, epoch: 3 | loss: 0.1639353\n",
      "\tspeed: 0.1294s/iter; left time: 8494.9647s\n",
      "1299it [02:49,  7.72it/s]\titers: 1300, epoch: 3 | loss: 0.2385784\n",
      "\tspeed: 0.1297s/iter; left time: 8497.8942s\n",
      "1399it [03:02,  7.58it/s]\titers: 1400, epoch: 3 | loss: 0.3162254\n",
      "\tspeed: 0.1325s/iter; left time: 8670.8155s\n",
      "1499it [03:15,  7.03it/s]\titers: 1500, epoch: 3 | loss: 0.1490571\n",
      "\tspeed: 0.1297s/iter; left time: 8475.7814s\n",
      "1599it [03:29,  7.73it/s]\titers: 1600, epoch: 3 | loss: 0.3864870\n",
      "\tspeed: 0.1307s/iter; left time: 8524.3812s\n",
      "1699it [03:42,  7.97it/s]\titers: 1700, epoch: 3 | loss: 0.3177374\n",
      "\tspeed: 0.1322s/iter; left time: 8613.8330s\n",
      "1799it [03:55,  7.64it/s]\titers: 1800, epoch: 3 | loss: 0.1520831\n",
      "\tspeed: 0.1288s/iter; left time: 8373.8813s\n",
      "1899it [04:08,  7.91it/s]\titers: 1900, epoch: 3 | loss: 0.2257083\n",
      "\tspeed: 0.1304s/iter; left time: 8467.0423s\n",
      "1999it [04:21,  7.77it/s]\titers: 2000, epoch: 3 | loss: 0.2256435\n",
      "\tspeed: 0.1295s/iter; left time: 8394.7477s\n",
      "2099it [04:33,  7.81it/s]\titers: 2100, epoch: 3 | loss: 0.2019173\n",
      "\tspeed: 0.1281s/iter; left time: 8289.6898s\n",
      "2199it [04:47,  7.88it/s]\titers: 2200, epoch: 3 | loss: 0.1541355\n",
      "\tspeed: 0.1316s/iter; left time: 8502.7703s\n",
      "2299it [05:00,  7.85it/s]\titers: 2300, epoch: 3 | loss: 0.1263089\n",
      "\tspeed: 0.1310s/iter; left time: 8451.2051s\n",
      "2399it [05:12,  7.87it/s]\titers: 2400, epoch: 3 | loss: 0.2702385\n",
      "\tspeed: 0.1264s/iter; left time: 8144.7847s\n",
      "2499it [05:25,  7.90it/s]\titers: 2500, epoch: 3 | loss: 0.2562164\n",
      "\tspeed: 0.1294s/iter; left time: 8327.7767s\n",
      "2599it [05:38,  7.08it/s]\titers: 2600, epoch: 3 | loss: 0.2490318\n",
      "\tspeed: 0.1290s/iter; left time: 8284.2528s\n",
      "2699it [05:51,  7.91it/s]\titers: 2700, epoch: 3 | loss: 0.1571666\n",
      "\tspeed: 0.1272s/iter; left time: 8155.6866s\n",
      "2799it [06:04,  7.79it/s]\titers: 2800, epoch: 3 | loss: 0.1761787\n",
      "\tspeed: 0.1289s/iter; left time: 8254.6760s\n",
      "2899it [06:17,  7.80it/s]\titers: 2900, epoch: 3 | loss: 0.1350867\n",
      "\tspeed: 0.1277s/iter; left time: 8165.8856s\n",
      "2999it [06:29,  7.71it/s]\titers: 3000, epoch: 3 | loss: 0.2478373\n",
      "\tspeed: 0.1287s/iter; left time: 8217.4150s\n",
      "3099it [06:42,  7.83it/s]\titers: 3100, epoch: 3 | loss: 0.2496981\n",
      "\tspeed: 0.1299s/iter; left time: 8281.7341s\n",
      "3199it [06:55,  7.50it/s]\titers: 3200, epoch: 3 | loss: 0.1517304\n",
      "\tspeed: 0.1306s/iter; left time: 8307.6520s\n",
      "3299it [07:08,  7.81it/s]\titers: 3300, epoch: 3 | loss: 0.1905589\n",
      "\tspeed: 0.1299s/iter; left time: 8255.4373s\n",
      "3399it [07:22,  7.73it/s]\titers: 3400, epoch: 3 | loss: 0.2230773\n",
      "\tspeed: 0.1323s/iter; left time: 8391.9180s\n",
      "3499it [07:35,  7.68it/s]\titers: 3500, epoch: 3 | loss: 0.2365967\n",
      "\tspeed: 0.1298s/iter; left time: 8220.1556s\n",
      "3599it [07:48,  7.77it/s]\titers: 3600, epoch: 3 | loss: 0.1072769\n",
      "\tspeed: 0.1312s/iter; left time: 8293.7054s\n",
      "3699it [08:01,  7.69it/s]\titers: 3700, epoch: 3 | loss: 0.2879986\n",
      "\tspeed: 0.1332s/iter; left time: 8407.6610s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 3 cost time: 483.4823913574219\n",
      "810it [00:49, 16.20it/s]\n",
      "807it [00:49, 16.35it/s]\n",
      "Epoch: 3 | Train Loss: 0.2212686 Vali Loss: 0.2801371 Test Loss: 0.3329907 MAE Loss: 0.3440673\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:13,  7.80it/s]\titers: 100, epoch: 4 | loss: 0.2128312\n",
      "\tspeed: 1.1825s/iter; left time: 74524.6950s\n",
      "199it [00:27,  7.58it/s]\titers: 200, epoch: 4 | loss: 0.2195538\n",
      "\tspeed: 0.1340s/iter; left time: 8429.7965s\n",
      "299it [00:40,  7.67it/s]\titers: 300, epoch: 4 | loss: 0.3302707\n",
      "\tspeed: 0.1299s/iter; left time: 8160.0765s\n",
      "399it [00:53,  7.60it/s]\titers: 400, epoch: 4 | loss: 0.4481091\n",
      "\tspeed: 0.1335s/iter; left time: 8374.7982s\n",
      "499it [01:06,  7.59it/s]\titers: 500, epoch: 4 | loss: 0.0987328\n",
      "\tspeed: 0.1336s/iter; left time: 8367.1181s\n",
      "599it [01:20,  7.55it/s]\titers: 600, epoch: 4 | loss: 0.2090068\n",
      "\tspeed: 0.1312s/iter; left time: 8202.8580s\n",
      "699it [01:33,  7.78it/s]\titers: 700, epoch: 4 | loss: 0.3150179\n",
      "\tspeed: 0.1336s/iter; left time: 8340.5657s\n",
      "799it [01:46,  7.87it/s]\titers: 800, epoch: 4 | loss: 0.1733373\n",
      "\tspeed: 0.1308s/iter; left time: 8149.8054s\n",
      "899it [01:59,  7.23it/s]\titers: 900, epoch: 4 | loss: 0.2353803\n",
      "\tspeed: 0.1289s/iter; left time: 8022.7098s\n",
      "999it [02:12,  7.65it/s]\titers: 1000, epoch: 4 | loss: 0.2693732\n",
      "\tspeed: 0.1300s/iter; left time: 8075.5701s\n",
      "1099it [02:25,  7.44it/s]\titers: 1100, epoch: 4 | loss: 0.2488151\n",
      "\tspeed: 0.1336s/iter; left time: 8289.2193s\n",
      "1199it [02:38,  7.15it/s]\titers: 1200, epoch: 4 | loss: 0.3202523\n",
      "\tspeed: 0.1286s/iter; left time: 7961.3516s\n",
      "1299it [02:51,  7.60it/s]\titers: 1300, epoch: 4 | loss: 0.2792143\n",
      "\tspeed: 0.1321s/iter; left time: 8164.7204s\n",
      "1399it [03:05,  7.90it/s]\titers: 1400, epoch: 4 | loss: 0.3689791\n",
      "\tspeed: 0.1329s/iter; left time: 8202.8967s\n",
      "1499it [03:18,  6.92it/s]\titers: 1500, epoch: 4 | loss: 0.1964427\n",
      "\tspeed: 0.1306s/iter; left time: 8045.7311s\n",
      "1599it [03:31,  7.97it/s]\titers: 1600, epoch: 4 | loss: 0.1753232\n",
      "\tspeed: 0.1294s/iter; left time: 7958.8608s\n",
      "1699it [03:44,  7.76it/s]\titers: 1700, epoch: 4 | loss: 0.1751649\n",
      "\tspeed: 0.1298s/iter; left time: 7975.3103s\n",
      "1799it [03:57,  6.89it/s]\titers: 1800, epoch: 4 | loss: 0.1906732\n",
      "\tspeed: 0.1301s/iter; left time: 7980.8608s\n",
      "1899it [04:10,  7.47it/s]\titers: 1900, epoch: 4 | loss: 0.1933302\n",
      "\tspeed: 0.1315s/iter; left time: 8053.5229s\n",
      "1999it [04:23,  7.76it/s]\titers: 2000, epoch: 4 | loss: 0.1602807\n",
      "\tspeed: 0.1344s/iter; left time: 8217.4018s\n",
      "2099it [04:36,  7.31it/s]\titers: 2100, epoch: 4 | loss: 0.2727919\n",
      "\tspeed: 0.1297s/iter; left time: 7915.0626s\n",
      "2199it [04:49,  7.77it/s]\titers: 2200, epoch: 4 | loss: 0.1243803\n",
      "\tspeed: 0.1329s/iter; left time: 8097.4275s\n",
      "2299it [05:03,  7.47it/s]\titers: 2300, epoch: 4 | loss: 0.2286512\n",
      "\tspeed: 0.1337s/iter; left time: 8133.1621s\n",
      "2399it [05:16,  7.36it/s]\titers: 2400, epoch: 4 | loss: 0.1426104\n",
      "\tspeed: 0.1308s/iter; left time: 7941.0021s\n",
      "2499it [05:29,  7.81it/s]\titers: 2500, epoch: 4 | loss: 0.1815710\n",
      "\tspeed: 0.1308s/iter; left time: 7927.6447s\n",
      "2599it [05:42,  7.68it/s]\titers: 2600, epoch: 4 | loss: 0.2303303\n",
      "\tspeed: 0.1339s/iter; left time: 8103.9024s\n",
      "2699it [05:56,  6.83it/s]\titers: 2700, epoch: 4 | loss: 0.1436880\n",
      "\tspeed: 0.1353s/iter; left time: 8172.1888s\n",
      "2799it [06:09,  7.74it/s]\titers: 2800, epoch: 4 | loss: 0.3447067\n",
      "\tspeed: 0.1300s/iter; left time: 7844.7544s\n",
      "2899it [06:22,  7.73it/s]\titers: 2900, epoch: 4 | loss: 0.1544191\n",
      "\tspeed: 0.1320s/iter; left time: 7949.0549s\n",
      "2999it [06:35,  7.71it/s]\titers: 3000, epoch: 4 | loss: 0.2189909\n",
      "\tspeed: 0.1336s/iter; left time: 8031.9786s\n",
      "3099it [06:48,  7.78it/s]\titers: 3100, epoch: 4 | loss: 0.1446553\n",
      "\tspeed: 0.1291s/iter; left time: 7748.3308s\n",
      "3199it [07:02,  7.76it/s]\titers: 3200, epoch: 4 | loss: 0.2125824\n",
      "\tspeed: 0.1327s/iter; left time: 7951.4862s\n",
      "3299it [07:15,  7.65it/s]\titers: 3300, epoch: 4 | loss: 0.1498930\n",
      "\tspeed: 0.1321s/iter; left time: 7900.0393s\n",
      "3399it [07:28,  7.75it/s]\titers: 3400, epoch: 4 | loss: 0.1350155\n",
      "\tspeed: 0.1286s/iter; left time: 7681.1129s\n",
      "3499it [07:41,  7.78it/s]\titers: 3500, epoch: 4 | loss: 0.2077062\n",
      "\tspeed: 0.1315s/iter; left time: 7842.8196s\n",
      "3599it [07:54,  7.75it/s]\titers: 3600, epoch: 4 | loss: 0.1565008\n",
      "\tspeed: 0.1318s/iter; left time: 7843.6119s\n",
      "3699it [08:08,  5.53it/s]\titers: 3700, epoch: 4 | loss: 0.1517958\n",
      "\tspeed: 0.1360s/iter; left time: 8084.1826s\n",
      "3713it [08:10,  7.57it/s]\n",
      "Epoch: 4 cost time: 490.21391320228577\n",
      "810it [00:49, 16.42it/s]\n",
      "807it [00:49, 16.41it/s]\n",
      "Epoch: 4 | Train Loss: 0.2116419 Vali Loss: 0.2813208 Test Loss: 0.3359991 MAE Loss: 0.3474960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 5 | loss: 0.1215705\n",
      "\tspeed: 1.1374s/iter; left time: 67456.5391s\n",
      "199it [00:26,  7.62it/s]\titers: 200, epoch: 5 | loss: 0.1519264\n",
      "\tspeed: 0.1343s/iter; left time: 7952.3108s\n",
      "299it [00:39,  6.67it/s]\titers: 300, epoch: 5 | loss: 0.1742376\n",
      "\tspeed: 0.1327s/iter; left time: 7846.5699s\n",
      "399it [00:52,  7.80it/s]\titers: 400, epoch: 5 | loss: 0.2460077\n",
      "\tspeed: 0.1290s/iter; left time: 7614.7672s\n",
      "499it [01:05,  7.83it/s]\titers: 500, epoch: 5 | loss: 0.0752749\n",
      "\tspeed: 0.1306s/iter; left time: 7691.3824s\n",
      "599it [01:18,  7.71it/s]\titers: 600, epoch: 5 | loss: 0.1421984\n",
      "\tspeed: 0.1309s/iter; left time: 7699.5268s\n",
      "699it [01:31,  7.82it/s]\titers: 700, epoch: 5 | loss: 0.2719428\n",
      "\tspeed: 0.1293s/iter; left time: 7592.8828s\n",
      "799it [01:44,  7.78it/s]\titers: 800, epoch: 5 | loss: 0.2143029\n",
      "\tspeed: 0.1309s/iter; left time: 7670.1602s\n",
      "899it [01:57,  7.60it/s]\titers: 900, epoch: 5 | loss: 0.2020324\n",
      "\tspeed: 0.1304s/iter; left time: 7627.3199s\n",
      "999it [02:10,  7.74it/s]\titers: 1000, epoch: 5 | loss: 0.2187834\n",
      "\tspeed: 0.1294s/iter; left time: 7558.2192s\n",
      "1099it [02:24,  7.91it/s]\titers: 1100, epoch: 5 | loss: 0.2859931\n",
      "\tspeed: 0.1322s/iter; left time: 7708.0266s\n",
      "1199it [02:37,  7.25it/s]\titers: 1200, epoch: 5 | loss: 0.1921416\n",
      "\tspeed: 0.1303s/iter; left time: 7585.8764s\n",
      "1299it [02:50,  7.66it/s]\titers: 1300, epoch: 5 | loss: 0.1542293\n",
      "\tspeed: 0.1297s/iter; left time: 7536.3844s\n",
      "1399it [03:03,  7.71it/s]\titers: 1400, epoch: 5 | loss: 0.1083390\n",
      "\tspeed: 0.1314s/iter; left time: 7620.9577s\n",
      "1499it [03:16,  7.77it/s]\titers: 1500, epoch: 5 | loss: 0.1162234\n",
      "\tspeed: 0.1289s/iter; left time: 7463.0696s\n",
      "1599it [03:29,  7.91it/s]\titers: 1600, epoch: 5 | loss: 0.2247154\n",
      "\tspeed: 0.1293s/iter; left time: 7475.0828s\n",
      "1699it [03:42,  7.86it/s]\titers: 1700, epoch: 5 | loss: 0.2029028\n",
      "\tspeed: 0.1314s/iter; left time: 7583.7786s\n",
      "1799it [03:55,  6.92it/s]\titers: 1800, epoch: 5 | loss: 0.2313351\n",
      "\tspeed: 0.1288s/iter; left time: 7418.2420s\n",
      "1899it [04:08,  7.73it/s]\titers: 1900, epoch: 5 | loss: 0.2222791\n",
      "\tspeed: 0.1301s/iter; left time: 7483.4158s\n",
      "1999it [04:21,  7.71it/s]\titers: 2000, epoch: 5 | loss: 0.1447722\n",
      "\tspeed: 0.1308s/iter; left time: 7508.8304s\n",
      "2099it [04:34,  7.03it/s]\titers: 2100, epoch: 5 | loss: 0.2559798\n",
      "\tspeed: 0.1292s/iter; left time: 7403.3624s\n",
      "2199it [04:47,  7.92it/s]\titers: 2200, epoch: 5 | loss: 0.1325725\n",
      "\tspeed: 0.1293s/iter; left time: 7396.7396s\n",
      "2299it [05:00,  7.84it/s]\titers: 2300, epoch: 5 | loss: 0.2350173\n",
      "\tspeed: 0.1303s/iter; left time: 7442.6577s\n",
      "2399it [05:12,  7.13it/s]\titers: 2400, epoch: 5 | loss: 0.1642561\n",
      "\tspeed: 0.1295s/iter; left time: 7384.2219s\n",
      "2499it [05:25,  7.82it/s]\titers: 2500, epoch: 5 | loss: 0.1604826\n",
      "\tspeed: 0.1289s/iter; left time: 7334.3306s\n",
      "2599it [05:38,  7.71it/s]\titers: 2600, epoch: 5 | loss: 0.2684038\n",
      "\tspeed: 0.1304s/iter; left time: 7406.8786s\n",
      "2699it [05:51,  7.62it/s]\titers: 2700, epoch: 5 | loss: 0.1760338\n",
      "\tspeed: 0.1288s/iter; left time: 7304.9225s\n",
      "2799it [06:04,  7.75it/s]\titers: 2800, epoch: 5 | loss: 0.1796928\n",
      "\tspeed: 0.1314s/iter; left time: 7439.0862s\n",
      "2899it [06:18,  7.79it/s]\titers: 2900, epoch: 5 | loss: 0.2157445\n",
      "\tspeed: 0.1317s/iter; left time: 7442.3547s\n",
      "2999it [06:31,  7.42it/s]\titers: 3000, epoch: 5 | loss: 0.1468672\n",
      "\tspeed: 0.1291s/iter; left time: 7281.7606s\n",
      "3099it [06:43,  7.76it/s]\titers: 3100, epoch: 5 | loss: 0.2015075\n",
      "\tspeed: 0.1297s/iter; left time: 7306.0170s\n",
      "3199it [06:57,  7.83it/s]\titers: 3200, epoch: 5 | loss: 0.1676449\n",
      "\tspeed: 0.1308s/iter; left time: 7351.4428s\n",
      "3299it [07:10,  6.05it/s]\titers: 3300, epoch: 5 | loss: 0.1916084\n",
      "\tspeed: 0.1313s/iter; left time: 7366.8941s\n",
      "3399it [07:23,  7.74it/s]\titers: 3400, epoch: 5 | loss: 0.2393851\n",
      "\tspeed: 0.1295s/iter; left time: 7250.4324s\n",
      "3499it [07:36,  7.58it/s]\titers: 3500, epoch: 5 | loss: 0.3022619\n",
      "\tspeed: 0.1309s/iter; left time: 7317.2789s\n",
      "3599it [07:49,  7.44it/s]\titers: 3600, epoch: 5 | loss: 0.2383408\n",
      "\tspeed: 0.1295s/iter; left time: 7224.5517s\n",
      "3699it [08:02,  7.90it/s]\titers: 3700, epoch: 5 | loss: 0.1483875\n",
      "\tspeed: 0.1311s/iter; left time: 7305.3372s\n",
      "3713it [08:04,  7.67it/s]\n",
      "Epoch: 5 cost time: 484.16480469703674\n",
      "810it [00:49, 16.52it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 5 | Train Loss: 0.2056262 Vali Loss: 0.2857605 Test Loss: 0.3462862 MAE Loss: 0.3538258\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:13,  8.03it/s]\titers: 100, epoch: 6 | loss: 0.2537978\n",
      "\tspeed: 1.1249s/iter; left time: 62537.8014s\n",
      "199it [00:26,  6.99it/s]\titers: 200, epoch: 6 | loss: 0.1386817\n",
      "\tspeed: 0.1305s/iter; left time: 7244.6451s\n",
      "299it [00:39,  6.41it/s]\titers: 300, epoch: 6 | loss: 0.2591326\n",
      "\tspeed: 0.1285s/iter; left time: 7117.1344s\n",
      "399it [00:52,  7.92it/s]\titers: 400, epoch: 6 | loss: 0.1535020\n",
      "\tspeed: 0.1293s/iter; left time: 7151.4746s\n",
      "499it [01:05,  8.01it/s]\titers: 500, epoch: 6 | loss: 0.2082774\n",
      "\tspeed: 0.1315s/iter; left time: 7259.8823s\n",
      "599it [01:18,  7.92it/s]\titers: 600, epoch: 6 | loss: 0.2359465\n",
      "\tspeed: 0.1296s/iter; left time: 7143.1575s\n",
      "699it [01:30,  7.98it/s]\titers: 700, epoch: 6 | loss: 0.3018428\n",
      "\tspeed: 0.1280s/iter; left time: 7039.6886s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 6 | loss: 0.2652551\n",
      "\tspeed: 0.1287s/iter; left time: 7067.5588s\n",
      "899it [01:56,  6.72it/s]\titers: 900, epoch: 6 | loss: 0.2376828\n",
      "\tspeed: 0.1302s/iter; left time: 7136.6489s\n",
      "999it [02:09,  7.49it/s]\titers: 1000, epoch: 6 | loss: 0.1226375\n",
      "\tspeed: 0.1309s/iter; left time: 7157.0021s\n",
      "1099it [02:23,  7.41it/s]\titers: 1100, epoch: 6 | loss: 0.1675810\n",
      "\tspeed: 0.1347s/iter; left time: 7355.2663s\n",
      "1199it [02:36,  7.71it/s]\titers: 1200, epoch: 6 | loss: 0.2391902\n",
      "\tspeed: 0.1313s/iter; left time: 7154.5023s\n",
      "1299it [02:49,  7.95it/s]\titers: 1300, epoch: 6 | loss: 0.1843557\n",
      "\tspeed: 0.1277s/iter; left time: 6946.1290s\n",
      "1399it [03:02,  7.90it/s]\titers: 1400, epoch: 6 | loss: 0.1571867\n",
      "\tspeed: 0.1292s/iter; left time: 7016.0276s\n",
      "1499it [03:15,  7.71it/s]\titers: 1500, epoch: 6 | loss: 0.1495090\n",
      "\tspeed: 0.1307s/iter; left time: 7084.4020s\n",
      "1599it [03:28,  7.65it/s]\titers: 1600, epoch: 6 | loss: 0.0854176\n",
      "\tspeed: 0.1276s/iter; left time: 6900.6249s\n",
      "1699it [03:41,  7.71it/s]\titers: 1700, epoch: 6 | loss: 0.2547580\n",
      "\tspeed: 0.1306s/iter; left time: 7051.3996s\n",
      "1799it [03:54,  7.89it/s]\titers: 1800, epoch: 6 | loss: 0.1928886\n",
      "\tspeed: 0.1302s/iter; left time: 7014.8396s\n",
      "1899it [04:06,  7.88it/s]\titers: 1900, epoch: 6 | loss: 0.2520036\n",
      "\tspeed: 0.1277s/iter; left time: 6871.5270s\n",
      "1999it [04:20,  7.90it/s]\titers: 2000, epoch: 6 | loss: 0.1259657\n",
      "\tspeed: 0.1309s/iter; left time: 7030.8391s\n",
      "2099it [04:32,  7.87it/s]\titers: 2100, epoch: 6 | loss: 0.2468439\n",
      "\tspeed: 0.1295s/iter; left time: 6939.2114s\n",
      "2199it [04:45,  7.86it/s]\titers: 2200, epoch: 6 | loss: 0.1148948\n",
      "\tspeed: 0.1270s/iter; left time: 6793.3687s\n",
      "2299it [04:58,  7.72it/s]\titers: 2300, epoch: 6 | loss: 0.1980886\n",
      "\tspeed: 0.1313s/iter; left time: 7010.9937s\n",
      "2399it [05:12,  7.72it/s]\titers: 2400, epoch: 6 | loss: 0.1522728\n",
      "\tspeed: 0.1357s/iter; left time: 7230.5244s\n",
      "2499it [05:25,  5.93it/s]\titers: 2500, epoch: 6 | loss: 0.3693871\n",
      "\tspeed: 0.1330s/iter; left time: 7073.8179s\n",
      "2599it [05:39,  7.69it/s]\titers: 2600, epoch: 6 | loss: 0.1994973\n",
      "\tspeed: 0.1345s/iter; left time: 7141.0385s\n",
      "2699it [05:52,  7.64it/s]\titers: 2700, epoch: 6 | loss: 0.2647148\n",
      "\tspeed: 0.1345s/iter; left time: 7126.2563s\n",
      "2799it [06:05,  7.14it/s]\titers: 2800, epoch: 6 | loss: 0.2415183\n",
      "\tspeed: 0.1294s/iter; left time: 6847.0898s\n",
      "2899it [06:18,  7.87it/s]\titers: 2900, epoch: 6 | loss: 0.2359923\n",
      "\tspeed: 0.1291s/iter; left time: 6814.9882s\n",
      "2999it [06:31,  7.74it/s]\titers: 3000, epoch: 6 | loss: 0.1775244\n",
      "\tspeed: 0.1300s/iter; left time: 6849.0749s\n",
      "3099it [06:44,  7.71it/s]\titers: 3100, epoch: 6 | loss: 0.1864435\n",
      "\tspeed: 0.1316s/iter; left time: 6920.6569s\n",
      "3199it [06:57,  7.68it/s]\titers: 3200, epoch: 6 | loss: 0.1932236\n",
      "\tspeed: 0.1301s/iter; left time: 6830.5767s\n",
      "3299it [07:10,  7.87it/s]\titers: 3300, epoch: 6 | loss: 0.1104027\n",
      "\tspeed: 0.1323s/iter; left time: 6931.2826s\n",
      "3399it [07:23,  7.75it/s]\titers: 3400, epoch: 6 | loss: 0.2285420\n",
      "\tspeed: 0.1315s/iter; left time: 6877.3935s\n",
      "3499it [07:36,  7.84it/s]\titers: 3500, epoch: 6 | loss: 0.1582985\n",
      "\tspeed: 0.1289s/iter; left time: 6728.0666s\n",
      "3599it [07:50,  7.73it/s]\titers: 3600, epoch: 6 | loss: 0.2720512\n",
      "\tspeed: 0.1318s/iter; left time: 6867.0234s\n",
      "3699it [08:03,  7.80it/s]\titers: 3700, epoch: 6 | loss: 0.3566822\n",
      "\tspeed: 0.1297s/iter; left time: 6744.8405s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 6 cost time: 484.9444179534912\n",
      "810it [00:48, 16.70it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 6 | Train Loss: 0.2030284 Vali Loss: 0.2816860 Test Loss: 0.3389031 MAE Loss: 0.3452845\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:13,  7.80it/s]\titers: 100, epoch: 7 | loss: 0.1816242\n",
      "\tspeed: 1.1272s/iter; left time: 58480.9936s\n",
      "199it [00:26,  7.71it/s]\titers: 200, epoch: 7 | loss: 0.1633084\n",
      "\tspeed: 0.1325s/iter; left time: 6861.9220s\n",
      "299it [00:39,  6.62it/s]\titers: 300, epoch: 7 | loss: 0.4109701\n",
      "\tspeed: 0.1303s/iter; left time: 6732.9699s\n",
      "399it [00:52,  7.70it/s]\titers: 400, epoch: 7 | loss: 0.1848504\n",
      "\tspeed: 0.1319s/iter; left time: 6801.2247s\n",
      "499it [01:06,  7.82it/s]\titers: 500, epoch: 7 | loss: 0.1937406\n",
      "\tspeed: 0.1319s/iter; left time: 6792.5681s\n",
      "599it [01:19,  7.74it/s]\titers: 600, epoch: 7 | loss: 0.0962959\n",
      "\tspeed: 0.1294s/iter; left time: 6649.4411s\n",
      "699it [01:32,  7.74it/s]\titers: 700, epoch: 7 | loss: 0.1348601\n",
      "\tspeed: 0.1327s/iter; left time: 6805.7421s\n",
      "799it [01:45,  7.12it/s]\titers: 800, epoch: 7 | loss: 0.2012894\n",
      "\tspeed: 0.1339s/iter; left time: 6852.5888s\n",
      "899it [01:58,  7.69it/s]\titers: 900, epoch: 7 | loss: 0.1680372\n",
      "\tspeed: 0.1284s/iter; left time: 6560.7507s\n",
      "999it [02:11,  7.83it/s]\titers: 1000, epoch: 7 | loss: 0.1848904\n",
      "\tspeed: 0.1324s/iter; left time: 6752.3672s\n",
      "1099it [02:24,  7.76it/s]\titers: 1100, epoch: 7 | loss: 0.2683204\n",
      "\tspeed: 0.1306s/iter; left time: 6644.5460s\n",
      "1199it [02:37,  7.81it/s]\titers: 1200, epoch: 7 | loss: 0.1783266\n",
      "\tspeed: 0.1307s/iter; left time: 6635.1892s\n",
      "1299it [02:51,  7.81it/s]\titers: 1300, epoch: 7 | loss: 0.2116267\n",
      "\tspeed: 0.1316s/iter; left time: 6672.1216s\n",
      "1399it [03:04,  7.88it/s]\titers: 1400, epoch: 7 | loss: 0.4300954\n",
      "\tspeed: 0.1296s/iter; left time: 6554.1266s\n",
      "1499it [03:16,  7.76it/s]\titers: 1500, epoch: 7 | loss: 0.0957096\n",
      "\tspeed: 0.1279s/iter; left time: 6455.3211s\n",
      "1599it [03:29,  8.00it/s]\titers: 1600, epoch: 7 | loss: 0.4175620\n",
      "\tspeed: 0.1294s/iter; left time: 6520.7315s\n",
      "1699it [03:42,  7.43it/s]\titers: 1700, epoch: 7 | loss: 0.2002852\n",
      "\tspeed: 0.1288s/iter; left time: 6477.2554s\n",
      "1799it [03:55,  7.83it/s]\titers: 1800, epoch: 7 | loss: 0.2869585\n",
      "\tspeed: 0.1286s/iter; left time: 6455.9009s\n",
      "1899it [04:08,  7.75it/s]\titers: 1900, epoch: 7 | loss: 0.1711172\n",
      "\tspeed: 0.1300s/iter; left time: 6509.2525s\n",
      "1999it [04:21,  7.80it/s]\titers: 2000, epoch: 7 | loss: 0.3147885\n",
      "\tspeed: 0.1288s/iter; left time: 6437.5564s\n",
      "2099it [04:35,  7.93it/s]\titers: 2100, epoch: 7 | loss: 0.1433862\n",
      "\tspeed: 0.1450s/iter; left time: 7235.4068s\n",
      "2199it [04:48,  7.88it/s]\titers: 2200, epoch: 7 | loss: 0.1799153\n",
      "\tspeed: 0.1296s/iter; left time: 6449.9507s\n",
      "2299it [05:01,  7.53it/s]\titers: 2300, epoch: 7 | loss: 0.1999256\n",
      "\tspeed: 0.1305s/iter; left time: 6482.0212s\n",
      "2399it [05:15,  7.93it/s]\titers: 2400, epoch: 7 | loss: 0.1239488\n",
      "\tspeed: 0.1312s/iter; left time: 6503.9396s\n",
      "2499it [05:28,  7.69it/s]\titers: 2500, epoch: 7 | loss: 0.1484330\n",
      "\tspeed: 0.1319s/iter; left time: 6528.7910s\n",
      "2599it [05:41,  7.67it/s]\titers: 2600, epoch: 7 | loss: 0.1561098\n",
      "\tspeed: 0.1312s/iter; left time: 6480.4592s\n",
      "2699it [05:54,  7.61it/s]\titers: 2700, epoch: 7 | loss: 0.1467226\n",
      "\tspeed: 0.1342s/iter; left time: 6612.1262s\n",
      "2799it [06:08,  7.45it/s]\titers: 2800, epoch: 7 | loss: 0.1576784\n",
      "\tspeed: 0.1333s/iter; left time: 6553.8863s\n",
      "2899it [06:20,  7.85it/s]\titers: 2900, epoch: 7 | loss: 0.1832876\n",
      "\tspeed: 0.1283s/iter; left time: 6298.7057s\n",
      "2999it [06:34,  7.72it/s]\titers: 3000, epoch: 7 | loss: 0.3054015\n",
      "\tspeed: 0.1317s/iter; left time: 6452.3426s\n",
      "3099it [06:47,  6.88it/s]\titers: 3100, epoch: 7 | loss: 0.1696397\n",
      "\tspeed: 0.1321s/iter; left time: 6456.8004s\n",
      "3199it [07:00,  7.83it/s]\titers: 3200, epoch: 7 | loss: 0.2006701\n",
      "\tspeed: 0.1279s/iter; left time: 6237.4040s\n",
      "3299it [07:13,  7.78it/s]\titers: 3300, epoch: 7 | loss: 0.2382244\n",
      "\tspeed: 0.1339s/iter; left time: 6516.2320s\n",
      "3399it [07:26,  8.01it/s]\titers: 3400, epoch: 7 | loss: 0.1469581\n",
      "\tspeed: 0.1312s/iter; left time: 6373.5756s\n",
      "3499it [07:39,  7.43it/s]\titers: 3500, epoch: 7 | loss: 0.1741498\n",
      "\tspeed: 0.1296s/iter; left time: 6284.3976s\n",
      "3599it [07:52,  7.50it/s]\titers: 3600, epoch: 7 | loss: 0.1849421\n",
      "\tspeed: 0.1312s/iter; left time: 6349.1515s\n",
      "3699it [08:05,  7.76it/s]\titers: 3700, epoch: 7 | loss: 0.1843563\n",
      "\tspeed: 0.1320s/iter; left time: 6373.8388s\n",
      "3713it [08:07,  7.61it/s]\n",
      "Epoch: 7 cost time: 487.79139137268066\n",
      "810it [00:48, 16.80it/s]\n",
      "807it [00:48, 16.67it/s]\n",
      "Epoch: 7 | Train Loss: 0.2013410 Vali Loss: 0.2826792 Test Loss: 0.3383601 MAE Loss: 0.3447699\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:13,  7.61it/s]\titers: 100, epoch: 8 | loss: 0.1279582\n",
      "\tspeed: 1.1217s/iter; left time: 54032.8632s\n",
      "199it [00:26,  7.67it/s]\titers: 200, epoch: 8 | loss: 0.2164734\n",
      "\tspeed: 0.1313s/iter; left time: 6312.1012s\n",
      "299it [00:39,  7.58it/s]\titers: 300, epoch: 8 | loss: 0.1220205\n",
      "\tspeed: 0.1306s/iter; left time: 6264.8663s\n",
      "399it [00:53,  7.77it/s]\titers: 400, epoch: 8 | loss: 0.2323599\n",
      "\tspeed: 0.1332s/iter; left time: 6375.1941s\n",
      "499it [01:06,  6.51it/s]\titers: 500, epoch: 8 | loss: 0.1516758\n",
      "\tspeed: 0.1335s/iter; left time: 6379.6197s\n",
      "599it [01:19,  7.56it/s]\titers: 600, epoch: 8 | loss: 0.2472006\n",
      "\tspeed: 0.1297s/iter; left time: 6185.1197s\n",
      "699it [01:32,  7.70it/s]\titers: 700, epoch: 8 | loss: 0.3572842\n",
      "\tspeed: 0.1317s/iter; left time: 6264.4968s\n",
      "799it [01:45,  6.39it/s]\titers: 800, epoch: 8 | loss: 0.2375330\n",
      "\tspeed: 0.1309s/iter; left time: 6214.5150s\n",
      "899it [01:58,  7.84it/s]\titers: 900, epoch: 8 | loss: 0.1513738\n",
      "\tspeed: 0.1276s/iter; left time: 6045.1114s\n",
      "999it [02:11,  7.81it/s]\titers: 1000, epoch: 8 | loss: 0.2617031\n",
      "\tspeed: 0.1335s/iter; left time: 6311.8158s\n",
      "1099it [02:24,  7.81it/s]\titers: 1100, epoch: 8 | loss: 0.1723645\n",
      "\tspeed: 0.1315s/iter; left time: 6201.8919s\n",
      "1199it [02:37,  7.50it/s]\titers: 1200, epoch: 8 | loss: 0.2137951\n",
      "\tspeed: 0.1289s/iter; left time: 6067.7133s\n",
      "1299it [02:50,  7.82it/s]\titers: 1300, epoch: 8 | loss: 0.3421403\n",
      "\tspeed: 0.1281s/iter; left time: 6016.7453s\n",
      "1399it [03:03,  7.76it/s]\titers: 1400, epoch: 8 | loss: 0.2555632\n",
      "\tspeed: 0.1320s/iter; left time: 6188.1950s\n",
      "1499it [03:16,  7.19it/s]\titers: 1500, epoch: 8 | loss: 0.1085190\n",
      "\tspeed: 0.1298s/iter; left time: 6072.6476s\n",
      "1599it [03:29,  7.78it/s]\titers: 1600, epoch: 8 | loss: 0.2211587\n",
      "\tspeed: 0.1300s/iter; left time: 6066.0828s\n",
      "1699it [03:42,  7.77it/s]\titers: 1700, epoch: 8 | loss: 0.2141633\n",
      "\tspeed: 0.1314s/iter; left time: 6121.5817s\n",
      "1799it [03:55,  7.86it/s]\titers: 1800, epoch: 8 | loss: 0.1186428\n",
      "\tspeed: 0.1304s/iter; left time: 6059.8979s\n",
      "1899it [04:08,  7.69it/s]\titers: 1900, epoch: 8 | loss: 0.1627512\n",
      "\tspeed: 0.1292s/iter; left time: 5991.3989s\n",
      "1999it [04:22,  7.61it/s]\titers: 2000, epoch: 8 | loss: 0.2959258\n",
      "\tspeed: 0.1339s/iter; left time: 6193.7442s\n",
      "2099it [04:35,  6.55it/s]\titers: 2100, epoch: 8 | loss: 0.2173650\n",
      "\tspeed: 0.1332s/iter; left time: 6150.1055s\n",
      "2199it [04:48,  7.42it/s]\titers: 2200, epoch: 8 | loss: 0.2223504\n",
      "\tspeed: 0.1291s/iter; left time: 5947.2999s\n",
      "2299it [05:01,  7.96it/s]\titers: 2300, epoch: 8 | loss: 0.2041960\n",
      "\tspeed: 0.1307s/iter; left time: 6007.4042s\n",
      "2399it [05:14,  7.93it/s]\titers: 2400, epoch: 8 | loss: 0.2009455\n",
      "\tspeed: 0.1287s/iter; left time: 5901.4440s\n",
      "2499it [05:27,  7.69it/s]\titers: 2500, epoch: 8 | loss: 0.2436721\n",
      "\tspeed: 0.1268s/iter; left time: 5802.1276s\n",
      "2599it [05:39,  7.79it/s]\titers: 2600, epoch: 8 | loss: 0.1071552\n",
      "\tspeed: 0.1284s/iter; left time: 5863.6868s\n",
      "2699it [05:52,  7.87it/s]\titers: 2700, epoch: 8 | loss: 0.2414134\n",
      "\tspeed: 0.1288s/iter; left time: 5870.4132s\n",
      "2799it [06:05,  7.30it/s]\titers: 2800, epoch: 8 | loss: 0.1024023\n",
      "\tspeed: 0.1283s/iter; left time: 5832.5339s\n",
      "2899it [06:18,  7.78it/s]\titers: 2900, epoch: 8 | loss: 0.2330065\n",
      "\tspeed: 0.1286s/iter; left time: 5834.4799s\n",
      "2999it [06:31,  7.83it/s]\titers: 3000, epoch: 8 | loss: 0.1946887\n",
      "\tspeed: 0.1304s/iter; left time: 5904.6926s\n",
      "3099it [06:44,  7.95it/s]\titers: 3100, epoch: 8 | loss: 0.3304685\n",
      "\tspeed: 0.1280s/iter; left time: 5780.3157s\n",
      "3199it [06:57,  7.89it/s]\titers: 3200, epoch: 8 | loss: 0.1626873\n",
      "\tspeed: 0.1278s/iter; left time: 5761.1602s\n",
      "3299it [07:10,  7.92it/s]\titers: 3300, epoch: 8 | loss: 0.2423405\n",
      "\tspeed: 0.1289s/iter; left time: 5797.7545s\n",
      "3399it [07:22,  7.11it/s]\titers: 3400, epoch: 8 | loss: 0.1369114\n",
      "\tspeed: 0.1284s/iter; left time: 5763.3125s\n",
      "3499it [07:35,  7.85it/s]\titers: 3500, epoch: 8 | loss: 0.2636695\n",
      "\tspeed: 0.1270s/iter; left time: 5685.8544s\n",
      "3599it [07:48,  7.82it/s]\titers: 3600, epoch: 8 | loss: 0.1168666\n",
      "\tspeed: 0.1300s/iter; left time: 5806.8647s\n",
      "3699it [08:01,  7.88it/s]\titers: 3700, epoch: 8 | loss: 0.2894470\n",
      "\tspeed: 0.1322s/iter; left time: 5892.7150s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 8 cost time: 483.6595969200134\n",
      "810it [00:48, 16.70it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 8 | Train Loss: 0.2007458 Vali Loss: 0.2816134 Test Loss: 0.3387974 MAE Loss: 0.3444809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:13,  7.88it/s]\titers: 100, epoch: 9 | loss: 0.2003011\n",
      "\tspeed: 1.1243s/iter; left time: 49983.0702s\n",
      "199it [00:26,  6.40it/s]\titers: 200, epoch: 9 | loss: 0.1307631\n",
      "\tspeed: 0.1314s/iter; left time: 5828.2518s\n",
      "299it [00:39,  7.77it/s]\titers: 300, epoch: 9 | loss: 0.1951911\n",
      "\tspeed: 0.1266s/iter; left time: 5601.8584s\n",
      "399it [00:52,  7.63it/s]\titers: 400, epoch: 9 | loss: 0.1443585\n",
      "\tspeed: 0.1310s/iter; left time: 5786.4324s\n",
      "499it [01:05,  7.77it/s]\titers: 500, epoch: 9 | loss: 0.1766445\n",
      "\tspeed: 0.1335s/iter; left time: 5882.2023s\n",
      "599it [01:18,  6.87it/s]\titers: 600, epoch: 9 | loss: 0.1759405\n",
      "\tspeed: 0.1306s/iter; left time: 5741.5441s\n",
      "699it [01:31,  7.57it/s]\titers: 700, epoch: 9 | loss: 0.1444973\n",
      "\tspeed: 0.1298s/iter; left time: 5691.3585s\n",
      "799it [01:45,  7.95it/s]\titers: 800, epoch: 9 | loss: 0.2164062\n",
      "\tspeed: 0.1331s/iter; left time: 5825.1980s\n",
      "899it [01:57,  7.83it/s]\titers: 900, epoch: 9 | loss: 0.1583990\n",
      "\tspeed: 0.1294s/iter; left time: 5650.7521s\n",
      "999it [02:10,  7.59it/s]\titers: 1000, epoch: 9 | loss: 0.2654483\n",
      "\tspeed: 0.1297s/iter; left time: 5648.9689s\n",
      "1099it [02:23,  7.86it/s]\titers: 1100, epoch: 9 | loss: 0.2316056\n",
      "\tspeed: 0.1305s/iter; left time: 5672.6459s\n",
      "1199it [02:36,  7.93it/s]\titers: 1200, epoch: 9 | loss: 0.1286955\n",
      "\tspeed: 0.1289s/iter; left time: 5587.1203s\n",
      "1299it [02:49,  7.67it/s]\titers: 1300, epoch: 9 | loss: 0.1373106\n",
      "\tspeed: 0.1284s/iter; left time: 5554.4789s\n",
      "1399it [03:02,  7.70it/s]\titers: 1400, epoch: 9 | loss: 0.2391982\n",
      "\tspeed: 0.1314s/iter; left time: 5671.0211s\n",
      "1499it [03:15,  7.88it/s]\titers: 1500, epoch: 9 | loss: 0.3220335\n",
      "\tspeed: 0.1288s/iter; left time: 5546.5328s\n",
      "1599it [03:28,  7.77it/s]\titers: 1600, epoch: 9 | loss: 0.1655974\n",
      "\tspeed: 0.1283s/iter; left time: 5512.2614s\n",
      "1699it [03:41,  7.86it/s]\titers: 1700, epoch: 9 | loss: 0.2797700\n",
      "\tspeed: 0.1315s/iter; left time: 5633.9515s\n",
      "1799it [03:54,  7.75it/s]\titers: 1800, epoch: 9 | loss: 0.1983084\n",
      "\tspeed: 0.1306s/iter; left time: 5584.8375s\n",
      "1899it [04:07,  6.38it/s]\titers: 1900, epoch: 9 | loss: 0.1109257\n",
      "\tspeed: 0.1297s/iter; left time: 5533.2509s\n",
      "1999it [04:20,  7.83it/s]\titers: 2000, epoch: 9 | loss: 0.1946364\n",
      "\tspeed: 0.1299s/iter; left time: 5528.4719s\n",
      "2099it [04:33,  7.82it/s]\titers: 2100, epoch: 9 | loss: 0.1541816\n",
      "\tspeed: 0.1308s/iter; left time: 5551.3477s\n",
      "2199it [04:46,  7.72it/s]\titers: 2200, epoch: 9 | loss: 0.1911540\n",
      "\tspeed: 0.1284s/iter; left time: 5439.7692s\n",
      "2299it [04:59,  7.88it/s]\titers: 2300, epoch: 9 | loss: 0.2803768\n",
      "\tspeed: 0.1279s/iter; left time: 5403.8932s\n",
      "2399it [05:12,  7.79it/s]\titers: 2400, epoch: 9 | loss: 0.2161340\n",
      "\tspeed: 0.1297s/iter; left time: 5467.3670s\n",
      "2499it [05:25,  7.83it/s]\titers: 2500, epoch: 9 | loss: 0.1608322\n",
      "\tspeed: 0.1297s/iter; left time: 5455.5505s\n",
      "2599it [05:38,  7.84it/s]\titers: 2600, epoch: 9 | loss: 0.1170731\n",
      "\tspeed: 0.1276s/iter; left time: 5354.3577s\n",
      "2699it [05:51,  7.86it/s]\titers: 2700, epoch: 9 | loss: 0.1482374\n",
      "\tspeed: 0.1318s/iter; left time: 5517.3851s\n",
      "2799it [06:04,  7.87it/s]\titers: 2800, epoch: 9 | loss: 0.2600410\n",
      "\tspeed: 0.1296s/iter; left time: 5410.1335s\n",
      "2899it [06:17,  7.42it/s]\titers: 2900, epoch: 9 | loss: 0.2394323\n",
      "\tspeed: 0.1295s/iter; left time: 5393.1266s\n",
      "2999it [06:29,  7.99it/s]\titers: 3000, epoch: 9 | loss: 0.1812843\n",
      "\tspeed: 0.1276s/iter; left time: 5303.7687s\n",
      "3099it [06:42,  7.88it/s]\titers: 3100, epoch: 9 | loss: 0.2702093\n",
      "\tspeed: 0.1299s/iter; left time: 5387.1313s\n",
      "3199it [06:55,  7.84it/s]\titers: 3200, epoch: 9 | loss: 0.2112910\n",
      "\tspeed: 0.1270s/iter; left time: 5253.5577s\n",
      "3299it [07:08,  7.86it/s]\titers: 3300, epoch: 9 | loss: 0.1367011\n",
      "\tspeed: 0.1280s/iter; left time: 5279.4883s\n",
      "3399it [07:21,  7.88it/s]\titers: 3400, epoch: 9 | loss: 0.1591177\n",
      "\tspeed: 0.1286s/iter; left time: 5292.4345s\n",
      "3499it [07:34,  7.99it/s]\titers: 3500, epoch: 9 | loss: 0.1455339\n",
      "\tspeed: 0.1270s/iter; left time: 5212.6109s\n",
      "3599it [07:46,  7.83it/s]\titers: 3600, epoch: 9 | loss: 0.1673865\n",
      "\tspeed: 0.1271s/iter; left time: 5207.4104s\n",
      "3699it [07:59,  7.85it/s]\titers: 3700, epoch: 9 | loss: 0.1879564\n",
      "\tspeed: 0.1306s/iter; left time: 5336.2904s\n",
      "3713it [08:01,  7.71it/s]\n",
      "Epoch: 9 cost time: 481.6420624256134\n",
      "810it [00:48, 16.75it/s]\n",
      "807it [00:48, 16.78it/s]\n",
      "Epoch: 9 | Train Loss: 0.2000246 Vali Loss: 0.2808785 Test Loss: 0.3386556 MAE Loss: 0.3452881\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 10 | loss: 0.1908673\n",
      "\tspeed: 1.1199s/iter; left time: 45628.1615s\n",
      "199it [00:26,  7.96it/s]\titers: 200, epoch: 10 | loss: 0.1978689\n",
      "\tspeed: 0.1302s/iter; left time: 5293.0266s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 10 | loss: 0.1750423\n",
      "\tspeed: 0.1282s/iter; left time: 5197.4612s\n",
      "399it [00:52,  7.82it/s]\titers: 400, epoch: 10 | loss: 0.2005215\n",
      "\tspeed: 0.1287s/iter; left time: 5204.7362s\n",
      "499it [01:04,  7.85it/s]\titers: 500, epoch: 10 | loss: 0.1575629\n",
      "\tspeed: 0.1291s/iter; left time: 5207.0451s\n",
      "599it [01:17,  7.89it/s]\titers: 600, epoch: 10 | loss: 0.1473856\n",
      "\tspeed: 0.1276s/iter; left time: 5136.4176s\n",
      "699it [01:30,  7.82it/s]\titers: 700, epoch: 10 | loss: 0.1861153\n",
      "\tspeed: 0.1282s/iter; left time: 5146.3839s\n",
      "799it [01:43,  7.72it/s]\titers: 800, epoch: 10 | loss: 0.2066590\n",
      "\tspeed: 0.1309s/iter; left time: 5243.5751s\n",
      "899it [01:56,  7.84it/s]\titers: 900, epoch: 10 | loss: 0.1746807\n",
      "\tspeed: 0.1294s/iter; left time: 5168.2416s\n",
      "999it [02:09,  7.64it/s]\titers: 1000, epoch: 10 | loss: 0.1866677\n",
      "\tspeed: 0.1284s/iter; left time: 5115.1388s\n",
      "1099it [02:22,  7.85it/s]\titers: 1100, epoch: 10 | loss: 0.1075767\n",
      "\tspeed: 0.1301s/iter; left time: 5170.8340s\n",
      "1199it [02:35,  7.81it/s]\titers: 1200, epoch: 10 | loss: 0.1957726\n",
      "\tspeed: 0.1301s/iter; left time: 5157.6115s\n",
      "1299it [02:48,  7.68it/s]\titers: 1300, epoch: 10 | loss: 0.1697790\n",
      "\tspeed: 0.1292s/iter; left time: 5107.9951s\n",
      "1399it [03:01,  7.85it/s]\titers: 1400, epoch: 10 | loss: 0.2389533\n",
      "\tspeed: 0.1280s/iter; left time: 5047.3476s\n",
      "1499it [03:14,  7.74it/s]\titers: 1500, epoch: 10 | loss: 0.3297002\n",
      "\tspeed: 0.1303s/iter; left time: 5125.3429s\n",
      "1599it [03:27,  7.69it/s]\titers: 1600, epoch: 10 | loss: 0.2177351\n",
      "\tspeed: 0.1314s/iter; left time: 5158.6034s\n",
      "1699it [03:40,  7.04it/s]\titers: 1700, epoch: 10 | loss: 0.1073710\n",
      "\tspeed: 0.1296s/iter; left time: 5074.4227s\n",
      "1799it [03:53,  7.79it/s]\titers: 1800, epoch: 10 | loss: 0.3009464\n",
      "\tspeed: 0.1311s/iter; left time: 5120.0122s\n",
      "1899it [04:06,  7.81it/s]\titers: 1900, epoch: 10 | loss: 0.3686776\n",
      "\tspeed: 0.1312s/iter; left time: 5110.3391s\n",
      "1999it [04:19,  7.10it/s]\titers: 2000, epoch: 10 | loss: 0.1824735\n",
      "\tspeed: 0.1305s/iter; left time: 5069.4684s\n",
      "2058it [04:27,  7.85it/s]^C\n",
      "2058it [04:27,  7.70it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 237, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 2002, in backward\n",
      "    self.allreduce_gradients()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1918, in allreduce_gradients\n",
      "    self.optimizer.overlapping_partition_gradients_reduce_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 859, in overlapping_partition_gradients_reduce_epilogue\n",
      "    self.independent_gradient_partition_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 760, in independent_gradient_partition_epilogue\n",
      "    get_accelerator().synchronize()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/accelerator/cuda_accelerator.py\", line 77, in synchronize\n",
      "    return torch.cuda.synchronize(device_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 801, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 92.78709202210108 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-03 23:11:43,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:11:43,917] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-03 23:11:46,684] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "d_llm 768\n",
      "[2024-05-03 23:11:47,587] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 23:11:47,588] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 23:11:47,588] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 23:11:47,589] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 23:11:47,589] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 23:11:47,589] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "0it [00:00, ?it/s][2024-05-03 23:11:47,892] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 23:11:47,893] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.5 GB         CA 0.51 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:47,893] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 204.92 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.55 GB         CA 0.61 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 204.96 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,183] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 23:11:48,312] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 23:11:48,313] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.45 GB         CA 0.61 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:48,313] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 205.09 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe8c48dbb10>\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   train_batch_size ............. 48\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   world_size ................... 2\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 23:11:48,316] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 48, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 215, in <module>\n",
      "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1852, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/models/TimeLLM.py\", line 238, in forward\n",
      "    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/models/TimeLLM.py\", line 285, in forecast\n",
      "    dec_out = self.llm_model(inputs_embeds=llama_enc_out).last_hidden_state\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 900, in forward\n",
      "    outputs = block(\n",
      "              ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 391, in forward\n",
      "    attn_outputs = self.attn(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 332, in forward\n",
      "    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 213, in _attn\n",
      "    attn_weights = self.attn_dropout(attn_weights)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 59, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1268, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 1 has a total capacity of 79.32 GiB of which 2.50 MiB is free. Process 26038 has 77.25 GiB memory in use. Including non-PyTorch memory, this process has 2.04 GiB memory in use. Of the allocated memory 1.30 GiB is allocated by PyTorch, and 86.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[2024-05-03 23:11:53,794] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 65363 closing signal SIGTERM\n",
      "[2024-05-03 23:11:54,009] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 65364) of binary: /usr/local/anaconda3-2023.03/envs/python311/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1048, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 702, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-05-03_23:11:53\n",
      "  host      : gruenau10.informatik.hu-berlin.de\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 65364)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "Total time: 0.3587648391723633 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 2\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --multi_gpu --mixed_precision bf16 --num_processes=2 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ist /vol/cs-hu/riabchuv/.conda/envs/val/bin/python\n"
     ]
    }
   ],
   "source": [
    "!type python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.27s/it]\n",
      "d_llm 4096\n",
      "[2024-05-05 14:44:49,542] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-05 14:44:50,436] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-05 14:44:50,436] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-05 14:44:50,436] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-05 14:44:51,504] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-05 14:44:51,504] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-05 14:45:03,352] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-05 14:45:03,356] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-05 14:45:03,356] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-05 14:45:03,357] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-05 14:45:03,357] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-05 14:45:03,357] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-05 14:45:03,358] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-05 14:45:03,358] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-05 14:45:03,358] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-05 14:45:03,358] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-05 14:45:03,770] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-05 14:45:03,770] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-05 14:45:03,772] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 266.85 GB, percent = 35.4%\n",
      "[2024-05-05 14:45:04,104] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-05 14:45:04,105] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 14:45:04,105] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 271.48 GB, percent = 36.0%\n",
      "[2024-05-05 14:45:04,105] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-05 14:45:04,265] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-05 14:45:04,266] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 14:45:04,266] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 272.95 GB, percent = 36.2%\n",
      "[2024-05-05 14:45:04,267] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-05 14:45:04,267] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-05 14:45:04,267] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-05 14:45:04,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-05 14:45:04,268] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-05 14:45:04,268] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-05 14:45:04,268] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-05 14:45:04,268] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-05 14:45:04,268] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe2e9ff99d0>\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-05 14:45:04,269] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   train_batch_size ............. 3\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-05 14:45:04,270] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 3, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:17,  5.96it/s]\titers: 100, epoch: 1 | loss: 0.9995176\n",
      "\tspeed: 0.3406s/iter; left time: 10084.6244s\n",
      "199it [00:34,  5.91it/s]\titers: 200, epoch: 1 | loss: 0.7528370\n",
      "\tspeed: 0.1704s/iter; left time: 5028.9147s\n",
      "299it [00:52,  5.84it/s]\titers: 300, epoch: 1 | loss: 0.6342762\n",
      "\tspeed: 0.1719s/iter; left time: 5054.5693s\n",
      "399it [01:09,  5.96it/s]\titers: 400, epoch: 1 | loss: 0.1369442\n",
      "\tspeed: 0.1742s/iter; left time: 5105.1180s\n",
      "499it [01:26,  5.93it/s]\titers: 500, epoch: 1 | loss: 1.7759447\n",
      "\tspeed: 0.1717s/iter; left time: 5015.7862s\n",
      "599it [01:43,  5.83it/s]\titers: 600, epoch: 1 | loss: 0.7212697\n",
      "\tspeed: 0.1724s/iter; left time: 5018.9003s\n",
      "699it [02:01,  5.89it/s]\titers: 700, epoch: 1 | loss: 0.1912604\n",
      "\tspeed: 0.1732s/iter; left time: 5024.4249s\n",
      "799it [02:18,  5.94it/s]\titers: 800, epoch: 1 | loss: 0.1718992\n",
      "\tspeed: 0.1715s/iter; left time: 4955.9986s\n",
      "899it [02:35,  5.88it/s]\titers: 900, epoch: 1 | loss: 0.2013323\n",
      "\tspeed: 0.1724s/iter; left time: 4966.5460s\n",
      "999it [02:53,  5.87it/s]\titers: 1000, epoch: 1 | loss: 1.1996839\n",
      "\tspeed: 0.1749s/iter; left time: 5020.9132s\n",
      "1099it [03:10,  5.93it/s]\titers: 1100, epoch: 1 | loss: 0.2342540\n",
      "\tspeed: 0.1737s/iter; left time: 4969.8234s\n",
      "1199it [03:27,  5.63it/s]\titers: 1200, epoch: 1 | loss: 1.5789831\n",
      "\tspeed: 0.1736s/iter; left time: 4948.5152s\n",
      "1299it [03:44,  5.78it/s]\titers: 1300, epoch: 1 | loss: 0.3627469\n",
      "\tspeed: 0.1710s/iter; left time: 4857.3022s\n",
      "1399it [04:02,  5.39it/s]\titers: 1400, epoch: 1 | loss: 0.4371550\n",
      "\tspeed: 0.1738s/iter; left time: 4919.5517s\n",
      "1499it [04:19,  5.86it/s]\titers: 1500, epoch: 1 | loss: 0.2585745\n",
      "\tspeed: 0.1731s/iter; left time: 4883.5297s\n",
      "1599it [04:36,  5.83it/s]\titers: 1600, epoch: 1 | loss: 0.1844499\n",
      "\tspeed: 0.1733s/iter; left time: 4869.5544s\n",
      "1699it [04:54,  5.81it/s]\titers: 1700, epoch: 1 | loss: 0.1986266\n",
      "\tspeed: 0.1731s/iter; left time: 4848.0310s\n",
      "1799it [05:11,  5.88it/s]\titers: 1800, epoch: 1 | loss: 0.2149292\n",
      "\tspeed: 0.1726s/iter; left time: 4815.3267s\n",
      "1899it [05:28,  5.81it/s]\titers: 1900, epoch: 1 | loss: 0.2028953\n",
      "\tspeed: 0.1736s/iter; left time: 4828.0226s\n",
      "1999it [05:46,  5.84it/s]\titers: 2000, epoch: 1 | loss: 0.4653367\n",
      "\tspeed: 0.1744s/iter; left time: 4830.9709s\n",
      "2099it [06:03,  5.87it/s]\titers: 2100, epoch: 1 | loss: 0.1648085\n",
      "\tspeed: 0.1732s/iter; left time: 4780.1288s\n",
      "2199it [06:21,  4.83it/s]\titers: 2200, epoch: 1 | loss: 0.4138450\n",
      "\tspeed: 0.1737s/iter; left time: 4779.0368s\n",
      "2299it [06:38,  5.81it/s]\titers: 2300, epoch: 1 | loss: 0.2147816\n",
      "\tspeed: 0.1716s/iter; left time: 4701.8116s\n",
      "2399it [06:55,  5.91it/s]\titers: 2400, epoch: 1 | loss: 0.1635985\n",
      "\tspeed: 0.1726s/iter; left time: 4712.4236s\n",
      "2499it [07:12,  5.82it/s]\titers: 2500, epoch: 1 | loss: 0.3079199\n",
      "\tspeed: 0.1735s/iter; left time: 4719.6876s\n",
      "2599it [07:30,  5.88it/s]\titers: 2600, epoch: 1 | loss: 0.1539550\n",
      "\tspeed: 0.1738s/iter; left time: 4711.1707s\n",
      "2699it [07:47,  5.78it/s]\titers: 2700, epoch: 1 | loss: 0.1684938\n",
      "\tspeed: 0.1769s/iter; left time: 4778.3302s\n",
      "2799it [08:05,  5.81it/s]\titers: 2800, epoch: 1 | loss: 0.1634436\n",
      "\tspeed: 0.1764s/iter; left time: 4745.4727s\n",
      "2899it [08:22,  5.76it/s]\titers: 2900, epoch: 1 | loss: 0.3425570\n",
      "\tspeed: 0.1737s/iter; left time: 4655.4046s\n",
      "2999it [08:40,  5.79it/s]\titers: 3000, epoch: 1 | loss: 0.1012242\n",
      "\tspeed: 0.1768s/iter; left time: 4722.7634s\n",
      "3099it [08:58,  5.78it/s]\titers: 3100, epoch: 1 | loss: 0.9708627\n",
      "\tspeed: 0.1765s/iter; left time: 4696.6624s\n",
      "3199it [09:15,  5.87it/s]\titers: 3200, epoch: 1 | loss: 0.5205498\n",
      "\tspeed: 0.1731s/iter; left time: 4588.3170s\n",
      "3299it [09:32,  5.82it/s]\titers: 3300, epoch: 1 | loss: 0.1735685\n",
      "\tspeed: 0.1728s/iter; left time: 4564.2558s\n",
      "3399it [09:50,  5.92it/s]\titers: 3400, epoch: 1 | loss: 0.1689824\n",
      "\tspeed: 0.1740s/iter; left time: 4578.4159s\n",
      "3499it [10:07,  5.82it/s]\titers: 3500, epoch: 1 | loss: 0.4004982\n",
      "\tspeed: 0.1734s/iter; left time: 4544.5573s\n",
      "3599it [10:24,  5.84it/s]\titers: 3600, epoch: 1 | loss: 0.3065372\n",
      "\tspeed: 0.1735s/iter; left time: 4528.9785s\n",
      "3699it [10:42,  5.80it/s]\titers: 3700, epoch: 1 | loss: 0.1145960\n",
      "\tspeed: 0.1724s/iter; left time: 4482.5472s\n",
      "3799it [10:59,  5.70it/s]\titers: 3800, epoch: 1 | loss: 0.2801390\n",
      "\tspeed: 0.1730s/iter; left time: 4480.4576s\n",
      "3899it [11:16,  5.75it/s]\titers: 3900, epoch: 1 | loss: 0.1654157\n",
      "\tspeed: 0.1707s/iter; left time: 4405.1569s\n",
      "3999it [11:33,  5.78it/s]\titers: 4000, epoch: 1 | loss: 0.1941476\n",
      "\tspeed: 0.1718s/iter; left time: 4417.3755s\n",
      "4099it [11:51,  5.78it/s]\titers: 4100, epoch: 1 | loss: 0.1112789\n",
      "\tspeed: 0.1742s/iter; left time: 4459.4255s\n",
      "4199it [12:08,  5.82it/s]\titers: 4200, epoch: 1 | loss: 0.0875820\n",
      "\tspeed: 0.1727s/iter; left time: 4405.4652s\n",
      "4299it [12:25,  5.83it/s]\titers: 4300, epoch: 1 | loss: 0.1463878\n",
      "\tspeed: 0.1723s/iter; left time: 4376.9867s\n",
      "4399it [12:42,  5.87it/s]\titers: 4400, epoch: 1 | loss: 0.8804156\n",
      "\tspeed: 0.1716s/iter; left time: 4342.0831s\n",
      "4499it [12:59,  5.83it/s]\titers: 4500, epoch: 1 | loss: 0.1141298\n",
      "\tspeed: 0.1695s/iter; left time: 4272.8979s\n",
      "4599it [13:17,  5.75it/s]\titers: 4600, epoch: 1 | loss: 0.1119518\n",
      "\tspeed: 0.1732s/iter; left time: 4347.9817s\n",
      "4699it [13:34,  5.82it/s]\titers: 4700, epoch: 1 | loss: 0.7007938\n",
      "\tspeed: 0.1736s/iter; left time: 4342.0597s\n",
      "4799it [13:51,  5.79it/s]\titers: 4800, epoch: 1 | loss: 0.3734833\n",
      "\tspeed: 0.1737s/iter; left time: 4326.8144s\n",
      "4899it [14:09,  5.84it/s]\titers: 4900, epoch: 1 | loss: 0.3359680\n",
      "\tspeed: 0.1731s/iter; left time: 4295.1484s\n",
      "4999it [14:26,  5.84it/s]\titers: 5000, epoch: 1 | loss: 0.2773645\n",
      "\tspeed: 0.1745s/iter; left time: 4310.4248s\n",
      "5099it [14:44,  5.56it/s]\titers: 5100, epoch: 1 | loss: 0.8992349\n",
      "\tspeed: 0.1753s/iter; left time: 4312.5897s\n",
      "5199it [15:01,  5.77it/s]\titers: 5200, epoch: 1 | loss: 0.1540292\n",
      "\tspeed: 0.1734s/iter; left time: 4249.4105s\n",
      "5299it [15:18,  5.84it/s]\titers: 5300, epoch: 1 | loss: 0.2612482\n",
      "\tspeed: 0.1731s/iter; left time: 4224.9300s\n",
      "5399it [15:35,  5.92it/s]\titers: 5400, epoch: 1 | loss: 0.1455708\n",
      "\tspeed: 0.1725s/iter; left time: 4193.8816s\n",
      "5499it [15:53,  5.79it/s]\titers: 5500, epoch: 1 | loss: 0.1947661\n",
      "\tspeed: 0.1710s/iter; left time: 4140.0533s\n",
      "5599it [16:10,  5.82it/s]\titers: 5600, epoch: 1 | loss: 0.1214142\n",
      "\tspeed: 0.1730s/iter; left time: 4170.2484s\n",
      "5699it [16:27,  5.87it/s]\titers: 5700, epoch: 1 | loss: 0.2476432\n",
      "\tspeed: 0.1718s/iter; left time: 4125.0079s\n",
      "5799it [16:44,  5.98it/s]\titers: 5800, epoch: 1 | loss: 0.1254494\n",
      "\tspeed: 0.1700s/iter; left time: 4063.6985s\n",
      "5899it [17:01,  5.30it/s]\titers: 5900, epoch: 1 | loss: 0.2213359\n",
      "\tspeed: 0.1732s/iter; left time: 4122.8547s\n",
      "5999it [17:18,  5.90it/s]\titers: 6000, epoch: 1 | loss: 0.0789860\n",
      "\tspeed: 0.1705s/iter; left time: 4041.2593s\n",
      "6099it [17:36,  5.82it/s]\titers: 6100, epoch: 1 | loss: 0.2488994\n",
      "\tspeed: 0.1720s/iter; left time: 4060.0620s\n",
      "6199it [17:53,  5.85it/s]\titers: 6200, epoch: 1 | loss: 1.0039293\n",
      "\tspeed: 0.1733s/iter; left time: 4074.2232s\n",
      "6299it [18:10,  5.78it/s]\titers: 6300, epoch: 1 | loss: 0.2651639\n",
      "\tspeed: 0.1729s/iter; left time: 4046.7558s\n",
      "6399it [18:28,  5.82it/s]\titers: 6400, epoch: 1 | loss: 0.2597941\n",
      "\tspeed: 0.1741s/iter; left time: 4057.6275s\n",
      "6499it [18:45,  5.81it/s]\titers: 6500, epoch: 1 | loss: 0.1216619\n",
      "\tspeed: 0.1743s/iter; left time: 4045.4198s\n",
      "6599it [19:03,  5.84it/s]\titers: 6600, epoch: 1 | loss: 0.1354033\n",
      "\tspeed: 0.1749s/iter; left time: 4040.1200s\n",
      "6699it [19:20,  5.78it/s]\titers: 6700, epoch: 1 | loss: 0.2305555\n",
      "\tspeed: 0.1730s/iter; left time: 3980.2973s\n",
      "6799it [19:37,  5.90it/s]\titers: 6800, epoch: 1 | loss: 0.1952226\n",
      "\tspeed: 0.1722s/iter; left time: 3945.2286s\n",
      "6899it [19:55,  5.75it/s]\titers: 6900, epoch: 1 | loss: 0.2733072\n",
      "\tspeed: 0.1749s/iter; left time: 3988.5899s\n",
      "6999it [20:12,  5.82it/s]\titers: 7000, epoch: 1 | loss: 0.4113727\n",
      "\tspeed: 0.1726s/iter; left time: 3919.7334s\n",
      "7099it [20:29,  5.81it/s]\titers: 7100, epoch: 1 | loss: 0.5628402\n",
      "\tspeed: 0.1748s/iter; left time: 3951.4248s\n",
      "7199it [20:47,  5.75it/s]\titers: 7200, epoch: 1 | loss: 0.1677743\n",
      "\tspeed: 0.1755s/iter; left time: 3950.8857s\n",
      "7299it [21:04,  5.41it/s]\titers: 7300, epoch: 1 | loss: 0.1742498\n",
      "\tspeed: 0.1730s/iter; left time: 3875.9195s\n",
      "7399it [21:21,  5.62it/s]\titers: 7400, epoch: 1 | loss: 0.1738543\n",
      "\tspeed: 0.1732s/iter; left time: 3863.0005s\n",
      "7499it [21:39,  5.77it/s]\titers: 7500, epoch: 1 | loss: 0.3550659\n",
      "\tspeed: 0.1749s/iter; left time: 3884.6985s\n",
      "7599it [21:56,  5.85it/s]\titers: 7600, epoch: 1 | loss: 0.9472451\n",
      "\tspeed: 0.1731s/iter; left time: 3827.4008s\n",
      "7699it [22:14,  5.75it/s]\titers: 7700, epoch: 1 | loss: 0.1091144\n",
      "\tspeed: 0.1741s/iter; left time: 3831.1742s\n",
      "7799it [22:31,  5.75it/s]\titers: 7800, epoch: 1 | loss: 0.7928885\n",
      "\tspeed: 0.1761s/iter; left time: 3857.9424s\n",
      "7899it [22:49,  5.80it/s]\titers: 7900, epoch: 1 | loss: 0.0686032\n",
      "\tspeed: 0.1744s/iter; left time: 3802.4709s\n",
      "7999it [23:06,  5.89it/s]\titers: 8000, epoch: 1 | loss: 0.1612759\n",
      "\tspeed: 0.1713s/iter; left time: 3717.1567s\n",
      "8099it [23:23,  5.88it/s]\titers: 8100, epoch: 1 | loss: 0.1165099\n",
      "\tspeed: 0.1699s/iter; left time: 3670.6801s\n",
      "8199it [23:40,  5.76it/s]\titers: 8200, epoch: 1 | loss: 0.1135871\n",
      "\tspeed: 0.1713s/iter; left time: 3683.0137s\n",
      "8299it [23:58,  5.62it/s]\titers: 8300, epoch: 1 | loss: 0.1251438\n",
      "\tspeed: 0.1781s/iter; left time: 3812.1797s\n",
      "8399it [24:15,  5.78it/s]\titers: 8400, epoch: 1 | loss: 0.0660727\n",
      "\tspeed: 0.1746s/iter; left time: 3720.3723s\n",
      "8499it [24:33,  5.46it/s]\titers: 8500, epoch: 1 | loss: 0.1437341\n",
      "\tspeed: 0.1733s/iter; left time: 3675.6754s\n",
      "8599it [24:50,  5.81it/s]\titers: 8600, epoch: 1 | loss: 0.2793804\n",
      "\tspeed: 0.1722s/iter; left time: 3635.3750s\n",
      "8699it [25:07,  5.86it/s]\titers: 8700, epoch: 1 | loss: 0.2188035\n",
      "\tspeed: 0.1727s/iter; left time: 3627.7568s\n",
      "8799it [25:24,  5.85it/s]\titers: 8800, epoch: 1 | loss: 0.2560190\n",
      "\tspeed: 0.1724s/iter; left time: 3603.7167s\n",
      "8899it [25:42,  5.80it/s]\titers: 8900, epoch: 1 | loss: 0.1619446\n",
      "\tspeed: 0.1739s/iter; left time: 3618.1103s\n",
      "8999it [25:59,  5.81it/s]\titers: 9000, epoch: 1 | loss: 0.4721746\n",
      "\tspeed: 0.1739s/iter; left time: 3601.6965s\n",
      "9099it [26:17,  5.79it/s]\titers: 9100, epoch: 1 | loss: 0.1548792\n",
      "\tspeed: 0.1762s/iter; left time: 3631.6284s\n",
      "9199it [26:34,  5.61it/s]\titers: 9200, epoch: 1 | loss: 0.2133459\n",
      "\tspeed: 0.1770s/iter; left time: 3629.7343s\n",
      "9299it [26:52,  5.67it/s]\titers: 9300, epoch: 1 | loss: 0.0920845\n",
      "\tspeed: 0.1777s/iter; left time: 3625.2640s\n",
      "9399it [27:10,  5.84it/s]\titers: 9400, epoch: 1 | loss: 0.2078221\n",
      "\tspeed: 0.1799s/iter; left time: 3653.3873s\n",
      "9499it [27:28,  5.80it/s]\titers: 9500, epoch: 1 | loss: 0.5962553\n",
      "\tspeed: 0.1776s/iter; left time: 3588.0198s\n",
      "9599it [27:45,  5.83it/s]\titers: 9600, epoch: 1 | loss: 0.1345300\n",
      "\tspeed: 0.1730s/iter; left time: 3479.1179s\n",
      "9699it [28:03,  5.85it/s]\titers: 9700, epoch: 1 | loss: 0.7007051\n",
      "\tspeed: 0.1728s/iter; left time: 3457.1214s\n",
      "9799it [28:20,  5.78it/s]\titers: 9800, epoch: 1 | loss: 0.1719010\n",
      "\tspeed: 0.1735s/iter; left time: 3453.0517s\n",
      "9899it [28:37,  5.73it/s]\titers: 9900, epoch: 1 | loss: 0.1262725\n",
      "\tspeed: 0.1726s/iter; left time: 3417.5931s\n",
      "9999it [28:54,  5.79it/s]\titers: 10000, epoch: 1 | loss: 0.1639885\n",
      "\tspeed: 0.1727s/iter; left time: 3402.9608s\n",
      "10099it [29:12,  5.85it/s]\titers: 10100, epoch: 1 | loss: 0.0426773\n",
      "\tspeed: 0.1721s/iter; left time: 3374.4590s\n",
      "10199it [29:29,  5.80it/s]\titers: 10200, epoch: 1 | loss: 0.5532264\n",
      "\tspeed: 0.1742s/iter; left time: 3397.9498s\n",
      "10299it [29:46,  5.94it/s]\titers: 10300, epoch: 1 | loss: 0.1898806\n",
      "\tspeed: 0.1694s/iter; left time: 3286.7090s\n",
      "10399it [30:03,  5.83it/s]\titers: 10400, epoch: 1 | loss: 0.2934946\n",
      "\tspeed: 0.1723s/iter; left time: 3325.8036s\n",
      "10499it [30:21,  5.91it/s]\titers: 10500, epoch: 1 | loss: 0.0936582\n",
      "\tspeed: 0.1730s/iter; left time: 3322.9827s\n",
      "10599it [30:38,  5.85it/s]\titers: 10600, epoch: 1 | loss: 0.3450982\n",
      "\tspeed: 0.1741s/iter; left time: 3326.2996s\n",
      "10699it [30:55,  5.87it/s]\titers: 10700, epoch: 1 | loss: 0.5284604\n",
      "\tspeed: 0.1727s/iter; left time: 3282.4380s\n",
      "10799it [31:12,  5.81it/s]\titers: 10800, epoch: 1 | loss: 0.1592788\n",
      "\tspeed: 0.1723s/iter; left time: 3257.3144s\n",
      "10899it [31:30,  5.98it/s]\titers: 10900, epoch: 1 | loss: 0.2415662\n",
      "\tspeed: 0.1709s/iter; left time: 3213.0436s\n",
      "10999it [31:47,  5.82it/s]\titers: 11000, epoch: 1 | loss: 0.0938571\n",
      "\tspeed: 0.1708s/iter; left time: 3195.8292s\n",
      "11099it [32:04,  5.82it/s]\titers: 11100, epoch: 1 | loss: 0.1506357\n",
      "\tspeed: 0.1747s/iter; left time: 3250.1013s\n",
      "11199it [32:21,  5.70it/s]\titers: 11200, epoch: 1 | loss: 0.0396508\n",
      "\tspeed: 0.1740s/iter; left time: 3220.4328s\n",
      "11299it [32:39,  5.76it/s]\titers: 11300, epoch: 1 | loss: 0.1362401\n",
      "\tspeed: 0.1729s/iter; left time: 3182.4589s\n",
      "11399it [32:56,  5.81it/s]\titers: 11400, epoch: 1 | loss: 0.1181507\n",
      "\tspeed: 0.1738s/iter; left time: 3180.7698s\n",
      "11499it [33:13,  5.81it/s]\titers: 11500, epoch: 1 | loss: 0.1033998\n",
      "\tspeed: 0.1736s/iter; left time: 3160.8278s\n",
      "11599it [33:31,  5.77it/s]\titers: 11600, epoch: 1 | loss: 0.4199752\n",
      "\tspeed: 0.1745s/iter; left time: 3158.7248s\n",
      "11699it [33:48,  5.77it/s]\titers: 11700, epoch: 1 | loss: 0.9203606\n",
      "\tspeed: 0.1730s/iter; left time: 3114.4714s\n",
      "11799it [34:06,  5.81it/s]\titers: 11800, epoch: 1 | loss: 0.1672671\n",
      "\tspeed: 0.1732s/iter; left time: 3100.5610s\n",
      "11899it [34:23,  5.84it/s]\titers: 11900, epoch: 1 | loss: 0.2857038\n",
      "\tspeed: 0.1741s/iter; left time: 3100.4245s\n",
      "11999it [34:40,  5.82it/s]\titers: 12000, epoch: 1 | loss: 0.5969759\n",
      "\tspeed: 0.1748s/iter; left time: 3095.0972s\n",
      "12099it [34:58,  5.94it/s]\titers: 12100, epoch: 1 | loss: 0.0742296\n",
      "\tspeed: 0.1708s/iter; left time: 3007.3899s\n",
      "12199it [35:15,  5.81it/s]\titers: 12200, epoch: 1 | loss: 0.9567947\n",
      "\tspeed: 0.1699s/iter; left time: 2975.1292s\n",
      "12299it [35:32,  5.89it/s]\titers: 12300, epoch: 1 | loss: 0.1370284\n",
      "\tspeed: 0.1742s/iter; left time: 3031.7429s\n",
      "12399it [35:49,  6.01it/s]\titers: 12400, epoch: 1 | loss: 0.2177869\n",
      "\tspeed: 0.1716s/iter; left time: 2968.9797s\n",
      "12499it [36:06,  5.86it/s]\titers: 12500, epoch: 1 | loss: 0.1174163\n",
      "\tspeed: 0.1700s/iter; left time: 2924.7666s\n",
      "12599it [36:24,  5.84it/s]\titers: 12600, epoch: 1 | loss: 0.0952167\n",
      "\tspeed: 0.1747s/iter; left time: 2988.5428s\n",
      "12699it [36:41,  5.70it/s]\titers: 12700, epoch: 1 | loss: 0.0745180\n",
      "\tspeed: 0.1755s/iter; left time: 2984.9546s\n",
      "12799it [36:58,  5.57it/s]\titers: 12800, epoch: 1 | loss: 0.0613569\n",
      "\tspeed: 0.1738s/iter; left time: 2938.6501s\n",
      "12899it [37:16,  5.76it/s]\titers: 12900, epoch: 1 | loss: 0.1212397\n",
      "\tspeed: 0.1713s/iter; left time: 2879.1180s\n",
      "12999it [37:33,  5.93it/s]\titers: 13000, epoch: 1 | loss: 0.1994453\n",
      "\tspeed: 0.1733s/iter; left time: 2895.0752s\n",
      "13099it [37:50,  5.79it/s]\titers: 13100, epoch: 1 | loss: 0.3642481\n",
      "\tspeed: 0.1750s/iter; left time: 2906.3229s\n",
      "13199it [38:08,  5.83it/s]\titers: 13200, epoch: 1 | loss: 0.0462200\n",
      "\tspeed: 0.1762s/iter; left time: 2907.8509s\n",
      "13299it [38:25,  5.85it/s]\titers: 13300, epoch: 1 | loss: 0.2604310\n",
      "\tspeed: 0.1741s/iter; left time: 2856.3705s\n",
      "13399it [38:43,  5.94it/s]\titers: 13400, epoch: 1 | loss: 0.1015811\n",
      "\tspeed: 0.1710s/iter; left time: 2788.3393s\n",
      "13499it [39:00,  5.81it/s]\titers: 13500, epoch: 1 | loss: 0.2014813\n",
      "\tspeed: 0.1714s/iter; left time: 2778.5078s\n",
      "13599it [39:17,  5.84it/s]\titers: 13600, epoch: 1 | loss: 0.6772938\n",
      "\tspeed: 0.1732s/iter; left time: 2790.2190s\n",
      "13699it [39:34,  5.90it/s]\titers: 13700, epoch: 1 | loss: 0.0883630\n",
      "\tspeed: 0.1743s/iter; left time: 2789.8010s\n",
      "13799it [39:52,  5.77it/s]\titers: 13800, epoch: 1 | loss: 0.6614763\n",
      "\tspeed: 0.1745s/iter; left time: 2775.5211s\n",
      "13899it [40:09,  5.84it/s]\titers: 13900, epoch: 1 | loss: 0.2683596\n",
      "\tspeed: 0.1725s/iter; left time: 2725.9269s\n",
      "13999it [40:27,  5.79it/s]\titers: 14000, epoch: 1 | loss: 0.3193859\n",
      "\tspeed: 0.1760s/iter; left time: 2763.6243s\n",
      "14099it [40:44,  5.85it/s]\titers: 14100, epoch: 1 | loss: 0.4356972\n",
      "\tspeed: 0.1737s/iter; left time: 2710.1240s\n",
      "14199it [41:01,  5.83it/s]\titers: 14200, epoch: 1 | loss: 0.1829053\n",
      "\tspeed: 0.1733s/iter; left time: 2687.0694s\n",
      "14299it [41:19,  5.89it/s]\titers: 14300, epoch: 1 | loss: 0.1240173\n",
      "\tspeed: 0.1737s/iter; left time: 2675.9265s\n",
      "14399it [41:36,  5.81it/s]\titers: 14400, epoch: 1 | loss: 0.2043637\n",
      "\tspeed: 0.1730s/iter; left time: 2647.8473s\n",
      "14499it [41:53,  5.81it/s]\titers: 14500, epoch: 1 | loss: 0.5491531\n",
      "\tspeed: 0.1724s/iter; left time: 2622.2338s\n",
      "14599it [42:11,  5.46it/s]\titers: 14600, epoch: 1 | loss: 0.0543813\n",
      "\tspeed: 0.1714s/iter; left time: 2588.9675s\n",
      "14699it [42:28,  5.79it/s]\titers: 14700, epoch: 1 | loss: 0.4447525\n",
      "\tspeed: 0.1725s/iter; left time: 2587.8146s\n",
      "14799it [42:45,  5.80it/s]\titers: 14800, epoch: 1 | loss: 0.1639715\n",
      "\tspeed: 0.1734s/iter; left time: 2584.6482s\n",
      "14899it [43:02,  5.84it/s]\titers: 14900, epoch: 1 | loss: 0.1213382\n",
      "\tspeed: 0.1711s/iter; left time: 2532.7662s\n",
      "14999it [43:19,  5.90it/s]\titers: 15000, epoch: 1 | loss: 0.2863824\n",
      "\tspeed: 0.1708s/iter; left time: 2512.1444s\n",
      "15099it [43:36,  5.87it/s]\titers: 15100, epoch: 1 | loss: 0.1850952\n",
      "\tspeed: 0.1698s/iter; left time: 2479.4939s\n",
      "15199it [43:53,  5.81it/s]\titers: 15200, epoch: 1 | loss: 0.2748749\n",
      "\tspeed: 0.1710s/iter; left time: 2479.9188s\n",
      "15299it [44:10,  5.80it/s]\titers: 15300, epoch: 1 | loss: 0.0349729\n",
      "\tspeed: 0.1704s/iter; left time: 2454.4213s\n",
      "15399it [44:28,  5.87it/s]\titers: 15400, epoch: 1 | loss: 0.6873962\n",
      "\tspeed: 0.1726s/iter; left time: 2468.7689s\n",
      "15499it [44:45,  5.84it/s]\titers: 15500, epoch: 1 | loss: 0.0980209\n",
      "\tspeed: 0.1736s/iter; left time: 2466.4705s\n",
      "15599it [45:02,  5.81it/s]\titers: 15600, epoch: 1 | loss: 0.3816456\n",
      "\tspeed: 0.1733s/iter; left time: 2444.7757s\n",
      "15699it [45:20,  5.90it/s]\titers: 15700, epoch: 1 | loss: 0.0737382\n",
      "\tspeed: 0.1723s/iter; left time: 2412.5372s\n",
      "15799it [45:37,  5.87it/s]\titers: 15800, epoch: 1 | loss: 0.1256571\n",
      "\tspeed: 0.1746s/iter; left time: 2427.8267s\n",
      "15899it [45:55,  5.86it/s]\titers: 15900, epoch: 1 | loss: 0.2091437\n",
      "\tspeed: 0.1752s/iter; left time: 2419.3877s\n",
      "15999it [46:12,  5.94it/s]\titers: 16000, epoch: 1 | loss: 0.3124808\n",
      "\tspeed: 0.1721s/iter; left time: 2358.1480s\n",
      "16099it [46:29,  5.52it/s]\titers: 16100, epoch: 1 | loss: 0.3842218\n",
      "\tspeed: 0.1729s/iter; left time: 2352.2671s\n",
      "16199it [46:46,  5.09it/s]\titers: 16200, epoch: 1 | loss: 0.6273005\n",
      "\tspeed: 0.1737s/iter; left time: 2346.2468s\n",
      "16299it [47:04,  5.48it/s]\titers: 16300, epoch: 1 | loss: 0.3433484\n",
      "\tspeed: 0.1738s/iter; left time: 2329.9524s\n",
      "16399it [47:21,  5.84it/s]\titers: 16400, epoch: 1 | loss: 0.2394594\n",
      "\tspeed: 0.1718s/iter; left time: 2285.7863s\n",
      "16499it [47:38,  5.89it/s]\titers: 16500, epoch: 1 | loss: 0.2778091\n",
      "\tspeed: 0.1705s/iter; left time: 2251.2600s\n",
      "16599it [47:55,  5.88it/s]\titers: 16600, epoch: 1 | loss: 0.5105854\n",
      "\tspeed: 0.1704s/iter; left time: 2232.9056s\n",
      "16699it [48:12,  5.88it/s]\titers: 16700, epoch: 1 | loss: 0.2387884\n",
      "\tspeed: 0.1704s/iter; left time: 2215.9351s\n",
      "16799it [48:29,  5.89it/s]\titers: 16800, epoch: 1 | loss: 0.2312557\n",
      "\tspeed: 0.1704s/iter; left time: 2198.8205s\n",
      "16899it [48:46,  5.86it/s]\titers: 16900, epoch: 1 | loss: 0.1799667\n",
      "\tspeed: 0.1702s/iter; left time: 2179.5249s\n",
      "16999it [49:03,  5.85it/s]\titers: 17000, epoch: 1 | loss: 0.6795046\n",
      "\tspeed: 0.1701s/iter; left time: 2161.5627s\n",
      "17099it [49:20,  5.91it/s]\titers: 17100, epoch: 1 | loss: 0.5513248\n",
      "\tspeed: 0.1699s/iter; left time: 2141.6030s\n",
      "17199it [49:37,  5.88it/s]\titers: 17200, epoch: 1 | loss: 0.2325266\n",
      "\tspeed: 0.1706s/iter; left time: 2134.1125s\n",
      "17299it [49:54,  5.85it/s]\titers: 17300, epoch: 1 | loss: 0.1668275\n",
      "\tspeed: 0.1712s/iter; left time: 2124.2445s\n",
      "17399it [50:12,  5.77it/s]\titers: 17400, epoch: 1 | loss: 0.1121390\n",
      "\tspeed: 0.1727s/iter; left time: 2125.8439s\n",
      "17499it [50:29,  5.76it/s]\titers: 17500, epoch: 1 | loss: 0.2772318\n",
      "\tspeed: 0.1731s/iter; left time: 2113.4015s\n",
      "17599it [50:46,  5.69it/s]\titers: 17600, epoch: 1 | loss: 0.1169566\n",
      "\tspeed: 0.1727s/iter; left time: 2091.0772s\n",
      "17699it [51:04,  5.82it/s]\titers: 17700, epoch: 1 | loss: 0.7953797\n",
      "\tspeed: 0.1737s/iter; left time: 2085.6553s\n",
      "17799it [51:21,  5.81it/s]\titers: 17800, epoch: 1 | loss: 0.0739596\n",
      "\tspeed: 0.1711s/iter; left time: 2036.5890s\n",
      "17899it [51:38,  5.82it/s]\titers: 17900, epoch: 1 | loss: 0.0994916\n",
      "\tspeed: 0.1712s/iter; left time: 2021.6920s\n",
      "17999it [51:55,  5.82it/s]\titers: 18000, epoch: 1 | loss: 0.0536118\n",
      "\tspeed: 0.1711s/iter; left time: 2002.9564s\n",
      "18099it [52:12,  5.84it/s]\titers: 18100, epoch: 1 | loss: 0.2855749\n",
      "\tspeed: 0.1718s/iter; left time: 1994.4722s\n",
      "18199it [52:29,  5.85it/s]\titers: 18200, epoch: 1 | loss: 0.2222405\n",
      "\tspeed: 0.1715s/iter; left time: 1973.4160s\n",
      "18299it [52:46,  5.80it/s]\titers: 18300, epoch: 1 | loss: 0.6102778\n",
      "\tspeed: 0.1713s/iter; left time: 1953.8186s\n",
      "18399it [53:04,  5.76it/s]\titers: 18400, epoch: 1 | loss: 0.0920710\n",
      "\tspeed: 0.1760s/iter; left time: 1989.3512s\n",
      "18499it [53:21,  5.83it/s]\titers: 18500, epoch: 1 | loss: 0.1471266\n",
      "\tspeed: 0.1712s/iter; left time: 1918.9864s\n",
      "18599it [53:38,  5.87it/s]\titers: 18600, epoch: 1 | loss: 0.0648521\n",
      "\tspeed: 0.1707s/iter; left time: 1895.6478s\n",
      "18699it [53:55,  5.86it/s]\titers: 18700, epoch: 1 | loss: 0.1082078\n",
      "\tspeed: 0.1714s/iter; left time: 1886.5997s\n",
      "18799it [54:12,  5.83it/s]\titers: 18800, epoch: 1 | loss: 0.5018492\n",
      "\tspeed: 0.1714s/iter; left time: 1869.5387s\n",
      "18899it [54:30,  5.83it/s]\titers: 18900, epoch: 1 | loss: 0.2417234\n",
      "\tspeed: 0.1720s/iter; left time: 1858.2383s\n",
      "18999it [54:47,  5.89it/s]\titers: 19000, epoch: 1 | loss: 0.1081420\n",
      "\tspeed: 0.1711s/iter; left time: 1831.9511s\n",
      "19099it [55:04,  5.85it/s]\titers: 19100, epoch: 1 | loss: 0.1186238\n",
      "\tspeed: 0.1710s/iter; left time: 1813.5191s\n",
      "19199it [55:21,  5.81it/s]\titers: 19200, epoch: 1 | loss: 0.0658043\n",
      "\tspeed: 0.1709s/iter; left time: 1795.0487s\n",
      "19299it [55:38,  5.90it/s]\titers: 19300, epoch: 1 | loss: 0.2509463\n",
      "\tspeed: 0.1706s/iter; left time: 1774.8618s\n",
      "19399it [55:55,  5.89it/s]\titers: 19400, epoch: 1 | loss: 0.1218918\n",
      "\tspeed: 0.1708s/iter; left time: 1760.0752s\n",
      "19499it [56:12,  5.83it/s]\titers: 19500, epoch: 1 | loss: 0.1762856\n",
      "\tspeed: 0.1710s/iter; left time: 1745.5960s\n",
      "19599it [56:29,  5.86it/s]\titers: 19600, epoch: 1 | loss: 0.1748880\n",
      "\tspeed: 0.1714s/iter; left time: 1731.7066s\n",
      "19699it [56:46,  5.91it/s]\titers: 19700, epoch: 1 | loss: 0.6551110\n",
      "\tspeed: 0.1708s/iter; left time: 1708.5728s\n",
      "19799it [57:03,  5.86it/s]\titers: 19800, epoch: 1 | loss: 0.2309869\n",
      "\tspeed: 0.1701s/iter; left time: 1685.4757s\n",
      "19899it [57:20,  5.86it/s]\titers: 19900, epoch: 1 | loss: 0.2013379\n",
      "\tspeed: 0.1698s/iter; left time: 1664.9389s\n",
      "19999it [57:37,  5.86it/s]\titers: 20000, epoch: 1 | loss: 0.1232175\n",
      "\tspeed: 0.1700s/iter; left time: 1650.0405s\n",
      "20099it [57:55,  5.84it/s]\titers: 20100, epoch: 1 | loss: 0.2577030\n",
      "\tspeed: 0.1710s/iter; left time: 1642.2787s\n",
      "20199it [58:12,  5.86it/s]\titers: 20200, epoch: 1 | loss: 0.2628649\n",
      "\tspeed: 0.1707s/iter; left time: 1622.4860s\n",
      "20299it [58:29,  5.87it/s]\titers: 20300, epoch: 1 | loss: 0.0221700\n",
      "\tspeed: 0.1706s/iter; left time: 1605.0899s\n",
      "20399it [58:46,  5.71it/s]\titers: 20400, epoch: 1 | loss: 0.3109417\n",
      "\tspeed: 0.1724s/iter; left time: 1604.2899s\n",
      "20499it [59:03,  5.93it/s]\titers: 20500, epoch: 1 | loss: 0.0799850\n",
      "\tspeed: 0.1729s/iter; left time: 1591.4882s\n",
      "20599it [59:20,  5.83it/s]\titers: 20600, epoch: 1 | loss: 0.3188447\n",
      "\tspeed: 0.1712s/iter; left time: 1558.7496s\n",
      "20699it [59:37,  5.82it/s]\titers: 20700, epoch: 1 | loss: 0.1060150\n",
      "\tspeed: 0.1719s/iter; left time: 1547.9833s\n",
      "20799it [59:55,  5.88it/s]\titers: 20800, epoch: 1 | loss: 0.1011181\n",
      "\tspeed: 0.1713s/iter; left time: 1525.8001s\n",
      "20899it [1:00:12,  5.82it/s]\titers: 20900, epoch: 1 | loss: 0.4541431\n",
      "\tspeed: 0.1710s/iter; left time: 1506.0275s\n",
      "20999it [1:00:29,  5.82it/s]\titers: 21000, epoch: 1 | loss: 0.2296910\n",
      "\tspeed: 0.1717s/iter; left time: 1494.9696s\n",
      "21099it [1:00:46,  5.82it/s]\titers: 21100, epoch: 1 | loss: 0.8036953\n",
      "\tspeed: 0.1711s/iter; left time: 1472.9090s\n",
      "21199it [1:01:03,  5.83it/s]\titers: 21200, epoch: 1 | loss: 0.1426893\n",
      "\tspeed: 0.1712s/iter; left time: 1456.5536s\n",
      "21299it [1:01:20,  5.79it/s]\titers: 21300, epoch: 1 | loss: 0.1056532\n",
      "\tspeed: 0.1718s/iter; left time: 1444.0763s\n",
      "21399it [1:01:37,  5.82it/s]\titers: 21400, epoch: 1 | loss: 0.1434236\n",
      "\tspeed: 0.1718s/iter; left time: 1427.3696s\n",
      "21499it [1:01:55,  5.84it/s]\titers: 21500, epoch: 1 | loss: 0.3239945\n",
      "\tspeed: 0.1714s/iter; left time: 1406.5592s\n",
      "21599it [1:02:12,  5.86it/s]\titers: 21600, epoch: 1 | loss: 0.1823280\n",
      "\tspeed: 0.1709s/iter; left time: 1385.2586s\n",
      "21699it [1:02:29,  5.87it/s]\titers: 21700, epoch: 1 | loss: 0.0270296\n",
      "\tspeed: 0.1710s/iter; left time: 1368.8788s\n",
      "21799it [1:02:46,  5.85it/s]\titers: 21800, epoch: 1 | loss: 0.1809842\n",
      "\tspeed: 0.1711s/iter; left time: 1352.6002s\n",
      "21899it [1:03:03,  5.88it/s]\titers: 21900, epoch: 1 | loss: 0.0779025\n",
      "\tspeed: 0.1714s/iter; left time: 1338.1193s\n",
      "21999it [1:03:20,  5.88it/s]\titers: 22000, epoch: 1 | loss: 0.6630195\n",
      "\tspeed: 0.1707s/iter; left time: 1315.2918s\n",
      "22099it [1:03:37,  5.69it/s]\titers: 22100, epoch: 1 | loss: 0.2591875\n",
      "\tspeed: 0.1727s/iter; left time: 1313.3122s\n",
      "22199it [1:03:55,  5.74it/s]\titers: 22200, epoch: 1 | loss: 0.1057750\n",
      "\tspeed: 0.1748s/iter; left time: 1311.8912s\n",
      "22299it [1:04:12,  5.75it/s]\titers: 22300, epoch: 1 | loss: 0.2553610\n",
      "\tspeed: 0.1747s/iter; left time: 1293.7321s\n",
      "22399it [1:04:30,  5.69it/s]\titers: 22400, epoch: 1 | loss: 0.0376381\n",
      "\tspeed: 0.1749s/iter; left time: 1278.0430s\n",
      "22499it [1:04:47,  5.72it/s]\titers: 22500, epoch: 1 | loss: 0.0955512\n",
      "\tspeed: 0.1750s/iter; left time: 1261.0086s\n",
      "22599it [1:05:05,  5.90it/s]\titers: 22600, epoch: 1 | loss: 0.0831237\n",
      "\tspeed: 0.1730s/iter; left time: 1229.4286s\n",
      "22699it [1:05:22,  5.84it/s]\titers: 22700, epoch: 1 | loss: 0.0440906\n",
      "\tspeed: 0.1705s/iter; left time: 1194.6663s\n",
      "22799it [1:05:39,  5.86it/s]\titers: 22800, epoch: 1 | loss: 0.5756562\n",
      "\tspeed: 0.1706s/iter; left time: 1177.9617s\n",
      "22899it [1:05:56,  5.85it/s]\titers: 22900, epoch: 1 | loss: 0.0965473\n",
      "\tspeed: 0.1702s/iter; left time: 1158.2810s\n",
      "22999it [1:06:13,  5.86it/s]\titers: 23000, epoch: 1 | loss: 0.0362349\n",
      "\tspeed: 0.1704s/iter; left time: 1142.5205s\n",
      "23099it [1:06:30,  5.86it/s]\titers: 23100, epoch: 1 | loss: 0.1411740\n",
      "\tspeed: 0.1705s/iter; left time: 1126.0176s\n",
      "23199it [1:06:47,  5.85it/s]\titers: 23200, epoch: 1 | loss: 0.2161383\n",
      "\tspeed: 0.1708s/iter; left time: 1111.0185s\n",
      "23299it [1:07:04,  5.84it/s]\titers: 23300, epoch: 1 | loss: 0.3066402\n",
      "\tspeed: 0.1705s/iter; left time: 1091.9607s\n",
      "23399it [1:07:21,  5.83it/s]\titers: 23400, epoch: 1 | loss: 0.3364982\n",
      "\tspeed: 0.1704s/iter; left time: 1074.7704s\n",
      "23499it [1:07:38,  5.89it/s]\titers: 23500, epoch: 1 | loss: 0.1173545\n",
      "\tspeed: 0.1703s/iter; left time: 1056.9417s\n",
      "23599it [1:07:55,  5.92it/s]\titers: 23600, epoch: 1 | loss: 0.1614152\n",
      "\tspeed: 0.1701s/iter; left time: 1038.8682s\n",
      "23699it [1:08:12,  5.88it/s]\titers: 23700, epoch: 1 | loss: 0.2097004\n",
      "\tspeed: 0.1699s/iter; left time: 1020.6364s\n",
      "23799it [1:08:29,  5.86it/s]\titers: 23800, epoch: 1 | loss: 0.2035635\n",
      "\tspeed: 0.1698s/iter; left time: 1002.9099s\n",
      "23899it [1:08:46,  5.89it/s]\titers: 23900, epoch: 1 | loss: 0.0951586\n",
      "\tspeed: 0.1698s/iter; left time: 985.9563s\n",
      "23999it [1:09:03,  5.90it/s]\titers: 24000, epoch: 1 | loss: 0.1602112\n",
      "\tspeed: 0.1698s/iter; left time: 968.6994s\n",
      "24099it [1:09:20,  5.90it/s]\titers: 24100, epoch: 1 | loss: 0.4585220\n",
      "\tspeed: 0.1700s/iter; left time: 952.8972s\n",
      "24199it [1:09:37,  5.93it/s]\titers: 24200, epoch: 1 | loss: 0.4631023\n",
      "\tspeed: 0.1700s/iter; left time: 936.1964s\n",
      "24299it [1:09:54,  5.90it/s]\titers: 24300, epoch: 1 | loss: 0.0662834\n",
      "\tspeed: 0.1698s/iter; left time: 918.2087s\n",
      "24399it [1:10:11,  5.89it/s]\titers: 24400, epoch: 1 | loss: 0.3272948\n",
      "\tspeed: 0.1700s/iter; left time: 902.1022s\n",
      "24499it [1:10:28,  5.87it/s]\titers: 24500, epoch: 1 | loss: 0.0666922\n",
      "\tspeed: 0.1704s/iter; left time: 887.1906s\n",
      "24599it [1:10:45,  5.87it/s]\titers: 24600, epoch: 1 | loss: 0.0940862\n",
      "\tspeed: 0.1701s/iter; left time: 868.6296s\n",
      "24699it [1:11:02,  5.87it/s]\titers: 24700, epoch: 1 | loss: 0.0743787\n",
      "\tspeed: 0.1701s/iter; left time: 851.4831s\n",
      "24799it [1:11:19,  5.86it/s]\titers: 24800, epoch: 1 | loss: 0.0612723\n",
      "\tspeed: 0.1707s/iter; left time: 837.4893s\n",
      "24899it [1:11:36,  5.86it/s]\titers: 24900, epoch: 1 | loss: 0.3857566\n",
      "\tspeed: 0.1705s/iter; left time: 819.4982s\n",
      "24999it [1:11:53,  5.75it/s]\titers: 25000, epoch: 1 | loss: 0.1199505\n",
      "\tspeed: 0.1709s/iter; left time: 804.4648s\n",
      "25099it [1:12:10,  5.90it/s]\titers: 25100, epoch: 1 | loss: 0.3126957\n",
      "\tspeed: 0.1704s/iter; left time: 784.9375s\n",
      "25199it [1:12:27,  5.86it/s]\titers: 25200, epoch: 1 | loss: 0.1946324\n",
      "\tspeed: 0.1704s/iter; left time: 767.9522s\n",
      "25299it [1:12:44,  5.84it/s]\titers: 25300, epoch: 1 | loss: 0.1304453\n",
      "\tspeed: 0.1707s/iter; left time: 752.1929s\n",
      "25399it [1:13:01,  5.87it/s]\titers: 25400, epoch: 1 | loss: 0.0551400\n",
      "\tspeed: 0.1705s/iter; left time: 734.0835s\n",
      "25499it [1:13:18,  5.92it/s]\titers: 25500, epoch: 1 | loss: 0.1305899\n",
      "\tspeed: 0.1703s/iter; left time: 716.3822s\n",
      "25599it [1:13:36,  5.86it/s]\titers: 25600, epoch: 1 | loss: 0.3532454\n",
      "\tspeed: 0.1705s/iter; left time: 699.9774s\n",
      "25699it [1:13:53,  5.89it/s]\titers: 25700, epoch: 1 | loss: 0.1015201\n",
      "\tspeed: 0.1703s/iter; left time: 682.1593s\n",
      "25799it [1:14:10,  5.86it/s]\titers: 25800, epoch: 1 | loss: 0.1301935\n",
      "\tspeed: 0.1704s/iter; left time: 665.5808s\n",
      "25899it [1:14:27,  5.91it/s]\titers: 25900, epoch: 1 | loss: 0.1652094\n",
      "\tspeed: 0.1700s/iter; left time: 647.0300s\n",
      "25999it [1:14:44,  5.86it/s]\titers: 26000, epoch: 1 | loss: 0.1596953\n",
      "\tspeed: 0.1707s/iter; left time: 632.6190s\n",
      "26099it [1:15:01,  5.87it/s]\titers: 26100, epoch: 1 | loss: 0.3074009\n",
      "\tspeed: 0.1703s/iter; left time: 614.2152s\n",
      "26199it [1:15:18,  5.86it/s]\titers: 26200, epoch: 1 | loss: 0.2752254\n",
      "\tspeed: 0.1702s/iter; left time: 596.7158s\n",
      "26299it [1:15:35,  5.86it/s]\titers: 26300, epoch: 1 | loss: 0.1357759\n",
      "\tspeed: 0.1704s/iter; left time: 580.3127s\n",
      "26399it [1:15:52,  5.85it/s]\titers: 26400, epoch: 1 | loss: 0.1975400\n",
      "\tspeed: 0.1702s/iter; left time: 562.6026s\n",
      "26499it [1:16:09,  5.83it/s]\titers: 26500, epoch: 1 | loss: 0.2353301\n",
      "\tspeed: 0.1707s/iter; left time: 547.1683s\n",
      "26599it [1:16:26,  5.85it/s]\titers: 26600, epoch: 1 | loss: 0.2255458\n",
      "\tspeed: 0.1705s/iter; left time: 529.6493s\n",
      "26699it [1:16:43,  5.84it/s]\titers: 26700, epoch: 1 | loss: 0.2594674\n",
      "\tspeed: 0.1702s/iter; left time: 511.5947s\n",
      "26799it [1:17:00,  5.89it/s]\titers: 26800, epoch: 1 | loss: 0.7253950\n",
      "\tspeed: 0.1702s/iter; left time: 494.5835s\n",
      "26899it [1:17:17,  5.82it/s]\titers: 26900, epoch: 1 | loss: 0.1567582\n",
      "\tspeed: 0.1705s/iter; left time: 478.4870s\n",
      "26999it [1:17:34,  5.88it/s]\titers: 27000, epoch: 1 | loss: 0.1951847\n",
      "\tspeed: 0.1702s/iter; left time: 460.6664s\n",
      "27099it [1:17:51,  5.88it/s]\titers: 27100, epoch: 1 | loss: 0.0903886\n",
      "\tspeed: 0.1703s/iter; left time: 443.8083s\n",
      "27199it [1:18:08,  5.92it/s]\titers: 27200, epoch: 1 | loss: 0.3706902\n",
      "\tspeed: 0.1702s/iter; left time: 426.5594s\n",
      "27299it [1:18:25,  5.87it/s]\titers: 27300, epoch: 1 | loss: 0.3245256\n",
      "\tspeed: 0.1705s/iter; left time: 410.1549s\n",
      "27399it [1:18:42,  5.85it/s]\titers: 27400, epoch: 1 | loss: 0.0680483\n",
      "\tspeed: 0.1707s/iter; left time: 393.5306s\n",
      "27499it [1:18:59,  5.77it/s]\titers: 27500, epoch: 1 | loss: 0.1720057\n",
      "\tspeed: 0.1707s/iter; left time: 376.6170s\n",
      "27599it [1:19:16,  5.84it/s]\titers: 27600, epoch: 1 | loss: 0.6142737\n",
      "\tspeed: 0.1702s/iter; left time: 358.3779s\n",
      "27699it [1:19:33,  5.84it/s]\titers: 27700, epoch: 1 | loss: 0.3691139\n",
      "\tspeed: 0.1707s/iter; left time: 342.3907s\n",
      "27799it [1:19:50,  5.82it/s]\titers: 27800, epoch: 1 | loss: 0.0387597\n",
      "\tspeed: 0.1709s/iter; left time: 325.7201s\n",
      "27899it [1:20:08,  5.70it/s]\titers: 27900, epoch: 1 | loss: 0.1552235\n",
      "\tspeed: 0.1722s/iter; left time: 311.0584s\n",
      "27999it [1:20:25,  5.72it/s]\titers: 28000, epoch: 1 | loss: 0.1458867\n",
      "\tspeed: 0.1749s/iter; left time: 298.4353s\n",
      "28099it [1:20:42,  5.88it/s]\titers: 28100, epoch: 1 | loss: 0.5761591\n",
      "\tspeed: 0.1731s/iter; left time: 277.9370s\n",
      "28199it [1:21:00,  5.89it/s]\titers: 28200, epoch: 1 | loss: 0.3503025\n",
      "\tspeed: 0.1708s/iter; left time: 257.2244s\n",
      "28299it [1:21:17,  5.84it/s]\titers: 28300, epoch: 1 | loss: 0.2815970\n",
      "\tspeed: 0.1705s/iter; left time: 239.6795s\n",
      "28399it [1:21:34,  5.83it/s]\titers: 28400, epoch: 1 | loss: 0.6013454\n",
      "\tspeed: 0.1706s/iter; left time: 222.8412s\n",
      "28499it [1:21:51,  5.86it/s]\titers: 28500, epoch: 1 | loss: 0.3941776\n",
      "\tspeed: 0.1715s/iter; left time: 206.8390s\n",
      "28599it [1:22:08,  5.87it/s]\titers: 28600, epoch: 1 | loss: 0.4810668\n",
      "\tspeed: 0.1711s/iter; left time: 189.2134s\n",
      "28699it [1:22:25,  5.88it/s]\titers: 28700, epoch: 1 | loss: 0.0654329\n",
      "\tspeed: 0.1706s/iter; left time: 171.6142s\n",
      "28799it [1:22:42,  5.85it/s]\titers: 28800, epoch: 1 | loss: 0.0563467\n",
      "\tspeed: 0.1703s/iter; left time: 154.2633s\n",
      "28899it [1:22:59,  5.81it/s]\titers: 28900, epoch: 1 | loss: 0.1827449\n",
      "\tspeed: 0.1709s/iter; left time: 137.7650s\n",
      "28999it [1:23:16,  5.84it/s]\titers: 29000, epoch: 1 | loss: 0.0585531\n",
      "\tspeed: 0.1711s/iter; left time: 120.7904s\n",
      "29099it [1:23:33,  5.80it/s]\titers: 29100, epoch: 1 | loss: 0.2691645\n",
      "\tspeed: 0.1712s/iter; left time: 103.7308s\n",
      "29199it [1:23:50,  5.82it/s]\titers: 29200, epoch: 1 | loss: 0.1599855\n",
      "\tspeed: 0.1711s/iter; left time: 86.5622s\n",
      "29299it [1:24:08,  5.84it/s]\titers: 29300, epoch: 1 | loss: 0.2513905\n",
      "\tspeed: 0.1714s/iter; left time: 69.5783s\n",
      "29399it [1:24:25,  5.82it/s]\titers: 29400, epoch: 1 | loss: 0.1516926\n",
      "\tspeed: 0.1710s/iter; left time: 52.3202s\n",
      "29499it [1:24:42,  5.88it/s]\titers: 29500, epoch: 1 | loss: 0.1653662\n",
      "\tspeed: 0.1709s/iter; left time: 35.2152s\n",
      "29599it [1:24:59,  5.83it/s]\titers: 29600, epoch: 1 | loss: 0.1844983\n",
      "\tspeed: 0.1711s/iter; left time: 18.1355s\n",
      "29699it [1:25:16,  5.86it/s]\titers: 29700, epoch: 1 | loss: 0.1536553\n",
      "\tspeed: 0.1709s/iter; left time: 1.0254s\n",
      "29705it [1:25:17,  5.80it/s]\n",
      "Epoch: 1 cost time: 5117.517580747604\n",
      "6481it [08:28, 12.74it/s]\n",
      "6457it [08:28, 12.70it/s]\n",
      "Epoch: 1 | Train Loss: 0.2670069 Vali Loss: 0.3092261 Test Loss: 0.3865547 MAE Loss: 0.3827427\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 105.75188378095626 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 01:36:58 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             62W /  300W |     842MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off |   00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   63C    P0            295W /  300W |   64909MiB /  81920MiB |     99%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off |   00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   66C    P0            277W /  300W |   79126MiB /  81920MiB |     97%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      7139      G   /usr/bin/X                                      4MiB |\n",
      "|    0   N/A  N/A     29499      C   ...holuka/.conda/envs/py27/bin/python2        826MiB |\n",
      "|    1   N/A  N/A      7139      G   /usr/bin/X                                      4MiB |\n",
      "|    1   N/A  N/A      7498      C   python                                       9376MiB |\n",
      "|    1   N/A  N/A     12807      C   ...i/.conda/envs/nerfstudio/bin/python      49642MiB |\n",
      "|    1   N/A  N/A     33678      C   python3                                      5086MiB |\n",
      "|    1   N/A  N/A     35854      C   python                                        774MiB |\n",
      "|    2   N/A  N/A      7139      G   /usr/bin/X                                      4MiB |\n",
      "|    2   N/A  N/A     26038      C   python                                      79108MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.12s/it]\n",
      "d_llm 4096\n",
      "[2024-05-05 16:49:07,269] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-05 16:49:08,118] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-05 16:49:08,118] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-05 16:49:08,118] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-05 16:49:09,056] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-05 16:49:09,056] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-05 16:49:20,168] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-05 16:49:20,169] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-05 16:49:20,169] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-05 16:49:20,171] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-05 16:49:20,171] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-05 16:49:20,171] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-05 16:49:20,171] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-05 16:49:20,171] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-05 16:49:20,171] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-05 16:49:20,171] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-05 16:49:20,451] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-05 16:49:20,452] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-05 16:49:20,452] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.42 GB, percent = 16.4%\n",
      "[2024-05-05 16:49:20,706] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-05 16:49:20,706] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 16:49:20,706] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.4 GB, percent = 16.4%\n",
      "[2024-05-05 16:49:20,706] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-05 16:49:20,820] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-05 16:49:20,821] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 16:49:20,821] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 123.4 GB, percent = 16.4%\n",
      "[2024-05-05 16:49:20,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-05 16:49:20,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-05 16:49:20,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-05 16:49:20,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-05 16:49:20,822] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f13881ee250>\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-05 16:49:20,823] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   train_batch_size ............. 3\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-05 16:49:20,824] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 3, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:17,  5.97it/s]\titers: 100, epoch: 1 | loss: 0.9995176\n",
      "\tspeed: 0.3180s/iter; left time: 9413.4504s\n",
      "199it [00:34,  5.94it/s]\titers: 200, epoch: 1 | loss: 0.7528370\n",
      "\tspeed: 0.1688s/iter; left time: 4981.1281s\n",
      "299it [00:51,  5.93it/s]\titers: 300, epoch: 1 | loss: 0.6342762\n",
      "\tspeed: 0.1700s/iter; left time: 4997.8054s\n",
      "399it [01:08,  5.88it/s]\titers: 400, epoch: 1 | loss: 0.1369442\n",
      "\tspeed: 0.1705s/iter; left time: 4997.4726s\n",
      "499it [01:25,  5.61it/s]\titers: 500, epoch: 1 | loss: 1.7759447\n",
      "\tspeed: 0.1717s/iter; left time: 5015.4573s\n",
      "599it [01:42,  5.75it/s]\titers: 600, epoch: 1 | loss: 0.7212697\n",
      "\tspeed: 0.1713s/iter; left time: 4986.0787s\n",
      "699it [01:59,  5.74it/s]\titers: 700, epoch: 1 | loss: 0.1912604\n",
      "\tspeed: 0.1690s/iter; left time: 4902.2886s\n",
      "799it [02:16,  5.81it/s]\titers: 800, epoch: 1 | loss: 0.1718992\n",
      "\tspeed: 0.1721s/iter; left time: 4974.0039s\n",
      "899it [02:34,  5.87it/s]\titers: 900, epoch: 1 | loss: 0.2013323\n",
      "\tspeed: 0.1733s/iter; left time: 4992.0904s\n",
      "999it [02:51,  5.82it/s]\titers: 1000, epoch: 1 | loss: 1.1996839\n",
      "\tspeed: 0.1738s/iter; left time: 4989.4707s\n",
      "1099it [03:09,  5.87it/s]\titers: 1100, epoch: 1 | loss: 0.2342540\n",
      "\tspeed: 0.1749s/iter; left time: 5004.3378s\n",
      "1199it [03:26,  5.82it/s]\titers: 1200, epoch: 1 | loss: 1.5789831\n",
      "\tspeed: 0.1734s/iter; left time: 4943.2623s\n",
      "1299it [03:43,  5.84it/s]\titers: 1300, epoch: 1 | loss: 0.3627469\n",
      "\tspeed: 0.1725s/iter; left time: 4899.0411s\n",
      "1399it [04:01,  5.86it/s]\titers: 1400, epoch: 1 | loss: 0.4371550\n",
      "\tspeed: 0.1732s/iter; left time: 4903.8328s\n",
      "1499it [04:18,  5.64it/s]\titers: 1500, epoch: 1 | loss: 0.2585745\n",
      "\tspeed: 0.1750s/iter; left time: 4934.8976s\n",
      "1599it [04:36,  5.74it/s]\titers: 1600, epoch: 1 | loss: 0.1844499\n",
      "\tspeed: 0.1772s/iter; left time: 4981.4111s\n",
      "1699it [04:53,  5.82it/s]\titers: 1700, epoch: 1 | loss: 0.1986266\n",
      "\tspeed: 0.1749s/iter; left time: 4897.8832s\n",
      "1799it [05:11,  5.84it/s]\titers: 1800, epoch: 1 | loss: 0.2149292\n",
      "\tspeed: 0.1723s/iter; left time: 4808.5916s\n",
      "1899it [05:28,  5.86it/s]\titers: 1900, epoch: 1 | loss: 0.2028953\n",
      "\tspeed: 0.1721s/iter; left time: 4786.6795s\n",
      "1999it [05:45,  5.80it/s]\titers: 2000, epoch: 1 | loss: 0.4653367\n",
      "\tspeed: 0.1745s/iter; left time: 4833.8280s\n",
      "2099it [06:03,  5.78it/s]\titers: 2100, epoch: 1 | loss: 0.1648085\n",
      "\tspeed: 0.1734s/iter; left time: 4786.7576s\n",
      "2199it [06:20,  5.77it/s]\titers: 2200, epoch: 1 | loss: 0.4138450\n",
      "\tspeed: 0.1744s/iter; left time: 4796.2768s\n",
      "2299it [06:37,  5.80it/s]\titers: 2300, epoch: 1 | loss: 0.2147816\n",
      "\tspeed: 0.1744s/iter; left time: 4779.7656s\n",
      "2399it [06:54,  5.91it/s]\titers: 2400, epoch: 1 | loss: 0.1635985\n",
      "\tspeed: 0.1704s/iter; left time: 4652.5190s\n",
      "2499it [07:12,  5.78it/s]\titers: 2500, epoch: 1 | loss: 0.3079199\n",
      "\tspeed: 0.1724s/iter; left time: 4689.3270s\n",
      "2599it [07:29,  5.86it/s]\titers: 2600, epoch: 1 | loss: 0.1539550\n",
      "\tspeed: 0.1731s/iter; left time: 4691.9084s\n",
      "2699it [07:46,  5.82it/s]\titers: 2700, epoch: 1 | loss: 0.1684938\n",
      "\tspeed: 0.1704s/iter; left time: 4601.0867s\n",
      "2799it [08:03,  5.79it/s]\titers: 2800, epoch: 1 | loss: 0.1634436\n",
      "\tspeed: 0.1722s/iter; left time: 4632.4716s\n",
      "2899it [08:21,  5.75it/s]\titers: 2900, epoch: 1 | loss: 0.3425570\n",
      "\tspeed: 0.1731s/iter; left time: 4640.5139s\n",
      "2999it [08:38,  5.78it/s]\titers: 3000, epoch: 1 | loss: 0.1012242\n",
      "\tspeed: 0.1731s/iter; left time: 4622.5006s\n",
      "3099it [08:55,  5.82it/s]\titers: 3100, epoch: 1 | loss: 0.9708627\n",
      "\tspeed: 0.1738s/iter; left time: 4623.7196s\n",
      "3199it [09:13,  5.84it/s]\titers: 3200, epoch: 1 | loss: 0.5205498\n",
      "\tspeed: 0.1723s/iter; left time: 4567.0195s\n",
      "3299it [09:30,  5.93it/s]\titers: 3300, epoch: 1 | loss: 0.1735685\n",
      "\tspeed: 0.1713s/iter; left time: 4524.2723s\n",
      "3399it [09:47,  5.92it/s]\titers: 3400, epoch: 1 | loss: 0.1689824\n",
      "\tspeed: 0.1698s/iter; left time: 4465.7446s\n",
      "3499it [10:04,  5.85it/s]\titers: 3500, epoch: 1 | loss: 0.4004982\n",
      "\tspeed: 0.1720s/iter; left time: 4506.9514s\n",
      "3599it [10:21,  5.77it/s]\titers: 3600, epoch: 1 | loss: 0.3065372\n",
      "\tspeed: 0.1732s/iter; left time: 4522.3066s\n",
      "3699it [10:38,  5.60it/s]\titers: 3700, epoch: 1 | loss: 0.1145960\n",
      "\tspeed: 0.1731s/iter; left time: 4502.5533s\n",
      "3799it [10:56,  5.88it/s]\titers: 3800, epoch: 1 | loss: 0.2801390\n",
      "\tspeed: 0.1721s/iter; left time: 4458.1310s\n",
      "3899it [11:13,  5.79it/s]\titers: 3900, epoch: 1 | loss: 0.1654157\n",
      "\tspeed: 0.1711s/iter; left time: 4415.5560s\n",
      "3999it [11:30,  5.83it/s]\titers: 4000, epoch: 1 | loss: 0.1941476\n",
      "\tspeed: 0.1733s/iter; left time: 4455.0745s\n",
      "4099it [11:47,  5.91it/s]\titers: 4100, epoch: 1 | loss: 0.1112789\n",
      "\tspeed: 0.1688s/iter; left time: 4323.4331s\n",
      "4199it [12:04,  5.83it/s]\titers: 4200, epoch: 1 | loss: 0.0875820\n",
      "\tspeed: 0.1702s/iter; left time: 4341.6287s\n",
      "4299it [12:21,  5.84it/s]\titers: 4300, epoch: 1 | loss: 0.1463878\n",
      "\tspeed: 0.1723s/iter; left time: 4376.9751s\n",
      "4399it [12:38,  5.82it/s]\titers: 4400, epoch: 1 | loss: 0.8804156\n",
      "\tspeed: 0.1724s/iter; left time: 4363.5233s\n",
      "4499it [12:56,  5.93it/s]\titers: 4500, epoch: 1 | loss: 0.1141298\n",
      "\tspeed: 0.1715s/iter; left time: 4322.6197s\n",
      "4599it [13:13,  5.85it/s]\titers: 4600, epoch: 1 | loss: 0.1119518\n",
      "\tspeed: 0.1707s/iter; left time: 4286.3098s\n",
      "4699it [13:30,  5.82it/s]\titers: 4700, epoch: 1 | loss: 0.7007938\n",
      "\tspeed: 0.1742s/iter; left time: 4356.3465s\n",
      "4799it [13:47,  5.68it/s]\titers: 4800, epoch: 1 | loss: 0.3734833\n",
      "\tspeed: 0.1723s/iter; left time: 4290.2052s\n",
      "4899it [14:04,  5.83it/s]\titers: 4900, epoch: 1 | loss: 0.3359680\n",
      "\tspeed: 0.1713s/iter; left time: 4248.5013s\n",
      "4999it [14:22,  5.83it/s]\titers: 5000, epoch: 1 | loss: 0.2773645\n",
      "\tspeed: 0.1736s/iter; left time: 4289.4798s\n",
      "5099it [14:39,  5.84it/s]\titers: 5100, epoch: 1 | loss: 0.8992349\n",
      "\tspeed: 0.1720s/iter; left time: 4232.8332s\n",
      "5199it [14:56,  5.83it/s]\titers: 5200, epoch: 1 | loss: 0.1540292\n",
      "\tspeed: 0.1716s/iter; left time: 4204.9255s\n",
      "5299it [15:13,  5.84it/s]\titers: 5300, epoch: 1 | loss: 0.2612482\n",
      "\tspeed: 0.1710s/iter; left time: 4174.1248s\n",
      "5399it [15:31,  5.89it/s]\titers: 5400, epoch: 1 | loss: 0.1455708\n",
      "\tspeed: 0.1721s/iter; left time: 4183.2658s\n",
      "5499it [15:48,  5.84it/s]\titers: 5500, epoch: 1 | loss: 0.1947661\n",
      "\tspeed: 0.1726s/iter; left time: 4177.9518s\n",
      "5599it [16:05,  5.85it/s]\titers: 5600, epoch: 1 | loss: 0.1214142\n",
      "\tspeed: 0.1730s/iter; left time: 4169.4861s\n",
      "5699it [16:22,  5.78it/s]\titers: 5700, epoch: 1 | loss: 0.2476432\n",
      "\tspeed: 0.1737s/iter; left time: 4169.0065s\n",
      "5799it [16:40,  5.68it/s]\titers: 5800, epoch: 1 | loss: 0.1254494\n",
      "\tspeed: 0.1758s/iter; left time: 4202.0756s\n",
      "5899it [16:57,  5.40it/s]\titers: 5900, epoch: 1 | loss: 0.2213359\n",
      "\tspeed: 0.1740s/iter; left time: 4142.7547s\n",
      "5999it [17:15,  5.79it/s]\titers: 6000, epoch: 1 | loss: 0.0789860\n",
      "\tspeed: 0.1732s/iter; left time: 4106.2215s\n",
      "6099it [17:32,  5.80it/s]\titers: 6100, epoch: 1 | loss: 0.2488994\n",
      "\tspeed: 0.1736s/iter; left time: 4098.2620s\n",
      "6199it [17:49,  5.86it/s]\titers: 6200, epoch: 1 | loss: 1.0039293\n",
      "\tspeed: 0.1732s/iter; left time: 4072.1956s\n",
      "6299it [18:07,  5.81it/s]\titers: 6300, epoch: 1 | loss: 0.2651639\n",
      "\tspeed: 0.1719s/iter; left time: 4023.7376s\n",
      "6399it [18:24,  5.79it/s]\titers: 6400, epoch: 1 | loss: 0.2597941\n",
      "\tspeed: 0.1736s/iter; left time: 4045.3409s\n",
      "6499it [18:41,  5.84it/s]\titers: 6500, epoch: 1 | loss: 0.1216619\n",
      "\tspeed: 0.1743s/iter; left time: 4044.4241s\n",
      "6599it [18:59,  5.83it/s]\titers: 6600, epoch: 1 | loss: 0.1354033\n",
      "\tspeed: 0.1738s/iter; left time: 4016.4684s\n",
      "6699it [19:16,  5.84it/s]\titers: 6700, epoch: 1 | loss: 0.2305555\n",
      "\tspeed: 0.1750s/iter; left time: 4026.0414s\n",
      "6799it [19:34,  5.89it/s]\titers: 6800, epoch: 1 | loss: 0.1952226\n",
      "\tspeed: 0.1730s/iter; left time: 3963.1608s\n",
      "6899it [19:51,  5.85it/s]\titers: 6900, epoch: 1 | loss: 0.2733072\n",
      "\tspeed: 0.1725s/iter; left time: 3934.7129s\n",
      "6999it [20:08,  5.77it/s]\titers: 7000, epoch: 1 | loss: 0.4113727\n",
      "\tspeed: 0.1735s/iter; left time: 3938.5969s\n",
      "7099it [20:25,  5.36it/s]\titers: 7100, epoch: 1 | loss: 0.5628402\n",
      "\tspeed: 0.1725s/iter; left time: 3899.2603s\n",
      "7199it [20:43,  5.82it/s]\titers: 7200, epoch: 1 | loss: 0.1677743\n",
      "\tspeed: 0.1722s/iter; left time: 3876.0813s\n",
      "7299it [21:00,  5.88it/s]\titers: 7300, epoch: 1 | loss: 0.1742498\n",
      "\tspeed: 0.1727s/iter; left time: 3870.5807s\n",
      "7399it [21:17,  5.80it/s]\titers: 7400, epoch: 1 | loss: 0.1738543\n",
      "\tspeed: 0.1736s/iter; left time: 3871.8374s\n",
      "7499it [21:35,  5.74it/s]\titers: 7500, epoch: 1 | loss: 0.3550659\n",
      "\tspeed: 0.1724s/iter; left time: 3828.3405s\n",
      "7599it [21:52,  5.86it/s]\titers: 7600, epoch: 1 | loss: 0.9472451\n",
      "\tspeed: 0.1733s/iter; left time: 3829.9573s\n",
      "7699it [22:09,  5.78it/s]\titers: 7700, epoch: 1 | loss: 0.1091144\n",
      "\tspeed: 0.1736s/iter; left time: 3819.5989s\n",
      "7799it [22:27,  5.81it/s]\titers: 7800, epoch: 1 | loss: 0.7928885\n",
      "\tspeed: 0.1730s/iter; left time: 3790.5936s\n",
      "7899it [22:44,  5.81it/s]\titers: 7900, epoch: 1 | loss: 0.0686032\n",
      "\tspeed: 0.1734s/iter; left time: 3780.6856s\n",
      "7999it [23:01,  5.85it/s]\titers: 8000, epoch: 1 | loss: 0.1612759\n",
      "\tspeed: 0.1737s/iter; left time: 3770.0021s\n",
      "8099it [23:18,  5.89it/s]\titers: 8100, epoch: 1 | loss: 0.1165099\n",
      "\tspeed: 0.1704s/iter; left time: 3682.5496s\n",
      "8199it [23:36,  5.81it/s]\titers: 8200, epoch: 1 | loss: 0.1135871\n",
      "\tspeed: 0.1734s/iter; left time: 3728.1106s\n",
      "8299it [23:53,  5.83it/s]\titers: 8300, epoch: 1 | loss: 0.1251438\n",
      "\tspeed: 0.1732s/iter; left time: 3707.7502s\n",
      "8399it [24:10,  5.86it/s]\titers: 8400, epoch: 1 | loss: 0.0660727\n",
      "\tspeed: 0.1734s/iter; left time: 3695.3368s\n",
      "8499it [24:27,  5.81it/s]\titers: 8500, epoch: 1 | loss: 0.1437341\n",
      "\tspeed: 0.1720s/iter; left time: 3647.9389s\n",
      "8599it [24:45,  5.31it/s]\titers: 8600, epoch: 1 | loss: 0.2793804\n",
      "\tspeed: 0.1724s/iter; left time: 3637.7967s\n",
      "8699it [25:02,  5.84it/s]\titers: 8700, epoch: 1 | loss: 0.2188035\n",
      "\tspeed: 0.1714s/iter; left time: 3599.9720s\n",
      "8799it [25:19,  5.98it/s]\titers: 8800, epoch: 1 | loss: 0.2560190\n",
      "\tspeed: 0.1693s/iter; left time: 3539.0736s\n",
      "8899it [25:36,  5.91it/s]\titers: 8900, epoch: 1 | loss: 0.1619446\n",
      "\tspeed: 0.1690s/iter; left time: 3516.3009s\n",
      "8999it [25:53,  5.92it/s]\titers: 9000, epoch: 1 | loss: 0.4721746\n",
      "\tspeed: 0.1686s/iter; left time: 3490.6476s\n",
      "9099it [26:10,  5.84it/s]\titers: 9100, epoch: 1 | loss: 0.1548792\n",
      "\tspeed: 0.1720s/iter; left time: 3544.1305s\n",
      "9199it [26:27,  5.81it/s]\titers: 9200, epoch: 1 | loss: 0.2133459\n",
      "\tspeed: 0.1733s/iter; left time: 3553.7062s\n",
      "9299it [26:44,  5.83it/s]\titers: 9300, epoch: 1 | loss: 0.0920845\n",
      "\tspeed: 0.1722s/iter; left time: 3513.2260s\n",
      "9399it [27:02,  5.88it/s]\titers: 9400, epoch: 1 | loss: 0.2078221\n",
      "\tspeed: 0.1736s/iter; left time: 3524.4604s\n",
      "9499it [27:19,  5.90it/s]\titers: 9500, epoch: 1 | loss: 0.5962553\n",
      "\tspeed: 0.1706s/iter; left time: 3446.4485s\n",
      "9599it [27:36,  5.94it/s]\titers: 9600, epoch: 1 | loss: 0.1345300\n",
      "\tspeed: 0.1704s/iter; left time: 3426.2700s\n",
      "9699it [27:53,  5.88it/s]\titers: 9700, epoch: 1 | loss: 0.7007051\n",
      "\tspeed: 0.1704s/iter; left time: 3409.6871s\n",
      "9799it [28:10,  5.78it/s]\titers: 9800, epoch: 1 | loss: 0.1719010\n",
      "\tspeed: 0.1721s/iter; left time: 3425.7686s\n",
      "9899it [28:27,  5.82it/s]\titers: 9900, epoch: 1 | loss: 0.1262725\n",
      "\tspeed: 0.1737s/iter; left time: 3441.2555s\n",
      "9999it [28:45,  5.87it/s]\titers: 10000, epoch: 1 | loss: 0.1639885\n",
      "\tspeed: 0.1743s/iter; left time: 3435.3808s\n",
      "10099it [29:02,  5.81it/s]\titers: 10100, epoch: 1 | loss: 0.0426773\n",
      "\tspeed: 0.1740s/iter; left time: 3410.6786s\n",
      "10199it [29:19,  5.27it/s]\titers: 10200, epoch: 1 | loss: 0.5532264\n",
      "\tspeed: 0.1732s/iter; left time: 3378.0645s\n",
      "10299it [29:37,  5.35it/s]\titers: 10300, epoch: 1 | loss: 0.1898806\n",
      "\tspeed: 0.1723s/iter; left time: 3343.8954s\n",
      "10399it [29:54,  5.81it/s]\titers: 10400, epoch: 1 | loss: 0.2934946\n",
      "\tspeed: 0.1732s/iter; left time: 3344.0154s\n",
      "10499it [30:11,  5.88it/s]\titers: 10500, epoch: 1 | loss: 0.0936582\n",
      "\tspeed: 0.1727s/iter; left time: 3317.7780s\n",
      "10599it [30:29,  5.82it/s]\titers: 10600, epoch: 1 | loss: 0.3450982\n",
      "\tspeed: 0.1739s/iter; left time: 3321.7394s\n",
      "10699it [30:46,  5.83it/s]\titers: 10700, epoch: 1 | loss: 0.5284604\n",
      "\tspeed: 0.1729s/iter; left time: 3285.5269s\n",
      "10799it [31:03,  5.83it/s]\titers: 10800, epoch: 1 | loss: 0.1592788\n",
      "\tspeed: 0.1730s/iter; left time: 3270.8275s\n",
      "10899it [31:20,  5.95it/s]\titers: 10900, epoch: 1 | loss: 0.2415662\n",
      "\tspeed: 0.1699s/iter; left time: 3195.8786s\n",
      "10999it [31:37,  5.95it/s]\titers: 11000, epoch: 1 | loss: 0.0938571\n",
      "\tspeed: 0.1690s/iter; left time: 3160.9928s\n",
      "11099it [31:54,  5.91it/s]\titers: 11100, epoch: 1 | loss: 0.1506357\n",
      "\tspeed: 0.1692s/iter; left time: 3147.9491s\n",
      "11199it [32:16,  3.90it/s]\titers: 11200, epoch: 1 | loss: 0.0396508\n",
      "\tspeed: 0.2212s/iter; left time: 4093.2679s\n",
      "11299it [32:42,  3.88it/s]\titers: 11300, epoch: 1 | loss: 0.1362401\n",
      "\tspeed: 0.2623s/iter; left time: 4827.6084s\n",
      "11399it [33:06,  5.19it/s]\titers: 11400, epoch: 1 | loss: 0.1181507\n",
      "\tspeed: 0.2365s/iter; left time: 4329.0603s\n",
      "11499it [33:42,  2.72it/s]\titers: 11500, epoch: 1 | loss: 0.1033998\n",
      "\tspeed: 0.3643s/iter; left time: 6631.6908s\n",
      "11599it [34:20,  2.68it/s]\titers: 11600, epoch: 1 | loss: 0.4199752\n",
      "\tspeed: 0.3750s/iter; left time: 6788.9818s\n",
      "11699it [34:57,  2.67it/s]\titers: 11700, epoch: 1 | loss: 0.9203606\n",
      "\tspeed: 0.3753s/iter; left time: 6757.3101s\n",
      "11799it [35:35,  2.71it/s]\titers: 11800, epoch: 1 | loss: 0.1672671\n",
      "\tspeed: 0.3752s/iter; left time: 6717.8905s\n",
      "11899it [36:12,  2.67it/s]\titers: 11900, epoch: 1 | loss: 0.2857038\n",
      "\tspeed: 0.3751s/iter; left time: 6678.6771s\n",
      "11999it [36:50,  2.65it/s]\titers: 12000, epoch: 1 | loss: 0.5969759\n",
      "\tspeed: 0.3755s/iter; left time: 6649.2730s\n",
      "12099it [37:17,  5.79it/s]\titers: 12100, epoch: 1 | loss: 0.0742296\n",
      "\tspeed: 0.2699s/iter; left time: 4751.7777s\n",
      "12199it [37:34,  5.77it/s]\titers: 12200, epoch: 1 | loss: 0.9567947\n",
      "\tspeed: 0.1729s/iter; left time: 3025.9304s\n",
      "12299it [37:52,  5.84it/s]\titers: 12300, epoch: 1 | loss: 0.1370284\n",
      "\tspeed: 0.1725s/iter; left time: 3003.1884s\n",
      "12399it [38:09,  5.96it/s]\titers: 12400, epoch: 1 | loss: 0.2177869\n",
      "\tspeed: 0.1721s/iter; left time: 2978.3031s\n",
      "12499it [38:26,  5.82it/s]\titers: 12500, epoch: 1 | loss: 0.1174163\n",
      "\tspeed: 0.1701s/iter; left time: 2925.9387s\n",
      "12599it [38:43,  5.78it/s]\titers: 12600, epoch: 1 | loss: 0.0952167\n",
      "\tspeed: 0.1722s/iter; left time: 2944.9720s\n",
      "12699it [39:00,  5.86it/s]\titers: 12700, epoch: 1 | loss: 0.0745180\n",
      "\tspeed: 0.1732s/iter; left time: 2945.9280s\n",
      "12799it [39:18,  5.81it/s]\titers: 12800, epoch: 1 | loss: 0.0613569\n",
      "\tspeed: 0.1724s/iter; left time: 2914.8225s\n",
      "12899it [39:35,  5.89it/s]\titers: 12900, epoch: 1 | loss: 0.1212397\n",
      "\tspeed: 0.1725s/iter; left time: 2899.4739s\n",
      "12999it [39:52,  5.83it/s]\titers: 13000, epoch: 1 | loss: 0.1994453\n",
      "\tspeed: 0.1739s/iter; left time: 2905.3983s\n",
      "13099it [40:10,  5.84it/s]\titers: 13100, epoch: 1 | loss: 0.3642481\n",
      "\tspeed: 0.1727s/iter; left time: 2867.6100s\n",
      "13199it [40:27,  5.92it/s]\titers: 13200, epoch: 1 | loss: 0.0462200\n",
      "\tspeed: 0.1701s/iter; left time: 2807.8255s\n",
      "13299it [40:44,  5.84it/s]\titers: 13300, epoch: 1 | loss: 0.2604310\n",
      "\tspeed: 0.1739s/iter; left time: 2853.8102s\n",
      "13399it [41:03,  3.74it/s]\titers: 13400, epoch: 1 | loss: 0.1015811\n",
      "\tspeed: 0.1924s/iter; left time: 3137.7580s\n",
      "13499it [41:30,  3.78it/s]\titers: 13500, epoch: 1 | loss: 0.2014813\n",
      "\tspeed: 0.2639s/iter; left time: 4277.4404s\n",
      "13599it [41:56,  3.92it/s]\titers: 13600, epoch: 1 | loss: 0.6772938\n",
      "\tspeed: 0.2636s/iter; left time: 4246.1929s\n",
      "13699it [42:29,  2.62it/s]\titers: 13700, epoch: 1 | loss: 0.0883630\n",
      "\tspeed: 0.3342s/iter; left time: 5349.4731s\n",
      "13799it [43:07,  2.60it/s]\titers: 13800, epoch: 1 | loss: 0.6614763\n",
      "\tspeed: 0.3810s/iter; left time: 6060.5643s\n",
      "13899it [43:45,  2.63it/s]\titers: 13900, epoch: 1 | loss: 0.2683596\n",
      "\tspeed: 0.3799s/iter; left time: 6004.9213s\n",
      "13999it [44:23,  2.62it/s]\titers: 14000, epoch: 1 | loss: 0.3193859\n",
      "\tspeed: 0.3807s/iter; left time: 5979.5522s\n",
      "14099it [45:02,  2.64it/s]\titers: 14100, epoch: 1 | loss: 0.4356972\n",
      "\tspeed: 0.3810s/iter; left time: 5945.8619s\n",
      "14199it [45:40,  2.64it/s]\titers: 14200, epoch: 1 | loss: 0.1829053\n",
      "\tspeed: 0.3806s/iter; left time: 5902.0261s\n",
      "14299it [46:18,  2.64it/s]\titers: 14300, epoch: 1 | loss: 0.1240173\n",
      "\tspeed: 0.3793s/iter; left time: 5843.2677s\n",
      "14399it [46:56,  2.62it/s]\titers: 14400, epoch: 1 | loss: 0.2043637\n",
      "\tspeed: 0.3804s/iter; left time: 5821.7779s\n",
      "14499it [47:34,  2.62it/s]\titers: 14500, epoch: 1 | loss: 0.5491531\n",
      "\tspeed: 0.3801s/iter; left time: 5779.7857s\n",
      "14599it [48:12,  2.61it/s]\titers: 14600, epoch: 1 | loss: 0.0543813\n",
      "\tspeed: 0.3804s/iter; left time: 5745.5724s\n",
      "14699it [48:50,  2.63it/s]\titers: 14700, epoch: 1 | loss: 0.4447525\n",
      "\tspeed: 0.3796s/iter; left time: 5696.0080s\n",
      "14799it [49:15,  5.91it/s]\titers: 14800, epoch: 1 | loss: 0.1639715\n",
      "\tspeed: 0.2514s/iter; left time: 3747.9906s\n",
      "14899it [49:32,  5.92it/s]\titers: 14900, epoch: 1 | loss: 0.1213382\n",
      "\tspeed: 0.1694s/iter; left time: 2508.1499s\n",
      "14999it [49:51,  3.83it/s]\titers: 15000, epoch: 1 | loss: 0.2863824\n",
      "\tspeed: 0.1952s/iter; left time: 2870.7876s\n",
      "15099it [50:18,  3.77it/s]\titers: 15100, epoch: 1 | loss: 0.1850952\n",
      "\tspeed: 0.2639s/iter; left time: 3854.6039s\n",
      "15199it [50:44,  5.56it/s]\titers: 15200, epoch: 1 | loss: 0.2748749\n",
      "\tspeed: 0.2585s/iter; left time: 3749.2995s\n",
      "15299it [51:18,  2.67it/s]\titers: 15300, epoch: 1 | loss: 0.0349729\n",
      "\tspeed: 0.3424s/iter; left time: 4932.9916s\n",
      "15399it [51:55,  2.68it/s]\titers: 15400, epoch: 1 | loss: 0.6873962\n",
      "\tspeed: 0.3730s/iter; left time: 5336.4056s\n",
      "15499it [52:33,  2.67it/s]\titers: 15500, epoch: 1 | loss: 0.0980209\n",
      "\tspeed: 0.3752s/iter; left time: 5330.5330s\n",
      "15599it [53:10,  2.67it/s]\titers: 15600, epoch: 1 | loss: 0.3816456\n",
      "\tspeed: 0.3744s/iter; left time: 5281.0865s\n",
      "15699it [53:47,  2.69it/s]\titers: 15700, epoch: 1 | loss: 0.0737382\n",
      "\tspeed: 0.3741s/iter; left time: 5239.5827s\n",
      "15799it [54:25,  2.67it/s]\titers: 15800, epoch: 1 | loss: 0.1256571\n",
      "\tspeed: 0.3747s/iter; left time: 5210.4199s\n",
      "15899it [54:54,  5.85it/s]\titers: 15900, epoch: 1 | loss: 0.2091437\n",
      "\tspeed: 0.2952s/iter; left time: 4075.6520s\n",
      "15999it [55:12,  5.80it/s]\titers: 16000, epoch: 1 | loss: 0.3124808\n",
      "\tspeed: 0.1731s/iter; left time: 2372.0591s\n",
      "16099it [55:29,  4.74it/s]\titers: 16100, epoch: 1 | loss: 0.3842218\n",
      "\tspeed: 0.1739s/iter; left time: 2365.4112s\n",
      "16199it [55:46,  5.81it/s]\titers: 16200, epoch: 1 | loss: 0.6273005\n",
      "\tspeed: 0.1711s/iter; left time: 2310.2667s\n",
      "16299it [56:04,  5.81it/s]\titers: 16300, epoch: 1 | loss: 0.3433484\n",
      "\tspeed: 0.1740s/iter; left time: 2332.3555s\n",
      "16399it [56:21,  5.85it/s]\titers: 16400, epoch: 1 | loss: 0.2394594\n",
      "\tspeed: 0.1735s/iter; left time: 2308.8867s\n",
      "16499it [56:38,  5.81it/s]\titers: 16500, epoch: 1 | loss: 0.2778091\n",
      "\tspeed: 0.1732s/iter; left time: 2286.6370s\n",
      "16599it [56:55,  5.82it/s]\titers: 16600, epoch: 1 | loss: 0.5105854\n",
      "\tspeed: 0.1711s/iter; left time: 2242.9128s\n",
      "16699it [57:13,  5.81it/s]\titers: 16700, epoch: 1 | loss: 0.2387884\n",
      "\tspeed: 0.1720s/iter; left time: 2237.3773s\n",
      "16799it [57:30,  5.85it/s]\titers: 16800, epoch: 1 | loss: 0.2312557\n",
      "\tspeed: 0.1722s/iter; left time: 2222.0668s\n",
      "16899it [57:47,  5.80it/s]\titers: 16900, epoch: 1 | loss: 0.1799667\n",
      "\tspeed: 0.1727s/iter; left time: 2211.5573s\n",
      "16999it [58:04,  5.87it/s]\titers: 17000, epoch: 1 | loss: 0.6795046\n",
      "\tspeed: 0.1734s/iter; left time: 2203.3503s\n",
      "17099it [58:21,  5.97it/s]\titers: 17100, epoch: 1 | loss: 0.5513248\n",
      "\tspeed: 0.1695s/iter; left time: 2136.5180s\n",
      "17199it [58:38,  5.98it/s]\titers: 17200, epoch: 1 | loss: 0.2325266\n",
      "\tspeed: 0.1678s/iter; left time: 2098.4367s\n",
      "17299it [58:55,  6.01it/s]\titers: 17300, epoch: 1 | loss: 0.1668275\n",
      "\tspeed: 0.1676s/iter; left time: 2079.3641s\n",
      "17399it [59:12,  5.95it/s]\titers: 17400, epoch: 1 | loss: 0.1121390\n",
      "\tspeed: 0.1684s/iter; left time: 2071.9932s\n",
      "17499it [59:29,  5.94it/s]\titers: 17500, epoch: 1 | loss: 0.2772318\n",
      "\tspeed: 0.1683s/iter; left time: 2053.9648s\n",
      "17599it [59:45,  5.84it/s]\titers: 17600, epoch: 1 | loss: 0.1169566\n",
      "\tspeed: 0.1689s/iter; left time: 2045.1867s\n",
      "17699it [1:00:02,  5.95it/s]\titers: 17700, epoch: 1 | loss: 0.7953797\n",
      "\tspeed: 0.1699s/iter; left time: 2039.4640s\n",
      "17799it [1:00:19,  5.90it/s]\titers: 17800, epoch: 1 | loss: 0.0739596\n",
      "\tspeed: 0.1698s/iter; left time: 2022.0622s\n",
      "17899it [1:00:36,  5.88it/s]\titers: 17900, epoch: 1 | loss: 0.0994916\n",
      "\tspeed: 0.1693s/iter; left time: 1998.4771s\n",
      "17999it [1:00:53,  5.74it/s]\titers: 18000, epoch: 1 | loss: 0.0536118\n",
      "\tspeed: 0.1690s/iter; left time: 1978.4415s\n",
      "18099it [1:01:10,  5.85it/s]\titers: 18100, epoch: 1 | loss: 0.2855749\n",
      "\tspeed: 0.1701s/iter; left time: 1973.9915s\n",
      "18199it [1:01:27,  5.84it/s]\titers: 18200, epoch: 1 | loss: 0.2222405\n",
      "\tspeed: 0.1708s/iter; left time: 1964.9935s\n",
      "18299it [1:01:45,  5.76it/s]\titers: 18300, epoch: 1 | loss: 0.6102778\n",
      "\tspeed: 0.1722s/iter; left time: 1963.9421s\n",
      "18399it [1:02:02,  5.83it/s]\titers: 18400, epoch: 1 | loss: 0.0920710\n",
      "\tspeed: 0.1725s/iter; left time: 1949.7678s\n",
      "18499it [1:02:19,  5.82it/s]\titers: 18500, epoch: 1 | loss: 0.1471266\n",
      "\tspeed: 0.1719s/iter; left time: 1926.6980s\n",
      "18599it [1:02:36,  5.85it/s]\titers: 18600, epoch: 1 | loss: 0.0648521\n",
      "\tspeed: 0.1733s/iter; left time: 1924.2674s\n",
      "18699it [1:02:54,  5.85it/s]\titers: 18700, epoch: 1 | loss: 0.1082078\n",
      "\tspeed: 0.1732s/iter; left time: 1906.1145s\n",
      "18799it [1:03:11,  5.78it/s]\titers: 18800, epoch: 1 | loss: 0.5018492\n",
      "\tspeed: 0.1746s/iter; left time: 1904.5655s\n",
      "18899it [1:03:29,  5.75it/s]\titers: 18900, epoch: 1 | loss: 0.2417234\n",
      "\tspeed: 0.1756s/iter; left time: 1897.1574s\n",
      "18999it [1:03:46,  5.82it/s]\titers: 19000, epoch: 1 | loss: 0.1081420\n",
      "\tspeed: 0.1740s/iter; left time: 1862.5591s\n",
      "19099it [1:04:03,  5.82it/s]\titers: 19100, epoch: 1 | loss: 0.1186238\n",
      "\tspeed: 0.1733s/iter; left time: 1838.1857s\n",
      "19199it [1:04:21,  5.75it/s]\titers: 19200, epoch: 1 | loss: 0.0658043\n",
      "\tspeed: 0.1730s/iter; left time: 1817.9429s\n",
      "19299it [1:04:38,  5.79it/s]\titers: 19300, epoch: 1 | loss: 0.2509463\n",
      "\tspeed: 0.1725s/iter; left time: 1794.9986s\n",
      "19399it [1:04:55,  5.69it/s]\titers: 19400, epoch: 1 | loss: 0.1218918\n",
      "\tspeed: 0.1727s/iter; left time: 1780.0240s\n",
      "19499it [1:05:13,  5.03it/s]\titers: 19500, epoch: 1 | loss: 0.1762856\n",
      "\tspeed: 0.1745s/iter; left time: 1781.2833s\n",
      "19599it [1:05:30,  5.24it/s]\titers: 19600, epoch: 1 | loss: 0.1748880\n",
      "\tspeed: 0.1747s/iter; left time: 1765.2364s\n",
      "19699it [1:05:47,  5.87it/s]\titers: 19700, epoch: 1 | loss: 0.6551110\n",
      "\tspeed: 0.1729s/iter; left time: 1729.6606s\n",
      "19799it [1:06:05,  5.76it/s]\titers: 19800, epoch: 1 | loss: 0.2309869\n",
      "\tspeed: 0.1734s/iter; left time: 1717.8464s\n",
      "19899it [1:06:22,  5.86it/s]\titers: 19900, epoch: 1 | loss: 0.2013379\n",
      "\tspeed: 0.1702s/iter; left time: 1668.8576s\n",
      "19999it [1:06:39,  5.82it/s]\titers: 20000, epoch: 1 | loss: 0.1232175\n",
      "\tspeed: 0.1707s/iter; left time: 1656.6895s\n",
      "20099it [1:06:56,  5.79it/s]\titers: 20100, epoch: 1 | loss: 0.2577030\n",
      "\tspeed: 0.1737s/iter; left time: 1668.7114s\n",
      "20199it [1:07:14,  5.72it/s]\titers: 20200, epoch: 1 | loss: 0.2628649\n",
      "\tspeed: 0.1741s/iter; left time: 1654.6253s\n",
      "20299it [1:07:31,  5.78it/s]\titers: 20300, epoch: 1 | loss: 0.0221700\n",
      "\tspeed: 0.1747s/iter; left time: 1642.8557s\n",
      "20399it [1:07:49,  5.80it/s]\titers: 20400, epoch: 1 | loss: 0.3109417\n",
      "\tspeed: 0.1741s/iter; left time: 1620.1651s\n",
      "20499it [1:08:06,  5.78it/s]\titers: 20500, epoch: 1 | loss: 0.0799850\n",
      "\tspeed: 0.1742s/iter; left time: 1603.2885s\n",
      "20599it [1:08:23,  5.55it/s]\titers: 20600, epoch: 1 | loss: 0.3188447\n",
      "\tspeed: 0.1738s/iter; left time: 1582.7122s\n",
      "20699it [1:08:41,  5.34it/s]\titers: 20700, epoch: 1 | loss: 0.1060150\n",
      "\tspeed: 0.1740s/iter; left time: 1566.9644s\n",
      "20799it [1:08:58,  5.46it/s]\titers: 20800, epoch: 1 | loss: 0.1011181\n",
      "\tspeed: 0.1732s/iter; left time: 1542.8345s\n",
      "20899it [1:09:15,  5.76it/s]\titers: 20900, epoch: 1 | loss: 0.4541431\n",
      "\tspeed: 0.1729s/iter; left time: 1522.4757s\n",
      "20999it [1:09:33,  5.77it/s]\titers: 21000, epoch: 1 | loss: 0.2296910\n",
      "\tspeed: 0.1737s/iter; left time: 1512.2925s\n",
      "21099it [1:09:50,  5.79it/s]\titers: 21100, epoch: 1 | loss: 0.8036953\n",
      "\tspeed: 0.1743s/iter; left time: 1500.1023s\n",
      "21199it [1:10:07,  5.90it/s]\titers: 21200, epoch: 1 | loss: 0.1426893\n",
      "\tspeed: 0.1700s/iter; left time: 1445.9542s\n",
      "21299it [1:10:24,  5.89it/s]\titers: 21300, epoch: 1 | loss: 0.1056532\n",
      "\tspeed: 0.1693s/iter; left time: 1423.5406s\n",
      "21399it [1:10:41,  5.91it/s]\titers: 21400, epoch: 1 | loss: 0.1434236\n",
      "\tspeed: 0.1691s/iter; left time: 1404.5840s\n",
      "21499it [1:10:58,  5.84it/s]\titers: 21500, epoch: 1 | loss: 0.3239945\n",
      "\tspeed: 0.1696s/iter; left time: 1391.3749s\n",
      "21599it [1:11:15,  5.92it/s]\titers: 21600, epoch: 1 | loss: 0.1823280\n",
      "\tspeed: 0.1703s/iter; left time: 1380.7883s\n",
      "21699it [1:11:32,  5.85it/s]\titers: 21700, epoch: 1 | loss: 0.0270296\n",
      "\tspeed: 0.1700s/iter; left time: 1361.2793s\n",
      "21799it [1:11:49,  5.85it/s]\titers: 21800, epoch: 1 | loss: 0.1809842\n",
      "\tspeed: 0.1728s/iter; left time: 1366.5062s\n",
      "21899it [1:12:07,  5.88it/s]\titers: 21900, epoch: 1 | loss: 0.0779025\n",
      "\tspeed: 0.1737s/iter; left time: 1355.9457s\n",
      "21999it [1:12:24,  5.84it/s]\titers: 22000, epoch: 1 | loss: 0.6630195\n",
      "\tspeed: 0.1734s/iter; left time: 1336.0039s\n",
      "22099it [1:12:41,  5.83it/s]\titers: 22100, epoch: 1 | loss: 0.2591875\n",
      "\tspeed: 0.1727s/iter; left time: 1313.8914s\n",
      "22199it [1:12:59,  5.73it/s]\titers: 22200, epoch: 1 | loss: 0.1057750\n",
      "\tspeed: 0.1726s/iter; left time: 1295.4606s\n",
      "22299it [1:13:16,  5.62it/s]\titers: 22300, epoch: 1 | loss: 0.2553610\n",
      "\tspeed: 0.1726s/iter; left time: 1278.0043s\n",
      "22399it [1:13:33,  5.83it/s]\titers: 22400, epoch: 1 | loss: 0.0376381\n",
      "\tspeed: 0.1687s/iter; left time: 1232.4915s\n",
      "22499it [1:13:50,  5.80it/s]\titers: 22500, epoch: 1 | loss: 0.0955512\n",
      "\tspeed: 0.1723s/iter; left time: 1241.3228s\n",
      "22599it [1:14:07,  5.72it/s]\titers: 22600, epoch: 1 | loss: 0.0831237\n",
      "\tspeed: 0.1741s/iter; left time: 1237.2822s\n",
      "22699it [1:14:24,  5.86it/s]\titers: 22700, epoch: 1 | loss: 0.0440906\n",
      "\tspeed: 0.1707s/iter; left time: 1195.9221s\n",
      "22799it [1:14:42,  5.78it/s]\titers: 22800, epoch: 1 | loss: 0.5756562\n",
      "\tspeed: 0.1721s/iter; left time: 1188.5003s\n",
      "22899it [1:14:59,  5.80it/s]\titers: 22900, epoch: 1 | loss: 0.0965473\n",
      "\tspeed: 0.1727s/iter; left time: 1175.6740s\n",
      "22999it [1:15:16,  5.79it/s]\titers: 23000, epoch: 1 | loss: 0.0362349\n",
      "\tspeed: 0.1743s/iter; left time: 1169.0554s\n",
      "23099it [1:15:34,  5.80it/s]\titers: 23100, epoch: 1 | loss: 0.1411740\n",
      "\tspeed: 0.1745s/iter; left time: 1152.7887s\n",
      "23199it [1:15:51,  5.81it/s]\titers: 23200, epoch: 1 | loss: 0.2161383\n",
      "\tspeed: 0.1745s/iter; left time: 1135.2027s\n",
      "23299it [1:16:08,  5.79it/s]\titers: 23300, epoch: 1 | loss: 0.3066402\n",
      "\tspeed: 0.1721s/iter; left time: 1102.6445s\n",
      "23399it [1:16:26,  5.78it/s]\titers: 23400, epoch: 1 | loss: 0.3364982\n",
      "\tspeed: 0.1725s/iter; left time: 1087.4967s\n",
      "23499it [1:16:43,  5.79it/s]\titers: 23500, epoch: 1 | loss: 0.1173545\n",
      "\tspeed: 0.1744s/iter; left time: 1082.4570s\n",
      "23599it [1:17:00,  5.84it/s]\titers: 23600, epoch: 1 | loss: 0.1614152\n",
      "\tspeed: 0.1737s/iter; left time: 1060.6661s\n",
      "23699it [1:17:18,  5.81it/s]\titers: 23700, epoch: 1 | loss: 0.2097004\n",
      "\tspeed: 0.1723s/iter; left time: 1034.8844s\n",
      "23799it [1:17:35,  5.89it/s]\titers: 23800, epoch: 1 | loss: 0.2035635\n",
      "\tspeed: 0.1720s/iter; left time: 1016.1197s\n",
      "23899it [1:17:52,  5.91it/s]\titers: 23900, epoch: 1 | loss: 0.0951586\n",
      "\tspeed: 0.1696s/iter; left time: 984.8015s\n",
      "23999it [1:18:09,  5.82it/s]\titers: 24000, epoch: 1 | loss: 0.1602112\n",
      "\tspeed: 0.1720s/iter; left time: 981.4225s\n",
      "24099it [1:18:26,  5.44it/s]\titers: 24100, epoch: 1 | loss: 0.4585220\n",
      "\tspeed: 0.1738s/iter; left time: 974.5292s\n",
      "24199it [1:18:44,  5.00it/s]\titers: 24200, epoch: 1 | loss: 0.4631023\n",
      "\tspeed: 0.1732s/iter; left time: 953.3764s\n",
      "24299it [1:19:01,  5.53it/s]\titers: 24300, epoch: 1 | loss: 0.0662834\n",
      "\tspeed: 0.1726s/iter; left time: 933.0189s\n",
      "24399it [1:19:18,  5.38it/s]\titers: 24400, epoch: 1 | loss: 0.3272948\n",
      "\tspeed: 0.1731s/iter; left time: 918.5050s\n",
      "24499it [1:19:36,  5.73it/s]\titers: 24500, epoch: 1 | loss: 0.0666922\n",
      "\tspeed: 0.1729s/iter; left time: 900.0708s\n",
      "24599it [1:19:53,  5.82it/s]\titers: 24600, epoch: 1 | loss: 0.0940862\n",
      "\tspeed: 0.1728s/iter; left time: 882.2888s\n",
      "24699it [1:20:10,  5.82it/s]\titers: 24700, epoch: 1 | loss: 0.0743787\n",
      "\tspeed: 0.1742s/iter; left time: 872.0275s\n",
      "24799it [1:20:28,  5.82it/s]\titers: 24800, epoch: 1 | loss: 0.0612723\n",
      "\tspeed: 0.1737s/iter; left time: 851.9771s\n",
      "24899it [1:20:45,  5.82it/s]\titers: 24900, epoch: 1 | loss: 0.3857566\n",
      "\tspeed: 0.1723s/iter; left time: 828.0207s\n",
      "24999it [1:21:02,  5.80it/s]\titers: 25000, epoch: 1 | loss: 0.1199505\n",
      "\tspeed: 0.1724s/iter; left time: 811.3114s\n",
      "25099it [1:21:19,  5.83it/s]\titers: 25100, epoch: 1 | loss: 0.3126957\n",
      "\tspeed: 0.1727s/iter; left time: 795.2803s\n",
      "25199it [1:21:37,  5.77it/s]\titers: 25200, epoch: 1 | loss: 0.1946324\n",
      "\tspeed: 0.1747s/iter; left time: 787.2203s\n",
      "25299it [1:21:54,  5.78it/s]\titers: 25300, epoch: 1 | loss: 0.1304453\n",
      "\tspeed: 0.1734s/iter; left time: 763.8392s\n",
      "25399it [1:22:11,  5.81it/s]\titers: 25400, epoch: 1 | loss: 0.0551400\n",
      "\tspeed: 0.1728s/iter; left time: 744.0111s\n",
      "25499it [1:22:29,  5.85it/s]\titers: 25500, epoch: 1 | loss: 0.1305899\n",
      "\tspeed: 0.1726s/iter; left time: 726.1097s\n",
      "25599it [1:22:46,  5.79it/s]\titers: 25600, epoch: 1 | loss: 0.3532454\n",
      "\tspeed: 0.1737s/iter; left time: 713.3660s\n",
      "25699it [1:23:04,  5.84it/s]\titers: 25700, epoch: 1 | loss: 0.1015201\n",
      "\tspeed: 0.1745s/iter; left time: 698.9922s\n",
      "25799it [1:23:21,  5.80it/s]\titers: 25800, epoch: 1 | loss: 0.1301935\n",
      "\tspeed: 0.1739s/iter; left time: 679.1630s\n",
      "25899it [1:23:38,  5.84it/s]\titers: 25900, epoch: 1 | loss: 0.1652094\n",
      "\tspeed: 0.1735s/iter; left time: 660.3176s\n",
      "25999it [1:23:56,  5.78it/s]\titers: 26000, epoch: 1 | loss: 0.1596953\n",
      "\tspeed: 0.1744s/iter; left time: 646.4734s\n",
      "26099it [1:24:13,  5.80it/s]\titers: 26100, epoch: 1 | loss: 0.3074009\n",
      "\tspeed: 0.1741s/iter; left time: 627.6761s\n",
      "26199it [1:24:30,  5.81it/s]\titers: 26200, epoch: 1 | loss: 0.2752254\n",
      "\tspeed: 0.1730s/iter; left time: 606.6332s\n",
      "26299it [1:24:48,  5.79it/s]\titers: 26300, epoch: 1 | loss: 0.1357759\n",
      "\tspeed: 0.1740s/iter; left time: 592.5928s\n",
      "26399it [1:25:05,  5.80it/s]\titers: 26400, epoch: 1 | loss: 0.1975400\n",
      "\tspeed: 0.1739s/iter; left time: 574.9495s\n",
      "26499it [1:25:23,  5.81it/s]\titers: 26500, epoch: 1 | loss: 0.2353301\n",
      "\tspeed: 0.1744s/iter; left time: 559.2055s\n",
      "26599it [1:25:40,  5.80it/s]\titers: 26600, epoch: 1 | loss: 0.2255458\n",
      "\tspeed: 0.1742s/iter; left time: 541.1269s\n",
      "26699it [1:25:57,  5.81it/s]\titers: 26700, epoch: 1 | loss: 0.2594674\n",
      "\tspeed: 0.1728s/iter; left time: 519.5171s\n",
      "26799it [1:26:15,  5.83it/s]\titers: 26800, epoch: 1 | loss: 0.7253950\n",
      "\tspeed: 0.1741s/iter; left time: 505.8868s\n",
      "26899it [1:26:32,  5.73it/s]\titers: 26900, epoch: 1 | loss: 0.1567582\n",
      "\tspeed: 0.1737s/iter; left time: 487.5302s\n",
      "26999it [1:26:49,  5.63it/s]\titers: 27000, epoch: 1 | loss: 0.1951847\n",
      "\tspeed: 0.1720s/iter; left time: 465.3718s\n",
      "27099it [1:27:07,  5.75it/s]\titers: 27100, epoch: 1 | loss: 0.0903886\n",
      "\tspeed: 0.1730s/iter; left time: 450.8982s\n",
      "27199it [1:27:24,  5.47it/s]\titers: 27200, epoch: 1 | loss: 0.3706902\n",
      "\tspeed: 0.1737s/iter; left time: 435.3835s\n",
      "27299it [1:27:41,  5.53it/s]\titers: 27300, epoch: 1 | loss: 0.3245256\n",
      "\tspeed: 0.1728s/iter; left time: 415.8520s\n",
      "27399it [1:27:59,  5.83it/s]\titers: 27400, epoch: 1 | loss: 0.0680483\n",
      "\tspeed: 0.1716s/iter; left time: 395.7693s\n",
      "27499it [1:28:16,  5.78it/s]\titers: 27500, epoch: 1 | loss: 0.1720057\n",
      "\tspeed: 0.1729s/iter; left time: 381.5127s\n",
      "27599it [1:28:33,  5.78it/s]\titers: 27600, epoch: 1 | loss: 0.6142737\n",
      "\tspeed: 0.1730s/iter; left time: 364.2606s\n",
      "27699it [1:28:51,  5.80it/s]\titers: 27700, epoch: 1 | loss: 0.3691139\n",
      "\tspeed: 0.1749s/iter; left time: 350.7523s\n",
      "27799it [1:29:08,  5.81it/s]\titers: 27800, epoch: 1 | loss: 0.0387597\n",
      "\tspeed: 0.1735s/iter; left time: 330.6360s\n",
      "27899it [1:29:25,  5.80it/s]\titers: 27900, epoch: 1 | loss: 0.1552235\n",
      "\tspeed: 0.1723s/iter; left time: 311.2582s\n",
      "27999it [1:29:43,  5.80it/s]\titers: 28000, epoch: 1 | loss: 0.1458867\n",
      "\tspeed: 0.1740s/iter; left time: 296.9232s\n",
      "28099it [1:30:00,  5.83it/s]\titers: 28100, epoch: 1 | loss: 0.5761591\n",
      "\tspeed: 0.1721s/iter; left time: 276.3914s\n",
      "28199it [1:30:17,  5.94it/s]\titers: 28200, epoch: 1 | loss: 0.3503025\n",
      "\tspeed: 0.1704s/iter; left time: 256.6603s\n",
      "28299it [1:30:34,  5.87it/s]\titers: 28300, epoch: 1 | loss: 0.2815970\n",
      "\tspeed: 0.1693s/iter; left time: 238.0785s\n",
      "28399it [1:30:51,  5.88it/s]\titers: 28400, epoch: 1 | loss: 0.6013454\n",
      "\tspeed: 0.1698s/iter; left time: 221.7164s\n",
      "28499it [1:31:08,  5.81it/s]\titers: 28500, epoch: 1 | loss: 0.3941776\n",
      "\tspeed: 0.1693s/iter; left time: 204.1363s\n",
      "28599it [1:31:25,  5.86it/s]\titers: 28600, epoch: 1 | loss: 0.4810668\n",
      "\tspeed: 0.1730s/iter; left time: 191.3400s\n",
      "28699it [1:31:42,  5.83it/s]\titers: 28700, epoch: 1 | loss: 0.0654329\n",
      "\tspeed: 0.1724s/iter; left time: 173.4022s\n",
      "28799it [1:32:00,  5.80it/s]\titers: 28800, epoch: 1 | loss: 0.0563467\n",
      "\tspeed: 0.1738s/iter; left time: 157.4448s\n",
      "28899it [1:32:17,  5.74it/s]\titers: 28900, epoch: 1 | loss: 0.1827449\n",
      "\tspeed: 0.1725s/iter; left time: 139.0402s\n",
      "28999it [1:32:34,  5.82it/s]\titers: 29000, epoch: 1 | loss: 0.0585531\n",
      "\tspeed: 0.1724s/iter; left time: 121.7214s\n",
      "29099it [1:32:51,  5.80it/s]\titers: 29100, epoch: 1 | loss: 0.2691645\n",
      "\tspeed: 0.1740s/iter; left time: 105.4632s\n",
      "29199it [1:33:09,  5.79it/s]\titers: 29200, epoch: 1 | loss: 0.1599855\n",
      "\tspeed: 0.1738s/iter; left time: 87.9629s\n",
      "29299it [1:33:26,  5.75it/s]\titers: 29300, epoch: 1 | loss: 0.2513905\n",
      "\tspeed: 0.1765s/iter; left time: 71.6519s\n",
      "29399it [1:33:44,  5.66it/s]\titers: 29400, epoch: 1 | loss: 0.1516926\n",
      "\tspeed: 0.1787s/iter; left time: 54.6818s\n",
      "29499it [1:34:02,  5.71it/s]\titers: 29500, epoch: 1 | loss: 0.1653662\n",
      "\tspeed: 0.1773s/iter; left time: 36.5200s\n",
      "29599it [1:34:20,  5.58it/s]\titers: 29600, epoch: 1 | loss: 0.1844983\n",
      "\tspeed: 0.1790s/iter; left time: 18.9752s\n",
      "29699it [1:34:37,  5.84it/s]\titers: 29700, epoch: 1 | loss: 0.1536553\n",
      "\tspeed: 0.1734s/iter; left time: 1.0406s\n",
      "29705it [1:34:38,  5.23it/s]\n",
      "Epoch: 1 cost time: 5678.904793739319\n",
      "6481it [08:26, 12.79it/s]\n",
      "6457it [08:29, 12.68it/s]\n",
      "Epoch: 1 | Train Loss: 0.2670069 Vali Loss: 0.3092261 Test Loss: 0.3865547 MAE Loss: 0.3827427\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 114.23530952135722 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-05 20:36:00,798] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-05 20:36:00,828] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-05 20:36:01,772] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-05 20:36:01,772] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-05 20:36:01,772] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.35s/it]\n",
      "d_llm 4096\n",
      "[2024-05-05 20:36:44,407] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:07<00:00,  3.98s/it]\n",
      "d_llm 4096\n",
      "[2024-05-05 20:36:58,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-05 20:36:58,070] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-05 20:36:58,070] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-05 20:36:58,071] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-05 20:36:58,071] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-05 20:36:58,071] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-05 20:36:58,072] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-05 20:36:58,072] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-05 20:36:58,072] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-05 20:36:58,072] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "0it [00:00, ?it/s][2024-05-05 20:36:59,421] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-05 20:36:59,422] [INFO] [utils.py:801:see_memory_usage] MA 12.51 GB         Max_MA 12.55 GB         CA 12.55 GB         Max_CA 13 GB \n",
      "[2024-05-05 20:36:59,422] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.05 GB, percent = 16.7%\n",
      "[2024-05-05 20:36:59,559] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-05 20:36:59,559] [INFO] [utils.py:801:see_memory_usage] MA 12.51 GB         Max_MA 12.59 GB         CA 12.63 GB         Max_CA 13 GB \n",
      "[2024-05-05 20:36:59,559] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.14 GB, percent = 16.7%\n",
      "[2024-05-05 20:36:59,559] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-05 20:36:59,690] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-05 20:36:59,691] [INFO] [utils.py:801:see_memory_usage] MA 12.51 GB         Max_MA 12.51 GB         CA 12.63 GB         Max_CA 13 GB \n",
      "[2024-05-05 20:36:59,691] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.31 GB, percent = 16.7%\n",
      "[2024-05-05 20:36:59,691] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-05 20:36:59,691] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-05 20:36:59,691] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-05 20:36:59,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f42e1856390>\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-05 20:36:59,692] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   train_batch_size ............. 6\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   world_size ................... 2\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-05 20:36:59,693] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-05 20:36:59,694] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-05 20:36:59,694] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 6, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:20,  5.46it/s]\titers: 100, epoch: 1 | loss: 0.9655402\n",
      "\tspeed: 0.3533s/iter; left time: 10460.3207s\n",
      "199it [00:39,  5.43it/s]\titers: 200, epoch: 1 | loss: 0.2792688\n",
      "\tspeed: 0.1868s/iter; left time: 5511.3371s\n",
      "299it [00:58,  5.30it/s]\titers: 300, epoch: 1 | loss: 1.1771156\n",
      "\tspeed: 0.1902s/iter; left time: 5593.6493s\n",
      "399it [01:16,  5.28it/s]\titers: 400, epoch: 1 | loss: 0.2437604\n",
      "\tspeed: 0.1927s/iter; left time: 5647.5714s\n",
      "499it [01:36,  5.07it/s]\titers: 500, epoch: 1 | loss: 0.2174005\n",
      "\tspeed: 0.1912s/iter; left time: 5583.6500s\n",
      "599it [01:55,  4.68it/s]\titers: 600, epoch: 1 | loss: 0.3037770\n",
      "\tspeed: 0.1884s/iter; left time: 5482.2524s\n",
      "699it [02:14,  5.13it/s]\titers: 700, epoch: 1 | loss: 0.2740186\n",
      "\tspeed: 0.1890s/iter; left time: 5481.8478s\n",
      "799it [02:33,  5.25it/s]\titers: 800, epoch: 1 | loss: 0.1501022\n",
      "\tspeed: 0.1921s/iter; left time: 5552.8955s\n",
      "899it [02:52,  5.11it/s]\titers: 900, epoch: 1 | loss: 0.3384548\n",
      "\tspeed: 0.1935s/iter; left time: 5575.0364s\n",
      "999it [03:11,  5.07it/s]\titers: 1000, epoch: 1 | loss: 0.3915646\n",
      "\tspeed: 0.1915s/iter; left time: 5497.1495s\n",
      "1099it [03:31,  5.06it/s]\titers: 1100, epoch: 1 | loss: 0.1148399\n",
      "\tspeed: 0.1912s/iter; left time: 5468.4224s\n",
      "1199it [03:49,  5.09it/s]\titers: 1200, epoch: 1 | loss: 0.1493269\n",
      "\tspeed: 0.1917s/iter; left time: 5465.1119s\n",
      "1299it [04:09,  5.26it/s]\titers: 1300, epoch: 1 | loss: 0.2562720\n",
      "\tspeed: 0.1929s/iter; left time: 5479.4661s\n",
      "1399it [04:29,  5.29it/s]\titers: 1400, epoch: 1 | loss: 0.2583771\n",
      "\tspeed: 0.1965s/iter; left time: 5561.8158s\n",
      "1499it [04:48,  5.23it/s]\titers: 1500, epoch: 1 | loss: 0.2163442\n",
      "\tspeed: 0.1954s/iter; left time: 5512.6020s\n",
      "1599it [05:08,  5.31it/s]\titers: 1600, epoch: 1 | loss: 0.4652200\n",
      "\tspeed: 0.1982s/iter; left time: 5570.6800s\n",
      "1699it [05:27,  5.33it/s]\titers: 1700, epoch: 1 | loss: 0.1824312\n",
      "\tspeed: 0.1944s/iter; left time: 5443.0278s\n",
      "1799it [05:47,  5.35it/s]\titers: 1800, epoch: 1 | loss: 0.2093977\n",
      "\tspeed: 0.1934s/iter; left time: 5395.9550s\n",
      "1899it [06:06,  5.27it/s]\titers: 1900, epoch: 1 | loss: 0.3562241\n",
      "\tspeed: 0.1950s/iter; left time: 5422.8866s\n",
      "1918it [06:09,  5.26it/s]^C\n",
      "[2024-05-05 20:43:09,787] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2024-05-05 20:43:09,788] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 11062 closing signal SIGINT\n",
      "[2024-05-05 20:43:09,789] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 11063 closing signal SIGINT\n",
      "1918it [06:10,  5.18it/s]\n",
      "1918it [06:10,  5.18it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 237, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 237, in <module>\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    accelerator.backward(loss)\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Total time: 7.363555800914765 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --multi_gpu --mixed_precision bf16 --num_processes=2 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.16s/it]\n",
      "d_llm 4096\n",
      "[2024-05-05 22:20:32,512] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-05 22:20:33,346] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-05 22:20:33,346] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-05 22:20:33,346] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-05 22:20:34,324] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-05 22:20:34,324] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-05 22:20:46,913] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-05 22:20:46,915] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-05 22:20:46,915] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-05 22:20:46,916] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-05 22:20:46,916] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-05 22:20:46,916] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-05 22:20:46,917] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-05 22:20:46,917] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-05 22:20:46,917] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-05 22:20:46,917] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-05 22:20:47,483] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-05 22:20:47,484] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-05 22:20:47,484] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 198.7 GB, percent = 26.3%\n",
      "[2024-05-05 22:20:47,596] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-05 22:20:47,597] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 22:20:47,597] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 198.7 GB, percent = 26.3%\n",
      "[2024-05-05 22:20:47,597] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-05 22:20:47,705] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-05 22:20:47,706] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-05 22:20:47,706] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 198.7 GB, percent = 26.3%\n",
      "[2024-05-05 22:20:47,706] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-05 22:20:47,706] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-05 22:20:47,706] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-05 22:20:47,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-05 22:20:47,707] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-05 22:20:47,707] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb2d8f31ed0>\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-05 22:20:47,708] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   train_batch_size ............. 3\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-05 22:20:47,709] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 3, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:09, 11.17it/s]\titers: 100, epoch: 1 | loss: 0.1703860\n",
      "\tspeed: 0.2569s/iter; left time: 7606.9150s\n",
      "198it [00:18, 12.24it/s]\titers: 200, epoch: 1 | loss: 0.0680731\n",
      "\tspeed: 0.0910s/iter; left time: 2683.9438s\n",
      "298it [00:27, 11.08it/s]\titers: 300, epoch: 1 | loss: 0.0956602\n",
      "\tspeed: 0.0890s/iter; left time: 2616.8633s\n",
      "398it [00:36, 11.40it/s]\titers: 400, epoch: 1 | loss: 0.0291667\n",
      "\tspeed: 0.0895s/iter; left time: 2624.1811s\n",
      "498it [00:45, 11.04it/s]\titers: 500, epoch: 1 | loss: 0.2579892\n",
      "\tspeed: 0.0891s/iter; left time: 2603.5760s\n",
      "598it [00:54, 11.75it/s]\titers: 600, epoch: 1 | loss: 0.1895175\n",
      "\tspeed: 0.0912s/iter; left time: 2654.8592s\n",
      "698it [01:04, 11.07it/s]\titers: 700, epoch: 1 | loss: 0.0645779\n",
      "\tspeed: 0.0953s/iter; left time: 2763.8526s\n",
      "798it [01:13, 11.91it/s]\titers: 800, epoch: 1 | loss: 0.0450226\n",
      "\tspeed: 0.0886s/iter; left time: 2560.8171s\n",
      "898it [01:22, 11.23it/s]\titers: 900, epoch: 1 | loss: 0.0278185\n",
      "\tspeed: 0.0905s/iter; left time: 2608.0891s\n",
      "998it [01:31, 11.94it/s]\titers: 1000, epoch: 1 | loss: 0.1686552\n",
      "\tspeed: 0.0887s/iter; left time: 2547.4361s\n",
      "1098it [01:40, 11.22it/s]\titers: 1100, epoch: 1 | loss: 0.0429421\n",
      "\tspeed: 0.0909s/iter; left time: 2600.5649s\n",
      "1198it [01:49, 11.91it/s]\titers: 1200, epoch: 1 | loss: 0.4358104\n",
      "\tspeed: 0.0887s/iter; left time: 2528.4570s\n",
      "1298it [01:58, 10.42it/s]\titers: 1300, epoch: 1 | loss: 0.1812191\n",
      "\tspeed: 0.0916s/iter; left time: 2602.2945s\n",
      "1398it [02:07, 11.61it/s]\titers: 1400, epoch: 1 | loss: 0.1387118\n",
      "\tspeed: 0.0895s/iter; left time: 2533.8034s\n",
      "1498it [02:16, 10.90it/s]\titers: 1500, epoch: 1 | loss: 0.0439558\n",
      "\tspeed: 0.0913s/iter; left time: 2575.5035s\n",
      "1598it [02:25, 11.68it/s]\titers: 1600, epoch: 1 | loss: 0.0753992\n",
      "\tspeed: 0.0914s/iter; left time: 2569.6068s\n",
      "1698it [02:34, 11.10it/s]\titers: 1700, epoch: 1 | loss: 0.0950600\n",
      "\tspeed: 0.0899s/iter; left time: 2516.3979s\n",
      "1798it [02:43, 11.70it/s]\titers: 1800, epoch: 1 | loss: 0.2062502\n",
      "\tspeed: 0.0898s/iter; left time: 2507.0507s\n",
      "1898it [02:52, 10.90it/s]\titers: 1900, epoch: 1 | loss: 0.0590712\n",
      "\tspeed: 0.0905s/iter; left time: 2516.1777s\n",
      "1998it [03:01, 11.99it/s]\titers: 2000, epoch: 1 | loss: 0.2238774\n",
      "\tspeed: 0.0912s/iter; left time: 2525.8198s\n",
      "2098it [03:10, 10.96it/s]\titers: 2100, epoch: 1 | loss: 0.0549697\n",
      "\tspeed: 0.0899s/iter; left time: 2480.8245s\n",
      "2198it [03:19, 11.07it/s]\titers: 2200, epoch: 1 | loss: 0.0918931\n",
      "\tspeed: 0.0909s/iter; left time: 2499.8473s\n",
      "2298it [03:28, 11.05it/s]\titers: 2300, epoch: 1 | loss: 0.0662607\n",
      "\tspeed: 0.0902s/iter; left time: 2472.6325s\n",
      "2398it [03:37, 11.60it/s]\titers: 2400, epoch: 1 | loss: 0.0748228\n",
      "\tspeed: 0.0906s/iter; left time: 2473.0321s\n",
      "2498it [03:47, 10.87it/s]\titers: 2500, epoch: 1 | loss: 0.1968698\n",
      "\tspeed: 0.0926s/iter; left time: 2519.6743s\n",
      "2598it [03:56, 11.72it/s]\titers: 2600, epoch: 1 | loss: 0.0919301\n",
      "\tspeed: 0.0901s/iter; left time: 2443.0692s\n",
      "2698it [04:05, 11.05it/s]\titers: 2700, epoch: 1 | loss: 0.1064090\n",
      "\tspeed: 0.0915s/iter; left time: 2470.3327s\n",
      "2798it [04:14, 11.71it/s]\titers: 2800, epoch: 1 | loss: 0.0575783\n",
      "\tspeed: 0.0897s/iter; left time: 2413.4718s\n",
      "2898it [04:23, 10.91it/s]\titers: 2900, epoch: 1 | loss: 0.0486975\n",
      "\tspeed: 0.0916s/iter; left time: 2455.2270s\n",
      "2998it [04:32, 11.49it/s]\titers: 3000, epoch: 1 | loss: 0.0493898\n",
      "\tspeed: 0.0903s/iter; left time: 2410.6420s\n",
      "3098it [04:41, 10.10it/s]\titers: 3100, epoch: 1 | loss: 0.1339038\n",
      "\tspeed: 0.0919s/iter; left time: 2445.2367s\n",
      "3198it [04:50, 11.82it/s]\titers: 3200, epoch: 1 | loss: 0.1657118\n",
      "\tspeed: 0.0900s/iter; left time: 2384.8319s\n",
      "3298it [04:59, 11.05it/s]\titers: 3300, epoch: 1 | loss: 0.0409744\n",
      "\tspeed: 0.0901s/iter; left time: 2378.1307s\n",
      "3398it [05:08, 11.73it/s]\titers: 3400, epoch: 1 | loss: 0.0560182\n",
      "\tspeed: 0.0902s/iter; left time: 2372.7981s\n",
      "3498it [05:17, 10.69it/s]\titers: 3500, epoch: 1 | loss: 0.1516048\n",
      "\tspeed: 0.0911s/iter; left time: 2387.2793s\n",
      "3598it [05:26, 11.75it/s]\titers: 3600, epoch: 1 | loss: 0.0323526\n",
      "\tspeed: 0.0909s/iter; left time: 2373.7842s\n",
      "3698it [05:35, 10.87it/s]\titers: 3700, epoch: 1 | loss: 0.0522081\n",
      "\tspeed: 0.0910s/iter; left time: 2367.0351s\n",
      "3798it [05:45, 11.88it/s]\titers: 3800, epoch: 1 | loss: 0.0610515\n",
      "\tspeed: 0.0914s/iter; left time: 2366.7096s\n",
      "3898it [05:54, 10.87it/s]\titers: 3900, epoch: 1 | loss: 0.0428516\n",
      "\tspeed: 0.0906s/iter; left time: 2337.1280s\n",
      "3998it [06:03, 11.87it/s]\titers: 4000, epoch: 1 | loss: 0.1540412\n",
      "\tspeed: 0.0907s/iter; left time: 2332.1474s\n",
      "4098it [06:12, 10.93it/s]\titers: 4100, epoch: 1 | loss: 0.1016509\n",
      "\tspeed: 0.0900s/iter; left time: 2303.5672s\n",
      "4198it [06:21, 11.35it/s]\titers: 4200, epoch: 1 | loss: 0.0691137\n",
      "\tspeed: 0.0903s/iter; left time: 2304.3962s\n",
      "4298it [06:30, 10.99it/s]\titers: 4300, epoch: 1 | loss: 0.0563752\n",
      "\tspeed: 0.0897s/iter; left time: 2280.1119s\n",
      "4398it [06:39, 11.31it/s]\titers: 4400, epoch: 1 | loss: 0.1381996\n",
      "\tspeed: 0.0901s/iter; left time: 2279.9780s\n",
      "4498it [06:48, 10.98it/s]\titers: 4500, epoch: 1 | loss: 0.0333126\n",
      "\tspeed: 0.0902s/iter; left time: 2273.8249s\n",
      "4598it [06:57, 11.69it/s]\titers: 4600, epoch: 1 | loss: 0.0885903\n",
      "\tspeed: 0.0901s/iter; left time: 2261.0519s\n",
      "4698it [07:06, 11.02it/s]\titers: 4700, epoch: 1 | loss: 0.0843723\n",
      "\tspeed: 0.0917s/iter; left time: 2294.0112s\n",
      "4798it [07:15, 11.80it/s]\titers: 4800, epoch: 1 | loss: 0.2948415\n",
      "\tspeed: 0.0895s/iter; left time: 2229.9666s\n",
      "4898it [07:24, 10.91it/s]\titers: 4900, epoch: 1 | loss: 0.1595931\n",
      "\tspeed: 0.0926s/iter; left time: 2297.3079s\n",
      "4998it [07:33, 11.46it/s]\titers: 5000, epoch: 1 | loss: 0.2070010\n",
      "\tspeed: 0.0911s/iter; left time: 2251.3390s\n",
      "5098it [07:42, 11.04it/s]\titers: 5100, epoch: 1 | loss: 0.1173670\n",
      "\tspeed: 0.0914s/iter; left time: 2248.8059s\n",
      "5198it [07:51, 11.78it/s]\titers: 5200, epoch: 1 | loss: 0.1215703\n",
      "\tspeed: 0.0893s/iter; left time: 2187.8437s\n",
      "5298it [08:00, 10.93it/s]\titers: 5300, epoch: 1 | loss: 0.1351731\n",
      "\tspeed: 0.0911s/iter; left time: 2223.9136s\n",
      "5398it [08:09, 11.87it/s]\titers: 5400, epoch: 1 | loss: 0.0660883\n",
      "\tspeed: 0.0893s/iter; left time: 2169.8238s\n",
      "5498it [08:18, 11.06it/s]\titers: 5500, epoch: 1 | loss: 0.0408881\n",
      "\tspeed: 0.0911s/iter; left time: 2205.0355s\n",
      "5598it [08:27, 11.89it/s]\titers: 5600, epoch: 1 | loss: 0.0458027\n",
      "\tspeed: 0.0895s/iter; left time: 2157.3432s\n",
      "5698it [08:36, 10.93it/s]\titers: 5700, epoch: 1 | loss: 0.0843788\n",
      "\tspeed: 0.0910s/iter; left time: 2184.4296s\n",
      "5798it [08:45, 11.78it/s]\titers: 5800, epoch: 1 | loss: 0.0831848\n",
      "\tspeed: 0.0894s/iter; left time: 2136.3342s\n",
      "5898it [08:54, 10.88it/s]\titers: 5900, epoch: 1 | loss: 0.1219983\n",
      "\tspeed: 0.0907s/iter; left time: 2159.7353s\n",
      "5998it [09:03, 11.87it/s]\titers: 6000, epoch: 1 | loss: 0.1045603\n",
      "\tspeed: 0.0893s/iter; left time: 2117.1669s\n",
      "6098it [09:13, 10.59it/s]\titers: 6100, epoch: 1 | loss: 0.2529277\n",
      "\tspeed: 0.0915s/iter; left time: 2160.5646s\n",
      "6198it [09:21, 11.95it/s]\titers: 6200, epoch: 1 | loss: 0.1778631\n",
      "\tspeed: 0.0891s/iter; left time: 2095.1734s\n",
      "6298it [09:30, 11.09it/s]\titers: 6300, epoch: 1 | loss: 0.0589889\n",
      "\tspeed: 0.0901s/iter; left time: 2108.9164s\n",
      "6398it [09:39, 11.86it/s]\titers: 6400, epoch: 1 | loss: 0.0679489\n",
      "\tspeed: 0.0896s/iter; left time: 2087.3509s\n",
      "6498it [09:49, 10.95it/s]\titers: 6500, epoch: 1 | loss: 0.0299342\n",
      "\tspeed: 0.0907s/iter; left time: 2105.6337s\n",
      "6598it [09:58, 11.77it/s]\titers: 6600, epoch: 1 | loss: 0.0278910\n",
      "\tspeed: 0.0904s/iter; left time: 2088.0532s\n",
      "6698it [10:07, 10.76it/s]\titers: 6700, epoch: 1 | loss: 0.0930693\n",
      "\tspeed: 0.0909s/iter; left time: 2092.3434s\n",
      "6798it [10:16, 11.94it/s]\titers: 6800, epoch: 1 | loss: 0.0620420\n",
      "\tspeed: 0.0911s/iter; left time: 2087.0964s\n",
      "6898it [10:25, 10.92it/s]\titers: 6900, epoch: 1 | loss: 0.0981741\n",
      "\tspeed: 0.0899s/iter; left time: 2050.6495s\n",
      "6998it [10:34, 11.81it/s]\titers: 7000, epoch: 1 | loss: 0.1219157\n",
      "\tspeed: 0.0899s/iter; left time: 2040.8754s\n",
      "7098it [10:43, 10.81it/s]\titers: 7100, epoch: 1 | loss: 0.0502727\n",
      "\tspeed: 0.0914s/iter; left time: 2065.0625s\n",
      "7198it [10:52, 11.63it/s]\titers: 7200, epoch: 1 | loss: 0.0917590\n",
      "\tspeed: 0.0905s/iter; left time: 2037.5538s\n",
      "7298it [11:01, 11.01it/s]\titers: 7300, epoch: 1 | loss: 0.1126586\n",
      "\tspeed: 0.0954s/iter; left time: 2137.1032s\n",
      "7398it [11:10, 11.87it/s]\titers: 7400, epoch: 1 | loss: 0.0193352\n",
      "\tspeed: 0.0896s/iter; left time: 1999.0463s\n",
      "7498it [11:20, 10.94it/s]\titers: 7500, epoch: 1 | loss: 0.2036739\n",
      "\tspeed: 0.0932s/iter; left time: 2070.0636s\n",
      "7598it [11:29, 11.91it/s]\titers: 7600, epoch: 1 | loss: 0.3415259\n",
      "\tspeed: 0.0892s/iter; left time: 1971.3150s\n",
      "7698it [11:38, 10.96it/s]\titers: 7700, epoch: 1 | loss: 0.0628124\n",
      "\tspeed: 0.0915s/iter; left time: 2013.3428s\n",
      "7798it [11:47, 11.80it/s]\titers: 7800, epoch: 1 | loss: 0.0506679\n",
      "\tspeed: 0.0891s/iter; left time: 1950.9569s\n",
      "7898it [11:56, 11.10it/s]\titers: 7900, epoch: 1 | loss: 0.0347831\n",
      "\tspeed: 0.0906s/iter; left time: 1976.0540s\n",
      "7998it [12:05, 11.94it/s]\titers: 8000, epoch: 1 | loss: 0.0718083\n",
      "\tspeed: 0.0894s/iter; left time: 1940.7050s\n",
      "8098it [12:14, 11.02it/s]\titers: 8100, epoch: 1 | loss: 0.0845160\n",
      "\tspeed: 0.0919s/iter; left time: 1986.2582s\n",
      "8198it [12:23, 11.91it/s]\titers: 8200, epoch: 1 | loss: 0.0833920\n",
      "\tspeed: 0.0891s/iter; left time: 1915.6278s\n",
      "8298it [12:32, 11.00it/s]\titers: 8300, epoch: 1 | loss: 0.0533806\n",
      "\tspeed: 0.0918s/iter; left time: 1966.0691s\n",
      "8398it [12:41, 11.70it/s]\titers: 8400, epoch: 1 | loss: 0.0562423\n",
      "\tspeed: 0.0895s/iter; left time: 1906.2742s\n",
      "8499it [12:50,  7.91it/s]\titers: 8500, epoch: 1 | loss: 0.0723086\n",
      "\tspeed: 0.0952s/iter; left time: 2019.2277s\n",
      "8598it [12:59, 11.85it/s]\titers: 8600, epoch: 1 | loss: 0.1609857\n",
      "\tspeed: 0.0898s/iter; left time: 1895.6444s\n",
      "8698it [13:09, 11.05it/s]\titers: 8700, epoch: 1 | loss: 0.0140619\n",
      "\tspeed: 0.0906s/iter; left time: 1902.9888s\n",
      "8798it [13:18, 10.12it/s]\titers: 8800, epoch: 1 | loss: 0.1065282\n",
      "\tspeed: 0.0928s/iter; left time: 1939.4170s\n",
      "8898it [13:27, 10.92it/s]\titers: 8900, epoch: 1 | loss: 0.0663962\n",
      "\tspeed: 0.0904s/iter; left time: 1880.4930s\n",
      "8998it [13:36, 11.79it/s]\titers: 9000, epoch: 1 | loss: 0.0925952\n",
      "\tspeed: 0.0896s/iter; left time: 1854.5915s\n",
      "9098it [13:45, 10.93it/s]\titers: 9100, epoch: 1 | loss: 0.0770058\n",
      "\tspeed: 0.0904s/iter; left time: 1862.4273s\n",
      "9198it [13:54, 12.00it/s]\titers: 9200, epoch: 1 | loss: 0.0914885\n",
      "\tspeed: 0.0901s/iter; left time: 1847.5068s\n",
      "9298it [14:03, 10.96it/s]\titers: 9300, epoch: 1 | loss: 0.0372436\n",
      "\tspeed: 0.0903s/iter; left time: 1842.2504s\n",
      "9398it [14:12, 12.05it/s]\titers: 9400, epoch: 1 | loss: 0.0846212\n",
      "\tspeed: 0.0893s/iter; left time: 1813.7789s\n",
      "9498it [14:21, 10.95it/s]\titers: 9500, epoch: 1 | loss: 0.2169215\n",
      "\tspeed: 0.0901s/iter; left time: 1821.2156s\n",
      "9598it [14:30, 11.99it/s]\titers: 9600, epoch: 1 | loss: 0.0887768\n",
      "\tspeed: 0.0904s/iter; left time: 1818.1605s\n",
      "9698it [14:39, 10.79it/s]\titers: 9700, epoch: 1 | loss: 0.2275443\n",
      "\tspeed: 0.0910s/iter; left time: 1819.8672s\n",
      "9799it [14:48, 11.32it/s]\titers: 9800, epoch: 1 | loss: 0.0818637\n",
      "\tspeed: 0.0928s/iter; left time: 1847.8030s\n",
      "9899it [14:58, 10.73it/s]\titers: 9900, epoch: 1 | loss: 0.0999508\n",
      "\tspeed: 0.0922s/iter; left time: 1825.3483s\n",
      "9999it [15:07, 11.77it/s]\titers: 10000, epoch: 1 | loss: 0.1120867\n",
      "\tspeed: 0.0905s/iter; left time: 1782.9823s\n",
      "10099it [15:16, 10.88it/s]\titers: 10100, epoch: 1 | loss: 0.0177383\n",
      "\tspeed: 0.0922s/iter; left time: 1807.7088s\n",
      "10199it [15:25, 11.89it/s]\titers: 10200, epoch: 1 | loss: 0.0939340\n",
      "\tspeed: 0.0894s/iter; left time: 1743.1232s\n",
      "10299it [15:34, 10.88it/s]\titers: 10300, epoch: 1 | loss: 0.0912841\n",
      "\tspeed: 0.0914s/iter; left time: 1774.0309s\n",
      "10399it [15:43, 11.72it/s]\titers: 10400, epoch: 1 | loss: 0.2030257\n",
      "\tspeed: 0.0906s/iter; left time: 1749.5777s\n",
      "10499it [15:52, 11.01it/s]\titers: 10500, epoch: 1 | loss: 0.0227849\n",
      "\tspeed: 0.0928s/iter; left time: 1782.9727s\n",
      "10599it [16:01, 11.90it/s]\titers: 10600, epoch: 1 | loss: 0.1721632\n",
      "\tspeed: 0.0898s/iter; left time: 1715.6762s\n",
      "10699it [16:10, 10.92it/s]\titers: 10700, epoch: 1 | loss: 0.1846100\n",
      "\tspeed: 0.0917s/iter; left time: 1742.2826s\n",
      "10799it [16:19, 11.77it/s]\titers: 10800, epoch: 1 | loss: 0.0554893\n",
      "\tspeed: 0.0899s/iter; left time: 1699.4379s\n",
      "10899it [16:29, 10.31it/s]\titers: 10900, epoch: 1 | loss: 0.0375981\n",
      "\tspeed: 0.0915s/iter; left time: 1721.1421s\n",
      "10999it [16:38, 11.77it/s]\titers: 11000, epoch: 1 | loss: 0.0300118\n",
      "\tspeed: 0.0904s/iter; left time: 1691.6533s\n",
      "11099it [16:47, 10.85it/s]\titers: 11100, epoch: 1 | loss: 0.0672714\n",
      "\tspeed: 0.0918s/iter; left time: 1707.1475s\n",
      "11199it [16:56, 11.66it/s]\titers: 11200, epoch: 1 | loss: 0.0251680\n",
      "\tspeed: 0.0909s/iter; left time: 1681.3257s\n",
      "11299it [17:05, 11.01it/s]\titers: 11300, epoch: 1 | loss: 0.0420262\n",
      "\tspeed: 0.0908s/iter; left time: 1671.5474s\n",
      "11398it [17:14, 11.84it/s]\titers: 11400, epoch: 1 | loss: 0.0261161\n",
      "\tspeed: 0.0928s/iter; left time: 1698.3600s\n",
      "11498it [17:23, 10.94it/s]\titers: 11500, epoch: 1 | loss: 0.0198546\n",
      "\tspeed: 0.0908s/iter; left time: 1653.2212s\n",
      "11598it [17:32, 11.71it/s]\titers: 11600, epoch: 1 | loss: 0.0655582\n",
      "\tspeed: 0.0925s/iter; left time: 1675.5365s\n",
      "11698it [17:42, 10.73it/s]\titers: 11700, epoch: 1 | loss: 0.0687323\n",
      "\tspeed: 0.0919s/iter; left time: 1654.4111s\n",
      "11798it [17:51, 11.95it/s]\titers: 11800, epoch: 1 | loss: 0.0391170\n",
      "\tspeed: 0.0935s/iter; left time: 1674.0167s\n",
      "11898it [18:00, 10.96it/s]\titers: 11900, epoch: 1 | loss: 0.1656390\n",
      "\tspeed: 0.0906s/iter; left time: 1613.6053s\n",
      "11998it [18:09, 11.48it/s]\titers: 12000, epoch: 1 | loss: 0.1565248\n",
      "\tspeed: 0.0920s/iter; left time: 1628.9090s\n",
      "12098it [18:18, 10.83it/s]\titers: 12100, epoch: 1 | loss: 0.0226204\n",
      "\tspeed: 0.0911s/iter; left time: 1603.6263s\n",
      "12198it [18:27, 11.22it/s]\titers: 12200, epoch: 1 | loss: 0.1051604\n",
      "\tspeed: 0.0910s/iter; left time: 1593.7092s\n",
      "12298it [18:36, 10.98it/s]\titers: 12300, epoch: 1 | loss: 0.0713475\n",
      "\tspeed: 0.0905s/iter; left time: 1576.0226s\n",
      "12398it [18:46, 11.95it/s]\titers: 12400, epoch: 1 | loss: 0.0466539\n",
      "\tspeed: 0.0905s/iter; left time: 1565.8030s\n",
      "12498it [18:55, 10.90it/s]\titers: 12500, epoch: 1 | loss: 0.0278124\n",
      "\tspeed: 0.0922s/iter; left time: 1585.5667s\n",
      "12598it [19:04, 11.56it/s]\titers: 12600, epoch: 1 | loss: 0.0263337\n",
      "\tspeed: 0.0905s/iter; left time: 1548.0254s\n",
      "12698it [19:13, 10.95it/s]\titers: 12700, epoch: 1 | loss: 0.0220444\n",
      "\tspeed: 0.0918s/iter; left time: 1561.8014s\n",
      "12798it [19:22, 11.49it/s]\titers: 12800, epoch: 1 | loss: 0.0189343\n",
      "\tspeed: 0.0906s/iter; left time: 1531.5986s\n",
      "12899it [19:31, 10.88it/s]\titers: 12900, epoch: 1 | loss: 0.0282356\n",
      "\tspeed: 0.0937s/iter; left time: 1574.9281s\n",
      "12999it [19:41, 11.78it/s]\titers: 13000, epoch: 1 | loss: 0.0898804\n",
      "\tspeed: 0.0905s/iter; left time: 1512.3659s\n",
      "13099it [19:50, 10.87it/s]\titers: 13100, epoch: 1 | loss: 0.0877812\n",
      "\tspeed: 0.0936s/iter; left time: 1554.1678s\n",
      "13199it [19:59, 11.47it/s]\titers: 13200, epoch: 1 | loss: 0.0125270\n",
      "\tspeed: 0.0909s/iter; left time: 1499.6781s\n",
      "13299it [20:08, 10.67it/s]\titers: 13300, epoch: 1 | loss: 0.0417522\n",
      "\tspeed: 0.0915s/iter; left time: 1501.4131s\n",
      "13399it [20:17, 11.75it/s]\titers: 13400, epoch: 1 | loss: 0.0325340\n",
      "\tspeed: 0.0919s/iter; left time: 1499.0888s\n",
      "13499it [20:27, 10.41it/s]\titers: 13500, epoch: 1 | loss: 0.0523608\n",
      "\tspeed: 0.0933s/iter; left time: 1512.2145s\n",
      "13599it [20:36, 11.52it/s]\titers: 13600, epoch: 1 | loss: 0.1246652\n",
      "\tspeed: 0.0928s/iter; left time: 1494.5565s\n",
      "13699it [20:45, 10.73it/s]\titers: 13700, epoch: 1 | loss: 0.0298829\n",
      "\tspeed: 0.0928s/iter; left time: 1485.9432s\n",
      "13799it [20:55, 11.72it/s]\titers: 13800, epoch: 1 | loss: 0.0847763\n",
      "\tspeed: 0.0928s/iter; left time: 1476.0528s\n",
      "13899it [21:04, 10.89it/s]\titers: 13900, epoch: 1 | loss: 0.0992653\n",
      "\tspeed: 0.0918s/iter; left time: 1450.9996s\n",
      "13999it [21:13, 10.69it/s]\titers: 14000, epoch: 1 | loss: 0.0622462\n",
      "\tspeed: 0.0916s/iter; left time: 1438.0479s\n",
      "14099it [21:22, 10.88it/s]\titers: 14100, epoch: 1 | loss: 0.0670922\n",
      "\tspeed: 0.0918s/iter; left time: 1432.3993s\n",
      "14199it [21:31, 11.74it/s]\titers: 14200, epoch: 1 | loss: 0.0193540\n",
      "\tspeed: 0.0900s/iter; left time: 1394.9497s\n",
      "14299it [21:40, 11.03it/s]\titers: 14300, epoch: 1 | loss: 0.0389316\n",
      "\tspeed: 0.0914s/iter; left time: 1407.7229s\n",
      "14399it [21:49, 11.67it/s]\titers: 14400, epoch: 1 | loss: 0.0364892\n",
      "\tspeed: 0.0897s/iter; left time: 1372.3398s\n",
      "14499it [21:58, 10.84it/s]\titers: 14500, epoch: 1 | loss: 0.0732012\n",
      "\tspeed: 0.0920s/iter; left time: 1399.6199s\n",
      "14599it [22:07, 11.33it/s]\titers: 14600, epoch: 1 | loss: 0.0169495\n",
      "\tspeed: 0.0911s/iter; left time: 1376.1225s\n",
      "14699it [22:17, 10.95it/s]\titers: 14700, epoch: 1 | loss: 0.1028436\n",
      "\tspeed: 0.0919s/iter; left time: 1379.2258s\n",
      "14799it [22:26, 11.72it/s]\titers: 14800, epoch: 1 | loss: 0.0297080\n",
      "\tspeed: 0.0901s/iter; left time: 1343.5311s\n",
      "14899it [22:35, 10.48it/s]\titers: 14900, epoch: 1 | loss: 0.0147885\n",
      "\tspeed: 0.0923s/iter; left time: 1366.5460s\n",
      "14999it [22:44, 11.68it/s]\titers: 15000, epoch: 1 | loss: 0.0668879\n",
      "\tspeed: 0.0906s/iter; left time: 1331.8266s\n",
      "15099it [22:53, 10.78it/s]\titers: 15100, epoch: 1 | loss: 0.0404404\n",
      "\tspeed: 0.0918s/iter; left time: 1341.3238s\n",
      "15199it [23:02, 11.43it/s]\titers: 15200, epoch: 1 | loss: 0.0760934\n",
      "\tspeed: 0.0919s/iter; left time: 1332.4695s\n",
      "15299it [23:12, 10.62it/s]\titers: 15300, epoch: 1 | loss: 0.0122800\n",
      "\tspeed: 0.0930s/iter; left time: 1340.2994s\n",
      "15399it [23:21, 11.71it/s]\titers: 15400, epoch: 1 | loss: 0.0551337\n",
      "\tspeed: 0.0917s/iter; left time: 1312.0641s\n",
      "15499it [23:30, 10.93it/s]\titers: 15500, epoch: 1 | loss: 0.0212366\n",
      "\tspeed: 0.0913s/iter; left time: 1297.5537s\n",
      "15599it [23:39, 11.43it/s]\titers: 15600, epoch: 1 | loss: 0.0696104\n",
      "\tspeed: 0.0917s/iter; left time: 1293.6241s\n",
      "15699it [23:48, 10.90it/s]\titers: 15700, epoch: 1 | loss: 0.0217924\n",
      "\tspeed: 0.0908s/iter; left time: 1271.3052s\n",
      "15799it [23:57, 11.37it/s]\titers: 15800, epoch: 1 | loss: 0.0270561\n",
      "\tspeed: 0.0906s/iter; left time: 1259.2274s\n",
      "15899it [24:06, 10.96it/s]\titers: 15900, epoch: 1 | loss: 0.0276782\n",
      "\tspeed: 0.0909s/iter; left time: 1255.5977s\n",
      "15999it [24:15, 11.70it/s]\titers: 16000, epoch: 1 | loss: 0.1069945\n",
      "\tspeed: 0.0901s/iter; left time: 1234.8562s\n",
      "16099it [24:24, 10.96it/s]\titers: 16100, epoch: 1 | loss: 0.0667488\n",
      "\tspeed: 0.0914s/iter; left time: 1243.8839s\n",
      "16199it [24:34, 11.79it/s]\titers: 16200, epoch: 1 | loss: 0.0484028\n",
      "\tspeed: 0.0907s/iter; left time: 1224.6304s\n",
      "16299it [24:43, 10.97it/s]\titers: 16300, epoch: 1 | loss: 0.0629482\n",
      "\tspeed: 0.0910s/iter; left time: 1219.5293s\n",
      "16399it [24:52, 11.79it/s]\titers: 16400, epoch: 1 | loss: 0.0580629\n",
      "\tspeed: 0.0898s/iter; left time: 1195.0135s\n",
      "16499it [25:01, 10.98it/s]\titers: 16500, epoch: 1 | loss: 0.0357557\n",
      "\tspeed: 0.0910s/iter; left time: 1201.7618s\n",
      "16599it [25:10, 11.82it/s]\titers: 16600, epoch: 1 | loss: 0.1286362\n",
      "\tspeed: 0.0900s/iter; left time: 1179.3785s\n",
      "16699it [25:19, 10.82it/s]\titers: 16700, epoch: 1 | loss: 0.0776157\n",
      "\tspeed: 0.0916s/iter; left time: 1191.8307s\n",
      "16799it [25:28, 11.91it/s]\titers: 16800, epoch: 1 | loss: 0.0694128\n",
      "\tspeed: 0.0895s/iter; left time: 1155.1782s\n",
      "16899it [25:37, 10.23it/s]\titers: 16900, epoch: 1 | loss: 0.0305965\n",
      "\tspeed: 0.0916s/iter; left time: 1173.1629s\n",
      "16999it [25:46, 11.76it/s]\titers: 17000, epoch: 1 | loss: 0.0480798\n",
      "\tspeed: 0.0898s/iter; left time: 1140.7999s\n",
      "17099it [25:55, 10.47it/s]\titers: 17100, epoch: 1 | loss: 0.0532652\n",
      "\tspeed: 0.0913s/iter; left time: 1150.4665s\n",
      "17199it [26:04, 11.66it/s]\titers: 17200, epoch: 1 | loss: 0.0156015\n",
      "\tspeed: 0.0909s/iter; left time: 1136.4751s\n",
      "17299it [26:13, 10.88it/s]\titers: 17300, epoch: 1 | loss: 0.0369445\n",
      "\tspeed: 0.0907s/iter; left time: 1125.6323s\n",
      "17399it [26:22, 11.79it/s]\titers: 17400, epoch: 1 | loss: 0.0239610\n",
      "\tspeed: 0.0911s/iter; left time: 1121.4383s\n",
      "17499it [26:32, 10.72it/s]\titers: 17500, epoch: 1 | loss: 0.0609630\n",
      "\tspeed: 0.0918s/iter; left time: 1119.9300s\n",
      "17599it [26:41, 11.69it/s]\titers: 17600, epoch: 1 | loss: 0.0201050\n",
      "\tspeed: 0.0912s/iter; left time: 1103.9619s\n",
      "17699it [26:50, 10.66it/s]\titers: 17700, epoch: 1 | loss: 0.1003336\n",
      "\tspeed: 0.0914s/iter; left time: 1097.4534s\n",
      "17799it [26:59, 11.85it/s]\titers: 17800, epoch: 1 | loss: 0.0158030\n",
      "\tspeed: 0.0914s/iter; left time: 1088.2492s\n",
      "17899it [27:08, 10.93it/s]\titers: 17900, epoch: 1 | loss: 0.0260790\n",
      "\tspeed: 0.0928s/iter; left time: 1095.8824s\n",
      "17999it [27:17, 10.42it/s]\titers: 18000, epoch: 1 | loss: 0.0164845\n",
      "\tspeed: 0.0917s/iter; left time: 1073.4309s\n",
      "18099it [27:27, 10.61it/s]\titers: 18100, epoch: 1 | loss: 0.0599336\n",
      "\tspeed: 0.0914s/iter; left time: 1061.1090s\n",
      "18199it [27:36, 11.80it/s]\titers: 18200, epoch: 1 | loss: 0.0364375\n",
      "\tspeed: 0.0903s/iter; left time: 1038.8860s\n",
      "18299it [27:45, 10.90it/s]\titers: 18300, epoch: 1 | loss: 0.0724566\n",
      "\tspeed: 0.0930s/iter; left time: 1060.3526s\n",
      "18399it [27:54, 11.56it/s]\titers: 18400, epoch: 1 | loss: 0.0211044\n",
      "\tspeed: 0.0911s/iter; left time: 1030.1240s\n",
      "18499it [28:03, 10.87it/s]\titers: 18500, epoch: 1 | loss: 0.0448676\n",
      "\tspeed: 0.0921s/iter; left time: 1032.3943s\n",
      "18599it [28:12, 11.50it/s]\titers: 18600, epoch: 1 | loss: 0.0105246\n",
      "\tspeed: 0.0905s/iter; left time: 1004.9084s\n",
      "18699it [28:22, 10.80it/s]\titers: 18700, epoch: 1 | loss: 0.0142554\n",
      "\tspeed: 0.0928s/iter; left time: 1021.0697s\n",
      "18799it [28:31, 11.67it/s]\titers: 18800, epoch: 1 | loss: 0.1127545\n",
      "\tspeed: 0.0908s/iter; left time: 990.1127s\n",
      "18899it [28:40, 10.94it/s]\titers: 18900, epoch: 1 | loss: 0.0426270\n",
      "\tspeed: 0.0928s/iter; left time: 1002.6359s\n",
      "18999it [28:49, 11.79it/s]\titers: 19000, epoch: 1 | loss: 0.0108679\n",
      "\tspeed: 0.0896s/iter; left time: 959.2908s\n",
      "19099it [28:58, 10.91it/s]\titers: 19100, epoch: 1 | loss: 0.0137422\n",
      "\tspeed: 0.0920s/iter; left time: 976.2003s\n",
      "19199it [29:07, 11.71it/s]\titers: 19200, epoch: 1 | loss: 0.0363794\n",
      "\tspeed: 0.0905s/iter; left time: 950.6570s\n",
      "19299it [29:16, 10.92it/s]\titers: 19300, epoch: 1 | loss: 0.0439289\n",
      "\tspeed: 0.0918s/iter; left time: 955.1480s\n",
      "19399it [29:25, 11.79it/s]\titers: 19400, epoch: 1 | loss: 0.0164775\n",
      "\tspeed: 0.0910s/iter; left time: 937.5106s\n",
      "19499it [29:34, 10.93it/s]\titers: 19500, epoch: 1 | loss: 0.0280467\n",
      "\tspeed: 0.0910s/iter; left time: 928.2697s\n",
      "19599it [29:44, 11.66it/s]\titers: 19600, epoch: 1 | loss: 0.0288554\n",
      "\tspeed: 0.0911s/iter; left time: 920.5687s\n",
      "19699it [29:53, 10.99it/s]\titers: 19700, epoch: 1 | loss: 0.0866710\n",
      "\tspeed: 0.0916s/iter; left time: 916.8497s\n",
      "19799it [30:02, 11.79it/s]\titers: 19800, epoch: 1 | loss: 0.0350940\n",
      "\tspeed: 0.0914s/iter; left time: 905.2877s\n",
      "19899it [30:11, 10.76it/s]\titers: 19900, epoch: 1 | loss: 0.0333497\n",
      "\tspeed: 0.0916s/iter; left time: 897.7807s\n",
      "19999it [30:20, 11.60it/s]\titers: 20000, epoch: 1 | loss: 0.0403726\n",
      "\tspeed: 0.0906s/iter; left time: 879.7918s\n",
      "20099it [30:29, 10.82it/s]\titers: 20100, epoch: 1 | loss: 0.0254595\n",
      "\tspeed: 0.0902s/iter; left time: 866.5226s\n",
      "20199it [30:38, 11.11it/s]\titers: 20200, epoch: 1 | loss: 0.0520014\n",
      "\tspeed: 0.0916s/iter; left time: 870.8222s\n",
      "20299it [30:47, 10.94it/s]\titers: 20300, epoch: 1 | loss: 0.0054018\n",
      "\tspeed: 0.0908s/iter; left time: 853.6010s\n",
      "20399it [30:56, 11.77it/s]\titers: 20400, epoch: 1 | loss: 0.0809065\n",
      "\tspeed: 0.0904s/iter; left time: 841.3747s\n",
      "20499it [31:06, 10.98it/s]\titers: 20500, epoch: 1 | loss: 0.0148373\n",
      "\tspeed: 0.0929s/iter; left time: 855.1333s\n",
      "20599it [31:15, 11.82it/s]\titers: 20600, epoch: 1 | loss: 0.0540450\n",
      "\tspeed: 0.0905s/iter; left time: 824.1992s\n",
      "20699it [31:24, 10.66it/s]\titers: 20700, epoch: 1 | loss: 0.0225168\n",
      "\tspeed: 0.0925s/iter; left time: 832.8973s\n",
      "20799it [31:33, 11.70it/s]\titers: 20800, epoch: 1 | loss: 0.0436015\n",
      "\tspeed: 0.0914s/iter; left time: 813.8682s\n",
      "20899it [31:42, 10.92it/s]\titers: 20900, epoch: 1 | loss: 0.0851459\n",
      "\tspeed: 0.0925s/iter; left time: 814.6946s\n",
      "20999it [31:51, 11.53it/s]\titers: 21000, epoch: 1 | loss: 0.0257197\n",
      "\tspeed: 0.0907s/iter; left time: 789.5244s\n",
      "21099it [32:01, 10.54it/s]\titers: 21100, epoch: 1 | loss: 0.1355439\n",
      "\tspeed: 0.0916s/iter; left time: 788.3418s\n",
      "21199it [32:10, 11.77it/s]\titers: 21200, epoch: 1 | loss: 0.0343101\n",
      "\tspeed: 0.0894s/iter; left time: 760.6080s\n",
      "21299it [32:19, 10.72it/s]\titers: 21300, epoch: 1 | loss: 0.0118762\n",
      "\tspeed: 0.0913s/iter; left time: 767.0499s\n",
      "21399it [32:28, 11.77it/s]\titers: 21400, epoch: 1 | loss: 0.0205319\n",
      "\tspeed: 0.0903s/iter; left time: 750.3406s\n",
      "21499it [32:37, 10.99it/s]\titers: 21500, epoch: 1 | loss: 0.0450413\n",
      "\tspeed: 0.0909s/iter; left time: 746.1154s\n",
      "21599it [32:46, 11.66it/s]\titers: 21600, epoch: 1 | loss: 0.0421311\n",
      "\tspeed: 0.0914s/iter; left time: 740.8133s\n",
      "21699it [32:55, 10.80it/s]\titers: 21700, epoch: 1 | loss: 0.0041169\n",
      "\tspeed: 0.0911s/iter; left time: 729.0933s\n",
      "21799it [33:04, 11.88it/s]\titers: 21800, epoch: 1 | loss: 0.0269637\n",
      "\tspeed: 0.0910s/iter; left time: 719.4944s\n",
      "21899it [33:13, 10.92it/s]\titers: 21900, epoch: 1 | loss: 0.0142691\n",
      "\tspeed: 0.0914s/iter; left time: 713.1533s\n",
      "21999it [33:22, 11.72it/s]\titers: 22000, epoch: 1 | loss: 0.1203735\n",
      "\tspeed: 0.0915s/iter; left time: 705.4615s\n",
      "22099it [33:32, 10.64it/s]\titers: 22100, epoch: 1 | loss: 0.0348718\n",
      "\tspeed: 0.0911s/iter; left time: 692.8551s\n",
      "22199it [33:41,  9.78it/s]\titers: 22200, epoch: 1 | loss: 0.0167618\n",
      "\tspeed: 0.0919s/iter; left time: 690.1113s\n",
      "22299it [33:50, 10.84it/s]\titers: 22300, epoch: 1 | loss: 0.0354162\n",
      "\tspeed: 0.0917s/iter; left time: 679.4448s\n",
      "22399it [33:59, 11.61it/s]\titers: 22400, epoch: 1 | loss: 0.0111159\n",
      "\tspeed: 0.0897s/iter; left time: 655.3390s\n",
      "22499it [34:08, 10.91it/s]\titers: 22500, epoch: 1 | loss: 0.0313969\n",
      "\tspeed: 0.0925s/iter; left time: 666.6507s\n",
      "22599it [34:17, 11.70it/s]\titers: 22600, epoch: 1 | loss: 0.0146072\n",
      "\tspeed: 0.0914s/iter; left time: 649.3027s\n",
      "22699it [34:26, 11.08it/s]\titers: 22700, epoch: 1 | loss: 0.0127113\n",
      "\tspeed: 0.0911s/iter; left time: 638.5477s\n",
      "22799it [34:35, 11.62it/s]\titers: 22800, epoch: 1 | loss: 0.1213412\n",
      "\tspeed: 0.0894s/iter; left time: 617.3976s\n",
      "22899it [34:45, 10.82it/s]\titers: 22900, epoch: 1 | loss: 0.0220599\n",
      "\tspeed: 0.0930s/iter; left time: 633.1674s\n",
      "22999it [34:54, 11.66it/s]\titers: 23000, epoch: 1 | loss: 0.0074190\n",
      "\tspeed: 0.0899s/iter; left time: 603.0683s\n",
      "23099it [35:03, 11.02it/s]\titers: 23100, epoch: 1 | loss: 0.0360984\n",
      "\tspeed: 0.0916s/iter; left time: 605.0246s\n",
      "23199it [35:12, 11.64it/s]\titers: 23200, epoch: 1 | loss: 0.0112264\n",
      "\tspeed: 0.0898s/iter; left time: 584.3045s\n",
      "23299it [35:21, 10.23it/s]\titers: 23300, epoch: 1 | loss: 0.0744329\n",
      "\tspeed: 0.0925s/iter; left time: 592.7709s\n",
      "23399it [35:30, 11.72it/s]\titers: 23400, epoch: 1 | loss: 0.0366240\n",
      "\tspeed: 0.0900s/iter; left time: 567.3474s\n",
      "23499it [35:39, 10.97it/s]\titers: 23500, epoch: 1 | loss: 0.0515958\n",
      "\tspeed: 0.0906s/iter; left time: 562.0410s\n",
      "23599it [35:48, 11.82it/s]\titers: 23600, epoch: 1 | loss: 0.0465159\n",
      "\tspeed: 0.0910s/iter; left time: 555.3988s\n",
      "23699it [35:57, 10.62it/s]\titers: 23700, epoch: 1 | loss: 0.0402328\n",
      "\tspeed: 0.0913s/iter; left time: 548.6417s\n",
      "23799it [36:06, 11.74it/s]\titers: 23800, epoch: 1 | loss: 0.0369159\n",
      "\tspeed: 0.0909s/iter; left time: 537.0643s\n",
      "23899it [36:15, 10.98it/s]\titers: 23900, epoch: 1 | loss: 0.0200767\n",
      "\tspeed: 0.0904s/iter; left time: 525.1074s\n",
      "23999it [36:24, 11.79it/s]\titers: 24000, epoch: 1 | loss: 0.0381466\n",
      "\tspeed: 0.0904s/iter; left time: 515.7482s\n",
      "24099it [36:34, 10.93it/s]\titers: 24100, epoch: 1 | loss: 0.0512282\n",
      "\tspeed: 0.0910s/iter; left time: 510.0550s\n",
      "24199it [36:43, 11.98it/s]\titers: 24200, epoch: 1 | loss: 0.0814370\n",
      "\tspeed: 0.0919s/iter; left time: 505.9243s\n",
      "24299it [36:52, 10.96it/s]\titers: 24300, epoch: 1 | loss: 0.0097495\n",
      "\tspeed: 0.0900s/iter; left time: 486.7235s\n",
      "24399it [37:01, 11.87it/s]\titers: 24400, epoch: 1 | loss: 0.0441244\n",
      "\tspeed: 0.0903s/iter; left time: 479.1201s\n",
      "24499it [37:10, 10.97it/s]\titers: 24500, epoch: 1 | loss: 0.0085216\n",
      "\tspeed: 0.0910s/iter; left time: 473.8951s\n",
      "24599it [37:19, 11.28it/s]\titers: 24600, epoch: 1 | loss: 0.0176268\n",
      "\tspeed: 0.0913s/iter; left time: 465.9509s\n",
      "24699it [37:28, 10.77it/s]\titers: 24700, epoch: 1 | loss: 0.0116877\n",
      "\tspeed: 0.0912s/iter; left time: 456.7539s\n",
      "24799it [37:37, 11.62it/s]\titers: 24800, epoch: 1 | loss: 0.0104377\n",
      "\tspeed: 0.0911s/iter; left time: 447.1690s\n",
      "24899it [37:46, 10.88it/s]\titers: 24900, epoch: 1 | loss: 0.0480599\n",
      "\tspeed: 0.0916s/iter; left time: 440.1987s\n",
      "24999it [37:55, 11.76it/s]\titers: 25000, epoch: 1 | loss: 0.0243946\n",
      "\tspeed: 0.0900s/iter; left time: 423.4317s\n",
      "25099it [38:04, 11.06it/s]\titers: 25100, epoch: 1 | loss: 0.0382263\n",
      "\tspeed: 0.0909s/iter; left time: 418.5622s\n",
      "25199it [38:13, 11.72it/s]\titers: 25200, epoch: 1 | loss: 0.0421665\n",
      "\tspeed: 0.0890s/iter; left time: 401.1129s\n",
      "25299it [38:23, 10.91it/s]\titers: 25300, epoch: 1 | loss: 0.0267531\n",
      "\tspeed: 0.0925s/iter; left time: 407.5510s\n",
      "25399it [38:32, 11.78it/s]\titers: 25400, epoch: 1 | loss: 0.0182530\n",
      "\tspeed: 0.0905s/iter; left time: 389.7618s\n",
      "25499it [38:41, 10.68it/s]\titers: 25500, epoch: 1 | loss: 0.0184978\n",
      "\tspeed: 0.0920s/iter; left time: 386.8966s\n",
      "25599it [38:50, 11.66it/s]\titers: 25600, epoch: 1 | loss: 0.0264232\n",
      "\tspeed: 0.0913s/iter; left time: 375.0159s\n",
      "25699it [38:59, 10.30it/s]\titers: 25700, epoch: 1 | loss: 0.0100810\n",
      "\tspeed: 0.0919s/iter; left time: 368.0580s\n",
      "25799it [39:08, 11.56it/s]\titers: 25800, epoch: 1 | loss: 0.0156504\n",
      "\tspeed: 0.0917s/iter; left time: 358.1404s\n",
      "25899it [39:18, 10.93it/s]\titers: 25900, epoch: 1 | loss: 0.0230698\n",
      "\tspeed: 0.0914s/iter; left time: 347.8570s\n",
      "25999it [39:27, 11.50it/s]\titers: 26000, epoch: 1 | loss: 0.0229373\n",
      "\tspeed: 0.0910s/iter; left time: 337.0984s\n",
      "26099it [39:36, 10.56it/s]\titers: 26100, epoch: 1 | loss: 0.0413035\n",
      "\tspeed: 0.0921s/iter; left time: 332.2712s\n",
      "26198it [39:45, 11.85it/s]\titers: 26200, epoch: 1 | loss: 0.0413880\n",
      "\tspeed: 0.0932s/iter; left time: 326.8963s\n",
      "26298it [39:54, 10.88it/s]\titers: 26300, epoch: 1 | loss: 0.0317826\n",
      "\tspeed: 0.0913s/iter; left time: 311.0920s\n",
      "26398it [40:04, 11.81it/s]\titers: 26400, epoch: 1 | loss: 0.0266156\n",
      "\tspeed: 0.0930s/iter; left time: 307.4458s\n",
      "26498it [40:13, 10.74it/s]\titers: 26500, epoch: 1 | loss: 0.0738417\n",
      "\tspeed: 0.0919s/iter; left time: 294.6478s\n",
      "26598it [40:22, 10.69it/s]\titers: 26600, epoch: 1 | loss: 0.0326991\n",
      "\tspeed: 0.0915s/iter; left time: 284.2022s\n",
      "26698it [40:31, 11.00it/s]\titers: 26700, epoch: 1 | loss: 0.0321631\n",
      "\tspeed: 0.0912s/iter; left time: 274.1718s\n",
      "26798it [40:40, 11.87it/s]\titers: 26800, epoch: 1 | loss: 0.1023195\n",
      "\tspeed: 0.0895s/iter; left time: 260.0838s\n",
      "26898it [40:49, 10.93it/s]\titers: 26900, epoch: 1 | loss: 0.0220453\n",
      "\tspeed: 0.0921s/iter; left time: 258.5686s\n",
      "26998it [40:58, 11.65it/s]\titers: 27000, epoch: 1 | loss: 0.0220971\n",
      "\tspeed: 0.0907s/iter; left time: 245.4821s\n",
      "27098it [41:07, 10.94it/s]\titers: 27100, epoch: 1 | loss: 0.0394894\n",
      "\tspeed: 0.0917s/iter; left time: 238.9638s\n",
      "27198it [41:16, 11.83it/s]\titers: 27200, epoch: 1 | loss: 0.0534703\n",
      "\tspeed: 0.0900s/iter; left time: 225.4952s\n",
      "27298it [41:26, 10.61it/s]\titers: 27300, epoch: 1 | loss: 0.0410339\n",
      "\tspeed: 0.0928s/iter; left time: 223.2144s\n",
      "27398it [41:35, 11.63it/s]\titers: 27400, epoch: 1 | loss: 0.0118250\n",
      "\tspeed: 0.0902s/iter; left time: 208.0610s\n",
      "27498it [41:44, 10.78it/s]\titers: 27500, epoch: 1 | loss: 0.0383414\n",
      "\tspeed: 0.0919s/iter; left time: 202.7238s\n",
      "27598it [41:53, 11.68it/s]\titers: 27600, epoch: 1 | loss: 0.0729805\n",
      "\tspeed: 0.0906s/iter; left time: 190.7496s\n",
      "27698it [42:02, 10.83it/s]\titers: 27700, epoch: 1 | loss: 0.0338108\n",
      "\tspeed: 0.0914s/iter; left time: 183.4377s\n",
      "27798it [42:11, 11.44it/s]\titers: 27800, epoch: 1 | loss: 0.0093487\n",
      "\tspeed: 0.0915s/iter; left time: 174.4615s\n",
      "27898it [42:20, 11.03it/s]\titers: 27900, epoch: 1 | loss: 0.0105861\n",
      "\tspeed: 0.0903s/iter; left time: 163.0689s\n",
      "27998it [42:29, 11.69it/s]\titers: 28000, epoch: 1 | loss: 0.0095212\n",
      "\tspeed: 0.0897s/iter; left time: 152.9458s\n",
      "28098it [42:38, 10.97it/s]\titers: 28100, epoch: 1 | loss: 0.0744045\n",
      "\tspeed: 0.0914s/iter; left time: 146.7398s\n",
      "28198it [42:47, 11.72it/s]\titers: 28200, epoch: 1 | loss: 0.0387555\n",
      "\tspeed: 0.0912s/iter; left time: 137.3865s\n",
      "28298it [42:57, 10.89it/s]\titers: 28300, epoch: 1 | loss: 0.0408095\n",
      "\tspeed: 0.0912s/iter; left time: 128.2056s\n",
      "28398it [43:06, 11.57it/s]\titers: 28400, epoch: 1 | loss: 0.0402574\n",
      "\tspeed: 0.0912s/iter; left time: 119.1523s\n",
      "28498it [43:15, 11.01it/s]\titers: 28500, epoch: 1 | loss: 0.0473827\n",
      "\tspeed: 0.0915s/iter; left time: 110.3046s\n",
      "28598it [43:24, 10.89it/s]\titers: 28600, epoch: 1 | loss: 0.0918470\n",
      "\tspeed: 0.0917s/iter; left time: 101.4723s\n",
      "28698it [43:33, 10.86it/s]\titers: 28700, epoch: 1 | loss: 0.0167491\n",
      "\tspeed: 0.0913s/iter; left time: 91.8439s\n",
      "28798it [43:42, 11.71it/s]\titers: 28800, epoch: 1 | loss: 0.0104708\n",
      "\tspeed: 0.0906s/iter; left time: 82.0692s\n",
      "28898it [43:51, 10.86it/s]\titers: 28900, epoch: 1 | loss: 0.0370964\n",
      "\tspeed: 0.0927s/iter; left time: 74.6846s\n",
      "28998it [44:01, 11.81it/s]\titers: 29000, epoch: 1 | loss: 0.0063149\n",
      "\tspeed: 0.0904s/iter; left time: 63.7999s\n",
      "29098it [44:10, 10.72it/s]\titers: 29100, epoch: 1 | loss: 0.0520401\n",
      "\tspeed: 0.0925s/iter; left time: 56.0469s\n",
      "29198it [44:19, 11.80it/s]\titers: 29200, epoch: 1 | loss: 0.0232004\n",
      "\tspeed: 0.0901s/iter; left time: 45.5942s\n",
      "29298it [44:28, 10.93it/s]\titers: 29300, epoch: 1 | loss: 0.0376858\n",
      "\tspeed: 0.0916s/iter; left time: 37.1944s\n",
      "29398it [44:37, 11.65it/s]\titers: 29400, epoch: 1 | loss: 0.0204563\n",
      "\tspeed: 0.0912s/iter; left time: 27.9050s\n",
      "29498it [44:46, 11.03it/s]\titers: 29500, epoch: 1 | loss: 0.0184098\n",
      "\tspeed: 0.0924s/iter; left time: 19.0270s\n",
      "29598it [44:55, 11.81it/s]\titers: 29600, epoch: 1 | loss: 0.0506629\n",
      "\tspeed: 0.0905s/iter; left time: 9.5942s\n",
      "29698it [45:05, 10.68it/s]\titers: 29700, epoch: 1 | loss: 0.0362011\n",
      "\tspeed: 0.0921s/iter; left time: 0.5528s\n",
      "29705it [45:05, 10.98it/s]\n",
      "Epoch: 1 cost time: 2705.85785984993\n",
      "6481it [08:35, 12.58it/s]\n",
      "6457it [08:35, 12.53it/s]\n",
      "Epoch: 1 | Train Loss: 0.0641343 Vali Loss: 0.3622034 Test Loss: 0.4503529 MAE Loss: 0.4459062\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 65.15003038644791 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA 7b with Gradient accumulation with Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:07<00:00,  3.59s/it]\n",
      "d_llm 4096\n",
      "[2024-05-06 01:38:09,462] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 01:38:10,171] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 01:38:10,172] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 01:38:10,172] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 01:38:11,083] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-06 01:38:11,083] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 01:38:23,873] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 01:38:23,875] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 01:38:23,875] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 01:38:23,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 01:38:23,876] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 01:38:23,876] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 01:38:23,877] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 01:38:23,877] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 01:38:23,877] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 01:38:23,877] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 01:38:24,503] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 01:38:24,503] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-06 01:38:24,504] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 234.82 GB, percent = 31.1%\n",
      "[2024-05-06 01:38:24,620] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 01:38:24,621] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-06 01:38:24,621] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 234.77 GB, percent = 31.1%\n",
      "[2024-05-06 01:38:24,621] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 01:38:24,729] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 01:38:24,730] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-06 01:38:24,730] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 234.77 GB, percent = 31.1%\n",
      "[2024-05-06 01:38:24,730] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 01:38:24,731] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 01:38:24,731] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 01:38:24,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 01:38:24,731] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9180ed8810>\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 8\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 01:38:24,732] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 01:38:24,733] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 8, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:17,  5.21it/s]\titers: 100, epoch: 1 | loss: 1.2656367\n",
      "\tspeed: 0.3328s/iter; left time: 197702.0453s\n",
      "199it [00:33,  6.18it/s]\titers: 200, epoch: 1 | loss: 0.5786861\n",
      "\tspeed: 0.1604s/iter; left time: 95280.6588s\n",
      "299it [00:49,  6.25it/s]\titers: 300, epoch: 1 | loss: 0.5726986\n",
      "\tspeed: 0.1616s/iter; left time: 95939.4511s\n",
      "399it [01:06,  6.15it/s]\titers: 400, epoch: 1 | loss: 0.1438369\n",
      "\tspeed: 0.1647s/iter; left time: 97804.7951s\n",
      "499it [01:22,  6.20it/s]\titers: 500, epoch: 1 | loss: 2.0264332\n",
      "\tspeed: 0.1660s/iter; left time: 98518.1146s\n",
      "599it [01:39,  6.18it/s]\titers: 600, epoch: 1 | loss: 1.0076452\n",
      "\tspeed: 0.1663s/iter; left time: 98691.2915s\n",
      "699it [01:55,  6.15it/s]\titers: 700, epoch: 1 | loss: 0.3251689\n",
      "\tspeed: 0.1633s/iter; left time: 96930.0106s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 1 | loss: 0.2943802\n",
      "\tspeed: 0.1664s/iter; left time: 98696.0754s\n",
      "899it [02:28,  6.12it/s]\titers: 900, epoch: 1 | loss: 0.2147481\n",
      "\tspeed: 0.1666s/iter; left time: 98837.8081s\n",
      "999it [02:45,  6.11it/s]\titers: 1000, epoch: 1 | loss: 1.2959622\n",
      "\tspeed: 0.1652s/iter; left time: 97983.2306s\n",
      "1099it [03:02,  6.22it/s]\titers: 1100, epoch: 1 | loss: 0.3229691\n",
      "\tspeed: 0.1661s/iter; left time: 98509.2412s\n",
      "1199it [03:18,  6.11it/s]\titers: 1200, epoch: 1 | loss: 3.5836139\n",
      "\tspeed: 0.1654s/iter; left time: 98047.1786s\n",
      "1299it [03:34,  6.10it/s]\titers: 1300, epoch: 1 | loss: 0.7928461\n",
      "\tspeed: 0.1641s/iter; left time: 97283.7411s\n",
      "1399it [03:51,  6.13it/s]\titers: 1400, epoch: 1 | loss: 0.9669264\n",
      "\tspeed: 0.1647s/iter; left time: 97602.5142s\n",
      "1499it [04:08,  6.07it/s]\titers: 1500, epoch: 1 | loss: 0.2766066\n",
      "\tspeed: 0.1670s/iter; left time: 98960.7164s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 1 | loss: 0.4848849\n",
      "\tspeed: 0.1676s/iter; left time: 99295.8784s\n",
      "1699it [04:41,  6.07it/s]\titers: 1700, epoch: 1 | loss: 0.6695154\n",
      "\tspeed: 0.1654s/iter; left time: 97990.5967s\n",
      "1799it [04:57,  6.16it/s]\titers: 1800, epoch: 1 | loss: 1.2255758\n",
      "\tspeed: 0.1656s/iter; left time: 98102.6054s\n",
      "1899it [05:14,  5.50it/s]\titers: 1900, epoch: 1 | loss: 0.5021087\n",
      "\tspeed: 0.1658s/iter; left time: 98174.4129s\n",
      "1999it [05:31,  6.10it/s]\titers: 2000, epoch: 1 | loss: 1.5542575\n",
      "\tspeed: 0.1658s/iter; left time: 98141.5330s\n",
      "2099it [05:47,  6.09it/s]\titers: 2100, epoch: 1 | loss: 0.2956932\n",
      "\tspeed: 0.1676s/iter; left time: 99220.1452s\n",
      "2199it [06:04,  6.07it/s]\titers: 2200, epoch: 1 | loss: 0.4262205\n",
      "\tspeed: 0.1686s/iter; left time: 99788.5428s\n",
      "2299it [06:21,  6.05it/s]\titers: 2300, epoch: 1 | loss: 0.2466510\n",
      "\tspeed: 0.1666s/iter; left time: 98619.6970s\n",
      "2399it [06:37,  6.15it/s]\titers: 2400, epoch: 1 | loss: 0.2156907\n",
      "\tspeed: 0.1651s/iter; left time: 97681.3199s\n",
      "2499it [06:54,  6.03it/s]\titers: 2500, epoch: 1 | loss: 0.3934126\n",
      "\tspeed: 0.1678s/iter; left time: 99275.3671s\n",
      "2599it [07:11,  6.12it/s]\titers: 2600, epoch: 1 | loss: 0.4883535\n",
      "\tspeed: 0.1646s/iter; left time: 97362.0562s\n",
      "2699it [07:28,  6.05it/s]\titers: 2700, epoch: 1 | loss: 0.2329644\n",
      "\tspeed: 0.1683s/iter; left time: 99518.0476s\n",
      "2799it [07:44,  6.02it/s]\titers: 2800, epoch: 1 | loss: 0.2674466\n",
      "\tspeed: 0.1680s/iter; left time: 99350.3083s\n",
      "2899it [08:01,  6.07it/s]\titers: 2900, epoch: 1 | loss: 0.4920942\n",
      "\tspeed: 0.1689s/iter; left time: 99865.4852s\n",
      "2999it [08:18,  6.02it/s]\titers: 3000, epoch: 1 | loss: 0.1507949\n",
      "\tspeed: 0.1663s/iter; left time: 98295.3716s\n",
      "3099it [08:35,  5.90it/s]\titers: 3100, epoch: 1 | loss: 1.2729228\n",
      "\tspeed: 0.1691s/iter; left time: 99966.7480s\n",
      "3199it [08:51,  6.15it/s]\titers: 3200, epoch: 1 | loss: 0.5421988\n",
      "\tspeed: 0.1641s/iter; left time: 96962.1632s\n",
      "3299it [09:08,  6.12it/s]\titers: 3300, epoch: 1 | loss: 0.4190972\n",
      "\tspeed: 0.1665s/iter; left time: 98395.3442s\n",
      "3399it [09:25,  6.09it/s]\titers: 3400, epoch: 1 | loss: 0.1650268\n",
      "\tspeed: 0.1680s/iter; left time: 99225.8701s\n",
      "3499it [09:41,  6.00it/s]\titers: 3500, epoch: 1 | loss: 0.4030348\n",
      "\tspeed: 0.1670s/iter; left time: 98616.1525s\n",
      "3599it [09:58,  6.13it/s]\titers: 3600, epoch: 1 | loss: 0.2903863\n",
      "\tspeed: 0.1665s/iter; left time: 98334.5005s\n",
      "3699it [10:14,  6.07it/s]\titers: 3700, epoch: 1 | loss: 0.1307596\n",
      "\tspeed: 0.1650s/iter; left time: 97417.8527s\n",
      "3799it [10:31,  6.05it/s]\titers: 3800, epoch: 1 | loss: 0.2359500\n",
      "\tspeed: 0.1677s/iter; left time: 99018.0210s\n",
      "3899it [10:48,  5.98it/s]\titers: 3900, epoch: 1 | loss: 0.4007958\n",
      "\tspeed: 0.1669s/iter; left time: 98510.0295s\n",
      "3999it [11:04,  6.01it/s]\titers: 4000, epoch: 1 | loss: 0.2180763\n",
      "\tspeed: 0.1656s/iter; left time: 97719.6419s\n",
      "4099it [11:21,  6.07it/s]\titers: 4100, epoch: 1 | loss: 0.1402368\n",
      "\tspeed: 0.1651s/iter; left time: 97429.3030s\n",
      "4199it [11:38,  6.00it/s]\titers: 4200, epoch: 1 | loss: 0.1530070\n",
      "\tspeed: 0.1659s/iter; left time: 97881.8351s\n",
      "4299it [11:54,  6.10it/s]\titers: 4300, epoch: 1 | loss: 0.1997754\n",
      "\tspeed: 0.1656s/iter; left time: 97662.3311s\n",
      "4399it [12:11,  6.07it/s]\titers: 4400, epoch: 1 | loss: 0.9157153\n",
      "\tspeed: 0.1674s/iter; left time: 98721.9143s\n",
      "4499it [12:28,  6.13it/s]\titers: 4500, epoch: 1 | loss: 0.1579884\n",
      "\tspeed: 0.1663s/iter; left time: 98066.6511s\n",
      "4599it [12:44,  5.99it/s]\titers: 4600, epoch: 1 | loss: 0.2861905\n",
      "\tspeed: 0.1654s/iter; left time: 97482.9733s\n",
      "4699it [13:01,  6.06it/s]\titers: 4700, epoch: 1 | loss: 0.7005666\n",
      "\tspeed: 0.1662s/iter; left time: 97950.5649s\n",
      "4799it [13:17,  6.08it/s]\titers: 4800, epoch: 1 | loss: 0.5066194\n",
      "\tspeed: 0.1668s/iter; left time: 98292.4665s\n",
      "4899it [13:34,  6.11it/s]\titers: 4900, epoch: 1 | loss: 0.3654936\n",
      "\tspeed: 0.1650s/iter; left time: 97246.0440s\n",
      "4999it [13:50,  6.15it/s]\titers: 5000, epoch: 1 | loss: 0.4218225\n",
      "\tspeed: 0.1664s/iter; left time: 98012.9657s\n",
      "5099it [14:07,  6.07it/s]\titers: 5100, epoch: 1 | loss: 0.5963903\n",
      "\tspeed: 0.1644s/iter; left time: 96844.2067s\n",
      "5199it [14:23,  6.08it/s]\titers: 5200, epoch: 1 | loss: 0.2203692\n",
      "\tspeed: 0.1649s/iter; left time: 97088.7269s\n",
      "5299it [14:40,  6.13it/s]\titers: 5300, epoch: 1 | loss: 0.2719721\n",
      "\tspeed: 0.1669s/iter; left time: 98246.3935s\n",
      "5399it [14:57,  6.14it/s]\titers: 5400, epoch: 1 | loss: 0.1654903\n",
      "\tspeed: 0.1652s/iter; left time: 97230.0539s\n",
      "5499it [15:13,  6.11it/s]\titers: 5500, epoch: 1 | loss: 0.1962334\n",
      "\tspeed: 0.1662s/iter; left time: 97797.5872s\n",
      "5599it [15:30,  6.07it/s]\titers: 5600, epoch: 1 | loss: 0.1712907\n",
      "\tspeed: 0.1657s/iter; left time: 97490.2337s\n",
      "5699it [15:46,  6.03it/s]\titers: 5700, epoch: 1 | loss: 0.1609384\n",
      "\tspeed: 0.1650s/iter; left time: 97078.7355s\n",
      "5799it [16:03,  6.14it/s]\titers: 5800, epoch: 1 | loss: 0.1968787\n",
      "\tspeed: 0.1656s/iter; left time: 97437.6799s\n",
      "5899it [16:20,  6.01it/s]\titers: 5900, epoch: 1 | loss: 0.3110353\n",
      "\tspeed: 0.1668s/iter; left time: 98114.3968s\n",
      "5999it [16:36,  6.00it/s]\titers: 6000, epoch: 1 | loss: 0.2768937\n",
      "\tspeed: 0.1688s/iter; left time: 99256.6793s\n",
      "6099it [16:53,  6.08it/s]\titers: 6100, epoch: 1 | loss: 0.2760840\n",
      "\tspeed: 0.1655s/iter; left time: 97316.4223s\n",
      "6199it [17:10,  5.99it/s]\titers: 6200, epoch: 1 | loss: 0.9600676\n",
      "\tspeed: 0.1667s/iter; left time: 98014.1044s\n",
      "6299it [17:26,  6.01it/s]\titers: 6300, epoch: 1 | loss: 0.2491993\n",
      "\tspeed: 0.1657s/iter; left time: 97386.7328s\n",
      "6399it [17:43,  6.03it/s]\titers: 6400, epoch: 1 | loss: 0.2270503\n",
      "\tspeed: 0.1665s/iter; left time: 97862.3967s\n",
      "6499it [17:59,  6.13it/s]\titers: 6500, epoch: 1 | loss: 0.1633934\n",
      "\tspeed: 0.1662s/iter; left time: 97681.4752s\n",
      "6599it [18:16,  5.20it/s]\titers: 6600, epoch: 1 | loss: 0.1511570\n",
      "\tspeed: 0.1673s/iter; left time: 98291.1221s\n",
      "6699it [18:33,  6.01it/s]\titers: 6700, epoch: 1 | loss: 0.3299534\n",
      "\tspeed: 0.1659s/iter; left time: 97460.2953s\n",
      "6799it [18:50,  6.08it/s]\titers: 6800, epoch: 1 | loss: 0.2689808\n",
      "\tspeed: 0.1689s/iter; left time: 99166.2513s\n",
      "6899it [19:06,  6.03it/s]\titers: 6900, epoch: 1 | loss: 0.3077254\n",
      "\tspeed: 0.1678s/iter; left time: 98553.0490s\n",
      "6999it [19:23,  6.03it/s]\titers: 7000, epoch: 1 | loss: 0.4068074\n",
      "\tspeed: 0.1667s/iter; left time: 97878.1889s\n",
      "7099it [19:40,  6.05it/s]\titers: 7100, epoch: 1 | loss: 0.3582238\n",
      "\tspeed: 0.1669s/iter; left time: 97991.6224s\n",
      "7199it [19:56,  6.07it/s]\titers: 7200, epoch: 1 | loss: 0.1896965\n",
      "\tspeed: 0.1657s/iter; left time: 97264.3977s\n",
      "7299it [20:13,  6.10it/s]\titers: 7300, epoch: 1 | loss: 0.2461447\n",
      "\tspeed: 0.1685s/iter; left time: 98863.4927s\n",
      "7399it [20:30,  6.06it/s]\titers: 7400, epoch: 1 | loss: 0.1440787\n",
      "\tspeed: 0.1663s/iter; left time: 97593.3498s\n",
      "7499it [20:47,  5.92it/s]\titers: 7500, epoch: 1 | loss: 0.3906360\n",
      "\tspeed: 0.1684s/iter; left time: 98760.4323s\n",
      "7599it [21:03,  6.10it/s]\titers: 7600, epoch: 1 | loss: 0.9539621\n",
      "\tspeed: 0.1666s/iter; left time: 97685.9224s\n",
      "7699it [21:20,  5.95it/s]\titers: 7700, epoch: 1 | loss: 0.1091226\n",
      "\tspeed: 0.1681s/iter; left time: 98571.1235s\n",
      "7799it [21:37,  6.03it/s]\titers: 7800, epoch: 1 | loss: 0.9081524\n",
      "\tspeed: 0.1653s/iter; left time: 96942.6609s\n",
      "7899it [21:54,  6.05it/s]\titers: 7900, epoch: 1 | loss: 0.1123061\n",
      "\tspeed: 0.1677s/iter; left time: 98277.9246s\n",
      "7999it [22:10,  6.07it/s]\titers: 8000, epoch: 1 | loss: 0.2290815\n",
      "\tspeed: 0.1679s/iter; left time: 98434.9787s\n",
      "8099it [22:27,  6.00it/s]\titers: 8100, epoch: 1 | loss: 0.1137453\n",
      "\tspeed: 0.1676s/iter; left time: 98201.9478s\n",
      "8199it [22:44,  6.07it/s]\titers: 8200, epoch: 1 | loss: 0.1587885\n",
      "\tspeed: 0.1663s/iter; left time: 97449.0727s\n",
      "8299it [23:00,  5.98it/s]\titers: 8300, epoch: 1 | loss: 0.0926051\n",
      "\tspeed: 0.1677s/iter; left time: 98212.3721s\n",
      "8399it [23:17,  5.27it/s]\titers: 8400, epoch: 1 | loss: 0.0647519\n",
      "\tspeed: 0.1662s/iter; left time: 97348.2198s\n",
      "8499it [23:34,  5.98it/s]\titers: 8500, epoch: 1 | loss: 0.1248680\n",
      "\tspeed: 0.1678s/iter; left time: 98260.5485s\n",
      "8599it [23:50,  6.04it/s]\titers: 8600, epoch: 1 | loss: 0.3652635\n",
      "\tspeed: 0.1657s/iter; left time: 97034.7063s\n",
      "8699it [24:07,  6.03it/s]\titers: 8700, epoch: 1 | loss: 0.1904032\n",
      "\tspeed: 0.1675s/iter; left time: 98066.3202s\n",
      "8799it [24:24,  6.13it/s]\titers: 8800, epoch: 1 | loss: 0.3782054\n",
      "\tspeed: 0.1677s/iter; left time: 98177.0008s\n",
      "8899it [24:41,  6.12it/s]\titers: 8900, epoch: 1 | loss: 0.2053458\n",
      "\tspeed: 0.1661s/iter; left time: 97219.0342s\n",
      "8999it [24:57,  6.03it/s]\titers: 9000, epoch: 1 | loss: 0.5273315\n",
      "\tspeed: 0.1655s/iter; left time: 96854.3756s\n",
      "9099it [25:14,  6.11it/s]\titers: 9100, epoch: 1 | loss: 0.1882799\n",
      "\tspeed: 0.1654s/iter; left time: 96788.0672s\n",
      "9199it [25:30,  6.06it/s]\titers: 9200, epoch: 1 | loss: 0.2074475\n",
      "\tspeed: 0.1660s/iter; left time: 97097.1912s\n",
      "9299it [25:47,  6.07it/s]\titers: 9300, epoch: 1 | loss: 0.1381924\n",
      "\tspeed: 0.1672s/iter; left time: 97771.4005s\n",
      "9399it [26:04,  6.13it/s]\titers: 9400, epoch: 1 | loss: 0.2717637\n",
      "\tspeed: 0.1659s/iter; left time: 96981.9272s\n",
      "9499it [26:20,  6.14it/s]\titers: 9500, epoch: 1 | loss: 0.2236086\n",
      "\tspeed: 0.1639s/iter; left time: 95821.7703s\n",
      "9599it [26:36,  5.35it/s]\titers: 9600, epoch: 1 | loss: 0.2154243\n",
      "\tspeed: 0.1653s/iter; left time: 96605.7560s\n",
      "9699it [26:53,  6.09it/s]\titers: 9700, epoch: 1 | loss: 0.6067473\n",
      "\tspeed: 0.1653s/iter; left time: 96613.4858s\n",
      "9799it [27:10,  6.05it/s]\titers: 9800, epoch: 1 | loss: 0.2660284\n",
      "\tspeed: 0.1664s/iter; left time: 97254.7811s\n",
      "9899it [27:26,  6.04it/s]\titers: 9900, epoch: 1 | loss: 0.1716065\n",
      "\tspeed: 0.1665s/iter; left time: 97260.1824s\n",
      "9999it [27:43,  6.13it/s]\titers: 10000, epoch: 1 | loss: 0.1944377\n",
      "\tspeed: 0.1660s/iter; left time: 96945.5624s\n",
      "10099it [27:59,  6.09it/s]\titers: 10100, epoch: 1 | loss: 0.0364947\n",
      "\tspeed: 0.1648s/iter; left time: 96226.6871s\n",
      "10199it [28:16,  6.14it/s]\titers: 10200, epoch: 1 | loss: 0.6702064\n",
      "\tspeed: 0.1659s/iter; left time: 96878.5194s\n",
      "10299it [28:32,  6.10it/s]\titers: 10300, epoch: 1 | loss: 0.1408983\n",
      "\tspeed: 0.1648s/iter; left time: 96182.2525s\n",
      "10399it [28:49,  6.04it/s]\titers: 10400, epoch: 1 | loss: 0.2868299\n",
      "\tspeed: 0.1650s/iter; left time: 96327.3481s\n",
      "10499it [29:06,  6.10it/s]\titers: 10500, epoch: 1 | loss: 0.0830280\n",
      "\tspeed: 0.1682s/iter; left time: 98142.4710s\n",
      "10599it [29:22,  6.12it/s]\titers: 10600, epoch: 1 | loss: 0.3344839\n",
      "\tspeed: 0.1661s/iter; left time: 96927.9377s\n",
      "10699it [29:39,  6.08it/s]\titers: 10700, epoch: 1 | loss: 0.2746340\n",
      "\tspeed: 0.1680s/iter; left time: 97992.5136s\n",
      "10799it [29:56,  6.09it/s]\titers: 10800, epoch: 1 | loss: 0.2334372\n",
      "\tspeed: 0.1655s/iter; left time: 96538.5612s\n",
      "10899it [30:12,  6.18it/s]\titers: 10900, epoch: 1 | loss: 0.1292695\n",
      "\tspeed: 0.1654s/iter; left time: 96438.2231s\n",
      "10999it [30:29,  5.26it/s]\titers: 11000, epoch: 1 | loss: 0.1224874\n",
      "\tspeed: 0.1662s/iter; left time: 96934.6509s\n",
      "11099it [30:45,  6.10it/s]\titers: 11100, epoch: 1 | loss: 0.1782735\n",
      "\tspeed: 0.1659s/iter; left time: 96716.8158s\n",
      "11199it [31:02,  6.06it/s]\titers: 11200, epoch: 1 | loss: 0.0612306\n",
      "\tspeed: 0.1683s/iter; left time: 98087.7831s\n",
      "11299it [31:19,  6.09it/s]\titers: 11300, epoch: 1 | loss: 0.1699242\n",
      "\tspeed: 0.1680s/iter; left time: 97922.9857s\n",
      "11399it [31:36,  6.06it/s]\titers: 11400, epoch: 1 | loss: 0.1363565\n",
      "\tspeed: 0.1669s/iter; left time: 97256.6538s\n",
      "11499it [31:53,  6.04it/s]\titers: 11500, epoch: 1 | loss: 0.1271717\n",
      "\tspeed: 0.1671s/iter; left time: 97361.0962s\n",
      "11599it [32:09,  6.09it/s]\titers: 11600, epoch: 1 | loss: 0.4219858\n",
      "\tspeed: 0.1674s/iter; left time: 97498.2614s\n",
      "11699it [32:26,  5.84it/s]\titers: 11700, epoch: 1 | loss: 0.8908160\n",
      "\tspeed: 0.1660s/iter; left time: 96706.8225s\n",
      "11799it [32:42,  6.07it/s]\titers: 11800, epoch: 1 | loss: 0.2107601\n",
      "\tspeed: 0.1648s/iter; left time: 95991.1808s\n",
      "11899it [32:59,  6.08it/s]\titers: 11900, epoch: 1 | loss: 0.3046662\n",
      "\tspeed: 0.1673s/iter; left time: 97398.3436s\n",
      "11999it [33:16,  6.04it/s]\titers: 12000, epoch: 1 | loss: 0.7576277\n",
      "\tspeed: 0.1675s/iter; left time: 97519.5680s\n",
      "12099it [33:32,  6.07it/s]\titers: 12100, epoch: 1 | loss: 0.1137525\n",
      "\tspeed: 0.1656s/iter; left time: 96398.9318s\n",
      "12199it [33:49,  6.04it/s]\titers: 12200, epoch: 1 | loss: 0.6421388\n",
      "\tspeed: 0.1654s/iter; left time: 96237.2034s\n",
      "12299it [34:06,  6.07it/s]\titers: 12300, epoch: 1 | loss: 0.1658582\n",
      "\tspeed: 0.1666s/iter; left time: 96907.3915s\n",
      "12399it [34:22,  6.18it/s]\titers: 12400, epoch: 1 | loss: 0.1991151\n",
      "\tspeed: 0.1658s/iter; left time: 96454.1053s\n",
      "12499it [34:39,  6.04it/s]\titers: 12500, epoch: 1 | loss: 0.1482913\n",
      "\tspeed: 0.1678s/iter; left time: 97594.7955s\n",
      "12599it [34:56,  6.06it/s]\titers: 12600, epoch: 1 | loss: 0.1209964\n",
      "\tspeed: 0.1671s/iter; left time: 97176.8737s\n",
      "12699it [35:12,  6.09it/s]\titers: 12700, epoch: 1 | loss: 0.1875156\n",
      "\tspeed: 0.1681s/iter; left time: 97704.5923s\n",
      "12799it [35:29,  6.10it/s]\titers: 12800, epoch: 1 | loss: 0.0984909\n",
      "\tspeed: 0.1670s/iter; left time: 97103.6997s\n",
      "12899it [35:46,  4.77it/s]\titers: 12900, epoch: 1 | loss: 0.1146961\n",
      "\tspeed: 0.1681s/iter; left time: 97696.2531s\n",
      "12999it [36:02,  6.02it/s]\titers: 13000, epoch: 1 | loss: 0.2220015\n",
      "\tspeed: 0.1653s/iter; left time: 96039.5470s\n",
      "13099it [36:19,  6.05it/s]\titers: 13100, epoch: 1 | loss: 0.3599639\n",
      "\tspeed: 0.1647s/iter; left time: 95668.4285s\n",
      "13199it [36:35,  6.12it/s]\titers: 13200, epoch: 1 | loss: 0.0547104\n",
      "\tspeed: 0.1649s/iter; left time: 95777.4662s\n",
      "13299it [36:52,  6.11it/s]\titers: 13300, epoch: 1 | loss: 0.2140785\n",
      "\tspeed: 0.1683s/iter; left time: 97771.0537s\n",
      "13399it [37:09,  6.05it/s]\titers: 13400, epoch: 1 | loss: 0.0903382\n",
      "\tspeed: 0.1676s/iter; left time: 97331.4658s\n",
      "13499it [37:26,  6.11it/s]\titers: 13500, epoch: 1 | loss: 0.2052125\n",
      "\tspeed: 0.1674s/iter; left time: 97175.3969s\n",
      "13599it [37:43,  6.00it/s]\titers: 13600, epoch: 1 | loss: 0.8204823\n",
      "\tspeed: 0.1683s/iter; left time: 97670.1212s\n",
      "13699it [37:59,  6.05it/s]\titers: 13700, epoch: 1 | loss: 0.1021319\n",
      "\tspeed: 0.1654s/iter; left time: 95989.1452s\n",
      "13799it [38:16,  6.01it/s]\titers: 13800, epoch: 1 | loss: 0.4719047\n",
      "\tspeed: 0.1674s/iter; left time: 97160.9671s\n",
      "13899it [38:33,  6.05it/s]\titers: 13900, epoch: 1 | loss: 0.2974567\n",
      "\tspeed: 0.1677s/iter; left time: 97299.1750s\n",
      "13999it [38:49,  6.02it/s]\titers: 14000, epoch: 1 | loss: 0.1690110\n",
      "\tspeed: 0.1681s/iter; left time: 97514.2683s\n",
      "14099it [39:06,  6.04it/s]\titers: 14100, epoch: 1 | loss: 0.5721066\n",
      "\tspeed: 0.1688s/iter; left time: 97909.0619s\n",
      "14199it [39:23,  6.06it/s]\titers: 14200, epoch: 1 | loss: 0.1852437\n",
      "\tspeed: 0.1676s/iter; left time: 97212.4216s\n",
      "14299it [39:40,  5.67it/s]\titers: 14300, epoch: 1 | loss: 0.1553525\n",
      "\tspeed: 0.1663s/iter; left time: 96417.2092s\n",
      "14399it [39:57,  6.02it/s]\titers: 14400, epoch: 1 | loss: 0.1410348\n",
      "\tspeed: 0.1681s/iter; left time: 97440.6351s\n",
      "14499it [40:13,  6.05it/s]\titers: 14500, epoch: 1 | loss: 0.7996014\n",
      "\tspeed: 0.1676s/iter; left time: 97123.4022s\n",
      "14599it [40:30,  6.03it/s]\titers: 14600, epoch: 1 | loss: 0.0937230\n",
      "\tspeed: 0.1667s/iter; left time: 96601.1205s\n",
      "14699it [40:47,  6.06it/s]\titers: 14700, epoch: 1 | loss: 0.5412911\n",
      "\tspeed: 0.1677s/iter; left time: 97173.7103s\n",
      "14799it [41:04,  6.12it/s]\titers: 14800, epoch: 1 | loss: 0.1854702\n",
      "\tspeed: 0.1678s/iter; left time: 97223.1117s\n",
      "14899it [41:20,  6.01it/s]\titers: 14900, epoch: 1 | loss: 0.1028510\n",
      "\tspeed: 0.1657s/iter; left time: 95973.5031s\n",
      "14999it [41:37,  6.11it/s]\titers: 15000, epoch: 1 | loss: 0.2243265\n",
      "\tspeed: 0.1687s/iter; left time: 97683.5038s\n",
      "15099it [41:54,  6.01it/s]\titers: 15100, epoch: 1 | loss: 0.2611559\n",
      "\tspeed: 0.1668s/iter; left time: 96571.0102s\n",
      "15199it [42:10,  6.04it/s]\titers: 15200, epoch: 1 | loss: 0.4092097\n",
      "\tspeed: 0.1662s/iter; left time: 96229.1710s\n",
      "15299it [42:27,  6.08it/s]\titers: 15300, epoch: 1 | loss: 0.0446701\n",
      "\tspeed: 0.1674s/iter; left time: 96916.8196s\n",
      "15399it [42:44,  6.03it/s]\titers: 15400, epoch: 1 | loss: 0.6915508\n",
      "\tspeed: 0.1653s/iter; left time: 95652.7890s\n",
      "15499it [43:00,  6.08it/s]\titers: 15500, epoch: 1 | loss: 0.2406015\n",
      "\tspeed: 0.1653s/iter; left time: 95668.1057s\n",
      "15599it [43:17,  6.08it/s]\titers: 15600, epoch: 1 | loss: 0.4767619\n",
      "\tspeed: 0.1664s/iter; left time: 96270.3791s\n",
      "15699it [43:33,  6.08it/s]\titers: 15700, epoch: 1 | loss: 0.0616158\n",
      "\tspeed: 0.1668s/iter; left time: 96472.8261s\n",
      "15799it [43:50,  5.98it/s]\titers: 15800, epoch: 1 | loss: 0.1442405\n",
      "\tspeed: 0.1694s/iter; left time: 97975.4240s\n",
      "15899it [44:07,  6.04it/s]\titers: 15900, epoch: 1 | loss: 0.2435529\n",
      "\tspeed: 0.1655s/iter; left time: 95668.2566s\n",
      "15999it [44:24,  6.11it/s]\titers: 16000, epoch: 1 | loss: 0.5225781\n",
      "\tspeed: 0.1683s/iter; left time: 97298.9021s\n",
      "16099it [44:40,  6.11it/s]\titers: 16100, epoch: 1 | loss: 0.3809279\n",
      "\tspeed: 0.1658s/iter; left time: 95809.9086s\n",
      "16199it [44:57,  6.00it/s]\titers: 16200, epoch: 1 | loss: 0.3498441\n",
      "\tspeed: 0.1665s/iter; left time: 96239.7198s\n",
      "16299it [45:14,  6.07it/s]\titers: 16300, epoch: 1 | loss: 0.1502168\n",
      "\tspeed: 0.1672s/iter; left time: 96613.9121s\n",
      "16399it [45:30,  5.94it/s]\titers: 16400, epoch: 1 | loss: 0.2424872\n",
      "\tspeed: 0.1669s/iter; left time: 96405.0775s\n",
      "16499it [45:47,  6.09it/s]\titers: 16500, epoch: 1 | loss: 0.3347593\n",
      "\tspeed: 0.1654s/iter; left time: 95519.6604s\n",
      "16599it [46:03,  6.03it/s]\titers: 16600, epoch: 1 | loss: 0.5881454\n",
      "\tspeed: 0.1660s/iter; left time: 95870.4829s\n",
      "16699it [46:20,  6.10it/s]\titers: 16700, epoch: 1 | loss: 0.1775435\n",
      "\tspeed: 0.1653s/iter; left time: 95431.0442s\n",
      "16799it [46:37,  6.06it/s]\titers: 16800, epoch: 1 | loss: 0.4035986\n",
      "\tspeed: 0.1657s/iter; left time: 95638.8672s\n",
      "16899it [46:53,  6.06it/s]\titers: 16900, epoch: 1 | loss: 0.1989632\n",
      "\tspeed: 0.1662s/iter; left time: 95912.9747s\n",
      "16999it [47:10,  6.03it/s]\titers: 17000, epoch: 1 | loss: 0.4471209\n",
      "\tspeed: 0.1647s/iter; left time: 95031.7982s\n",
      "17099it [47:26,  6.06it/s]\titers: 17100, epoch: 1 | loss: 0.4663295\n",
      "\tspeed: 0.1645s/iter; left time: 94889.7235s\n",
      "17199it [47:43,  6.15it/s]\titers: 17200, epoch: 1 | loss: 0.1891944\n",
      "\tspeed: 0.1651s/iter; left time: 95233.0958s\n",
      "17299it [47:59,  6.14it/s]\titers: 17300, epoch: 1 | loss: 0.2550479\n",
      "\tspeed: 0.1659s/iter; left time: 95672.4383s\n",
      "17399it [48:16,  6.09it/s]\titers: 17400, epoch: 1 | loss: 0.1122202\n",
      "\tspeed: 0.1677s/iter; left time: 96710.1685s\n",
      "17499it [48:33,  6.04it/s]\titers: 17500, epoch: 1 | loss: 0.2386822\n",
      "\tspeed: 0.1652s/iter; left time: 95237.3588s\n",
      "17599it [48:49,  6.10it/s]\titers: 17600, epoch: 1 | loss: 0.1355786\n",
      "\tspeed: 0.1672s/iter; left time: 96400.9461s\n",
      "17699it [49:06,  6.13it/s]\titers: 17700, epoch: 1 | loss: 0.4814391\n",
      "\tspeed: 0.1654s/iter; left time: 95314.5654s\n",
      "17799it [49:22,  5.84it/s]\titers: 17800, epoch: 1 | loss: 0.0828011\n",
      "\tspeed: 0.1658s/iter; left time: 95555.6999s\n",
      "17899it [49:39,  6.07it/s]\titers: 17900, epoch: 1 | loss: 0.1188368\n",
      "\tspeed: 0.1652s/iter; left time: 95200.9160s\n",
      "17999it [49:56,  6.04it/s]\titers: 18000, epoch: 1 | loss: 0.0939394\n",
      "\tspeed: 0.1678s/iter; left time: 96695.3860s\n",
      "18099it [50:12,  6.11it/s]\titers: 18100, epoch: 1 | loss: 0.4247698\n",
      "\tspeed: 0.1667s/iter; left time: 96019.3809s\n",
      "18199it [50:29,  5.95it/s]\titers: 18200, epoch: 1 | loss: 0.2121956\n",
      "\tspeed: 0.1677s/iter; left time: 96551.0225s\n",
      "18299it [50:46,  6.06it/s]\titers: 18300, epoch: 1 | loss: 0.5956801\n",
      "\tspeed: 0.1670s/iter; left time: 96176.8322s\n",
      "18399it [51:02,  6.01it/s]\titers: 18400, epoch: 1 | loss: 0.0876412\n",
      "\tspeed: 0.1671s/iter; left time: 96218.4224s\n",
      "18499it [51:19,  6.07it/s]\titers: 18500, epoch: 1 | loss: 0.1814256\n",
      "\tspeed: 0.1678s/iter; left time: 96596.9128s\n",
      "18599it [51:36,  4.75it/s]\titers: 18600, epoch: 1 | loss: 0.0471026\n",
      "\tspeed: 0.1683s/iter; left time: 96862.5656s\n",
      "18699it [51:53,  6.06it/s]\titers: 18700, epoch: 1 | loss: 0.1321760\n",
      "\tspeed: 0.1655s/iter; left time: 95217.3786s\n",
      "18799it [52:09,  6.05it/s]\titers: 18800, epoch: 1 | loss: 0.4819761\n",
      "\tspeed: 0.1677s/iter; left time: 96486.3884s\n",
      "18899it [52:26,  6.07it/s]\titers: 18900, epoch: 1 | loss: 0.2045627\n",
      "\tspeed: 0.1652s/iter; left time: 95046.9506s\n",
      "18999it [52:43,  6.13it/s]\titers: 19000, epoch: 1 | loss: 0.0543334\n",
      "\tspeed: 0.1674s/iter; left time: 96276.0168s\n",
      "19099it [53:00,  6.05it/s]\titers: 19100, epoch: 1 | loss: 0.0684647\n",
      "\tspeed: 0.1684s/iter; left time: 96850.7219s\n",
      "19199it [53:16,  6.10it/s]\titers: 19200, epoch: 1 | loss: 0.1113411\n",
      "\tspeed: 0.1666s/iter; left time: 95758.8201s\n",
      "19299it [53:33,  5.84it/s]\titers: 19300, epoch: 1 | loss: 0.2290215\n",
      "\tspeed: 0.1646s/iter; left time: 94605.0363s\n",
      "19399it [53:49,  6.13it/s]\titers: 19400, epoch: 1 | loss: 0.1667654\n",
      "\tspeed: 0.1644s/iter; left time: 94469.8914s\n",
      "19499it [54:06,  6.06it/s]\titers: 19500, epoch: 1 | loss: 0.1223684\n",
      "\tspeed: 0.1680s/iter; left time: 96540.9779s\n",
      "19599it [54:23,  6.07it/s]\titers: 19600, epoch: 1 | loss: 0.1601311\n",
      "\tspeed: 0.1682s/iter; left time: 96642.8529s\n",
      "19699it [54:40,  6.08it/s]\titers: 19700, epoch: 1 | loss: 0.4576455\n",
      "\tspeed: 0.1679s/iter; left time: 96427.9782s\n",
      "19799it [54:56,  6.01it/s]\titers: 19800, epoch: 1 | loss: 0.2930227\n",
      "\tspeed: 0.1665s/iter; left time: 95594.5360s\n",
      "19899it [55:13,  6.12it/s]\titers: 19900, epoch: 1 | loss: 0.2038973\n",
      "\tspeed: 0.1681s/iter; left time: 96519.5079s\n",
      "19999it [55:30,  5.97it/s]\titers: 20000, epoch: 1 | loss: 0.1459615\n",
      "\tspeed: 0.1670s/iter; left time: 95851.4696s\n",
      "20099it [55:46,  6.02it/s]\titers: 20100, epoch: 1 | loss: 0.2582350\n",
      "\tspeed: 0.1651s/iter; left time: 94746.1175s\n",
      "20199it [56:03,  6.00it/s]\titers: 20200, epoch: 1 | loss: 0.2962359\n",
      "\tspeed: 0.1656s/iter; left time: 95066.0387s\n",
      "20299it [56:19,  6.10it/s]\titers: 20300, epoch: 1 | loss: 0.0412868\n",
      "\tspeed: 0.1673s/iter; left time: 95974.7450s\n",
      "20399it [56:36,  6.03it/s]\titers: 20400, epoch: 1 | loss: 0.3203923\n",
      "\tspeed: 0.1676s/iter; left time: 96150.6024s\n",
      "20499it [56:53,  6.04it/s]\titers: 20500, epoch: 1 | loss: 0.1095407\n",
      "\tspeed: 0.1677s/iter; left time: 96211.5700s\n",
      "20599it [57:10,  6.07it/s]\titers: 20600, epoch: 1 | loss: 0.2818589\n",
      "\tspeed: 0.1669s/iter; left time: 95703.2378s\n",
      "20699it [57:26,  5.96it/s]\titers: 20700, epoch: 1 | loss: 0.0714981\n",
      "\tspeed: 0.1665s/iter; left time: 95446.6265s\n",
      "20799it [57:43,  6.11it/s]\titers: 20800, epoch: 1 | loss: 0.0779549\n",
      "\tspeed: 0.1657s/iter; left time: 94998.2115s\n",
      "20899it [58:00,  6.01it/s]\titers: 20900, epoch: 1 | loss: 0.5954518\n",
      "\tspeed: 0.1690s/iter; left time: 96868.5916s\n",
      "20999it [58:16,  6.07it/s]\titers: 21000, epoch: 1 | loss: 0.2354627\n",
      "\tspeed: 0.1665s/iter; left time: 95438.4432s\n",
      "21099it [58:33,  6.05it/s]\titers: 21100, epoch: 1 | loss: 0.8873650\n",
      "\tspeed: 0.1692s/iter; left time: 96935.3240s\n",
      "21199it [58:50,  6.01it/s]\titers: 21200, epoch: 1 | loss: 0.1568628\n",
      "\tspeed: 0.1673s/iter; left time: 95823.2933s\n",
      "21299it [59:07,  6.00it/s]\titers: 21300, epoch: 1 | loss: 0.0787045\n",
      "\tspeed: 0.1658s/iter; left time: 94969.0452s\n",
      "21399it [59:24,  6.07it/s]\titers: 21400, epoch: 1 | loss: 0.1909160\n",
      "\tspeed: 0.1684s/iter; left time: 96433.7610s\n",
      "21499it [59:40,  5.07it/s]\titers: 21500, epoch: 1 | loss: 0.3225350\n",
      "\tspeed: 0.1667s/iter; left time: 95469.0731s\n",
      "21599it [59:57,  6.05it/s]\titers: 21600, epoch: 1 | loss: 0.1855324\n",
      "\tspeed: 0.1664s/iter; left time: 95288.9504s\n",
      "21699it [1:00:14,  6.09it/s]\titers: 21700, epoch: 1 | loss: 0.0220022\n",
      "\tspeed: 0.1683s/iter; left time: 96361.5878s\n",
      "21799it [1:00:31,  6.11it/s]\titers: 21800, epoch: 1 | loss: 0.1476921\n",
      "\tspeed: 0.1693s/iter; left time: 96903.0569s\n",
      "21899it [1:00:48,  6.10it/s]\titers: 21900, epoch: 1 | loss: 0.0702452\n",
      "\tspeed: 0.1691s/iter; left time: 96779.5276s\n",
      "21999it [1:01:04,  6.08it/s]\titers: 22000, epoch: 1 | loss: 0.9013218\n",
      "\tspeed: 0.1682s/iter; left time: 96247.1985s\n",
      "22099it [1:01:21,  6.09it/s]\titers: 22100, epoch: 1 | loss: 0.2186380\n",
      "\tspeed: 0.1688s/iter; left time: 96556.5761s\n",
      "22199it [1:01:38,  5.94it/s]\titers: 22200, epoch: 1 | loss: 0.0601720\n",
      "\tspeed: 0.1673s/iter; left time: 95669.0428s\n",
      "22299it [1:01:54,  6.03it/s]\titers: 22300, epoch: 1 | loss: 0.2880798\n",
      "\tspeed: 0.1647s/iter; left time: 94173.9085s\n",
      "22399it [1:02:11,  6.01it/s]\titers: 22400, epoch: 1 | loss: 0.0540120\n",
      "\tspeed: 0.1659s/iter; left time: 94872.4699s\n",
      "22499it [1:02:28,  6.07it/s]\titers: 22500, epoch: 1 | loss: 0.1021945\n",
      "\tspeed: 0.1677s/iter; left time: 95829.3880s\n",
      "22599it [1:02:45,  6.12it/s]\titers: 22600, epoch: 1 | loss: 0.0988513\n",
      "\tspeed: 0.1675s/iter; left time: 95699.1103s\n",
      "22699it [1:03:01,  5.97it/s]\titers: 22700, epoch: 1 | loss: 0.1014180\n",
      "\tspeed: 0.1657s/iter; left time: 94695.7644s\n",
      "22799it [1:03:18,  6.06it/s]\titers: 22800, epoch: 1 | loss: 0.5188270\n",
      "\tspeed: 0.1666s/iter; left time: 95179.3110s\n",
      "22899it [1:03:34,  5.61it/s]\titers: 22900, epoch: 1 | loss: 0.1275275\n",
      "\tspeed: 0.1660s/iter; left time: 94838.7269s\n",
      "22999it [1:03:51,  6.01it/s]\titers: 23000, epoch: 1 | loss: 0.0456666\n",
      "\tspeed: 0.1680s/iter; left time: 95940.9455s\n",
      "23099it [1:04:08,  6.04it/s]\titers: 23100, epoch: 1 | loss: 0.1900773\n",
      "\tspeed: 0.1674s/iter; left time: 95587.9621s\n",
      "23199it [1:04:25,  6.07it/s]\titers: 23200, epoch: 1 | loss: 0.0867180\n",
      "\tspeed: 0.1670s/iter; left time: 95361.9378s\n",
      "23299it [1:04:41,  6.02it/s]\titers: 23300, epoch: 1 | loss: 0.2940042\n",
      "\tspeed: 0.1679s/iter; left time: 95865.8406s\n",
      "23399it [1:04:58,  5.95it/s]\titers: 23400, epoch: 1 | loss: 0.2784250\n",
      "\tspeed: 0.1668s/iter; left time: 95180.0731s\n",
      "23499it [1:05:15,  6.12it/s]\titers: 23500, epoch: 1 | loss: 0.2185078\n",
      "\tspeed: 0.1679s/iter; left time: 95791.5524s\n",
      "23599it [1:05:32,  5.54it/s]\titers: 23600, epoch: 1 | loss: 0.1923767\n",
      "\tspeed: 0.1689s/iter; left time: 96331.1572s\n",
      "23699it [1:05:48,  6.03it/s]\titers: 23700, epoch: 1 | loss: 0.2481428\n",
      "\tspeed: 0.1646s/iter; left time: 93880.9018s\n",
      "23799it [1:06:05,  6.04it/s]\titers: 23800, epoch: 1 | loss: 0.2491987\n",
      "\tspeed: 0.1669s/iter; left time: 95195.2461s\n",
      "23899it [1:06:22,  6.03it/s]\titers: 23900, epoch: 1 | loss: 0.1286279\n",
      "\tspeed: 0.1687s/iter; left time: 96194.9309s\n",
      "23999it [1:06:38,  6.12it/s]\titers: 24000, epoch: 1 | loss: 0.2544964\n",
      "\tspeed: 0.1653s/iter; left time: 94258.7183s\n",
      "24099it [1:06:55,  6.07it/s]\titers: 24100, epoch: 1 | loss: 0.3517513\n",
      "\tspeed: 0.1655s/iter; left time: 94352.7179s\n",
      "24199it [1:07:12,  6.17it/s]\titers: 24200, epoch: 1 | loss: 0.4001854\n",
      "\tspeed: 0.1672s/iter; left time: 95313.8655s\n",
      "24299it [1:07:28,  6.00it/s]\titers: 24300, epoch: 1 | loss: 0.0566563\n",
      "\tspeed: 0.1656s/iter; left time: 94380.3630s\n",
      "24399it [1:07:45,  6.06it/s]\titers: 24400, epoch: 1 | loss: 0.1961337\n",
      "\tspeed: 0.1658s/iter; left time: 94475.2076s\n",
      "24499it [1:08:02,  6.03it/s]\titers: 24500, epoch: 1 | loss: 0.0407609\n",
      "\tspeed: 0.1685s/iter; left time: 95965.2971s\n",
      "24599it [1:08:18,  6.05it/s]\titers: 24600, epoch: 1 | loss: 0.1010724\n",
      "\tspeed: 0.1682s/iter; left time: 95771.1306s\n",
      "24699it [1:08:35,  6.08it/s]\titers: 24700, epoch: 1 | loss: 0.0671581\n",
      "\tspeed: 0.1659s/iter; left time: 94479.4871s\n",
      "24799it [1:08:52,  6.11it/s]\titers: 24800, epoch: 1 | loss: 0.0550439\n",
      "\tspeed: 0.1661s/iter; left time: 94547.6250s\n",
      "24899it [1:09:09,  5.33it/s]\titers: 24900, epoch: 1 | loss: 0.4781666\n",
      "\tspeed: 0.1697s/iter; left time: 96566.1977s\n",
      "24999it [1:09:25,  6.03it/s]\titers: 25000, epoch: 1 | loss: 0.1421007\n",
      "\tspeed: 0.1652s/iter; left time: 94032.7509s\n",
      "25099it [1:09:42,  6.09it/s]\titers: 25100, epoch: 1 | loss: 0.2393528\n",
      "\tspeed: 0.1665s/iter; left time: 94765.3406s\n",
      "25199it [1:09:58,  6.07it/s]\titers: 25200, epoch: 1 | loss: 0.2066544\n",
      "\tspeed: 0.1668s/iter; left time: 94891.4909s\n",
      "25299it [1:10:15,  6.03it/s]\titers: 25300, epoch: 1 | loss: 0.2044657\n",
      "\tspeed: 0.1684s/iter; left time: 95805.7667s\n",
      "25399it [1:10:32,  6.14it/s]\titers: 25400, epoch: 1 | loss: 0.0827070\n",
      "\tspeed: 0.1671s/iter; left time: 95027.4859s\n",
      "25499it [1:10:48,  6.16it/s]\titers: 25500, epoch: 1 | loss: 0.1231523\n",
      "\tspeed: 0.1643s/iter; left time: 93446.9359s\n",
      "25599it [1:11:05,  6.06it/s]\titers: 25600, epoch: 1 | loss: 0.4159671\n",
      "\tspeed: 0.1666s/iter; left time: 94723.1416s\n",
      "25699it [1:11:22,  6.08it/s]\titers: 25700, epoch: 1 | loss: 0.0958681\n",
      "\tspeed: 0.1684s/iter; left time: 95723.9833s\n",
      "25799it [1:11:38,  6.08it/s]\titers: 25800, epoch: 1 | loss: 0.0837929\n",
      "\tspeed: 0.1655s/iter; left time: 94062.4286s\n",
      "25899it [1:11:55,  6.08it/s]\titers: 25900, epoch: 1 | loss: 0.1252727\n",
      "\tspeed: 0.1658s/iter; left time: 94219.8242s\n",
      "25999it [1:12:12,  6.12it/s]\titers: 26000, epoch: 1 | loss: 0.1238383\n",
      "\tspeed: 0.1665s/iter; left time: 94605.4092s\n",
      "26099it [1:12:28,  6.05it/s]\titers: 26100, epoch: 1 | loss: 0.2132652\n",
      "\tspeed: 0.1657s/iter; left time: 94119.3525s\n",
      "26199it [1:12:45,  6.06it/s]\titers: 26200, epoch: 1 | loss: 0.2786344\n",
      "\tspeed: 0.1675s/iter; left time: 95127.0191s\n",
      "26299it [1:13:02,  5.94it/s]\titers: 26300, epoch: 1 | loss: 0.1461017\n",
      "\tspeed: 0.1671s/iter; left time: 94879.6191s\n",
      "26399it [1:13:18,  6.04it/s]\titers: 26400, epoch: 1 | loss: 0.1952648\n",
      "\tspeed: 0.1660s/iter; left time: 94255.4724s\n",
      "26499it [1:13:35,  6.03it/s]\titers: 26500, epoch: 1 | loss: 0.4005190\n",
      "\tspeed: 0.1683s/iter; left time: 95506.1464s\n",
      "26599it [1:13:52,  6.10it/s]\titers: 26600, epoch: 1 | loss: 0.2285941\n",
      "\tspeed: 0.1671s/iter; left time: 94853.0087s\n",
      "26699it [1:14:08,  6.05it/s]\titers: 26700, epoch: 1 | loss: 0.2944614\n",
      "\tspeed: 0.1655s/iter; left time: 93906.0584s\n",
      "26799it [1:14:25,  6.05it/s]\titers: 26800, epoch: 1 | loss: 1.0107285\n",
      "\tspeed: 0.1666s/iter; left time: 94530.6498s\n",
      "26899it [1:14:42,  6.04it/s]\titers: 26900, epoch: 1 | loss: 0.1936084\n",
      "\tspeed: 0.1670s/iter; left time: 94698.1526s\n",
      "26999it [1:14:58,  6.11it/s]\titers: 27000, epoch: 1 | loss: 0.1531978\n",
      "\tspeed: 0.1650s/iter; left time: 93550.8687s\n",
      "27099it [1:15:15,  6.08it/s]\titers: 27100, epoch: 1 | loss: 0.1574369\n",
      "\tspeed: 0.1647s/iter; left time: 93389.7057s\n",
      "27199it [1:15:31,  6.03it/s]\titers: 27200, epoch: 1 | loss: 0.4242097\n",
      "\tspeed: 0.1656s/iter; left time: 93881.8666s\n",
      "27299it [1:15:48,  6.10it/s]\titers: 27300, epoch: 1 | loss: 0.2813334\n",
      "\tspeed: 0.1647s/iter; left time: 93334.6964s\n",
      "27399it [1:16:04,  6.08it/s]\titers: 27400, epoch: 1 | loss: 0.0347105\n",
      "\tspeed: 0.1660s/iter; left time: 94090.9488s\n",
      "27499it [1:16:21,  6.08it/s]\titers: 27500, epoch: 1 | loss: 0.1576362\n",
      "\tspeed: 0.1642s/iter; left time: 93012.9304s\n",
      "27599it [1:16:37,  6.11it/s]\titers: 27600, epoch: 1 | loss: 0.3820943\n",
      "\tspeed: 0.1639s/iter; left time: 92852.4170s\n",
      "27699it [1:16:54,  6.06it/s]\titers: 27700, epoch: 1 | loss: 0.2140025\n",
      "\tspeed: 0.1659s/iter; left time: 93955.2140s\n",
      "27799it [1:17:10,  6.08it/s]\titers: 27800, epoch: 1 | loss: 0.0533362\n",
      "\tspeed: 0.1657s/iter; left time: 93841.9418s\n",
      "27899it [1:17:27,  6.10it/s]\titers: 27900, epoch: 1 | loss: 0.1280921\n",
      "\tspeed: 0.1652s/iter; left time: 93512.9069s\n",
      "27999it [1:17:44,  5.72it/s]\titers: 28000, epoch: 1 | loss: 0.1624269\n",
      "\tspeed: 0.1667s/iter; left time: 94375.8342s\n",
      "28099it [1:18:00,  6.07it/s]\titers: 28100, epoch: 1 | loss: 0.5867969\n",
      "\tspeed: 0.1653s/iter; left time: 93566.5761s\n",
      "28199it [1:18:17,  6.07it/s]\titers: 28200, epoch: 1 | loss: 0.3657664\n",
      "\tspeed: 0.1653s/iter; left time: 93558.9551s\n",
      "28299it [1:18:33,  5.99it/s]\titers: 28300, epoch: 1 | loss: 0.2724121\n",
      "\tspeed: 0.1653s/iter; left time: 93521.3433s\n",
      "28399it [1:18:50,  6.03it/s]\titers: 28400, epoch: 1 | loss: 0.3380302\n",
      "\tspeed: 0.1657s/iter; left time: 93738.8187s\n",
      "28499it [1:19:06,  6.09it/s]\titers: 28500, epoch: 1 | loss: 0.2580764\n",
      "\tspeed: 0.1659s/iter; left time: 93824.1381s\n",
      "28599it [1:19:23,  5.65it/s]\titers: 28600, epoch: 1 | loss: 0.6585406\n",
      "\tspeed: 0.1659s/iter; left time: 93833.9810s\n",
      "28699it [1:19:39,  6.06it/s]\titers: 28700, epoch: 1 | loss: 0.1085463\n",
      "\tspeed: 0.1650s/iter; left time: 93291.9253s\n",
      "28799it [1:19:56,  6.07it/s]\titers: 28800, epoch: 1 | loss: 0.0538631\n",
      "\tspeed: 0.1671s/iter; left time: 94465.2220s\n",
      "28899it [1:20:13,  6.06it/s]\titers: 28900, epoch: 1 | loss: 0.2545820\n",
      "\tspeed: 0.1664s/iter; left time: 94029.8577s\n",
      "28999it [1:20:30,  6.15it/s]\titers: 29000, epoch: 1 | loss: 0.0675351\n",
      "\tspeed: 0.1683s/iter; left time: 95132.5871s\n",
      "29099it [1:20:46,  6.07it/s]\titers: 29100, epoch: 1 | loss: 0.2810234\n",
      "\tspeed: 0.1645s/iter; left time: 92932.5847s\n",
      "29199it [1:21:02,  6.03it/s]\titers: 29200, epoch: 1 | loss: 0.2295236\n",
      "\tspeed: 0.1644s/iter; left time: 92852.8867s\n",
      "29299it [1:21:19,  6.08it/s]\titers: 29300, epoch: 1 | loss: 0.3168116\n",
      "\tspeed: 0.1651s/iter; left time: 93270.9850s\n",
      "29399it [1:21:36,  5.99it/s]\titers: 29400, epoch: 1 | loss: 0.0754416\n",
      "\tspeed: 0.1657s/iter; left time: 93595.4010s\n",
      "29499it [1:21:52,  6.05it/s]\titers: 29500, epoch: 1 | loss: 0.1567690\n",
      "\tspeed: 0.1677s/iter; left time: 94657.3128s\n",
      "29599it [1:22:09,  6.06it/s]\titers: 29600, epoch: 1 | loss: 0.3342732\n",
      "\tspeed: 0.1659s/iter; left time: 93671.4432s\n",
      "29699it [1:22:26,  6.03it/s]\titers: 29700, epoch: 1 | loss: 0.1431380\n",
      "\tspeed: 0.1665s/iter; left time: 93974.1463s\n",
      "29705it [1:22:27,  6.00it/s]\n",
      "Epoch: 1 cost time: 4947.052392959595\n",
      "6481it [08:31, 12.68it/s]\n",
      "6457it [08:34, 12.54it/s]\n",
      "Epoch: 1 | Train Loss: 0.3084781 Vali Loss: 0.3033325 Test Loss: 0.3750699 MAE Loss: 0.4082166\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:16,  6.23it/s]\titers: 100, epoch: 2 | loss: 0.1476300\n",
      "\tspeed: 11.6906s/iter; left time: 6596944.7217s\n",
      "199it [00:32,  6.07it/s]\titers: 200, epoch: 2 | loss: 0.0733887\n",
      "\tspeed: 0.1633s/iter; left time: 92159.5524s\n",
      "299it [00:49,  6.19it/s]\titers: 300, epoch: 2 | loss: 0.0603053\n",
      "\tspeed: 0.1659s/iter; left time: 93586.8196s\n",
      "399it [01:05,  5.71it/s]\titers: 400, epoch: 2 | loss: 0.1261853\n",
      "\tspeed: 0.1639s/iter; left time: 92434.5573s\n",
      "499it [01:22,  6.08it/s]\titers: 500, epoch: 2 | loss: 0.2002185\n",
      "\tspeed: 0.1638s/iter; left time: 92384.9028s\n",
      "599it [01:38,  6.05it/s]\titers: 600, epoch: 2 | loss: 1.0302582\n",
      "\tspeed: 0.1657s/iter; left time: 93418.1660s\n",
      "699it [01:55,  6.09it/s]\titers: 700, epoch: 2 | loss: 0.6372427\n",
      "\tspeed: 0.1656s/iter; left time: 93349.5370s\n",
      "799it [02:11,  6.15it/s]\titers: 800, epoch: 2 | loss: 0.1129433\n",
      "\tspeed: 0.1634s/iter; left time: 92091.7606s\n",
      "899it [02:27,  6.11it/s]\titers: 900, epoch: 2 | loss: 0.1959215\n",
      "\tspeed: 0.1632s/iter; left time: 91969.6014s\n",
      "999it [02:44,  6.11it/s]\titers: 1000, epoch: 2 | loss: 0.2951171\n",
      "\tspeed: 0.1643s/iter; left time: 92573.9125s\n",
      "1099it [03:00,  6.17it/s]\titers: 1100, epoch: 2 | loss: 0.0648148\n",
      "\tspeed: 0.1643s/iter; left time: 92574.4794s\n",
      "1199it [03:17,  6.05it/s]\titers: 1200, epoch: 2 | loss: 0.0807365\n",
      "\tspeed: 0.1638s/iter; left time: 92247.0448s\n",
      "1299it [03:33,  6.11it/s]\titers: 1300, epoch: 2 | loss: 0.4055331\n",
      "\tspeed: 0.1643s/iter; left time: 92539.5001s\n",
      "1399it [03:50,  6.07it/s]\titers: 1400, epoch: 2 | loss: 0.3168083\n",
      "\tspeed: 0.1655s/iter; left time: 93156.4269s\n",
      "1499it [04:06,  6.17it/s]\titers: 1500, epoch: 2 | loss: 0.0836687\n",
      "\tspeed: 0.1674s/iter; left time: 94251.2590s\n",
      "1599it [04:23,  5.89it/s]\titers: 1600, epoch: 2 | loss: 0.1215605\n",
      "\tspeed: 0.1653s/iter; left time: 93024.4759s\n",
      "1699it [04:39,  6.06it/s]\titers: 1700, epoch: 2 | loss: 0.1799752\n",
      "\tspeed: 0.1652s/iter; left time: 92937.0100s\n",
      "1799it [04:56,  5.99it/s]\titers: 1800, epoch: 2 | loss: 0.2842595\n",
      "\tspeed: 0.1654s/iter; left time: 93025.7521s\n",
      "1899it [05:13,  6.09it/s]\titers: 1900, epoch: 2 | loss: 0.1091686\n",
      "\tspeed: 0.1661s/iter; left time: 93422.1683s\n",
      "1999it [05:29,  6.13it/s]\titers: 2000, epoch: 2 | loss: 0.1582393\n",
      "\tspeed: 0.1667s/iter; left time: 93772.8848s\n",
      "2099it [05:46,  5.02it/s]\titers: 2100, epoch: 2 | loss: 1.9941553\n",
      "\tspeed: 0.1671s/iter; left time: 93954.8021s\n",
      "2199it [06:02,  6.02it/s]\titers: 2200, epoch: 2 | loss: 0.1024483\n",
      "\tspeed: 0.1641s/iter; left time: 92264.8366s\n",
      "2299it [06:19,  6.10it/s]\titers: 2300, epoch: 2 | loss: 0.2359404\n",
      "\tspeed: 0.1663s/iter; left time: 93462.9282s\n",
      "2399it [06:35,  6.07it/s]\titers: 2400, epoch: 2 | loss: 0.1485652\n",
      "\tspeed: 0.1644s/iter; left time: 92368.9168s\n",
      "2499it [06:52,  6.10it/s]\titers: 2500, epoch: 2 | loss: 1.0053369\n",
      "\tspeed: 0.1647s/iter; left time: 92521.9740s\n",
      "2599it [07:08,  6.02it/s]\titers: 2600, epoch: 2 | loss: 1.3658199\n",
      "\tspeed: 0.1649s/iter; left time: 92659.4120s\n",
      "2699it [07:25,  6.03it/s]\titers: 2700, epoch: 2 | loss: 0.0778381\n",
      "\tspeed: 0.1654s/iter; left time: 92888.6354s\n",
      "2799it [07:42,  6.03it/s]\titers: 2800, epoch: 2 | loss: 0.0841954\n",
      "\tspeed: 0.1654s/iter; left time: 92898.9964s\n",
      "2899it [07:58,  6.06it/s]\titers: 2900, epoch: 2 | loss: 0.1298243\n",
      "\tspeed: 0.1668s/iter; left time: 93636.6921s\n",
      "2999it [08:15,  6.02it/s]\titers: 3000, epoch: 2 | loss: 0.3117059\n",
      "\tspeed: 0.1654s/iter; left time: 92858.5790s\n",
      "3099it [08:31,  6.14it/s]\titers: 3100, epoch: 2 | loss: 0.4376058\n",
      "\tspeed: 0.1660s/iter; left time: 93181.4680s\n",
      "3199it [08:48,  6.04it/s]\titers: 3200, epoch: 2 | loss: 0.4144229\n",
      "\tspeed: 0.1642s/iter; left time: 92162.0553s\n",
      "3299it [09:04,  6.08it/s]\titers: 3300, epoch: 2 | loss: 0.0474750\n",
      "\tspeed: 0.1646s/iter; left time: 92359.4211s\n",
      "3399it [09:21,  5.97it/s]\titers: 3400, epoch: 2 | loss: 0.0598363\n",
      "\tspeed: 0.1659s/iter; left time: 93053.6137s\n",
      "3499it [09:37,  6.14it/s]\titers: 3500, epoch: 2 | loss: 0.1289276\n",
      "\tspeed: 0.1669s/iter; left time: 93629.0953s\n",
      "3599it [09:54,  6.05it/s]\titers: 3600, epoch: 2 | loss: 0.0932073\n",
      "\tspeed: 0.1671s/iter; left time: 93718.2855s\n",
      "3699it [10:11,  6.12it/s]\titers: 3700, epoch: 2 | loss: 0.5414150\n",
      "\tspeed: 0.1655s/iter; left time: 92773.5061s\n",
      "3799it [10:27,  5.81it/s]\titers: 3800, epoch: 2 | loss: 0.1113951\n",
      "\tspeed: 0.1654s/iter; left time: 92721.3098s\n",
      "3899it [10:44,  6.07it/s]\titers: 3900, epoch: 2 | loss: 0.0785010\n",
      "\tspeed: 0.1647s/iter; left time: 92338.2290s\n",
      "3999it [11:00,  6.00it/s]\titers: 4000, epoch: 2 | loss: 0.1791601\n",
      "\tspeed: 0.1654s/iter; left time: 92709.7907s\n",
      "4099it [11:17,  6.06it/s]\titers: 4100, epoch: 2 | loss: 0.0976131\n",
      "\tspeed: 0.1656s/iter; left time: 92792.4166s\n",
      "4199it [11:34,  5.99it/s]\titers: 4200, epoch: 2 | loss: 0.3682707\n",
      "\tspeed: 0.1671s/iter; left time: 93603.2264s\n",
      "4299it [11:50,  6.02it/s]\titers: 4300, epoch: 2 | loss: 0.2283959\n",
      "\tspeed: 0.1657s/iter; left time: 92810.5121s\n",
      "4399it [12:07,  6.11it/s]\titers: 4400, epoch: 2 | loss: 0.2884372\n",
      "\tspeed: 0.1675s/iter; left time: 93771.5445s\n",
      "4499it [12:24,  5.43it/s]\titers: 4500, epoch: 2 | loss: 0.2785695\n",
      "\tspeed: 0.1683s/iter; left time: 94203.5502s\n",
      "4599it [12:40,  5.98it/s]\titers: 4600, epoch: 2 | loss: 0.1764796\n",
      "\tspeed: 0.1653s/iter; left time: 92548.1818s\n",
      "4699it [12:57,  6.11it/s]\titers: 4700, epoch: 2 | loss: 0.0550034\n",
      "\tspeed: 0.1674s/iter; left time: 93714.7427s\n",
      "4799it [13:14,  6.01it/s]\titers: 4800, epoch: 2 | loss: 0.1479438\n",
      "\tspeed: 0.1686s/iter; left time: 94357.9994s\n",
      "4899it [13:31,  6.03it/s]\titers: 4900, epoch: 2 | loss: 0.1731054\n",
      "\tspeed: 0.1677s/iter; left time: 93809.3095s\n",
      "4999it [13:47,  6.07it/s]\titers: 5000, epoch: 2 | loss: 0.1433186\n",
      "\tspeed: 0.1658s/iter; left time: 92744.2447s\n",
      "5099it [14:04,  5.45it/s]\titers: 5100, epoch: 2 | loss: 0.0721829\n",
      "\tspeed: 0.1663s/iter; left time: 92983.5134s\n",
      "5199it [14:20,  6.01it/s]\titers: 5200, epoch: 2 | loss: 0.5390909\n",
      "\tspeed: 0.1659s/iter; left time: 92772.9571s\n",
      "5299it [14:37,  6.10it/s]\titers: 5300, epoch: 2 | loss: 0.1409254\n",
      "\tspeed: 0.1663s/iter; left time: 92996.4046s\n",
      "5399it [14:53,  6.04it/s]\titers: 5400, epoch: 2 | loss: 0.2940744\n",
      "\tspeed: 0.1638s/iter; left time: 91589.5940s\n",
      "5499it [15:10,  6.10it/s]\titers: 5500, epoch: 2 | loss: 0.0336484\n",
      "\tspeed: 0.1642s/iter; left time: 91763.4108s\n",
      "5599it [15:26,  6.01it/s]\titers: 5600, epoch: 2 | loss: 0.1316083\n",
      "\tspeed: 0.1648s/iter; left time: 92076.7551s\n",
      "5699it [15:43,  6.10it/s]\titers: 5700, epoch: 2 | loss: 0.2799419\n",
      "\tspeed: 0.1642s/iter; left time: 91752.7371s\n",
      "5799it [15:59,  6.05it/s]\titers: 5800, epoch: 2 | loss: 0.3097433\n",
      "\tspeed: 0.1641s/iter; left time: 91674.0037s\n",
      "5899it [16:16,  6.13it/s]\titers: 5900, epoch: 2 | loss: 0.0529920\n",
      "\tspeed: 0.1639s/iter; left time: 91554.6281s\n",
      "5999it [16:32,  6.09it/s]\titers: 6000, epoch: 2 | loss: 0.1546302\n",
      "\tspeed: 0.1640s/iter; left time: 91571.0375s\n",
      "6099it [16:48,  6.11it/s]\titers: 6100, epoch: 2 | loss: 0.0982659\n",
      "\tspeed: 0.1639s/iter; left time: 91489.4887s\n",
      "6199it [17:05,  6.05it/s]\titers: 6200, epoch: 2 | loss: 0.3280897\n",
      "\tspeed: 0.1641s/iter; left time: 91581.4121s\n",
      "6299it [17:21,  6.12it/s]\titers: 6300, epoch: 2 | loss: 0.1992609\n",
      "\tspeed: 0.1640s/iter; left time: 91510.1859s\n",
      "6399it [17:38,  6.09it/s]\titers: 6400, epoch: 2 | loss: 0.0682657\n",
      "\tspeed: 0.1639s/iter; left time: 91475.2397s\n",
      "6499it [17:54,  6.11it/s]\titers: 6500, epoch: 2 | loss: 0.2286790\n",
      "\tspeed: 0.1641s/iter; left time: 91553.7481s\n",
      "6599it [18:10,  6.06it/s]\titers: 6600, epoch: 2 | loss: 0.0671935\n",
      "\tspeed: 0.1640s/iter; left time: 91488.0971s\n",
      "6699it [18:27,  6.13it/s]\titers: 6700, epoch: 2 | loss: 1.6461879\n",
      "\tspeed: 0.1634s/iter; left time: 91119.6517s\n",
      "6799it [18:43,  6.07it/s]\titers: 6800, epoch: 2 | loss: 0.0826742\n",
      "\tspeed: 0.1634s/iter; left time: 91115.6753s\n",
      "6899it [18:59,  6.11it/s]\titers: 6900, epoch: 2 | loss: 0.1386496\n",
      "\tspeed: 0.1633s/iter; left time: 91034.3140s\n",
      "6999it [19:16,  6.05it/s]\titers: 7000, epoch: 2 | loss: 0.1215942\n",
      "\tspeed: 0.1635s/iter; left time: 91133.7498s\n",
      "7099it [19:32,  6.14it/s]\titers: 7100, epoch: 2 | loss: 0.0612039\n",
      "\tspeed: 0.1635s/iter; left time: 91137.9761s\n",
      "7199it [19:48,  6.09it/s]\titers: 7200, epoch: 2 | loss: 0.6688268\n",
      "\tspeed: 0.1636s/iter; left time: 91164.5715s\n",
      "7299it [20:05,  6.13it/s]\titers: 7300, epoch: 2 | loss: 0.0585072\n",
      "\tspeed: 0.1635s/iter; left time: 91076.2805s\n",
      "7399it [20:21,  6.07it/s]\titers: 7400, epoch: 2 | loss: 0.1183116\n",
      "\tspeed: 0.1637s/iter; left time: 91178.2898s\n",
      "7499it [20:38,  6.08it/s]\titers: 7500, epoch: 2 | loss: 0.1484357\n",
      "\tspeed: 0.1635s/iter; left time: 91062.3500s\n",
      "7599it [20:54,  6.05it/s]\titers: 7600, epoch: 2 | loss: 0.1444309\n",
      "\tspeed: 0.1637s/iter; left time: 91124.4551s\n",
      "7699it [21:10,  6.15it/s]\titers: 7700, epoch: 2 | loss: 0.1383824\n",
      "\tspeed: 0.1641s/iter; left time: 91365.1224s\n",
      "7799it [21:27,  6.04it/s]\titers: 7800, epoch: 2 | loss: 0.0650591\n",
      "\tspeed: 0.1638s/iter; left time: 91161.1548s\n",
      "7899it [21:43,  6.08it/s]\titers: 7900, epoch: 2 | loss: 0.1277667\n",
      "\tspeed: 0.1634s/iter; left time: 90954.0796s\n",
      "7999it [21:59,  6.08it/s]\titers: 8000, epoch: 2 | loss: 0.1670485\n",
      "\tspeed: 0.1635s/iter; left time: 90988.3355s\n",
      "8099it [22:16,  6.06it/s]\titers: 8100, epoch: 2 | loss: 0.2256121\n",
      "\tspeed: 0.1640s/iter; left time: 91245.3501s\n",
      "8199it [22:32,  6.04it/s]\titers: 8200, epoch: 2 | loss: 0.2022997\n",
      "\tspeed: 0.1633s/iter; left time: 90831.9038s\n",
      "8299it [22:48,  6.14it/s]\titers: 8300, epoch: 2 | loss: 0.0447309\n",
      "\tspeed: 0.1634s/iter; left time: 90882.2532s\n",
      "8399it [23:05,  6.02it/s]\titers: 8400, epoch: 2 | loss: 0.4017943\n",
      "\tspeed: 0.1639s/iter; left time: 91111.8047s\n",
      "8499it [23:21,  6.13it/s]\titers: 8500, epoch: 2 | loss: 0.2014034\n",
      "\tspeed: 0.1630s/iter; left time: 90622.7825s\n",
      "8599it [23:37,  6.07it/s]\titers: 8600, epoch: 2 | loss: 0.3413974\n",
      "\tspeed: 0.1635s/iter; left time: 90859.8117s\n",
      "8699it [23:54,  6.12it/s]\titers: 8700, epoch: 2 | loss: 0.1789502\n",
      "\tspeed: 0.1631s/iter; left time: 90655.1041s\n",
      "8799it [24:10,  6.12it/s]\titers: 8800, epoch: 2 | loss: 0.3219842\n",
      "\tspeed: 0.1629s/iter; left time: 90494.8240s\n",
      "8899it [24:26,  6.13it/s]\titers: 8900, epoch: 2 | loss: 0.2712420\n",
      "\tspeed: 0.1632s/iter; left time: 90663.9768s\n",
      "8999it [24:43,  6.08it/s]\titers: 9000, epoch: 2 | loss: 0.3052200\n",
      "\tspeed: 0.1633s/iter; left time: 90715.0358s\n",
      "9099it [24:59,  6.13it/s]\titers: 9100, epoch: 2 | loss: 0.2243119\n",
      "\tspeed: 0.1630s/iter; left time: 90536.8905s\n",
      "9199it [25:15,  6.07it/s]\titers: 9200, epoch: 2 | loss: 0.0843751\n",
      "\tspeed: 0.1631s/iter; left time: 90554.9836s\n",
      "9299it [25:32,  6.16it/s]\titers: 9300, epoch: 2 | loss: 0.2713581\n",
      "\tspeed: 0.1633s/iter; left time: 90670.9098s\n",
      "9399it [25:48,  6.08it/s]\titers: 9400, epoch: 2 | loss: 0.1134811\n",
      "\tspeed: 0.1634s/iter; left time: 90693.3206s\n",
      "9499it [26:04,  6.15it/s]\titers: 9500, epoch: 2 | loss: 0.2870037\n",
      "\tspeed: 0.1631s/iter; left time: 90516.2762s\n",
      "9599it [26:21,  6.09it/s]\titers: 9600, epoch: 2 | loss: 0.0646567\n",
      "\tspeed: 0.1634s/iter; left time: 90639.4267s\n",
      "9699it [26:37,  6.15it/s]\titers: 9700, epoch: 2 | loss: 0.0904000\n",
      "\tspeed: 0.1633s/iter; left time: 90576.5558s\n",
      "9799it [26:53,  6.06it/s]\titers: 9800, epoch: 2 | loss: 0.2439189\n",
      "\tspeed: 0.1631s/iter; left time: 90471.8734s\n",
      "9899it [27:10,  6.14it/s]\titers: 9900, epoch: 2 | loss: 0.6999472\n",
      "\tspeed: 0.1634s/iter; left time: 90593.9045s\n",
      "9999it [27:26,  6.07it/s]\titers: 10000, epoch: 2 | loss: 0.1530704\n",
      "\tspeed: 0.1636s/iter; left time: 90692.5959s\n",
      "10099it [27:42,  6.12it/s]\titers: 10100, epoch: 2 | loss: 0.2030766\n",
      "\tspeed: 0.1637s/iter; left time: 90735.3815s\n",
      "10199it [27:59,  6.08it/s]\titers: 10200, epoch: 2 | loss: 0.2323625\n",
      "\tspeed: 0.1636s/iter; left time: 90667.8365s\n",
      "10299it [28:15,  6.20it/s]\titers: 10300, epoch: 2 | loss: 0.1380421\n",
      "\tspeed: 0.1636s/iter; left time: 90628.2453s\n",
      "10399it [28:31,  6.10it/s]\titers: 10400, epoch: 2 | loss: 0.4256867\n",
      "\tspeed: 0.1636s/iter; left time: 90641.0201s\n",
      "10499it [28:48,  6.14it/s]\titers: 10500, epoch: 2 | loss: 0.0812482\n",
      "\tspeed: 0.1641s/iter; left time: 90904.0985s\n",
      "10599it [29:04,  6.09it/s]\titers: 10600, epoch: 2 | loss: 0.0539595\n",
      "\tspeed: 0.1638s/iter; left time: 90724.2311s\n",
      "10699it [29:21,  6.09it/s]\titers: 10700, epoch: 2 | loss: 0.1126816\n",
      "\tspeed: 0.1639s/iter; left time: 90761.8006s\n",
      "10799it [29:37,  6.09it/s]\titers: 10800, epoch: 2 | loss: 0.3763274\n",
      "\tspeed: 0.1640s/iter; left time: 90781.0848s\n",
      "10899it [29:53,  6.10it/s]\titers: 10900, epoch: 2 | loss: 0.1361880\n",
      "\tspeed: 0.1639s/iter; left time: 90696.6208s\n",
      "10999it [30:10,  6.07it/s]\titers: 11000, epoch: 2 | loss: 0.1199333\n",
      "\tspeed: 0.1642s/iter; left time: 90888.5546s\n",
      "11099it [30:26,  6.07it/s]\titers: 11100, epoch: 2 | loss: 0.2762271\n",
      "\tspeed: 0.1646s/iter; left time: 91068.0815s\n",
      "11199it [30:43,  6.07it/s]\titers: 11200, epoch: 2 | loss: 0.5847563\n",
      "\tspeed: 0.1636s/iter; left time: 90523.0498s\n",
      "11299it [30:59,  6.13it/s]\titers: 11300, epoch: 2 | loss: 0.1646081\n",
      "\tspeed: 0.1641s/iter; left time: 90757.7147s\n",
      "11399it [31:15,  6.04it/s]\titers: 11400, epoch: 2 | loss: 0.2520775\n",
      "\tspeed: 0.1641s/iter; left time: 90742.5279s\n",
      "11499it [31:32,  6.11it/s]\titers: 11500, epoch: 2 | loss: 0.0396859\n",
      "\tspeed: 0.1643s/iter; left time: 90815.6433s\n",
      "11599it [31:48,  6.04it/s]\titers: 11600, epoch: 2 | loss: 0.1175538\n",
      "\tspeed: 0.1641s/iter; left time: 90729.4064s\n",
      "11699it [32:05,  6.07it/s]\titers: 11700, epoch: 2 | loss: 0.0941740\n",
      "\tspeed: 0.1645s/iter; left time: 90894.9879s\n",
      "11799it [32:21,  6.10it/s]\titers: 11800, epoch: 2 | loss: 0.1934090\n",
      "\tspeed: 0.1640s/iter; left time: 90618.5089s\n",
      "11899it [32:38,  6.16it/s]\titers: 11900, epoch: 2 | loss: 0.2396995\n",
      "\tspeed: 0.1641s/iter; left time: 90648.2391s\n",
      "11999it [32:54,  5.99it/s]\titers: 12000, epoch: 2 | loss: 0.2731007\n",
      "\tspeed: 0.1636s/iter; left time: 90372.9860s\n",
      "12099it [33:10,  6.16it/s]\titers: 12100, epoch: 2 | loss: 0.1721079\n",
      "\tspeed: 0.1637s/iter; left time: 90389.1659s\n",
      "12199it [33:27,  6.14it/s]\titers: 12200, epoch: 2 | loss: 0.1369260\n",
      "\tspeed: 0.1633s/iter; left time: 90148.7080s\n",
      "12299it [33:43,  6.07it/s]\titers: 12300, epoch: 2 | loss: 0.0951414\n",
      "\tspeed: 0.1638s/iter; left time: 90446.1844s\n",
      "12399it [33:59,  6.07it/s]\titers: 12400, epoch: 2 | loss: 0.1541999\n",
      "\tspeed: 0.1637s/iter; left time: 90377.0280s\n",
      "12499it [34:16,  6.13it/s]\titers: 12500, epoch: 2 | loss: 0.0471042\n",
      "\tspeed: 0.1639s/iter; left time: 90446.9192s\n",
      "12599it [34:32,  6.06it/s]\titers: 12600, epoch: 2 | loss: 0.0308776\n",
      "\tspeed: 0.1636s/iter; left time: 90282.8539s\n",
      "12699it [34:49,  6.10it/s]\titers: 12700, epoch: 2 | loss: 0.0701100\n",
      "\tspeed: 0.1640s/iter; left time: 90450.6446s\n",
      "12799it [35:05,  6.08it/s]\titers: 12800, epoch: 2 | loss: 0.0669385\n",
      "\tspeed: 0.1639s/iter; left time: 90400.6249s\n",
      "12899it [35:21,  6.14it/s]\titers: 12900, epoch: 2 | loss: 0.0891679\n",
      "\tspeed: 0.1637s/iter; left time: 90256.3177s\n",
      "12999it [35:38,  6.04it/s]\titers: 13000, epoch: 2 | loss: 0.1828417\n",
      "\tspeed: 0.1641s/iter; left time: 90471.0245s\n",
      "13099it [35:54,  6.07it/s]\titers: 13100, epoch: 2 | loss: 0.3546188\n",
      "\tspeed: 0.1639s/iter; left time: 90344.0962s\n",
      "13199it [36:10,  6.13it/s]\titers: 13200, epoch: 2 | loss: 0.1729181\n",
      "\tspeed: 0.1634s/iter; left time: 90079.0445s\n",
      "13299it [36:27,  6.08it/s]\titers: 13300, epoch: 2 | loss: 0.1311955\n",
      "\tspeed: 0.1636s/iter; left time: 90142.8154s\n",
      "13399it [36:43,  6.08it/s]\titers: 13400, epoch: 2 | loss: 0.0642410\n",
      "\tspeed: 0.1640s/iter; left time: 90339.5906s\n",
      "13499it [37:00,  6.08it/s]\titers: 13500, epoch: 2 | loss: 0.0427569\n",
      "\tspeed: 0.1638s/iter; left time: 90219.9652s\n",
      "13599it [37:16,  6.09it/s]\titers: 13600, epoch: 2 | loss: 0.1724524\n",
      "\tspeed: 0.1641s/iter; left time: 90401.1842s\n",
      "13699it [37:32,  6.10it/s]\titers: 13700, epoch: 2 | loss: 0.3992647\n",
      "\tspeed: 0.1640s/iter; left time: 90287.1500s\n",
      "13799it [37:49,  6.07it/s]\titers: 13800, epoch: 2 | loss: 0.1464934\n",
      "\tspeed: 0.1638s/iter; left time: 90199.8994s\n",
      "13899it [38:05,  6.07it/s]\titers: 13900, epoch: 2 | loss: 0.4505351\n",
      "\tspeed: 0.1633s/iter; left time: 89909.4848s\n",
      "13999it [38:21,  6.10it/s]\titers: 14000, epoch: 2 | loss: 0.0565163\n",
      "\tspeed: 0.1637s/iter; left time: 90103.6301s\n",
      "14099it [38:38,  6.17it/s]\titers: 14100, epoch: 2 | loss: 0.1715777\n",
      "\tspeed: 0.1637s/iter; left time: 90088.1096s\n",
      "14199it [38:54,  6.09it/s]\titers: 14200, epoch: 2 | loss: 0.2727892\n",
      "\tspeed: 0.1638s/iter; left time: 90119.3455s\n",
      "14299it [39:11,  6.11it/s]\titers: 14300, epoch: 2 | loss: 0.0557815\n",
      "\tspeed: 0.1635s/iter; left time: 89954.9230s\n",
      "14399it [39:27,  6.03it/s]\titers: 14400, epoch: 2 | loss: 0.9813871\n",
      "\tspeed: 0.1636s/iter; left time: 89988.8585s\n",
      "14499it [39:43,  6.12it/s]\titers: 14500, epoch: 2 | loss: 0.0688428\n",
      "\tspeed: 0.1641s/iter; left time: 90224.6321s\n",
      "14599it [40:00,  6.05it/s]\titers: 14600, epoch: 2 | loss: 0.0683084\n",
      "\tspeed: 0.1640s/iter; left time: 90141.9025s\n",
      "14699it [40:16,  6.11it/s]\titers: 14700, epoch: 2 | loss: 0.2685004\n",
      "\tspeed: 0.1632s/iter; left time: 89734.8147s\n",
      "14799it [40:32,  6.08it/s]\titers: 14800, epoch: 2 | loss: 0.1796795\n",
      "\tspeed: 0.1640s/iter; left time: 90161.0677s\n",
      "14899it [40:49,  6.10it/s]\titers: 14900, epoch: 2 | loss: 0.0728162\n",
      "\tspeed: 0.1638s/iter; left time: 90009.7604s\n",
      "14999it [41:05,  6.10it/s]\titers: 15000, epoch: 2 | loss: 0.1362587\n",
      "\tspeed: 0.1636s/iter; left time: 89893.7479s\n",
      "15099it [41:22,  6.16it/s]\titers: 15100, epoch: 2 | loss: 0.1119214\n",
      "\tspeed: 0.1636s/iter; left time: 89879.0947s\n",
      "15199it [41:38,  6.10it/s]\titers: 15200, epoch: 2 | loss: 0.2610802\n",
      "\tspeed: 0.1636s/iter; left time: 89829.5208s\n",
      "15299it [41:54,  6.11it/s]\titers: 15300, epoch: 2 | loss: 0.5228898\n",
      "\tspeed: 0.1641s/iter; left time: 90097.1719s\n",
      "15399it [42:11,  6.06it/s]\titers: 15400, epoch: 2 | loss: 0.1516881\n",
      "\tspeed: 0.1637s/iter; left time: 89884.9496s\n",
      "15499it [42:27,  6.13it/s]\titers: 15500, epoch: 2 | loss: 0.4939700\n",
      "\tspeed: 0.1635s/iter; left time: 89763.6924s\n",
      "15599it [42:43,  6.09it/s]\titers: 15600, epoch: 2 | loss: 0.2130433\n",
      "\tspeed: 0.1637s/iter; left time: 89826.8928s\n",
      "15699it [43:00,  6.09it/s]\titers: 15700, epoch: 2 | loss: 0.4385494\n",
      "\tspeed: 0.1639s/iter; left time: 89919.9800s\n",
      "15799it [43:16,  6.06it/s]\titers: 15800, epoch: 2 | loss: 0.1094949\n",
      "\tspeed: 0.1636s/iter; left time: 89755.5892s\n",
      "15899it [43:33,  6.08it/s]\titers: 15900, epoch: 2 | loss: 0.1018843\n",
      "\tspeed: 0.1635s/iter; left time: 89670.4018s\n",
      "15999it [43:49,  6.10it/s]\titers: 16000, epoch: 2 | loss: 0.3152764\n",
      "\tspeed: 0.1636s/iter; left time: 89725.6548s\n",
      "16099it [44:05,  6.15it/s]\titers: 16100, epoch: 2 | loss: 0.2274127\n",
      "\tspeed: 0.1635s/iter; left time: 89638.8566s\n",
      "16199it [44:22,  6.07it/s]\titers: 16200, epoch: 2 | loss: 0.6733568\n",
      "\tspeed: 0.1635s/iter; left time: 89616.7755s\n",
      "16299it [44:38,  6.15it/s]\titers: 16300, epoch: 2 | loss: 0.1144959\n",
      "\tspeed: 0.1635s/iter; left time: 89593.3675s\n",
      "16399it [44:54,  6.08it/s]\titers: 16400, epoch: 2 | loss: 0.1239258\n",
      "\tspeed: 0.1633s/iter; left time: 89487.0095s\n",
      "16499it [45:11,  6.12it/s]\titers: 16500, epoch: 2 | loss: 0.1110008\n",
      "\tspeed: 0.1640s/iter; left time: 89850.6534s\n",
      "16599it [45:27,  6.13it/s]\titers: 16600, epoch: 2 | loss: 0.0690162\n",
      "\tspeed: 0.1635s/iter; left time: 89547.6812s\n",
      "16699it [45:43,  6.14it/s]\titers: 16700, epoch: 2 | loss: 0.3534371\n",
      "\tspeed: 0.1636s/iter; left time: 89612.1495s\n",
      "16799it [46:00,  6.07it/s]\titers: 16800, epoch: 2 | loss: 0.2597807\n",
      "\tspeed: 0.1639s/iter; left time: 89726.5134s\n",
      "16899it [46:16,  6.12it/s]\titers: 16900, epoch: 2 | loss: 0.4077452\n",
      "\tspeed: 0.1635s/iter; left time: 89530.8418s\n",
      "16999it [46:32,  6.03it/s]\titers: 17000, epoch: 2 | loss: 0.3823028\n",
      "\tspeed: 0.1638s/iter; left time: 89666.9278s\n",
      "17099it [46:49,  6.12it/s]\titers: 17100, epoch: 2 | loss: 0.2265569\n",
      "\tspeed: 0.1637s/iter; left time: 89567.9838s\n",
      "17199it [47:05,  6.06it/s]\titers: 17200, epoch: 2 | loss: 0.4334850\n",
      "\tspeed: 0.1637s/iter; left time: 89569.4576s\n",
      "17299it [47:22,  6.13it/s]\titers: 17300, epoch: 2 | loss: 0.1963412\n",
      "\tspeed: 0.1633s/iter; left time: 89354.5532s\n",
      "17399it [47:38,  6.05it/s]\titers: 17400, epoch: 2 | loss: 0.1095516\n",
      "\tspeed: 0.1638s/iter; left time: 89585.5248s\n",
      "17499it [47:54,  6.12it/s]\titers: 17500, epoch: 2 | loss: 0.0825618\n",
      "\tspeed: 0.1636s/iter; left time: 89468.7427s\n",
      "17599it [48:11,  6.05it/s]\titers: 17600, epoch: 2 | loss: 0.1524411\n",
      "\tspeed: 0.1637s/iter; left time: 89495.2230s\n",
      "17699it [48:27,  6.11it/s]\titers: 17700, epoch: 2 | loss: 0.2420819\n",
      "\tspeed: 0.1632s/iter; left time: 89241.5426s\n",
      "17799it [48:43,  6.06it/s]\titers: 17800, epoch: 2 | loss: 0.0921118\n",
      "\tspeed: 0.1638s/iter; left time: 89511.9719s\n",
      "17899it [49:00,  6.12it/s]\titers: 17900, epoch: 2 | loss: 0.4133547\n",
      "\tspeed: 0.1633s/iter; left time: 89259.4637s\n",
      "17999it [49:16,  6.07it/s]\titers: 18000, epoch: 2 | loss: 0.3019810\n",
      "\tspeed: 0.1629s/iter; left time: 89033.2628s\n",
      "18099it [49:32,  6.13it/s]\titers: 18100, epoch: 2 | loss: 0.0768021\n",
      "\tspeed: 0.1633s/iter; left time: 89224.5639s\n",
      "18199it [49:49,  6.10it/s]\titers: 18200, epoch: 2 | loss: 0.1341782\n",
      "\tspeed: 0.1632s/iter; left time: 89163.2925s\n",
      "18299it [50:05,  6.18it/s]\titers: 18300, epoch: 2 | loss: 1.1329545\n",
      "\tspeed: 0.1635s/iter; left time: 89270.1836s\n",
      "18399it [50:21,  6.11it/s]\titers: 18400, epoch: 2 | loss: 0.1400969\n",
      "\tspeed: 0.1634s/iter; left time: 89200.4425s\n",
      "18499it [50:38,  6.18it/s]\titers: 18500, epoch: 2 | loss: 0.1291327\n",
      "\tspeed: 0.1632s/iter; left time: 89078.1409s\n",
      "18599it [50:54,  6.06it/s]\titers: 18600, epoch: 2 | loss: 0.1632121\n",
      "\tspeed: 0.1641s/iter; left time: 89552.7840s\n",
      "18699it [51:10,  6.08it/s]\titers: 18700, epoch: 2 | loss: 0.0570602\n",
      "\tspeed: 0.1639s/iter; left time: 89454.7815s\n",
      "18799it [51:27,  6.13it/s]\titers: 18800, epoch: 2 | loss: 0.0941457\n",
      "\tspeed: 0.1635s/iter; left time: 89227.8149s\n",
      "18899it [51:43,  6.16it/s]\titers: 18900, epoch: 2 | loss: 0.0846936\n",
      "\tspeed: 0.1635s/iter; left time: 89191.0496s\n",
      "18999it [51:59,  6.06it/s]\titers: 19000, epoch: 2 | loss: 0.1708645\n",
      "\tspeed: 0.1633s/iter; left time: 89085.9260s\n",
      "19099it [52:16,  6.13it/s]\titers: 19100, epoch: 2 | loss: 0.0569132\n",
      "\tspeed: 0.1641s/iter; left time: 89468.3103s\n",
      "19199it [52:32,  6.05it/s]\titers: 19200, epoch: 2 | loss: 0.3082506\n",
      "\tspeed: 0.1639s/iter; left time: 89365.9908s\n",
      "19299it [52:49,  6.13it/s]\titers: 19300, epoch: 2 | loss: 0.0822608\n",
      "\tspeed: 0.1631s/iter; left time: 88918.9877s\n",
      "19399it [53:05,  6.10it/s]\titers: 19400, epoch: 2 | loss: 0.1902982\n",
      "\tspeed: 0.1633s/iter; left time: 88999.1419s\n",
      "19499it [53:21,  6.10it/s]\titers: 19500, epoch: 2 | loss: 0.1236868\n",
      "\tspeed: 0.1638s/iter; left time: 89249.4808s\n",
      "19599it [53:38,  6.08it/s]\titers: 19600, epoch: 2 | loss: 0.7589589\n",
      "\tspeed: 0.1634s/iter; left time: 89029.9688s\n",
      "19699it [53:54,  6.11it/s]\titers: 19700, epoch: 2 | loss: 0.7897795\n",
      "\tspeed: 0.1634s/iter; left time: 89017.2306s\n",
      "19799it [54:10,  6.08it/s]\titers: 19800, epoch: 2 | loss: 0.2427908\n",
      "\tspeed: 0.1634s/iter; left time: 88998.3770s\n",
      "19899it [54:27,  6.11it/s]\titers: 19900, epoch: 2 | loss: 0.2450962\n",
      "\tspeed: 0.1634s/iter; left time: 88959.8061s\n",
      "19999it [54:43,  6.07it/s]\titers: 20000, epoch: 2 | loss: 0.0713729\n",
      "\tspeed: 0.1631s/iter; left time: 88804.2613s\n",
      "20099it [54:59,  6.14it/s]\titers: 20100, epoch: 2 | loss: 0.1993112\n",
      "\tspeed: 0.1632s/iter; left time: 88851.0160s\n",
      "20199it [55:16,  6.13it/s]\titers: 20200, epoch: 2 | loss: 0.2712132\n",
      "\tspeed: 0.1632s/iter; left time: 88819.6465s\n",
      "20299it [55:32,  6.12it/s]\titers: 20300, epoch: 2 | loss: 0.3151533\n",
      "\tspeed: 0.1634s/iter; left time: 88906.7375s\n",
      "20399it [55:48,  6.08it/s]\titers: 20400, epoch: 2 | loss: 0.1993435\n",
      "\tspeed: 0.1634s/iter; left time: 88892.7007s\n",
      "20499it [56:05,  6.10it/s]\titers: 20500, epoch: 2 | loss: 0.1694256\n",
      "\tspeed: 0.1635s/iter; left time: 88904.7770s\n",
      "20599it [56:21,  6.09it/s]\titers: 20600, epoch: 2 | loss: 0.0695782\n",
      "\tspeed: 0.1637s/iter; left time: 89019.2892s\n",
      "20699it [56:37,  6.09it/s]\titers: 20700, epoch: 2 | loss: 0.1268817\n",
      "\tspeed: 0.1635s/iter; left time: 88882.2337s\n",
      "20799it [56:54,  6.07it/s]\titers: 20800, epoch: 2 | loss: 0.3134364\n",
      "\tspeed: 0.1638s/iter; left time: 89045.8674s\n",
      "20899it [57:10,  6.10it/s]\titers: 20900, epoch: 2 | loss: 0.4508135\n",
      "\tspeed: 0.1639s/iter; left time: 89095.8546s\n",
      "20999it [57:26,  6.10it/s]\titers: 21000, epoch: 2 | loss: 0.3376225\n",
      "\tspeed: 0.1637s/iter; left time: 88947.9961s\n",
      "21099it [57:43,  6.09it/s]\titers: 21100, epoch: 2 | loss: 0.0641273\n",
      "\tspeed: 0.1647s/iter; left time: 89465.2039s\n",
      "21199it [57:59,  6.09it/s]\titers: 21200, epoch: 2 | loss: 0.0712917\n",
      "\tspeed: 0.1643s/iter; left time: 89244.5933s\n",
      "21299it [58:16,  6.11it/s]\titers: 21300, epoch: 2 | loss: 0.1588763\n",
      "\tspeed: 0.1640s/iter; left time: 89080.0701s\n",
      "21399it [58:32,  6.01it/s]\titers: 21400, epoch: 2 | loss: 0.3313339\n",
      "\tspeed: 0.1642s/iter; left time: 89178.7917s\n",
      "21499it [58:49,  6.07it/s]\titers: 21500, epoch: 2 | loss: 0.3992696\n",
      "\tspeed: 0.1643s/iter; left time: 89222.5640s\n",
      "21599it [59:05,  6.07it/s]\titers: 21600, epoch: 2 | loss: 0.0978865\n",
      "\tspeed: 0.1636s/iter; left time: 88774.6017s\n",
      "21699it [59:21,  6.05it/s]\titers: 21700, epoch: 2 | loss: 0.1666285\n",
      "\tspeed: 0.1641s/iter; left time: 89073.6344s\n",
      "21799it [59:38,  6.06it/s]\titers: 21800, epoch: 2 | loss: 0.8115878\n",
      "\tspeed: 0.1638s/iter; left time: 88879.3832s\n",
      "21899it [59:54,  6.07it/s]\titers: 21900, epoch: 2 | loss: 0.2968875\n",
      "\tspeed: 0.1638s/iter; left time: 88843.3533s\n",
      "21999it [1:00:11,  6.07it/s]\titers: 22000, epoch: 2 | loss: 0.1486410\n",
      "\tspeed: 0.1636s/iter; left time: 88721.4032s\n",
      "22099it [1:00:27,  6.11it/s]\titers: 22100, epoch: 2 | loss: 0.2644492\n",
      "\tspeed: 0.1637s/iter; left time: 88764.9928s\n",
      "22199it [1:00:43,  6.05it/s]\titers: 22200, epoch: 2 | loss: 0.0684150\n",
      "\tspeed: 0.1635s/iter; left time: 88622.4276s\n",
      "22299it [1:01:00,  6.10it/s]\titers: 22300, epoch: 2 | loss: 0.2136669\n",
      "\tspeed: 0.1637s/iter; left time: 88768.0765s\n",
      "22399it [1:01:16,  6.06it/s]\titers: 22400, epoch: 2 | loss: 0.5637086\n",
      "\tspeed: 0.1641s/iter; left time: 88942.3853s\n",
      "22499it [1:01:32,  6.14it/s]\titers: 22500, epoch: 2 | loss: 0.5667499\n",
      "\tspeed: 0.1641s/iter; left time: 88900.8138s\n",
      "22599it [1:01:49,  6.09it/s]\titers: 22600, epoch: 2 | loss: 0.1698933\n",
      "\tspeed: 0.1635s/iter; left time: 88597.0641s\n",
      "22699it [1:02:05,  6.10it/s]\titers: 22700, epoch: 2 | loss: 0.3008924\n",
      "\tspeed: 0.1638s/iter; left time: 88709.1246s\n",
      "22799it [1:02:22,  6.08it/s]\titers: 22800, epoch: 2 | loss: 0.1591337\n",
      "\tspeed: 0.1634s/iter; left time: 88473.8001s\n",
      "22899it [1:02:38,  6.12it/s]\titers: 22900, epoch: 2 | loss: 0.9950485\n",
      "\tspeed: 0.1635s/iter; left time: 88561.2332s\n",
      "22999it [1:02:54,  6.15it/s]\titers: 23000, epoch: 2 | loss: 0.0497491\n",
      "\tspeed: 0.1635s/iter; left time: 88536.8367s\n",
      "23099it [1:03:11,  6.13it/s]\titers: 23100, epoch: 2 | loss: 0.0539006\n",
      "\tspeed: 0.1635s/iter; left time: 88520.6149s\n",
      "23199it [1:03:27,  6.06it/s]\titers: 23200, epoch: 2 | loss: 0.0518122\n",
      "\tspeed: 0.1641s/iter; left time: 88800.4925s\n",
      "23299it [1:03:43,  6.13it/s]\titers: 23300, epoch: 2 | loss: 0.1554338\n",
      "\tspeed: 0.1633s/iter; left time: 88371.2028s\n",
      "23399it [1:04:00,  6.12it/s]\titers: 23400, epoch: 2 | loss: 0.0785448\n",
      "\tspeed: 0.1639s/iter; left time: 88693.5661s\n",
      "23499it [1:04:16,  6.12it/s]\titers: 23500, epoch: 2 | loss: 0.7481164\n",
      "\tspeed: 0.1640s/iter; left time: 88683.6879s\n",
      "23599it [1:04:32,  6.13it/s]\titers: 23600, epoch: 2 | loss: 0.0786750\n",
      "\tspeed: 0.1632s/iter; left time: 88257.0546s\n",
      "23699it [1:04:49,  6.05it/s]\titers: 23700, epoch: 2 | loss: 0.0617764\n",
      "\tspeed: 0.1642s/iter; left time: 88758.5767s\n",
      "23799it [1:05:05,  6.07it/s]\titers: 23800, epoch: 2 | loss: 0.1877648\n",
      "\tspeed: 0.1654s/iter; left time: 89395.3442s\n",
      "23899it [1:05:22,  6.18it/s]\titers: 23900, epoch: 2 | loss: 0.0375636\n",
      "\tspeed: 0.1642s/iter; left time: 88743.6615s\n",
      "23999it [1:05:38,  5.98it/s]\titers: 24000, epoch: 2 | loss: 0.0955036\n",
      "\tspeed: 0.1644s/iter; left time: 88852.9212s\n",
      "24099it [1:05:55,  6.09it/s]\titers: 24100, epoch: 2 | loss: 0.0680451\n",
      "\tspeed: 0.1648s/iter; left time: 89024.9055s\n",
      "24199it [1:06:11,  6.04it/s]\titers: 24200, epoch: 2 | loss: 0.5437136\n",
      "\tspeed: 0.1645s/iter; left time: 88855.2900s\n",
      "24299it [1:06:28,  6.09it/s]\titers: 24300, epoch: 2 | loss: 0.2040515\n",
      "\tspeed: 0.1639s/iter; left time: 88523.2467s\n",
      "24399it [1:06:44,  6.05it/s]\titers: 24400, epoch: 2 | loss: 0.2195622\n",
      "\tspeed: 0.1645s/iter; left time: 88842.8193s\n",
      "24499it [1:07:00,  6.17it/s]\titers: 24500, epoch: 2 | loss: 0.1223515\n",
      "\tspeed: 0.1642s/iter; left time: 88630.5599s\n",
      "24599it [1:07:17,  6.07it/s]\titers: 24600, epoch: 2 | loss: 0.3327048\n",
      "\tspeed: 0.1648s/iter; left time: 88936.0995s\n",
      "24699it [1:07:33,  6.13it/s]\titers: 24700, epoch: 2 | loss: 0.3684649\n",
      "\tspeed: 0.1655s/iter; left time: 89326.8330s\n",
      "24799it [1:07:50,  6.11it/s]\titers: 24800, epoch: 2 | loss: 0.2128126\n",
      "\tspeed: 0.1637s/iter; left time: 88349.9707s\n",
      "24899it [1:08:06,  6.03it/s]\titers: 24900, epoch: 2 | loss: 0.0790886\n",
      "\tspeed: 0.1640s/iter; left time: 88455.9167s\n",
      "24999it [1:08:23,  6.11it/s]\titers: 25000, epoch: 2 | loss: 0.0872144\n",
      "\tspeed: 0.1638s/iter; left time: 88344.4902s\n",
      "25099it [1:08:39,  6.11it/s]\titers: 25100, epoch: 2 | loss: 0.1079280\n",
      "\tspeed: 0.1642s/iter; left time: 88566.8442s\n",
      "25199it [1:08:55,  6.08it/s]\titers: 25200, epoch: 2 | loss: 0.3069256\n",
      "\tspeed: 0.1642s/iter; left time: 88511.7241s\n",
      "25299it [1:09:12,  6.11it/s]\titers: 25300, epoch: 2 | loss: 0.1900712\n",
      "\tspeed: 0.1651s/iter; left time: 89030.0122s\n",
      "25399it [1:09:28,  6.12it/s]\titers: 25400, epoch: 2 | loss: 0.1476922\n",
      "\tspeed: 0.1652s/iter; left time: 89051.6255s\n",
      "25499it [1:09:45,  6.10it/s]\titers: 25500, epoch: 2 | loss: 0.0940897\n",
      "\tspeed: 0.1643s/iter; left time: 88559.0903s\n",
      "25599it [1:10:01,  6.13it/s]\titers: 25600, epoch: 2 | loss: 0.0976221\n",
      "\tspeed: 0.1647s/iter; left time: 88714.1175s\n",
      "25699it [1:10:18,  6.04it/s]\titers: 25700, epoch: 2 | loss: 0.0517221\n",
      "\tspeed: 0.1644s/iter; left time: 88579.7449s\n",
      "25799it [1:10:34,  6.06it/s]\titers: 25800, epoch: 2 | loss: 0.1070463\n",
      "\tspeed: 0.1643s/iter; left time: 88485.6371s\n",
      "25899it [1:10:51,  6.17it/s]\titers: 25900, epoch: 2 | loss: 0.1252665\n",
      "\tspeed: 0.1667s/iter; left time: 89793.6801s\n",
      "25999it [1:11:07,  6.09it/s]\titers: 26000, epoch: 2 | loss: 0.6052353\n",
      "\tspeed: 0.1655s/iter; left time: 89088.8774s\n",
      "26099it [1:11:24,  6.19it/s]\titers: 26100, epoch: 2 | loss: 0.1661481\n",
      "\tspeed: 0.1649s/iter; left time: 88751.6657s\n",
      "26199it [1:11:40,  6.06it/s]\titers: 26200, epoch: 2 | loss: 0.1990195\n",
      "\tspeed: 0.1651s/iter; left time: 88856.3341s\n",
      "26299it [1:11:57,  6.10it/s]\titers: 26300, epoch: 2 | loss: 0.1051774\n",
      "\tspeed: 0.1651s/iter; left time: 88829.3028s\n",
      "26399it [1:12:13,  6.11it/s]\titers: 26400, epoch: 2 | loss: 0.2508316\n",
      "\tspeed: 0.1641s/iter; left time: 88282.2478s\n",
      "26499it [1:12:30,  6.10it/s]\titers: 26500, epoch: 2 | loss: 0.1748221\n",
      "\tspeed: 0.1640s/iter; left time: 88213.6287s\n",
      "26599it [1:12:46,  6.08it/s]\titers: 26600, epoch: 2 | loss: 0.1332360\n",
      "\tspeed: 0.1643s/iter; left time: 88365.1146s\n",
      "26699it [1:13:03,  6.10it/s]\titers: 26700, epoch: 2 | loss: 0.1053721\n",
      "\tspeed: 0.1641s/iter; left time: 88239.0331s\n",
      "26799it [1:13:19,  6.04it/s]\titers: 26800, epoch: 2 | loss: 0.0651917\n",
      "\tspeed: 0.1643s/iter; left time: 88320.9349s\n",
      "26899it [1:13:35,  6.10it/s]\titers: 26900, epoch: 2 | loss: 0.1511873\n",
      "\tspeed: 0.1646s/iter; left time: 88467.5501s\n",
      "26999it [1:13:52,  6.05it/s]\titers: 27000, epoch: 2 | loss: 0.1924187\n",
      "\tspeed: 0.1645s/iter; left time: 88410.3086s\n",
      "27099it [1:14:08,  6.06it/s]\titers: 27100, epoch: 2 | loss: 0.1642588\n",
      "\tspeed: 0.1651s/iter; left time: 88696.1596s\n",
      "27199it [1:14:25,  6.04it/s]\titers: 27200, epoch: 2 | loss: 0.1184070\n",
      "\tspeed: 0.1651s/iter; left time: 88690.5370s\n",
      "27299it [1:14:41,  6.04it/s]\titers: 27300, epoch: 2 | loss: 0.3885778\n",
      "\tspeed: 0.1648s/iter; left time: 88500.7205s\n",
      "27399it [1:14:58,  6.01it/s]\titers: 27400, epoch: 2 | loss: 0.1490618\n",
      "\tspeed: 0.1642s/iter; left time: 88178.2427s\n",
      "27499it [1:15:14,  6.05it/s]\titers: 27500, epoch: 2 | loss: 0.2425725\n",
      "\tspeed: 0.1648s/iter; left time: 88475.5570s\n",
      "27599it [1:15:31,  5.95it/s]\titers: 27600, epoch: 2 | loss: 0.0679605\n",
      "\tspeed: 0.1647s/iter; left time: 88405.9359s\n",
      "27699it [1:15:47,  6.11it/s]\titers: 27700, epoch: 2 | loss: 0.1114070\n",
      "\tspeed: 0.1648s/iter; left time: 88453.4702s\n",
      "27799it [1:16:04,  6.07it/s]\titers: 27800, epoch: 2 | loss: 0.2864105\n",
      "\tspeed: 0.1642s/iter; left time: 88103.1108s\n",
      "27899it [1:16:20,  6.16it/s]\titers: 27900, epoch: 2 | loss: 0.0934578\n",
      "\tspeed: 0.1646s/iter; left time: 88288.3686s\n",
      "27999it [1:16:37,  6.08it/s]\titers: 28000, epoch: 2 | loss: 0.2324196\n",
      "\tspeed: 0.1645s/iter; left time: 88257.4494s\n",
      "28099it [1:16:53,  6.07it/s]\titers: 28100, epoch: 2 | loss: 0.2836437\n",
      "\tspeed: 0.1649s/iter; left time: 88437.1041s\n",
      "28199it [1:17:10,  5.99it/s]\titers: 28200, epoch: 2 | loss: 0.1091606\n",
      "\tspeed: 0.1644s/iter; left time: 88144.3164s\n",
      "28299it [1:17:26,  6.09it/s]\titers: 28300, epoch: 2 | loss: 0.4054630\n",
      "\tspeed: 0.1641s/iter; left time: 87949.3171s\n",
      "28399it [1:17:42,  6.00it/s]\titers: 28400, epoch: 2 | loss: 0.1576273\n",
      "\tspeed: 0.1649s/iter; left time: 88376.5190s\n",
      "28499it [1:17:59,  6.07it/s]\titers: 28500, epoch: 2 | loss: 0.1551670\n",
      "\tspeed: 0.1652s/iter; left time: 88527.4446s\n",
      "28599it [1:18:15,  6.05it/s]\titers: 28600, epoch: 2 | loss: 0.5342354\n",
      "\tspeed: 0.1647s/iter; left time: 88228.9180s\n",
      "28699it [1:18:32,  6.11it/s]\titers: 28700, epoch: 2 | loss: 0.2227833\n",
      "\tspeed: 0.1670s/iter; left time: 89476.3888s\n",
      "28799it [1:18:49,  6.04it/s]\titers: 28800, epoch: 2 | loss: 0.0452349\n",
      "\tspeed: 0.1655s/iter; left time: 88641.2603s\n",
      "28899it [1:19:05,  6.06it/s]\titers: 28900, epoch: 2 | loss: 0.1416145\n",
      "\tspeed: 0.1656s/iter; left time: 88663.3592s\n",
      "28999it [1:19:22,  6.03it/s]\titers: 29000, epoch: 2 | loss: 0.2981861\n",
      "\tspeed: 0.1652s/iter; left time: 88439.8393s\n",
      "29099it [1:19:38,  6.04it/s]\titers: 29100, epoch: 2 | loss: 0.4349076\n",
      "\tspeed: 0.1651s/iter; left time: 88387.0307s\n",
      "29199it [1:19:55,  6.10it/s]\titers: 29200, epoch: 2 | loss: 0.0476038\n",
      "\tspeed: 0.1649s/iter; left time: 88271.1639s\n",
      "29299it [1:20:11,  6.09it/s]\titers: 29300, epoch: 2 | loss: 0.5275880\n",
      "\tspeed: 0.1648s/iter; left time: 88177.5007s\n",
      "29399it [1:20:28,  6.04it/s]\titers: 29400, epoch: 2 | loss: 0.1126936\n",
      "\tspeed: 0.1652s/iter; left time: 88358.8439s\n",
      "29499it [1:20:44,  6.08it/s]\titers: 29500, epoch: 2 | loss: 0.1731227\n",
      "\tspeed: 0.1648s/iter; left time: 88157.0193s\n",
      "29599it [1:21:01,  6.05it/s]\titers: 29600, epoch: 2 | loss: 0.1860874\n",
      "\tspeed: 0.1650s/iter; left time: 88252.4177s\n",
      "29699it [1:21:17,  6.08it/s]\titers: 29700, epoch: 2 | loss: 0.1031781\n",
      "\tspeed: 0.1647s/iter; left time: 88065.7508s\n",
      "29705it [1:21:18,  6.09it/s]\n",
      "Epoch: 2 cost time: 4878.767728567123\n",
      "6481it [08:28, 12.74it/s]\n",
      "6457it [08:29, 12.66it/s]\n",
      "Epoch: 2 | Train Loss: 0.2284158 Vali Loss: 0.3079563 Test Loss: 0.3783611 MAE Loss: 0.3931622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:16,  5.47it/s]\titers: 100, epoch: 3 | loss: 0.0642321\n",
      "\tspeed: 10.3688s/iter; left time: 5543052.3599s\n",
      "199it [00:33,  5.64it/s]\titers: 200, epoch: 3 | loss: 0.1529325\n",
      "\tspeed: 0.1672s/iter; left time: 89378.5822s\n",
      "299it [00:50,  6.04it/s]\titers: 300, epoch: 3 | loss: 0.1372408\n",
      "\tspeed: 0.1672s/iter; left time: 89352.2050s\n",
      "399it [01:07,  5.99it/s]\titers: 400, epoch: 3 | loss: 0.0608371\n",
      "\tspeed: 0.1677s/iter; left time: 89626.4712s\n",
      "499it [01:24,  6.00it/s]\titers: 500, epoch: 3 | loss: 0.0717668\n",
      "\tspeed: 0.1685s/iter; left time: 90014.2639s\n",
      "599it [01:40,  5.98it/s]\titers: 600, epoch: 3 | loss: 0.1412322\n",
      "\tspeed: 0.1694s/iter; left time: 90460.1465s\n",
      "699it [01:57,  6.05it/s]\titers: 700, epoch: 3 | loss: 0.1994200\n",
      "\tspeed: 0.1690s/iter; left time: 90227.4463s\n",
      "799it [02:14,  6.01it/s]\titers: 800, epoch: 3 | loss: 0.1287755\n",
      "\tspeed: 0.1686s/iter; left time: 89992.3637s\n",
      "899it [02:31,  6.03it/s]\titers: 900, epoch: 3 | loss: 0.0286060\n",
      "\tspeed: 0.1701s/iter; left time: 90803.4055s\n",
      "999it [02:48,  6.01it/s]\titers: 1000, epoch: 3 | loss: 0.3066550\n",
      "\tspeed: 0.1685s/iter; left time: 89943.0100s\n",
      "1099it [03:05,  6.07it/s]\titers: 1100, epoch: 3 | loss: 0.1075951\n",
      "\tspeed: 0.1702s/iter; left time: 90805.7983s\n",
      "1199it [03:22,  5.97it/s]\titers: 1200, epoch: 3 | loss: 0.1583334\n",
      "\tspeed: 0.1665s/iter; left time: 88804.1253s\n",
      "1299it [03:38,  6.02it/s]\titers: 1300, epoch: 3 | loss: 0.4336807\n",
      "\tspeed: 0.1660s/iter; left time: 88564.8767s\n",
      "1399it [03:55,  6.04it/s]\titers: 1400, epoch: 3 | loss: 0.4755102\n",
      "\tspeed: 0.1657s/iter; left time: 88358.4632s\n",
      "1499it [04:12,  5.98it/s]\titers: 1500, epoch: 3 | loss: 0.0280975\n",
      "\tspeed: 0.1681s/iter; left time: 89603.9518s\n",
      "1599it [04:29,  5.97it/s]\titers: 1600, epoch: 3 | loss: 0.2153023\n",
      "\tspeed: 0.1686s/iter; left time: 89862.8721s\n",
      "1699it [04:46,  6.03it/s]\titers: 1700, epoch: 3 | loss: 0.1135083\n",
      "\tspeed: 0.1701s/iter; left time: 90662.9000s\n",
      "1799it [05:02,  6.03it/s]\titers: 1800, epoch: 3 | loss: 0.1375277\n",
      "\tspeed: 0.1680s/iter; left time: 89546.1735s\n",
      "1899it [05:19,  5.98it/s]\titers: 1900, epoch: 3 | loss: 0.1108198\n",
      "\tspeed: 0.1669s/iter; left time: 88927.4953s\n",
      "1999it [05:36,  6.05it/s]\titers: 2000, epoch: 3 | loss: 0.2846176\n",
      "\tspeed: 0.1681s/iter; left time: 89561.9333s\n",
      "2099it [05:53,  6.13it/s]\titers: 2100, epoch: 3 | loss: 0.0161439\n",
      "\tspeed: 0.1693s/iter; left time: 90146.6022s\n",
      "2199it [06:10,  5.98it/s]\titers: 2200, epoch: 3 | loss: 0.0708350\n",
      "\tspeed: 0.1687s/iter; left time: 89825.9320s\n",
      "2299it [06:26,  6.19it/s]\titers: 2300, epoch: 3 | loss: 0.0751425\n",
      "\tspeed: 0.1657s/iter; left time: 88195.6175s\n",
      "2399it [06:43,  6.07it/s]\titers: 2400, epoch: 3 | loss: 0.0778787\n",
      "\tspeed: 0.1675s/iter; left time: 89173.4740s\n",
      "2499it [07:00,  5.58it/s]\titers: 2500, epoch: 3 | loss: 0.1275522\n",
      "\tspeed: 0.1668s/iter; left time: 88776.4505s\n",
      "2599it [07:16,  6.02it/s]\titers: 2600, epoch: 3 | loss: 0.0351311\n",
      "\tspeed: 0.1653s/iter; left time: 87975.4739s\n",
      "2699it [07:33,  6.04it/s]\titers: 2700, epoch: 3 | loss: 1.2566741\n",
      "\tspeed: 0.1684s/iter; left time: 89603.3364s\n",
      "2799it [07:50,  6.05it/s]\titers: 2800, epoch: 3 | loss: 0.1979304\n",
      "\tspeed: 0.1673s/iter; left time: 88970.0911s\n",
      "2899it [08:06,  6.05it/s]\titers: 2900, epoch: 3 | loss: 0.2694724\n",
      "\tspeed: 0.1653s/iter; left time: 87879.3888s\n",
      "2999it [08:23,  6.04it/s]\titers: 3000, epoch: 3 | loss: 0.1176070\n",
      "\tspeed: 0.1658s/iter; left time: 88146.7919s\n",
      "3099it [08:40,  6.07it/s]\titers: 3100, epoch: 3 | loss: 0.0624404\n",
      "\tspeed: 0.1689s/iter; left time: 89804.1600s\n",
      "3199it [08:56,  6.06it/s]\titers: 3200, epoch: 3 | loss: 0.1501526\n",
      "\tspeed: 0.1667s/iter; left time: 88624.5920s\n",
      "3299it [09:13,  6.15it/s]\titers: 3300, epoch: 3 | loss: 0.1071169\n",
      "\tspeed: 0.1680s/iter; left time: 89255.3489s\n",
      "3399it [09:30,  5.06it/s]\titers: 3400, epoch: 3 | loss: 0.1091510\n",
      "\tspeed: 0.1695s/iter; left time: 90031.0964s\n",
      "3499it [09:47,  6.05it/s]\titers: 3500, epoch: 3 | loss: 0.0250530\n",
      "\tspeed: 0.1661s/iter; left time: 88210.9905s\n",
      "3599it [10:04,  6.02it/s]\titers: 3600, epoch: 3 | loss: 0.1289907\n",
      "\tspeed: 0.1675s/iter; left time: 88981.0207s\n",
      "3699it [10:20,  6.00it/s]\titers: 3700, epoch: 3 | loss: 0.0617823\n",
      "\tspeed: 0.1671s/iter; left time: 88737.4442s\n",
      "3799it [10:37,  6.01it/s]\titers: 3800, epoch: 3 | loss: 0.1889699\n",
      "\tspeed: 0.1670s/iter; left time: 88634.3899s\n",
      "3899it [10:54,  6.08it/s]\titers: 3900, epoch: 3 | loss: 0.1144825\n",
      "\tspeed: 0.1682s/iter; left time: 89264.6912s\n",
      "3999it [11:11,  5.91it/s]\titers: 4000, epoch: 3 | loss: 0.0309456\n",
      "\tspeed: 0.1684s/iter; left time: 89376.6363s\n",
      "4099it [11:28,  6.02it/s]\titers: 4100, epoch: 3 | loss: 0.0934060\n",
      "\tspeed: 0.1696s/iter; left time: 89969.6328s\n",
      "4199it [11:44,  6.04it/s]\titers: 4200, epoch: 3 | loss: 0.2210872\n",
      "\tspeed: 0.1690s/iter; left time: 89631.6918s\n",
      "4299it [12:01,  6.00it/s]\titers: 4300, epoch: 3 | loss: 0.0866531\n",
      "\tspeed: 0.1690s/iter; left time: 89617.7726s\n",
      "4399it [12:18,  6.04it/s]\titers: 4400, epoch: 3 | loss: 0.0498060\n",
      "\tspeed: 0.1697s/iter; left time: 90000.6314s\n",
      "4499it [12:35,  5.98it/s]\titers: 4500, epoch: 3 | loss: 0.1075810\n",
      "\tspeed: 0.1671s/iter; left time: 88598.6984s\n",
      "4599it [12:52,  5.55it/s]\titers: 4600, epoch: 3 | loss: 0.0855843\n",
      "\tspeed: 0.1658s/iter; left time: 87863.9434s\n",
      "4699it [13:08,  6.15it/s]\titers: 4700, epoch: 3 | loss: 0.2467742\n",
      "\tspeed: 0.1651s/iter; left time: 87495.2782s\n",
      "4799it [13:25,  6.04it/s]\titers: 4800, epoch: 3 | loss: 0.0694034\n",
      "\tspeed: 0.1650s/iter; left time: 87445.0061s\n",
      "4899it [13:41,  6.07it/s]\titers: 4900, epoch: 3 | loss: 0.1504305\n",
      "\tspeed: 0.1642s/iter; left time: 87001.4642s\n",
      "4999it [13:58,  6.01it/s]\titers: 5000, epoch: 3 | loss: 0.0310754\n",
      "\tspeed: 0.1644s/iter; left time: 87070.2061s\n",
      "5099it [14:14,  6.07it/s]\titers: 5100, epoch: 3 | loss: 0.0889565\n",
      "\tspeed: 0.1644s/iter; left time: 87044.3374s\n",
      "5199it [14:30,  6.07it/s]\titers: 5200, epoch: 3 | loss: 0.2126888\n",
      "\tspeed: 0.1646s/iter; left time: 87161.9157s\n",
      "5299it [14:47,  6.14it/s]\titers: 5300, epoch: 3 | loss: 0.1566767\n",
      "\tspeed: 0.1657s/iter; left time: 87699.5049s\n",
      "5399it [15:03,  6.03it/s]\titers: 5400, epoch: 3 | loss: 0.1109937\n",
      "\tspeed: 0.1651s/iter; left time: 87381.9311s\n",
      "5499it [15:20,  6.07it/s]\titers: 5500, epoch: 3 | loss: 0.0968226\n",
      "\tspeed: 0.1643s/iter; left time: 86952.8695s\n",
      "5599it [15:36,  6.03it/s]\titers: 5600, epoch: 3 | loss: 0.0969181\n",
      "\tspeed: 0.1649s/iter; left time: 87260.5833s\n",
      "5699it [15:53,  5.99it/s]\titers: 5700, epoch: 3 | loss: 0.3615874\n",
      "\tspeed: 0.1659s/iter; left time: 87759.6670s\n",
      "5799it [16:10,  6.07it/s]\titers: 5800, epoch: 3 | loss: 0.3756682\n",
      "\tspeed: 0.1656s/iter; left time: 87591.0526s\n",
      "5899it [16:26,  6.11it/s]\titers: 5900, epoch: 3 | loss: 0.2024260\n",
      "\tspeed: 0.1655s/iter; left time: 87529.0658s\n",
      "5999it [16:43,  6.00it/s]\titers: 6000, epoch: 3 | loss: 0.2676552\n",
      "\tspeed: 0.1692s/iter; left time: 89439.8366s\n",
      "6099it [17:00,  6.05it/s]\titers: 6100, epoch: 3 | loss: 0.1018148\n",
      "\tspeed: 0.1685s/iter; left time: 89044.6929s\n",
      "6199it [17:17,  6.06it/s]\titers: 6200, epoch: 3 | loss: 0.1029208\n",
      "\tspeed: 0.1689s/iter; left time: 89262.9759s\n",
      "6299it [17:33,  5.95it/s]\titers: 6300, epoch: 3 | loss: 0.1394328\n",
      "\tspeed: 0.1663s/iter; left time: 87888.8253s\n",
      "6399it [17:50,  6.09it/s]\titers: 6400, epoch: 3 | loss: 0.0531691\n",
      "\tspeed: 0.1655s/iter; left time: 87424.9468s\n",
      "6499it [18:07,  6.05it/s]\titers: 6500, epoch: 3 | loss: 0.2879387\n",
      "\tspeed: 0.1680s/iter; left time: 88732.9319s\n",
      "6599it [18:24,  6.01it/s]\titers: 6600, epoch: 3 | loss: 0.1666680\n",
      "\tspeed: 0.1677s/iter; left time: 88563.4719s\n",
      "6699it [18:40,  6.07it/s]\titers: 6700, epoch: 3 | loss: 0.6245655\n",
      "\tspeed: 0.1657s/iter; left time: 87510.6250s\n",
      "6799it [18:57,  6.04it/s]\titers: 6800, epoch: 3 | loss: 0.0645830\n",
      "\tspeed: 0.1660s/iter; left time: 87643.4479s\n",
      "6899it [19:14,  6.01it/s]\titers: 6900, epoch: 3 | loss: 0.4772364\n",
      "\tspeed: 0.1695s/iter; left time: 89460.7924s\n",
      "6999it [19:30,  6.04it/s]\titers: 7000, epoch: 3 | loss: 0.1720875\n",
      "\tspeed: 0.1673s/iter; left time: 88259.9275s\n",
      "7099it [19:47,  6.08it/s]\titers: 7100, epoch: 3 | loss: 0.0984529\n",
      "\tspeed: 0.1693s/iter; left time: 89306.7401s\n",
      "7199it [20:04,  5.99it/s]\titers: 7200, epoch: 3 | loss: 0.0954290\n",
      "\tspeed: 0.1691s/iter; left time: 89221.9118s\n",
      "7299it [20:21,  5.62it/s]\titers: 7300, epoch: 3 | loss: 0.2120314\n",
      "\tspeed: 0.1676s/iter; left time: 88372.0969s\n",
      "7399it [20:38,  5.99it/s]\titers: 7400, epoch: 3 | loss: 0.0574131\n",
      "\tspeed: 0.1669s/iter; left time: 87999.3543s\n",
      "7499it [20:55,  6.04it/s]\titers: 7500, epoch: 3 | loss: 0.2020275\n",
      "\tspeed: 0.1697s/iter; left time: 89454.2085s\n",
      "7599it [21:11,  6.03it/s]\titers: 7600, epoch: 3 | loss: 0.0961373\n",
      "\tspeed: 0.1679s/iter; left time: 88484.0062s\n",
      "7699it [21:28,  6.03it/s]\titers: 7700, epoch: 3 | loss: 0.0512162\n",
      "\tspeed: 0.1672s/iter; left time: 88132.5386s\n",
      "7799it [21:45,  6.02it/s]\titers: 7800, epoch: 3 | loss: 0.1316636\n",
      "\tspeed: 0.1694s/iter; left time: 89242.0224s\n",
      "7899it [22:02,  6.08it/s]\titers: 7900, epoch: 3 | loss: 0.1557589\n",
      "\tspeed: 0.1672s/iter; left time: 88083.1831s\n",
      "7999it [22:19,  5.26it/s]\titers: 8000, epoch: 3 | loss: 0.1010452\n",
      "\tspeed: 0.1685s/iter; left time: 88739.1138s\n",
      "8099it [22:35,  6.11it/s]\titers: 8100, epoch: 3 | loss: 0.1873783\n",
      "\tspeed: 0.1665s/iter; left time: 87671.8188s\n",
      "8199it [22:52,  5.98it/s]\titers: 8200, epoch: 3 | loss: 0.0505925\n",
      "\tspeed: 0.1674s/iter; left time: 88157.3700s\n",
      "8299it [23:09,  6.04it/s]\titers: 8300, epoch: 3 | loss: 0.1776711\n",
      "\tspeed: 0.1677s/iter; left time: 88267.0382s\n",
      "8399it [23:25,  5.94it/s]\titers: 8400, epoch: 3 | loss: 0.1516279\n",
      "\tspeed: 0.1662s/iter; left time: 87476.8639s\n",
      "8499it [23:42,  6.05it/s]\titers: 8500, epoch: 3 | loss: 0.0479243\n",
      "\tspeed: 0.1666s/iter; left time: 87640.8808s\n",
      "8599it [23:59,  6.07it/s]\titers: 8600, epoch: 3 | loss: 0.2121468\n",
      "\tspeed: 0.1686s/iter; left time: 88698.0339s\n",
      "8699it [24:16,  5.72it/s]\titers: 8700, epoch: 3 | loss: 0.0653621\n",
      "\tspeed: 0.1695s/iter; left time: 89132.8603s\n",
      "8799it [24:33,  6.02it/s]\titers: 8800, epoch: 3 | loss: 0.0825274\n",
      "\tspeed: 0.1663s/iter; left time: 87467.2743s\n",
      "8899it [24:49,  5.99it/s]\titers: 8900, epoch: 3 | loss: 0.0968559\n",
      "\tspeed: 0.1673s/iter; left time: 87959.4139s\n",
      "8999it [25:06,  6.09it/s]\titers: 9000, epoch: 3 | loss: 0.0711833\n",
      "\tspeed: 0.1685s/iter; left time: 88567.3784s\n",
      "9099it [25:23,  6.09it/s]\titers: 9100, epoch: 3 | loss: 0.2811102\n",
      "\tspeed: 0.1667s/iter; left time: 87632.9082s\n",
      "9199it [25:39,  6.00it/s]\titers: 9200, epoch: 3 | loss: 0.1711250\n",
      "\tspeed: 0.1658s/iter; left time: 87139.5600s\n",
      "9299it [25:56,  6.09it/s]\titers: 9300, epoch: 3 | loss: 0.3203587\n",
      "\tspeed: 0.1656s/iter; left time: 87012.6434s\n",
      "9399it [26:13,  5.41it/s]\titers: 9400, epoch: 3 | loss: 0.1014733\n",
      "\tspeed: 0.1686s/iter; left time: 88537.8232s\n",
      "9499it [26:29,  6.05it/s]\titers: 9500, epoch: 3 | loss: 0.3284439\n",
      "\tspeed: 0.1648s/iter; left time: 86540.3165s\n",
      "9599it [26:46,  6.09it/s]\titers: 9600, epoch: 3 | loss: 0.0239247\n",
      "\tspeed: 0.1675s/iter; left time: 87928.3540s\n",
      "9699it [27:03,  6.05it/s]\titers: 9700, epoch: 3 | loss: 0.7806684\n",
      "\tspeed: 0.1666s/iter; left time: 87487.7560s\n",
      "9799it [27:19,  6.07it/s]\titers: 9800, epoch: 3 | loss: 0.5998971\n",
      "\tspeed: 0.1671s/iter; left time: 87715.5347s\n",
      "9899it [27:36,  6.06it/s]\titers: 9900, epoch: 3 | loss: 0.0348271\n",
      "\tspeed: 0.1651s/iter; left time: 86658.3100s\n",
      "9999it [27:52,  6.04it/s]\titers: 10000, epoch: 3 | loss: 0.1674319\n",
      "\tspeed: 0.1647s/iter; left time: 86435.3110s\n",
      "10099it [28:09,  6.04it/s]\titers: 10100, epoch: 3 | loss: 0.2627383\n",
      "\tspeed: 0.1664s/iter; left time: 87270.0766s\n",
      "10199it [28:26,  6.08it/s]\titers: 10200, epoch: 3 | loss: 0.1034455\n",
      "\tspeed: 0.1665s/iter; left time: 87348.3675s\n",
      "10299it [28:42,  6.02it/s]\titers: 10300, epoch: 3 | loss: 0.2482408\n",
      "\tspeed: 0.1673s/iter; left time: 87723.7668s\n",
      "10399it [28:59,  5.89it/s]\titers: 10400, epoch: 3 | loss: 0.3590967\n",
      "\tspeed: 0.1663s/iter; left time: 87172.7163s\n",
      "10499it [29:16,  6.02it/s]\titers: 10500, epoch: 3 | loss: 0.2353022\n",
      "\tspeed: 0.1676s/iter; left time: 87864.1060s\n",
      "10599it [29:32,  5.99it/s]\titers: 10600, epoch: 3 | loss: 0.0640991\n",
      "\tspeed: 0.1665s/iter; left time: 87247.3934s\n",
      "10699it [29:49,  6.05it/s]\titers: 10700, epoch: 3 | loss: 0.1442638\n",
      "\tspeed: 0.1670s/iter; left time: 87528.2574s\n",
      "10799it [30:06,  6.03it/s]\titers: 10800, epoch: 3 | loss: 0.1742587\n",
      "\tspeed: 0.1686s/iter; left time: 88309.4399s\n",
      "10899it [30:23,  6.01it/s]\titers: 10900, epoch: 3 | loss: 0.1547537\n",
      "\tspeed: 0.1689s/iter; left time: 88473.2420s\n",
      "10999it [30:40,  6.06it/s]\titers: 11000, epoch: 3 | loss: 0.0481388\n",
      "\tspeed: 0.1679s/iter; left time: 87938.7112s\n",
      "11099it [30:56,  6.11it/s]\titers: 11100, epoch: 3 | loss: 0.1336683\n",
      "\tspeed: 0.1668s/iter; left time: 87315.3266s\n",
      "11199it [31:13,  5.91it/s]\titers: 11200, epoch: 3 | loss: 0.3722110\n",
      "\tspeed: 0.1674s/iter; left time: 87615.7201s\n",
      "11299it [31:30,  6.04it/s]\titers: 11300, epoch: 3 | loss: 0.1005140\n",
      "\tspeed: 0.1655s/iter; left time: 86606.5516s\n",
      "11399it [31:46,  5.99it/s]\titers: 11400, epoch: 3 | loss: 0.5076135\n",
      "\tspeed: 0.1677s/iter; left time: 87731.1290s\n",
      "11499it [32:03,  6.07it/s]\titers: 11500, epoch: 3 | loss: 0.3194572\n",
      "\tspeed: 0.1652s/iter; left time: 86406.6807s\n",
      "11599it [32:20,  5.91it/s]\titers: 11600, epoch: 3 | loss: 0.2702033\n",
      "\tspeed: 0.1672s/iter; left time: 87459.9486s\n",
      "11699it [32:36,  6.04it/s]\titers: 11700, epoch: 3 | loss: 0.0470993\n",
      "\tspeed: 0.1668s/iter; left time: 87260.6366s\n",
      "11799it [32:53,  6.07it/s]\titers: 11800, epoch: 3 | loss: 0.0477483\n",
      "\tspeed: 0.1658s/iter; left time: 86716.5906s\n",
      "11899it [33:10,  6.08it/s]\titers: 11900, epoch: 3 | loss: 0.1660390\n",
      "\tspeed: 0.1672s/iter; left time: 87417.9682s\n",
      "11999it [33:26,  6.12it/s]\titers: 12000, epoch: 3 | loss: 0.4199611\n",
      "\tspeed: 0.1672s/iter; left time: 87410.3577s\n",
      "12099it [33:43,  5.92it/s]\titers: 12100, epoch: 3 | loss: 0.4527001\n",
      "\tspeed: 0.1672s/iter; left time: 87363.6656s\n",
      "12199it [34:00,  6.03it/s]\titers: 12200, epoch: 3 | loss: 0.0361502\n",
      "\tspeed: 0.1653s/iter; left time: 86362.4268s\n",
      "12299it [34:16,  6.02it/s]\titers: 12300, epoch: 3 | loss: 0.1925638\n",
      "\tspeed: 0.1681s/iter; left time: 87800.8256s\n",
      "12399it [34:33,  6.02it/s]\titers: 12400, epoch: 3 | loss: 0.2243162\n",
      "\tspeed: 0.1680s/iter; left time: 87743.6898s\n",
      "12499it [34:50,  6.09it/s]\titers: 12500, epoch: 3 | loss: 0.2455083\n",
      "\tspeed: 0.1670s/iter; left time: 87212.4584s\n",
      "12599it [35:07,  5.98it/s]\titers: 12600, epoch: 3 | loss: 0.0879827\n",
      "\tspeed: 0.1682s/iter; left time: 87804.8441s\n",
      "12699it [35:24,  6.14it/s]\titers: 12700, epoch: 3 | loss: 0.0907751\n",
      "\tspeed: 0.1686s/iter; left time: 88024.7246s\n",
      "12799it [35:40,  6.13it/s]\titers: 12800, epoch: 3 | loss: 0.2434840\n",
      "\tspeed: 0.1670s/iter; left time: 87151.0204s\n",
      "12899it [35:57,  6.02it/s]\titers: 12900, epoch: 3 | loss: 0.1287539\n",
      "\tspeed: 0.1649s/iter; left time: 86023.6315s\n",
      "12999it [36:13,  6.03it/s]\titers: 13000, epoch: 3 | loss: 0.2043973\n",
      "\tspeed: 0.1674s/iter; left time: 87327.6405s\n",
      "13099it [36:30,  6.06it/s]\titers: 13100, epoch: 3 | loss: 0.0937032\n",
      "\tspeed: 0.1675s/iter; left time: 87351.5324s\n",
      "13199it [36:47,  5.97it/s]\titers: 13200, epoch: 3 | loss: 0.0577115\n",
      "\tspeed: 0.1655s/iter; left time: 86283.8419s\n",
      "13299it [37:04,  6.06it/s]\titers: 13300, epoch: 3 | loss: 0.2479391\n",
      "\tspeed: 0.1684s/iter; left time: 87785.4261s\n",
      "13399it [37:20,  6.11it/s]\titers: 13400, epoch: 3 | loss: 0.4965813\n",
      "\tspeed: 0.1674s/iter; left time: 87249.3595s\n",
      "13499it [37:37,  5.78it/s]\titers: 13500, epoch: 3 | loss: 0.1375604\n",
      "\tspeed: 0.1680s/iter; left time: 87553.5006s\n",
      "13599it [37:54,  6.01it/s]\titers: 13600, epoch: 3 | loss: 0.2790565\n",
      "\tspeed: 0.1659s/iter; left time: 86426.6548s\n",
      "13699it [38:10,  6.06it/s]\titers: 13700, epoch: 3 | loss: 0.1677209\n",
      "\tspeed: 0.1670s/iter; left time: 86997.5364s\n",
      "13799it [38:27,  6.07it/s]\titers: 13800, epoch: 3 | loss: 0.1447442\n",
      "\tspeed: 0.1674s/iter; left time: 87192.5932s\n",
      "13899it [38:44,  5.96it/s]\titers: 13900, epoch: 3 | loss: 0.4863590\n",
      "\tspeed: 0.1670s/iter; left time: 86988.2823s\n",
      "13999it [39:01,  6.08it/s]\titers: 14000, epoch: 3 | loss: 0.1589646\n",
      "\tspeed: 0.1670s/iter; left time: 86971.5792s\n",
      "14099it [39:17,  6.01it/s]\titers: 14100, epoch: 3 | loss: 0.3786048\n",
      "\tspeed: 0.1658s/iter; left time: 86325.0104s\n",
      "14199it [39:34,  6.00it/s]\titers: 14200, epoch: 3 | loss: 0.0739269\n",
      "\tspeed: 0.1673s/iter; left time: 87064.1912s\n",
      "14299it [39:51,  6.00it/s]\titers: 14300, epoch: 3 | loss: 0.1670679\n",
      "\tspeed: 0.1671s/iter; left time: 86964.2657s\n",
      "14399it [40:07,  6.00it/s]\titers: 14400, epoch: 3 | loss: 0.0498159\n",
      "\tspeed: 0.1675s/iter; left time: 87135.7275s\n",
      "14499it [40:24,  6.05it/s]\titers: 14500, epoch: 3 | loss: 0.2305354\n",
      "\tspeed: 0.1681s/iter; left time: 87456.1011s\n",
      "14599it [40:41,  5.46it/s]\titers: 14600, epoch: 3 | loss: 0.1492082\n",
      "\tspeed: 0.1697s/iter; left time: 88271.4385s\n",
      "14699it [40:58,  6.07it/s]\titers: 14700, epoch: 3 | loss: 0.1281650\n",
      "\tspeed: 0.1658s/iter; left time: 86218.4969s\n",
      "14799it [41:15,  6.00it/s]\titers: 14800, epoch: 3 | loss: 0.0793965\n",
      "\tspeed: 0.1695s/iter; left time: 88141.9346s\n",
      "14899it [41:32,  6.02it/s]\titers: 14900, epoch: 3 | loss: 0.3424425\n",
      "\tspeed: 0.1692s/iter; left time: 87932.3721s\n",
      "14999it [41:49,  6.02it/s]\titers: 15000, epoch: 3 | loss: 0.0306599\n",
      "\tspeed: 0.1692s/iter; left time: 87953.6176s\n",
      "15099it [42:05,  5.93it/s]\titers: 15100, epoch: 3 | loss: 0.2006073\n",
      "\tspeed: 0.1680s/iter; left time: 87315.2325s\n",
      "15199it [42:22,  5.99it/s]\titers: 15200, epoch: 3 | loss: 0.0844463\n",
      "\tspeed: 0.1665s/iter; left time: 86478.1450s\n",
      "15299it [42:39,  6.02it/s]\titers: 15300, epoch: 3 | loss: 0.1824959\n",
      "\tspeed: 0.1677s/iter; left time: 87100.8316s\n",
      "15399it [42:55,  6.05it/s]\titers: 15400, epoch: 3 | loss: 0.0744227\n",
      "\tspeed: 0.1668s/iter; left time: 86600.9197s\n",
      "15499it [43:12,  6.07it/s]\titers: 15500, epoch: 3 | loss: 0.0309840\n",
      "\tspeed: 0.1664s/iter; left time: 86410.6064s\n",
      "15599it [43:29,  5.88it/s]\titers: 15600, epoch: 3 | loss: 0.2418546\n",
      "\tspeed: 0.1661s/iter; left time: 86203.4628s\n",
      "15699it [43:45,  6.01it/s]\titers: 15700, epoch: 3 | loss: 0.1425210\n",
      "\tspeed: 0.1653s/iter; left time: 85790.4545s\n",
      "15799it [44:02,  6.03it/s]\titers: 15800, epoch: 3 | loss: 0.1698889\n",
      "\tspeed: 0.1667s/iter; left time: 86514.6450s\n",
      "15899it [44:18,  6.06it/s]\titers: 15900, epoch: 3 | loss: 0.3378665\n",
      "\tspeed: 0.1653s/iter; left time: 85776.4855s\n",
      "15999it [44:35,  5.97it/s]\titers: 16000, epoch: 3 | loss: 0.3433162\n",
      "\tspeed: 0.1681s/iter; left time: 87175.7393s\n",
      "16099it [44:52,  6.03it/s]\titers: 16100, epoch: 3 | loss: 0.3943836\n",
      "\tspeed: 0.1689s/iter; left time: 87608.9030s\n",
      "16199it [45:09,  6.14it/s]\titers: 16200, epoch: 3 | loss: 0.0386212\n",
      "\tspeed: 0.1657s/iter; left time: 85930.6406s\n",
      "16299it [45:25,  6.08it/s]\titers: 16300, epoch: 3 | loss: 0.3458451\n",
      "\tspeed: 0.1651s/iter; left time: 85563.8562s\n",
      "16399it [45:42,  6.03it/s]\titers: 16400, epoch: 3 | loss: 0.0949999\n",
      "\tspeed: 0.1662s/iter; left time: 86125.3836s\n",
      "16499it [45:59,  6.02it/s]\titers: 16500, epoch: 3 | loss: 0.2163284\n",
      "\tspeed: 0.1675s/iter; left time: 86792.2063s\n",
      "16599it [46:15,  6.07it/s]\titers: 16600, epoch: 3 | loss: 0.3966898\n",
      "\tspeed: 0.1673s/iter; left time: 86692.6490s\n",
      "16699it [46:32,  6.08it/s]\titers: 16700, epoch: 3 | loss: 0.1036175\n",
      "\tspeed: 0.1669s/iter; left time: 86469.5805s\n",
      "16799it [46:49,  6.09it/s]\titers: 16800, epoch: 3 | loss: 0.1203048\n",
      "\tspeed: 0.1688s/iter; left time: 87435.9494s\n",
      "16899it [47:06,  6.12it/s]\titers: 16900, epoch: 3 | loss: 0.0974374\n",
      "\tspeed: 0.1674s/iter; left time: 86677.1246s\n",
      "16999it [47:22,  4.93it/s]\titers: 17000, epoch: 3 | loss: 0.4264764\n",
      "\tspeed: 0.1680s/iter; left time: 86960.0240s\n",
      "17099it [47:39,  6.02it/s]\titers: 17100, epoch: 3 | loss: 0.0620461\n",
      "\tspeed: 0.1664s/iter; left time: 86120.9876s\n",
      "17199it [47:56,  6.10it/s]\titers: 17200, epoch: 3 | loss: 0.0859113\n",
      "\tspeed: 0.1651s/iter; left time: 85461.8847s\n",
      "17299it [48:12,  6.12it/s]\titers: 17300, epoch: 3 | loss: 0.0658910\n",
      "\tspeed: 0.1681s/iter; left time: 86971.8503s\n",
      "17399it [48:29,  6.02it/s]\titers: 17400, epoch: 3 | loss: 0.1870735\n",
      "\tspeed: 0.1680s/iter; left time: 86891.5470s\n",
      "17499it [48:46,  6.01it/s]\titers: 17500, epoch: 3 | loss: 0.4688503\n",
      "\tspeed: 0.1690s/iter; left time: 87408.8887s\n",
      "17599it [49:03,  6.05it/s]\titers: 17600, epoch: 3 | loss: 0.0445735\n",
      "\tspeed: 0.1687s/iter; left time: 87240.2228s\n",
      "17699it [49:20,  6.03it/s]\titers: 17700, epoch: 3 | loss: 0.2612444\n",
      "\tspeed: 0.1682s/iter; left time: 86981.9426s\n",
      "17799it [49:37,  6.08it/s]\titers: 17800, epoch: 3 | loss: 0.1887956\n",
      "\tspeed: 0.1688s/iter; left time: 87247.6768s\n",
      "17899it [49:53,  5.87it/s]\titers: 17900, epoch: 3 | loss: 0.0808792\n",
      "\tspeed: 0.1666s/iter; left time: 86116.7106s\n",
      "17999it [50:10,  6.08it/s]\titers: 18000, epoch: 3 | loss: 0.0804561\n",
      "\tspeed: 0.1652s/iter; left time: 85353.2435s\n",
      "18099it [50:27,  6.05it/s]\titers: 18100, epoch: 3 | loss: 0.1008144\n",
      "\tspeed: 0.1677s/iter; left time: 86607.6308s\n",
      "18199it [50:43,  6.08it/s]\titers: 18200, epoch: 3 | loss: 0.2224946\n",
      "\tspeed: 0.1670s/iter; left time: 86242.2521s\n",
      "18299it [51:00,  6.08it/s]\titers: 18300, epoch: 3 | loss: 0.2469314\n",
      "\tspeed: 0.1685s/iter; left time: 87022.3627s\n",
      "18399it [51:17,  6.06it/s]\titers: 18400, epoch: 3 | loss: 0.4132911\n",
      "\tspeed: 0.1680s/iter; left time: 86712.6814s\n",
      "18499it [51:34,  6.06it/s]\titers: 18500, epoch: 3 | loss: 0.0588572\n",
      "\tspeed: 0.1685s/iter; left time: 87000.8463s\n",
      "18599it [51:50,  6.03it/s]\titers: 18600, epoch: 3 | loss: 0.2735735\n",
      "\tspeed: 0.1671s/iter; left time: 86220.8515s\n",
      "18699it [52:07,  6.14it/s]\titers: 18700, epoch: 3 | loss: 0.0940480\n",
      "\tspeed: 0.1682s/iter; left time: 86809.3201s\n",
      "18799it [52:24,  5.97it/s]\titers: 18800, epoch: 3 | loss: 0.0652715\n",
      "\tspeed: 0.1646s/iter; left time: 84909.8865s\n",
      "18899it [52:40,  6.08it/s]\titers: 18900, epoch: 3 | loss: 0.2278994\n",
      "\tspeed: 0.1661s/iter; left time: 85674.4685s\n",
      "18999it [52:57,  6.01it/s]\titers: 19000, epoch: 3 | loss: 0.2484599\n",
      "\tspeed: 0.1671s/iter; left time: 86185.7490s\n",
      "19099it [53:14,  6.07it/s]\titers: 19100, epoch: 3 | loss: 0.0423316\n",
      "\tspeed: 0.1672s/iter; left time: 86185.6745s\n",
      "19199it [53:30,  6.09it/s]\titers: 19200, epoch: 3 | loss: 0.3814060\n",
      "\tspeed: 0.1649s/iter; left time: 85013.5202s\n",
      "19299it [53:47,  5.48it/s]\titers: 19300, epoch: 3 | loss: 0.2447930\n",
      "\tspeed: 0.1672s/iter; left time: 86171.8246s\n",
      "19399it [54:04,  6.00it/s]\titers: 19400, epoch: 3 | loss: 0.0327782\n",
      "\tspeed: 0.1652s/iter; left time: 85118.2657s\n",
      "19499it [54:20,  6.06it/s]\titers: 19500, epoch: 3 | loss: 0.2049045\n",
      "\tspeed: 0.1676s/iter; left time: 86368.1126s\n",
      "19599it [54:37,  6.06it/s]\titers: 19600, epoch: 3 | loss: 0.1376462\n",
      "\tspeed: 0.1683s/iter; left time: 86683.0261s\n",
      "19699it [54:54,  6.05it/s]\titers: 19700, epoch: 3 | loss: 0.0514238\n",
      "\tspeed: 0.1663s/iter; left time: 85652.0923s\n",
      "19799it [55:10,  6.03it/s]\titers: 19800, epoch: 3 | loss: 0.1154998\n",
      "\tspeed: 0.1667s/iter; left time: 85834.2918s\n",
      "19899it [55:27,  6.05it/s]\titers: 19900, epoch: 3 | loss: 0.2234884\n",
      "\tspeed: 0.1666s/iter; left time: 85751.5110s\n",
      "19999it [55:44,  5.97it/s]\titers: 20000, epoch: 3 | loss: 0.4575052\n",
      "\tspeed: 0.1661s/iter; left time: 85481.3602s\n",
      "20099it [56:01,  6.03it/s]\titers: 20100, epoch: 3 | loss: 0.0952571\n",
      "\tspeed: 0.1684s/iter; left time: 86675.9983s\n",
      "20199it [56:17,  6.03it/s]\titers: 20200, epoch: 3 | loss: 0.0810745\n",
      "\tspeed: 0.1663s/iter; left time: 85551.2895s\n",
      "20299it [56:34,  5.98it/s]\titers: 20300, epoch: 3 | loss: 0.1043954\n",
      "\tspeed: 0.1653s/iter; left time: 85014.2404s\n",
      "20399it [56:51,  6.00it/s]\titers: 20400, epoch: 3 | loss: 0.3670653\n",
      "\tspeed: 0.1690s/iter; left time: 86899.5398s\n",
      "20499it [57:07,  6.13it/s]\titers: 20500, epoch: 3 | loss: 0.1164811\n",
      "\tspeed: 0.1680s/iter; left time: 86381.5954s\n",
      "20599it [57:24,  6.02it/s]\titers: 20600, epoch: 3 | loss: 0.2767954\n",
      "\tspeed: 0.1644s/iter; left time: 84513.9083s\n",
      "20699it [57:40,  6.08it/s]\titers: 20700, epoch: 3 | loss: 0.0525283\n",
      "\tspeed: 0.1652s/iter; left time: 84926.8616s\n",
      "20799it [57:57,  5.91it/s]\titers: 20800, epoch: 3 | loss: 0.0306008\n",
      "\tspeed: 0.1669s/iter; left time: 85767.5677s\n",
      "20899it [58:14,  6.13it/s]\titers: 20900, epoch: 3 | loss: 0.1206944\n",
      "\tspeed: 0.1687s/iter; left time: 86701.2500s\n",
      "20999it [58:30,  6.04it/s]\titers: 21000, epoch: 3 | loss: 0.0645737\n",
      "\tspeed: 0.1651s/iter; left time: 84811.2548s\n",
      "21099it [58:47,  6.00it/s]\titers: 21100, epoch: 3 | loss: 0.0566830\n",
      "\tspeed: 0.1657s/iter; left time: 85123.8966s\n",
      "21199it [59:04,  5.89it/s]\titers: 21200, epoch: 3 | loss: 0.1161811\n",
      "\tspeed: 0.1676s/iter; left time: 86055.3094s\n",
      "21299it [59:20,  6.13it/s]\titers: 21300, epoch: 3 | loss: 0.1833278\n",
      "\tspeed: 0.1643s/iter; left time: 84362.7405s\n",
      "21399it [59:37,  6.13it/s]\titers: 21400, epoch: 3 | loss: 0.1035904\n",
      "\tspeed: 0.1679s/iter; left time: 86183.6012s\n",
      "21499it [59:54,  6.11it/s]\titers: 21500, epoch: 3 | loss: 0.1126701\n",
      "\tspeed: 0.1676s/iter; left time: 86001.1896s\n",
      "21599it [1:00:11,  6.01it/s]\titers: 21600, epoch: 3 | loss: 0.0524276\n",
      "\tspeed: 0.1694s/iter; left time: 86919.8201s\n",
      "21699it [1:00:27,  6.08it/s]\titers: 21700, epoch: 3 | loss: 0.2978765\n",
      "\tspeed: 0.1658s/iter; left time: 85036.0311s\n",
      "21799it [1:00:44,  6.04it/s]\titers: 21800, epoch: 3 | loss: 0.0327909\n",
      "\tspeed: 0.1678s/iter; left time: 86068.5598s\n",
      "21899it [1:01:01,  6.07it/s]\titers: 21900, epoch: 3 | loss: 0.1458005\n",
      "\tspeed: 0.1684s/iter; left time: 86329.1035s\n",
      "21999it [1:01:18,  6.07it/s]\titers: 22000, epoch: 3 | loss: 0.3914178\n",
      "\tspeed: 0.1690s/iter; left time: 86636.5714s\n",
      "22099it [1:01:34,  6.07it/s]\titers: 22100, epoch: 3 | loss: 0.0868230\n",
      "\tspeed: 0.1659s/iter; left time: 85027.7216s\n",
      "22199it [1:01:51,  6.00it/s]\titers: 22200, epoch: 3 | loss: 0.1964748\n",
      "\tspeed: 0.1668s/iter; left time: 85493.3242s\n",
      "22299it [1:02:08,  6.11it/s]\titers: 22300, epoch: 3 | loss: 0.0421848\n",
      "\tspeed: 0.1661s/iter; left time: 85124.0637s\n",
      "22399it [1:02:24,  6.04it/s]\titers: 22400, epoch: 3 | loss: 0.1987894\n",
      "\tspeed: 0.1656s/iter; left time: 84834.0531s\n",
      "22499it [1:02:41,  6.13it/s]\titers: 22500, epoch: 3 | loss: 0.1874323\n",
      "\tspeed: 0.1673s/iter; left time: 85704.0764s\n",
      "22599it [1:02:58,  5.97it/s]\titers: 22600, epoch: 3 | loss: 0.2596111\n",
      "\tspeed: 0.1670s/iter; left time: 85507.3861s\n",
      "22699it [1:03:14,  6.08it/s]\titers: 22700, epoch: 3 | loss: 0.0531811\n",
      "\tspeed: 0.1666s/iter; left time: 85309.6881s\n",
      "22799it [1:03:31,  6.02it/s]\titers: 22800, epoch: 3 | loss: 0.3329715\n",
      "\tspeed: 0.1664s/iter; left time: 85153.4120s\n",
      "22899it [1:03:48,  6.12it/s]\titers: 22900, epoch: 3 | loss: 0.2399371\n",
      "\tspeed: 0.1661s/iter; left time: 85026.4594s\n",
      "22999it [1:04:04,  5.59it/s]\titers: 23000, epoch: 3 | loss: 0.1034057\n",
      "\tspeed: 0.1663s/iter; left time: 85110.9177s\n",
      "23099it [1:04:21,  6.04it/s]\titers: 23100, epoch: 3 | loss: 0.0478396\n",
      "\tspeed: 0.1645s/iter; left time: 84166.8825s\n",
      "23199it [1:04:38,  6.00it/s]\titers: 23200, epoch: 3 | loss: 0.2047163\n",
      "\tspeed: 0.1688s/iter; left time: 86329.5865s\n",
      "23299it [1:04:54,  6.04it/s]\titers: 23300, epoch: 3 | loss: 0.4032577\n",
      "\tspeed: 0.1666s/iter; left time: 85188.9697s\n",
      "23399it [1:05:11,  6.00it/s]\titers: 23400, epoch: 3 | loss: 0.2533425\n",
      "\tspeed: 0.1695s/iter; left time: 86643.4977s\n",
      "23499it [1:05:28,  6.06it/s]\titers: 23500, epoch: 3 | loss: 0.1727314\n",
      "\tspeed: 0.1672s/iter; left time: 85477.2280s\n",
      "23599it [1:05:45,  6.05it/s]\titers: 23600, epoch: 3 | loss: 0.1944556\n",
      "\tspeed: 0.1669s/iter; left time: 85277.5790s\n",
      "23699it [1:06:01,  6.12it/s]\titers: 23700, epoch: 3 | loss: 0.2032152\n",
      "\tspeed: 0.1668s/iter; left time: 85223.5162s\n",
      "23799it [1:06:18,  6.03it/s]\titers: 23800, epoch: 3 | loss: 0.0935576\n",
      "\tspeed: 0.1657s/iter; left time: 84658.0952s\n",
      "23899it [1:06:34,  5.74it/s]\titers: 23900, epoch: 3 | loss: 0.1069295\n",
      "\tspeed: 0.1665s/iter; left time: 85040.9648s\n",
      "23999it [1:06:51,  6.06it/s]\titers: 24000, epoch: 3 | loss: 0.1685874\n",
      "\tspeed: 0.1659s/iter; left time: 84740.8190s\n",
      "24099it [1:07:08,  6.01it/s]\titers: 24100, epoch: 3 | loss: 0.0374281\n",
      "\tspeed: 0.1677s/iter; left time: 85630.2021s\n",
      "24199it [1:07:24,  5.99it/s]\titers: 24200, epoch: 3 | loss: 0.1642046\n",
      "\tspeed: 0.1664s/iter; left time: 84964.5729s\n",
      "24299it [1:07:41,  6.00it/s]\titers: 24300, epoch: 3 | loss: 0.1555015\n",
      "\tspeed: 0.1654s/iter; left time: 84416.6159s\n",
      "24399it [1:07:58,  5.98it/s]\titers: 24400, epoch: 3 | loss: 0.1146324\n",
      "\tspeed: 0.1699s/iter; left time: 86714.1501s\n",
      "24499it [1:08:15,  6.07it/s]\titers: 24500, epoch: 3 | loss: 0.0633434\n",
      "\tspeed: 0.1681s/iter; left time: 85776.0200s\n",
      "24599it [1:08:31,  6.04it/s]\titers: 24600, epoch: 3 | loss: 0.2264463\n",
      "\tspeed: 0.1662s/iter; left time: 84801.1937s\n",
      "24699it [1:08:48,  6.04it/s]\titers: 24700, epoch: 3 | loss: 0.1968326\n",
      "\tspeed: 0.1658s/iter; left time: 84538.0729s\n",
      "24799it [1:09:05,  6.04it/s]\titers: 24800, epoch: 3 | loss: 0.2734780\n",
      "\tspeed: 0.1654s/iter; left time: 84342.5881s\n",
      "24899it [1:09:21,  6.12it/s]\titers: 24900, epoch: 3 | loss: 0.1068762\n",
      "\tspeed: 0.1689s/iter; left time: 86093.8347s\n",
      "24999it [1:09:38,  4.69it/s]\titers: 25000, epoch: 3 | loss: 0.1704529\n",
      "\tspeed: 0.1689s/iter; left time: 86089.2384s\n",
      "25099it [1:09:55,  6.00it/s]\titers: 25100, epoch: 3 | loss: 0.1279649\n",
      "\tspeed: 0.1653s/iter; left time: 84234.2853s\n",
      "25199it [1:10:12,  6.07it/s]\titers: 25200, epoch: 3 | loss: 0.0830435\n",
      "\tspeed: 0.1674s/iter; left time: 85288.0841s\n",
      "25299it [1:10:28,  6.09it/s]\titers: 25300, epoch: 3 | loss: 0.1221675\n",
      "\tspeed: 0.1660s/iter; left time: 84560.4503s\n",
      "25399it [1:10:45,  6.09it/s]\titers: 25400, epoch: 3 | loss: 0.0902356\n",
      "\tspeed: 0.1681s/iter; left time: 85608.0514s\n",
      "25499it [1:11:02,  6.03it/s]\titers: 25500, epoch: 3 | loss: 0.0512791\n",
      "\tspeed: 0.1668s/iter; left time: 84918.7630s\n",
      "25599it [1:11:19,  6.01it/s]\titers: 25600, epoch: 3 | loss: 0.1689345\n",
      "\tspeed: 0.1697s/iter; left time: 86385.0633s\n",
      "25699it [1:11:36,  6.02it/s]\titers: 25700, epoch: 3 | loss: 0.0889149\n",
      "\tspeed: 0.1700s/iter; left time: 86540.1806s\n",
      "25799it [1:11:52,  6.01it/s]\titers: 25800, epoch: 3 | loss: 0.0270811\n",
      "\tspeed: 0.1660s/iter; left time: 84495.9272s\n",
      "25899it [1:12:09,  6.10it/s]\titers: 25900, epoch: 3 | loss: 0.1272263\n",
      "\tspeed: 0.1657s/iter; left time: 84307.7710s\n",
      "25999it [1:12:25,  5.93it/s]\titers: 26000, epoch: 3 | loss: 0.0245215\n",
      "\tspeed: 0.1663s/iter; left time: 84611.1302s\n",
      "26099it [1:12:42,  6.10it/s]\titers: 26100, epoch: 3 | loss: 0.2207496\n",
      "\tspeed: 0.1657s/iter; left time: 84275.7935s\n",
      "26199it [1:12:59,  6.01it/s]\titers: 26200, epoch: 3 | loss: 0.1662920\n",
      "\tspeed: 0.1673s/iter; left time: 85056.2764s\n",
      "26299it [1:13:15,  6.03it/s]\titers: 26300, epoch: 3 | loss: 0.0431960\n",
      "\tspeed: 0.1657s/iter; left time: 84220.1669s\n",
      "26399it [1:13:32,  6.02it/s]\titers: 26400, epoch: 3 | loss: 0.0452680\n",
      "\tspeed: 0.1671s/iter; left time: 84912.9366s\n",
      "26499it [1:13:49,  6.03it/s]\titers: 26500, epoch: 3 | loss: 0.1099562\n",
      "\tspeed: 0.1667s/iter; left time: 84710.3852s\n",
      "26599it [1:14:05,  6.00it/s]\titers: 26600, epoch: 3 | loss: 0.0434592\n",
      "\tspeed: 0.1675s/iter; left time: 85130.1183s\n",
      "26699it [1:14:22,  6.01it/s]\titers: 26700, epoch: 3 | loss: 0.0637829\n",
      "\tspeed: 0.1695s/iter; left time: 86110.5716s\n",
      "26799it [1:14:39,  6.00it/s]\titers: 26800, epoch: 3 | loss: 0.0324697\n",
      "\tspeed: 0.1694s/iter; left time: 86061.8959s\n",
      "26899it [1:14:56,  6.06it/s]\titers: 26900, epoch: 3 | loss: 0.1837632\n",
      "\tspeed: 0.1687s/iter; left time: 85677.2880s\n",
      "26999it [1:15:13,  6.08it/s]\titers: 27000, epoch: 3 | loss: 0.1359375\n",
      "\tspeed: 0.1671s/iter; left time: 84856.7579s\n",
      "27099it [1:15:30,  5.79it/s]\titers: 27100, epoch: 3 | loss: 0.0667904\n",
      "\tspeed: 0.1692s/iter; left time: 85896.7064s\n",
      "27199it [1:15:47,  4.82it/s]\titers: 27200, epoch: 3 | loss: 0.1674396\n",
      "\tspeed: 0.1683s/iter; left time: 85430.6737s\n",
      "27299it [1:16:03,  5.99it/s]\titers: 27300, epoch: 3 | loss: 0.3368477\n",
      "\tspeed: 0.1664s/iter; left time: 84425.3410s\n",
      "27399it [1:16:20,  5.99it/s]\titers: 27400, epoch: 3 | loss: 0.3161516\n",
      "\tspeed: 0.1670s/iter; left time: 84721.0950s\n",
      "27499it [1:16:37,  6.00it/s]\titers: 27500, epoch: 3 | loss: 0.3222137\n",
      "\tspeed: 0.1660s/iter; left time: 84173.7761s\n",
      "27599it [1:16:53,  6.01it/s]\titers: 27600, epoch: 3 | loss: 0.1251161\n",
      "\tspeed: 0.1668s/iter; left time: 84582.4781s\n",
      "27699it [1:17:10,  6.07it/s]\titers: 27700, epoch: 3 | loss: 0.1269917\n",
      "\tspeed: 0.1662s/iter; left time: 84237.9883s\n",
      "27799it [1:17:27,  6.03it/s]\titers: 27800, epoch: 3 | loss: 0.1093791\n",
      "\tspeed: 0.1696s/iter; left time: 85982.3822s\n",
      "27899it [1:17:44,  6.02it/s]\titers: 27900, epoch: 3 | loss: 0.1498055\n",
      "\tspeed: 0.1690s/iter; left time: 85658.9214s\n",
      "27999it [1:18:01,  6.02it/s]\titers: 28000, epoch: 3 | loss: 0.1607132\n",
      "\tspeed: 0.1681s/iter; left time: 85192.7325s\n",
      "28099it [1:18:17,  6.11it/s]\titers: 28100, epoch: 3 | loss: 0.1401153\n",
      "\tspeed: 0.1675s/iter; left time: 84846.8459s\n",
      "28199it [1:18:34,  5.70it/s]\titers: 28200, epoch: 3 | loss: 0.1420034\n",
      "\tspeed: 0.1684s/iter; left time: 85304.6802s\n",
      "28299it [1:18:51,  6.00it/s]\titers: 28300, epoch: 3 | loss: 0.5078357\n",
      "\tspeed: 0.1656s/iter; left time: 83854.4207s\n",
      "28399it [1:19:07,  5.93it/s]\titers: 28400, epoch: 3 | loss: 0.0869999\n",
      "\tspeed: 0.1674s/iter; left time: 84757.9020s\n",
      "28499it [1:19:24,  6.02it/s]\titers: 28500, epoch: 3 | loss: 0.2067414\n",
      "\tspeed: 0.1666s/iter; left time: 84349.1147s\n",
      "28599it [1:19:41,  6.03it/s]\titers: 28600, epoch: 3 | loss: 0.3722058\n",
      "\tspeed: 0.1661s/iter; left time: 84062.7511s\n",
      "28699it [1:19:57,  6.03it/s]\titers: 28700, epoch: 3 | loss: 0.1305753\n",
      "\tspeed: 0.1668s/iter; left time: 84382.2711s\n",
      "28799it [1:20:14,  5.98it/s]\titers: 28800, epoch: 3 | loss: 0.2523097\n",
      "\tspeed: 0.1681s/iter; left time: 85056.9782s\n",
      "28899it [1:20:31,  6.08it/s]\titers: 28900, epoch: 3 | loss: 0.0387710\n",
      "\tspeed: 0.1685s/iter; left time: 85246.8621s\n",
      "28999it [1:20:48,  6.00it/s]\titers: 29000, epoch: 3 | loss: 0.1321580\n",
      "\tspeed: 0.1668s/iter; left time: 84330.5171s\n",
      "29099it [1:21:05,  6.09it/s]\titers: 29100, epoch: 3 | loss: 0.0703731\n",
      "\tspeed: 0.1688s/iter; left time: 85329.9786s\n",
      "29199it [1:21:21,  6.09it/s]\titers: 29200, epoch: 3 | loss: 0.1809044\n",
      "\tspeed: 0.1659s/iter; left time: 83870.3364s\n",
      "29299it [1:21:38,  5.51it/s]\titers: 29300, epoch: 3 | loss: 0.2490336\n",
      "\tspeed: 0.1670s/iter; left time: 84386.9742s\n",
      "29399it [1:21:55,  6.01it/s]\titers: 29400, epoch: 3 | loss: 0.0314322\n",
      "\tspeed: 0.1676s/iter; left time: 84669.6852s\n",
      "29499it [1:22:11,  6.09it/s]\titers: 29500, epoch: 3 | loss: 0.0594514\n",
      "\tspeed: 0.1679s/iter; left time: 84844.0646s\n",
      "29599it [1:22:28,  6.07it/s]\titers: 29600, epoch: 3 | loss: 0.2183356\n",
      "\tspeed: 0.1686s/iter; left time: 85174.9580s\n",
      "29699it [1:22:45,  6.12it/s]\titers: 29700, epoch: 3 | loss: 0.1073037\n",
      "\tspeed: 0.1691s/iter; left time: 85372.3055s\n",
      "29705it [1:22:46,  5.98it/s]\n",
      "Epoch: 3 cost time: 4966.806148767471\n",
      "6481it [08:34, 12.60it/s]\n",
      "6457it [08:36, 12.51it/s]\n",
      "Epoch: 3 | Train Loss: 0.1874742 Vali Loss: 0.3113709 Test Loss: 0.4294630 MAE Loss: 0.3985128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:16,  6.09it/s]\titers: 100, epoch: 4 | loss: 0.4812549\n",
      "\tspeed: 10.4883s/iter; left time: 5295410.2530s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 4 | loss: 0.7354182\n",
      "\tspeed: 0.1667s/iter; left time: 84122.6288s\n",
      "299it [00:50,  5.36it/s]\titers: 300, epoch: 4 | loss: 0.1614022\n",
      "\tspeed: 0.1695s/iter; left time: 85522.8748s\n",
      "399it [01:07,  6.06it/s]\titers: 400, epoch: 4 | loss: 0.0358172\n",
      "\tspeed: 0.1656s/iter; left time: 83537.8121s\n",
      "499it [01:23,  6.09it/s]\titers: 500, epoch: 4 | loss: 0.0631168\n",
      "\tspeed: 0.1665s/iter; left time: 84011.9868s\n",
      "599it [01:40,  6.06it/s]\titers: 600, epoch: 4 | loss: 0.2220306\n",
      "\tspeed: 0.1661s/iter; left time: 83758.3762s\n",
      "699it [01:57,  6.02it/s]\titers: 700, epoch: 4 | loss: 0.0815879\n",
      "\tspeed: 0.1675s/iter; left time: 84450.0447s\n",
      "799it [02:14,  6.05it/s]\titers: 800, epoch: 4 | loss: 0.6947249\n",
      "\tspeed: 0.1692s/iter; left time: 85313.2073s\n",
      "899it [02:30,  5.88it/s]\titers: 900, epoch: 4 | loss: 0.2730703\n",
      "\tspeed: 0.1681s/iter; left time: 84740.6000s\n",
      "999it [02:47,  5.99it/s]\titers: 1000, epoch: 4 | loss: 0.1139679\n",
      "\tspeed: 0.1653s/iter; left time: 83330.7847s\n",
      "1099it [03:03,  5.99it/s]\titers: 1100, epoch: 4 | loss: 0.1566250\n",
      "\tspeed: 0.1659s/iter; left time: 83594.8443s\n",
      "1199it [03:20,  6.10it/s]\titers: 1200, epoch: 4 | loss: 0.1299630\n",
      "\tspeed: 0.1673s/iter; left time: 84287.1154s\n",
      "1299it [03:37,  6.06it/s]\titers: 1300, epoch: 4 | loss: 0.0675168\n",
      "\tspeed: 0.1657s/iter; left time: 83448.3504s\n",
      "1399it [03:53,  5.99it/s]\titers: 1400, epoch: 4 | loss: 0.1309020\n",
      "\tspeed: 0.1664s/iter; left time: 83778.0649s\n",
      "1499it [04:10,  5.27it/s]\titers: 1500, epoch: 4 | loss: 0.0353064\n",
      "\tspeed: 0.1671s/iter; left time: 84127.7740s\n",
      "1599it [04:27,  6.03it/s]\titers: 1600, epoch: 4 | loss: 0.0500858\n",
      "\tspeed: 0.1668s/iter; left time: 83969.9675s\n",
      "1699it [04:43,  6.07it/s]\titers: 1700, epoch: 4 | loss: 0.0340070\n",
      "\tspeed: 0.1666s/iter; left time: 83864.0226s\n",
      "1799it [05:00,  5.91it/s]\titers: 1800, epoch: 4 | loss: 0.1401872\n",
      "\tspeed: 0.1676s/iter; left time: 84338.5108s\n",
      "1899it [05:17,  6.05it/s]\titers: 1900, epoch: 4 | loss: 0.0913064\n",
      "\tspeed: 0.1673s/iter; left time: 84190.0046s\n",
      "1999it [05:34,  6.04it/s]\titers: 2000, epoch: 4 | loss: 0.0963837\n",
      "\tspeed: 0.1678s/iter; left time: 84419.7188s\n",
      "2099it [05:50,  6.16it/s]\titers: 2100, epoch: 4 | loss: 0.2892154\n",
      "\tspeed: 0.1660s/iter; left time: 83477.8718s\n",
      "2199it [06:07,  6.04it/s]\titers: 2200, epoch: 4 | loss: 0.0701933\n",
      "\tspeed: 0.1663s/iter; left time: 83627.9262s\n",
      "2299it [06:24,  5.98it/s]\titers: 2300, epoch: 4 | loss: 0.0627193\n",
      "\tspeed: 0.1663s/iter; left time: 83588.8394s\n",
      "2399it [06:40,  6.02it/s]\titers: 2400, epoch: 4 | loss: 0.3727893\n",
      "\tspeed: 0.1678s/iter; left time: 84347.0276s\n",
      "2499it [06:57,  6.14it/s]\titers: 2500, epoch: 4 | loss: 0.1494918\n",
      "\tspeed: 0.1662s/iter; left time: 83520.0469s\n",
      "2599it [07:14,  5.99it/s]\titers: 2600, epoch: 4 | loss: 0.0746606\n",
      "\tspeed: 0.1686s/iter; left time: 84703.8829s\n",
      "2699it [07:31,  6.10it/s]\titers: 2700, epoch: 4 | loss: 0.0875119\n",
      "\tspeed: 0.1691s/iter; left time: 84930.0676s\n",
      "2799it [07:48,  5.96it/s]\titers: 2800, epoch: 4 | loss: 0.0291754\n",
      "\tspeed: 0.1690s/iter; left time: 84859.4274s\n",
      "2899it [08:04,  6.10it/s]\titers: 2900, epoch: 4 | loss: 0.4491275\n",
      "\tspeed: 0.1666s/iter; left time: 83626.6991s\n",
      "2999it [08:21,  6.08it/s]\titers: 3000, epoch: 4 | loss: 0.3607832\n",
      "\tspeed: 0.1660s/iter; left time: 83350.8953s\n",
      "3099it [08:37,  6.00it/s]\titers: 3100, epoch: 4 | loss: 0.0465076\n",
      "\tspeed: 0.1658s/iter; left time: 83199.1351s\n",
      "3199it [08:54,  6.06it/s]\titers: 3200, epoch: 4 | loss: 0.3225823\n",
      "\tspeed: 0.1681s/iter; left time: 84367.8629s\n",
      "3299it [09:11,  6.03it/s]\titers: 3300, epoch: 4 | loss: 0.0477697\n",
      "\tspeed: 0.1692s/iter; left time: 84897.2758s\n",
      "3399it [09:28,  6.01it/s]\titers: 3400, epoch: 4 | loss: 0.0354022\n",
      "\tspeed: 0.1686s/iter; left time: 84576.5128s\n",
      "3499it [09:45,  6.01it/s]\titers: 3500, epoch: 4 | loss: 0.0896320\n",
      "\tspeed: 0.1666s/iter; left time: 83532.6907s\n",
      "3599it [10:02,  6.03it/s]\titers: 3600, epoch: 4 | loss: 0.0589503\n",
      "\tspeed: 0.1683s/iter; left time: 84369.2832s\n",
      "3699it [10:18,  6.10it/s]\titers: 3700, epoch: 4 | loss: 0.4501051\n",
      "\tspeed: 0.1671s/iter; left time: 83755.0056s\n",
      "3799it [10:35,  6.03it/s]\titers: 3800, epoch: 4 | loss: 0.1571617\n",
      "\tspeed: 0.1680s/iter; left time: 84190.8702s\n",
      "3899it [10:52,  6.07it/s]\titers: 3900, epoch: 4 | loss: 0.1338965\n",
      "\tspeed: 0.1682s/iter; left time: 84296.7872s\n",
      "3999it [11:09,  5.62it/s]\titers: 4000, epoch: 4 | loss: 0.1684163\n",
      "\tspeed: 0.1667s/iter; left time: 83515.8059s\n",
      "4099it [11:25,  5.99it/s]\titers: 4100, epoch: 4 | loss: 0.1370188\n",
      "\tspeed: 0.1661s/iter; left time: 83212.1597s\n",
      "4199it [11:42,  5.97it/s]\titers: 4200, epoch: 4 | loss: 0.2637285\n",
      "\tspeed: 0.1689s/iter; left time: 84595.0717s\n",
      "4299it [11:59,  6.06it/s]\titers: 4300, epoch: 4 | loss: 0.0622646\n",
      "\tspeed: 0.1685s/iter; left time: 84375.7981s\n",
      "4399it [12:16,  6.03it/s]\titers: 4400, epoch: 4 | loss: 0.0566508\n",
      "\tspeed: 0.1679s/iter; left time: 84040.2090s\n",
      "4499it [12:33,  5.97it/s]\titers: 4500, epoch: 4 | loss: 0.1863081\n",
      "\tspeed: 0.1680s/iter; left time: 84072.2151s\n",
      "4599it [12:49,  6.00it/s]\titers: 4600, epoch: 4 | loss: 0.1493955\n",
      "\tspeed: 0.1683s/iter; left time: 84230.3915s\n",
      "4699it [13:06,  6.04it/s]\titers: 4700, epoch: 4 | loss: 0.6047858\n",
      "\tspeed: 0.1700s/iter; left time: 85039.2364s\n",
      "4799it [13:23,  6.03it/s]\titers: 4800, epoch: 4 | loss: 0.2891861\n",
      "\tspeed: 0.1691s/iter; left time: 84598.5695s\n",
      "4899it [13:40,  5.56it/s]\titers: 4900, epoch: 4 | loss: 0.1896762\n",
      "\tspeed: 0.1697s/iter; left time: 84884.2422s\n",
      "4999it [13:57,  6.04it/s]\titers: 5000, epoch: 4 | loss: 0.5970343\n",
      "\tspeed: 0.1662s/iter; left time: 83105.9610s\n",
      "5099it [14:14,  6.03it/s]\titers: 5100, epoch: 4 | loss: 0.0820593\n",
      "\tspeed: 0.1685s/iter; left time: 84213.8416s\n",
      "5199it [14:30,  6.01it/s]\titers: 5200, epoch: 4 | loss: 0.1894921\n",
      "\tspeed: 0.1677s/iter; left time: 83800.3338s\n",
      "5299it [14:47,  6.06it/s]\titers: 5300, epoch: 4 | loss: 0.1166583\n",
      "\tspeed: 0.1675s/iter; left time: 83709.1731s\n",
      "5399it [15:04,  6.06it/s]\titers: 5400, epoch: 4 | loss: 0.2088642\n",
      "\tspeed: 0.1700s/iter; left time: 84916.0700s\n",
      "5499it [15:21,  6.10it/s]\titers: 5500, epoch: 4 | loss: 0.1452461\n",
      "\tspeed: 0.1693s/iter; left time: 84587.1750s\n",
      "5599it [15:38,  6.04it/s]\titers: 5600, epoch: 4 | loss: 0.2741712\n",
      "\tspeed: 0.1672s/iter; left time: 83477.8297s\n",
      "5699it [15:54,  6.04it/s]\titers: 5700, epoch: 4 | loss: 0.7247469\n",
      "\tspeed: 0.1661s/iter; left time: 82948.6790s\n",
      "5799it [16:11,  6.01it/s]\titers: 5800, epoch: 4 | loss: 0.2309612\n",
      "\tspeed: 0.1683s/iter; left time: 83990.8594s\n",
      "5899it [16:28,  6.07it/s]\titers: 5900, epoch: 4 | loss: 0.2590478\n",
      "\tspeed: 0.1692s/iter; left time: 84424.0914s\n",
      "5999it [16:45,  6.02it/s]\titers: 6000, epoch: 4 | loss: 0.1331757\n",
      "\tspeed: 0.1719s/iter; left time: 85780.4786s\n",
      "6099it [17:02,  5.99it/s]\titers: 6100, epoch: 4 | loss: 0.0804507\n",
      "\tspeed: 0.1685s/iter; left time: 84076.4424s\n",
      "6199it [17:19,  6.07it/s]\titers: 6200, epoch: 4 | loss: 0.0959612\n",
      "\tspeed: 0.1667s/iter; left time: 83153.9626s\n",
      "6299it [17:36,  6.07it/s]\titers: 6300, epoch: 4 | loss: 0.4701876\n",
      "\tspeed: 0.1661s/iter; left time: 82841.1892s\n",
      "6399it [17:52,  6.00it/s]\titers: 6400, epoch: 4 | loss: 0.1974417\n",
      "\tspeed: 0.1659s/iter; left time: 82738.5376s\n",
      "6499it [18:09,  6.02it/s]\titers: 6500, epoch: 4 | loss: 0.0769992\n",
      "\tspeed: 0.1670s/iter; left time: 83261.3706s\n",
      "6599it [18:26,  6.06it/s]\titers: 6600, epoch: 4 | loss: 0.4067331\n",
      "\tspeed: 0.1677s/iter; left time: 83564.0834s\n",
      "6699it [18:42,  6.07it/s]\titers: 6700, epoch: 4 | loss: 0.1516930\n",
      "\tspeed: 0.1668s/iter; left time: 83130.9332s\n",
      "6799it [18:59,  6.00it/s]\titers: 6800, epoch: 4 | loss: 0.1609459\n",
      "\tspeed: 0.1659s/iter; left time: 82665.1738s\n",
      "6899it [19:16,  6.04it/s]\titers: 6900, epoch: 4 | loss: 0.2294145\n",
      "\tspeed: 0.1677s/iter; left time: 83537.7113s\n",
      "6999it [19:32,  5.42it/s]\titers: 7000, epoch: 4 | loss: 0.1867167\n",
      "\tspeed: 0.1680s/iter; left time: 83646.8577s\n",
      "7099it [19:49,  6.07it/s]\titers: 7100, epoch: 4 | loss: 0.0363549\n",
      "\tspeed: 0.1677s/iter; left time: 83488.9533s\n",
      "7199it [20:06,  6.07it/s]\titers: 7200, epoch: 4 | loss: 0.0554331\n",
      "\tspeed: 0.1679s/iter; left time: 83576.1424s\n",
      "7299it [20:23,  6.06it/s]\titers: 7300, epoch: 4 | loss: 0.0916149\n",
      "\tspeed: 0.1668s/iter; left time: 82995.3342s\n",
      "7399it [20:39,  6.02it/s]\titers: 7400, epoch: 4 | loss: 0.0484872\n",
      "\tspeed: 0.1649s/iter; left time: 82052.6136s\n",
      "7499it [20:56,  6.09it/s]\titers: 7500, epoch: 4 | loss: 0.0672679\n",
      "\tspeed: 0.1669s/iter; left time: 83007.6607s\n",
      "7599it [21:13,  6.06it/s]\titers: 7600, epoch: 4 | loss: 0.2469484\n",
      "\tspeed: 0.1666s/iter; left time: 82851.4244s\n",
      "7699it [21:29,  6.09it/s]\titers: 7700, epoch: 4 | loss: 0.0525887\n",
      "\tspeed: 0.1648s/iter; left time: 81969.7667s\n",
      "7799it [21:46,  6.10it/s]\titers: 7800, epoch: 4 | loss: 0.1938096\n",
      "\tspeed: 0.1656s/iter; left time: 82315.2284s\n",
      "7899it [22:02,  6.09it/s]\titers: 7900, epoch: 4 | loss: 0.1787034\n",
      "\tspeed: 0.1671s/iter; left time: 83074.2123s\n",
      "7999it [22:19,  6.07it/s]\titers: 8000, epoch: 4 | loss: 0.0409177\n",
      "\tspeed: 0.1657s/iter; left time: 82373.1180s\n",
      "8099it [22:36,  6.16it/s]\titers: 8100, epoch: 4 | loss: 0.0762190\n",
      "\tspeed: 0.1667s/iter; left time: 82842.9056s\n",
      "8199it [22:52,  4.74it/s]\titers: 8200, epoch: 4 | loss: 0.1809125\n",
      "\tspeed: 0.1684s/iter; left time: 83642.5282s\n",
      "8299it [23:09,  5.11it/s]\titers: 8300, epoch: 4 | loss: 0.5294421\n",
      "\tspeed: 0.1681s/iter; left time: 83480.0098s\n",
      "8399it [23:26,  6.10it/s]\titers: 8400, epoch: 4 | loss: 0.0725081\n",
      "\tspeed: 0.1667s/iter; left time: 82798.5559s\n",
      "8499it [23:43,  6.09it/s]\titers: 8500, epoch: 4 | loss: 0.2804595\n",
      "\tspeed: 0.1681s/iter; left time: 83443.1114s\n",
      "8599it [23:59,  6.08it/s]\titers: 8600, epoch: 4 | loss: 0.2118566\n",
      "\tspeed: 0.1677s/iter; left time: 83258.9433s\n",
      "8699it [24:16,  6.12it/s]\titers: 8700, epoch: 4 | loss: 0.1657369\n",
      "\tspeed: 0.1682s/iter; left time: 83456.6606s\n",
      "8799it [24:33,  5.95it/s]\titers: 8800, epoch: 4 | loss: 0.1498206\n",
      "\tspeed: 0.1679s/iter; left time: 83316.7106s\n",
      "8899it [24:50,  6.07it/s]\titers: 8900, epoch: 4 | loss: 0.1550286\n",
      "\tspeed: 0.1698s/iter; left time: 84258.7293s\n",
      "8999it [25:07,  5.99it/s]\titers: 9000, epoch: 4 | loss: 0.1650929\n",
      "\tspeed: 0.1676s/iter; left time: 83123.8231s\n",
      "9099it [25:24,  6.01it/s]\titers: 9100, epoch: 4 | loss: 0.1367343\n",
      "\tspeed: 0.1685s/iter; left time: 83535.5236s\n",
      "9199it [25:40,  6.10it/s]\titers: 9200, epoch: 4 | loss: 0.1016574\n",
      "\tspeed: 0.1649s/iter; left time: 81778.7476s\n",
      "9299it [25:57,  6.01it/s]\titers: 9300, epoch: 4 | loss: 0.1089822\n",
      "\tspeed: 0.1669s/iter; left time: 82744.6020s\n",
      "9399it [26:14,  6.04it/s]\titers: 9400, epoch: 4 | loss: 0.0707721\n",
      "\tspeed: 0.1675s/iter; left time: 82997.6341s\n",
      "9499it [26:30,  6.04it/s]\titers: 9500, epoch: 4 | loss: 0.0440769\n",
      "\tspeed: 0.1691s/iter; left time: 83800.4219s\n",
      "9599it [26:47,  5.88it/s]\titers: 9600, epoch: 4 | loss: 0.1636975\n",
      "\tspeed: 0.1693s/iter; left time: 83854.1125s\n",
      "9699it [27:04,  5.78it/s]\titers: 9700, epoch: 4 | loss: 0.2855704\n",
      "\tspeed: 0.1662s/iter; left time: 82318.7290s\n",
      "9799it [27:21,  6.04it/s]\titers: 9800, epoch: 4 | loss: 0.0348206\n",
      "\tspeed: 0.1673s/iter; left time: 82861.2941s\n",
      "9899it [27:38,  6.01it/s]\titers: 9900, epoch: 4 | loss: 0.3894983\n",
      "\tspeed: 0.1689s/iter; left time: 83630.9716s\n",
      "9999it [27:54,  6.04it/s]\titers: 10000, epoch: 4 | loss: 0.0559347\n",
      "\tspeed: 0.1684s/iter; left time: 83369.2785s\n",
      "10099it [28:11,  6.01it/s]\titers: 10100, epoch: 4 | loss: 0.0948254\n",
      "\tspeed: 0.1689s/iter; left time: 83588.1326s\n",
      "10199it [28:28,  5.99it/s]\titers: 10200, epoch: 4 | loss: 0.0503630\n",
      "\tspeed: 0.1690s/iter; left time: 83615.3108s\n",
      "10299it [28:45,  5.99it/s]\titers: 10300, epoch: 4 | loss: 0.1056796\n",
      "\tspeed: 0.1677s/iter; left time: 82950.0224s\n",
      "10399it [29:02,  6.05it/s]\titers: 10400, epoch: 4 | loss: 0.1108061\n",
      "\tspeed: 0.1684s/iter; left time: 83297.2037s\n",
      "10499it [29:19,  6.06it/s]\titers: 10500, epoch: 4 | loss: 0.0653554\n",
      "\tspeed: 0.1689s/iter; left time: 83512.0661s\n",
      "10599it [29:36,  6.08it/s]\titers: 10600, epoch: 4 | loss: 0.1543567\n",
      "\tspeed: 0.1694s/iter; left time: 83742.5081s\n",
      "10699it [29:52,  5.26it/s]\titers: 10700, epoch: 4 | loss: 0.1446209\n",
      "\tspeed: 0.1679s/iter; left time: 82975.0681s\n",
      "10799it [30:09,  6.06it/s]\titers: 10800, epoch: 4 | loss: 0.1300168\n",
      "\tspeed: 0.1648s/iter; left time: 81443.3186s\n",
      "10899it [30:26,  6.09it/s]\titers: 10900, epoch: 4 | loss: 0.0992752\n",
      "\tspeed: 0.1685s/iter; left time: 83274.1655s\n",
      "10999it [30:42,  6.02it/s]\titers: 11000, epoch: 4 | loss: 0.1949231\n",
      "\tspeed: 0.1657s/iter; left time: 81858.3546s\n",
      "11099it [30:59,  5.97it/s]\titers: 11100, epoch: 4 | loss: 0.1117833\n",
      "\tspeed: 0.1663s/iter; left time: 82118.8519s\n",
      "11199it [31:16,  5.98it/s]\titers: 11200, epoch: 4 | loss: 0.0732892\n",
      "\tspeed: 0.1687s/iter; left time: 83289.9225s\n",
      "11299it [31:33,  6.04it/s]\titers: 11300, epoch: 4 | loss: 0.1418694\n",
      "\tspeed: 0.1661s/iter; left time: 81994.7763s\n",
      "11399it [31:49,  6.09it/s]\titers: 11400, epoch: 4 | loss: 0.0654706\n",
      "\tspeed: 0.1692s/iter; left time: 83529.6052s\n",
      "11499it [32:06,  6.16it/s]\titers: 11500, epoch: 4 | loss: 0.0741735\n",
      "\tspeed: 0.1690s/iter; left time: 83384.8969s\n",
      "11599it [32:23,  6.03it/s]\titers: 11600, epoch: 4 | loss: 0.0762986\n",
      "\tspeed: 0.1667s/iter; left time: 82259.3427s\n",
      "11699it [32:40,  4.92it/s]\titers: 11700, epoch: 4 | loss: 0.1061935\n",
      "\tspeed: 0.1690s/iter; left time: 83355.9152s\n",
      "11799it [32:56,  6.07it/s]\titers: 11800, epoch: 4 | loss: 0.4583750\n",
      "\tspeed: 0.1657s/iter; left time: 81741.9181s\n",
      "11899it [33:13,  6.05it/s]\titers: 11900, epoch: 4 | loss: 0.1272593\n",
      "\tspeed: 0.1664s/iter; left time: 82026.0270s\n",
      "11999it [33:30,  6.02it/s]\titers: 12000, epoch: 4 | loss: 0.1295835\n",
      "\tspeed: 0.1675s/iter; left time: 82557.8159s\n",
      "12099it [33:47,  6.02it/s]\titers: 12100, epoch: 4 | loss: 0.0487563\n",
      "\tspeed: 0.1675s/iter; left time: 82577.8605s\n",
      "12199it [34:03,  5.93it/s]\titers: 12200, epoch: 4 | loss: 0.1010707\n",
      "\tspeed: 0.1686s/iter; left time: 83092.3957s\n",
      "12299it [34:20,  6.04it/s]\titers: 12300, epoch: 4 | loss: 0.0907702\n",
      "\tspeed: 0.1691s/iter; left time: 83318.7791s\n",
      "12399it [34:37,  6.07it/s]\titers: 12400, epoch: 4 | loss: 0.0667250\n",
      "\tspeed: 0.1684s/iter; left time: 82930.0724s\n",
      "12499it [34:54,  6.07it/s]\titers: 12500, epoch: 4 | loss: 0.1581663\n",
      "\tspeed: 0.1664s/iter; left time: 81958.1438s\n",
      "12599it [35:11,  5.56it/s]\titers: 12600, epoch: 4 | loss: 0.2199995\n",
      "\tspeed: 0.1669s/iter; left time: 82168.9517s\n",
      "12699it [35:27,  6.01it/s]\titers: 12700, epoch: 4 | loss: 0.1221715\n",
      "\tspeed: 0.1663s/iter; left time: 81865.1354s\n",
      "12799it [35:44,  6.02it/s]\titers: 12800, epoch: 4 | loss: 0.1632298\n",
      "\tspeed: 0.1671s/iter; left time: 82264.5911s\n",
      "12899it [36:01,  6.11it/s]\titers: 12900, epoch: 4 | loss: 0.1186567\n",
      "\tspeed: 0.1681s/iter; left time: 82720.2746s\n",
      "12999it [36:17,  6.02it/s]\titers: 13000, epoch: 4 | loss: 0.1016329\n",
      "\tspeed: 0.1678s/iter; left time: 82541.1103s\n",
      "13099it [36:34,  6.02it/s]\titers: 13100, epoch: 4 | loss: 0.0391213\n",
      "\tspeed: 0.1665s/iter; left time: 81888.0730s\n",
      "13199it [36:51,  6.00it/s]\titers: 13200, epoch: 4 | loss: 0.0622114\n",
      "\tspeed: 0.1662s/iter; left time: 81741.8712s\n",
      "13299it [37:07,  6.06it/s]\titers: 13300, epoch: 4 | loss: 0.1532260\n",
      "\tspeed: 0.1673s/iter; left time: 82279.8206s\n",
      "13399it [37:24,  6.13it/s]\titers: 13400, epoch: 4 | loss: 0.0867374\n",
      "\tspeed: 0.1660s/iter; left time: 81582.9923s\n",
      "13499it [37:41,  6.04it/s]\titers: 13500, epoch: 4 | loss: 0.1648964\n",
      "\tspeed: 0.1663s/iter; left time: 81747.5757s\n",
      "13599it [37:57,  5.29it/s]\titers: 13600, epoch: 4 | loss: 0.0517035\n",
      "\tspeed: 0.1669s/iter; left time: 82036.1203s\n",
      "13699it [38:14,  6.07it/s]\titers: 13700, epoch: 4 | loss: 0.3193899\n",
      "\tspeed: 0.1665s/iter; left time: 81779.5292s\n",
      "13799it [38:31,  6.03it/s]\titers: 13800, epoch: 4 | loss: 0.0995670\n",
      "\tspeed: 0.1678s/iter; left time: 82443.9556s\n",
      "13899it [38:48,  6.06it/s]\titers: 13900, epoch: 4 | loss: 0.0551059\n",
      "\tspeed: 0.1667s/iter; left time: 81847.0828s\n",
      "13999it [39:04,  6.05it/s]\titers: 14000, epoch: 4 | loss: 0.1005626\n",
      "\tspeed: 0.1680s/iter; left time: 82508.1104s\n",
      "14099it [39:21,  6.02it/s]\titers: 14100, epoch: 4 | loss: 0.0777638\n",
      "\tspeed: 0.1677s/iter; left time: 82313.9127s\n",
      "14199it [39:38,  6.10it/s]\titers: 14200, epoch: 4 | loss: 0.2580663\n",
      "\tspeed: 0.1683s/iter; left time: 82600.6794s\n",
      "14299it [39:55,  6.08it/s]\titers: 14300, epoch: 4 | loss: 0.1021101\n",
      "\tspeed: 0.1674s/iter; left time: 82138.1071s\n",
      "14399it [40:11,  6.03it/s]\titers: 14400, epoch: 4 | loss: 0.2491979\n",
      "\tspeed: 0.1658s/iter; left time: 81342.7925s\n",
      "14499it [40:28,  6.05it/s]\titers: 14500, epoch: 4 | loss: 0.1865836\n",
      "\tspeed: 0.1686s/iter; left time: 82672.9403s\n",
      "14599it [40:45,  6.05it/s]\titers: 14600, epoch: 4 | loss: 0.0886663\n",
      "\tspeed: 0.1656s/iter; left time: 81184.8746s\n",
      "14699it [41:02,  5.84it/s]\titers: 14700, epoch: 4 | loss: 0.0781495\n",
      "\tspeed: 0.1688s/iter; left time: 82749.3689s\n",
      "14799it [41:18,  4.74it/s]\titers: 14800, epoch: 4 | loss: 0.1727414\n",
      "\tspeed: 0.1682s/iter; left time: 82448.1512s\n",
      "14899it [41:35,  6.11it/s]\titers: 14900, epoch: 4 | loss: 0.1681100\n",
      "\tspeed: 0.1672s/iter; left time: 81953.0766s\n",
      "14999it [41:52,  6.02it/s]\titers: 15000, epoch: 4 | loss: 0.2645068\n",
      "\tspeed: 0.1692s/iter; left time: 82886.8793s\n",
      "15099it [42:09,  6.14it/s]\titers: 15100, epoch: 4 | loss: 0.1199311\n",
      "\tspeed: 0.1662s/iter; left time: 81423.6486s\n",
      "15199it [42:25,  6.03it/s]\titers: 15200, epoch: 4 | loss: 0.0391710\n",
      "\tspeed: 0.1670s/iter; left time: 81808.5005s\n",
      "15299it [42:42,  6.11it/s]\titers: 15300, epoch: 4 | loss: 0.0569875\n",
      "\tspeed: 0.1680s/iter; left time: 82263.8270s\n",
      "15399it [42:59,  6.08it/s]\titers: 15400, epoch: 4 | loss: 0.1684825\n",
      "\tspeed: 0.1664s/iter; left time: 81442.7991s\n",
      "15499it [43:15,  6.14it/s]\titers: 15500, epoch: 4 | loss: 0.1248940\n",
      "\tspeed: 0.1666s/iter; left time: 81546.3537s\n",
      "15599it [43:32,  6.12it/s]\titers: 15600, epoch: 4 | loss: 0.4833641\n",
      "\tspeed: 0.1665s/iter; left time: 81477.6846s\n",
      "15699it [43:49,  6.00it/s]\titers: 15700, epoch: 4 | loss: 0.0975002\n",
      "\tspeed: 0.1657s/iter; left time: 81083.5953s\n",
      "15799it [44:05,  5.91it/s]\titers: 15800, epoch: 4 | loss: 0.4115763\n",
      "\tspeed: 0.1647s/iter; left time: 80588.8024s\n",
      "15899it [44:22,  6.03it/s]\titers: 15900, epoch: 4 | loss: 0.2825936\n",
      "\tspeed: 0.1663s/iter; left time: 81336.9252s\n",
      "15999it [44:38,  6.07it/s]\titers: 16000, epoch: 4 | loss: 0.2927889\n",
      "\tspeed: 0.1671s/iter; left time: 81697.2204s\n",
      "16099it [44:55,  5.93it/s]\titers: 16100, epoch: 4 | loss: 0.1479528\n",
      "\tspeed: 0.1651s/iter; left time: 80694.5151s\n",
      "16199it [45:12,  6.02it/s]\titers: 16200, epoch: 4 | loss: 0.1096779\n",
      "\tspeed: 0.1675s/iter; left time: 81857.8991s\n",
      "16299it [45:28,  6.06it/s]\titers: 16300, epoch: 4 | loss: 0.1442544\n",
      "\tspeed: 0.1657s/iter; left time: 80987.5223s\n",
      "16399it [45:45,  6.13it/s]\titers: 16400, epoch: 4 | loss: 0.1713358\n",
      "\tspeed: 0.1655s/iter; left time: 80881.5417s\n",
      "16499it [46:02,  6.11it/s]\titers: 16500, epoch: 4 | loss: 0.1287715\n",
      "\tspeed: 0.1695s/iter; left time: 82793.5579s\n",
      "16599it [46:19,  6.02it/s]\titers: 16600, epoch: 4 | loss: 0.0661614\n",
      "\tspeed: 0.1682s/iter; left time: 82144.0121s\n",
      "16699it [46:35,  5.06it/s]\titers: 16700, epoch: 4 | loss: 0.1753389\n",
      "\tspeed: 0.1676s/iter; left time: 81856.2147s\n",
      "16799it [46:52,  6.06it/s]\titers: 16800, epoch: 4 | loss: 0.0361122\n",
      "\tspeed: 0.1671s/iter; left time: 81591.3063s\n",
      "16899it [47:09,  6.09it/s]\titers: 16900, epoch: 4 | loss: 0.1088860\n",
      "\tspeed: 0.1689s/iter; left time: 82453.7743s\n",
      "16999it [47:26,  6.01it/s]\titers: 17000, epoch: 4 | loss: 0.0399124\n",
      "\tspeed: 0.1684s/iter; left time: 82165.4611s\n",
      "17099it [47:42,  6.03it/s]\titers: 17100, epoch: 4 | loss: 0.1316141\n",
      "\tspeed: 0.1664s/iter; left time: 81196.8134s\n",
      "17199it [47:59,  6.05it/s]\titers: 17200, epoch: 4 | loss: 0.1028574\n",
      "\tspeed: 0.1696s/iter; left time: 82733.1228s\n",
      "17299it [48:16,  6.08it/s]\titers: 17300, epoch: 4 | loss: 0.1068852\n",
      "\tspeed: 0.1681s/iter; left time: 81956.4605s\n",
      "17399it [48:33,  6.08it/s]\titers: 17400, epoch: 4 | loss: 0.1189511\n",
      "\tspeed: 0.1693s/iter; left time: 82550.9118s\n",
      "17499it [48:50,  4.82it/s]\titers: 17500, epoch: 4 | loss: 0.1767251\n",
      "\tspeed: 0.1687s/iter; left time: 82239.6687s\n",
      "17599it [49:07,  6.08it/s]\titers: 17600, epoch: 4 | loss: 0.1250314\n",
      "\tspeed: 0.1660s/iter; left time: 80898.2412s\n",
      "17699it [49:23,  6.03it/s]\titers: 17700, epoch: 4 | loss: 0.0972328\n",
      "\tspeed: 0.1673s/iter; left time: 81503.2081s\n",
      "17799it [49:40,  6.07it/s]\titers: 17800, epoch: 4 | loss: 0.1431170\n",
      "\tspeed: 0.1686s/iter; left time: 82157.2947s\n",
      "17899it [49:57,  6.01it/s]\titers: 17900, epoch: 4 | loss: 0.0569874\n",
      "\tspeed: 0.1668s/iter; left time: 81247.9484s\n",
      "17999it [50:14,  6.02it/s]\titers: 18000, epoch: 4 | loss: 0.1033125\n",
      "\tspeed: 0.1693s/iter; left time: 82438.5876s\n",
      "18099it [50:31,  6.07it/s]\titers: 18100, epoch: 4 | loss: 0.0899337\n",
      "\tspeed: 0.1688s/iter; left time: 82186.8078s\n",
      "18199it [50:48,  6.10it/s]\titers: 18200, epoch: 4 | loss: 0.1380861\n",
      "\tspeed: 0.1687s/iter; left time: 82115.1491s\n",
      "18299it [51:04,  5.11it/s]\titers: 18300, epoch: 4 | loss: 0.1012869\n",
      "\tspeed: 0.1686s/iter; left time: 82076.2069s\n",
      "18399it [51:21,  6.02it/s]\titers: 18400, epoch: 4 | loss: 0.0628026\n",
      "\tspeed: 0.1664s/iter; left time: 80950.6102s\n",
      "18499it [51:38,  6.10it/s]\titers: 18500, epoch: 4 | loss: 0.0875329\n",
      "\tspeed: 0.1669s/iter; left time: 81205.5394s\n",
      "18599it [51:54,  6.05it/s]\titers: 18600, epoch: 4 | loss: 0.1826852\n",
      "\tspeed: 0.1675s/iter; left time: 81457.9241s\n",
      "18699it [52:11,  5.91it/s]\titers: 18700, epoch: 4 | loss: 0.1185549\n",
      "\tspeed: 0.1695s/iter; left time: 82433.2405s\n",
      "18799it [52:28,  6.07it/s]\titers: 18800, epoch: 4 | loss: 0.0832391\n",
      "\tspeed: 0.1686s/iter; left time: 81948.7925s\n",
      "18899it [52:45,  5.88it/s]\titers: 18900, epoch: 4 | loss: 0.4523149\n",
      "\tspeed: 0.1690s/iter; left time: 82127.2474s\n",
      "18999it [53:02,  5.98it/s]\titers: 19000, epoch: 4 | loss: 0.0842778\n",
      "\tspeed: 0.1670s/iter; left time: 81175.4122s\n",
      "19099it [53:19,  6.05it/s]\titers: 19100, epoch: 4 | loss: 0.3719335\n",
      "\tspeed: 0.1681s/iter; left time: 81698.4678s\n",
      "19199it [53:36,  5.96it/s]\titers: 19200, epoch: 4 | loss: 0.1174329\n",
      "\tspeed: 0.1681s/iter; left time: 81663.6944s\n",
      "19299it [53:52,  6.11it/s]\titers: 19300, epoch: 4 | loss: 0.1851236\n",
      "\tspeed: 0.1671s/iter; left time: 81139.6624s\n",
      "19399it [54:09,  6.05it/s]\titers: 19400, epoch: 4 | loss: 0.1541767\n",
      "\tspeed: 0.1660s/iter; left time: 80584.9661s\n",
      "19499it [54:25,  6.11it/s]\titers: 19500, epoch: 4 | loss: 0.0703813\n",
      "\tspeed: 0.1666s/iter; left time: 80887.9939s\n",
      "19599it [54:42,  6.10it/s]\titers: 19600, epoch: 4 | loss: 0.0797947\n",
      "\tspeed: 0.1690s/iter; left time: 82009.6829s\n",
      "19699it [54:59,  6.12it/s]\titers: 19700, epoch: 4 | loss: 0.1262574\n",
      "\tspeed: 0.1670s/iter; left time: 81051.1656s\n",
      "19799it [55:16,  5.97it/s]\titers: 19800, epoch: 4 | loss: 0.2863485\n",
      "\tspeed: 0.1689s/iter; left time: 81945.1281s\n",
      "19899it [55:33,  5.76it/s]\titers: 19900, epoch: 4 | loss: 0.1352288\n",
      "\tspeed: 0.1659s/iter; left time: 80487.0154s\n",
      "19999it [55:49,  6.04it/s]\titers: 20000, epoch: 4 | loss: 0.0703628\n",
      "\tspeed: 0.1646s/iter; left time: 79848.4974s\n",
      "20099it [56:06,  6.04it/s]\titers: 20100, epoch: 4 | loss: 0.0566782\n",
      "\tspeed: 0.1685s/iter; left time: 81703.4894s\n",
      "20199it [56:23,  6.08it/s]\titers: 20200, epoch: 4 | loss: 0.4021735\n",
      "\tspeed: 0.1695s/iter; left time: 82148.7257s\n",
      "20299it [56:39,  6.09it/s]\titers: 20300, epoch: 4 | loss: 0.1828872\n",
      "\tspeed: 0.1649s/iter; left time: 79940.2848s\n",
      "20399it [56:56,  6.14it/s]\titers: 20400, epoch: 4 | loss: 0.0849356\n",
      "\tspeed: 0.1683s/iter; left time: 81555.8396s\n",
      "20499it [57:13,  4.71it/s]\titers: 20500, epoch: 4 | loss: 0.1816210\n",
      "\tspeed: 0.1679s/iter; left time: 81337.9625s\n",
      "20599it [57:30,  6.02it/s]\titers: 20600, epoch: 4 | loss: 0.2252067\n",
      "\tspeed: 0.1658s/iter; left time: 80332.4930s\n",
      "20699it [57:46,  6.02it/s]\titers: 20700, epoch: 4 | loss: 0.1893627\n",
      "\tspeed: 0.1674s/iter; left time: 81068.3518s\n",
      "20799it [58:03,  6.03it/s]\titers: 20800, epoch: 4 | loss: 0.0783981\n",
      "\tspeed: 0.1683s/iter; left time: 81502.6089s\n",
      "20899it [58:20,  6.00it/s]\titers: 20900, epoch: 4 | loss: 0.0357543\n",
      "\tspeed: 0.1661s/iter; left time: 80423.9017s\n",
      "20999it [58:36,  6.01it/s]\titers: 21000, epoch: 4 | loss: 0.1683664\n",
      "\tspeed: 0.1678s/iter; left time: 81205.0721s\n",
      "21099it [58:53,  5.95it/s]\titers: 21100, epoch: 4 | loss: 0.1896247\n",
      "\tspeed: 0.1672s/iter; left time: 80914.3861s\n",
      "21199it [59:10,  5.98it/s]\titers: 21200, epoch: 4 | loss: 0.1882277\n",
      "\tspeed: 0.1671s/iter; left time: 80839.4677s\n",
      "21299it [59:27,  6.15it/s]\titers: 21300, epoch: 4 | loss: 0.1232918\n",
      "\tspeed: 0.1678s/iter; left time: 81181.8394s\n",
      "21399it [59:43,  6.05it/s]\titers: 21400, epoch: 4 | loss: 0.0857875\n",
      "\tspeed: 0.1656s/iter; left time: 80097.0846s\n",
      "21499it [1:00:00,  5.57it/s]\titers: 21500, epoch: 4 | loss: 0.0704589\n",
      "\tspeed: 0.1668s/iter; left time: 80655.5699s\n",
      "21599it [1:00:17,  6.09it/s]\titers: 21600, epoch: 4 | loss: 0.0645070\n",
      "\tspeed: 0.1662s/iter; left time: 80337.7834s\n",
      "21699it [1:00:33,  6.04it/s]\titers: 21700, epoch: 4 | loss: 0.1097447\n",
      "\tspeed: 0.1693s/iter; left time: 81810.3717s\n",
      "21799it [1:00:50,  5.98it/s]\titers: 21800, epoch: 4 | loss: 0.1041207\n",
      "\tspeed: 0.1700s/iter; left time: 82153.1781s\n",
      "21899it [1:01:07,  5.90it/s]\titers: 21900, epoch: 4 | loss: 0.0721803\n",
      "\tspeed: 0.1695s/iter; left time: 81905.7670s\n",
      "21999it [1:01:24,  6.03it/s]\titers: 22000, epoch: 4 | loss: 0.1006180\n",
      "\tspeed: 0.1692s/iter; left time: 81718.6867s\n",
      "22099it [1:01:41,  6.11it/s]\titers: 22100, epoch: 4 | loss: 0.1681444\n",
      "\tspeed: 0.1665s/iter; left time: 80399.1057s\n",
      "22199it [1:01:58,  5.21it/s]\titers: 22200, epoch: 4 | loss: 0.0595902\n",
      "\tspeed: 0.1686s/iter; left time: 81392.3702s\n",
      "22299it [1:02:14,  6.02it/s]\titers: 22300, epoch: 4 | loss: 0.0834233\n",
      "\tspeed: 0.1657s/iter; left time: 79975.7899s\n",
      "22399it [1:02:31,  6.00it/s]\titers: 22400, epoch: 4 | loss: 0.0556228\n",
      "\tspeed: 0.1688s/iter; left time: 81462.9991s\n",
      "22499it [1:02:48,  6.06it/s]\titers: 22500, epoch: 4 | loss: 0.0728373\n",
      "\tspeed: 0.1667s/iter; left time: 80447.8890s\n",
      "22599it [1:03:05,  6.07it/s]\titers: 22600, epoch: 4 | loss: 0.0993915\n",
      "\tspeed: 0.1676s/iter; left time: 80823.9520s\n",
      "22699it [1:03:21,  6.10it/s]\titers: 22700, epoch: 4 | loss: 0.2361708\n",
      "\tspeed: 0.1658s/iter; left time: 79945.4026s\n",
      "22799it [1:03:38,  6.09it/s]\titers: 22800, epoch: 4 | loss: 0.0878643\n",
      "\tspeed: 0.1679s/iter; left time: 80976.0218s\n",
      "22899it [1:03:55,  6.07it/s]\titers: 22900, epoch: 4 | loss: 0.1150033\n",
      "\tspeed: 0.1671s/iter; left time: 80553.2261s\n",
      "22999it [1:04:12,  4.72it/s]\titers: 23000, epoch: 4 | loss: 0.2489293\n",
      "\tspeed: 0.1705s/iter; left time: 82166.1457s\n",
      "23099it [1:04:28,  6.03it/s]\titers: 23100, epoch: 4 | loss: 0.0208687\n",
      "\tspeed: 0.1655s/iter; left time: 79731.1744s\n",
      "23199it [1:04:45,  6.04it/s]\titers: 23200, epoch: 4 | loss: 0.0770301\n",
      "\tspeed: 0.1658s/iter; left time: 79885.5930s\n",
      "23299it [1:05:02,  6.05it/s]\titers: 23300, epoch: 4 | loss: 0.1053587\n",
      "\tspeed: 0.1659s/iter; left time: 79898.2531s\n",
      "23399it [1:05:18,  6.06it/s]\titers: 23400, epoch: 4 | loss: 0.0416395\n",
      "\tspeed: 0.1671s/iter; left time: 80448.9673s\n",
      "23499it [1:05:35,  6.04it/s]\titers: 23500, epoch: 4 | loss: 0.0563239\n",
      "\tspeed: 0.1692s/iter; left time: 81474.2734s\n",
      "23599it [1:05:52,  6.03it/s]\titers: 23600, epoch: 4 | loss: 0.1320387\n",
      "\tspeed: 0.1677s/iter; left time: 80717.1903s\n",
      "23699it [1:06:09,  6.01it/s]\titers: 23700, epoch: 4 | loss: 0.0619866\n",
      "\tspeed: 0.1692s/iter; left time: 81413.0127s\n",
      "23799it [1:06:26,  6.02it/s]\titers: 23800, epoch: 4 | loss: 0.0807061\n",
      "\tspeed: 0.1676s/iter; left time: 80647.4160s\n",
      "23899it [1:06:42,  6.09it/s]\titers: 23900, epoch: 4 | loss: 0.0599193\n",
      "\tspeed: 0.1678s/iter; left time: 80742.1154s\n",
      "23999it [1:06:59,  5.27it/s]\titers: 24000, epoch: 4 | loss: 0.2924875\n",
      "\tspeed: 0.1672s/iter; left time: 80434.7466s\n",
      "24099it [1:07:16,  6.07it/s]\titers: 24100, epoch: 4 | loss: 0.1954733\n",
      "\tspeed: 0.1685s/iter; left time: 81039.9257s\n",
      "24199it [1:07:33,  6.01it/s]\titers: 24200, epoch: 4 | loss: 0.1841345\n",
      "\tspeed: 0.1686s/iter; left time: 81055.2359s\n",
      "24299it [1:07:50,  5.99it/s]\titers: 24300, epoch: 4 | loss: 0.2902395\n",
      "\tspeed: 0.1675s/iter; left time: 80510.1455s\n",
      "24399it [1:08:06,  6.05it/s]\titers: 24400, epoch: 4 | loss: 0.0931701\n",
      "\tspeed: 0.1688s/iter; left time: 81101.0015s\n",
      "24499it [1:08:23,  6.04it/s]\titers: 24500, epoch: 4 | loss: 0.0838571\n",
      "\tspeed: 0.1698s/iter; left time: 81573.0338s\n",
      "24599it [1:08:40,  6.04it/s]\titers: 24600, epoch: 4 | loss: 0.1211032\n",
      "\tspeed: 0.1690s/iter; left time: 81195.9605s\n",
      "24699it [1:08:57,  6.05it/s]\titers: 24700, epoch: 4 | loss: 0.1546703\n",
      "\tspeed: 0.1691s/iter; left time: 81222.9095s\n",
      "24799it [1:09:14,  6.11it/s]\titers: 24800, epoch: 4 | loss: 0.0428239\n",
      "\tspeed: 0.1657s/iter; left time: 79545.0173s\n",
      "24899it [1:09:31,  5.97it/s]\titers: 24900, epoch: 4 | loss: 0.0338688\n",
      "\tspeed: 0.1682s/iter; left time: 80727.8130s\n",
      "24999it [1:09:47,  5.27it/s]\titers: 25000, epoch: 4 | loss: 0.0558214\n",
      "\tspeed: 0.1673s/iter; left time: 80315.2176s\n",
      "25099it [1:10:04,  6.01it/s]\titers: 25100, epoch: 4 | loss: 0.1830734\n",
      "\tspeed: 0.1666s/iter; left time: 79955.0456s\n",
      "25199it [1:10:21,  6.00it/s]\titers: 25200, epoch: 4 | loss: 0.0794105\n",
      "\tspeed: 0.1664s/iter; left time: 79856.7615s\n",
      "25299it [1:10:37,  6.07it/s]\titers: 25300, epoch: 4 | loss: 0.2072427\n",
      "\tspeed: 0.1677s/iter; left time: 80466.7860s\n",
      "25399it [1:10:54,  6.07it/s]\titers: 25400, epoch: 4 | loss: 0.0654191\n",
      "\tspeed: 0.1680s/iter; left time: 80571.7398s\n",
      "25499it [1:11:11,  6.08it/s]\titers: 25500, epoch: 4 | loss: 0.0815900\n",
      "\tspeed: 0.1664s/iter; left time: 79784.7984s\n",
      "25599it [1:11:28,  6.00it/s]\titers: 25600, epoch: 4 | loss: 0.2160251\n",
      "\tspeed: 0.1684s/iter; left time: 80741.3001s\n",
      "25699it [1:11:45,  6.04it/s]\titers: 25700, epoch: 4 | loss: 0.0612782\n",
      "\tspeed: 0.1685s/iter; left time: 80779.4628s\n",
      "25799it [1:12:01,  5.97it/s]\titers: 25800, epoch: 4 | loss: 0.1170125\n",
      "\tspeed: 0.1664s/iter; left time: 79745.2177s\n",
      "25899it [1:12:18,  6.10it/s]\titers: 25900, epoch: 4 | loss: 0.1262346\n",
      "\tspeed: 0.1679s/iter; left time: 80459.6899s\n",
      "25999it [1:12:35,  6.05it/s]\titers: 26000, epoch: 4 | loss: 0.2110021\n",
      "\tspeed: 0.1690s/iter; left time: 80938.9184s\n",
      "26099it [1:12:51,  6.12it/s]\titers: 26100, epoch: 4 | loss: 0.0443049\n",
      "\tspeed: 0.1648s/iter; left time: 78931.2458s\n",
      "26199it [1:13:08,  5.99it/s]\titers: 26200, epoch: 4 | loss: 0.3791763\n",
      "\tspeed: 0.1668s/iter; left time: 79868.4661s\n",
      "26299it [1:13:25,  5.90it/s]\titers: 26300, epoch: 4 | loss: 0.1977901\n",
      "\tspeed: 0.1659s/iter; left time: 79421.0795s\n",
      "26399it [1:13:42,  6.06it/s]\titers: 26400, epoch: 4 | loss: 0.0905129\n",
      "\tspeed: 0.1680s/iter; left time: 80422.4205s\n",
      "26499it [1:13:58,  6.12it/s]\titers: 26500, epoch: 4 | loss: 0.1246782\n",
      "\tspeed: 0.1668s/iter; left time: 79798.3995s\n",
      "26599it [1:14:15,  6.08it/s]\titers: 26600, epoch: 4 | loss: 0.3164386\n",
      "\tspeed: 0.1684s/iter; left time: 80541.8287s\n",
      "26699it [1:14:32,  5.91it/s]\titers: 26700, epoch: 4 | loss: 0.3907356\n",
      "\tspeed: 0.1702s/iter; left time: 81412.1955s\n",
      "26799it [1:14:49,  5.07it/s]\titers: 26800, epoch: 4 | loss: 0.0440340\n",
      "\tspeed: 0.1684s/iter; left time: 80504.3451s\n",
      "26899it [1:15:05,  6.09it/s]\titers: 26900, epoch: 4 | loss: 0.1586637\n",
      "\tspeed: 0.1644s/iter; left time: 78594.0799s\n",
      "26999it [1:15:22,  6.04it/s]\titers: 27000, epoch: 4 | loss: 0.2803997\n",
      "\tspeed: 0.1658s/iter; left time: 79251.4779s\n",
      "27099it [1:15:38,  6.09it/s]\titers: 27100, epoch: 4 | loss: 0.1405623\n",
      "\tspeed: 0.1652s/iter; left time: 78955.7510s\n",
      "27199it [1:15:55,  6.12it/s]\titers: 27200, epoch: 4 | loss: 0.7727392\n",
      "\tspeed: 0.1671s/iter; left time: 79820.0323s\n",
      "27299it [1:16:12,  5.05it/s]\titers: 27300, epoch: 4 | loss: 0.0383338\n",
      "\tspeed: 0.1670s/iter; left time: 79770.5430s\n",
      "27399it [1:16:28,  6.07it/s]\titers: 27400, epoch: 4 | loss: 0.0951655\n",
      "\tspeed: 0.1662s/iter; left time: 79359.8046s\n",
      "27499it [1:16:45,  6.10it/s]\titers: 27500, epoch: 4 | loss: 0.1276657\n",
      "\tspeed: 0.1680s/iter; left time: 80209.2941s\n",
      "27599it [1:17:02,  6.01it/s]\titers: 27600, epoch: 4 | loss: 0.0607836\n",
      "\tspeed: 0.1668s/iter; left time: 79625.7475s\n",
      "27699it [1:17:19,  6.03it/s]\titers: 27700, epoch: 4 | loss: 0.1745622\n",
      "\tspeed: 0.1667s/iter; left time: 79547.3655s\n",
      "27799it [1:17:35,  6.08it/s]\titers: 27800, epoch: 4 | loss: 0.0733478\n",
      "\tspeed: 0.1681s/iter; left time: 80207.2084s\n",
      "27899it [1:17:52,  6.11it/s]\titers: 27900, epoch: 4 | loss: 0.0833746\n",
      "\tspeed: 0.1654s/iter; left time: 78905.9441s\n",
      "27999it [1:18:09,  5.97it/s]\titers: 28000, epoch: 4 | loss: 0.0946824\n",
      "\tspeed: 0.1667s/iter; left time: 79518.1120s\n",
      "28099it [1:18:25,  6.09it/s]\titers: 28100, epoch: 4 | loss: 0.2764496\n",
      "\tspeed: 0.1653s/iter; left time: 78805.7531s\n",
      "28199it [1:18:42,  6.01it/s]\titers: 28200, epoch: 4 | loss: 0.2210569\n",
      "\tspeed: 0.1659s/iter; left time: 79089.5814s\n",
      "28299it [1:18:58,  6.06it/s]\titers: 28300, epoch: 4 | loss: 0.0568027\n",
      "\tspeed: 0.1665s/iter; left time: 79388.7459s\n",
      "28399it [1:19:15,  6.05it/s]\titers: 28400, epoch: 4 | loss: 0.1497135\n",
      "\tspeed: 0.1660s/iter; left time: 79113.9448s\n",
      "28499it [1:19:32,  6.17it/s]\titers: 28500, epoch: 4 | loss: 0.1185187\n",
      "\tspeed: 0.1667s/iter; left time: 79409.9134s\n",
      "28599it [1:19:48,  6.08it/s]\titers: 28600, epoch: 4 | loss: 0.0407731\n",
      "\tspeed: 0.1655s/iter; left time: 78844.2407s\n",
      "28699it [1:20:05,  6.09it/s]\titers: 28700, epoch: 4 | loss: 0.1319848\n",
      "\tspeed: 0.1655s/iter; left time: 78815.6624s\n",
      "28799it [1:20:21,  5.41it/s]\titers: 28800, epoch: 4 | loss: 0.0763944\n",
      "\tspeed: 0.1672s/iter; left time: 79603.9523s\n",
      "28899it [1:20:38,  6.05it/s]\titers: 28900, epoch: 4 | loss: 0.0770667\n",
      "\tspeed: 0.1652s/iter; left time: 78654.8634s\n",
      "28999it [1:20:55,  6.03it/s]\titers: 29000, epoch: 4 | loss: 0.1235621\n",
      "\tspeed: 0.1696s/iter; left time: 80718.8155s\n",
      "29099it [1:21:12,  6.04it/s]\titers: 29100, epoch: 4 | loss: 0.1718981\n",
      "\tspeed: 0.1693s/iter; left time: 80576.9547s\n",
      "29199it [1:21:29,  6.03it/s]\titers: 29200, epoch: 4 | loss: 0.1324018\n",
      "\tspeed: 0.1692s/iter; left time: 80513.9495s\n",
      "29299it [1:21:46,  5.98it/s]\titers: 29300, epoch: 4 | loss: 0.1387995\n",
      "\tspeed: 0.1687s/iter; left time: 80264.0827s\n",
      "29399it [1:22:03,  6.06it/s]\titers: 29400, epoch: 4 | loss: 0.2446293\n",
      "\tspeed: 0.1685s/iter; left time: 80140.2080s\n",
      "29499it [1:22:19,  6.17it/s]\titers: 29500, epoch: 4 | loss: 0.0477468\n",
      "\tspeed: 0.1655s/iter; left time: 78709.5203s\n",
      "29599it [1:22:36,  5.95it/s]\titers: 29600, epoch: 4 | loss: 0.0633622\n",
      "\tspeed: 0.1663s/iter; left time: 79045.7822s\n",
      "29699it [1:22:52,  6.02it/s]\titers: 29700, epoch: 4 | loss: 0.2000665\n",
      "\tspeed: 0.1654s/iter; left time: 78633.7789s\n",
      "29705it [1:22:53,  5.97it/s]\n",
      "Epoch: 4 cost time: 4973.786438703537\n",
      "6481it [08:35, 12.58it/s]\n",
      "6457it [08:34, 12.54it/s]\n",
      "Epoch: 4 | Train Loss: 0.1606410 Vali Loss: 0.3163966 Test Loss: 0.4347986 MAE Loss: 0.3827471\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "99it [00:16,  6.02it/s]\titers: 100, epoch: 5 | loss: 0.1117442\n",
      "\tspeed: 10.4805s/iter; left time: 4980123.4243s\n",
      "199it [00:33,  6.03it/s]\titers: 200, epoch: 5 | loss: 0.1309669\n",
      "\tspeed: 0.1654s/iter; left time: 78573.5448s\n",
      "299it [00:50,  6.04it/s]\titers: 300, epoch: 5 | loss: 0.2198228\n",
      "\tspeed: 0.1673s/iter; left time: 79456.8620s\n",
      "399it [01:06,  6.00it/s]\titers: 400, epoch: 5 | loss: 0.0826374\n",
      "\tspeed: 0.1662s/iter; left time: 78912.0213s\n",
      "499it [01:23,  6.01it/s]\titers: 500, epoch: 5 | loss: 0.0545316\n",
      "\tspeed: 0.1690s/iter; left time: 80224.9832s\n",
      "599it [01:40,  6.04it/s]\titers: 600, epoch: 5 | loss: 0.0705815\n",
      "\tspeed: 0.1685s/iter; left time: 79975.7807s\n",
      "699it [01:57,  5.97it/s]\titers: 700, epoch: 5 | loss: 0.0785646\n",
      "\tspeed: 0.1686s/iter; left time: 80023.7588s\n",
      "799it [02:13,  5.77it/s]\titers: 800, epoch: 5 | loss: 0.1567989\n",
      "\tspeed: 0.1670s/iter; left time: 79218.9184s\n",
      "899it [02:30,  6.07it/s]\titers: 900, epoch: 5 | loss: 0.0605509\n",
      "\tspeed: 0.1660s/iter; left time: 78723.8404s\n",
      "999it [02:47,  6.04it/s]\titers: 1000, epoch: 5 | loss: 0.0955128\n",
      "\tspeed: 0.1677s/iter; left time: 79548.4575s\n",
      "1099it [03:03,  6.03it/s]\titers: 1100, epoch: 5 | loss: 0.1605765\n",
      "\tspeed: 0.1661s/iter; left time: 78766.4934s\n",
      "1199it [03:20,  6.06it/s]\titers: 1200, epoch: 5 | loss: 0.1174657\n",
      "\tspeed: 0.1664s/iter; left time: 78903.2840s\n",
      "1299it [03:37,  6.02it/s]\titers: 1300, epoch: 5 | loss: 0.1487789\n",
      "\tspeed: 0.1658s/iter; left time: 78589.0226s\n",
      "1399it [03:53,  6.05it/s]\titers: 1400, epoch: 5 | loss: 0.1260864\n",
      "\tspeed: 0.1655s/iter; left time: 78423.9983s\n",
      "1499it [04:10,  6.01it/s]\titers: 1500, epoch: 5 | loss: 0.2319924\n",
      "\tspeed: 0.1657s/iter; left time: 78503.1856s\n",
      "1599it [04:27,  6.06it/s]\titers: 1600, epoch: 5 | loss: 0.0715867\n",
      "\tspeed: 0.1685s/iter; left time: 79793.5579s\n",
      "1699it [04:43,  6.08it/s]\titers: 1700, epoch: 5 | loss: 0.2957515\n",
      "\tspeed: 0.1662s/iter; left time: 78714.5159s\n",
      "1799it [05:00,  6.12it/s]\titers: 1800, epoch: 5 | loss: 0.8119810\n",
      "\tspeed: 0.1659s/iter; left time: 78538.3690s\n",
      "1899it [05:17,  6.12it/s]\titers: 1900, epoch: 5 | loss: 0.0838631\n",
      "\tspeed: 0.1679s/iter; left time: 79479.7454s\n",
      "1999it [05:33,  6.08it/s]\titers: 2000, epoch: 5 | loss: 0.3295611\n",
      "\tspeed: 0.1643s/iter; left time: 77766.1055s\n",
      "2099it [05:50,  6.05it/s]\titers: 2100, epoch: 5 | loss: 0.1798907\n",
      "\tspeed: 0.1677s/iter; left time: 79370.9880s\n",
      "2199it [06:07,  6.00it/s]\titers: 2200, epoch: 5 | loss: 0.2820850\n",
      "\tspeed: 0.1685s/iter; left time: 79729.3918s\n",
      "2299it [06:23,  6.06it/s]\titers: 2300, epoch: 5 | loss: 0.0821029\n",
      "\tspeed: 0.1678s/iter; left time: 79376.2096s\n",
      "2399it [06:40,  5.46it/s]\titers: 2400, epoch: 5 | loss: 0.0696080\n",
      "\tspeed: 0.1680s/iter; left time: 79464.5440s\n",
      "2499it [06:57,  6.04it/s]\titers: 2500, epoch: 5 | loss: 0.1709957\n",
      "\tspeed: 0.1656s/iter; left time: 78291.8581s\n",
      "2599it [07:13,  6.04it/s]\titers: 2600, epoch: 5 | loss: 0.1296974\n",
      "\tspeed: 0.1658s/iter; left time: 78380.4323s\n",
      "2699it [07:30,  6.05it/s]\titers: 2700, epoch: 5 | loss: 0.1689449\n",
      "\tspeed: 0.1657s/iter; left time: 78303.4783s\n",
      "2799it [07:47,  6.09it/s]\titers: 2800, epoch: 5 | loss: 0.0963417\n",
      "\tspeed: 0.1663s/iter; left time: 78588.8738s\n",
      "2899it [08:03,  5.50it/s]\titers: 2900, epoch: 5 | loss: 0.3068886\n",
      "\tspeed: 0.1672s/iter; left time: 78969.0164s\n",
      "2999it [08:20,  6.08it/s]\titers: 3000, epoch: 5 | loss: 0.0582604\n",
      "\tspeed: 0.1655s/iter; left time: 78161.4311s\n",
      "3099it [08:37,  6.10it/s]\titers: 3100, epoch: 5 | loss: 0.1423648\n",
      "\tspeed: 0.1686s/iter; left time: 79590.7267s\n",
      "3199it [08:54,  6.03it/s]\titers: 3200, epoch: 5 | loss: 0.2078622\n",
      "\tspeed: 0.1677s/iter; left time: 79185.8289s\n",
      "3299it [09:10,  6.02it/s]\titers: 3300, epoch: 5 | loss: 0.2505561\n",
      "\tspeed: 0.1680s/iter; left time: 79302.9365s\n",
      "3399it [09:27,  6.04it/s]\titers: 3400, epoch: 5 | loss: 0.1856772\n",
      "\tspeed: 0.1676s/iter; left time: 79106.2386s\n",
      "3499it [09:44,  6.12it/s]\titers: 3500, epoch: 5 | loss: 0.2037318\n",
      "\tspeed: 0.1663s/iter; left time: 78451.7232s\n",
      "3599it [10:01,  5.94it/s]\titers: 3600, epoch: 5 | loss: 0.1236890\n",
      "\tspeed: 0.1691s/iter; left time: 79757.6780s\n",
      "3699it [10:17,  5.99it/s]\titers: 3700, epoch: 5 | loss: 0.0416899\n",
      "\tspeed: 0.1669s/iter; left time: 78700.9540s\n",
      "3799it [10:34,  6.02it/s]\titers: 3800, epoch: 5 | loss: 0.0429284\n",
      "\tspeed: 0.1671s/iter; left time: 78800.1812s\n",
      "3899it [10:51,  6.08it/s]\titers: 3900, epoch: 5 | loss: 0.8812034\n",
      "\tspeed: 0.1661s/iter; left time: 78302.7941s\n",
      "3999it [11:07,  6.00it/s]\titers: 4000, epoch: 5 | loss: 0.4908732\n",
      "\tspeed: 0.1687s/iter; left time: 79512.8785s\n",
      "4099it [11:24,  6.08it/s]\titers: 4100, epoch: 5 | loss: 0.0778828\n",
      "\tspeed: 0.1680s/iter; left time: 79155.4477s\n",
      "4199it [11:41,  6.03it/s]\titers: 4200, epoch: 5 | loss: 0.0487124\n",
      "\tspeed: 0.1692s/iter; left time: 79709.1552s\n",
      "4299it [11:58,  6.05it/s]\titers: 4300, epoch: 5 | loss: 0.1515113\n",
      "\tspeed: 0.1668s/iter; left time: 78561.0527s\n",
      "4399it [12:15,  6.07it/s]\titers: 4400, epoch: 5 | loss: 0.2642557\n",
      "\tspeed: 0.1672s/iter; left time: 78714.7283s\n",
      "4499it [12:31,  5.86it/s]\titers: 4500, epoch: 5 | loss: 0.0524057\n",
      "\tspeed: 0.1689s/iter; left time: 79506.6144s\n",
      "4599it [12:48,  5.77it/s]\titers: 4600, epoch: 5 | loss: 0.1501005\n",
      "\tspeed: 0.1668s/iter; left time: 78493.7469s\n",
      "4699it [13:05,  6.08it/s]\titers: 4700, epoch: 5 | loss: 0.2465980\n",
      "\tspeed: 0.1674s/iter; left time: 78754.8792s\n",
      "4799it [13:22,  6.01it/s]\titers: 4800, epoch: 5 | loss: 0.1227934\n",
      "\tspeed: 0.1692s/iter; left time: 79590.6227s\n",
      "4899it [13:39,  6.04it/s]\titers: 4900, epoch: 5 | loss: 0.0492180\n",
      "\tspeed: 0.1683s/iter; left time: 79144.1010s\n",
      "4999it [13:55,  6.06it/s]\titers: 5000, epoch: 5 | loss: 0.0912988\n",
      "\tspeed: 0.1664s/iter; left time: 78258.1708s\n",
      "5099it [14:12,  6.11it/s]\titers: 5100, epoch: 5 | loss: 0.3507323\n",
      "\tspeed: 0.1668s/iter; left time: 78429.1965s\n",
      "5199it [14:29,  6.11it/s]\titers: 5200, epoch: 5 | loss: 0.1693055\n",
      "\tspeed: 0.1666s/iter; left time: 78312.4645s\n",
      "5299it [14:45,  6.06it/s]\titers: 5300, epoch: 5 | loss: 0.0711049\n",
      "\tspeed: 0.1655s/iter; left time: 77803.7559s\n",
      "5399it [15:02,  6.07it/s]\titers: 5400, epoch: 5 | loss: 0.0591046\n",
      "\tspeed: 0.1665s/iter; left time: 78229.8622s\n",
      "5499it [15:18,  6.06it/s]\titers: 5500, epoch: 5 | loss: 0.1710538\n",
      "\tspeed: 0.1660s/iter; left time: 77996.9170s\n",
      "5599it [15:35,  6.05it/s]\titers: 5600, epoch: 5 | loss: 0.1202477\n",
      "\tspeed: 0.1667s/iter; left time: 78291.5678s\n",
      "5699it [15:52,  6.01it/s]\titers: 5700, epoch: 5 | loss: 0.0977590\n",
      "\tspeed: 0.1666s/iter; left time: 78236.6240s\n",
      "5799it [16:09,  6.06it/s]\titers: 5800, epoch: 5 | loss: 0.0820493\n",
      "\tspeed: 0.1677s/iter; left time: 78735.1828s\n",
      "5899it [16:25,  6.05it/s]\titers: 5900, epoch: 5 | loss: 0.0298196\n",
      "\tspeed: 0.1664s/iter; left time: 78118.5198s\n",
      "5999it [16:42,  6.03it/s]\titers: 6000, epoch: 5 | loss: 0.0628542\n",
      "\tspeed: 0.1652s/iter; left time: 77530.4350s\n",
      "6099it [16:58,  6.02it/s]\titers: 6100, epoch: 5 | loss: 0.2419050\n",
      "\tspeed: 0.1678s/iter; left time: 78745.0947s\n",
      "6199it [17:15,  6.06it/s]\titers: 6200, epoch: 5 | loss: 0.0931498\n",
      "\tspeed: 0.1665s/iter; left time: 78101.3114s\n",
      "6299it [17:32,  6.06it/s]\titers: 6300, epoch: 5 | loss: 0.1243510\n",
      "\tspeed: 0.1675s/iter; left time: 78540.6740s\n",
      "6399it [17:49,  6.11it/s]\titers: 6400, epoch: 5 | loss: 0.2432109\n",
      "\tspeed: 0.1664s/iter; left time: 78029.4118s\n",
      "6499it [18:05,  6.12it/s]\titers: 6500, epoch: 5 | loss: 0.3370647\n",
      "\tspeed: 0.1655s/iter; left time: 77591.2052s\n",
      "6599it [18:22,  6.08it/s]\titers: 6600, epoch: 5 | loss: 0.0607655\n",
      "\tspeed: 0.1696s/iter; left time: 79497.5836s\n",
      "6699it [18:39,  6.05it/s]\titers: 6700, epoch: 5 | loss: 0.1276198\n",
      "\tspeed: 0.1679s/iter; left time: 78694.2893s\n",
      "6799it [18:55,  6.06it/s]\titers: 6800, epoch: 5 | loss: 0.5397709\n",
      "\tspeed: 0.1661s/iter; left time: 77816.0540s\n",
      "6899it [19:12,  6.11it/s]\titers: 6900, epoch: 5 | loss: 0.1431421\n",
      "\tspeed: 0.1669s/iter; left time: 78165.4379s\n",
      "6999it [19:29,  6.01it/s]\titers: 7000, epoch: 5 | loss: 0.0533750\n",
      "\tspeed: 0.1669s/iter; left time: 78158.1635s\n",
      "7099it [19:45,  6.07it/s]\titers: 7100, epoch: 5 | loss: 0.1152609\n",
      "\tspeed: 0.1660s/iter; left time: 77704.1083s\n",
      "7199it [20:02,  6.05it/s]\titers: 7200, epoch: 5 | loss: 0.1360266\n",
      "\tspeed: 0.1686s/iter; left time: 78900.3324s\n",
      "7299it [20:19,  6.10it/s]\titers: 7300, epoch: 5 | loss: 0.1591810\n",
      "\tspeed: 0.1679s/iter; left time: 78569.0892s\n",
      "7399it [20:36,  6.02it/s]\titers: 7400, epoch: 5 | loss: 0.1318866\n",
      "\tspeed: 0.1668s/iter; left time: 78030.4511s\n",
      "7499it [20:52,  5.96it/s]\titers: 7500, epoch: 5 | loss: 0.0405080\n",
      "\tspeed: 0.1658s/iter; left time: 77542.8960s\n",
      "7599it [21:09,  6.07it/s]\titers: 7600, epoch: 5 | loss: 0.1843643\n",
      "\tspeed: 0.1655s/iter; left time: 77395.5476s\n",
      "7699it [21:25,  5.98it/s]\titers: 7700, epoch: 5 | loss: 0.1225111\n",
      "\tspeed: 0.1660s/iter; left time: 77637.4585s\n",
      "7799it [21:42,  6.12it/s]\titers: 7800, epoch: 5 | loss: 0.1628092\n",
      "\tspeed: 0.1672s/iter; left time: 78172.9346s\n",
      "7899it [21:59,  6.13it/s]\titers: 7900, epoch: 5 | loss: 0.1546762\n",
      "\tspeed: 0.1671s/iter; left time: 78105.4428s\n",
      "7999it [22:16,  6.03it/s]\titers: 8000, epoch: 5 | loss: 0.1113451\n",
      "\tspeed: 0.1669s/iter; left time: 77983.0862s\n",
      "8099it [22:32,  6.05it/s]\titers: 8100, epoch: 5 | loss: 0.1410645\n",
      "\tspeed: 0.1665s/iter; left time: 77784.0274s\n",
      "8199it [22:49,  6.03it/s]\titers: 8200, epoch: 5 | loss: 0.4131178\n",
      "\tspeed: 0.1657s/iter; left time: 77375.6272s\n",
      "8299it [23:05,  6.05it/s]\titers: 8300, epoch: 5 | loss: 0.1237048\n",
      "\tspeed: 0.1665s/iter; left time: 77765.4858s\n",
      "8399it [23:22,  5.99it/s]\titers: 8400, epoch: 5 | loss: 0.1569480\n",
      "\tspeed: 0.1662s/iter; left time: 77581.7777s\n",
      "8499it [23:39,  6.05it/s]\titers: 8500, epoch: 5 | loss: 0.0472949\n",
      "\tspeed: 0.1673s/iter; left time: 78079.2358s\n",
      "8599it [23:55,  6.07it/s]\titers: 8600, epoch: 5 | loss: 0.3429286\n",
      "\tspeed: 0.1667s/iter; left time: 77809.0337s\n",
      "8699it [24:12,  6.05it/s]\titers: 8700, epoch: 5 | loss: 0.0577634\n",
      "\tspeed: 0.1676s/iter; left time: 78208.0351s\n",
      "8799it [24:29,  5.98it/s]\titers: 8800, epoch: 5 | loss: 0.5125893\n",
      "\tspeed: 0.1683s/iter; left time: 78499.0716s\n",
      "8899it [24:46,  6.05it/s]\titers: 8900, epoch: 5 | loss: 0.2536815\n",
      "\tspeed: 0.1685s/iter; left time: 78565.6435s\n",
      "8999it [25:03,  5.10it/s]\titers: 9000, epoch: 5 | loss: 0.0190026\n",
      "\tspeed: 0.1691s/iter; left time: 78828.4882s\n",
      "9099it [25:19,  6.06it/s]\titers: 9100, epoch: 5 | loss: 0.1615821\n",
      "\tspeed: 0.1659s/iter; left time: 77326.0555s\n",
      "9199it [25:36,  6.03it/s]\titers: 9200, epoch: 5 | loss: 0.1828024\n",
      "\tspeed: 0.1668s/iter; left time: 77729.9443s\n",
      "9299it [25:53,  6.08it/s]\titers: 9300, epoch: 5 | loss: 0.3066718\n",
      "\tspeed: 0.1683s/iter; left time: 78443.3443s\n",
      "9399it [26:10,  6.01it/s]\titers: 9400, epoch: 5 | loss: 0.1284712\n",
      "\tspeed: 0.1667s/iter; left time: 77656.9926s\n",
      "9499it [26:26,  6.07it/s]\titers: 9500, epoch: 5 | loss: 0.0517695\n",
      "\tspeed: 0.1667s/iter; left time: 77633.7373s\n",
      "9599it [26:43,  6.10it/s]\titers: 9600, epoch: 5 | loss: 0.1042904\n",
      "\tspeed: 0.1662s/iter; left time: 77377.6724s\n",
      "9699it [27:00,  6.01it/s]\titers: 9700, epoch: 5 | loss: 0.2832551\n",
      "\tspeed: 0.1686s/iter; left time: 78505.6832s\n",
      "9799it [27:17,  6.13it/s]\titers: 9800, epoch: 5 | loss: 0.0521682\n",
      "\tspeed: 0.1678s/iter; left time: 78117.1471s\n",
      "9899it [27:33,  6.08it/s]\titers: 9900, epoch: 5 | loss: 0.1452678\n",
      "\tspeed: 0.1666s/iter; left time: 77555.1909s\n",
      "9999it [27:50,  5.52it/s]\titers: 10000, epoch: 5 | loss: 0.0584006\n",
      "\tspeed: 0.1660s/iter; left time: 77233.4884s\n",
      "10099it [28:06,  6.02it/s]\titers: 10100, epoch: 5 | loss: 0.1492773\n",
      "\tspeed: 0.1663s/iter; left time: 77378.4773s\n",
      "10199it [28:23,  6.05it/s]\titers: 10200, epoch: 5 | loss: 0.1895513\n",
      "\tspeed: 0.1685s/iter; left time: 78345.8962s\n",
      "10299it [28:40,  6.06it/s]\titers: 10300, epoch: 5 | loss: 0.0589998\n",
      "\tspeed: 0.1686s/iter; left time: 78396.7251s\n",
      "10399it [28:57,  6.05it/s]\titers: 10400, epoch: 5 | loss: 0.1839335\n",
      "\tspeed: 0.1670s/iter; left time: 77637.3794s\n",
      "10499it [29:13,  5.94it/s]\titers: 10500, epoch: 5 | loss: 0.0622110\n",
      "\tspeed: 0.1664s/iter; left time: 77362.3042s\n",
      "10599it [29:31,  6.01it/s]\titers: 10600, epoch: 5 | loss: 0.0299341\n",
      "\tspeed: 0.1707s/iter; left time: 79309.1488s\n",
      "10699it [29:47,  6.07it/s]\titers: 10700, epoch: 5 | loss: 0.0950076\n",
      "\tspeed: 0.1689s/iter; left time: 78460.9304s\n",
      "10799it [30:04,  6.01it/s]\titers: 10800, epoch: 5 | loss: 0.1141909\n",
      "\tspeed: 0.1679s/iter; left time: 77995.9333s\n",
      "10899it [30:21,  6.05it/s]\titers: 10900, epoch: 5 | loss: 0.1074157\n",
      "\tspeed: 0.1682s/iter; left time: 78115.5114s\n",
      "10999it [30:38,  6.11it/s]\titers: 11000, epoch: 5 | loss: 0.1816781\n",
      "\tspeed: 0.1673s/iter; left time: 77669.9796s\n",
      "11099it [30:55,  5.88it/s]\titers: 11100, epoch: 5 | loss: 0.4205056\n",
      "\tspeed: 0.1693s/iter; left time: 78573.5969s\n",
      "11199it [31:11,  5.29it/s]\titers: 11200, epoch: 5 | loss: 0.0876579\n",
      "\tspeed: 0.1674s/iter; left time: 77700.9957s\n",
      "11299it [31:28,  6.04it/s]\titers: 11300, epoch: 5 | loss: 0.2599479\n",
      "\tspeed: 0.1660s/iter; left time: 77022.4717s\n",
      "11399it [31:45,  6.04it/s]\titers: 11400, epoch: 5 | loss: 0.0459927\n",
      "\tspeed: 0.1673s/iter; left time: 77619.0612s\n",
      "11499it [32:01,  5.99it/s]\titers: 11500, epoch: 5 | loss: 0.4091486\n",
      "\tspeed: 0.1663s/iter; left time: 77134.3552s\n",
      "11599it [32:18,  6.08it/s]\titers: 11600, epoch: 5 | loss: 0.3007316\n",
      "\tspeed: 0.1669s/iter; left time: 77375.9190s\n",
      "11699it [32:35,  6.03it/s]\titers: 11700, epoch: 5 | loss: 0.1440939\n",
      "\tspeed: 0.1681s/iter; left time: 77905.4096s\n",
      "11799it [32:52,  6.04it/s]\titers: 11800, epoch: 5 | loss: 0.1426906\n",
      "\tspeed: 0.1662s/iter; left time: 77018.9831s\n",
      "11899it [33:08,  6.00it/s]\titers: 11900, epoch: 5 | loss: 0.1786261\n",
      "\tspeed: 0.1676s/iter; left time: 77675.2855s\n",
      "11999it [33:25,  6.10it/s]\titers: 12000, epoch: 5 | loss: 0.2035907\n",
      "\tspeed: 0.1673s/iter; left time: 77515.8350s\n",
      "12099it [33:42,  6.07it/s]\titers: 12100, epoch: 5 | loss: 0.0860786\n",
      "\tspeed: 0.1663s/iter; left time: 77018.3773s\n",
      "12199it [33:58,  5.11it/s]\titers: 12200, epoch: 5 | loss: 0.0325678\n",
      "\tspeed: 0.1686s/iter; left time: 78095.8748s\n",
      "12299it [34:15,  6.04it/s]\titers: 12300, epoch: 5 | loss: 0.0855290\n",
      "\tspeed: 0.1657s/iter; left time: 76709.1154s\n",
      "12399it [34:32,  6.02it/s]\titers: 12400, epoch: 5 | loss: 0.1994289\n",
      "\tspeed: 0.1670s/iter; left time: 77307.6947s\n",
      "12499it [34:49,  6.06it/s]\titers: 12500, epoch: 5 | loss: 0.0997594\n",
      "\tspeed: 0.1682s/iter; left time: 77852.5242s\n",
      "12599it [35:05,  5.99it/s]\titers: 12600, epoch: 5 | loss: 0.0740729\n",
      "\tspeed: 0.1688s/iter; left time: 78100.9449s\n",
      "12699it [35:22,  5.98it/s]\titers: 12700, epoch: 5 | loss: 0.1289600\n",
      "\tspeed: 0.1672s/iter; left time: 77328.2365s\n",
      "12799it [35:39,  6.04it/s]\titers: 12800, epoch: 5 | loss: 0.2286876\n",
      "\tspeed: 0.1668s/iter; left time: 77150.9555s\n",
      "12899it [35:56,  6.07it/s]\titers: 12900, epoch: 5 | loss: 0.1194197\n",
      "\tspeed: 0.1666s/iter; left time: 77045.8586s\n",
      "12999it [36:12,  6.05it/s]\titers: 13000, epoch: 5 | loss: 0.1707224\n",
      "\tspeed: 0.1696s/iter; left time: 78411.2144s\n",
      "13099it [36:29,  6.08it/s]\titers: 13100, epoch: 5 | loss: 0.1523311\n",
      "\tspeed: 0.1671s/iter; left time: 77217.7687s\n",
      "13199it [36:46,  6.08it/s]\titers: 13200, epoch: 5 | loss: 0.0743591\n",
      "\tspeed: 0.1707s/iter; left time: 78868.2620s\n",
      "13299it [37:03,  6.01it/s]\titers: 13300, epoch: 5 | loss: 0.3125966\n",
      "\tspeed: 0.1692s/iter; left time: 78165.9486s\n",
      "13399it [37:20,  5.70it/s]\titers: 13400, epoch: 5 | loss: 0.1615106\n",
      "\tspeed: 0.1659s/iter; left time: 76615.3163s\n",
      "13499it [37:36,  6.05it/s]\titers: 13500, epoch: 5 | loss: 0.0951999\n",
      "\tspeed: 0.1670s/iter; left time: 77110.6276s\n",
      "13599it [37:53,  6.09it/s]\titers: 13600, epoch: 5 | loss: 0.0590435\n",
      "\tspeed: 0.1671s/iter; left time: 77149.7231s\n",
      "13699it [38:10,  6.09it/s]\titers: 13700, epoch: 5 | loss: 0.0937395\n",
      "\tspeed: 0.1673s/iter; left time: 77226.6128s\n",
      "13799it [38:26,  6.09it/s]\titers: 13800, epoch: 5 | loss: 0.0673751\n",
      "\tspeed: 0.1657s/iter; left time: 76478.1212s\n",
      "13899it [38:43,  6.16it/s]\titers: 13900, epoch: 5 | loss: 0.2513123\n",
      "\tspeed: 0.1655s/iter; left time: 76373.5595s\n",
      "13999it [39:00,  6.02it/s]\titers: 14000, epoch: 5 | loss: 0.0610511\n",
      "\tspeed: 0.1650s/iter; left time: 76121.9163s\n",
      "14099it [39:16,  6.10it/s]\titers: 14100, epoch: 5 | loss: 0.1227976\n",
      "\tspeed: 0.1670s/iter; left time: 77033.5257s\n",
      "14199it [39:33,  6.12it/s]\titers: 14200, epoch: 5 | loss: 0.0411379\n",
      "\tspeed: 0.1691s/iter; left time: 77970.6993s\n",
      "14299it [39:50,  5.87it/s]\titers: 14300, epoch: 5 | loss: 0.0699197\n",
      "\tspeed: 0.1663s/iter; left time: 76679.6348s\n",
      "14399it [40:06,  6.02it/s]\titers: 14400, epoch: 5 | loss: 0.1605339\n",
      "\tspeed: 0.1661s/iter; left time: 76539.7257s\n",
      "14499it [40:23,  6.04it/s]\titers: 14500, epoch: 5 | loss: 0.2762390\n",
      "\tspeed: 0.1689s/iter; left time: 77827.2923s\n",
      "14599it [40:40,  5.99it/s]\titers: 14600, epoch: 5 | loss: 0.1565793\n",
      "\tspeed: 0.1687s/iter; left time: 77719.1984s\n",
      "14699it [40:57,  6.04it/s]\titers: 14700, epoch: 5 | loss: 0.0572655\n",
      "\tspeed: 0.1672s/iter; left time: 77031.0166s\n",
      "14799it [41:14,  6.07it/s]\titers: 14800, epoch: 5 | loss: 0.0514029\n",
      "\tspeed: 0.1682s/iter; left time: 77439.4045s\n",
      "14899it [41:30,  6.05it/s]\titers: 14900, epoch: 5 | loss: 0.0433250\n",
      "\tspeed: 0.1659s/iter; left time: 76390.2650s\n",
      "14999it [41:47,  6.00it/s]\titers: 15000, epoch: 5 | loss: 0.1386543\n",
      "\tspeed: 0.1660s/iter; left time: 76418.1309s\n",
      "15099it [42:04,  6.08it/s]\titers: 15100, epoch: 5 | loss: 0.0467888\n",
      "\tspeed: 0.1666s/iter; left time: 76654.0391s\n",
      "15199it [42:20,  6.09it/s]\titers: 15200, epoch: 5 | loss: 0.1893649\n",
      "\tspeed: 0.1693s/iter; left time: 77909.1667s\n",
      "15299it [42:37,  5.95it/s]\titers: 15300, epoch: 5 | loss: 0.2657059\n",
      "\tspeed: 0.1665s/iter; left time: 76571.8300s\n",
      "15399it [42:54,  6.09it/s]\titers: 15400, epoch: 5 | loss: 0.0625359\n",
      "\tspeed: 0.1646s/iter; left time: 75700.8895s\n",
      "15499it [43:10,  6.09it/s]\titers: 15500, epoch: 5 | loss: 0.1027910\n",
      "\tspeed: 0.1686s/iter; left time: 77523.7240s\n",
      "15599it [43:27,  6.07it/s]\titers: 15600, epoch: 5 | loss: 0.2193272\n",
      "\tspeed: 0.1689s/iter; left time: 77621.3300s\n",
      "15699it [43:44,  6.06it/s]\titers: 15700, epoch: 5 | loss: 0.2970007\n",
      "\tspeed: 0.1684s/iter; left time: 77378.3299s\n",
      "15799it [44:01,  6.05it/s]\titers: 15800, epoch: 5 | loss: 0.0347191\n",
      "\tspeed: 0.1664s/iter; left time: 76446.1965s\n",
      "15899it [44:18,  6.07it/s]\titers: 15900, epoch: 5 | loss: 0.1005404\n",
      "\tspeed: 0.1683s/iter; left time: 77300.1817s\n",
      "15999it [44:34,  5.25it/s]\titers: 16000, epoch: 5 | loss: 0.1556148\n",
      "\tspeed: 0.1683s/iter; left time: 77309.1564s\n",
      "16099it [44:51,  6.07it/s]\titers: 16100, epoch: 5 | loss: 0.1324693\n",
      "\tspeed: 0.1659s/iter; left time: 76186.4806s\n",
      "16199it [45:08,  6.01it/s]\titers: 16200, epoch: 5 | loss: 0.0452463\n",
      "\tspeed: 0.1671s/iter; left time: 76722.1701s\n",
      "16299it [45:25,  6.04it/s]\titers: 16300, epoch: 5 | loss: 0.0904859\n",
      "\tspeed: 0.1677s/iter; left time: 76972.8535s\n",
      "16399it [45:41,  6.01it/s]\titers: 16400, epoch: 5 | loss: 0.2958187\n",
      "\tspeed: 0.1671s/iter; left time: 76697.3134s\n",
      "16499it [45:58,  6.02it/s]\titers: 16500, epoch: 5 | loss: 0.1793221\n",
      "\tspeed: 0.1659s/iter; left time: 76100.9157s\n",
      "16599it [46:15,  6.01it/s]\titers: 16600, epoch: 5 | loss: 0.1709524\n",
      "\tspeed: 0.1699s/iter; left time: 77921.0024s\n",
      "16699it [46:32,  6.09it/s]\titers: 16700, epoch: 5 | loss: 0.0759929\n",
      "\tspeed: 0.1697s/iter; left time: 77829.1597s\n",
      "16799it [46:49,  5.88it/s]\titers: 16800, epoch: 5 | loss: 0.1674919\n",
      "\tspeed: 0.1676s/iter; left time: 76860.8280s\n",
      "16899it [47:05,  5.98it/s]\titers: 16900, epoch: 5 | loss: 0.0756414\n",
      "\tspeed: 0.1667s/iter; left time: 76396.5299s\n",
      "16999it [47:22,  5.95it/s]\titers: 17000, epoch: 5 | loss: 0.0673059\n",
      "\tspeed: 0.1704s/iter; left time: 78109.6285s\n",
      "17099it [47:39,  6.00it/s]\titers: 17100, epoch: 5 | loss: 0.2369862\n",
      "\tspeed: 0.1673s/iter; left time: 76632.8037s\n",
      "17199it [47:56,  5.98it/s]\titers: 17200, epoch: 5 | loss: 0.0665715\n",
      "\tspeed: 0.1672s/iter; left time: 76607.6774s\n",
      "17299it [48:12,  6.06it/s]\titers: 17300, epoch: 5 | loss: 0.0186756\n",
      "\tspeed: 0.1664s/iter; left time: 76216.4553s\n",
      "17399it [48:29,  6.16it/s]\titers: 17400, epoch: 5 | loss: 0.2564669\n",
      "\tspeed: 0.1666s/iter; left time: 76276.6957s\n",
      "17499it [48:46,  5.87it/s]\titers: 17500, epoch: 5 | loss: 0.1282410\n",
      "\tspeed: 0.1661s/iter; left time: 76055.0110s\n",
      "17599it [49:02,  6.08it/s]\titers: 17600, epoch: 5 | loss: 0.1473303\n",
      "\tspeed: 0.1656s/iter; left time: 75803.5586s\n",
      "17699it [49:19,  6.08it/s]\titers: 17700, epoch: 5 | loss: 0.0853040\n",
      "\tspeed: 0.1683s/iter; left time: 77021.5581s\n",
      "17799it [49:36,  6.03it/s]\titers: 17800, epoch: 5 | loss: 0.1827366\n",
      "\tspeed: 0.1693s/iter; left time: 77437.3793s\n",
      "17899it [49:53,  6.05it/s]\titers: 17900, epoch: 5 | loss: 0.0701673\n",
      "\tspeed: 0.1666s/iter; left time: 76201.2409s\n",
      "17999it [50:09,  6.08it/s]\titers: 18000, epoch: 5 | loss: 0.1977500\n",
      "\tspeed: 0.1667s/iter; left time: 76247.3404s\n",
      "18099it [50:26,  5.40it/s]\titers: 18100, epoch: 5 | loss: 0.1935008\n",
      "\tspeed: 0.1680s/iter; left time: 76816.4293s\n",
      "18199it [50:43,  5.93it/s]\titers: 18200, epoch: 5 | loss: 0.0547732\n",
      "\tspeed: 0.1657s/iter; left time: 75737.3166s\n",
      "18299it [50:59,  5.96it/s]\titers: 18300, epoch: 5 | loss: 0.0693039\n",
      "\tspeed: 0.1661s/iter; left time: 75883.2434s\n",
      "18399it [51:16,  6.05it/s]\titers: 18400, epoch: 5 | loss: 0.1112575\n",
      "\tspeed: 0.1664s/iter; left time: 76024.3758s\n",
      "18499it [51:32,  6.06it/s]\titers: 18500, epoch: 5 | loss: 0.0446708\n",
      "\tspeed: 0.1650s/iter; left time: 75378.0501s\n",
      "18599it [51:49,  6.13it/s]\titers: 18600, epoch: 5 | loss: 0.0951898\n",
      "\tspeed: 0.1664s/iter; left time: 75998.8887s\n",
      "18699it [52:06,  4.92it/s]\titers: 18700, epoch: 5 | loss: 0.0329562\n",
      "\tspeed: 0.1697s/iter; left time: 77476.8058s\n",
      "18799it [52:23,  6.09it/s]\titers: 18800, epoch: 5 | loss: 0.0507543\n",
      "\tspeed: 0.1652s/iter; left time: 75390.7130s\n",
      "18899it [52:39,  5.99it/s]\titers: 18900, epoch: 5 | loss: 0.1034692\n",
      "\tspeed: 0.1655s/iter; left time: 75532.6015s\n",
      "18999it [52:56,  6.08it/s]\titers: 19000, epoch: 5 | loss: 0.2168421\n",
      "\tspeed: 0.1670s/iter; left time: 76201.1530s\n",
      "19099it [53:12,  6.09it/s]\titers: 19100, epoch: 5 | loss: 0.0476040\n",
      "\tspeed: 0.1665s/iter; left time: 75968.4141s\n",
      "19199it [53:29,  6.04it/s]\titers: 19200, epoch: 5 | loss: 0.1155920\n",
      "\tspeed: 0.1665s/iter; left time: 75932.1881s\n",
      "19299it [53:46,  6.05it/s]\titers: 19300, epoch: 5 | loss: 0.3678246\n",
      "\tspeed: 0.1673s/iter; left time: 76306.6783s\n",
      "19399it [54:02,  6.07it/s]\titers: 19400, epoch: 5 | loss: 0.0962096\n",
      "\tspeed: 0.1664s/iter; left time: 75878.0012s\n",
      "19499it [54:19,  6.10it/s]\titers: 19500, epoch: 5 | loss: 0.0678287\n",
      "\tspeed: 0.1666s/iter; left time: 75950.6092s\n",
      "19599it [54:36,  5.95it/s]\titers: 19600, epoch: 5 | loss: 0.1194612\n",
      "\tspeed: 0.1652s/iter; left time: 75276.7911s\n",
      "19699it [54:52,  6.12it/s]\titers: 19700, epoch: 5 | loss: 0.1567716\n",
      "\tspeed: 0.1649s/iter; left time: 75138.5976s\n",
      "19799it [55:09,  6.02it/s]\titers: 19800, epoch: 5 | loss: 0.1288095\n",
      "\tspeed: 0.1658s/iter; left time: 75515.5209s\n",
      "19899it [55:26,  6.02it/s]\titers: 19900, epoch: 5 | loss: 0.0340457\n",
      "\tspeed: 0.1679s/iter; left time: 76464.9004s\n",
      "19999it [55:42,  6.03it/s]\titers: 20000, epoch: 5 | loss: 0.0876119\n",
      "\tspeed: 0.1662s/iter; left time: 75674.0940s\n",
      "20099it [55:59,  6.06it/s]\titers: 20100, epoch: 5 | loss: 0.1656338\n",
      "\tspeed: 0.1662s/iter; left time: 75671.4147s\n",
      "20199it [56:16,  6.01it/s]\titers: 20200, epoch: 5 | loss: 0.0962284\n",
      "\tspeed: 0.1676s/iter; left time: 76278.8787s\n",
      "20299it [56:32,  6.07it/s]\titers: 20300, epoch: 5 | loss: 0.1654060\n",
      "\tspeed: 0.1671s/iter; left time: 76012.0844s\n",
      "20399it [56:49,  6.09it/s]\titers: 20400, epoch: 5 | loss: 0.1817095\n",
      "\tspeed: 0.1681s/iter; left time: 76457.5008s\n",
      "20499it [57:06,  5.54it/s]\titers: 20500, epoch: 5 | loss: 0.0785177\n",
      "\tspeed: 0.1668s/iter; left time: 75841.4660s\n",
      "20599it [57:22,  5.97it/s]\titers: 20600, epoch: 5 | loss: 0.2865821\n",
      "\tspeed: 0.1653s/iter; left time: 75137.3756s\n",
      "20699it [57:39,  6.05it/s]\titers: 20700, epoch: 5 | loss: 0.1854870\n",
      "\tspeed: 0.1670s/iter; left time: 75921.9701s\n",
      "20799it [57:56,  6.01it/s]\titers: 20800, epoch: 5 | loss: 0.0915226\n",
      "\tspeed: 0.1674s/iter; left time: 76072.9462s\n",
      "20899it [58:12,  6.07it/s]\titers: 20900, epoch: 5 | loss: 0.0507649\n",
      "\tspeed: 0.1658s/iter; left time: 75335.4248s\n",
      "20999it [58:29,  6.09it/s]\titers: 21000, epoch: 5 | loss: 0.1038727\n",
      "\tspeed: 0.1658s/iter; left time: 75327.1913s\n",
      "21099it [58:46,  6.09it/s]\titers: 21100, epoch: 5 | loss: 0.1704034\n",
      "\tspeed: 0.1678s/iter; left time: 76195.7913s\n",
      "21199it [59:02,  6.04it/s]\titers: 21200, epoch: 5 | loss: 0.1067150\n",
      "\tspeed: 0.1673s/iter; left time: 75965.4216s\n",
      "21299it [59:19,  6.09it/s]\titers: 21300, epoch: 5 | loss: 0.2740857\n",
      "\tspeed: 0.1668s/iter; left time: 75704.9445s\n",
      "21399it [59:36,  6.08it/s]\titers: 21400, epoch: 5 | loss: 0.2443156\n",
      "\tspeed: 0.1681s/iter; left time: 76292.2081s\n",
      "21499it [59:53,  6.12it/s]\titers: 21500, epoch: 5 | loss: 0.2009164\n",
      "\tspeed: 0.1683s/iter; left time: 76367.3335s\n",
      "21599it [1:00:10,  5.19it/s]\titers: 21600, epoch: 5 | loss: 0.0531958\n",
      "\tspeed: 0.1689s/iter; left time: 76643.2513s\n",
      "21699it [1:00:26,  6.06it/s]\titers: 21700, epoch: 5 | loss: 0.1125579\n",
      "\tspeed: 0.1659s/iter; left time: 75267.0542s\n",
      "21799it [1:00:43,  6.02it/s]\titers: 21800, epoch: 5 | loss: 0.2622010\n",
      "\tspeed: 0.1688s/iter; left time: 76546.3435s\n",
      "21899it [1:01:00,  6.04it/s]\titers: 21900, epoch: 5 | loss: 0.1205213\n",
      "\tspeed: 0.1678s/iter; left time: 76094.9208s\n",
      "21999it [1:01:17,  6.12it/s]\titers: 22000, epoch: 5 | loss: 0.2487322\n",
      "\tspeed: 0.1680s/iter; left time: 76155.6452s\n",
      "22099it [1:01:33,  6.06it/s]\titers: 22100, epoch: 5 | loss: 0.2998829\n",
      "\tspeed: 0.1677s/iter; left time: 76004.3422s\n",
      "22199it [1:01:50,  5.98it/s]\titers: 22200, epoch: 5 | loss: 0.0427298\n",
      "\tspeed: 0.1669s/iter; left time: 75636.2436s\n",
      "22299it [1:02:07,  6.11it/s]\titers: 22300, epoch: 5 | loss: 0.1243925\n",
      "\tspeed: 0.1658s/iter; left time: 75115.9522s\n",
      "22399it [1:02:23,  6.09it/s]\titers: 22400, epoch: 5 | loss: 0.1186862\n",
      "\tspeed: 0.1672s/iter; left time: 75743.8793s\n",
      "22499it [1:02:40,  6.01it/s]\titers: 22500, epoch: 5 | loss: 0.0600061\n",
      "\tspeed: 0.1690s/iter; left time: 76511.5908s\n",
      "22599it [1:02:57,  5.93it/s]\titers: 22600, epoch: 5 | loss: 0.1876808\n",
      "\tspeed: 0.1661s/iter; left time: 75186.4941s\n",
      "22699it [1:03:13,  6.06it/s]\titers: 22700, epoch: 5 | loss: 0.0476448\n",
      "\tspeed: 0.1657s/iter; left time: 75005.7450s\n",
      "22799it [1:03:30,  5.98it/s]\titers: 22800, epoch: 5 | loss: 0.0235378\n",
      "\tspeed: 0.1663s/iter; left time: 75232.9947s\n",
      "22899it [1:03:47,  6.00it/s]\titers: 22900, epoch: 5 | loss: 0.1677499\n",
      "\tspeed: 0.1662s/iter; left time: 75169.7611s\n",
      "22999it [1:04:03,  6.02it/s]\titers: 23000, epoch: 5 | loss: 0.2967650\n",
      "\tspeed: 0.1662s/iter; left time: 75155.1601s\n",
      "23099it [1:04:20,  6.02it/s]\titers: 23100, epoch: 5 | loss: 0.0753609\n",
      "\tspeed: 0.1691s/iter; left time: 76479.3804s\n",
      "23199it [1:04:37,  6.07it/s]\titers: 23200, epoch: 5 | loss: 0.0799155\n",
      "\tspeed: 0.1660s/iter; left time: 75043.0150s\n",
      "23299it [1:04:54,  5.92it/s]\titers: 23300, epoch: 5 | loss: 0.0575886\n",
      "\tspeed: 0.1680s/iter; left time: 75919.5942s\n",
      "23399it [1:05:10,  6.12it/s]\titers: 23400, epoch: 5 | loss: 0.2857945\n",
      "\tspeed: 0.1675s/iter; left time: 75693.3459s\n",
      "23499it [1:05:27,  5.19it/s]\titers: 23500, epoch: 5 | loss: 0.1452679\n",
      "\tspeed: 0.1676s/iter; left time: 75696.4338s\n",
      "23599it [1:05:44,  6.09it/s]\titers: 23600, epoch: 5 | loss: 0.1435567\n",
      "\tspeed: 0.1662s/iter; left time: 75049.9406s\n",
      "23699it [1:06:00,  6.08it/s]\titers: 23700, epoch: 5 | loss: 0.0565115\n",
      "\tspeed: 0.1662s/iter; left time: 75057.7713s\n",
      "23799it [1:06:17,  6.03it/s]\titers: 23800, epoch: 5 | loss: 0.0721085\n",
      "\tspeed: 0.1669s/iter; left time: 75366.1758s\n",
      "23899it [1:06:34,  6.00it/s]\titers: 23900, epoch: 5 | loss: 0.0617549\n",
      "\tspeed: 0.1670s/iter; left time: 75363.5924s\n",
      "23999it [1:06:50,  6.07it/s]\titers: 24000, epoch: 5 | loss: 0.0960988\n",
      "\tspeed: 0.1664s/iter; left time: 75101.6469s\n",
      "24099it [1:07:07,  6.09it/s]\titers: 24100, epoch: 5 | loss: 0.3310055\n",
      "\tspeed: 0.1680s/iter; left time: 75792.5033s\n",
      "24199it [1:07:24,  5.96it/s]\titers: 24200, epoch: 5 | loss: 0.1675771\n",
      "\tspeed: 0.1670s/iter; left time: 75335.8658s\n",
      "24299it [1:07:41,  6.07it/s]\titers: 24300, epoch: 5 | loss: 0.0310697\n",
      "\tspeed: 0.1676s/iter; left time: 75600.3934s\n",
      "24399it [1:07:58,  6.12it/s]\titers: 24400, epoch: 5 | loss: 0.0327856\n",
      "\tspeed: 0.1685s/iter; left time: 75972.0839s\n",
      "24499it [1:08:14,  5.89it/s]\titers: 24500, epoch: 5 | loss: 0.1395271\n",
      "\tspeed: 0.1691s/iter; left time: 76246.8697s\n",
      "24599it [1:08:31,  6.03it/s]\titers: 24600, epoch: 5 | loss: 0.1262235\n",
      "\tspeed: 0.1648s/iter; left time: 74252.3752s\n",
      "24699it [1:08:48,  6.10it/s]\titers: 24700, epoch: 5 | loss: 0.0863485\n",
      "\tspeed: 0.1662s/iter; left time: 74904.0153s\n",
      "24799it [1:09:04,  6.09it/s]\titers: 24800, epoch: 5 | loss: 0.2136122\n",
      "\tspeed: 0.1657s/iter; left time: 74653.0230s\n",
      "24899it [1:09:21,  6.09it/s]\titers: 24900, epoch: 5 | loss: 0.1571031\n",
      "\tspeed: 0.1680s/iter; left time: 75644.5614s\n",
      "24999it [1:09:37,  6.09it/s]\titers: 25000, epoch: 5 | loss: 0.2090053\n",
      "\tspeed: 0.1651s/iter; left time: 74331.9007s\n",
      "25099it [1:09:54,  6.06it/s]\titers: 25100, epoch: 5 | loss: 0.1655236\n",
      "\tspeed: 0.1651s/iter; left time: 74316.9491s\n",
      "25199it [1:10:11,  6.06it/s]\titers: 25200, epoch: 5 | loss: 0.1804008\n",
      "\tspeed: 0.1661s/iter; left time: 74756.3161s\n",
      "25299it [1:10:27,  6.06it/s]\titers: 25300, epoch: 5 | loss: 0.1091157\n",
      "\tspeed: 0.1657s/iter; left time: 74575.5118s\n",
      "25399it [1:10:44,  6.07it/s]\titers: 25400, epoch: 5 | loss: 0.4193893\n",
      "\tspeed: 0.1688s/iter; left time: 75942.2923s\n",
      "25499it [1:11:01,  6.11it/s]\titers: 25500, epoch: 5 | loss: 0.4396090\n",
      "\tspeed: 0.1661s/iter; left time: 74710.1056s\n",
      "25599it [1:11:17,  6.03it/s]\titers: 25600, epoch: 5 | loss: 0.1202265\n",
      "\tspeed: 0.1656s/iter; left time: 74447.1697s\n",
      "25699it [1:11:34,  6.09it/s]\titers: 25700, epoch: 5 | loss: 0.0870090\n",
      "\tspeed: 0.1673s/iter; left time: 75225.1797s\n",
      "25799it [1:11:51,  6.02it/s]\titers: 25800, epoch: 5 | loss: 0.1210035\n",
      "\tspeed: 0.1665s/iter; left time: 74845.0254s\n",
      "25899it [1:12:07,  5.47it/s]\titers: 25900, epoch: 5 | loss: 0.1689609\n",
      "\tspeed: 0.1665s/iter; left time: 74811.3289s\n",
      "25999it [1:12:24,  5.98it/s]\titers: 26000, epoch: 5 | loss: 0.3336939\n",
      "\tspeed: 0.1664s/iter; left time: 74753.9426s\n",
      "26099it [1:12:40,  5.98it/s]\titers: 26100, epoch: 5 | loss: 0.1138947\n",
      "\tspeed: 0.1658s/iter; left time: 74481.0763s\n",
      "26199it [1:12:57,  6.08it/s]\titers: 26200, epoch: 5 | loss: 0.1023391\n",
      "\tspeed: 0.1655s/iter; left time: 74324.4449s\n",
      "26299it [1:13:14,  6.05it/s]\titers: 26300, epoch: 5 | loss: 0.0366248\n",
      "\tspeed: 0.1669s/iter; left time: 74950.0718s\n",
      "26399it [1:13:30,  6.04it/s]\titers: 26400, epoch: 5 | loss: 0.0347352\n",
      "\tspeed: 0.1666s/iter; left time: 74786.6700s\n",
      "26499it [1:13:47,  6.05it/s]\titers: 26500, epoch: 5 | loss: 0.0582756\n",
      "\tspeed: 0.1653s/iter; left time: 74174.4365s\n",
      "26599it [1:14:04,  6.07it/s]\titers: 26600, epoch: 5 | loss: 0.1160421\n",
      "\tspeed: 0.1677s/iter; left time: 75242.0867s\n",
      "26699it [1:14:20,  6.10it/s]\titers: 26700, epoch: 5 | loss: 0.1738544\n",
      "\tspeed: 0.1680s/iter; left time: 75340.6295s\n",
      "26799it [1:14:37,  6.03it/s]\titers: 26800, epoch: 5 | loss: 0.2903828\n",
      "\tspeed: 0.1670s/iter; left time: 74885.3309s\n",
      "26899it [1:14:54,  6.05it/s]\titers: 26900, epoch: 5 | loss: 0.0998935\n",
      "\tspeed: 0.1686s/iter; left time: 75609.4646s\n",
      "26999it [1:15:11,  6.03it/s]\titers: 27000, epoch: 5 | loss: 0.0744143\n",
      "\tspeed: 0.1705s/iter; left time: 76433.3189s\n",
      "27099it [1:15:28,  6.03it/s]\titers: 27100, epoch: 5 | loss: 0.0483252\n",
      "\tspeed: 0.1674s/iter; left time: 75005.1116s\n",
      "27199it [1:15:44,  6.00it/s]\titers: 27200, epoch: 5 | loss: 0.0651030\n",
      "\tspeed: 0.1673s/iter; left time: 74960.0670s\n",
      "27299it [1:16:01,  6.09it/s]\titers: 27300, epoch: 5 | loss: 0.0344294\n",
      "\tspeed: 0.1668s/iter; left time: 74722.2207s\n",
      "27399it [1:16:18,  5.48it/s]\titers: 27400, epoch: 5 | loss: 0.0646531\n",
      "\tspeed: 0.1678s/iter; left time: 75146.7785s\n",
      "27499it [1:16:35,  6.05it/s]\titers: 27500, epoch: 5 | loss: 0.1000177\n",
      "\tspeed: 0.1658s/iter; left time: 74247.6612s\n",
      "27599it [1:16:51,  6.03it/s]\titers: 27600, epoch: 5 | loss: 0.1213007\n",
      "\tspeed: 0.1664s/iter; left time: 74473.5755s\n",
      "27699it [1:17:08,  6.02it/s]\titers: 27700, epoch: 5 | loss: 0.3509060\n",
      "\tspeed: 0.1681s/iter; left time: 75256.7309s\n",
      "27799it [1:17:25,  6.01it/s]\titers: 27800, epoch: 5 | loss: 0.2463521\n",
      "\tspeed: 0.1667s/iter; left time: 74615.5244s\n",
      "27899it [1:17:42,  6.06it/s]\titers: 27900, epoch: 5 | loss: 0.0552801\n",
      "\tspeed: 0.1687s/iter; left time: 75493.5534s\n",
      "27999it [1:17:58,  6.01it/s]\titers: 28000, epoch: 5 | loss: 0.0913743\n",
      "\tspeed: 0.1669s/iter; left time: 74650.6788s\n",
      "28099it [1:18:15,  6.10it/s]\titers: 28100, epoch: 5 | loss: 0.0454083\n",
      "\tspeed: 0.1685s/iter; left time: 75338.6285s\n",
      "28199it [1:18:32,  6.08it/s]\titers: 28200, epoch: 5 | loss: 0.2015540\n",
      "\tspeed: 0.1683s/iter; left time: 75247.6460s\n",
      "28299it [1:18:48,  5.83it/s]\titers: 28300, epoch: 5 | loss: 0.1965797\n",
      "\tspeed: 0.1658s/iter; left time: 74128.7139s\n",
      "28399it [1:19:05,  6.11it/s]\titers: 28400, epoch: 5 | loss: 0.1017591\n",
      "\tspeed: 0.1657s/iter; left time: 74068.4505s\n",
      "28499it [1:19:22,  6.06it/s]\titers: 28500, epoch: 5 | loss: 0.2435385\n",
      "\tspeed: 0.1655s/iter; left time: 73957.5922s\n",
      "28599it [1:19:38,  6.08it/s]\titers: 28600, epoch: 5 | loss: 0.0929389\n",
      "\tspeed: 0.1666s/iter; left time: 74417.7014s\n",
      "28699it [1:19:55,  6.09it/s]\titers: 28700, epoch: 5 | loss: 0.1321188\n",
      "\tspeed: 0.1680s/iter; left time: 75007.8278s\n",
      "28799it [1:20:12,  6.02it/s]\titers: 28800, epoch: 5 | loss: 0.0717651\n",
      "\tspeed: 0.1674s/iter; left time: 74725.0170s\n",
      "28899it [1:20:28,  6.09it/s]\titers: 28900, epoch: 5 | loss: 0.1197412\n",
      "\tspeed: 0.1663s/iter; left time: 74217.5886s\n",
      "28999it [1:20:45,  6.11it/s]\titers: 29000, epoch: 5 | loss: 0.0666102\n",
      "\tspeed: 0.1681s/iter; left time: 75041.2471s\n",
      "29099it [1:21:02,  4.82it/s]\titers: 29100, epoch: 5 | loss: 0.1226264\n",
      "\tspeed: 0.1687s/iter; left time: 75250.1852s\n",
      "29199it [1:21:19,  6.04it/s]\titers: 29200, epoch: 5 | loss: 0.0609272\n",
      "\tspeed: 0.1657s/iter; left time: 73913.7910s\n",
      "29299it [1:21:35,  6.01it/s]\titers: 29300, epoch: 5 | loss: 0.1743853\n",
      "\tspeed: 0.1676s/iter; left time: 74762.6086s\n",
      "29399it [1:21:52,  6.04it/s]\titers: 29400, epoch: 5 | loss: 0.1588228\n",
      "\tspeed: 0.1659s/iter; left time: 73982.8452s\n",
      "29499it [1:22:09,  6.07it/s]\titers: 29500, epoch: 5 | loss: 0.0492372\n",
      "\tspeed: 0.1661s/iter; left time: 74045.3162s\n",
      "29599it [1:22:25,  6.00it/s]\titers: 29600, epoch: 5 | loss: 0.0303767\n",
      "\tspeed: 0.1680s/iter; left time: 74858.7357s\n",
      "29699it [1:22:42,  6.16it/s]\titers: 29700, epoch: 5 | loss: 0.1238557\n",
      "\tspeed: 0.1675s/iter; left time: 74651.9340s\n",
      "29705it [1:22:43,  5.98it/s]\n",
      "Epoch: 5 cost time: 4963.73046040535\n",
      "6481it [08:27, 12.78it/s]\n",
      "6457it [08:22, 12.85it/s]\n",
      "Epoch: 5 | Train Loss: 0.1475055 Vali Loss: 0.3234994 Test Loss: 0.4362055 MAE Loss: 0.3837755\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:16,  6.13it/s]\titers: 100, epoch: 6 | loss: 0.0766682\n",
      "\tspeed: 10.2745s/iter; left time: 4577059.7118s\n",
      "199it [00:32,  6.14it/s]\titers: 200, epoch: 6 | loss: 0.1311761\n",
      "\tspeed: 0.1624s/iter; left time: 72344.2630s\n",
      "299it [00:48,  6.14it/s]\titers: 300, epoch: 6 | loss: 0.0565795\n",
      "\tspeed: 0.1631s/iter; left time: 72623.8508s\n",
      "399it [01:05,  6.15it/s]\titers: 400, epoch: 6 | loss: 0.0914784\n",
      "\tspeed: 0.1633s/iter; left time: 72678.6217s\n",
      "499it [01:21,  6.12it/s]\titers: 500, epoch: 6 | loss: 0.1041440\n",
      "\tspeed: 0.1630s/iter; left time: 72537.4258s\n",
      "599it [01:37,  6.16it/s]\titers: 600, epoch: 6 | loss: 0.1627111\n",
      "\tspeed: 0.1631s/iter; left time: 72569.3228s\n",
      "653it [01:46,  6.20it/s]^C\n",
      "653it [01:46,  6.11it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main_copy.py\", line 210, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 2002, in backward\n",
      "    self.allreduce_gradients()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1918, in allreduce_gradients\n",
      "    self.optimizer.overlapping_partition_gradients_reduce_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 859, in overlapping_partition_gradients_reduce_epilogue\n",
      "    self.independent_gradient_partition_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 760, in independent_gradient_partition_epilogue\n",
      "    get_accelerator().synchronize()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/accelerator/cuda_accelerator.py\", line 77, in synchronize\n",
      "    return torch.cuda.synchronize(device_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 801, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 502.5608570933342 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'val (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.87s/it]\n",
      "d_llm 4096\n",
      "[2024-05-06 17:09:38,263] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 17:09:39,079] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 17:09:39,079] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 17:09:39,079] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 17:09:40,012] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-06 17:09:40,013] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 17:09:51,811] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 17:09:51,812] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 17:09:51,812] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 17:09:51,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 17:09:51,814] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 17:09:51,814] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 17:09:51,814] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 17:09:51,814] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 17:09:51,814] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 17:09:51,814] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 17:09:52,084] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 17:09:52,085] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-06 17:09:52,086] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.54 GB, percent = 16.0%\n",
      "[2024-05-06 17:09:52,194] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 17:09:52,194] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-06 17:09:52,194] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.49 GB, percent = 16.0%\n",
      "[2024-05-06 17:09:52,194] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 17:09:52,297] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 17:09:52,298] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-06 17:09:52,298] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.49 GB, percent = 16.0%\n",
      "[2024-05-06 17:09:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 17:09:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 17:09:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 17:09:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-06 17:09:52,299] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 17:09:52,299] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 17:09:52,299] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 17:09:52,299] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 17:09:52,299] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe73c99b150>\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 8\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 17:09:52,300] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 17:09:52,301] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 8, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "119it [00:20,  6.25it/s]\titers: 120, epoch: 1 | loss: 1.4833735\n",
      "\tspeed: 0.2908s/iter; left time: 172715.0206s\n",
      "239it [00:39,  6.21it/s]\titers: 240, epoch: 1 | loss: 0.4924821\n",
      "\tspeed: 0.1618s/iter; left time: 96093.0229s\n",
      "359it [00:58,  6.26it/s]\titers: 360, epoch: 1 | loss: 0.6898559\n",
      "\tspeed: 0.1612s/iter; left time: 95683.7796s\n",
      "479it [01:18,  6.18it/s]\titers: 480, epoch: 1 | loss: 1.1691513\n",
      "\tspeed: 0.1611s/iter; left time: 95641.8269s\n",
      "599it [01:37,  5.52it/s]\titers: 600, epoch: 1 | loss: 1.1890677\n",
      "\tspeed: 0.1626s/iter; left time: 96480.9800s\n",
      "719it [01:57,  6.25it/s]\titers: 720, epoch: 1 | loss: 0.4652767\n",
      "\tspeed: 0.1618s/iter; left time: 95990.4628s\n",
      "839it [02:16,  6.17it/s]\titers: 840, epoch: 1 | loss: 0.4205935\n",
      "\tspeed: 0.1646s/iter; left time: 97676.1350s\n",
      "959it [02:36,  6.26it/s]\titers: 960, epoch: 1 | loss: 0.9713202\n",
      "\tspeed: 0.1651s/iter; left time: 97953.5868s\n",
      "1079it [02:56,  6.19it/s]\titers: 1080, epoch: 1 | loss: 0.7381857\n",
      "\tspeed: 0.1632s/iter; left time: 96789.7773s\n",
      "1199it [03:16,  6.14it/s]\titers: 1200, epoch: 1 | loss: 3.9505260\n",
      "\tspeed: 0.1650s/iter; left time: 97817.9957s\n",
      "1319it [03:35,  6.17it/s]\titers: 1320, epoch: 1 | loss: 0.5821628\n",
      "\tspeed: 0.1629s/iter; left time: 96547.3590s\n",
      "1439it [03:55,  6.14it/s]\titers: 1440, epoch: 1 | loss: 0.4031151\n",
      "\tspeed: 0.1637s/iter; left time: 97004.0213s\n",
      "1559it [04:14,  6.10it/s]\titers: 1560, epoch: 1 | loss: 0.1691605\n",
      "\tspeed: 0.1638s/iter; left time: 97056.2752s\n",
      "1679it [04:34,  6.06it/s]\titers: 1680, epoch: 1 | loss: 0.1354782\n",
      "\tspeed: 0.1649s/iter; left time: 97665.2550s\n",
      "1799it [04:54,  6.10it/s]\titers: 1800, epoch: 1 | loss: 0.6334717\n",
      "\tspeed: 0.1645s/iter; left time: 97453.8131s\n",
      "1919it [05:14,  6.12it/s]\titers: 1920, epoch: 1 | loss: 0.1570891\n",
      "\tspeed: 0.1633s/iter; left time: 96723.3633s\n",
      "2039it [05:33,  5.61it/s]\titers: 2040, epoch: 1 | loss: 1.0675327\n",
      "\tspeed: 0.1637s/iter; left time: 96943.7735s\n",
      "2159it [05:53,  6.22it/s]\titers: 2160, epoch: 1 | loss: 0.3934945\n",
      "\tspeed: 0.1632s/iter; left time: 96601.7269s\n",
      "2279it [06:12,  6.12it/s]\titers: 2280, epoch: 1 | loss: 0.2786219\n",
      "\tspeed: 0.1628s/iter; left time: 96345.1912s\n",
      "2399it [06:32,  6.20it/s]\titers: 2400, epoch: 1 | loss: 0.1272237\n",
      "\tspeed: 0.1630s/iter; left time: 96461.5146s\n",
      "2519it [06:52,  6.14it/s]\titers: 2520, epoch: 1 | loss: 0.3145923\n",
      "\tspeed: 0.1633s/iter; left time: 96623.7338s\n",
      "2639it [07:11,  6.06it/s]\titers: 2640, epoch: 1 | loss: 0.2084380\n",
      "\tspeed: 0.1636s/iter; left time: 96792.5057s\n",
      "2759it [07:31,  6.12it/s]\titers: 2760, epoch: 1 | loss: 0.4078075\n",
      "\tspeed: 0.1661s/iter; left time: 98225.0858s\n",
      "2879it [07:51,  6.15it/s]\titers: 2880, epoch: 1 | loss: 0.2990488\n",
      "\tspeed: 0.1651s/iter; left time: 97636.6904s\n",
      "2999it [08:11,  6.09it/s]\titers: 3000, epoch: 1 | loss: 0.1098532\n",
      "\tspeed: 0.1640s/iter; left time: 96929.7539s\n",
      "3119it [08:30,  6.14it/s]\titers: 3120, epoch: 1 | loss: 0.2449064\n",
      "\tspeed: 0.1651s/iter; left time: 97593.5356s\n",
      "3239it [08:50,  6.11it/s]\titers: 3240, epoch: 1 | loss: 2.0180895\n",
      "\tspeed: 0.1634s/iter; left time: 96552.9564s\n",
      "3359it [09:10,  6.07it/s]\titers: 3360, epoch: 1 | loss: 0.2840997\n",
      "\tspeed: 0.1637s/iter; left time: 96676.5417s\n",
      "3479it [09:29,  6.14it/s]\titers: 3480, epoch: 1 | loss: 0.1258422\n",
      "\tspeed: 0.1628s/iter; left time: 96165.8403s\n",
      "3599it [09:49,  6.16it/s]\titers: 3600, epoch: 1 | loss: 0.3391964\n",
      "\tspeed: 0.1631s/iter; left time: 96298.5857s\n",
      "3719it [10:08,  6.17it/s]\titers: 3720, epoch: 1 | loss: 0.7090424\n",
      "\tspeed: 0.1632s/iter; left time: 96339.2264s\n",
      "3839it [10:28,  6.16it/s]\titers: 3840, epoch: 1 | loss: 0.3136199\n",
      "\tspeed: 0.1632s/iter; left time: 96356.5380s\n",
      "3959it [10:47,  6.20it/s]\titers: 3960, epoch: 1 | loss: 0.4445247\n",
      "\tspeed: 0.1626s/iter; left time: 95984.6310s\n",
      "4079it [11:07,  5.07it/s]\titers: 4080, epoch: 1 | loss: 0.1327193\n",
      "\tspeed: 0.1646s/iter; left time: 97111.4726s\n",
      "4199it [11:27,  6.19it/s]\titers: 4200, epoch: 1 | loss: 0.1724528\n",
      "\tspeed: 0.1647s/iter; left time: 97140.8064s\n",
      "4319it [11:47,  6.14it/s]\titers: 4320, epoch: 1 | loss: 0.6177819\n",
      "\tspeed: 0.1652s/iter; left time: 97405.7436s\n",
      "4439it [12:07,  6.18it/s]\titers: 4440, epoch: 1 | loss: 0.5198262\n",
      "\tspeed: 0.1652s/iter; left time: 97425.5210s\n",
      "4559it [12:26,  6.19it/s]\titers: 4560, epoch: 1 | loss: 0.3285631\n",
      "\tspeed: 0.1629s/iter; left time: 96025.4369s\n",
      "4679it [12:46,  6.16it/s]\titers: 4680, epoch: 1 | loss: 0.2027600\n",
      "\tspeed: 0.1638s/iter; left time: 96537.1232s\n",
      "4799it [13:05,  6.13it/s]\titers: 4800, epoch: 1 | loss: 0.5107301\n",
      "\tspeed: 0.1631s/iter; left time: 96101.5204s\n",
      "4919it [13:25,  6.11it/s]\titers: 4920, epoch: 1 | loss: 0.1456599\n",
      "\tspeed: 0.1637s/iter; left time: 96428.2502s\n",
      "5039it [13:45,  6.01it/s]\titers: 5040, epoch: 1 | loss: 0.2887029\n",
      "\tspeed: 0.1639s/iter; left time: 96544.4938s\n",
      "5159it [14:05,  6.05it/s]\titers: 5160, epoch: 1 | loss: 0.0513344\n",
      "\tspeed: 0.1671s/iter; left time: 98388.3007s\n",
      "5279it [14:24,  6.19it/s]\titers: 5280, epoch: 1 | loss: 0.2203107\n",
      "\tspeed: 0.1639s/iter; left time: 96535.1137s\n",
      "5399it [14:44,  6.16it/s]\titers: 5400, epoch: 1 | loss: 0.1511711\n",
      "\tspeed: 0.1648s/iter; left time: 97013.4265s\n",
      "5519it [15:04,  6.12it/s]\titers: 5520, epoch: 1 | loss: 0.0816672\n",
      "\tspeed: 0.1641s/iter; left time: 96598.9069s\n",
      "5639it [15:24,  6.08it/s]\titers: 5640, epoch: 1 | loss: 1.5874424\n",
      "\tspeed: 0.1643s/iter; left time: 96697.6244s\n",
      "5759it [15:43,  6.16it/s]\titers: 5760, epoch: 1 | loss: 0.0879882\n",
      "\tspeed: 0.1650s/iter; left time: 97090.8086s\n",
      "5879it [16:03,  6.09it/s]\titers: 5880, epoch: 1 | loss: 0.0397550\n",
      "\tspeed: 0.1661s/iter; left time: 97707.9429s\n",
      "5999it [16:23,  6.05it/s]\titers: 6000, epoch: 1 | loss: 0.2352989\n",
      "\tspeed: 0.1642s/iter; left time: 96593.3285s\n",
      "6119it [16:43,  5.99it/s]\titers: 6120, epoch: 1 | loss: 0.3212229\n",
      "\tspeed: 0.1641s/iter; left time: 96474.2227s\n",
      "6239it [17:02,  6.12it/s]\titers: 6240, epoch: 1 | loss: 0.4925178\n",
      "\tspeed: 0.1645s/iter; left time: 96675.3356s\n",
      "6359it [17:22,  6.18it/s]\titers: 6360, epoch: 1 | loss: 0.1694060\n",
      "\tspeed: 0.1643s/iter; left time: 96592.3146s\n",
      "6479it [17:42,  6.18it/s]\titers: 6480, epoch: 1 | loss: 1.1777480\n",
      "\tspeed: 0.1637s/iter; left time: 96174.0409s\n",
      "6599it [18:01,  6.24it/s]\titers: 6600, epoch: 1 | loss: 0.0524570\n",
      "\tspeed: 0.1637s/iter; left time: 96177.8616s\n",
      "6719it [18:21,  6.16it/s]\titers: 6720, epoch: 1 | loss: 0.1707962\n",
      "\tspeed: 0.1665s/iter; left time: 97826.9988s\n",
      "6839it [18:41,  6.12it/s]\titers: 6840, epoch: 1 | loss: 0.2021303\n",
      "\tspeed: 0.1660s/iter; left time: 97459.4565s\n",
      "6959it [19:01,  6.18it/s]\titers: 6960, epoch: 1 | loss: 0.2320356\n",
      "\tspeed: 0.1642s/iter; left time: 96410.2320s\n",
      "7079it [19:21,  6.15it/s]\titers: 7080, epoch: 1 | loss: 0.2245304\n",
      "\tspeed: 0.1652s/iter; left time: 97004.5621s\n",
      "7199it [19:41,  6.15it/s]\titers: 7200, epoch: 1 | loss: 0.1930302\n",
      "\tspeed: 0.1653s/iter; left time: 96993.2585s\n",
      "7319it [20:01,  6.14it/s]\titers: 7320, epoch: 1 | loss: 0.0906178\n",
      "\tspeed: 0.1657s/iter; left time: 97250.2495s\n",
      "7439it [20:20,  6.12it/s]\titers: 7440, epoch: 1 | loss: 0.0984292\n",
      "\tspeed: 0.1649s/iter; left time: 96732.6611s\n",
      "7559it [20:40,  5.94it/s]\titers: 7560, epoch: 1 | loss: 0.6286129\n",
      "\tspeed: 0.1659s/iter; left time: 97298.3080s\n",
      "7679it [21:00,  6.16it/s]\titers: 7680, epoch: 1 | loss: 0.1666369\n",
      "\tspeed: 0.1647s/iter; left time: 96554.2311s\n",
      "7799it [21:20,  6.14it/s]\titers: 7800, epoch: 1 | loss: 0.9062099\n",
      "\tspeed: 0.1639s/iter; left time: 96116.4354s\n",
      "7919it [21:39,  6.10it/s]\titers: 7920, epoch: 1 | loss: 0.0764937\n",
      "\tspeed: 0.1632s/iter; left time: 95662.5164s\n",
      "8039it [21:59,  6.15it/s]\titers: 8040, epoch: 1 | loss: 0.2664986\n",
      "\tspeed: 0.1633s/iter; left time: 95675.3043s\n",
      "8159it [22:19,  6.16it/s]\titers: 8160, epoch: 1 | loss: 0.0760324\n",
      "\tspeed: 0.1631s/iter; left time: 95583.7307s\n",
      "8279it [22:38,  6.12it/s]\titers: 8280, epoch: 1 | loss: 0.2818111\n",
      "\tspeed: 0.1633s/iter; left time: 95666.5571s\n",
      "8399it [22:58,  6.11it/s]\titers: 8400, epoch: 1 | loss: 0.0684122\n",
      "\tspeed: 0.1633s/iter; left time: 95631.5197s\n",
      "8519it [23:17,  5.88it/s]\titers: 8520, epoch: 1 | loss: 0.6417209\n",
      "\tspeed: 0.1636s/iter; left time: 95816.4752s\n",
      "8639it [23:37,  6.14it/s]\titers: 8640, epoch: 1 | loss: 0.1633715\n",
      "\tspeed: 0.1637s/iter; left time: 95843.0927s\n",
      "8759it [23:57,  6.19it/s]\titers: 8760, epoch: 1 | loss: 0.3740100\n",
      "\tspeed: 0.1643s/iter; left time: 96194.7663s\n",
      "8879it [24:16,  6.17it/s]\titers: 8880, epoch: 1 | loss: 0.3938838\n",
      "\tspeed: 0.1633s/iter; left time: 95588.6751s\n",
      "8999it [24:36,  6.14it/s]\titers: 9000, epoch: 1 | loss: 0.6767637\n",
      "\tspeed: 0.1630s/iter; left time: 95349.5288s\n",
      "9119it [24:55,  6.15it/s]\titers: 9120, epoch: 1 | loss: 0.1741435\n",
      "\tspeed: 0.1635s/iter; left time: 95645.1321s\n",
      "9239it [25:15,  6.15it/s]\titers: 9240, epoch: 1 | loss: 0.3790534\n",
      "\tspeed: 0.1632s/iter; left time: 95473.9853s\n",
      "9359it [25:35,  6.12it/s]\titers: 9360, epoch: 1 | loss: 0.1763234\n",
      "\tspeed: 0.1631s/iter; left time: 95349.9456s\n",
      "9479it [25:54,  5.71it/s]\titers: 9480, epoch: 1 | loss: 0.2042020\n",
      "\tspeed: 0.1640s/iter; left time: 95901.8336s\n",
      "9599it [26:14,  6.15it/s]\titers: 9600, epoch: 1 | loss: 0.1537821\n",
      "\tspeed: 0.1638s/iter; left time: 95713.0217s\n",
      "9719it [26:34,  6.20it/s]\titers: 9720, epoch: 1 | loss: 0.4364022\n",
      "\tspeed: 0.1639s/iter; left time: 95753.1289s\n",
      "9839it [26:53,  6.10it/s]\titers: 9840, epoch: 1 | loss: 0.2716147\n",
      "\tspeed: 0.1636s/iter; left time: 95593.1683s\n",
      "9959it [27:13,  6.13it/s]\titers: 9960, epoch: 1 | loss: 0.0696333\n",
      "\tspeed: 0.1637s/iter; left time: 95619.8837s\n",
      "10079it [27:33,  6.18it/s]\titers: 10080, epoch: 1 | loss: 0.1475077\n",
      "\tspeed: 0.1633s/iter; left time: 95389.1656s\n",
      "10199it [27:52,  6.14it/s]\titers: 10200, epoch: 1 | loss: 0.9999121\n",
      "\tspeed: 0.1630s/iter; left time: 95202.6136s\n",
      "10319it [28:12,  5.92it/s]\titers: 10320, epoch: 1 | loss: 0.2284036\n",
      "\tspeed: 0.1656s/iter; left time: 96647.8752s\n",
      "10439it [28:32,  6.15it/s]\titers: 10440, epoch: 1 | loss: 0.2599048\n",
      "\tspeed: 0.1649s/iter; left time: 96261.1051s\n",
      "10559it [28:51,  6.16it/s]\titers: 10560, epoch: 1 | loss: 0.2251532\n",
      "\tspeed: 0.1636s/iter; left time: 95438.6728s\n",
      "10679it [29:11,  6.12it/s]\titers: 10680, epoch: 1 | loss: 0.3736761\n",
      "\tspeed: 0.1633s/iter; left time: 95267.7099s\n",
      "10799it [29:31,  6.16it/s]\titers: 10800, epoch: 1 | loss: 0.1846009\n",
      "\tspeed: 0.1634s/iter; left time: 95316.0656s\n",
      "10919it [29:50,  6.12it/s]\titers: 10920, epoch: 1 | loss: 0.2653820\n",
      "\tspeed: 0.1638s/iter; left time: 95496.6910s\n",
      "11039it [30:10,  6.10it/s]\titers: 11040, epoch: 1 | loss: 0.1187468\n",
      "\tspeed: 0.1637s/iter; left time: 95463.3365s\n",
      "11159it [30:29,  6.13it/s]\titers: 11160, epoch: 1 | loss: 0.3432931\n",
      "\tspeed: 0.1633s/iter; left time: 95215.1903s\n",
      "11279it [30:49,  5.99it/s]\titers: 11280, epoch: 1 | loss: 0.2250350\n",
      "\tspeed: 0.1656s/iter; left time: 96517.4410s\n",
      "11399it [31:09,  6.13it/s]\titers: 11400, epoch: 1 | loss: 0.0953847\n",
      "\tspeed: 0.1644s/iter; left time: 95811.6710s\n",
      "11519it [31:29,  6.13it/s]\titers: 11520, epoch: 1 | loss: 0.2876244\n",
      "\tspeed: 0.1656s/iter; left time: 96450.8181s\n",
      "11639it [31:49,  6.17it/s]\titers: 11640, epoch: 1 | loss: 0.6686051\n",
      "\tspeed: 0.1645s/iter; left time: 95786.1834s\n",
      "11759it [32:08,  6.14it/s]\titers: 11760, epoch: 1 | loss: 0.1286762\n",
      "\tspeed: 0.1641s/iter; left time: 95550.5645s\n",
      "11879it [32:28,  6.12it/s]\titers: 11880, epoch: 1 | loss: 0.6376153\n",
      "\tspeed: 0.1643s/iter; left time: 95676.3455s\n",
      "11999it [32:48,  6.17it/s]\titers: 12000, epoch: 1 | loss: 0.6890942\n",
      "\tspeed: 0.1646s/iter; left time: 95842.0687s\n",
      "12119it [33:07,  6.01it/s]\titers: 12120, epoch: 1 | loss: 0.1636506\n",
      "\tspeed: 0.1637s/iter; left time: 95269.0909s\n",
      "12239it [33:27,  6.15it/s]\titers: 12240, epoch: 1 | loss: 0.5017210\n",
      "\tspeed: 0.1629s/iter; left time: 94808.7120s\n",
      "12359it [33:47,  6.17it/s]\titers: 12360, epoch: 1 | loss: 0.4664230\n",
      "\tspeed: 0.1630s/iter; left time: 94814.4796s\n",
      "12479it [34:06,  6.14it/s]\titers: 12480, epoch: 1 | loss: 0.2411371\n",
      "\tspeed: 0.1629s/iter; left time: 94767.1899s\n",
      "12599it [34:26,  6.11it/s]\titers: 12600, epoch: 1 | loss: 0.1512552\n",
      "\tspeed: 0.1629s/iter; left time: 94698.0458s\n",
      "12719it [34:45,  6.18it/s]\titers: 12720, epoch: 1 | loss: 0.3253312\n",
      "\tspeed: 0.1649s/iter; left time: 95854.3426s\n",
      "12839it [35:06,  6.16it/s]\titers: 12840, epoch: 1 | loss: 0.1528597\n",
      "\tspeed: 0.1683s/iter; left time: 97815.1205s\n",
      "12959it [35:25,  6.14it/s]\titers: 12960, epoch: 1 | loss: 0.0943470\n",
      "\tspeed: 0.1649s/iter; left time: 95839.0547s\n",
      "13079it [35:45,  6.22it/s]\titers: 13080, epoch: 1 | loss: 0.3206886\n",
      "\tspeed: 0.1636s/iter; left time: 95044.6171s\n",
      "13199it [36:05,  6.16it/s]\titers: 13200, epoch: 1 | loss: 0.0662011\n",
      "\tspeed: 0.1634s/iter; left time: 94927.5231s\n",
      "13319it [36:24,  6.16it/s]\titers: 13320, epoch: 1 | loss: 0.4125440\n",
      "\tspeed: 0.1635s/iter; left time: 94967.9927s\n",
      "13439it [36:44,  6.14it/s]\titers: 13440, epoch: 1 | loss: 0.3507084\n",
      "\tspeed: 0.1634s/iter; left time: 94883.9578s\n",
      "13559it [37:04,  6.13it/s]\titers: 13560, epoch: 1 | loss: 0.0560444\n",
      "\tspeed: 0.1642s/iter; left time: 95305.8282s\n",
      "13679it [37:23,  6.17it/s]\titers: 13680, epoch: 1 | loss: 0.2444161\n",
      "\tspeed: 0.1634s/iter; left time: 94845.9660s\n",
      "13799it [37:43,  6.10it/s]\titers: 13800, epoch: 1 | loss: 0.6539209\n",
      "\tspeed: 0.1634s/iter; left time: 94806.0384s\n",
      "13919it [38:02,  6.16it/s]\titers: 13920, epoch: 1 | loss: 0.2701023\n",
      "\tspeed: 0.1632s/iter; left time: 94714.2873s\n",
      "14039it [38:22,  6.15it/s]\titers: 14040, epoch: 1 | loss: 0.1178183\n",
      "\tspeed: 0.1633s/iter; left time: 94703.3905s\n",
      "14159it [38:42,  6.19it/s]\titers: 14160, epoch: 1 | loss: 0.2590292\n",
      "\tspeed: 0.1641s/iter; left time: 95153.2072s\n",
      "14279it [39:01,  6.12it/s]\titers: 14280, epoch: 1 | loss: 0.1097786\n",
      "\tspeed: 0.1638s/iter; left time: 94993.4742s\n",
      "14399it [39:21,  5.85it/s]\titers: 14400, epoch: 1 | loss: 0.1651543\n",
      "\tspeed: 0.1643s/iter; left time: 95258.8997s\n",
      "14519it [39:41,  6.15it/s]\titers: 14520, epoch: 1 | loss: 0.1379476\n",
      "\tspeed: 0.1667s/iter; left time: 96607.5483s\n",
      "14639it [40:01,  6.14it/s]\titers: 14640, epoch: 1 | loss: 0.1243158\n",
      "\tspeed: 0.1666s/iter; left time: 96525.1487s\n",
      "14759it [40:21,  6.06it/s]\titers: 14760, epoch: 1 | loss: 0.5009219\n",
      "\tspeed: 0.1638s/iter; left time: 94884.8073s\n",
      "14879it [40:40,  6.16it/s]\titers: 14880, epoch: 1 | loss: 0.2145258\n",
      "\tspeed: 0.1634s/iter; left time: 94652.1792s\n",
      "14999it [41:00,  6.16it/s]\titers: 15000, epoch: 1 | loss: 0.3173815\n",
      "\tspeed: 0.1634s/iter; left time: 94603.3440s\n",
      "15119it [41:20,  6.12it/s]\titers: 15120, epoch: 1 | loss: 0.1629986\n",
      "\tspeed: 0.1635s/iter; left time: 94685.0192s\n",
      "15239it [41:39,  6.10it/s]\titers: 15240, epoch: 1 | loss: 0.3535830\n",
      "\tspeed: 0.1637s/iter; left time: 94767.5506s\n",
      "15359it [41:59,  6.15it/s]\titers: 15360, epoch: 1 | loss: 0.0829791\n",
      "\tspeed: 0.1637s/iter; left time: 94754.3188s\n",
      "15479it [42:18,  6.19it/s]\titers: 15480, epoch: 1 | loss: 0.1623231\n",
      "\tspeed: 0.1634s/iter; left time: 94563.8618s\n",
      "15599it [42:38,  6.14it/s]\titers: 15600, epoch: 1 | loss: 0.5377893\n",
      "\tspeed: 0.1634s/iter; left time: 94507.0713s\n",
      "15719it [42:58,  6.11it/s]\titers: 15720, epoch: 1 | loss: 0.2250087\n",
      "\tspeed: 0.1635s/iter; left time: 94566.9420s\n",
      "15839it [43:17,  6.16it/s]\titers: 15840, epoch: 1 | loss: 0.2134803\n",
      "\tspeed: 0.1640s/iter; left time: 94845.7821s\n",
      "15959it [43:37,  6.11it/s]\titers: 15960, epoch: 1 | loss: 0.0918555\n",
      "\tspeed: 0.1633s/iter; left time: 94384.2195s\n",
      "16079it [43:57,  6.08it/s]\titers: 16080, epoch: 1 | loss: 1.3706930\n",
      "\tspeed: 0.1636s/iter; left time: 94540.0496s\n",
      "16199it [44:16,  6.13it/s]\titers: 16200, epoch: 1 | loss: 0.3992651\n",
      "\tspeed: 0.1632s/iter; left time: 94323.4823s\n",
      "16319it [44:36,  6.17it/s]\titers: 16320, epoch: 1 | loss: 0.1406782\n",
      "\tspeed: 0.1641s/iter; left time: 94801.1860s\n",
      "16439it [44:55,  6.14it/s]\titers: 16440, epoch: 1 | loss: 0.8254682\n",
      "\tspeed: 0.1632s/iter; left time: 94250.7890s\n",
      "16559it [45:15,  6.12it/s]\titers: 16560, epoch: 1 | loss: 0.1570414\n",
      "\tspeed: 0.1640s/iter; left time: 94737.6026s\n",
      "16679it [45:35,  6.19it/s]\titers: 16680, epoch: 1 | loss: 0.3584875\n",
      "\tspeed: 0.1648s/iter; left time: 95165.3836s\n",
      "16799it [45:55,  6.14it/s]\titers: 16800, epoch: 1 | loss: 0.3616404\n",
      "\tspeed: 0.1644s/iter; left time: 94912.2217s\n",
      "16919it [46:14,  6.14it/s]\titers: 16920, epoch: 1 | loss: 0.3685995\n",
      "\tspeed: 0.1636s/iter; left time: 94433.1714s\n",
      "17039it [46:34,  6.05it/s]\titers: 17040, epoch: 1 | loss: 0.2253704\n",
      "\tspeed: 0.1650s/iter; left time: 95224.7368s\n",
      "17159it [46:54,  6.14it/s]\titers: 17160, epoch: 1 | loss: 0.1837221\n",
      "\tspeed: 0.1631s/iter; left time: 94122.7639s\n",
      "17279it [47:13,  6.14it/s]\titers: 17280, epoch: 1 | loss: 0.2280851\n",
      "\tspeed: 0.1631s/iter; left time: 94080.1974s\n",
      "17399it [47:33,  6.16it/s]\titers: 17400, epoch: 1 | loss: 0.1621178\n",
      "\tspeed: 0.1654s/iter; left time: 95367.9716s\n",
      "17519it [47:53,  6.16it/s]\titers: 17520, epoch: 1 | loss: 0.2739504\n",
      "\tspeed: 0.1655s/iter; left time: 95452.7368s\n",
      "17639it [48:13,  6.10it/s]\titers: 17640, epoch: 1 | loss: 0.2914813\n",
      "\tspeed: 0.1649s/iter; left time: 95082.9088s\n",
      "17759it [48:32,  6.15it/s]\titers: 17760, epoch: 1 | loss: 0.3487985\n",
      "\tspeed: 0.1643s/iter; left time: 94689.5838s\n",
      "17879it [48:52,  6.18it/s]\titers: 17880, epoch: 1 | loss: 0.1750244\n",
      "\tspeed: 0.1641s/iter; left time: 94568.8093s\n",
      "17999it [49:12,  6.00it/s]\titers: 18000, epoch: 1 | loss: 0.1028483\n",
      "\tspeed: 0.1642s/iter; left time: 94589.5735s\n",
      "18119it [49:31,  6.16it/s]\titers: 18120, epoch: 1 | loss: 0.2174446\n",
      "\tspeed: 0.1628s/iter; left time: 93790.3467s\n",
      "18239it [49:51,  6.17it/s]\titers: 18240, epoch: 1 | loss: 0.1843443\n",
      "\tspeed: 0.1637s/iter; left time: 94271.5614s\n",
      "18359it [50:11,  6.13it/s]\titers: 18360, epoch: 1 | loss: 0.1819778\n",
      "\tspeed: 0.1654s/iter; left time: 95248.9948s\n",
      "18479it [50:31,  6.16it/s]\titers: 18480, epoch: 1 | loss: 0.1718963\n",
      "\tspeed: 0.1652s/iter; left time: 95090.9521s\n",
      "18599it [50:51,  6.17it/s]\titers: 18600, epoch: 1 | loss: 0.0872288\n",
      "\tspeed: 0.1654s/iter; left time: 95179.1779s\n",
      "18719it [51:11,  5.47it/s]\titers: 18720, epoch: 1 | loss: 0.3378701\n",
      "\tspeed: 0.1669s/iter; left time: 96018.7123s\n",
      "18839it [51:30,  6.16it/s]\titers: 18840, epoch: 1 | loss: 0.1951478\n",
      "\tspeed: 0.1655s/iter; left time: 95231.4729s\n",
      "18959it [51:50,  6.19it/s]\titers: 18960, epoch: 1 | loss: 0.5236736\n",
      "\tspeed: 0.1649s/iter; left time: 94833.0062s\n",
      "19079it [52:10,  6.09it/s]\titers: 19080, epoch: 1 | loss: 0.1834211\n",
      "\tspeed: 0.1643s/iter; left time: 94456.4614s\n",
      "19199it [52:30,  6.11it/s]\titers: 19200, epoch: 1 | loss: 0.1888879\n",
      "\tspeed: 0.1651s/iter; left time: 94906.9581s\n",
      "19319it [52:49,  6.13it/s]\titers: 19320, epoch: 1 | loss: 0.1136642\n",
      "\tspeed: 0.1640s/iter; left time: 94279.4600s\n",
      "19439it [53:09,  6.12it/s]\titers: 19440, epoch: 1 | loss: 0.3236337\n",
      "\tspeed: 0.1641s/iter; left time: 94286.6662s\n",
      "19559it [53:29,  6.11it/s]\titers: 19560, epoch: 1 | loss: 0.1591550\n",
      "\tspeed: 0.1658s/iter; left time: 95241.2359s\n",
      "19679it [53:49,  6.11it/s]\titers: 19680, epoch: 1 | loss: 0.2230941\n",
      "\tspeed: 0.1643s/iter; left time: 94352.1075s\n",
      "19799it [54:09,  6.10it/s]\titers: 19800, epoch: 1 | loss: 0.3402408\n",
      "\tspeed: 0.1666s/iter; left time: 95688.0279s\n",
      "19919it [54:28,  6.11it/s]\titers: 19920, epoch: 1 | loss: 0.1400334\n",
      "\tspeed: 0.1633s/iter; left time: 93761.2610s\n",
      "20039it [54:48,  6.07it/s]\titers: 20040, epoch: 1 | loss: 0.1691215\n",
      "\tspeed: 0.1637s/iter; left time: 93962.6313s\n",
      "20159it [55:08,  5.05it/s]\titers: 20160, epoch: 1 | loss: 0.4903114\n",
      "\tspeed: 0.1677s/iter; left time: 96243.9479s\n",
      "20279it [55:28,  5.46it/s]\titers: 20280, epoch: 1 | loss: 1.1097529\n",
      "\tspeed: 0.1665s/iter; left time: 95520.0686s\n",
      "20399it [55:48,  5.85it/s]\titers: 20400, epoch: 1 | loss: 0.2748457\n",
      "\tspeed: 0.1660s/iter; left time: 95247.2226s\n",
      "20519it [56:08,  5.89it/s]\titers: 20520, epoch: 1 | loss: 0.7172539\n",
      "\tspeed: 0.1650s/iter; left time: 94626.3633s\n",
      "20639it [56:28,  6.08it/s]\titers: 20640, epoch: 1 | loss: 0.1203177\n",
      "\tspeed: 0.1645s/iter; left time: 94347.6970s\n",
      "20759it [56:47,  6.06it/s]\titers: 20760, epoch: 1 | loss: 0.1883609\n",
      "\tspeed: 0.1650s/iter; left time: 94575.2585s\n",
      "20879it [57:07,  5.96it/s]\titers: 20880, epoch: 1 | loss: 0.0887726\n",
      "\tspeed: 0.1652s/iter; left time: 94675.2362s\n",
      "20999it [57:27,  6.10it/s]\titers: 21000, epoch: 1 | loss: 0.1836026\n",
      "\tspeed: 0.1668s/iter; left time: 95581.9584s\n",
      "21119it [57:47,  6.14it/s]\titers: 21120, epoch: 1 | loss: 0.2509911\n",
      "\tspeed: 0.1659s/iter; left time: 95077.3118s\n",
      "21239it [58:07,  6.13it/s]\titers: 21240, epoch: 1 | loss: 0.1981741\n",
      "\tspeed: 0.1648s/iter; left time: 94401.0292s\n",
      "21359it [58:27,  6.16it/s]\titers: 21360, epoch: 1 | loss: 0.1240442\n",
      "\tspeed: 0.1642s/iter; left time: 94066.5407s\n",
      "21479it [58:46,  6.16it/s]\titers: 21480, epoch: 1 | loss: 0.1513966\n",
      "\tspeed: 0.1644s/iter; left time: 94139.7794s\n",
      "21599it [59:06,  6.12it/s]\titers: 21600, epoch: 1 | loss: 0.1383275\n",
      "\tspeed: 0.1638s/iter; left time: 93768.5269s\n",
      "21719it [59:26,  6.01it/s]\titers: 21720, epoch: 1 | loss: 0.3381077\n",
      "\tspeed: 0.1657s/iter; left time: 94869.5834s\n",
      "21839it [59:46,  6.00it/s]\titers: 21840, epoch: 1 | loss: 0.3989128\n",
      "\tspeed: 0.1655s/iter; left time: 94695.3386s\n",
      "21959it [1:00:06,  5.99it/s]\titers: 21960, epoch: 1 | loss: 0.2325507\n",
      "\tspeed: 0.1670s/iter; left time: 95519.0419s\n",
      "22079it [1:00:26,  6.17it/s]\titers: 22080, epoch: 1 | loss: 0.2292392\n",
      "\tspeed: 0.1661s/iter; left time: 95007.4200s\n",
      "22199it [1:00:46,  6.15it/s]\titers: 22200, epoch: 1 | loss: 0.0849600\n",
      "\tspeed: 0.1657s/iter; left time: 94790.0301s\n",
      "22319it [1:01:05,  6.03it/s]\titers: 22320, epoch: 1 | loss: 0.2148949\n",
      "\tspeed: 0.1647s/iter; left time: 94158.3800s\n",
      "22439it [1:01:25,  6.08it/s]\titers: 22440, epoch: 1 | loss: 0.2232145\n",
      "\tspeed: 0.1651s/iter; left time: 94369.1135s\n",
      "22559it [1:01:45,  6.16it/s]\titers: 22560, epoch: 1 | loss: 0.4171130\n",
      "\tspeed: 0.1648s/iter; left time: 94171.2408s\n",
      "22679it [1:02:05,  6.13it/s]\titers: 22680, epoch: 1 | loss: 0.1209785\n",
      "\tspeed: 0.1651s/iter; left time: 94364.7449s\n",
      "22799it [1:02:25,  6.14it/s]\titers: 22800, epoch: 1 | loss: 0.8073973\n",
      "\tspeed: 0.1655s/iter; left time: 94573.4308s\n",
      "22919it [1:02:44,  6.16it/s]\titers: 22920, epoch: 1 | loss: 1.2279140\n",
      "\tspeed: 0.1660s/iter; left time: 94793.4416s\n",
      "23039it [1:03:04,  6.14it/s]\titers: 23040, epoch: 1 | loss: 0.2204132\n",
      "\tspeed: 0.1662s/iter; left time: 94889.6806s\n",
      "23159it [1:03:24,  6.17it/s]\titers: 23160, epoch: 1 | loss: 0.3411772\n",
      "\tspeed: 0.1644s/iter; left time: 93867.1626s\n",
      "23279it [1:03:44,  6.15it/s]\titers: 23280, epoch: 1 | loss: 0.1596457\n",
      "\tspeed: 0.1635s/iter; left time: 93324.2905s\n",
      "23399it [1:04:03,  6.10it/s]\titers: 23400, epoch: 1 | loss: 0.4632519\n",
      "\tspeed: 0.1640s/iter; left time: 93591.4731s\n",
      "23519it [1:04:23,  6.09it/s]\titers: 23520, epoch: 1 | loss: 1.1981152\n",
      "\tspeed: 0.1646s/iter; left time: 93931.9838s\n",
      "23639it [1:04:43,  6.19it/s]\titers: 23640, epoch: 1 | loss: 0.2171714\n",
      "\tspeed: 0.1656s/iter; left time: 94471.0413s\n",
      "23759it [1:05:03,  6.16it/s]\titers: 23760, epoch: 1 | loss: 0.1358887\n",
      "\tspeed: 0.1642s/iter; left time: 93632.0043s\n",
      "23879it [1:05:23,  6.14it/s]\titers: 23880, epoch: 1 | loss: 0.1145143\n",
      "\tspeed: 0.1654s/iter; left time: 94288.7399s\n",
      "23999it [1:05:42,  6.15it/s]\titers: 24000, epoch: 1 | loss: 0.2414522\n",
      "\tspeed: 0.1640s/iter; left time: 93505.0312s\n",
      "24119it [1:06:02,  6.14it/s]\titers: 24120, epoch: 1 | loss: 0.2734980\n",
      "\tspeed: 0.1638s/iter; left time: 93363.3879s\n",
      "24239it [1:06:22,  6.11it/s]\titers: 24240, epoch: 1 | loss: 0.8122677\n",
      "\tspeed: 0.1654s/iter; left time: 94251.7602s\n",
      "24359it [1:06:41,  6.15it/s]\titers: 24360, epoch: 1 | loss: 0.0657222\n",
      "\tspeed: 0.1639s/iter; left time: 93402.0551s\n",
      "24479it [1:07:01,  6.14it/s]\titers: 24480, epoch: 1 | loss: 0.3954940\n",
      "\tspeed: 0.1661s/iter; left time: 94641.5896s\n",
      "24599it [1:07:21,  5.65it/s]\titers: 24600, epoch: 1 | loss: 0.1564143\n",
      "\tspeed: 0.1643s/iter; left time: 93592.6471s\n",
      "24719it [1:07:41,  6.14it/s]\titers: 24720, epoch: 1 | loss: 0.1423256\n",
      "\tspeed: 0.1634s/iter; left time: 93019.8313s\n",
      "24839it [1:08:00,  6.18it/s]\titers: 24840, epoch: 1 | loss: 0.2592956\n",
      "\tspeed: 0.1635s/iter; left time: 93052.5411s\n",
      "24959it [1:08:20,  6.13it/s]\titers: 24960, epoch: 1 | loss: 0.4195735\n",
      "\tspeed: 0.1630s/iter; left time: 92771.4086s\n",
      "25079it [1:08:40,  6.21it/s]\titers: 25080, epoch: 1 | loss: 0.1118655\n",
      "\tspeed: 0.1648s/iter; left time: 93751.5752s\n",
      "25199it [1:08:59,  6.13it/s]\titers: 25200, epoch: 1 | loss: 0.4676917\n",
      "\tspeed: 0.1643s/iter; left time: 93465.9349s\n",
      "25319it [1:09:19,  6.11it/s]\titers: 25320, epoch: 1 | loss: 0.1735726\n",
      "\tspeed: 0.1645s/iter; left time: 93556.7370s\n",
      "25439it [1:09:39,  6.24it/s]\titers: 25440, epoch: 1 | loss: 0.1257547\n",
      "\tspeed: 0.1633s/iter; left time: 92867.5134s\n",
      "25559it [1:09:58,  6.15it/s]\titers: 25560, epoch: 1 | loss: 0.4112696\n",
      "\tspeed: 0.1642s/iter; left time: 93358.3327s\n",
      "25679it [1:10:18,  6.17it/s]\titers: 25680, epoch: 1 | loss: 0.2658557\n",
      "\tspeed: 0.1630s/iter; left time: 92644.0848s\n",
      "25799it [1:10:38,  6.14it/s]\titers: 25800, epoch: 1 | loss: 0.1658617\n",
      "\tspeed: 0.1636s/iter; left time: 92949.6512s\n",
      "25919it [1:10:57,  6.12it/s]\titers: 25920, epoch: 1 | loss: 0.2355856\n",
      "\tspeed: 0.1640s/iter; left time: 93202.6633s\n",
      "26039it [1:11:17,  6.12it/s]\titers: 26040, epoch: 1 | loss: 0.1800166\n",
      "\tspeed: 0.1641s/iter; left time: 93196.3002s\n",
      "26159it [1:11:37,  6.19it/s]\titers: 26160, epoch: 1 | loss: 0.5176130\n",
      "\tspeed: 0.1630s/iter; left time: 92600.2558s\n",
      "26279it [1:11:56,  6.15it/s]\titers: 26280, epoch: 1 | loss: 0.0976777\n",
      "\tspeed: 0.1636s/iter; left time: 92897.3577s\n",
      "26399it [1:12:16,  6.15it/s]\titers: 26400, epoch: 1 | loss: 0.2850689\n",
      "\tspeed: 0.1635s/iter; left time: 92792.0947s\n",
      "26519it [1:12:35,  6.13it/s]\titers: 26520, epoch: 1 | loss: 0.1574546\n",
      "\tspeed: 0.1640s/iter; left time: 93066.6048s\n",
      "26639it [1:12:55,  6.09it/s]\titers: 26640, epoch: 1 | loss: 0.7904468\n",
      "\tspeed: 0.1633s/iter; left time: 92638.7305s\n",
      "26759it [1:13:15,  6.17it/s]\titers: 26760, epoch: 1 | loss: 0.7007142\n",
      "\tspeed: 0.1635s/iter; left time: 92737.6683s\n",
      "26879it [1:13:34,  6.16it/s]\titers: 26880, epoch: 1 | loss: 0.3686538\n",
      "\tspeed: 0.1637s/iter; left time: 92841.0311s\n",
      "26999it [1:13:54,  6.14it/s]\titers: 27000, epoch: 1 | loss: 0.2056358\n",
      "\tspeed: 0.1629s/iter; left time: 92377.6120s\n",
      "27119it [1:14:14,  6.19it/s]\titers: 27120, epoch: 1 | loss: 0.7156060\n",
      "\tspeed: 0.1639s/iter; left time: 92936.5376s\n",
      "27239it [1:14:34,  5.93it/s]\titers: 27240, epoch: 1 | loss: 0.4875138\n",
      "\tspeed: 0.1676s/iter; left time: 95010.7949s\n",
      "27359it [1:14:53,  6.17it/s]\titers: 27360, epoch: 1 | loss: 0.1252908\n",
      "\tspeed: 0.1634s/iter; left time: 92591.8593s\n",
      "27479it [1:15:13,  6.20it/s]\titers: 27480, epoch: 1 | loss: 0.1736516\n",
      "\tspeed: 0.1640s/iter; left time: 92918.6270s\n",
      "27599it [1:15:33,  6.14it/s]\titers: 27600, epoch: 1 | loss: 0.4362981\n",
      "\tspeed: 0.1635s/iter; left time: 92640.2552s\n",
      "27719it [1:15:52,  6.16it/s]\titers: 27720, epoch: 1 | loss: 0.4300221\n",
      "\tspeed: 0.1638s/iter; left time: 92747.3435s\n",
      "27839it [1:16:12,  6.16it/s]\titers: 27840, epoch: 1 | loss: 0.1231537\n",
      "\tspeed: 0.1643s/iter; left time: 93052.2648s\n",
      "27959it [1:16:32,  6.10it/s]\titers: 27960, epoch: 1 | loss: 0.4360585\n",
      "\tspeed: 0.1649s/iter; left time: 93328.7153s\n",
      "28079it [1:16:51,  6.13it/s]\titers: 28080, epoch: 1 | loss: 0.5340529\n",
      "\tspeed: 0.1650s/iter; left time: 93368.7003s\n",
      "28199it [1:17:12,  5.56it/s]\titers: 28200, epoch: 1 | loss: 0.3172041\n",
      "\tspeed: 0.1684s/iter; left time: 95282.3988s\n",
      "28319it [1:17:32,  6.18it/s]\titers: 28320, epoch: 1 | loss: 0.2200359\n",
      "\tspeed: 0.1655s/iter; left time: 93659.5058s\n",
      "28439it [1:17:52,  6.20it/s]\titers: 28440, epoch: 1 | loss: 0.4248086\n",
      "\tspeed: 0.1664s/iter; left time: 94102.1652s\n",
      "28559it [1:18:11,  6.12it/s]\titers: 28560, epoch: 1 | loss: 0.5185304\n",
      "\tspeed: 0.1642s/iter; left time: 92852.3072s\n",
      "28679it [1:18:31,  6.16it/s]\titers: 28680, epoch: 1 | loss: 0.2052570\n",
      "\tspeed: 0.1635s/iter; left time: 92438.5007s\n",
      "28799it [1:18:50,  6.09it/s]\titers: 28800, epoch: 1 | loss: 0.0877536\n",
      "\tspeed: 0.1638s/iter; left time: 92577.2681s\n",
      "28919it [1:19:10,  6.09it/s]\titers: 28920, epoch: 1 | loss: 0.2792259\n",
      "\tspeed: 0.1654s/iter; left time: 93486.1794s\n",
      "29039it [1:19:30,  6.13it/s]\titers: 29040, epoch: 1 | loss: 0.1943349\n",
      "\tspeed: 0.1643s/iter; left time: 92848.4827s\n",
      "29159it [1:19:50,  5.76it/s]\titers: 29160, epoch: 1 | loss: 0.1736463\n",
      "\tspeed: 0.1645s/iter; left time: 92908.2659s\n",
      "29279it [1:20:10,  6.11it/s]\titers: 29280, epoch: 1 | loss: 0.6502829\n",
      "\tspeed: 0.1645s/iter; left time: 92902.8706s\n",
      "29399it [1:20:29,  6.15it/s]\titers: 29400, epoch: 1 | loss: 0.1374366\n",
      "\tspeed: 0.1646s/iter; left time: 92930.7095s\n",
      "29519it [1:20:49,  6.09it/s]\titers: 29520, epoch: 1 | loss: 0.5660628\n",
      "\tspeed: 0.1675s/iter; left time: 94574.3547s\n",
      "29639it [1:21:09,  6.12it/s]\titers: 29640, epoch: 1 | loss: 0.1012298\n",
      "\tspeed: 0.1640s/iter; left time: 92545.6902s\n",
      "29705it [1:21:20,  6.09it/s]\n",
      "Epoch: 1 cost time: 4880.637107133865\n",
      "6481it [08:22, 12.91it/s]\n",
      "6457it [08:21, 12.87it/s]\n",
      "Epoch: 1 | Train Loss: 0.3581832 Vali Loss: 0.3902934 Test Loss: 0.4903239 MAE Loss: 0.4724226\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'constant' \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smallest model that gives best performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 22:10:59,618] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 22:11:00,506] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 22:11:00,506] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 22:11:00,507] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 22:11:01,451] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-06 22:11:01,452] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 22:11:02,329] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 22:11:02,331] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 22:11:02,331] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 22:11:02,332] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 22:11:02,332] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 22:11:02,333] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 22:11:02,333] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 22:11:02,333] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 22:11:02,333] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 22:11:02,333] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 22:11:02,645] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 22:11:02,645] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 22:11:02,646] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.79 GB, percent = 16.1%\n",
      "[2024-05-06 22:11:02,752] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 22:11:02,753] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 22:11:02,753] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.79 GB, percent = 16.1%\n",
      "[2024-05-06 22:11:02,753] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 22:11:02,856] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 22:11:02,857] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 22:11:02,857] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.79 GB, percent = 16.1%\n",
      "[2024-05-06 22:11:02,858] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 22:11:02,858] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 22:11:02,858] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 22:11:02,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 22:11:02,858] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 22:11:02,858] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 22:11:02,858] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 22:11:02,858] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 22:11:02,858] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f568c381250>\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 22:11:02,859] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 22:11:02,860] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:06, 15.69it/s]\titers: 100, epoch: 1 | loss: 0.3942876\n",
      "\tspeed: 0.1054s/iter; left time: 9772.0054s\n",
      "199it [00:12, 18.20it/s]\titers: 200, epoch: 1 | loss: 0.3994101\n",
      "\tspeed: 0.0554s/iter; left time: 5129.9822s\n",
      "299it [00:17, 18.94it/s]\titers: 300, epoch: 1 | loss: 0.3717009\n",
      "\tspeed: 0.0534s/iter; left time: 4940.7202s\n",
      "399it [00:22, 18.53it/s]\titers: 400, epoch: 1 | loss: 0.1968883\n",
      "\tspeed: 0.0538s/iter; left time: 4973.9305s\n",
      "499it [00:28, 18.60it/s]\titers: 500, epoch: 1 | loss: 0.2156977\n",
      "\tspeed: 0.0542s/iter; left time: 5001.6908s\n",
      "599it [00:33, 18.92it/s]\titers: 600, epoch: 1 | loss: 0.2496303\n",
      "\tspeed: 0.0535s/iter; left time: 4929.9496s\n",
      "698it [00:39, 18.35it/s]\titers: 700, epoch: 1 | loss: 0.3449880\n",
      "\tspeed: 0.0542s/iter; left time: 4993.6813s\n",
      "798it [00:44, 18.57it/s]\titers: 800, epoch: 1 | loss: 0.3175530\n",
      "\tspeed: 0.0538s/iter; left time: 4946.6540s\n",
      "898it [00:49, 18.52it/s]\titers: 900, epoch: 1 | loss: 0.2782859\n",
      "\tspeed: 0.0538s/iter; left time: 4947.4970s\n",
      "998it [00:55, 18.46it/s]\titers: 1000, epoch: 1 | loss: 0.2441426\n",
      "\tspeed: 0.0541s/iter; left time: 4963.2743s\n",
      "1098it [01:00, 19.17it/s]\titers: 1100, epoch: 1 | loss: 0.2254531\n",
      "\tspeed: 0.0534s/iter; left time: 4897.8265s\n",
      "1198it [01:06, 18.45it/s]\titers: 1200, epoch: 1 | loss: 0.2026713\n",
      "\tspeed: 0.0547s/iter; left time: 5014.9451s\n",
      "1298it [01:11, 19.02it/s]\titers: 1300, epoch: 1 | loss: 0.2031603\n",
      "\tspeed: 0.0530s/iter; left time: 4850.0383s\n",
      "1398it [01:16, 18.54it/s]\titers: 1400, epoch: 1 | loss: 0.3026957\n",
      "\tspeed: 0.0534s/iter; left time: 4878.1801s\n",
      "1498it [01:22, 18.51it/s]\titers: 1500, epoch: 1 | loss: 0.2730368\n",
      "\tspeed: 0.0535s/iter; left time: 4884.7597s\n",
      "1598it [01:27, 18.64it/s]\titers: 1600, epoch: 1 | loss: 0.2466287\n",
      "\tspeed: 0.0537s/iter; left time: 4899.3474s\n",
      "1698it [01:32, 18.98it/s]\titers: 1700, epoch: 1 | loss: 0.3752894\n",
      "\tspeed: 0.0533s/iter; left time: 4857.4505s\n",
      "1798it [01:37, 19.29it/s]\titers: 1800, epoch: 1 | loss: 0.2471694\n",
      "\tspeed: 0.0525s/iter; left time: 4780.2346s\n",
      "1898it [01:43, 18.78it/s]\titers: 1900, epoch: 1 | loss: 0.2876193\n",
      "\tspeed: 0.0527s/iter; left time: 4793.9995s\n",
      "1998it [01:48, 19.13it/s]\titers: 2000, epoch: 1 | loss: 0.2342070\n",
      "\tspeed: 0.0524s/iter; left time: 4756.2601s\n",
      "2098it [01:53, 18.42it/s]\titers: 2100, epoch: 1 | loss: 0.1890361\n",
      "\tspeed: 0.0532s/iter; left time: 4822.2712s\n",
      "2199it [01:59, 18.80it/s]\titers: 2200, epoch: 1 | loss: 0.1267297\n",
      "\tspeed: 0.0533s/iter; left time: 4829.0719s\n",
      "2299it [02:04, 18.71it/s]\titers: 2300, epoch: 1 | loss: 0.2778461\n",
      "\tspeed: 0.0537s/iter; left time: 4857.2757s\n",
      "2398it [02:09, 18.55it/s]\titers: 2400, epoch: 1 | loss: 0.5110396\n",
      "\tspeed: 0.0533s/iter; left time: 4821.7386s\n",
      "2498it [02:15, 18.61it/s]\titers: 2500, epoch: 1 | loss: 0.2351993\n",
      "\tspeed: 0.0539s/iter; left time: 4864.8082s\n",
      "2599it [02:20, 18.92it/s]\titers: 2600, epoch: 1 | loss: 0.1754566\n",
      "\tspeed: 0.0529s/iter; left time: 4770.8070s\n",
      "2699it [02:25, 18.96it/s]\titers: 2700, epoch: 1 | loss: 0.2899435\n",
      "\tspeed: 0.0526s/iter; left time: 4741.8610s\n",
      "2799it [02:31, 19.02it/s]\titers: 2800, epoch: 1 | loss: 0.1126703\n",
      "\tspeed: 0.0528s/iter; left time: 4749.8673s\n",
      "2899it [02:36, 18.41it/s]\titers: 2900, epoch: 1 | loss: 0.3843119\n",
      "\tspeed: 0.0535s/iter; left time: 4811.4395s\n",
      "2999it [02:41, 18.71it/s]\titers: 3000, epoch: 1 | loss: 0.1335167\n",
      "\tspeed: 0.0535s/iter; left time: 4805.8627s\n",
      "3099it [02:47, 19.13it/s]\titers: 3100, epoch: 1 | loss: 0.2361571\n",
      "\tspeed: 0.0531s/iter; left time: 4764.3624s\n",
      "3199it [02:52, 18.68it/s]\titers: 3200, epoch: 1 | loss: 0.5157725\n",
      "\tspeed: 0.0533s/iter; left time: 4775.9163s\n",
      "3297it [02:57, 21.58it/s]\titers: 3300, epoch: 1 | loss: 0.2417431\n",
      "\tspeed: 0.0494s/iter; left time: 4421.8101s\n",
      "3397it [03:02, 21.29it/s]\titers: 3400, epoch: 1 | loss: 0.2637550\n",
      "\tspeed: 0.0478s/iter; left time: 4271.7659s\n",
      "3498it [03:06, 19.54it/s]\titers: 3500, epoch: 1 | loss: 0.3545565\n",
      "\tspeed: 0.0473s/iter; left time: 4226.0635s\n",
      "3598it [03:12, 19.06it/s]\titers: 3600, epoch: 1 | loss: 0.4655709\n",
      "\tspeed: 0.0528s/iter; left time: 4714.8026s\n",
      "3698it [03:17, 21.07it/s]\titers: 3700, epoch: 1 | loss: 0.1617032\n",
      "\tspeed: 0.0498s/iter; left time: 4435.4763s\n",
      "3713it [03:17, 18.77it/s]\n",
      "Epoch: 1 cost time: 197.84745025634766\n",
      "810it [00:22, 35.62it/s]\n",
      "807it [00:22, 36.06it/s]\n",
      "Epoch: 1 | Train Loss: 0.2967043 Vali Loss: 0.3450846 Test Loss: 0.4375376 MAE Loss: 0.4380536\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "98it [00:05, 19.79it/s]\titers: 100, epoch: 2 | loss: 0.2197117\n",
      "\tspeed: 0.5274s/iter; left time: 46948.5676s\n",
      "199it [00:10, 19.93it/s]\titers: 200, epoch: 2 | loss: 0.1640685\n",
      "\tspeed: 0.0501s/iter; left time: 4454.3569s\n",
      "298it [00:15, 19.98it/s]\titers: 300, epoch: 2 | loss: 0.2017543\n",
      "\tspeed: 0.0501s/iter; left time: 4450.9233s\n",
      "398it [00:20, 19.92it/s]\titers: 400, epoch: 2 | loss: 0.3340349\n",
      "\tspeed: 0.0502s/iter; left time: 4449.3437s\n",
      "499it [00:25, 19.87it/s]\titers: 500, epoch: 2 | loss: 0.1512251\n",
      "\tspeed: 0.0503s/iter; left time: 4455.5750s\n",
      "597it [00:30, 20.06it/s]\titers: 600, epoch: 2 | loss: 0.3997647\n",
      "\tspeed: 0.0502s/iter; left time: 4445.9683s\n",
      "699it [00:35, 19.82it/s]\titers: 700, epoch: 2 | loss: 0.1931212\n",
      "\tspeed: 0.0503s/iter; left time: 4451.5322s\n",
      "799it [00:40, 19.79it/s]\titers: 800, epoch: 2 | loss: 0.2555334\n",
      "\tspeed: 0.0508s/iter; left time: 4485.6196s\n",
      "897it [00:45, 19.77it/s]\titers: 900, epoch: 2 | loss: 0.5921543\n",
      "\tspeed: 0.0506s/iter; left time: 4461.4628s\n",
      "998it [00:50, 19.82it/s]\titers: 1000, epoch: 2 | loss: 0.2059401\n",
      "\tspeed: 0.0506s/iter; left time: 4461.8473s\n",
      "1097it [00:55, 20.12it/s]\titers: 1100, epoch: 2 | loss: 0.2109083\n",
      "\tspeed: 0.0499s/iter; left time: 4393.9083s\n",
      "1198it [01:00, 20.03it/s]\titers: 1200, epoch: 2 | loss: 0.2606282\n",
      "\tspeed: 0.0503s/iter; left time: 4419.0830s\n",
      "1299it [01:05, 19.84it/s]\titers: 1300, epoch: 2 | loss: 0.1891504\n",
      "\tspeed: 0.0504s/iter; left time: 4425.2091s\n",
      "1397it [01:10, 20.15it/s]\titers: 1400, epoch: 2 | loss: 0.2627947\n",
      "\tspeed: 0.0508s/iter; left time: 4459.0829s\n",
      "1497it [01:15, 19.49it/s]\titers: 1500, epoch: 2 | loss: 0.1551007\n",
      "\tspeed: 0.0502s/iter; left time: 4393.8666s\n",
      "1599it [01:20, 19.77it/s]\titers: 1600, epoch: 2 | loss: 0.3689701\n",
      "\tspeed: 0.0506s/iter; left time: 4432.1289s\n",
      "1698it [01:25, 19.70it/s]\titers: 1700, epoch: 2 | loss: 0.2555215\n",
      "\tspeed: 0.0511s/iter; left time: 4463.1504s\n",
      "1798it [01:30, 19.73it/s]\titers: 1800, epoch: 2 | loss: 0.3480041\n",
      "\tspeed: 0.0506s/iter; left time: 4420.8331s\n",
      "1898it [01:35, 19.75it/s]\titers: 1900, epoch: 2 | loss: 0.2394767\n",
      "\tspeed: 0.0505s/iter; left time: 4407.3954s\n",
      "1999it [01:41, 19.94it/s]\titers: 2000, epoch: 2 | loss: 0.3806016\n",
      "\tspeed: 0.0499s/iter; left time: 4348.5828s\n",
      "2098it [01:45, 20.00it/s]\titers: 2100, epoch: 2 | loss: 0.3679832\n",
      "\tspeed: 0.0499s/iter; left time: 4345.7244s\n",
      "2197it [01:50, 20.17it/s]\titers: 2200, epoch: 2 | loss: 0.2356257\n",
      "\tspeed: 0.0498s/iter; left time: 4329.5057s\n",
      "2299it [01:56, 19.96it/s]\titers: 2300, epoch: 2 | loss: 0.3586487\n",
      "\tspeed: 0.0500s/iter; left time: 4341.5669s\n",
      "2397it [02:00, 20.06it/s]\titers: 2400, epoch: 2 | loss: 0.2642769\n",
      "\tspeed: 0.0503s/iter; left time: 4361.4542s\n",
      "2498it [02:06, 19.81it/s]\titers: 2500, epoch: 2 | loss: 0.1932698\n",
      "\tspeed: 0.0507s/iter; left time: 4390.6360s\n",
      "2599it [02:11, 19.85it/s]\titers: 2600, epoch: 2 | loss: 0.2120844\n",
      "\tspeed: 0.0505s/iter; left time: 4372.3154s\n",
      "2697it [02:16, 20.26it/s]\titers: 2700, epoch: 2 | loss: 0.2970347\n",
      "\tspeed: 0.0500s/iter; left time: 4323.2533s\n",
      "2798it [02:21, 19.95it/s]\titers: 2800, epoch: 2 | loss: 0.3204611\n",
      "\tspeed: 0.0502s/iter; left time: 4334.4360s\n",
      "2899it [02:26, 19.88it/s]\titers: 2900, epoch: 2 | loss: 0.2854888\n",
      "\tspeed: 0.0501s/iter; left time: 4321.2302s\n",
      "2999it [02:31, 20.10it/s]\titers: 3000, epoch: 2 | loss: 0.2710947\n",
      "\tspeed: 0.0501s/iter; left time: 4316.7960s\n",
      "3098it [02:36, 20.10it/s]\titers: 3100, epoch: 2 | loss: 0.1801856\n",
      "\tspeed: 0.0501s/iter; left time: 4312.5101s\n",
      "3198it [02:41, 19.91it/s]\titers: 3200, epoch: 2 | loss: 0.2295305\n",
      "\tspeed: 0.0500s/iter; left time: 4294.6443s\n",
      "3298it [02:46, 19.86it/s]\titers: 3300, epoch: 2 | loss: 0.2097574\n",
      "\tspeed: 0.0504s/iter; left time: 4321.2151s\n",
      "3399it [02:51, 19.89it/s]\titers: 3400, epoch: 2 | loss: 0.2456291\n",
      "\tspeed: 0.0501s/iter; left time: 4291.7478s\n",
      "3497it [02:56, 19.85it/s]\titers: 3500, epoch: 2 | loss: 0.1793177\n",
      "\tspeed: 0.0501s/iter; left time: 4293.4467s\n",
      "3599it [03:01, 19.90it/s]\titers: 3600, epoch: 2 | loss: 0.2109464\n",
      "\tspeed: 0.0504s/iter; left time: 4309.5905s\n",
      "3698it [03:06, 19.85it/s]\titers: 3700, epoch: 2 | loss: 0.3231293\n",
      "\tspeed: 0.0499s/iter; left time: 4265.1823s\n",
      "3713it [03:07, 19.85it/s]\n",
      "Epoch: 2 cost time: 187.07316780090332\n",
      "810it [00:19, 41.47it/s]\n",
      "807it [00:19, 41.33it/s]\n",
      "Epoch: 2 | Train Loss: 0.2500637 Vali Loss: 0.2879424 Test Loss: 0.3533074 MAE Loss: 0.3667313\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:05, 20.09it/s]\titers: 100, epoch: 3 | loss: 0.2473639\n",
      "\tspeed: 0.4661s/iter; left time: 39757.0717s\n",
      "199it [00:10, 19.85it/s]\titers: 200, epoch: 3 | loss: 0.1576733\n",
      "\tspeed: 0.0504s/iter; left time: 4293.6664s\n",
      "299it [00:15, 19.62it/s]\titers: 300, epoch: 3 | loss: 0.3959455\n",
      "\tspeed: 0.0503s/iter; left time: 4284.6686s\n",
      "399it [00:20, 19.86it/s]\titers: 400, epoch: 3 | loss: 0.2376025\n",
      "\tspeed: 0.0503s/iter; left time: 4276.7410s\n",
      "498it [00:25, 19.72it/s]\titers: 500, epoch: 3 | loss: 0.1658383\n",
      "\tspeed: 0.0502s/iter; left time: 4265.6694s\n",
      "598it [00:30, 19.83it/s]\titers: 600, epoch: 3 | loss: 0.2081687\n",
      "\tspeed: 0.0500s/iter; left time: 4243.0305s\n",
      "699it [00:35, 20.05it/s]\titers: 700, epoch: 3 | loss: 0.1871508\n",
      "\tspeed: 0.0500s/iter; left time: 4234.0079s\n",
      "799it [00:40, 19.58it/s]\titers: 800, epoch: 3 | loss: 0.1926102\n",
      "\tspeed: 0.0510s/iter; left time: 4311.3156s\n",
      "899it [00:45, 19.78it/s]\titers: 900, epoch: 3 | loss: 0.1308671\n",
      "\tspeed: 0.0518s/iter; left time: 4375.4896s\n",
      "999it [00:50, 19.73it/s]\titers: 1000, epoch: 3 | loss: 0.1768520\n",
      "\tspeed: 0.0507s/iter; left time: 4274.8840s\n",
      "1099it [00:55, 19.92it/s]\titers: 1100, epoch: 3 | loss: 0.1837931\n",
      "\tspeed: 0.0505s/iter; left time: 4257.4711s\n",
      "1197it [01:00, 19.87it/s]\titers: 1200, epoch: 3 | loss: 0.1257080\n",
      "\tspeed: 0.0501s/iter; left time: 4219.0289s\n",
      "1299it [01:05, 19.66it/s]\titers: 1300, epoch: 3 | loss: 0.2019659\n",
      "\tspeed: 0.0501s/iter; left time: 4213.1802s\n",
      "1399it [01:10, 20.07it/s]\titers: 1400, epoch: 3 | loss: 0.2295731\n",
      "\tspeed: 0.0504s/iter; left time: 4237.6388s\n",
      "1499it [01:15, 19.66it/s]\titers: 1500, epoch: 3 | loss: 0.3523498\n",
      "\tspeed: 0.0503s/iter; left time: 4223.6267s\n",
      "1598it [01:20, 19.89it/s]\titers: 1600, epoch: 3 | loss: 0.2367280\n",
      "\tspeed: 0.0502s/iter; left time: 4210.5445s\n",
      "1699it [01:25, 19.85it/s]\titers: 1700, epoch: 3 | loss: 0.1466590\n",
      "\tspeed: 0.0502s/iter; left time: 4203.5392s\n",
      "1798it [01:30, 19.95it/s]\titers: 1800, epoch: 3 | loss: 0.1639604\n",
      "\tspeed: 0.0502s/iter; left time: 4196.1312s\n",
      "1899it [01:35, 20.10it/s]\titers: 1900, epoch: 3 | loss: 0.3203186\n",
      "\tspeed: 0.0501s/iter; left time: 4184.7171s\n",
      "1997it [01:40, 19.83it/s]\titers: 2000, epoch: 3 | loss: 0.3613437\n",
      "\tspeed: 0.0503s/iter; left time: 4196.6624s\n",
      "2099it [01:46, 19.95it/s]\titers: 2100, epoch: 3 | loss: 0.1550383\n",
      "\tspeed: 0.0502s/iter; left time: 4181.2151s\n",
      "2198it [01:50, 19.86it/s]\titers: 2200, epoch: 3 | loss: 0.2156822\n",
      "\tspeed: 0.0503s/iter; left time: 4185.7854s\n",
      "2298it [01:56, 19.95it/s]\titers: 2300, epoch: 3 | loss: 0.1425221\n",
      "\tspeed: 0.0503s/iter; left time: 4183.5287s\n",
      "2398it [02:01, 19.79it/s]\titers: 2400, epoch: 3 | loss: 0.4217362\n",
      "\tspeed: 0.0502s/iter; left time: 4168.6149s\n",
      "2498it [02:06, 19.86it/s]\titers: 2500, epoch: 3 | loss: 0.1353447\n",
      "\tspeed: 0.0504s/iter; left time: 4181.9538s\n",
      "2599it [02:11, 19.89it/s]\titers: 2600, epoch: 3 | loss: 0.3011146\n",
      "\tspeed: 0.0505s/iter; left time: 4182.6026s\n",
      "2697it [02:16, 20.06it/s]\titers: 2700, epoch: 3 | loss: 0.1936860\n",
      "\tspeed: 0.0502s/iter; left time: 4154.3000s\n",
      "2799it [02:21, 20.03it/s]\titers: 2800, epoch: 3 | loss: 0.1388123\n",
      "\tspeed: 0.0503s/iter; left time: 4157.5166s\n",
      "2898it [02:26, 19.76it/s]\titers: 2900, epoch: 3 | loss: 0.2562187\n",
      "\tspeed: 0.0503s/iter; left time: 4153.4565s\n",
      "2998it [02:31, 19.71it/s]\titers: 3000, epoch: 3 | loss: 0.1984266\n",
      "\tspeed: 0.0506s/iter; left time: 4169.4150s\n",
      "3099it [02:36, 19.78it/s]\titers: 3100, epoch: 3 | loss: 0.2085183\n",
      "\tspeed: 0.0506s/iter; left time: 4162.8080s\n",
      "3199it [02:41, 19.89it/s]\titers: 3200, epoch: 3 | loss: 0.2738993\n",
      "\tspeed: 0.0503s/iter; left time: 4131.6754s\n",
      "3298it [02:46, 19.58it/s]\titers: 3300, epoch: 3 | loss: 0.2717395\n",
      "\tspeed: 0.0511s/iter; left time: 4191.4875s\n",
      "3398it [02:51, 19.81it/s]\titers: 3400, epoch: 3 | loss: 0.1884477\n",
      "\tspeed: 0.0505s/iter; left time: 4140.1137s\n",
      "3499it [02:56, 19.68it/s]\titers: 3500, epoch: 3 | loss: 0.2464365\n",
      "\tspeed: 0.0507s/iter; left time: 4155.4173s\n",
      "3598it [03:01, 19.86it/s]\titers: 3600, epoch: 3 | loss: 0.3297533\n",
      "\tspeed: 0.0508s/iter; left time: 4157.1113s\n",
      "3699it [03:06, 19.83it/s]\titers: 3700, epoch: 3 | loss: 0.1590366\n",
      "\tspeed: 0.0505s/iter; left time: 4129.8589s\n",
      "3713it [03:07, 19.79it/s]\n",
      "Epoch: 3 cost time: 187.5893304347992\n",
      "810it [00:19, 41.16it/s]\n",
      "807it [00:19, 40.69it/s]\n",
      "Epoch: 3 | Train Loss: 0.2323816 Vali Loss: 0.2759690 Test Loss: 0.3441534 MAE Loss: 0.3534792\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:05, 19.55it/s]\titers: 100, epoch: 4 | loss: 0.2218226\n",
      "\tspeed: 0.4750s/iter; left time: 38756.3226s\n",
      "199it [00:10, 19.83it/s]\titers: 200, epoch: 4 | loss: 0.1451505\n",
      "\tspeed: 0.0505s/iter; left time: 4118.3886s\n",
      "298it [00:15, 19.76it/s]\titers: 300, epoch: 4 | loss: 0.1655369\n",
      "\tspeed: 0.0504s/iter; left time: 4101.3448s\n",
      "398it [00:20, 19.85it/s]\titers: 400, epoch: 4 | loss: 0.3399979\n",
      "\tspeed: 0.0503s/iter; left time: 4089.7559s\n",
      "498it [00:25, 19.85it/s]\titers: 500, epoch: 4 | loss: 0.4839240\n",
      "\tspeed: 0.0505s/iter; left time: 4102.2662s\n",
      "598it [00:30, 19.81it/s]\titers: 600, epoch: 4 | loss: 0.1565793\n",
      "\tspeed: 0.0506s/iter; left time: 4100.8684s\n",
      "698it [00:35, 19.53it/s]\titers: 700, epoch: 4 | loss: 0.2619865\n",
      "\tspeed: 0.0505s/iter; left time: 4093.2040s\n",
      "798it [00:40, 19.85it/s]\titers: 800, epoch: 4 | loss: 0.2729763\n",
      "\tspeed: 0.0504s/iter; left time: 4075.9621s\n",
      "899it [00:45, 19.82it/s]\titers: 900, epoch: 4 | loss: 0.1808550\n",
      "\tspeed: 0.0503s/iter; left time: 4065.6520s\n",
      "998it [00:50, 19.79it/s]\titers: 1000, epoch: 4 | loss: 0.2723995\n",
      "\tspeed: 0.0503s/iter; left time: 4061.5223s\n",
      "1099it [00:55, 19.83it/s]\titers: 1100, epoch: 4 | loss: 0.1750422\n",
      "\tspeed: 0.0501s/iter; left time: 4040.7038s\n",
      "1199it [01:00, 19.94it/s]\titers: 1200, epoch: 4 | loss: 0.3277885\n",
      "\tspeed: 0.0502s/iter; left time: 4042.8622s\n",
      "1297it [01:05, 19.80it/s]\titers: 1300, epoch: 4 | loss: 0.1605314\n",
      "\tspeed: 0.0502s/iter; left time: 4038.6049s\n",
      "1399it [01:10, 19.83it/s]\titers: 1400, epoch: 4 | loss: 0.3425817\n",
      "\tspeed: 0.0505s/iter; left time: 4054.8298s\n",
      "1498it [01:15, 19.85it/s]\titers: 1500, epoch: 4 | loss: 0.2282176\n",
      "\tspeed: 0.0502s/iter; left time: 4022.0148s\n",
      "1598it [01:20, 19.81it/s]\titers: 1600, epoch: 4 | loss: 0.1833038\n",
      "\tspeed: 0.0504s/iter; left time: 4033.4070s\n",
      "1698it [01:25, 19.89it/s]\titers: 1700, epoch: 4 | loss: 0.2559721\n",
      "\tspeed: 0.0502s/iter; left time: 4017.8723s\n",
      "1797it [01:30, 19.89it/s]\titers: 1800, epoch: 4 | loss: 0.1211643\n",
      "\tspeed: 0.0501s/iter; left time: 4005.8116s\n",
      "1898it [01:35, 19.77it/s]\titers: 1900, epoch: 4 | loss: 0.2990504\n",
      "\tspeed: 0.0501s/iter; left time: 4001.1216s\n",
      "1998it [01:40, 19.92it/s]\titers: 2000, epoch: 4 | loss: 0.1272868\n",
      "\tspeed: 0.0503s/iter; left time: 4009.3422s\n",
      "2098it [01:45, 19.99it/s]\titers: 2100, epoch: 4 | loss: 0.2672447\n",
      "\tspeed: 0.0502s/iter; left time: 3991.7775s\n",
      "2197it [01:50, 20.08it/s]\titers: 2200, epoch: 4 | loss: 0.2433291\n",
      "\tspeed: 0.0506s/iter; left time: 4018.6561s\n",
      "2299it [01:56, 19.91it/s]\titers: 2300, epoch: 4 | loss: 0.2312996\n",
      "\tspeed: 0.0502s/iter; left time: 3989.0282s\n",
      "2398it [02:00, 19.92it/s]\titers: 2400, epoch: 4 | loss: 0.2488324\n",
      "\tspeed: 0.0502s/iter; left time: 3976.2796s\n",
      "2497it [02:05, 19.93it/s]\titers: 2500, epoch: 4 | loss: 0.2152109\n",
      "\tspeed: 0.0502s/iter; left time: 3976.9160s\n",
      "2598it [02:11, 19.83it/s]\titers: 2600, epoch: 4 | loss: 0.2241950\n",
      "\tspeed: 0.0504s/iter; left time: 3986.2242s\n",
      "2698it [02:16, 19.76it/s]\titers: 2700, epoch: 4 | loss: 0.2906448\n",
      "\tspeed: 0.0502s/iter; left time: 3967.7065s\n",
      "2798it [02:21, 20.12it/s]\titers: 2800, epoch: 4 | loss: 0.2479218\n",
      "\tspeed: 0.0504s/iter; left time: 3974.9166s\n",
      "2899it [02:26, 19.82it/s]\titers: 2900, epoch: 4 | loss: 0.1834983\n",
      "\tspeed: 0.0503s/iter; left time: 3966.8382s\n",
      "2997it [02:31, 20.06it/s]\titers: 3000, epoch: 4 | loss: 0.1718313\n",
      "\tspeed: 0.0502s/iter; left time: 3949.3186s\n",
      "3099it [02:36, 19.73it/s]\titers: 3100, epoch: 4 | loss: 0.2510684\n",
      "\tspeed: 0.0504s/iter; left time: 3963.7455s\n",
      "3198it [02:41, 19.91it/s]\titers: 3200, epoch: 4 | loss: 0.1623612\n",
      "\tspeed: 0.0503s/iter; left time: 3948.6098s\n",
      "3298it [02:46, 19.75it/s]\titers: 3300, epoch: 4 | loss: 0.2382050\n",
      "\tspeed: 0.0503s/iter; left time: 3943.0879s\n",
      "3399it [02:51, 19.79it/s]\titers: 3400, epoch: 4 | loss: 0.3670778\n",
      "\tspeed: 0.0504s/iter; left time: 3943.5063s\n",
      "3499it [02:56, 20.15it/s]\titers: 3500, epoch: 4 | loss: 0.1111439\n",
      "\tspeed: 0.0502s/iter; left time: 3922.6451s\n",
      "3598it [03:01, 19.78it/s]\titers: 3600, epoch: 4 | loss: 0.2204922\n",
      "\tspeed: 0.0504s/iter; left time: 3936.0281s\n",
      "3698it [03:06, 19.85it/s]\titers: 3700, epoch: 4 | loss: 0.0911898\n",
      "\tspeed: 0.0506s/iter; left time: 3942.6047s\n",
      "3713it [03:07, 19.83it/s]\n",
      "Epoch: 4 cost time: 187.24435186386108\n",
      "810it [00:19, 41.68it/s]\n",
      "807it [00:19, 41.16it/s]\n",
      "Epoch: 4 | Train Loss: 0.2238862 Vali Loss: 0.2754466 Test Loss: 0.3416765 MAE Loss: 0.3540409\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:05, 19.82it/s]\titers: 100, epoch: 5 | loss: 0.4100694\n",
      "\tspeed: 0.4650s/iter; left time: 36213.8901s\n",
      "198it [00:10, 19.83it/s]\titers: 200, epoch: 5 | loss: 0.1650324\n",
      "\tspeed: 0.0505s/iter; left time: 3927.3207s\n",
      "299it [00:15, 19.84it/s]\titers: 300, epoch: 5 | loss: 0.1208172\n",
      "\tspeed: 0.0506s/iter; left time: 3927.2341s\n",
      "399it [00:20, 19.89it/s]\titers: 400, epoch: 5 | loss: 0.2393042\n",
      "\tspeed: 0.0504s/iter; left time: 3907.7195s\n",
      "499it [00:25, 19.84it/s]\titers: 500, epoch: 5 | loss: 0.1506477\n",
      "\tspeed: 0.0503s/iter; left time: 3898.3196s\n",
      "599it [00:30, 19.45it/s]\titers: 600, epoch: 5 | loss: 0.3635897\n",
      "\tspeed: 0.0487s/iter; left time: 3767.6169s\n",
      "698it [00:35, 19.73it/s]\titers: 700, epoch: 5 | loss: 0.3162522\n",
      "\tspeed: 0.0508s/iter; left time: 3922.7536s\n",
      "799it [00:40, 19.73it/s]\titers: 800, epoch: 5 | loss: 0.1363403\n",
      "\tspeed: 0.0504s/iter; left time: 3891.4622s\n",
      "899it [00:45, 20.95it/s]\titers: 900, epoch: 5 | loss: 0.2240802\n",
      "\tspeed: 0.0505s/iter; left time: 3894.6416s\n",
      "998it [00:50, 21.40it/s]\titers: 1000, epoch: 5 | loss: 0.2880755\n",
      "\tspeed: 0.0468s/iter; left time: 3601.1476s\n",
      "1099it [00:55, 19.84it/s]\titers: 1100, epoch: 5 | loss: 0.3638848\n",
      "\tspeed: 0.0508s/iter; left time: 3907.1060s\n",
      "1199it [01:00, 19.83it/s]\titers: 1200, epoch: 5 | loss: 0.3250277\n",
      "\tspeed: 0.0505s/iter; left time: 3879.9075s\n",
      "1299it [01:05, 19.74it/s]\titers: 1300, epoch: 5 | loss: 0.1800656\n",
      "\tspeed: 0.0505s/iter; left time: 3874.3441s\n",
      "1399it [01:10, 23.22it/s]\titers: 1400, epoch: 5 | loss: 0.2219544\n",
      "\tspeed: 0.0482s/iter; left time: 3693.0575s\n",
      "1499it [01:14, 19.78it/s]\titers: 1500, epoch: 5 | loss: 0.1710520\n",
      "\tspeed: 0.0476s/iter; left time: 3638.1613s\n",
      "1599it [01:20, 19.79it/s]\titers: 1600, epoch: 5 | loss: 0.1682511\n",
      "\tspeed: 0.0506s/iter; left time: 3864.3610s\n",
      "1698it [01:25, 18.01it/s]\titers: 1700, epoch: 5 | loss: 0.1707610\n",
      "\tspeed: 0.0518s/iter; left time: 3947.5123s\n",
      "1799it [01:30, 19.64it/s]\titers: 1800, epoch: 5 | loss: 0.1605371\n",
      "\tspeed: 0.0501s/iter; left time: 3817.7084s\n",
      "1898it [01:35, 19.81it/s]\titers: 1900, epoch: 5 | loss: 0.1225296\n",
      "\tspeed: 0.0505s/iter; left time: 3840.8867s\n",
      "1998it [01:40, 21.05it/s]\titers: 2000, epoch: 5 | loss: 0.5063264\n",
      "\tspeed: 0.0482s/iter; left time: 3659.6499s\n",
      "2099it [01:45, 19.77it/s]\titers: 2100, epoch: 5 | loss: 0.3247736\n",
      "\tspeed: 0.0522s/iter; left time: 3957.0403s\n",
      "2198it [01:50, 20.54it/s]\titers: 2200, epoch: 5 | loss: 0.3186542\n",
      "\tspeed: 0.0505s/iter; left time: 3822.9631s\n",
      "2298it [01:55, 19.65it/s]\titers: 2300, epoch: 5 | loss: 0.2596578\n",
      "\tspeed: 0.0507s/iter; left time: 3834.8412s\n",
      "2398it [02:00, 22.23it/s]\titers: 2400, epoch: 5 | loss: 0.3873081\n",
      "\tspeed: 0.0497s/iter; left time: 3757.3711s\n",
      "2497it [02:04, 20.93it/s]\titers: 2500, epoch: 5 | loss: 0.1845836\n",
      "\tspeed: 0.0437s/iter; left time: 3298.6450s\n",
      "2599it [02:09, 19.77it/s]\titers: 2600, epoch: 5 | loss: 0.2189395\n",
      "\tspeed: 0.0500s/iter; left time: 3770.9912s\n",
      "2699it [02:14, 19.78it/s]\titers: 2700, epoch: 5 | loss: 0.1892806\n",
      "\tspeed: 0.0506s/iter; left time: 3807.5788s\n",
      "2798it [02:19, 19.83it/s]\titers: 2800, epoch: 5 | loss: 0.1543860\n",
      "\tspeed: 0.0516s/iter; left time: 3882.3189s\n",
      "2899it [02:25, 19.78it/s]\titers: 2900, epoch: 5 | loss: 0.2089998\n",
      "\tspeed: 0.0504s/iter; left time: 3786.9278s\n",
      "2998it [02:30, 19.72it/s]\titers: 3000, epoch: 5 | loss: 0.1011225\n",
      "\tspeed: 0.0507s/iter; left time: 3800.5066s\n",
      "3097it [02:35, 20.11it/s]\titers: 3100, epoch: 5 | loss: 0.1472476\n",
      "\tspeed: 0.0537s/iter; left time: 4017.0819s\n",
      "3199it [02:40, 19.99it/s]\titers: 3200, epoch: 5 | loss: 0.1792503\n",
      "\tspeed: 0.0503s/iter; left time: 3764.6585s\n",
      "3299it [02:45, 19.80it/s]\titers: 3300, epoch: 5 | loss: 0.2529353\n",
      "\tspeed: 0.0506s/iter; left time: 3776.2830s\n",
      "3399it [02:50, 19.79it/s]\titers: 3400, epoch: 5 | loss: 0.2313991\n",
      "\tspeed: 0.0534s/iter; left time: 3979.9192s\n",
      "3499it [02:55, 19.77it/s]\titers: 3500, epoch: 5 | loss: 0.2082111\n",
      "\tspeed: 0.0505s/iter; left time: 3764.4363s\n",
      "3599it [03:01, 19.73it/s]\titers: 3600, epoch: 5 | loss: 0.3440576\n",
      "\tspeed: 0.0506s/iter; left time: 3761.7740s\n",
      "3698it [03:06, 13.84it/s]\titers: 3700, epoch: 5 | loss: 0.1638912\n",
      "\tspeed: 0.0543s/iter; left time: 4031.2214s\n",
      "3713it [03:07, 19.82it/s]\n",
      "Epoch: 5 cost time: 187.3035671710968\n",
      "810it [00:19, 40.62it/s]\n",
      "807it [00:19, 40.53it/s]\n",
      "Epoch: 5 | Train Loss: 0.2195765 Vali Loss: 0.2758530 Test Loss: 0.3404929 MAE Loss: 0.3509954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "97it [00:04, 23.11it/s]\titers: 100, epoch: 6 | loss: 0.2904227\n",
      "\tspeed: 0.4543s/iter; left time: 33688.2561s\n",
      "199it [00:08, 20.67it/s]\titers: 200, epoch: 6 | loss: 0.2438291\n",
      "\tspeed: 0.0441s/iter; left time: 3262.5595s\n",
      "298it [00:13, 20.32it/s]\titers: 300, epoch: 6 | loss: 0.1421250\n",
      "\tspeed: 0.0449s/iter; left time: 3318.5077s\n",
      "399it [00:18, 19.81it/s]\titers: 400, epoch: 6 | loss: 0.2426186\n",
      "\tspeed: 0.0506s/iter; left time: 3733.9376s\n",
      "498it [00:23, 19.77it/s]\titers: 500, epoch: 6 | loss: 0.1628549\n",
      "\tspeed: 0.0505s/iter; left time: 3726.1117s\n",
      "599it [00:28, 19.72it/s]\titers: 600, epoch: 6 | loss: 0.2189313\n",
      "\tspeed: 0.0528s/iter; left time: 3886.9394s\n",
      "699it [00:33, 19.89it/s]\titers: 700, epoch: 6 | loss: 0.1237232\n",
      "\tspeed: 0.0505s/iter; left time: 3716.6460s\n",
      "798it [00:38, 19.84it/s]\titers: 800, epoch: 6 | loss: 0.1923674\n",
      "\tspeed: 0.0508s/iter; left time: 3732.4924s\n",
      "899it [00:43, 22.78it/s]\titers: 900, epoch: 6 | loss: 0.1865872\n",
      "\tspeed: 0.0459s/iter; left time: 3367.5948s\n",
      "998it [00:47, 23.22it/s]\titers: 1000, epoch: 6 | loss: 0.2622226\n",
      "\tspeed: 0.0431s/iter; left time: 3161.0007s\n",
      "1097it [00:52, 23.42it/s]\titers: 1100, epoch: 6 | loss: 0.1733276\n",
      "\tspeed: 0.0429s/iter; left time: 3138.1359s\n",
      "1199it [00:56, 23.05it/s]\titers: 1200, epoch: 6 | loss: 0.2090889\n",
      "\tspeed: 0.0434s/iter; left time: 3167.7579s\n",
      "1298it [01:01, 19.98it/s]\titers: 1300, epoch: 6 | loss: 0.1731649\n",
      "\tspeed: 0.0500s/iter; left time: 3645.0396s\n",
      "1398it [01:06, 19.76it/s]\titers: 1400, epoch: 6 | loss: 0.2497009\n",
      "\tspeed: 0.0505s/iter; left time: 3677.9996s\n",
      "1498it [01:11, 19.80it/s]\titers: 1500, epoch: 6 | loss: 0.2466545\n",
      "\tspeed: 0.0506s/iter; left time: 3678.2523s\n",
      "1598it [01:17, 19.72it/s]\titers: 1600, epoch: 6 | loss: 0.3589459\n",
      "\tspeed: 0.0547s/iter; left time: 3973.0897s\n",
      "1699it [01:22, 19.84it/s]\titers: 1700, epoch: 6 | loss: 0.1978748\n",
      "\tspeed: 0.0503s/iter; left time: 3652.5200s\n",
      "1799it [01:27, 19.78it/s]\titers: 1800, epoch: 6 | loss: 0.2425724\n",
      "\tspeed: 0.0503s/iter; left time: 3648.3257s\n",
      "1899it [01:32, 19.55it/s]\titers: 1900, epoch: 6 | loss: 0.1946072\n",
      "\tspeed: 0.0550s/iter; left time: 3983.2021s\n",
      "1999it [01:37, 19.82it/s]\titers: 2000, epoch: 6 | loss: 0.2744192\n",
      "\tspeed: 0.0503s/iter; left time: 3634.5946s\n",
      "2098it [01:42, 19.83it/s]\titers: 2100, epoch: 6 | loss: 0.1613900\n",
      "\tspeed: 0.0506s/iter; left time: 3650.1053s\n",
      "2199it [01:47, 19.81it/s]\titers: 2200, epoch: 6 | loss: 0.1453171\n",
      "\tspeed: 0.0506s/iter; left time: 3649.2727s\n",
      "2299it [01:52, 19.77it/s]\titers: 2300, epoch: 6 | loss: 0.1559437\n",
      "\tspeed: 0.0512s/iter; left time: 3682.7993s\n",
      "2399it [01:57, 19.79it/s]\titers: 2400, epoch: 6 | loss: 0.1607989\n",
      "\tspeed: 0.0505s/iter; left time: 3632.5505s\n",
      "2499it [02:03, 21.03it/s]\titers: 2500, epoch: 6 | loss: 0.2473557\n",
      "\tspeed: 0.0502s/iter; left time: 3605.0688s\n",
      "2599it [02:08, 19.83it/s]\titers: 2600, epoch: 6 | loss: 0.2420880\n",
      "\tspeed: 0.0515s/iter; left time: 3687.5381s\n",
      "2698it [02:13, 19.76it/s]\titers: 2700, epoch: 6 | loss: 0.1663619\n",
      "\tspeed: 0.0506s/iter; left time: 3617.9882s\n",
      "2799it [02:18, 19.84it/s]\titers: 2800, epoch: 6 | loss: 0.1409341\n",
      "\tspeed: 0.0505s/iter; left time: 3611.6261s\n",
      "2898it [02:23, 18.79it/s]\titers: 2900, epoch: 6 | loss: 0.1424564\n",
      "\tspeed: 0.0509s/iter; left time: 3635.8183s\n",
      "2999it [02:28, 19.96it/s]\titers: 3000, epoch: 6 | loss: 0.2091171\n",
      "\tspeed: 0.0497s/iter; left time: 3539.1939s\n",
      "3097it [02:33, 20.04it/s]\titers: 3100, epoch: 6 | loss: 0.2191590\n",
      "\tspeed: 0.0505s/iter; left time: 3590.9646s\n",
      "3197it [02:38, 19.67it/s]\titers: 3200, epoch: 6 | loss: 0.2721981\n",
      "\tspeed: 0.0507s/iter; left time: 3603.6494s\n",
      "3298it [02:43, 19.78it/s]\titers: 3300, epoch: 6 | loss: 0.2406085\n",
      "\tspeed: 0.0520s/iter; left time: 3691.7239s\n",
      "3398it [02:48, 19.69it/s]\titers: 3400, epoch: 6 | loss: 0.2796800\n",
      "\tspeed: 0.0506s/iter; left time: 3582.3982s\n",
      "3498it [02:53, 19.71it/s]\titers: 3500, epoch: 6 | loss: 0.1666376\n",
      "\tspeed: 0.0514s/iter; left time: 3635.4326s\n",
      "3598it [02:58, 19.79it/s]\titers: 3600, epoch: 6 | loss: 0.2090385\n",
      "\tspeed: 0.0517s/iter; left time: 3651.7372s\n",
      "3699it [03:04, 19.77it/s]\titers: 3700, epoch: 6 | loss: 0.1343992\n",
      "\tspeed: 0.0506s/iter; left time: 3567.2253s\n",
      "3713it [03:04, 20.09it/s]\n",
      "Epoch: 6 cost time: 184.82862305641174\n",
      "810it [00:19, 40.78it/s]\n",
      "807it [00:20, 39.46it/s]\n",
      "Epoch: 6 | Train Loss: 0.2166366 Vali Loss: 0.2754931 Test Loss: 0.3406104 MAE Loss: 0.3513093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:05, 19.78it/s]\titers: 100, epoch: 7 | loss: 0.2227399\n",
      "\tspeed: 0.4664s/iter; left time: 32859.6269s\n",
      "198it [00:10, 19.80it/s]\titers: 200, epoch: 7 | loss: 0.1674669\n",
      "\tspeed: 0.0506s/iter; left time: 3556.9990s\n",
      "298it [00:15, 19.75it/s]\titers: 300, epoch: 7 | loss: 0.1188815\n",
      "\tspeed: 0.0506s/iter; left time: 3554.4699s\n",
      "398it [00:20, 19.89it/s]\titers: 400, epoch: 7 | loss: 0.2471013\n",
      "\tspeed: 0.0519s/iter; left time: 3637.5843s\n",
      "499it [00:25, 19.76it/s]\titers: 500, epoch: 7 | loss: 0.2498300\n",
      "\tspeed: 0.0506s/iter; left time: 3541.7799s\n",
      "599it [00:30, 19.73it/s]\titers: 600, epoch: 7 | loss: 0.1905210\n",
      "\tspeed: 0.0502s/iter; left time: 3508.6716s\n",
      "698it [00:36, 18.99it/s]\titers: 700, epoch: 7 | loss: 0.2770319\n",
      "\tspeed: 0.0535s/iter; left time: 3737.8416s\n",
      "799it [00:41, 19.84it/s]\titers: 800, epoch: 7 | loss: 0.2286637\n",
      "\tspeed: 0.0506s/iter; left time: 3526.2103s\n",
      "898it [00:46, 19.76it/s]\titers: 900, epoch: 7 | loss: 0.1383742\n",
      "\tspeed: 0.0506s/iter; left time: 3522.1964s\n",
      "998it [00:51, 19.75it/s]\titers: 1000, epoch: 7 | loss: 0.2592935\n",
      "\tspeed: 0.0499s/iter; left time: 3468.9709s\n",
      "1097it [00:56, 22.75it/s]\titers: 1100, epoch: 7 | loss: 0.1372976\n",
      "\tspeed: 0.0516s/iter; left time: 3585.0468s\n",
      "1199it [01:01, 19.74it/s]\titers: 1200, epoch: 7 | loss: 0.1818882\n",
      "\tspeed: 0.0495s/iter; left time: 3432.1166s\n",
      "1298it [01:06, 19.70it/s]\titers: 1300, epoch: 7 | loss: 0.1965551\n",
      "\tspeed: 0.0506s/iter; left time: 3504.9417s\n",
      "1398it [01:11, 19.42it/s]\titers: 1400, epoch: 7 | loss: 0.2705731\n",
      "\tspeed: 0.0508s/iter; left time: 3513.4479s\n",
      "1498it [01:17, 19.94it/s]\titers: 1500, epoch: 7 | loss: 0.2082580\n",
      "\tspeed: 0.0554s/iter; left time: 3825.7083s\n",
      "1597it [01:22, 18.24it/s]\titers: 1600, epoch: 7 | loss: 0.1210956\n",
      "\tspeed: 0.0523s/iter; left time: 3605.2775s\n",
      "1699it [01:27, 19.71it/s]\titers: 1700, epoch: 7 | loss: 0.2108624\n",
      "\tspeed: 0.0506s/iter; left time: 3481.4037s\n",
      "1798it [01:32, 19.79it/s]\titers: 1800, epoch: 7 | loss: 0.2548808\n",
      "\tspeed: 0.0506s/iter; left time: 3479.9874s\n",
      "1898it [01:37, 19.72it/s]\titers: 1900, epoch: 7 | loss: 0.2268914\n",
      "\tspeed: 0.0534s/iter; left time: 3664.3381s\n",
      "1998it [01:42, 19.72it/s]\titers: 2000, epoch: 7 | loss: 0.2263605\n",
      "\tspeed: 0.0497s/iter; left time: 3409.1557s\n",
      "2099it [01:47, 19.65it/s]\titers: 2100, epoch: 7 | loss: 0.1656736\n",
      "\tspeed: 0.0506s/iter; left time: 3464.1316s\n",
      "2198it [01:52, 16.83it/s]\titers: 2200, epoch: 7 | loss: 0.1607473\n",
      "\tspeed: 0.0521s/iter; left time: 3558.8103s\n",
      "2299it [01:58, 19.19it/s]\titers: 2300, epoch: 7 | loss: 0.1662297\n",
      "\tspeed: 0.0530s/iter; left time: 3618.1115s\n",
      "2399it [02:03, 19.79it/s]\titers: 2400, epoch: 7 | loss: 0.2440114\n",
      "\tspeed: 0.0506s/iter; left time: 3447.7887s\n",
      "2498it [02:08, 19.56it/s]\titers: 2500, epoch: 7 | loss: 0.3018534\n",
      "\tspeed: 0.0507s/iter; left time: 3449.6521s\n",
      "2599it [02:13, 14.05it/s]\titers: 2600, epoch: 7 | loss: 0.1849991\n",
      "\tspeed: 0.0529s/iter; left time: 3597.3922s\n",
      "2698it [02:19, 19.74it/s]\titers: 2700, epoch: 7 | loss: 0.2386391\n",
      "\tspeed: 0.0533s/iter; left time: 3619.4343s\n",
      "2798it [02:24, 19.75it/s]\titers: 2800, epoch: 7 | loss: 0.2096949\n",
      "\tspeed: 0.0505s/iter; left time: 3424.5841s\n",
      "2899it [02:29, 19.90it/s]\titers: 2900, epoch: 7 | loss: 0.2451244\n",
      "\tspeed: 0.0506s/iter; left time: 3419.7911s\n",
      "2999it [02:34, 19.79it/s]\titers: 3000, epoch: 7 | loss: 0.2012083\n",
      "\tspeed: 0.0555s/iter; left time: 3749.8994s\n",
      "3098it [02:39, 19.74it/s]\titers: 3100, epoch: 7 | loss: 0.2286226\n",
      "\tspeed: 0.0507s/iter; left time: 3417.3437s\n",
      "3198it [02:44, 19.71it/s]\titers: 3200, epoch: 7 | loss: 0.1578452\n",
      "\tspeed: 0.0504s/iter; left time: 3395.7225s\n",
      "3299it [02:50, 19.76it/s]\titers: 3300, epoch: 7 | loss: 0.2077217\n",
      "\tspeed: 0.0521s/iter; left time: 3500.8117s\n",
      "3399it [02:55, 19.64it/s]\titers: 3400, epoch: 7 | loss: 0.2225291\n",
      "\tspeed: 0.0506s/iter; left time: 3400.7048s\n",
      "3499it [03:00, 19.66it/s]\titers: 3500, epoch: 7 | loss: 0.2186193\n",
      "\tspeed: 0.0509s/iter; left time: 3414.1962s\n",
      "3598it [03:05, 19.42it/s]\titers: 3600, epoch: 7 | loss: 0.1826516\n",
      "\tspeed: 0.0560s/iter; left time: 3751.1946s\n",
      "3699it [03:10, 19.83it/s]\titers: 3700, epoch: 7 | loss: 0.3864423\n",
      "\tspeed: 0.0509s/iter; left time: 3404.2086s\n",
      "3713it [03:11, 19.37it/s]\n",
      "Epoch: 7 cost time: 191.6736786365509\n",
      "810it [00:20, 40.42it/s]\n",
      "807it [00:20, 39.98it/s]\n",
      "Epoch: 7 | Train Loss: 0.2155371 Vali Loss: 0.2745227 Test Loss: 0.3363505 MAE Loss: 0.3467570\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:05, 19.79it/s]\titers: 100, epoch: 8 | loss: 0.2786378\n",
      "\tspeed: 0.4824s/iter; left time: 32193.3901s\n",
      "198it [00:10, 20.66it/s]\titers: 200, epoch: 8 | loss: 0.2710315\n",
      "\tspeed: 0.0499s/iter; left time: 3323.9720s\n",
      "297it [00:15, 19.60it/s]\titers: 300, epoch: 8 | loss: 0.2170390\n",
      "\tspeed: 0.0507s/iter; left time: 3375.0515s\n",
      "398it [00:20, 19.70it/s]\titers: 400, epoch: 8 | loss: 0.2417136\n",
      "\tspeed: 0.0506s/iter; left time: 3359.3347s\n",
      "498it [00:26, 19.79it/s]\titers: 500, epoch: 8 | loss: 0.3426365\n",
      "\tspeed: 0.0543s/iter; left time: 3601.9309s\n",
      "598it [00:31, 20.10it/s]\titers: 600, epoch: 8 | loss: 0.1068352\n",
      "\tspeed: 0.0495s/iter; left time: 3275.6740s\n",
      "699it [00:36, 19.70it/s]\titers: 700, epoch: 8 | loss: 0.1527071\n",
      "\tspeed: 0.0502s/iter; left time: 3318.9440s\n",
      "797it [00:41, 19.69it/s]\titers: 800, epoch: 8 | loss: 0.2598018\n",
      "\tspeed: 0.0507s/iter; left time: 3348.5916s\n",
      "899it [00:46, 19.92it/s]\titers: 900, epoch: 8 | loss: 0.2337403\n",
      "\tspeed: 0.0545s/iter; left time: 3592.1784s\n",
      "999it [00:51, 19.98it/s]\titers: 1000, epoch: 8 | loss: 0.1904162\n",
      "\tspeed: 0.0505s/iter; left time: 3322.2672s\n",
      "1098it [00:56, 19.80it/s]\titers: 1100, epoch: 8 | loss: 0.1839960\n",
      "\tspeed: 0.0502s/iter; left time: 3299.0692s\n",
      "1199it [01:01, 20.03it/s]\titers: 1200, epoch: 8 | loss: 0.1732445\n",
      "\tspeed: 0.0505s/iter; left time: 3314.3298s\n",
      "1298it [01:07, 19.76it/s]\titers: 1300, epoch: 8 | loss: 0.1387484\n",
      "\tspeed: 0.0539s/iter; left time: 3529.9785s\n",
      "1398it [01:12, 18.31it/s]\titers: 1400, epoch: 8 | loss: 0.1967897\n",
      "\tspeed: 0.0520s/iter; left time: 3404.1566s\n",
      "1498it [01:17, 18.68it/s]\titers: 1500, epoch: 8 | loss: 0.1411237\n",
      "\tspeed: 0.0540s/iter; left time: 3525.1275s\n",
      "1599it [01:23, 14.36it/s]\titers: 1600, epoch: 8 | loss: 0.3261814\n",
      "\tspeed: 0.0564s/iter; left time: 3679.4048s\n",
      "1697it [01:28, 21.64it/s]\titers: 1700, epoch: 8 | loss: 0.1469200\n",
      "\tspeed: 0.0491s/iter; left time: 3196.8671s\n",
      "1799it [01:33, 19.39it/s]\titers: 1800, epoch: 8 | loss: 0.2017586\n",
      "\tspeed: 0.0505s/iter; left time: 3282.0826s\n",
      "1899it [01:38, 19.41it/s]\titers: 1900, epoch: 8 | loss: 0.1910969\n",
      "\tspeed: 0.0507s/iter; left time: 3290.7546s\n",
      "1998it [01:44, 18.89it/s]\titers: 2000, epoch: 8 | loss: 0.1147423\n",
      "\tspeed: 0.0552s/iter; left time: 3575.8046s\n",
      "2099it [01:49, 19.87it/s]\titers: 2100, epoch: 8 | loss: 0.4468918\n",
      "\tspeed: 0.0502s/iter; left time: 3252.3092s\n",
      "2199it [01:54, 19.30it/s]\titers: 2200, epoch: 8 | loss: 0.2316685\n",
      "\tspeed: 0.0502s/iter; left time: 3243.2532s\n",
      "2298it [01:59, 19.65it/s]\titers: 2300, epoch: 8 | loss: 0.2134553\n",
      "\tspeed: 0.0520s/iter; left time: 3356.2018s\n",
      "2398it [02:04, 19.69it/s]\titers: 2400, epoch: 8 | loss: 0.3089409\n",
      "\tspeed: 0.0542s/iter; left time: 3491.0596s\n",
      "2499it [02:09, 19.39it/s]\titers: 2500, epoch: 8 | loss: 0.2977727\n",
      "\tspeed: 0.0509s/iter; left time: 3275.0410s\n",
      "2599it [02:14, 19.73it/s]\titers: 2600, epoch: 8 | loss: 0.2382092\n",
      "\tspeed: 0.0507s/iter; left time: 3255.9795s\n",
      "2699it [02:20, 19.54it/s]\titers: 2700, epoch: 8 | loss: 0.1799687\n",
      "\tspeed: 0.0508s/iter; left time: 3260.9545s\n",
      "2798it [02:25, 19.71it/s]\titers: 2800, epoch: 8 | loss: 0.4740205\n",
      "\tspeed: 0.0553s/iter; left time: 3537.9773s\n",
      "2898it [02:30, 20.38it/s]\titers: 2900, epoch: 8 | loss: 0.2653501\n",
      "\tspeed: 0.0473s/iter; left time: 3024.2813s\n",
      "2999it [02:35, 19.58it/s]\titers: 3000, epoch: 8 | loss: 0.1679090\n",
      "\tspeed: 0.0504s/iter; left time: 3217.7369s\n",
      "3097it [02:40, 19.87it/s]\titers: 3100, epoch: 8 | loss: 0.2297585\n",
      "\tspeed: 0.0510s/iter; left time: 3250.2771s\n",
      "3198it [02:45, 19.77it/s]\titers: 3200, epoch: 8 | loss: 0.2000555\n",
      "\tspeed: 0.0548s/iter; left time: 3487.9137s\n",
      "3298it [02:50, 21.51it/s]\titers: 3300, epoch: 8 | loss: 0.2938821\n",
      "\tspeed: 0.0495s/iter; left time: 3147.2668s\n",
      "3399it [02:55, 19.84it/s]\titers: 3400, epoch: 8 | loss: 0.1683079\n",
      "\tspeed: 0.0494s/iter; left time: 3134.4256s\n",
      "3498it [03:00, 19.82it/s]\titers: 3500, epoch: 8 | loss: 0.3080443\n",
      "\tspeed: 0.0506s/iter; left time: 3205.8876s\n",
      "3598it [03:06, 18.10it/s]\titers: 3600, epoch: 8 | loss: 0.2887488\n",
      "\tspeed: 0.0547s/iter; left time: 3459.3438s\n",
      "3698it [03:11, 20.89it/s]\titers: 3700, epoch: 8 | loss: 0.2520700\n",
      "\tspeed: 0.0493s/iter; left time: 3110.5990s\n",
      "3713it [03:11, 19.34it/s]\n",
      "Epoch: 8 cost time: 191.98204565048218\n",
      "810it [00:20, 38.77it/s]\n",
      "807it [00:21, 38.32it/s]\n",
      "Epoch: 8 | Train Loss: 0.2154173 Vali Loss: 0.2755143 Test Loss: 0.3400271 MAE Loss: 0.3509573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "98it [00:05, 19.77it/s]\titers: 100, epoch: 9 | loss: 0.1454974\n",
      "\tspeed: 0.4822s/iter; left time: 30389.1513s\n",
      "198it [00:10, 19.20it/s]\titers: 200, epoch: 9 | loss: 0.1913862\n",
      "\tspeed: 0.0553s/iter; left time: 3479.5500s\n",
      "298it [00:15, 19.25it/s]\titers: 300, epoch: 9 | loss: 0.2767942\n",
      "\tspeed: 0.0512s/iter; left time: 3214.4863s\n",
      "399it [00:21, 19.69it/s]\titers: 400, epoch: 9 | loss: 0.1567416\n",
      "\tspeed: 0.0504s/iter; left time: 3160.5517s\n",
      "498it [00:25, 20.58it/s]\titers: 500, epoch: 9 | loss: 0.1706051\n",
      "\tspeed: 0.0481s/iter; left time: 3012.4278s\n",
      "599it [00:31, 19.57it/s]\titers: 600, epoch: 9 | loss: 0.1486783\n",
      "\tspeed: 0.0544s/iter; left time: 3402.4117s\n",
      "698it [00:36, 21.16it/s]\titers: 700, epoch: 9 | loss: 0.3081464\n",
      "\tspeed: 0.0489s/iter; left time: 3054.5959s\n",
      "797it [00:41, 20.58it/s]\titers: 800, epoch: 9 | loss: 0.1660386\n",
      "\tspeed: 0.0502s/iter; left time: 3130.8757s\n",
      "898it [00:46, 16.22it/s]\titers: 900, epoch: 9 | loss: 0.3212689\n",
      "\tspeed: 0.0521s/iter; left time: 3240.9939s\n",
      "999it [00:51, 20.86it/s]\titers: 1000, epoch: 9 | loss: 0.1436147\n",
      "\tspeed: 0.0506s/iter; left time: 3145.5097s\n",
      "1099it [00:56, 20.56it/s]\titers: 1100, epoch: 9 | loss: 0.3214273\n",
      "\tspeed: 0.0481s/iter; left time: 2981.7170s\n",
      "1198it [01:01, 19.49it/s]\titers: 1200, epoch: 9 | loss: 0.2310148\n",
      "\tspeed: 0.0514s/iter; left time: 3185.3062s\n",
      "1298it [01:06, 18.22it/s]\titers: 1300, epoch: 9 | loss: 0.1558540\n",
      "\tspeed: 0.0544s/iter; left time: 3361.0207s\n",
      "1398it [01:11, 20.53it/s]\titers: 1400, epoch: 9 | loss: 0.1660047\n",
      "\tspeed: 0.0498s/iter; left time: 3076.6318s\n",
      "1498it [01:16, 19.47it/s]\titers: 1500, epoch: 9 | loss: 0.2981940\n",
      "\tspeed: 0.0502s/iter; left time: 3096.3090s\n",
      "1597it [01:21, 21.55it/s]\titers: 1600, epoch: 9 | loss: 0.1866152\n",
      "\tspeed: 0.0493s/iter; left time: 3031.4320s\n",
      "1699it [01:27, 19.59it/s]\titers: 1700, epoch: 9 | loss: 0.1452501\n",
      "\tspeed: 0.0527s/iter; left time: 3237.6616s\n",
      "1798it [01:32, 19.71it/s]\titers: 1800, epoch: 9 | loss: 0.2375763\n",
      "\tspeed: 0.0520s/iter; left time: 3188.4825s\n",
      "1899it [01:37, 19.79it/s]\titers: 1900, epoch: 9 | loss: 0.1779971\n",
      "\tspeed: 0.0506s/iter; left time: 3095.8650s\n",
      "1998it [01:42, 15.65it/s]\titers: 2000, epoch: 9 | loss: 0.3367044\n",
      "\tspeed: 0.0530s/iter; left time: 3237.9015s\n",
      "2098it [01:47, 19.77it/s]\titers: 2100, epoch: 9 | loss: 0.1966998\n",
      "\tspeed: 0.0514s/iter; left time: 3135.7909s\n",
      "2198it [01:52, 19.77it/s]\titers: 2200, epoch: 9 | loss: 0.2413703\n",
      "\tspeed: 0.0513s/iter; left time: 3123.2373s\n",
      "2297it [01:57, 19.69it/s]\titers: 2300, epoch: 9 | loss: 0.1379028\n",
      "\tspeed: 0.0508s/iter; left time: 3089.8383s\n",
      "2397it [02:03, 21.03it/s]\titers: 2400, epoch: 9 | loss: 0.3327178\n",
      "\tspeed: 0.0527s/iter; left time: 3200.1422s\n",
      "2499it [02:08, 19.92it/s]\titers: 2500, epoch: 9 | loss: 0.1489848\n",
      "\tspeed: 0.0506s/iter; left time: 3067.0640s\n",
      "2599it [02:13, 19.82it/s]\titers: 2600, epoch: 9 | loss: 0.2102255\n",
      "\tspeed: 0.0504s/iter; left time: 3048.4120s\n",
      "2699it [02:18, 19.75it/s]\titers: 2700, epoch: 9 | loss: 0.2489707\n",
      "\tspeed: 0.0546s/iter; left time: 3300.9356s\n",
      "2798it [02:23, 19.76it/s]\titers: 2800, epoch: 9 | loss: 0.1418840\n",
      "\tspeed: 0.0505s/iter; left time: 3045.3676s\n",
      "2897it [02:28, 21.04it/s]\titers: 2900, epoch: 9 | loss: 0.2291190\n",
      "\tspeed: 0.0487s/iter; left time: 2933.5380s\n",
      "2998it [02:33, 14.24it/s]\titers: 3000, epoch: 9 | loss: 0.2005869\n",
      "\tspeed: 0.0527s/iter; left time: 3170.7382s\n",
      "3098it [02:39, 19.82it/s]\titers: 3100, epoch: 9 | loss: 0.1255269\n",
      "\tspeed: 0.0521s/iter; left time: 3127.0408s\n",
      "3199it [02:44, 19.76it/s]\titers: 3200, epoch: 9 | loss: 0.3054868\n",
      "\tspeed: 0.0506s/iter; left time: 3031.7590s\n",
      "3299it [02:49, 19.15it/s]\titers: 3300, epoch: 9 | loss: 0.1301544\n",
      "\tspeed: 0.0511s/iter; left time: 3057.0058s\n",
      "3398it [02:54, 19.76it/s]\titers: 3400, epoch: 9 | loss: 0.2780200\n",
      "\tspeed: 0.0552s/iter; left time: 3298.6692s\n",
      "3498it [02:59, 20.24it/s]\titers: 3500, epoch: 9 | loss: 0.2467569\n",
      "\tspeed: 0.0505s/iter; left time: 3009.6862s\n",
      "3598it [03:04, 19.85it/s]\titers: 3600, epoch: 9 | loss: 0.3265379\n",
      "\tspeed: 0.0507s/iter; left time: 3016.3745s\n",
      "3699it [03:10, 19.19it/s]\titers: 3700, epoch: 9 | loss: 0.1908322\n",
      "\tspeed: 0.0545s/iter; left time: 3239.1608s\n",
      "3713it [03:11, 19.41it/s]\n",
      "Epoch: 9 cost time: 191.2776346206665\n",
      "810it [00:20, 39.28it/s]\n",
      "807it [00:20, 38.60it/s]\n",
      "Epoch: 9 | Train Loss: 0.2149778 Vali Loss: 0.2751592 Test Loss: 0.3383785 MAE Loss: 0.3491313\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "98it [00:05, 19.77it/s]\titers: 100, epoch: 10 | loss: 0.2569150\n",
      "\tspeed: 0.4783s/iter; left time: 28370.1184s\n",
      "199it [00:10, 19.74it/s]\titers: 200, epoch: 10 | loss: 0.3195561\n",
      "\tspeed: 0.0530s/iter; left time: 3135.8642s\n",
      "298it [00:15, 19.73it/s]\titers: 300, epoch: 10 | loss: 0.2412108\n",
      "\tspeed: 0.0505s/iter; left time: 2982.6167s\n",
      "398it [00:20, 19.75it/s]\titers: 400, epoch: 10 | loss: 0.1822399\n",
      "\tspeed: 0.0506s/iter; left time: 2984.3269s\n",
      "498it [00:26, 19.30it/s]\titers: 500, epoch: 10 | loss: 0.3216189\n",
      "\tspeed: 0.0540s/iter; left time: 3182.3903s\n",
      "599it [00:31, 19.76it/s]\titers: 600, epoch: 10 | loss: 0.3571704\n",
      "\tspeed: 0.0506s/iter; left time: 2973.8185s\n",
      "698it [00:36, 19.67it/s]\titers: 700, epoch: 10 | loss: 0.2427208\n",
      "\tspeed: 0.0509s/iter; left time: 2985.9504s\n",
      "799it [00:41, 17.32it/s]\titers: 800, epoch: 10 | loss: 0.1670142\n",
      "\tspeed: 0.0516s/iter; left time: 3024.7116s\n",
      "899it [00:46, 19.73it/s]\titers: 900, epoch: 10 | loss: 0.2083600\n",
      "\tspeed: 0.0512s/iter; left time: 2997.4739s\n",
      "998it [00:51, 19.87it/s]\titers: 1000, epoch: 10 | loss: 0.0827355\n",
      "\tspeed: 0.0506s/iter; left time: 2953.4447s\n",
      "1099it [00:56, 19.90it/s]\titers: 1100, epoch: 10 | loss: 0.1302571\n",
      "\tspeed: 0.0505s/iter; left time: 2945.7941s\n",
      "1199it [01:01, 19.83it/s]\titers: 1200, epoch: 10 | loss: 0.2445807\n",
      "\tspeed: 0.0520s/iter; left time: 3028.6439s\n",
      "1298it [01:06, 19.79it/s]\titers: 1300, epoch: 10 | loss: 0.1575307\n",
      "\tspeed: 0.0505s/iter; left time: 2936.8240s\n",
      "1398it [01:11, 19.79it/s]\titers: 1400, epoch: 10 | loss: 0.2063795\n",
      "\tspeed: 0.0506s/iter; left time: 2932.4723s\n",
      "1498it [01:17, 19.92it/s]\titers: 1500, epoch: 10 | loss: 0.2209348\n",
      "\tspeed: 0.0520s/iter; left time: 3008.7695s\n",
      "1598it [01:22, 19.78it/s]\titers: 1600, epoch: 10 | loss: 0.2986484\n",
      "\tspeed: 0.0506s/iter; left time: 2923.7050s\n",
      "1699it [01:27, 19.74it/s]\titers: 1700, epoch: 10 | loss: 0.2596985\n",
      "\tspeed: 0.0505s/iter; left time: 2916.7413s\n",
      "1799it [01:32, 13.49it/s]\titers: 1800, epoch: 10 | loss: 0.2193541\n",
      "\tspeed: 0.0544s/iter; left time: 3135.9271s\n",
      "1899it [01:37, 19.84it/s]\titers: 1900, epoch: 10 | loss: 0.1960420\n",
      "\tspeed: 0.0511s/iter; left time: 2939.9669s\n",
      "1998it [01:42, 19.69it/s]\titers: 2000, epoch: 10 | loss: 0.2252353\n",
      "\tspeed: 0.0506s/iter; left time: 2907.6939s\n",
      "2098it [01:48, 16.22it/s]\titers: 2100, epoch: 10 | loss: 0.1680154\n",
      "\tspeed: 0.0517s/iter; left time: 2964.3969s\n",
      "2199it [01:53, 19.76it/s]\titers: 2200, epoch: 10 | loss: 0.1209109\n",
      "\tspeed: 0.0531s/iter; left time: 3039.5177s\n",
      "2298it [01:58, 19.73it/s]\titers: 2300, epoch: 10 | loss: 0.2134561\n",
      "\tspeed: 0.0506s/iter; left time: 2888.5402s\n",
      "2397it [02:03, 19.70it/s]\titers: 2400, epoch: 10 | loss: 0.1753313\n",
      "\tspeed: 0.0497s/iter; left time: 2830.5577s\n",
      "2499it [02:08, 19.82it/s]\titers: 2500, epoch: 10 | loss: 0.2047290\n",
      "\tspeed: 0.0547s/iter; left time: 3112.2279s\n",
      "2598it [02:13, 19.89it/s]\titers: 2600, epoch: 10 | loss: 0.3118169\n",
      "\tspeed: 0.0505s/iter; left time: 2870.6116s\n",
      "2699it [02:19, 19.80it/s]\titers: 2700, epoch: 10 | loss: 0.1624915\n",
      "\tspeed: 0.0506s/iter; left time: 2867.3873s\n",
      "2799it [02:24, 23.18it/s]\titers: 2800, epoch: 10 | loss: 0.1721722\n",
      "\tspeed: 0.0499s/iter; left time: 2822.7101s\n",
      "2898it [02:28, 23.29it/s]\titers: 2900, epoch: 10 | loss: 0.1895968\n",
      "\tspeed: 0.0431s/iter; left time: 2436.0048s\n",
      "2997it [02:32, 23.27it/s]\titers: 3000, epoch: 10 | loss: 0.2166403\n",
      "\tspeed: 0.0431s/iter; left time: 2432.5721s\n",
      "3099it [02:36, 23.25it/s]\titers: 3100, epoch: 10 | loss: 0.3333257\n",
      "\tspeed: 0.0431s/iter; left time: 2429.1033s\n",
      "3197it [02:41, 23.25it/s]\titers: 3200, epoch: 10 | loss: 0.2744052\n",
      "\tspeed: 0.0453s/iter; left time: 2545.0387s\n",
      "3299it [02:45, 23.03it/s]\titers: 3300, epoch: 10 | loss: 0.1310734\n",
      "\tspeed: 0.0430s/iter; left time: 2413.3831s\n",
      "3398it [02:50, 23.14it/s]\titers: 3400, epoch: 10 | loss: 0.1732120\n",
      "\tspeed: 0.0431s/iter; left time: 2414.1030s\n",
      "3499it [02:55, 18.75it/s]\titers: 3500, epoch: 10 | loss: 0.1889812\n",
      "\tspeed: 0.0526s/iter; left time: 2941.8061s\n",
      "3598it [03:00, 19.82it/s]\titers: 3600, epoch: 10 | loss: 0.1601386\n",
      "\tspeed: 0.0505s/iter; left time: 2821.0455s\n",
      "3698it [03:05, 19.76it/s]\titers: 3700, epoch: 10 | loss: 0.2091234\n",
      "\tspeed: 0.0505s/iter; left time: 2815.9596s\n",
      "3713it [03:06, 19.94it/s]\n",
      "Epoch: 10 cost time: 186.24596500396729\n",
      "810it [00:21, 38.39it/s]\n",
      "807it [00:20, 38.76it/s]\n",
      "Epoch: 10 | Train Loss: 0.2144178 Vali Loss: 0.2749725 Test Loss: 0.3380711 MAE Loss: 0.3482471\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 7.812499999999999e-08\n",
      "99it [00:05, 19.72it/s]\titers: 100, epoch: 11 | loss: 0.2245844\n",
      "\tspeed: 0.4832s/iter; left time: 26866.6701s\n",
      "199it [00:10, 19.65it/s]\titers: 200, epoch: 11 | loss: 0.2612220\n",
      "\tspeed: 0.0508s/iter; left time: 2818.0216s\n",
      "297it [00:15, 19.71it/s]\titers: 300, epoch: 11 | loss: 0.4378271\n",
      "\tspeed: 0.0516s/iter; left time: 2858.2246s\n",
      "398it [00:21, 19.67it/s]\titers: 400, epoch: 11 | loss: 0.3365444\n",
      "\tspeed: 0.0543s/iter; left time: 3003.7805s\n",
      "499it [00:26, 19.76it/s]\titers: 500, epoch: 11 | loss: 0.2127449\n",
      "\tspeed: 0.0514s/iter; left time: 2835.8817s\n",
      "599it [00:31, 19.85it/s]\titers: 600, epoch: 11 | loss: 0.1943600\n",
      "\tspeed: 0.0505s/iter; left time: 2784.5633s\n",
      "698it [00:36, 19.69it/s]\titers: 700, epoch: 11 | loss: 0.1460741\n",
      "\tspeed: 0.0517s/iter; left time: 2841.1555s\n",
      "799it [00:41, 19.82it/s]\titers: 800, epoch: 11 | loss: 0.2881437\n",
      "\tspeed: 0.0506s/iter; left time: 2780.2571s\n",
      "899it [00:46, 18.62it/s]\titers: 900, epoch: 11 | loss: 0.1721698\n",
      "\tspeed: 0.0512s/iter; left time: 2804.1550s\n",
      "999it [00:52, 17.55it/s]\titers: 1000, epoch: 11 | loss: 0.2068194\n",
      "\tspeed: 0.0544s/iter; left time: 2975.1178s\n",
      "1098it [00:57, 19.87it/s]\titers: 1100, epoch: 11 | loss: 0.1456630\n",
      "\tspeed: 0.0507s/iter; left time: 2767.9055s\n",
      "1198it [01:02, 19.76it/s]\titers: 1200, epoch: 11 | loss: 0.1685269\n",
      "\tspeed: 0.0508s/iter; left time: 2770.4629s\n",
      "1298it [01:07, 19.81it/s]\titers: 1300, epoch: 11 | loss: 0.3200010\n",
      "\tspeed: 0.0506s/iter; left time: 2751.8598s\n",
      "1398it [01:12, 19.82it/s]\titers: 1400, epoch: 11 | loss: 0.3089668\n",
      "\tspeed: 0.0517s/iter; left time: 2809.3264s\n",
      "1498it [01:17, 19.71it/s]\titers: 1500, epoch: 11 | loss: 0.1267045\n",
      "\tspeed: 0.0512s/iter; left time: 2773.9973s\n",
      "1598it [01:22, 19.81it/s]\titers: 1600, epoch: 11 | loss: 0.2209289\n",
      "\tspeed: 0.0507s/iter; left time: 2743.7668s\n",
      "1698it [01:27, 19.79it/s]\titers: 1700, epoch: 11 | loss: 0.2298638\n",
      "\tspeed: 0.0516s/iter; left time: 2787.2502s\n",
      "1799it [01:32, 19.80it/s]\titers: 1800, epoch: 11 | loss: 0.3469776\n",
      "\tspeed: 0.0504s/iter; left time: 2718.3155s\n",
      "1898it [01:37, 19.82it/s]\titers: 1900, epoch: 11 | loss: 0.1332630\n",
      "\tspeed: 0.0505s/iter; left time: 2719.3354s\n",
      "1999it [01:43, 19.79it/s]\titers: 2000, epoch: 11 | loss: 0.2041427\n",
      "\tspeed: 0.0535s/iter; left time: 2872.9157s\n",
      "2098it [01:48, 19.72it/s]\titers: 2100, epoch: 11 | loss: 0.1850900\n",
      "\tspeed: 0.0512s/iter; left time: 2742.0937s\n",
      "2198it [01:53, 18.59it/s]\titers: 2200, epoch: 11 | loss: 0.1682402\n",
      "\tspeed: 0.0513s/iter; left time: 2742.0344s\n",
      "2298it [01:58, 16.79it/s]\titers: 2300, epoch: 11 | loss: 0.2723113\n",
      "\tspeed: 0.0517s/iter; left time: 2762.9414s\n",
      "2397it [02:03, 18.87it/s]\titers: 2400, epoch: 11 | loss: 0.1299610\n",
      "\tspeed: 0.0519s/iter; left time: 2767.4975s\n",
      "2499it [02:09, 19.78it/s]\titers: 2500, epoch: 11 | loss: 0.3661303\n",
      "\tspeed: 0.0506s/iter; left time: 2691.1832s\n",
      "2598it [02:14, 19.79it/s]\titers: 2600, epoch: 11 | loss: 0.2733271\n",
      "\tspeed: 0.0511s/iter; left time: 2711.7372s\n",
      "2698it [02:19, 19.78it/s]\titers: 2700, epoch: 11 | loss: 0.2296294\n",
      "\tspeed: 0.0517s/iter; left time: 2738.8095s\n",
      "2798it [02:24, 18.75it/s]\titers: 2800, epoch: 11 | loss: 0.2190166\n",
      "\tspeed: 0.0508s/iter; left time: 2685.9510s\n",
      "2899it [02:29, 19.29it/s]\titers: 2900, epoch: 11 | loss: 0.4384509\n",
      "\tspeed: 0.0506s/iter; left time: 2670.4012s\n",
      "2998it [02:34, 19.78it/s]\titers: 3000, epoch: 11 | loss: 0.2717016\n",
      "\tspeed: 0.0536s/iter; left time: 2822.3589s\n",
      "3099it [02:39, 19.73it/s]\titers: 3100, epoch: 11 | loss: 0.1124882\n",
      "\tspeed: 0.0506s/iter; left time: 2660.3363s\n",
      "3198it [02:44, 19.77it/s]\titers: 3200, epoch: 11 | loss: 0.1590402\n",
      "\tspeed: 0.0505s/iter; left time: 2651.6455s\n",
      "3298it [02:50, 19.70it/s]\titers: 3300, epoch: 11 | loss: 0.3283332\n",
      "\tspeed: 0.0524s/iter; left time: 2745.4882s\n",
      "3399it [02:55, 19.73it/s]\titers: 3400, epoch: 11 | loss: 0.1022675\n",
      "\tspeed: 0.0510s/iter; left time: 2668.2852s\n",
      "3498it [03:00, 19.76it/s]\titers: 3500, epoch: 11 | loss: 0.2435901\n",
      "\tspeed: 0.0505s/iter; left time: 2635.2098s\n",
      "3598it [03:05, 19.80it/s]\titers: 3600, epoch: 11 | loss: 0.1673331\n",
      "\tspeed: 0.0509s/iter; left time: 2651.2711s\n",
      "3698it [03:10, 19.75it/s]\titers: 3700, epoch: 11 | loss: 0.1102010\n",
      "\tspeed: 0.0554s/iter; left time: 2881.1359s\n",
      "3713it [03:11, 19.37it/s]\n",
      "Epoch: 11 cost time: 191.73157501220703\n",
      "810it [00:20, 39.78it/s]\n",
      "807it [00:20, 39.57it/s]\n",
      "Epoch: 11 | Train Loss: 0.2145903 Vali Loss: 0.2750762 Test Loss: 0.3383052 MAE Loss: 0.3490143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9062499999999997e-08\n",
      "99it [00:05, 19.83it/s]\titers: 100, epoch: 12 | loss: 0.2413119\n",
      "\tspeed: 0.4707s/iter; left time: 24420.8470s\n",
      "199it [00:10, 17.75it/s]\titers: 200, epoch: 12 | loss: 0.1895789\n",
      "\tspeed: 0.0529s/iter; left time: 2738.4807s\n",
      "298it [00:15, 19.63it/s]\titers: 300, epoch: 12 | loss: 0.1102533\n",
      "\tspeed: 0.0512s/iter; left time: 2644.4772s\n",
      "398it [00:20, 19.75it/s]\titers: 400, epoch: 12 | loss: 0.1692680\n",
      "\tspeed: 0.0510s/iter; left time: 2632.7693s\n",
      "498it [00:25, 19.81it/s]\titers: 500, epoch: 12 | loss: 0.1925704\n",
      "\tspeed: 0.0509s/iter; left time: 2621.1642s\n",
      "599it [00:30, 19.94it/s]\titers: 600, epoch: 12 | loss: 0.1041491\n",
      "\tspeed: 0.0518s/iter; left time: 2660.4853s\n",
      "699it [00:35, 19.80it/s]\titers: 700, epoch: 12 | loss: 0.2290626\n",
      "\tspeed: 0.0505s/iter; left time: 2588.5101s\n",
      "799it [00:41, 19.82it/s]\titers: 800, epoch: 12 | loss: 0.1544472\n",
      "\tspeed: 0.0507s/iter; left time: 2593.1780s\n",
      "899it [00:46, 19.77it/s]\titers: 900, epoch: 12 | loss: 0.2058899\n",
      "\tspeed: 0.0506s/iter; left time: 2586.0898s\n",
      "998it [00:51, 19.82it/s]\titers: 1000, epoch: 12 | loss: 0.1432300\n",
      "\tspeed: 0.0533s/iter; left time: 2715.5315s\n",
      "1099it [00:56, 19.76it/s]\titers: 1100, epoch: 12 | loss: 0.1430591\n",
      "\tspeed: 0.0506s/iter; left time: 2575.7970s\n",
      "1198it [01:01, 19.72it/s]\titers: 1200, epoch: 12 | loss: 0.2479924\n",
      "\tspeed: 0.0506s/iter; left time: 2569.3957s\n",
      "1299it [01:06, 19.91it/s]\titers: 1300, epoch: 12 | loss: 0.2185073\n",
      "\tspeed: 0.0522s/iter; left time: 2643.3400s\n",
      "1398it [01:11, 19.75it/s]\titers: 1400, epoch: 12 | loss: 0.2367185\n",
      "\tspeed: 0.0505s/iter; left time: 2556.0906s\n",
      "1497it [01:16, 20.19it/s]\titers: 1500, epoch: 12 | loss: 0.1992850\n",
      "\tspeed: 0.0495s/iter; left time: 2501.3291s\n",
      "1599it [01:21, 16.44it/s]\titers: 1600, epoch: 12 | loss: 0.1929590\n",
      "\tspeed: 0.0520s/iter; left time: 2621.1028s\n",
      "1698it [01:27, 19.78it/s]\titers: 1700, epoch: 12 | loss: 0.2046870\n",
      "\tspeed: 0.0507s/iter; left time: 2550.2694s\n",
      "1798it [01:32, 20.01it/s]\titers: 1800, epoch: 12 | loss: 0.3352174\n",
      "\tspeed: 0.0505s/iter; left time: 2533.4656s\n",
      "1899it [01:37, 19.95it/s]\titers: 1900, epoch: 12 | loss: 0.1961717\n",
      "\tspeed: 0.0504s/iter; left time: 2522.6868s\n",
      "1998it [01:42, 19.72it/s]\titers: 2000, epoch: 12 | loss: 0.1600339\n",
      "\tspeed: 0.0543s/iter; left time: 2715.9636s\n",
      "2099it [01:47, 19.77it/s]\titers: 2100, epoch: 12 | loss: 0.3061701\n",
      "\tspeed: 0.0506s/iter; left time: 2523.3765s\n",
      "2199it [01:52, 19.75it/s]\titers: 2200, epoch: 12 | loss: 0.3577336\n",
      "\tspeed: 0.0504s/iter; left time: 2509.6867s\n",
      "2297it [01:57, 23.09it/s]\titers: 2300, epoch: 12 | loss: 0.2709140\n",
      "\tspeed: 0.0496s/iter; left time: 2463.9099s\n",
      "2399it [02:01, 23.30it/s]\titers: 2400, epoch: 12 | loss: 0.2156548\n",
      "\tspeed: 0.0430s/iter; left time: 2130.2580s\n",
      "2498it [02:06, 23.31it/s]\titers: 2500, epoch: 12 | loss: 0.2926738\n",
      "\tspeed: 0.0431s/iter; left time: 2130.6950s\n",
      "2597it [02:10, 21.80it/s]\titers: 2600, epoch: 12 | loss: 0.1290786\n",
      "\tspeed: 0.0440s/iter; left time: 2172.9525s\n",
      "2699it [02:15, 22.81it/s]\titers: 2700, epoch: 12 | loss: 0.4073841\n",
      "\tspeed: 0.0450s/iter; left time: 2216.5366s\n",
      "2798it [02:19, 22.88it/s]\titers: 2800, epoch: 12 | loss: 0.2013675\n",
      "\tspeed: 0.0439s/iter; left time: 2161.1377s\n",
      "2897it [02:23, 20.59it/s]\titers: 2900, epoch: 12 | loss: 0.1523498\n",
      "\tspeed: 0.0448s/iter; left time: 2199.9521s\n",
      "2999it [02:29, 19.60it/s]\titers: 3000, epoch: 12 | loss: 0.1139310\n",
      "\tspeed: 0.0527s/iter; left time: 2580.5157s\n",
      "3099it [02:34, 19.83it/s]\titers: 3100, epoch: 12 | loss: 0.2566945\n",
      "\tspeed: 0.0508s/iter; left time: 2481.6903s\n",
      "3199it [02:39, 19.73it/s]\titers: 3200, epoch: 12 | loss: 0.1939412\n",
      "\tspeed: 0.0507s/iter; left time: 2471.3615s\n",
      "3298it [02:44, 16.23it/s]\titers: 3300, epoch: 12 | loss: 0.3139943\n",
      "\tspeed: 0.0521s/iter; left time: 2534.2132s\n",
      "3398it [02:49, 19.72it/s]\titers: 3400, epoch: 12 | loss: 0.3168676\n",
      "\tspeed: 0.0510s/iter; left time: 2475.3062s\n",
      "3498it [02:54, 19.76it/s]\titers: 3500, epoch: 12 | loss: 0.2491274\n",
      "\tspeed: 0.0506s/iter; left time: 2453.4915s\n",
      "3599it [02:59, 19.69it/s]\titers: 3600, epoch: 12 | loss: 0.1380278\n",
      "\tspeed: 0.0504s/iter; left time: 2439.5632s\n",
      "3699it [03:04, 19.82it/s]\titers: 3700, epoch: 12 | loss: 0.1482697\n",
      "\tspeed: 0.0516s/iter; left time: 2490.2938s\n",
      "3713it [03:05, 19.99it/s]\n",
      "Epoch: 12 cost time: 185.76413130760193\n",
      "810it [00:20, 39.28it/s]\n",
      "807it [00:20, 39.67it/s]\n",
      "Epoch: 12 | Train Loss: 0.2143507 Vali Loss: 0.2751685 Test Loss: 0.3384463 MAE Loss: 0.3491969\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9531249999999998e-08\n",
      "98it [00:05, 19.47it/s]\titers: 100, epoch: 13 | loss: 0.3409480\n",
      "\tspeed: 0.4764s/iter; left time: 22950.2146s\n",
      "199it [00:10, 19.85it/s]\titers: 200, epoch: 13 | loss: 0.1056106\n",
      "\tspeed: 0.0494s/iter; left time: 2372.6775s\n",
      "297it [00:15, 20.21it/s]\titers: 300, epoch: 13 | loss: 0.1649433\n",
      "\tspeed: 0.0505s/iter; left time: 2421.1147s\n",
      "398it [00:20, 19.78it/s]\titers: 400, epoch: 13 | loss: 0.1849056\n",
      "\tspeed: 0.0508s/iter; left time: 2431.6849s\n",
      "499it [00:25, 19.78it/s]\titers: 500, epoch: 13 | loss: 0.1413750\n",
      "\tspeed: 0.0507s/iter; left time: 2423.7265s\n",
      "599it [00:30, 19.76it/s]\titers: 600, epoch: 13 | loss: 0.3070639\n",
      "\tspeed: 0.0505s/iter; left time: 2409.3435s\n",
      "698it [00:35, 19.75it/s]\titers: 700, epoch: 13 | loss: 0.1623667\n",
      "\tspeed: 0.0505s/iter; left time: 2404.4408s\n",
      "799it [00:41, 19.79it/s]\titers: 800, epoch: 13 | loss: 0.2424178\n",
      "\tspeed: 0.0542s/iter; left time: 2570.9853s\n",
      "899it [00:46, 19.80it/s]\titers: 900, epoch: 13 | loss: 0.2209168\n",
      "\tspeed: 0.0512s/iter; left time: 2423.2310s\n",
      "999it [00:51, 19.79it/s]\titers: 1000, epoch: 13 | loss: 0.1675952\n",
      "\tspeed: 0.0510s/iter; left time: 2409.8776s\n",
      "1099it [00:56, 19.84it/s]\titers: 1100, epoch: 13 | loss: 0.1757133\n",
      "\tspeed: 0.0527s/iter; left time: 2486.9225s\n",
      "1198it [01:01, 19.78it/s]\titers: 1200, epoch: 13 | loss: 0.1286990\n",
      "\tspeed: 0.0505s/iter; left time: 2379.3141s\n",
      "1298it [01:06, 19.78it/s]\titers: 1300, epoch: 13 | loss: 0.2882040\n",
      "\tspeed: 0.0505s/iter; left time: 2373.7786s\n",
      "1399it [01:11, 18.97it/s]\titers: 1400, epoch: 13 | loss: 0.3033693\n",
      "\tspeed: 0.0510s/iter; left time: 2391.7936s\n",
      "1499it [01:17, 19.78it/s]\titers: 1500, epoch: 13 | loss: 0.1652783\n",
      "\tspeed: 0.0538s/iter; left time: 2517.4080s\n",
      "1598it [01:22, 19.78it/s]\titers: 1600, epoch: 13 | loss: 0.1319261\n",
      "\tspeed: 0.0503s/iter; left time: 2346.6459s\n",
      "1699it [01:27, 19.79it/s]\titers: 1700, epoch: 13 | loss: 0.2900615\n",
      "\tspeed: 0.0506s/iter; left time: 2355.0997s\n",
      "1797it [01:32, 20.61it/s]\titers: 1800, epoch: 13 | loss: 0.1184777\n",
      "\tspeed: 0.0551s/iter; left time: 2561.1324s\n",
      "1898it [01:37, 19.62it/s]\titers: 1900, epoch: 13 | loss: 0.2724834\n",
      "\tspeed: 0.0506s/iter; left time: 2346.4992s\n",
      "1998it [01:42, 22.94it/s]\titers: 2000, epoch: 13 | loss: 0.1143113\n",
      "\tspeed: 0.0486s/iter; left time: 2246.8144s\n",
      "2099it [01:48, 19.86it/s]\titers: 2100, epoch: 13 | loss: 0.1492468\n",
      "\tspeed: 0.0555s/iter; left time: 2563.0480s\n",
      "2199it [01:53, 19.82it/s]\titers: 2200, epoch: 13 | loss: 0.2417267\n",
      "\tspeed: 0.0509s/iter; left time: 2344.4041s\n",
      "2298it [01:58, 19.68it/s]\titers: 2300, epoch: 13 | loss: 0.2900813\n",
      "\tspeed: 0.0507s/iter; left time: 2330.8949s\n",
      "2397it [02:03, 19.70it/s]\titers: 2400, epoch: 13 | loss: 0.1193925\n",
      "\tspeed: 0.0507s/iter; left time: 2325.2304s\n",
      "2499it [02:08, 19.86it/s]\titers: 2500, epoch: 13 | loss: 0.3085585\n",
      "\tspeed: 0.0536s/iter; left time: 2451.5812s\n",
      "2598it [02:13, 19.77it/s]\titers: 2600, epoch: 13 | loss: 0.1971044\n",
      "\tspeed: 0.0506s/iter; left time: 2309.6535s\n",
      "2699it [02:18, 19.76it/s]\titers: 2700, epoch: 13 | loss: 0.2070840\n",
      "\tspeed: 0.0509s/iter; left time: 2317.7820s\n",
      "2798it [02:24, 19.83it/s]\titers: 2800, epoch: 13 | loss: 0.2089837\n",
      "\tspeed: 0.0553s/iter; left time: 2515.1020s\n",
      "2898it [02:29, 19.70it/s]\titers: 2900, epoch: 13 | loss: 0.1078708\n",
      "\tspeed: 0.0506s/iter; left time: 2295.0774s\n",
      "2999it [02:34, 19.75it/s]\titers: 3000, epoch: 13 | loss: 0.0774128\n",
      "\tspeed: 0.0507s/iter; left time: 2293.8335s\n",
      "3099it [02:40, 19.63it/s]\titers: 3100, epoch: 13 | loss: 0.1405624\n",
      "\tspeed: 0.0552s/iter; left time: 2493.7475s\n",
      "3199it [02:45, 19.72it/s]\titers: 3200, epoch: 13 | loss: 0.2989958\n",
      "\tspeed: 0.0506s/iter; left time: 2280.3109s\n",
      "3297it [02:50, 20.46it/s]\titers: 3300, epoch: 13 | loss: 0.2865562\n",
      "\tspeed: 0.0501s/iter; left time: 2254.9439s\n",
      "3399it [02:55, 20.23it/s]\titers: 3400, epoch: 13 | loss: 0.2200558\n",
      "\tspeed: 0.0499s/iter; left time: 2238.6323s\n",
      "3499it [03:00, 19.67it/s]\titers: 3500, epoch: 13 | loss: 0.3061857\n",
      "\tspeed: 0.0524s/iter; left time: 2346.1144s\n",
      "3599it [03:05, 19.83it/s]\titers: 3600, epoch: 13 | loss: 0.2329418\n",
      "\tspeed: 0.0504s/iter; left time: 2252.9299s\n",
      "3698it [03:10, 19.82it/s]\titers: 3700, epoch: 13 | loss: 0.2088713\n",
      "\tspeed: 0.0505s/iter; left time: 2252.7583s\n",
      "3713it [03:11, 19.41it/s]\n",
      "Epoch: 13 cost time: 191.25306177139282\n",
      "810it [00:20, 39.86it/s]\n",
      "807it [00:20, 38.48it/s]\n",
      "Epoch: 13 | Train Loss: 0.2143879 Vali Loss: 0.2751984 Test Loss: 0.3384154 MAE Loss: 0.3491280\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.765624999999999e-09\n",
      "98it [00:05, 21.35it/s]\titers: 100, epoch: 14 | loss: 0.1498742\n",
      "\tspeed: 0.4742s/iter; left time: 21080.5366s\n",
      "198it [00:10, 19.78it/s]\titers: 200, epoch: 14 | loss: 0.2558699\n",
      "\tspeed: 0.0493s/iter; left time: 2187.0570s\n",
      "299it [00:15, 16.25it/s]\titers: 300, epoch: 14 | loss: 0.3733402\n",
      "\tspeed: 0.0521s/iter; left time: 2305.2390s\n",
      "399it [00:20, 19.77it/s]\titers: 400, epoch: 14 | loss: 0.2019031\n",
      "\tspeed: 0.0508s/iter; left time: 2242.0705s\n",
      "499it [00:25, 19.77it/s]\titers: 500, epoch: 14 | loss: 0.2210713\n",
      "\tspeed: 0.0506s/iter; left time: 2227.6712s\n",
      "597it [00:30, 19.81it/s]\titers: 600, epoch: 14 | loss: 0.3025512\n",
      "\tspeed: 0.0505s/iter; left time: 2218.0385s\n",
      "699it [00:35, 19.86it/s]\titers: 700, epoch: 14 | loss: 0.2652219\n",
      "\tspeed: 0.0512s/iter; left time: 2245.3061s\n",
      "798it [00:40, 19.78it/s]\titers: 800, epoch: 14 | loss: 0.2670419\n",
      "\tspeed: 0.0506s/iter; left time: 2212.7225s\n",
      "898it [00:45, 19.76it/s]\titers: 900, epoch: 14 | loss: 0.2298132\n",
      "\tspeed: 0.0506s/iter; left time: 2206.9258s\n",
      "998it [00:50, 19.79it/s]\titers: 1000, epoch: 14 | loss: 0.2628328\n",
      "\tspeed: 0.0514s/iter; left time: 2237.0231s\n",
      "1099it [00:56, 19.71it/s]\titers: 1100, epoch: 14 | loss: 0.1212429\n",
      "\tspeed: 0.0506s/iter; left time: 2197.8687s\n",
      "1199it [01:01, 19.74it/s]\titers: 1200, epoch: 14 | loss: 0.1139229\n",
      "\tspeed: 0.0505s/iter; left time: 2191.3112s\n",
      "1299it [01:06, 17.38it/s]\titers: 1300, epoch: 14 | loss: 0.2046651\n",
      "\tspeed: 0.0518s/iter; left time: 2240.8559s\n",
      "1397it [01:11, 20.14it/s]\titers: 1400, epoch: 14 | loss: 0.2100529\n",
      "\tspeed: 0.0503s/iter; left time: 2171.2449s\n",
      "1499it [01:16, 19.75it/s]\titers: 1500, epoch: 14 | loss: 0.2055234\n",
      "\tspeed: 0.0506s/iter; left time: 2177.3949s\n",
      "1599it [01:21, 20.23it/s]\titers: 1600, epoch: 14 | loss: 0.1343850\n",
      "\tspeed: 0.0511s/iter; left time: 2197.0058s\n",
      "1698it [01:26, 23.25it/s]\titers: 1700, epoch: 14 | loss: 0.2269122\n",
      "\tspeed: 0.0459s/iter; left time: 1965.5499s\n",
      "1797it [01:30, 23.39it/s]\titers: 1800, epoch: 14 | loss: 0.1296349\n",
      "\tspeed: 0.0428s/iter; left time: 1830.3715s\n",
      "1898it [01:34, 19.89it/s]\titers: 1900, epoch: 14 | loss: 0.2247564\n",
      "\tspeed: 0.0453s/iter; left time: 1930.6915s\n",
      "1999it [01:39, 20.97it/s]\titers: 2000, epoch: 14 | loss: 0.3180870\n",
      "\tspeed: 0.0501s/iter; left time: 2130.2414s\n",
      "2098it [01:44, 23.36it/s]\titers: 2100, epoch: 14 | loss: 0.3695192\n",
      "\tspeed: 0.0429s/iter; left time: 1820.3120s\n",
      "2197it [01:48, 23.09it/s]\titers: 2200, epoch: 14 | loss: 0.1959924\n",
      "\tspeed: 0.0432s/iter; left time: 1828.0110s\n",
      "2299it [01:52, 22.97it/s]\titers: 2300, epoch: 14 | loss: 0.1423977\n",
      "\tspeed: 0.0436s/iter; left time: 1844.1152s\n",
      "2398it [01:57, 16.65it/s]\titers: 2400, epoch: 14 | loss: 0.1490587\n",
      "\tspeed: 0.0521s/iter; left time: 2196.2363s\n",
      "2498it [02:03, 19.78it/s]\titers: 2500, epoch: 14 | loss: 0.2012629\n",
      "\tspeed: 0.0506s/iter; left time: 2126.6360s\n",
      "2599it [02:08, 19.80it/s]\titers: 2600, epoch: 14 | loss: 0.3537807\n",
      "\tspeed: 0.0505s/iter; left time: 2120.7605s\n",
      "2698it [02:13, 15.01it/s]\titers: 2700, epoch: 14 | loss: 0.1654900\n",
      "\tspeed: 0.0531s/iter; left time: 2222.3710s\n",
      "2799it [02:18, 19.75it/s]\titers: 2800, epoch: 14 | loss: 0.2639041\n",
      "\tspeed: 0.0525s/iter; left time: 2192.6050s\n",
      "2898it [02:23, 19.65it/s]\titers: 2900, epoch: 14 | loss: 0.3583098\n",
      "\tspeed: 0.0513s/iter; left time: 2137.0090s\n",
      "2998it [02:28, 19.67it/s]\titers: 3000, epoch: 14 | loss: 0.2156224\n",
      "\tspeed: 0.0505s/iter; left time: 2100.6282s\n",
      "3098it [02:34, 19.81it/s]\titers: 3100, epoch: 14 | loss: 0.2677544\n",
      "\tspeed: 0.0527s/iter; left time: 2184.2843s\n",
      "3198it [02:39, 19.73it/s]\titers: 3200, epoch: 14 | loss: 0.1276074\n",
      "\tspeed: 0.0506s/iter; left time: 2092.3444s\n",
      "3298it [02:44, 19.74it/s]\titers: 3300, epoch: 14 | loss: 0.3303566\n",
      "\tspeed: 0.0509s/iter; left time: 2098.9152s\n",
      "3398it [02:49, 19.83it/s]\titers: 3400, epoch: 14 | loss: 0.0959377\n",
      "\tspeed: 0.0542s/iter; left time: 2230.9885s\n",
      "3498it [02:54, 19.83it/s]\titers: 3500, epoch: 14 | loss: 0.2245432\n",
      "\tspeed: 0.0505s/iter; left time: 2074.5718s\n",
      "3599it [02:59, 19.80it/s]\titers: 3600, epoch: 14 | loss: 0.3446808\n",
      "\tspeed: 0.0504s/iter; left time: 2066.0795s\n",
      "3698it [03:05, 19.82it/s]\titers: 3700, epoch: 14 | loss: 0.1354236\n",
      "\tspeed: 0.0552s/iter; left time: 2256.7850s\n",
      "3713it [03:06, 19.95it/s]\n",
      "Epoch: 14 cost time: 186.10573363304138\n",
      "810it [00:20, 39.98it/s]\n",
      "807it [00:20, 39.67it/s]\n",
      "Epoch: 14 | Train Loss: 0.2141329 Vali Loss: 0.2752024 Test Loss: 0.3383651 MAE Loss: 0.3489967\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.8828124999999996e-09\n",
      "99it [00:05, 18.22it/s]\titers: 100, epoch: 15 | loss: 0.1670360\n",
      "\tspeed: 0.4692s/iter; left time: 19116.8374s\n",
      "198it [00:10, 19.81it/s]\titers: 200, epoch: 15 | loss: 0.1119912\n",
      "\tspeed: 0.0508s/iter; left time: 2063.3139s\n",
      "298it [00:15, 20.17it/s]\titers: 300, epoch: 15 | loss: 0.2425915\n",
      "\tspeed: 0.0499s/iter; left time: 2021.5593s\n",
      "398it [00:20, 19.77it/s]\titers: 400, epoch: 15 | loss: 0.3128148\n",
      "\tspeed: 0.0506s/iter; left time: 2048.2559s\n",
      "498it [00:25, 19.83it/s]\titers: 500, epoch: 15 | loss: 0.1993355\n",
      "\tspeed: 0.0534s/iter; left time: 2154.8654s\n",
      "599it [00:30, 19.81it/s]\titers: 600, epoch: 15 | loss: 0.1389245\n",
      "\tspeed: 0.0506s/iter; left time: 2034.7357s\n",
      "697it [00:35, 20.04it/s]\titers: 700, epoch: 15 | loss: 0.2427554\n",
      "\tspeed: 0.0509s/iter; left time: 2044.0024s\n",
      "799it [00:41, 19.58it/s]\titers: 800, epoch: 15 | loss: 0.1876413\n",
      "\tspeed: 0.0522s/iter; left time: 2089.8164s\n",
      "898it [00:46, 19.82it/s]\titers: 900, epoch: 15 | loss: 0.1358332\n",
      "\tspeed: 0.0505s/iter; left time: 2018.5496s\n",
      "999it [00:51, 19.78it/s]\titers: 1000, epoch: 15 | loss: 0.2497003\n",
      "\tspeed: 0.0505s/iter; left time: 2013.0419s\n",
      "1098it [00:56, 18.17it/s]\titers: 1100, epoch: 15 | loss: 0.2581726\n",
      "\tspeed: 0.0522s/iter; left time: 2075.8666s\n",
      "1199it [01:01, 19.69it/s]\titers: 1200, epoch: 15 | loss: 0.2839430\n",
      "\tspeed: 0.0506s/iter; left time: 2007.8652s\n",
      "1299it [01:06, 19.79it/s]\titers: 1300, epoch: 15 | loss: 0.1749220\n",
      "\tspeed: 0.0507s/iter; left time: 2003.3614s\n",
      "1399it [01:11, 19.73it/s]\titers: 1400, epoch: 15 | loss: 0.1786063\n",
      "\tspeed: 0.0506s/iter; left time: 1994.2816s\n",
      "1498it [01:16, 19.75it/s]\titers: 1500, epoch: 15 | loss: 0.1691953\n",
      "\tspeed: 0.0523s/iter; left time: 2056.2702s\n",
      "1598it [01:22, 19.14it/s]\titers: 1600, epoch: 15 | loss: 0.2276194\n",
      "\tspeed: 0.0510s/iter; left time: 2001.1760s\n",
      "1699it [01:27, 19.75it/s]\titers: 1700, epoch: 15 | loss: 0.1205826\n",
      "\tspeed: 0.0507s/iter; left time: 1983.4500s\n",
      "1799it [01:32, 19.87it/s]\titers: 1800, epoch: 15 | loss: 0.2686595\n",
      "\tspeed: 0.0530s/iter; left time: 2068.5147s\n",
      "1899it [01:37, 19.79it/s]\titers: 1900, epoch: 15 | loss: 0.2401867\n",
      "\tspeed: 0.0505s/iter; left time: 1966.8788s\n",
      "1999it [01:42, 19.80it/s]\titers: 2000, epoch: 15 | loss: 0.1749165\n",
      "\tspeed: 0.0506s/iter; left time: 1964.4138s\n",
      "2098it [01:47, 18.57it/s]\titers: 2100, epoch: 15 | loss: 0.1586903\n",
      "\tspeed: 0.0519s/iter; left time: 2009.8073s\n",
      "2199it [01:52, 19.79it/s]\titers: 2200, epoch: 15 | loss: 0.2158994\n",
      "\tspeed: 0.0505s/iter; left time: 1952.5473s\n",
      "2299it [01:57, 19.70it/s]\titers: 2300, epoch: 15 | loss: 0.1528003\n",
      "\tspeed: 0.0506s/iter; left time: 1948.5839s\n",
      "2398it [02:02, 19.50it/s]\titers: 2400, epoch: 15 | loss: 0.2002969\n",
      "\tspeed: 0.0507s/iter; left time: 1947.8594s\n",
      "2499it [02:08, 19.75it/s]\titers: 2500, epoch: 15 | loss: 0.1985809\n",
      "\tspeed: 0.0513s/iter; left time: 1968.8741s\n",
      "2598it [02:13, 19.71it/s]\titers: 2600, epoch: 15 | loss: 0.1328027\n",
      "\tspeed: 0.0507s/iter; left time: 1938.6203s\n",
      "2698it [02:18, 19.70it/s]\titers: 2700, epoch: 15 | loss: 0.2426506\n",
      "\tspeed: 0.0490s/iter; left time: 1868.0520s\n",
      "2799it [02:23, 20.07it/s]\titers: 2800, epoch: 15 | loss: 0.3746777\n",
      "\tspeed: 0.0515s/iter; left time: 1958.5354s\n",
      "2898it [02:28, 19.79it/s]\titers: 2900, epoch: 15 | loss: 0.1586412\n",
      "\tspeed: 0.0504s/iter; left time: 1913.4167s\n",
      "2998it [02:33, 19.79it/s]\titers: 3000, epoch: 15 | loss: 0.2217188\n",
      "\tspeed: 0.0505s/iter; left time: 1912.7880s\n",
      "3099it [02:38, 19.43it/s]\titers: 3100, epoch: 15 | loss: 0.1301017\n",
      "\tspeed: 0.0528s/iter; left time: 1994.0976s\n",
      "3199it [02:43, 19.70it/s]\titers: 3200, epoch: 15 | loss: 0.2105866\n",
      "\tspeed: 0.0506s/iter; left time: 1906.1784s\n",
      "3297it [02:47, 23.23it/s]\titers: 3300, epoch: 15 | loss: 0.3344091\n",
      "\tspeed: 0.0432s/iter; left time: 1623.3049s\n",
      "3399it [02:52, 23.22it/s]\titers: 3400, epoch: 15 | loss: 0.1111617\n",
      "\tspeed: 0.0431s/iter; left time: 1613.7861s\n",
      "3499it [02:57, 19.85it/s]\titers: 3500, epoch: 15 | loss: 0.2002393\n",
      "\tspeed: 0.0487s/iter; left time: 1817.4174s\n",
      "3599it [03:02, 19.76it/s]\titers: 3600, epoch: 15 | loss: 0.1886681\n",
      "\tspeed: 0.0505s/iter; left time: 1881.9555s\n",
      "3699it [03:07, 19.88it/s]\titers: 3700, epoch: 15 | loss: 0.2317575\n",
      "\tspeed: 0.0506s/iter; left time: 1878.5926s\n",
      "3713it [03:08, 19.75it/s]\n",
      "Epoch: 15 cost time: 188.014328956604\n",
      "810it [00:20, 39.90it/s]\n",
      "807it [00:20, 39.76it/s]\n",
      "Epoch: 15 | Train Loss: 0.2141449 Vali Loss: 0.2750725 Test Loss: 0.3382852 MAE Loss: 0.3488747\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.4414062499999998e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4414062499999998e-09\n",
      "99it [00:05, 19.76it/s]\titers: 100, epoch: 16 | loss: 0.2984001\n",
      "\tspeed: 0.4697s/iter; left time: 17392.1262s\n",
      "198it [00:10, 19.78it/s]\titers: 200, epoch: 16 | loss: 0.1403915\n",
      "\tspeed: 0.0506s/iter; left time: 1868.6241s\n",
      "299it [00:15, 17.10it/s]\titers: 300, epoch: 16 | loss: 0.3536987\n",
      "\tspeed: 0.0538s/iter; left time: 1980.4517s\n",
      "398it [00:20, 19.79it/s]\titers: 400, epoch: 16 | loss: 0.6197527\n",
      "\tspeed: 0.0506s/iter; left time: 1857.1443s\n",
      "499it [00:25, 19.66it/s]\titers: 500, epoch: 16 | loss: 0.2084269\n",
      "\tspeed: 0.0505s/iter; left time: 1851.5130s\n",
      "598it [00:30, 19.85it/s]\titers: 600, epoch: 16 | loss: 0.2168186\n",
      "\tspeed: 0.0508s/iter; left time: 1857.1693s\n",
      "699it [00:36, 20.04it/s]\titers: 700, epoch: 16 | loss: 0.0685041\n",
      "\tspeed: 0.0519s/iter; left time: 1891.6293s\n",
      "799it [00:41, 19.77it/s]\titers: 800, epoch: 16 | loss: 0.1838959\n",
      "\tspeed: 0.0508s/iter; left time: 1846.1140s\n",
      "899it [00:46, 19.96it/s]\titers: 900, epoch: 16 | loss: 0.2044287\n",
      "\tspeed: 0.0504s/iter; left time: 1824.5511s\n",
      "998it [00:51, 19.68it/s]\titers: 1000, epoch: 16 | loss: 0.2324146\n",
      "\tspeed: 0.0538s/iter; left time: 1943.8746s\n",
      "1098it [00:56, 18.89it/s]\titers: 1100, epoch: 16 | loss: 0.2393718\n",
      "\tspeed: 0.0513s/iter; left time: 1848.5927s\n",
      "1198it [01:01, 19.32it/s]\titers: 1200, epoch: 16 | loss: 0.2128393\n",
      "\tspeed: 0.0508s/iter; left time: 1824.2294s\n",
      "1297it [01:07, 19.83it/s]\titers: 1300, epoch: 16 | loss: 0.2557972\n",
      "\tspeed: 0.0541s/iter; left time: 1938.9517s\n",
      "1397it [01:12, 21.22it/s]\titers: 1400, epoch: 16 | loss: 0.5032099\n",
      "\tspeed: 0.0502s/iter; left time: 1795.3047s\n",
      "1499it [01:17, 19.77it/s]\titers: 1500, epoch: 16 | loss: 0.3238356\n",
      "\tspeed: 0.0488s/iter; left time: 1738.4373s\n",
      "1598it [01:22, 19.53it/s]\titers: 1600, epoch: 16 | loss: 0.2552408\n",
      "\tspeed: 0.0539s/iter; left time: 1916.0662s\n",
      "1698it [01:27, 19.05it/s]\titers: 1700, epoch: 16 | loss: 0.1728995\n",
      "\tspeed: 0.0516s/iter; left time: 1827.9796s\n",
      "1797it [01:32, 19.62it/s]\titers: 1800, epoch: 16 | loss: 0.1428023\n",
      "\tspeed: 0.0503s/iter; left time: 1778.5994s\n",
      "1898it [01:37, 17.06it/s]\titers: 1900, epoch: 16 | loss: 0.1268628\n",
      "\tspeed: 0.0523s/iter; left time: 1841.7434s\n",
      "1998it [01:42, 20.82it/s]\titers: 2000, epoch: 16 | loss: 0.2146999\n",
      "\tspeed: 0.0494s/iter; left time: 1734.5580s\n",
      "2099it [01:47, 19.72it/s]\titers: 2100, epoch: 16 | loss: 0.1170366\n",
      "\tspeed: 0.0506s/iter; left time: 1772.2665s\n",
      "2199it [01:53, 19.78it/s]\titers: 2200, epoch: 16 | loss: 0.2232636\n",
      "\tspeed: 0.0505s/iter; left time: 1765.4808s\n",
      "2299it [01:58, 19.83it/s]\titers: 2300, epoch: 16 | loss: 0.2186326\n",
      "\tspeed: 0.0528s/iter; left time: 1838.4932s\n",
      "2398it [02:03, 19.83it/s]\titers: 2400, epoch: 16 | loss: 0.1476033\n",
      "\tspeed: 0.0508s/iter; left time: 1764.7076s\n",
      "2499it [02:08, 19.72it/s]\titers: 2500, epoch: 16 | loss: 0.1831085\n",
      "\tspeed: 0.0505s/iter; left time: 1749.5881s\n",
      "2599it [02:13, 22.65it/s]\titers: 2600, epoch: 16 | loss: 0.2675277\n",
      "\tspeed: 0.0513s/iter; left time: 1770.8905s\n",
      "2698it [02:18, 19.77it/s]\titers: 2700, epoch: 16 | loss: 0.1889829\n",
      "\tspeed: 0.0501s/iter; left time: 1724.4102s\n",
      "2798it [02:23, 19.75it/s]\titers: 2800, epoch: 16 | loss: 0.1879467\n",
      "\tspeed: 0.0508s/iter; left time: 1743.3519s\n",
      "2898it [02:28, 19.84it/s]\titers: 2900, epoch: 16 | loss: 0.3446794\n",
      "\tspeed: 0.0539s/iter; left time: 1843.5206s\n",
      "2999it [02:34, 21.94it/s]\titers: 3000, epoch: 16 | loss: 0.1843051\n",
      "\tspeed: 0.0498s/iter; left time: 1700.4738s\n",
      "3099it [02:39, 19.82it/s]\titers: 3100, epoch: 16 | loss: 0.3883787\n",
      "\tspeed: 0.0506s/iter; left time: 1720.7470s\n",
      "3198it [02:44, 20.30it/s]\titers: 3200, epoch: 16 | loss: 0.1381322\n",
      "\tspeed: 0.0509s/iter; left time: 1725.9866s\n",
      "3297it [02:48, 23.35it/s]\titers: 3300, epoch: 16 | loss: 0.1944185\n",
      "\tspeed: 0.0436s/iter; left time: 1475.5050s\n",
      "3399it [02:52, 22.74it/s]\titers: 3400, epoch: 16 | loss: 0.2766067\n",
      "\tspeed: 0.0437s/iter; left time: 1475.6311s\n",
      "3498it [02:57, 23.00it/s]\titers: 3500, epoch: 16 | loss: 0.2143622\n",
      "\tspeed: 0.0437s/iter; left time: 1470.6835s\n",
      "3597it [03:01, 22.59it/s]\titers: 3600, epoch: 16 | loss: 0.2127485\n",
      "\tspeed: 0.0453s/iter; left time: 1519.7719s\n",
      "3698it [03:06, 19.90it/s]\titers: 3700, epoch: 16 | loss: 0.1124398\n",
      "\tspeed: 0.0492s/iter; left time: 1643.7640s\n",
      "3713it [03:07, 19.80it/s]\n",
      "Epoch: 16 cost time: 187.5013267993927\n",
      "810it [00:20, 40.16it/s]\n",
      "807it [00:20, 39.96it/s]\n",
      "Epoch: 16 | Train Loss: 0.2145413 Vali Loss: 0.2750444 Test Loss: 0.3382790 MAE Loss: 0.3488765\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2207031249999999e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2207031249999999e-09\n",
      "98it [00:05, 19.75it/s]\titers: 100, epoch: 17 | loss: 0.2720570\n",
      "\tspeed: 0.4674s/iter; left time: 15573.1629s\n",
      "198it [00:10, 19.74it/s]\titers: 200, epoch: 17 | loss: 0.1892811\n",
      "\tspeed: 0.0506s/iter; left time: 1680.4567s\n",
      "298it [00:15, 19.50it/s]\titers: 300, epoch: 17 | loss: 0.1577885\n",
      "\tspeed: 0.0510s/iter; left time: 1688.1843s\n",
      "398it [00:20, 19.56it/s]\titers: 400, epoch: 17 | loss: 0.2896492\n",
      "\tspeed: 0.0534s/iter; left time: 1763.1201s\n",
      "498it [00:25, 19.89it/s]\titers: 500, epoch: 17 | loss: 0.1681932\n",
      "\tspeed: 0.0503s/iter; left time: 1657.3183s\n",
      "598it [00:31, 19.72it/s]\titers: 600, epoch: 17 | loss: 0.2047274\n",
      "\tspeed: 0.0502s/iter; left time: 1647.1277s\n",
      "698it [00:36, 17.86it/s]\titers: 700, epoch: 17 | loss: 0.1754520\n",
      "\tspeed: 0.0521s/iter; left time: 1703.2366s\n",
      "799it [00:41, 19.91it/s]\titers: 800, epoch: 17 | loss: 0.1364781\n",
      "\tspeed: 0.0504s/iter; left time: 1645.3427s\n",
      "899it [00:46, 19.70it/s]\titers: 900, epoch: 17 | loss: 0.2444662\n",
      "\tspeed: 0.0508s/iter; left time: 1651.1438s\n",
      "999it [00:51, 21.30it/s]\titers: 1000, epoch: 17 | loss: 0.2002462\n",
      "\tspeed: 0.0503s/iter; left time: 1631.5873s\n",
      "1099it [00:56, 19.79it/s]\titers: 1100, epoch: 17 | loss: 0.1378663\n",
      "\tspeed: 0.0524s/iter; left time: 1694.7944s\n",
      "1199it [01:01, 19.74it/s]\titers: 1200, epoch: 17 | loss: 0.2514335\n",
      "\tspeed: 0.0509s/iter; left time: 1638.6733s\n",
      "1298it [01:06, 19.71it/s]\titers: 1300, epoch: 17 | loss: 0.2823029\n",
      "\tspeed: 0.0505s/iter; left time: 1621.6981s\n",
      "1398it [01:11, 19.79it/s]\titers: 1400, epoch: 17 | loss: 0.2471778\n",
      "\tspeed: 0.0510s/iter; left time: 1632.0957s\n",
      "1499it [01:16, 19.79it/s]\titers: 1500, epoch: 17 | loss: 0.2575284\n",
      "\tspeed: 0.0506s/iter; left time: 1614.5173s\n",
      "1598it [01:21, 19.80it/s]\titers: 1600, epoch: 17 | loss: 0.2377668\n",
      "\tspeed: 0.0505s/iter; left time: 1608.1165s\n",
      "1698it [01:27, 19.81it/s]\titers: 1700, epoch: 17 | loss: 0.3657208\n",
      "\tspeed: 0.0511s/iter; left time: 1620.0193s\n",
      "1798it [01:32, 19.78it/s]\titers: 1800, epoch: 17 | loss: 0.2022603\n",
      "\tspeed: 0.0506s/iter; left time: 1599.0906s\n",
      "1899it [01:37, 19.74it/s]\titers: 1900, epoch: 17 | loss: 0.3383333\n",
      "\tspeed: 0.0506s/iter; left time: 1594.0995s\n",
      "1999it [01:42, 19.73it/s]\titers: 2000, epoch: 17 | loss: 0.2400903\n",
      "\tspeed: 0.0507s/iter; left time: 1592.2199s\n",
      "2098it [01:47, 19.80it/s]\titers: 2100, epoch: 17 | loss: 0.3176881\n",
      "\tspeed: 0.0517s/iter; left time: 1617.5763s\n",
      "2199it [01:52, 19.67it/s]\titers: 2200, epoch: 17 | loss: 0.2026217\n",
      "\tspeed: 0.0506s/iter; left time: 1579.4198s\n",
      "2298it [01:57, 19.74it/s]\titers: 2300, epoch: 17 | loss: 0.3491940\n",
      "\tspeed: 0.0506s/iter; left time: 1573.8818s\n",
      "2398it [02:02, 19.71it/s]\titers: 2400, epoch: 17 | loss: 0.1451234\n",
      "\tspeed: 0.0511s/iter; left time: 1586.1279s\n",
      "2498it [02:07, 19.82it/s]\titers: 2500, epoch: 17 | loss: 0.2250119\n",
      "\tspeed: 0.0507s/iter; left time: 1567.4670s\n",
      "2598it [02:12, 19.79it/s]\titers: 2600, epoch: 17 | loss: 0.4135670\n",
      "\tspeed: 0.0506s/iter; left time: 1559.0919s\n",
      "2699it [02:17, 19.77it/s]\titers: 2700, epoch: 17 | loss: 0.1465902\n",
      "\tspeed: 0.0506s/iter; left time: 1555.5275s\n",
      "2798it [02:23, 19.71it/s]\titers: 2800, epoch: 17 | loss: 0.2456832\n",
      "\tspeed: 0.0546s/iter; left time: 1672.8378s\n",
      "2898it [02:28, 19.75it/s]\titers: 2900, epoch: 17 | loss: 0.1135398\n",
      "\tspeed: 0.0505s/iter; left time: 1542.2722s\n",
      "2999it [02:33, 19.71it/s]\titers: 3000, epoch: 17 | loss: 0.2364557\n",
      "\tspeed: 0.0507s/iter; left time: 1541.3813s\n",
      "3099it [02:38, 19.76it/s]\titers: 3100, epoch: 17 | loss: 0.1714394\n",
      "\tspeed: 0.0526s/iter; left time: 1594.2006s\n",
      "3198it [02:43, 21.82it/s]\titers: 3200, epoch: 17 | loss: 0.2904107\n",
      "\tspeed: 0.0498s/iter; left time: 1505.0975s\n",
      "3299it [02:48, 22.85it/s]\titers: 3300, epoch: 17 | loss: 0.3304763\n",
      "\tspeed: 0.0470s/iter; left time: 1415.6497s\n",
      "3399it [02:52, 19.57it/s]\titers: 3400, epoch: 17 | loss: 0.1317089\n",
      "\tspeed: 0.0458s/iter; left time: 1375.2105s\n",
      "3497it [02:57, 19.71it/s]\titers: 3500, epoch: 17 | loss: 0.2292297\n",
      "\tspeed: 0.0503s/iter; left time: 1504.6381s\n",
      "3597it [03:02, 22.95it/s]\titers: 3600, epoch: 17 | loss: 0.1506853\n",
      "\tspeed: 0.0450s/iter; left time: 1340.4841s\n",
      "3698it [03:07, 19.38it/s]\titers: 3700, epoch: 17 | loss: 0.1872596\n",
      "\tspeed: 0.0512s/iter; left time: 1521.0589s\n",
      "3713it [03:08, 19.71it/s]\n",
      "Epoch: 17 cost time: 188.42199230194092\n",
      "810it [00:20, 39.07it/s]\n",
      "807it [00:20, 39.15it/s]\n",
      "Epoch: 17 | Train Loss: 0.2143012 Vali Loss: 0.2751632 Test Loss: 0.3382734 MAE Loss: 0.3488627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Total time: 65.58865458567938 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=25\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vali_loss = [0.3450846, 0.2879424, 0.2759690, 0.2754466, 0.2758530, 0.2754931, 0.2745227, 0.2755143, 0.2751592, 0.2749725, 0.2750762, 0.2751685, 0.2751984, 0.2752024, 0.2750725, 0.2750444, 0.2751632]\n",
    "tr_loss = [0.2967043, 0.2500637, 0.2323816, 0.2238862, 0.2195765, 0.2166366, 0.2155371, 0.2154173, 0.2149778, 0.2144178, 0.2145903, 0.2143507, 0.2143879, 0.2141329, 0.2141449, 0.2145413, 0.2143012]\n",
    "legend_labels = plot_train_val_loss(tr_loss, vali_loss, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant learning rate: Overfitting!\n",
    "## from 5th epoch\n",
    "## lr = 0.0001 - too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 22:54:44,749] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 22:54:45,741] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 22:54:45,741] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 22:54:47,500] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 22:54:48,016] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 22:54:48,017] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 22:54:48,017] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 22:54:48,018] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 22:54:48,018] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 22:54:48,018] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 22:54:48,018] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 22:54:48,018] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 22:54:48,018] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 22:54:48,018] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 22:54:48,635] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 22:54:48,636] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 22:54:48,636] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 244.04 GB, percent = 32.3%\n",
      "[2024-05-07 22:54:48,760] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 22:54:48,760] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 22:54:48,761] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 244.06 GB, percent = 32.3%\n",
      "[2024-05-07 22:54:48,761] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 22:54:48,881] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 22:54:48,882] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 22:54:48,882] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 244.1 GB, percent = 32.4%\n",
      "[2024-05-07 22:54:48,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 22:54:48,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 22:54:48,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 22:54:48,882] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 22:54:48,883] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7eff71ef0590>\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 22:54:48,884] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 22:54:48,885] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "97it [00:06, 14.86it/s]\titers: 100, epoch: 1 | loss: 0.3453831\n",
      "\tspeed: 0.0841s/iter; left time: 7798.7318s\n",
      "198it [00:12, 19.95it/s]\titers: 200, epoch: 1 | loss: 0.4895096\n",
      "\tspeed: 0.0591s/iter; left time: 5471.5274s\n",
      "299it [00:18, 18.63it/s]\titers: 300, epoch: 1 | loss: 0.3186773\n",
      "\tspeed: 0.0544s/iter; left time: 5037.5904s\n",
      "398it [00:23, 17.51it/s]\titers: 400, epoch: 1 | loss: 0.1978747\n",
      "\tspeed: 0.0536s/iter; left time: 4955.0893s\n",
      "499it [00:29, 14.25it/s]\titers: 500, epoch: 1 | loss: 0.2141005\n",
      "\tspeed: 0.0572s/iter; left time: 5283.3429s\n",
      "599it [00:34, 18.76it/s]\titers: 600, epoch: 1 | loss: 0.2497248\n",
      "\tspeed: 0.0547s/iter; left time: 5048.0301s\n",
      "699it [00:40, 15.87it/s]\titers: 700, epoch: 1 | loss: 0.3037808\n",
      "\tspeed: 0.0588s/iter; left time: 5421.2927s\n",
      "798it [00:46, 17.56it/s]\titers: 800, epoch: 1 | loss: 0.2965395\n",
      "\tspeed: 0.0563s/iter; left time: 5179.1048s\n",
      "899it [00:52, 17.01it/s]\titers: 900, epoch: 1 | loss: 0.2929914\n",
      "\tspeed: 0.0570s/iter; left time: 5236.2659s\n",
      "998it [00:57, 19.14it/s]\titers: 1000, epoch: 1 | loss: 0.2350700\n",
      "\tspeed: 0.0563s/iter; left time: 5173.2978s\n",
      "1097it [01:02, 19.74it/s]\titers: 1100, epoch: 1 | loss: 0.2261717\n",
      "\tspeed: 0.0516s/iter; left time: 4729.2623s\n",
      "1198it [01:08, 18.77it/s]\titers: 1200, epoch: 1 | loss: 0.1948785\n",
      "\tspeed: 0.0565s/iter; left time: 5173.8225s\n",
      "1298it [01:13, 18.90it/s]\titers: 1300, epoch: 1 | loss: 0.2060513\n",
      "\tspeed: 0.0548s/iter; left time: 5013.2938s\n",
      "1399it [01:19, 18.07it/s]\titers: 1400, epoch: 1 | loss: 0.3027360\n",
      "\tspeed: 0.0545s/iter; left time: 4978.3595s\n",
      "1499it [01:25, 18.36it/s]\titers: 1500, epoch: 1 | loss: 0.2968274\n",
      "\tspeed: 0.0576s/iter; left time: 5260.2855s\n",
      "1598it [01:30, 18.47it/s]\titers: 1600, epoch: 1 | loss: 0.2250760\n",
      "\tspeed: 0.0560s/iter; left time: 5104.5972s\n",
      "1698it [01:36, 18.61it/s]\titers: 1700, epoch: 1 | loss: 0.4196134\n",
      "\tspeed: 0.0575s/iter; left time: 5238.8907s\n",
      "1799it [01:42, 17.99it/s]\titers: 1800, epoch: 1 | loss: 0.2656998\n",
      "\tspeed: 0.0548s/iter; left time: 4991.3167s\n",
      "1899it [01:47, 16.47it/s]\titers: 1900, epoch: 1 | loss: 0.2717248\n",
      "\tspeed: 0.0585s/iter; left time: 5321.8523s\n",
      "1999it [01:53, 18.55it/s]\titers: 2000, epoch: 1 | loss: 0.2903628\n",
      "\tspeed: 0.0585s/iter; left time: 5317.1183s\n",
      "2098it [01:59, 17.95it/s]\titers: 2100, epoch: 1 | loss: 0.2171446\n",
      "\tspeed: 0.0566s/iter; left time: 5137.8269s\n",
      "2198it [02:05, 14.81it/s]\titers: 2200, epoch: 1 | loss: 0.1588612\n",
      "\tspeed: 0.0592s/iter; left time: 5363.0220s\n",
      "2299it [02:10, 18.84it/s]\titers: 2300, epoch: 1 | loss: 0.2974658\n",
      "\tspeed: 0.0531s/iter; left time: 4810.1663s\n",
      "2399it [02:16, 11.43it/s]\titers: 2400, epoch: 1 | loss: 0.6279388\n",
      "\tspeed: 0.0585s/iter; left time: 5290.2283s\n",
      "2499it [02:22, 17.82it/s]\titers: 2500, epoch: 1 | loss: 0.2356152\n",
      "\tspeed: 0.0592s/iter; left time: 5347.8131s\n",
      "2598it [02:27, 17.48it/s]\titers: 2600, epoch: 1 | loss: 0.1865506\n",
      "\tspeed: 0.0560s/iter; left time: 5051.0628s\n",
      "2698it [02:33, 19.17it/s]\titers: 2700, epoch: 1 | loss: 0.2904184\n",
      "\tspeed: 0.0578s/iter; left time: 5204.9816s\n",
      "2798it [02:39, 17.76it/s]\titers: 2800, epoch: 1 | loss: 0.1207478\n",
      "\tspeed: 0.0550s/iter; left time: 4948.9692s\n",
      "2898it [02:45, 15.01it/s]\titers: 2900, epoch: 1 | loss: 0.3947440\n",
      "\tspeed: 0.0601s/iter; left time: 5402.8848s\n",
      "2999it [02:50, 18.40it/s]\titers: 3000, epoch: 1 | loss: 0.1562074\n",
      "\tspeed: 0.0551s/iter; left time: 4947.6121s\n",
      "3099it [02:56, 18.10it/s]\titers: 3100, epoch: 1 | loss: 0.2462260\n",
      "\tspeed: 0.0544s/iter; left time: 4882.9042s\n",
      "3198it [03:01, 17.73it/s]\titers: 3200, epoch: 1 | loss: 0.4196574\n",
      "\tspeed: 0.0579s/iter; left time: 5186.7361s\n",
      "3298it [03:07, 18.49it/s]\titers: 3300, epoch: 1 | loss: 0.2683868\n",
      "\tspeed: 0.0569s/iter; left time: 5097.2512s\n",
      "3398it [03:13, 18.15it/s]\titers: 3400, epoch: 1 | loss: 0.2795202\n",
      "\tspeed: 0.0547s/iter; left time: 4887.4984s\n",
      "3498it [03:18, 18.33it/s]\titers: 3500, epoch: 1 | loss: 0.3730585\n",
      "\tspeed: 0.0577s/iter; left time: 5155.6238s\n",
      "3598it [03:24, 18.61it/s]\titers: 3600, epoch: 1 | loss: 0.4946180\n",
      "\tspeed: 0.0557s/iter; left time: 4971.6642s\n",
      "3698it [03:30, 14.15it/s]\titers: 3700, epoch: 1 | loss: 0.1875834\n",
      "\tspeed: 0.0592s/iter; left time: 5280.4881s\n",
      "3713it [03:31, 17.57it/s]\n",
      "Epoch: 1 cost time: 211.2723958492279\n",
      "810it [00:24, 33.49it/s]\n",
      "807it [00:25, 32.27it/s]\n",
      "Epoch: 1 | Train Loss: 0.2935952 Vali Loss: 0.3391897 Test Loss: 0.4202398 MAE Loss: 0.4276125\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "99it [00:05, 18.68it/s]\titers: 100, epoch: 2 | loss: 0.2418687\n",
      "\tspeed: 0.5745s/iter; left time: 51135.7332s\n",
      "198it [00:11, 18.75it/s]\titers: 200, epoch: 2 | loss: 0.1720969\n",
      "\tspeed: 0.0535s/iter; left time: 4753.5550s\n",
      "299it [00:16, 16.00it/s]\titers: 300, epoch: 2 | loss: 0.2352639\n",
      "\tspeed: 0.0534s/iter; left time: 4743.3944s\n",
      "399it [00:22, 18.26it/s]\titers: 400, epoch: 2 | loss: 0.3555230\n",
      "\tspeed: 0.0586s/iter; left time: 5196.3243s\n",
      "498it [00:27, 19.35it/s]\titers: 500, epoch: 2 | loss: 0.1599125\n",
      "\tspeed: 0.0511s/iter; left time: 4527.9083s\n",
      "598it [00:32, 20.22it/s]\titers: 600, epoch: 2 | loss: 0.4651216\n",
      "\tspeed: 0.0513s/iter; left time: 4538.5014s\n",
      "699it [00:38, 19.45it/s]\titers: 700, epoch: 2 | loss: 0.1966076\n",
      "\tspeed: 0.0566s/iter; left time: 5001.7657s\n",
      "799it [00:43, 19.26it/s]\titers: 800, epoch: 2 | loss: 0.2439831\n",
      "\tspeed: 0.0515s/iter; left time: 4547.4460s\n",
      "899it [00:48, 18.26it/s]\titers: 900, epoch: 2 | loss: 0.5808522\n",
      "\tspeed: 0.0501s/iter; left time: 4421.1404s\n",
      "999it [00:53, 19.59it/s]\titers: 1000, epoch: 2 | loss: 0.1891215\n",
      "\tspeed: 0.0532s/iter; left time: 4689.6092s\n",
      "1099it [00:58, 19.69it/s]\titers: 1100, epoch: 2 | loss: 0.2327323\n",
      "\tspeed: 0.0522s/iter; left time: 4592.2119s\n",
      "1198it [01:04, 19.54it/s]\titers: 1200, epoch: 2 | loss: 0.3200083\n",
      "\tspeed: 0.0545s/iter; left time: 4788.3640s\n",
      "1298it [01:09, 19.62it/s]\titers: 1300, epoch: 2 | loss: 0.2233901\n",
      "\tspeed: 0.0514s/iter; left time: 4510.5425s\n",
      "1398it [01:14, 19.16it/s]\titers: 1400, epoch: 2 | loss: 0.3377310\n",
      "\tspeed: 0.0526s/iter; left time: 4613.5658s\n",
      "1498it [01:20, 19.61it/s]\titers: 1500, epoch: 2 | loss: 0.1814715\n",
      "\tspeed: 0.0552s/iter; left time: 4833.7612s\n",
      "1599it [01:25, 19.71it/s]\titers: 1600, epoch: 2 | loss: 0.3546838\n",
      "\tspeed: 0.0511s/iter; left time: 4470.2127s\n",
      "1699it [01:30, 18.80it/s]\titers: 1700, epoch: 2 | loss: 0.2611647\n",
      "\tspeed: 0.0527s/iter; left time: 4603.3662s\n",
      "1797it [01:35, 19.24it/s]\titers: 1800, epoch: 2 | loss: 0.4279857\n",
      "\tspeed: 0.0537s/iter; left time: 4692.5598s\n",
      "1897it [01:40, 22.46it/s]\titers: 1900, epoch: 2 | loss: 0.2655565\n",
      "\tspeed: 0.0495s/iter; left time: 4314.4471s\n",
      "1999it [01:46, 18.16it/s]\titers: 2000, epoch: 2 | loss: 0.3471815\n",
      "\tspeed: 0.0550s/iter; left time: 4791.7346s\n",
      "2099it [01:51, 19.53it/s]\titers: 2100, epoch: 2 | loss: 0.4102014\n",
      "\tspeed: 0.0523s/iter; left time: 4552.2914s\n",
      "2198it [01:57, 17.36it/s]\titers: 2200, epoch: 2 | loss: 0.2645913\n",
      "\tspeed: 0.0545s/iter; left time: 4740.4942s\n",
      "2298it [02:02, 19.80it/s]\titers: 2300, epoch: 2 | loss: 0.4020672\n",
      "\tspeed: 0.0525s/iter; left time: 4560.9234s\n",
      "2399it [02:07, 19.76it/s]\titers: 2400, epoch: 2 | loss: 0.2513393\n",
      "\tspeed: 0.0506s/iter; left time: 4384.0311s\n",
      "2499it [02:12, 19.60it/s]\titers: 2500, epoch: 2 | loss: 0.1986751\n",
      "\tspeed: 0.0550s/iter; left time: 4764.2366s\n",
      "2599it [02:18, 19.04it/s]\titers: 2600, epoch: 2 | loss: 0.2119800\n",
      "\tspeed: 0.0519s/iter; left time: 4488.6704s\n",
      "2698it [02:23, 19.67it/s]\titers: 2700, epoch: 2 | loss: 0.3026655\n",
      "\tspeed: 0.0517s/iter; left time: 4469.9400s\n",
      "2799it [02:28, 19.62it/s]\titers: 2800, epoch: 2 | loss: 0.3176678\n",
      "\tspeed: 0.0550s/iter; left time: 4747.5060s\n",
      "2899it [02:33, 19.78it/s]\titers: 2900, epoch: 2 | loss: 0.2538693\n",
      "\tspeed: 0.0507s/iter; left time: 4373.3575s\n",
      "2997it [02:39, 12.65it/s]\titers: 3000, epoch: 2 | loss: 0.2475111\n",
      "\tspeed: 0.0549s/iter; left time: 4724.4393s\n",
      "3099it [02:44, 19.40it/s]\titers: 3100, epoch: 2 | loss: 0.2469783\n",
      "\tspeed: 0.0484s/iter; left time: 4158.8481s\n",
      "3199it [02:49, 18.50it/s]\titers: 3200, epoch: 2 | loss: 0.2245615\n",
      "\tspeed: 0.0499s/iter; left time: 4288.6052s\n",
      "3299it [02:54, 19.43it/s]\titers: 3300, epoch: 2 | loss: 0.2671059\n",
      "\tspeed: 0.0564s/iter; left time: 4836.8591s\n",
      "3399it [02:59, 19.40it/s]\titers: 3400, epoch: 2 | loss: 0.2480429\n",
      "\tspeed: 0.0510s/iter; left time: 4368.7821s\n",
      "3497it [03:04, 18.97it/s]\titers: 3500, epoch: 2 | loss: 0.2000823\n",
      "\tspeed: 0.0508s/iter; left time: 4349.9415s\n",
      "3599it [03:10, 17.62it/s]\titers: 3600, epoch: 2 | loss: 0.2011305\n",
      "\tspeed: 0.0549s/iter; left time: 4697.9129s\n",
      "3699it [03:15, 18.86it/s]\titers: 3700, epoch: 2 | loss: 0.3327176\n",
      "\tspeed: 0.0516s/iter; left time: 4407.8291s\n",
      "3713it [03:16, 18.90it/s]\n",
      "Epoch: 2 cost time: 196.45046520233154\n",
      "810it [00:21, 38.28it/s]\n",
      "807it [00:21, 37.45it/s]\n",
      "Epoch: 2 | Train Loss: 0.2679011 Vali Loss: 0.3174409 Test Loss: 0.3937229 MAE Loss: 0.3954562\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "99it [00:05, 18.67it/s]\titers: 100, epoch: 3 | loss: 0.3282441\n",
      "\tspeed: 0.5044s/iter; left time: 43027.8785s\n",
      "199it [00:10, 19.85it/s]\titers: 200, epoch: 3 | loss: 0.1607892\n",
      "\tspeed: 0.0521s/iter; left time: 4442.5581s\n",
      "298it [00:15, 19.79it/s]\titers: 300, epoch: 3 | loss: 0.4358091\n",
      "\tspeed: 0.0506s/iter; left time: 4302.2216s\n",
      "398it [00:21, 19.30it/s]\titers: 400, epoch: 3 | loss: 0.2828276\n",
      "\tspeed: 0.0547s/iter; left time: 4651.9584s\n",
      "499it [00:26, 18.59it/s]\titers: 500, epoch: 3 | loss: 0.2489062\n",
      "\tspeed: 0.0531s/iter; left time: 4505.1438s\n",
      "598it [00:32, 12.93it/s]\titers: 600, epoch: 3 | loss: 0.2174115\n",
      "\tspeed: 0.0539s/iter; left time: 4570.3574s\n",
      "699it [00:37, 20.39it/s]\titers: 700, epoch: 3 | loss: 0.1917259\n",
      "\tspeed: 0.0497s/iter; left time: 4207.4662s\n",
      "798it [00:42, 19.82it/s]\titers: 800, epoch: 3 | loss: 0.2116142\n",
      "\tspeed: 0.0508s/iter; left time: 4294.1282s\n",
      "899it [00:48, 18.11it/s]\titers: 900, epoch: 3 | loss: 0.1793914\n",
      "\tspeed: 0.0583s/iter; left time: 4927.3663s\n",
      "999it [00:53, 19.78it/s]\titers: 1000, epoch: 3 | loss: 0.1774260\n",
      "\tspeed: 0.0515s/iter; left time: 4347.0532s\n",
      "1098it [00:58, 19.81it/s]\titers: 1100, epoch: 3 | loss: 0.1894496\n",
      "\tspeed: 0.0505s/iter; left time: 4257.4804s\n",
      "1198it [01:03, 19.64it/s]\titers: 1200, epoch: 3 | loss: 0.1386558\n",
      "\tspeed: 0.0543s/iter; left time: 4574.4516s\n",
      "1298it [01:08, 19.79it/s]\titers: 1300, epoch: 3 | loss: 0.2385891\n",
      "\tspeed: 0.0517s/iter; left time: 4345.0492s\n",
      "1399it [01:14, 15.67it/s]\titers: 1400, epoch: 3 | loss: 0.2529016\n",
      "\tspeed: 0.0531s/iter; left time: 4457.9608s\n",
      "1499it [01:19, 19.81it/s]\titers: 1500, epoch: 3 | loss: 0.3669663\n",
      "\tspeed: 0.0506s/iter; left time: 4241.9890s\n",
      "1599it [01:24, 19.42it/s]\titers: 1600, epoch: 3 | loss: 0.2933620\n",
      "\tspeed: 0.0506s/iter; left time: 4241.8549s\n",
      "1698it [01:29, 19.71it/s]\titers: 1700, epoch: 3 | loss: 0.1842592\n",
      "\tspeed: 0.0554s/iter; left time: 4638.2118s\n",
      "1799it [01:34, 19.82it/s]\titers: 1800, epoch: 3 | loss: 0.1963624\n",
      "\tspeed: 0.0505s/iter; left time: 4225.2687s\n",
      "1899it [01:39, 19.70it/s]\titers: 1900, epoch: 3 | loss: 0.3485758\n",
      "\tspeed: 0.0508s/iter; left time: 4245.8130s\n",
      "1999it [01:45, 17.86it/s]\titers: 2000, epoch: 3 | loss: 0.4045347\n",
      "\tspeed: 0.0546s/iter; left time: 4555.7108s\n",
      "2098it [01:50, 19.71it/s]\titers: 2100, epoch: 3 | loss: 0.1875800\n",
      "\tspeed: 0.0516s/iter; left time: 4297.5766s\n",
      "2198it [01:55, 16.12it/s]\titers: 2200, epoch: 3 | loss: 0.2415785\n",
      "\tspeed: 0.0514s/iter; left time: 4273.2955s\n",
      "2298it [02:01, 19.72it/s]\titers: 2300, epoch: 3 | loss: 0.1808403\n",
      "\tspeed: 0.0535s/iter; left time: 4448.1111s\n",
      "2399it [02:06, 14.49it/s]\titers: 2400, epoch: 3 | loss: 0.4576998\n",
      "\tspeed: 0.0556s/iter; left time: 4613.9528s\n",
      "2498it [02:12, 18.48it/s]\titers: 2500, epoch: 3 | loss: 0.1502730\n",
      "\tspeed: 0.0576s/iter; left time: 4771.4112s\n",
      "2599it [02:17, 17.58it/s]\titers: 2600, epoch: 3 | loss: 0.4159748\n",
      "\tspeed: 0.0554s/iter; left time: 4587.4956s\n",
      "2699it [02:23, 17.38it/s]\titers: 2700, epoch: 3 | loss: 0.2282728\n",
      "\tspeed: 0.0524s/iter; left time: 4335.7871s\n",
      "2798it [02:28, 19.37it/s]\titers: 2800, epoch: 3 | loss: 0.1891369\n",
      "\tspeed: 0.0581s/iter; left time: 4799.2258s\n",
      "2898it [02:34, 19.79it/s]\titers: 2900, epoch: 3 | loss: 0.2230300\n",
      "\tspeed: 0.0508s/iter; left time: 4192.7405s\n",
      "2998it [02:39, 15.15it/s]\titers: 3000, epoch: 3 | loss: 0.2270097\n",
      "\tspeed: 0.0537s/iter; left time: 4426.2516s\n",
      "3099it [02:45, 12.87it/s]\titers: 3100, epoch: 3 | loss: 0.2553735\n",
      "\tspeed: 0.0560s/iter; left time: 4609.2177s\n",
      "3197it [02:50, 19.22it/s]\titers: 3200, epoch: 3 | loss: 0.2734783\n",
      "\tspeed: 0.0514s/iter; left time: 4225.0770s\n",
      "3297it [02:55, 23.18it/s]\titers: 3300, epoch: 3 | loss: 0.3010468\n",
      "\tspeed: 0.0502s/iter; left time: 4119.3580s\n",
      "3399it [03:00, 19.70it/s]\titers: 3400, epoch: 3 | loss: 0.2343423\n",
      "\tspeed: 0.0503s/iter; left time: 4122.6698s\n",
      "3499it [03:05, 19.45it/s]\titers: 3500, epoch: 3 | loss: 0.2768264\n",
      "\tspeed: 0.0524s/iter; left time: 4290.5460s\n",
      "3598it [03:10, 19.73it/s]\titers: 3600, epoch: 3 | loss: 0.4186431\n",
      "\tspeed: 0.0537s/iter; left time: 4393.7478s\n",
      "3698it [03:15, 19.58it/s]\titers: 3700, epoch: 3 | loss: 0.1849582\n",
      "\tspeed: 0.0505s/iter; left time: 4128.3789s\n",
      "3713it [03:16, 18.88it/s]\n",
      "Epoch: 3 cost time: 196.63840174674988\n",
      "810it [00:21, 38.21it/s]\n",
      "807it [00:21, 37.77it/s]\n",
      "Epoch: 3 | Train Loss: 0.2612842 Vali Loss: 0.3056702 Test Loss: 0.3784787 MAE Loss: 0.3947761\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "99it [00:05, 19.84it/s]\titers: 100, epoch: 4 | loss: 0.2752561\n",
      "\tspeed: 0.5049s/iter; left time: 41189.9512s\n",
      "198it [00:10, 19.72it/s]\titers: 200, epoch: 4 | loss: 0.1662870\n",
      "\tspeed: 0.0509s/iter; left time: 4148.8541s\n",
      "299it [00:16, 14.61it/s]\titers: 300, epoch: 4 | loss: 0.1989927\n",
      "\tspeed: 0.0545s/iter; left time: 4432.7494s\n",
      "398it [00:21, 19.63it/s]\titers: 400, epoch: 4 | loss: 0.3864049\n",
      "\tspeed: 0.0542s/iter; left time: 4408.6367s\n",
      "499it [00:27, 21.20it/s]\titers: 500, epoch: 4 | loss: 0.4274825\n",
      "\tspeed: 0.0517s/iter; left time: 4196.3270s\n",
      "598it [00:32, 19.00it/s]\titers: 600, epoch: 4 | loss: 0.1727400\n",
      "\tspeed: 0.0559s/iter; left time: 4528.7376s\n",
      "698it [00:37, 20.96it/s]\titers: 700, epoch: 4 | loss: 0.3009813\n",
      "\tspeed: 0.0518s/iter; left time: 4192.9310s\n",
      "799it [00:43, 19.31it/s]\titers: 800, epoch: 4 | loss: 0.2863793\n",
      "\tspeed: 0.0549s/iter; left time: 4441.3209s\n",
      "897it [00:48, 18.18it/s]\titers: 900, epoch: 4 | loss: 0.2228332\n",
      "\tspeed: 0.0569s/iter; left time: 4597.9146s\n",
      "999it [00:54, 19.69it/s]\titers: 1000, epoch: 4 | loss: 0.3278057\n",
      "\tspeed: 0.0533s/iter; left time: 4298.0773s\n",
      "1099it [00:59, 18.92it/s]\titers: 1100, epoch: 4 | loss: 0.1996888\n",
      "\tspeed: 0.0557s/iter; left time: 4488.1744s\n",
      "1198it [01:04, 19.81it/s]\titers: 1200, epoch: 4 | loss: 0.3974451\n",
      "\tspeed: 0.0507s/iter; left time: 4077.5207s\n",
      "1299it [01:09, 19.73it/s]\titers: 1300, epoch: 4 | loss: 0.1866083\n",
      "\tspeed: 0.0505s/iter; left time: 4063.0324s\n",
      "1399it [01:15, 19.56it/s]\titers: 1400, epoch: 4 | loss: 0.3914025\n",
      "\tspeed: 0.0556s/iter; left time: 4460.3958s\n",
      "1499it [01:21, 19.16it/s]\titers: 1500, epoch: 4 | loss: 0.2423816\n",
      "\tspeed: 0.0571s/iter; left time: 4580.1617s\n",
      "1599it [01:26, 17.58it/s]\titers: 1600, epoch: 4 | loss: 0.2016351\n",
      "\tspeed: 0.0560s/iter; left time: 4485.2112s\n",
      "1698it [01:31, 19.80it/s]\titers: 1700, epoch: 4 | loss: 0.3021603\n",
      "\tspeed: 0.0505s/iter; left time: 4038.2357s\n",
      "1799it [01:36, 19.74it/s]\titers: 1800, epoch: 4 | loss: 0.1478353\n",
      "\tspeed: 0.0506s/iter; left time: 4042.5357s\n",
      "1899it [01:42, 19.77it/s]\titers: 1900, epoch: 4 | loss: 0.3833738\n",
      "\tspeed: 0.0587s/iter; left time: 4684.9018s\n",
      "1998it [01:47, 20.65it/s]\titers: 2000, epoch: 4 | loss: 0.1400331\n",
      "\tspeed: 0.0495s/iter; left time: 3947.1183s\n",
      "2099it [01:52, 20.95it/s]\titers: 2100, epoch: 4 | loss: 0.3207841\n",
      "\tspeed: 0.0480s/iter; left time: 3821.3408s\n",
      "2199it [01:58, 15.05it/s]\titers: 2200, epoch: 4 | loss: 0.3062786\n",
      "\tspeed: 0.0553s/iter; left time: 4399.2043s\n",
      "2298it [02:02, 23.25it/s]\titers: 2300, epoch: 4 | loss: 0.2366618\n",
      "\tspeed: 0.0449s/iter; left time: 3560.8048s\n",
      "2398it [02:07, 17.89it/s]\titers: 2400, epoch: 4 | loss: 0.2313027\n",
      "\tspeed: 0.0471s/iter; left time: 3731.4346s\n",
      "2499it [02:12, 21.09it/s]\titers: 2500, epoch: 4 | loss: 0.2749301\n",
      "\tspeed: 0.0522s/iter; left time: 4130.0929s\n",
      "2597it [02:17, 14.36it/s]\titers: 2600, epoch: 4 | loss: 0.2232432\n",
      "\tspeed: 0.0550s/iter; left time: 4348.4755s\n",
      "2699it [02:23, 19.51it/s]\titers: 2700, epoch: 4 | loss: 0.3332516\n",
      "\tspeed: 0.0533s/iter; left time: 4207.4274s\n",
      "2797it [02:28, 21.25it/s]\titers: 2800, epoch: 4 | loss: 0.2650799\n",
      "\tspeed: 0.0501s/iter; left time: 3950.1871s\n",
      "2898it [02:33, 21.48it/s]\titers: 2900, epoch: 4 | loss: 0.2090807\n",
      "\tspeed: 0.0489s/iter; left time: 3849.4370s\n",
      "2998it [02:38, 19.79it/s]\titers: 3000, epoch: 4 | loss: 0.1963132\n",
      "\tspeed: 0.0558s/iter; left time: 4387.6499s\n",
      "3098it [02:43, 19.80it/s]\titers: 3100, epoch: 4 | loss: 0.2552625\n",
      "\tspeed: 0.0505s/iter; left time: 3970.2038s\n",
      "3198it [02:48, 17.04it/s]\titers: 3200, epoch: 4 | loss: 0.1565856\n",
      "\tspeed: 0.0512s/iter; left time: 4019.2570s\n",
      "3298it [02:54, 16.80it/s]\titers: 3300, epoch: 4 | loss: 0.2542101\n",
      "\tspeed: 0.0527s/iter; left time: 4127.7654s\n",
      "3399it [02:59, 19.78it/s]\titers: 3400, epoch: 4 | loss: 0.4009456\n",
      "\tspeed: 0.0504s/iter; left time: 3948.0580s\n",
      "3498it [03:04, 18.13it/s]\titers: 3500, epoch: 4 | loss: 0.1301050\n",
      "\tspeed: 0.0525s/iter; left time: 4106.7200s\n",
      "3598it [03:09, 20.38it/s]\titers: 3600, epoch: 4 | loss: 0.2703345\n",
      "\tspeed: 0.0479s/iter; left time: 3740.7679s\n",
      "3699it [03:14, 16.39it/s]\titers: 3700, epoch: 4 | loss: 0.1079354\n",
      "\tspeed: 0.0523s/iter; left time: 4078.5544s\n",
      "3713it [03:15, 19.01it/s]\n",
      "Epoch: 4 cost time: 195.3293993473053\n",
      "810it [00:20, 38.88it/s]\n",
      "807it [00:21, 36.83it/s]\n",
      "Epoch: 4 | Train Loss: 0.2564711 Vali Loss: 0.3051671 Test Loss: 0.3851433 MAE Loss: 0.3975760\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "98it [00:05, 18.24it/s]\titers: 100, epoch: 5 | loss: 0.5290933\n",
      "\tspeed: 0.5016s/iter; left time: 39063.1447s\n",
      "199it [00:10, 21.10it/s]\titers: 200, epoch: 5 | loss: 0.1953999\n",
      "\tspeed: 0.0477s/iter; left time: 3711.5682s\n",
      "298it [00:15, 19.32it/s]\titers: 300, epoch: 5 | loss: 0.1424686\n",
      "\tspeed: 0.0540s/iter; left time: 4195.2244s\n",
      "398it [00:20, 19.93it/s]\titers: 400, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0504s/iter; left time: 3906.9216s\n",
      "499it [00:25, 19.76it/s]\titers: 500, epoch: 5 | loss: 0.2118587\n",
      "\tspeed: 0.0502s/iter; left time: 3888.0703s\n",
      "599it [00:31, 21.65it/s]\titers: 600, epoch: 5 | loss: 0.4407884\n",
      "\tspeed: 0.0553s/iter; left time: 4276.0660s\n",
      "698it [00:35, 22.98it/s]\titers: 700, epoch: 5 | loss: 0.3620656\n",
      "\tspeed: 0.0436s/iter; left time: 3370.6429s\n",
      "797it [00:39, 22.92it/s]\titers: 800, epoch: 5 | loss: 0.1634165\n",
      "\tspeed: 0.0436s/iter; left time: 3366.0252s\n",
      "897it [00:44, 22.57it/s]\titers: 900, epoch: 5 | loss: 0.2172196\n",
      "\tspeed: 0.0479s/iter; left time: 3692.1707s\n",
      "998it [00:49, 19.33it/s]\titers: 1000, epoch: 5 | loss: 0.4487520\n",
      "\tspeed: 0.0488s/iter; left time: 3757.3210s\n",
      "1098it [00:54, 23.04it/s]\titers: 1100, epoch: 5 | loss: 0.4040782\n",
      "\tspeed: 0.0457s/iter; left time: 3509.9975s\n",
      "1198it [00:59, 19.82it/s]\titers: 1200, epoch: 5 | loss: 0.3455753\n",
      "\tspeed: 0.0503s/iter; left time: 3863.2798s\n",
      "1298it [01:04, 19.79it/s]\titers: 1300, epoch: 5 | loss: 0.2289917\n",
      "\tspeed: 0.0506s/iter; left time: 3882.0135s\n",
      "1398it [01:09, 19.82it/s]\titers: 1400, epoch: 5 | loss: 0.2337640\n",
      "\tspeed: 0.0548s/iter; left time: 4195.5206s\n",
      "1499it [01:15, 19.79it/s]\titers: 1500, epoch: 5 | loss: 0.2656432\n",
      "\tspeed: 0.0535s/iter; left time: 4092.3451s\n",
      "1598it [01:20, 19.74it/s]\titers: 1600, epoch: 5 | loss: 0.2298183\n",
      "\tspeed: 0.0506s/iter; left time: 3862.4258s\n",
      "1697it [01:25, 12.83it/s]\titers: 1700, epoch: 5 | loss: 0.1843432\n",
      "\tspeed: 0.0582s/iter; left time: 4436.5448s\n",
      "1799it [01:30, 19.66it/s]\titers: 1800, epoch: 5 | loss: 0.2042810\n",
      "\tspeed: 0.0506s/iter; left time: 3851.0549s\n",
      "1898it [01:35, 19.76it/s]\titers: 1900, epoch: 5 | loss: 0.1626534\n",
      "\tspeed: 0.0506s/iter; left time: 3846.0778s\n",
      "1998it [01:41, 18.99it/s]\titers: 2000, epoch: 5 | loss: 0.4736218\n",
      "\tspeed: 0.0543s/iter; left time: 4126.2396s\n",
      "2098it [01:46, 19.78it/s]\titers: 2100, epoch: 5 | loss: 0.3584844\n",
      "\tspeed: 0.0540s/iter; left time: 4095.6508s\n",
      "2199it [01:51, 19.75it/s]\titers: 2200, epoch: 5 | loss: 0.2907690\n",
      "\tspeed: 0.0505s/iter; left time: 3823.6446s\n",
      "2299it [01:57, 19.63it/s]\titers: 2300, epoch: 5 | loss: 0.2887464\n",
      "\tspeed: 0.0532s/iter; left time: 4024.3140s\n",
      "2398it [02:02, 19.19it/s]\titers: 2400, epoch: 5 | loss: 0.4347079\n",
      "\tspeed: 0.0517s/iter; left time: 3904.1254s\n",
      "2499it [02:07, 17.34it/s]\titers: 2500, epoch: 5 | loss: 0.1895362\n",
      "\tspeed: 0.0534s/iter; left time: 4027.8357s\n",
      "2599it [02:12, 19.78it/s]\titers: 2600, epoch: 5 | loss: 0.2646768\n",
      "\tspeed: 0.0505s/iter; left time: 3809.2355s\n",
      "2699it [02:17, 19.81it/s]\titers: 2700, epoch: 5 | loss: 0.2032963\n",
      "\tspeed: 0.0506s/iter; left time: 3805.7273s\n",
      "2799it [02:23, 19.77it/s]\titers: 2800, epoch: 5 | loss: 0.1702503\n",
      "\tspeed: 0.0543s/iter; left time: 4080.1393s\n",
      "2899it [02:28, 19.80it/s]\titers: 2900, epoch: 5 | loss: 0.2277387\n",
      "\tspeed: 0.0505s/iter; left time: 3791.0438s\n",
      "2998it [02:33, 19.82it/s]\titers: 3000, epoch: 5 | loss: 0.1420409\n",
      "\tspeed: 0.0510s/iter; left time: 3822.2443s\n",
      "3099it [02:39, 17.58it/s]\titers: 3100, epoch: 5 | loss: 0.1827815\n",
      "\tspeed: 0.0558s/iter; left time: 4174.3416s\n",
      "3198it [02:44, 17.60it/s]\titers: 3200, epoch: 5 | loss: 0.1827106\n",
      "\tspeed: 0.0566s/iter; left time: 4232.6490s\n",
      "3299it [02:50, 19.73it/s]\titers: 3300, epoch: 5 | loss: 0.2739816\n",
      "\tspeed: 0.0567s/iter; left time: 4236.9396s\n",
      "3399it [02:55, 14.51it/s]\titers: 3400, epoch: 5 | loss: 0.2925797\n",
      "\tspeed: 0.0566s/iter; left time: 4223.6947s\n",
      "3499it [03:01, 16.40it/s]\titers: 3500, epoch: 5 | loss: 0.2444163\n",
      "\tspeed: 0.0595s/iter; left time: 4433.7349s\n",
      "3597it [03:07, 20.01it/s]\titers: 3600, epoch: 5 | loss: 0.3811908\n",
      "\tspeed: 0.0579s/iter; left time: 4304.0072s\n",
      "3699it [03:13, 17.07it/s]\titers: 3700, epoch: 5 | loss: 0.1699382\n",
      "\tspeed: 0.0562s/iter; left time: 4177.2015s\n",
      "3713it [03:14, 19.11it/s]\n",
      "Epoch: 5 cost time: 194.2919409275055\n",
      "810it [00:21, 38.09it/s]\n",
      "807it [00:21, 38.34it/s]\n",
      "Epoch: 5 | Train Loss: 0.2537823 Vali Loss: 0.3126151 Test Loss: 0.3874267 MAE Loss: 0.3919569\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "98it [00:05, 21.66it/s]\titers: 100, epoch: 6 | loss: 0.2887514\n",
      "\tspeed: 0.4888s/iter; left time: 36250.4606s\n",
      "198it [00:10, 19.82it/s]\titers: 200, epoch: 6 | loss: 0.3077810\n",
      "\tspeed: 0.0503s/iter; left time: 3723.9371s\n",
      "298it [00:16, 19.50it/s]\titers: 300, epoch: 6 | loss: 0.1618022\n",
      "\tspeed: 0.0573s/iter; left time: 4240.9528s\n",
      "398it [00:22, 16.57it/s]\titers: 400, epoch: 6 | loss: 0.2989357\n",
      "\tspeed: 0.0581s/iter; left time: 4290.9764s\n",
      "497it [00:27, 20.07it/s]\titers: 500, epoch: 6 | loss: 0.1989110\n",
      "\tspeed: 0.0523s/iter; left time: 3858.5476s\n",
      "598it [00:32, 16.67it/s]\titers: 600, epoch: 6 | loss: 0.2265774\n",
      "\tspeed: 0.0551s/iter; left time: 4057.3577s\n",
      "699it [00:38, 18.10it/s]\titers: 700, epoch: 6 | loss: 0.1525140\n",
      "\tspeed: 0.0595s/iter; left time: 4380.2890s\n",
      "798it [00:44, 19.02it/s]\titers: 800, epoch: 6 | loss: 0.2310233\n",
      "\tspeed: 0.0574s/iter; left time: 4219.7089s\n",
      "897it [00:49, 19.73it/s]\titers: 900, epoch: 6 | loss: 0.2050667\n",
      "\tspeed: 0.0504s/iter; left time: 3696.7322s\n",
      "998it [00:54, 19.76it/s]\titers: 1000, epoch: 6 | loss: 0.3073978\n",
      "\tspeed: 0.0533s/iter; left time: 3905.6720s\n",
      "1099it [01:00, 19.67it/s]\titers: 1100, epoch: 6 | loss: 0.1514832\n",
      "\tspeed: 0.0554s/iter; left time: 4050.1665s\n",
      "1199it [01:05, 19.77it/s]\titers: 1200, epoch: 6 | loss: 0.2657577\n",
      "\tspeed: 0.0506s/iter; left time: 3694.7858s\n",
      "1299it [01:10, 22.68it/s]\titers: 1300, epoch: 6 | loss: 0.2141628\n",
      "\tspeed: 0.0477s/iter; left time: 3483.6351s\n",
      "1399it [01:16, 19.74it/s]\titers: 1400, epoch: 6 | loss: 0.3479674\n",
      "\tspeed: 0.0576s/iter; left time: 4198.7739s\n",
      "1499it [01:21, 19.82it/s]\titers: 1500, epoch: 6 | loss: 0.2475664\n",
      "\tspeed: 0.0506s/iter; left time: 3680.1833s\n",
      "1598it [01:26, 13.07it/s]\titers: 1600, epoch: 6 | loss: 0.3973359\n",
      "\tspeed: 0.0543s/iter; left time: 3949.0493s\n",
      "1698it [01:31, 18.13it/s]\titers: 1700, epoch: 6 | loss: 0.2747901\n",
      "\tspeed: 0.0514s/iter; left time: 3728.9987s\n",
      "1798it [01:37, 19.77it/s]\titers: 1800, epoch: 6 | loss: 0.2978145\n",
      "\tspeed: 0.0544s/iter; left time: 3943.7582s\n",
      "1898it [01:42, 19.79it/s]\titers: 1900, epoch: 6 | loss: 0.2296276\n",
      "\tspeed: 0.0540s/iter; left time: 3905.5166s\n",
      "1997it [01:47, 19.74it/s]\titers: 2000, epoch: 6 | loss: 0.2928759\n",
      "\tspeed: 0.0505s/iter; left time: 3652.1079s\n",
      "2099it [01:52, 19.79it/s]\titers: 2100, epoch: 6 | loss: 0.2158156\n",
      "\tspeed: 0.0517s/iter; left time: 3728.1340s\n",
      "2198it [01:58, 19.70it/s]\titers: 2200, epoch: 6 | loss: 0.1808515\n",
      "\tspeed: 0.0547s/iter; left time: 3938.4325s\n",
      "2299it [02:03, 19.77it/s]\titers: 2300, epoch: 6 | loss: 0.1629061\n",
      "\tspeed: 0.0515s/iter; left time: 3707.9541s\n",
      "2397it [02:08, 18.53it/s]\titers: 2400, epoch: 6 | loss: 0.1972053\n",
      "\tspeed: 0.0513s/iter; left time: 3687.8292s\n",
      "2498it [02:13, 19.83it/s]\titers: 2500, epoch: 6 | loss: 0.2615496\n",
      "\tspeed: 0.0549s/iter; left time: 3941.8329s\n",
      "2597it [02:18, 23.20it/s]\titers: 2600, epoch: 6 | loss: 0.3470126\n",
      "\tspeed: 0.0453s/iter; left time: 3244.6072s\n",
      "2699it [02:23, 18.72it/s]\titers: 2700, epoch: 6 | loss: 0.1814590\n",
      "\tspeed: 0.0518s/iter; left time: 3703.4605s\n",
      "2799it [02:28, 19.76it/s]\titers: 2800, epoch: 6 | loss: 0.1504168\n",
      "\tspeed: 0.0505s/iter; left time: 3611.6240s\n",
      "2898it [02:33, 19.82it/s]\titers: 2900, epoch: 6 | loss: 0.2059671\n",
      "\tspeed: 0.0519s/iter; left time: 3707.0419s\n",
      "2998it [02:39, 19.77it/s]\titers: 3000, epoch: 6 | loss: 0.2572268\n",
      "\tspeed: 0.0542s/iter; left time: 3861.7237s\n",
      "3099it [02:44, 19.78it/s]\titers: 3100, epoch: 6 | loss: 0.2464277\n",
      "\tspeed: 0.0507s/iter; left time: 3609.9741s\n",
      "3199it [02:49, 17.40it/s]\titers: 3200, epoch: 6 | loss: 0.2800309\n",
      "\tspeed: 0.0522s/iter; left time: 3711.8434s\n",
      "3299it [02:55, 18.62it/s]\titers: 3300, epoch: 6 | loss: 0.2469424\n",
      "\tspeed: 0.0575s/iter; left time: 4082.0662s\n",
      "3397it [03:00, 18.88it/s]\titers: 3400, epoch: 6 | loss: 0.3510529\n",
      "\tspeed: 0.0528s/iter; left time: 3742.9043s\n",
      "3498it [03:06, 21.08it/s]\titers: 3500, epoch: 6 | loss: 0.2105810\n",
      "\tspeed: 0.0547s/iter; left time: 3867.4054s\n",
      "3599it [03:11, 18.56it/s]\titers: 3600, epoch: 6 | loss: 0.2370605\n",
      "\tspeed: 0.0524s/iter; left time: 3705.0047s\n",
      "3698it [03:16, 19.75it/s]\titers: 3700, epoch: 6 | loss: 0.1468817\n",
      "\tspeed: 0.0506s/iter; left time: 3568.3747s\n",
      "3713it [03:17, 18.82it/s]\n",
      "Epoch: 6 cost time: 197.2441487312317\n",
      "810it [00:21, 38.41it/s]\n",
      "807it [00:20, 39.64it/s]\n",
      "Epoch: 6 | Train Loss: 0.2508688 Vali Loss: 0.2996251 Test Loss: 0.3731943 MAE Loss: 0.3894249\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "98it [00:05, 19.38it/s]\titers: 100, epoch: 7 | loss: 0.2804155\n",
      "\tspeed: 0.4929s/iter; left time: 34721.7746s\n",
      "198it [00:10, 19.75it/s]\titers: 200, epoch: 7 | loss: 0.1866183\n",
      "\tspeed: 0.0508s/iter; left time: 3575.6083s\n",
      "298it [00:16, 18.00it/s]\titers: 300, epoch: 7 | loss: 0.1266267\n",
      "\tspeed: 0.0550s/iter; left time: 3865.0897s\n",
      "399it [00:21, 19.79it/s]\titers: 400, epoch: 7 | loss: 0.2547795\n",
      "\tspeed: 0.0518s/iter; left time: 3633.2505s\n",
      "497it [00:26, 23.13it/s]\titers: 500, epoch: 7 | loss: 0.2946172\n",
      "\tspeed: 0.0455s/iter; left time: 3187.5865s\n",
      "599it [00:30, 22.73it/s]\titers: 600, epoch: 7 | loss: 0.2139748\n",
      "\tspeed: 0.0478s/iter; left time: 3340.7033s\n",
      "698it [00:35, 21.62it/s]\titers: 700, epoch: 7 | loss: 0.4054187\n",
      "\tspeed: 0.0452s/iter; left time: 3156.8312s\n",
      "799it [00:40, 19.78it/s]\titers: 800, epoch: 7 | loss: 0.2461789\n",
      "\tspeed: 0.0490s/iter; left time: 3419.0656s\n",
      "898it [00:46, 19.53it/s]\titers: 900, epoch: 7 | loss: 0.1583218\n",
      "\tspeed: 0.0582s/iter; left time: 4056.1807s\n",
      "998it [00:51, 19.76it/s]\titers: 1000, epoch: 7 | loss: 0.3726473\n",
      "\tspeed: 0.0506s/iter; left time: 3517.1410s\n",
      "1099it [00:56, 16.77it/s]\titers: 1100, epoch: 7 | loss: 0.1457517\n",
      "\tspeed: 0.0545s/iter; left time: 3785.1561s\n",
      "1199it [01:01, 19.74it/s]\titers: 1200, epoch: 7 | loss: 0.1821498\n",
      "\tspeed: 0.0506s/iter; left time: 3507.4428s\n",
      "1298it [01:07, 19.76it/s]\titers: 1300, epoch: 7 | loss: 0.2638802\n",
      "\tspeed: 0.0554s/iter; left time: 3835.9337s\n",
      "1398it [01:12, 19.40it/s]\titers: 1400, epoch: 7 | loss: 0.3284431\n",
      "\tspeed: 0.0545s/iter; left time: 3770.8711s\n",
      "1499it [01:17, 19.91it/s]\titers: 1500, epoch: 7 | loss: 0.2858032\n",
      "\tspeed: 0.0499s/iter; left time: 3448.5320s\n",
      "1598it [01:22, 18.27it/s]\titers: 1600, epoch: 7 | loss: 0.1778256\n",
      "\tspeed: 0.0517s/iter; left time: 3563.8861s\n",
      "1697it [01:28, 19.75it/s]\titers: 1700, epoch: 7 | loss: 0.2154372\n",
      "\tspeed: 0.0540s/iter; left time: 3719.3060s\n",
      "1798it [01:33, 19.80it/s]\titers: 1800, epoch: 7 | loss: 0.2504506\n",
      "\tspeed: 0.0505s/iter; left time: 3475.2065s\n",
      "1898it [01:38, 18.43it/s]\titers: 1900, epoch: 7 | loss: 0.3351417\n",
      "\tspeed: 0.0545s/iter; left time: 3742.2689s\n",
      "1997it [01:44, 19.66it/s]\titers: 2000, epoch: 7 | loss: 0.2637779\n",
      "\tspeed: 0.0530s/iter; left time: 3633.9419s\n",
      "2099it [01:48, 22.96it/s]\titers: 2100, epoch: 7 | loss: 0.2311959\n",
      "\tspeed: 0.0433s/iter; left time: 2965.4882s\n",
      "2198it [01:53, 20.23it/s]\titers: 2200, epoch: 7 | loss: 0.2195098\n",
      "\tspeed: 0.0508s/iter; left time: 3472.8793s\n",
      "2299it [01:58, 19.71it/s]\titers: 2300, epoch: 7 | loss: 0.1690411\n",
      "\tspeed: 0.0508s/iter; left time: 3464.8261s\n",
      "2399it [02:04, 19.70it/s]\titers: 2400, epoch: 7 | loss: 0.2683022\n",
      "\tspeed: 0.0548s/iter; left time: 3733.1515s\n",
      "2499it [02:09, 19.89it/s]\titers: 2500, epoch: 7 | loss: 0.2175905\n",
      "\tspeed: 0.0542s/iter; left time: 3685.4081s\n",
      "2599it [02:14, 19.79it/s]\titers: 2600, epoch: 7 | loss: 0.1736453\n",
      "\tspeed: 0.0505s/iter; left time: 3434.0627s\n",
      "2698it [02:20, 19.54it/s]\titers: 2700, epoch: 7 | loss: 0.3157205\n",
      "\tspeed: 0.0552s/iter; left time: 3743.5043s\n",
      "2798it [02:24, 19.78it/s]\titers: 2800, epoch: 7 | loss: 0.2212453\n",
      "\tspeed: 0.0493s/iter; left time: 3337.8807s\n",
      "2897it [02:29, 20.08it/s]\titers: 2900, epoch: 7 | loss: 0.2835606\n",
      "\tspeed: 0.0505s/iter; left time: 3414.7608s\n",
      "2998it [02:35, 19.80it/s]\titers: 3000, epoch: 7 | loss: 0.2609344\n",
      "\tspeed: 0.0539s/iter; left time: 3641.4765s\n",
      "3098it [02:40, 19.97it/s]\titers: 3100, epoch: 7 | loss: 0.2540432\n",
      "\tspeed: 0.0550s/iter; left time: 3709.5688s\n",
      "3198it [02:46, 14.79it/s]\titers: 3200, epoch: 7 | loss: 0.1964737\n",
      "\tspeed: 0.0532s/iter; left time: 3580.3661s\n",
      "3297it [02:51, 20.96it/s]\titers: 3300, epoch: 7 | loss: 0.2640092\n",
      "\tspeed: 0.0492s/iter; left time: 3310.8771s\n",
      "3399it [02:56, 18.54it/s]\titers: 3400, epoch: 7 | loss: 0.2896124\n",
      "\tspeed: 0.0505s/iter; left time: 3391.8125s\n",
      "3498it [03:01, 18.15it/s]\titers: 3500, epoch: 7 | loss: 0.2168476\n",
      "\tspeed: 0.0530s/iter; left time: 3554.2003s\n",
      "3598it [03:06, 19.77it/s]\titers: 3600, epoch: 7 | loss: 0.2042206\n",
      "\tspeed: 0.0512s/iter; left time: 3429.3793s\n",
      "3698it [03:11, 19.84it/s]\titers: 3700, epoch: 7 | loss: 0.4239494\n",
      "\tspeed: 0.0505s/iter; left time: 3373.4755s\n",
      "3713it [03:12, 19.29it/s]\n",
      "Epoch: 7 cost time: 192.526264667511\n",
      "810it [00:20, 38.57it/s]\n",
      "807it [00:21, 38.35it/s]\n",
      "Epoch: 7 | Train Loss: 0.2508506 Vali Loss: 0.3007074 Test Loss: 0.3686368 MAE Loss: 0.3824610\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "98it [00:05, 19.44it/s]\titers: 100, epoch: 8 | loss: 0.3221764\n",
      "\tspeed: 0.4856s/iter; left time: 32408.6095s\n",
      "199it [00:10, 19.83it/s]\titers: 200, epoch: 8 | loss: 0.3660907\n",
      "\tspeed: 0.0505s/iter; left time: 3363.2594s\n",
      "298it [00:16, 18.75it/s]\titers: 300, epoch: 8 | loss: 0.2342499\n",
      "\tspeed: 0.0542s/iter; left time: 3608.7201s\n",
      "399it [00:21, 19.75it/s]\titers: 400, epoch: 8 | loss: 0.2780502\n",
      "\tspeed: 0.0506s/iter; left time: 3362.6746s\n",
      "499it [00:26, 19.74it/s]\titers: 500, epoch: 8 | loss: 0.3842768\n",
      "\tspeed: 0.0505s/iter; left time: 3352.2542s\n",
      "598it [00:31, 21.65it/s]\titers: 600, epoch: 8 | loss: 0.0973887\n",
      "\tspeed: 0.0521s/iter; left time: 3454.0811s\n",
      "699it [00:36, 19.78it/s]\titers: 700, epoch: 8 | loss: 0.1769516\n",
      "\tspeed: 0.0546s/iter; left time: 3611.5432s\n",
      "799it [00:41, 23.03it/s]\titers: 800, epoch: 8 | loss: 0.2376847\n",
      "\tspeed: 0.0479s/iter; left time: 3160.5970s\n",
      "899it [00:46, 20.52it/s]\titers: 900, epoch: 8 | loss: 0.2653276\n",
      "\tspeed: 0.0523s/iter; left time: 3450.3896s\n",
      "999it [00:52, 18.14it/s]\titers: 1000, epoch: 8 | loss: 0.2079099\n",
      "\tspeed: 0.0519s/iter; left time: 3417.0753s\n",
      "1098it [00:57, 16.45it/s]\titers: 1100, epoch: 8 | loss: 0.1486531\n",
      "\tspeed: 0.0537s/iter; left time: 3531.3665s\n",
      "1198it [01:02, 18.78it/s]\titers: 1200, epoch: 8 | loss: 0.1942614\n",
      "\tspeed: 0.0536s/iter; left time: 3516.7271s\n",
      "1299it [01:08, 19.50it/s]\titers: 1300, epoch: 8 | loss: 0.1215701\n",
      "\tspeed: 0.0542s/iter; left time: 3549.3980s\n",
      "1398it [01:13, 19.79it/s]\titers: 1400, epoch: 8 | loss: 0.2300561\n",
      "\tspeed: 0.0573s/iter; left time: 3749.7152s\n",
      "1499it [01:19, 19.80it/s]\titers: 1500, epoch: 8 | loss: 0.2108197\n",
      "\tspeed: 0.0506s/iter; left time: 3302.9544s\n",
      "1599it [01:24, 16.22it/s]\titers: 1600, epoch: 8 | loss: 0.3915426\n",
      "\tspeed: 0.0523s/iter; left time: 3411.9641s\n",
      "1699it [01:30, 18.90it/s]\titers: 1700, epoch: 8 | loss: 0.1707420\n",
      "\tspeed: 0.0575s/iter; left time: 3743.9577s\n",
      "1799it [01:35, 19.76it/s]\titers: 1800, epoch: 8 | loss: 0.2198480\n",
      "\tspeed: 0.0505s/iter; left time: 3286.4386s\n",
      "1899it [01:40, 19.71it/s]\titers: 1900, epoch: 8 | loss: 0.1876891\n",
      "\tspeed: 0.0545s/iter; left time: 3539.6105s\n",
      "1999it [01:45, 19.79it/s]\titers: 2000, epoch: 8 | loss: 0.1461149\n",
      "\tspeed: 0.0507s/iter; left time: 3286.7607s\n",
      "2097it [01:50, 19.78it/s]\titers: 2100, epoch: 8 | loss: 0.4217271\n",
      "\tspeed: 0.0523s/iter; left time: 3388.2277s\n",
      "2198it [01:56, 19.66it/s]\titers: 2200, epoch: 8 | loss: 0.2307946\n",
      "\tspeed: 0.0543s/iter; left time: 3510.9312s\n",
      "2298it [02:01, 19.59it/s]\titers: 2300, epoch: 8 | loss: 0.2537763\n",
      "\tspeed: 0.0510s/iter; left time: 3288.6646s\n",
      "2399it [02:06, 17.42it/s]\titers: 2400, epoch: 8 | loss: 0.3472365\n",
      "\tspeed: 0.0540s/iter; left time: 3476.4544s\n",
      "2499it [02:12, 19.81it/s]\titers: 2500, epoch: 8 | loss: 0.3828472\n",
      "\tspeed: 0.0532s/iter; left time: 3421.4150s\n",
      "2598it [02:17, 19.81it/s]\titers: 2600, epoch: 8 | loss: 0.2944769\n",
      "\tspeed: 0.0505s/iter; left time: 3245.8201s\n",
      "2699it [02:22, 18.67it/s]\titers: 2700, epoch: 8 | loss: 0.2137020\n",
      "\tspeed: 0.0511s/iter; left time: 3277.3350s\n",
      "2798it [02:27, 19.75it/s]\titers: 2800, epoch: 8 | loss: 0.5032064\n",
      "\tspeed: 0.0555s/iter; left time: 3550.7929s\n",
      "2899it [02:32, 19.73it/s]\titers: 2900, epoch: 8 | loss: 0.2878367\n",
      "\tspeed: 0.0507s/iter; left time: 3240.6659s\n",
      "2998it [02:37, 19.85it/s]\titers: 3000, epoch: 8 | loss: 0.2269292\n",
      "\tspeed: 0.0507s/iter; left time: 3235.2868s\n",
      "3099it [02:43, 19.80it/s]\titers: 3100, epoch: 8 | loss: 0.2637629\n",
      "\tspeed: 0.0556s/iter; left time: 3543.8523s\n",
      "3198it [02:48, 19.79it/s]\titers: 3200, epoch: 8 | loss: 0.2443337\n",
      "\tspeed: 0.0505s/iter; left time: 3214.6296s\n",
      "3297it [02:53, 19.70it/s]\titers: 3300, epoch: 8 | loss: 0.2863843\n",
      "\tspeed: 0.0506s/iter; left time: 3211.9942s\n",
      "3399it [02:59, 17.61it/s]\titers: 3400, epoch: 8 | loss: 0.1925337\n",
      "\tspeed: 0.0554s/iter; left time: 3512.8418s\n",
      "3498it [03:04, 19.76it/s]\titers: 3500, epoch: 8 | loss: 0.3639280\n",
      "\tspeed: 0.0507s/iter; left time: 3208.1858s\n",
      "3599it [03:09, 13.53it/s]\titers: 3600, epoch: 8 | loss: 0.3156505\n",
      "\tspeed: 0.0542s/iter; left time: 3428.5218s\n",
      "3698it [03:14, 18.63it/s]\titers: 3700, epoch: 8 | loss: 0.3030545\n",
      "\tspeed: 0.0519s/iter; left time: 3278.0289s\n",
      "3713it [03:15, 18.98it/s]\n",
      "Epoch: 8 cost time: 195.6299901008606\n",
      "810it [00:20, 38.72it/s]\n",
      "807it [00:20, 39.26it/s]\n",
      "Epoch: 8 | Train Loss: 0.2485492 Vali Loss: 0.3076998 Test Loss: 0.3804507 MAE Loss: 0.3875851\n",
      "EarlyStopping counter: 2 out of 3\n",
      "lr = 0.0001000000\n",
      "learning_rate 0.0001\n",
      "lr 0.0001\n",
      "98it [00:05, 19.78it/s]\titers: 100, epoch: 9 | loss: 0.1769496\n",
      "\tspeed: 0.4769s/iter; left time: 30053.2483s\n",
      "198it [00:10, 19.82it/s]\titers: 200, epoch: 9 | loss: 0.2065994\n",
      "\tspeed: 0.0544s/iter; left time: 3422.0438s\n",
      "298it [00:15, 19.76it/s]\titers: 300, epoch: 9 | loss: 0.2998700\n",
      "\tspeed: 0.0514s/iter; left time: 3231.3214s\n",
      "398it [00:21, 16.64it/s]\titers: 400, epoch: 9 | loss: 0.2128755\n",
      "\tspeed: 0.0531s/iter; left time: 3330.3297s\n",
      "499it [00:26, 19.75it/s]\titers: 500, epoch: 9 | loss: 0.1800736\n",
      "\tspeed: 0.0506s/iter; left time: 3167.2169s\n",
      "599it [00:31, 19.80it/s]\titers: 600, epoch: 9 | loss: 0.1758914\n",
      "\tspeed: 0.0505s/iter; left time: 3159.4055s\n",
      "699it [00:36, 19.67it/s]\titers: 700, epoch: 9 | loss: 0.3611583\n",
      "\tspeed: 0.0558s/iter; left time: 3482.5918s\n",
      "798it [00:41, 19.78it/s]\titers: 800, epoch: 9 | loss: 0.1816428\n",
      "\tspeed: 0.0507s/iter; left time: 3157.2921s\n",
      "899it [00:47, 19.79it/s]\titers: 900, epoch: 9 | loss: 0.4490946\n",
      "\tspeed: 0.0505s/iter; left time: 3144.0914s\n",
      "999it [00:52, 19.78it/s]\titers: 1000, epoch: 9 | loss: 0.1475918\n",
      "\tspeed: 0.0584s/iter; left time: 3628.7518s\n",
      "1098it [00:57, 19.75it/s]\titers: 1100, epoch: 9 | loss: 0.2635531\n",
      "\tspeed: 0.0505s/iter; left time: 3133.5592s\n",
      "1199it [01:03, 17.59it/s]\titers: 1200, epoch: 9 | loss: 0.2440730\n",
      "\tspeed: 0.0555s/iter; left time: 3436.9199s\n",
      "1299it [01:08, 19.80it/s]\titers: 1300, epoch: 9 | loss: 0.1966487\n",
      "\tspeed: 0.0507s/iter; left time: 3134.6769s\n",
      "1398it [01:13, 19.94it/s]\titers: 1400, epoch: 9 | loss: 0.1908001\n",
      "\tspeed: 0.0518s/iter; left time: 3197.8563s\n",
      "1498it [01:19, 19.76it/s]\titers: 1500, epoch: 9 | loss: 0.3414838\n",
      "\tspeed: 0.0545s/iter; left time: 3357.4144s\n",
      "1599it [01:24, 19.78it/s]\titers: 1600, epoch: 9 | loss: 0.2204745\n",
      "\tspeed: 0.0506s/iter; left time: 3111.2659s\n",
      "1699it [01:29, 18.69it/s]\titers: 1700, epoch: 9 | loss: 0.1662367\n",
      "\tspeed: 0.0541s/iter; left time: 3323.3151s\n",
      "1799it [01:35, 19.80it/s]\titers: 1800, epoch: 9 | loss: 0.3018598\n",
      "\tspeed: 0.0538s/iter; left time: 3296.0787s\n",
      "1899it [01:40, 19.75it/s]\titers: 1900, epoch: 9 | loss: 0.2714947\n",
      "\tspeed: 0.0508s/iter; left time: 3110.1902s\n",
      "1998it [01:45, 19.05it/s]\titers: 2000, epoch: 9 | loss: 0.3148700\n",
      "\tspeed: 0.0544s/iter; left time: 3323.9561s\n",
      "2098it [01:50, 19.55it/s]\titers: 2100, epoch: 9 | loss: 0.1980088\n",
      "\tspeed: 0.0536s/iter; left time: 3270.0278s\n",
      "2198it [01:55, 19.78it/s]\titers: 2200, epoch: 9 | loss: 0.2633793\n",
      "\tspeed: 0.0515s/iter; left time: 3138.4713s\n",
      "2298it [02:01, 19.79it/s]\titers: 2300, epoch: 9 | loss: 0.1942925\n",
      "\tspeed: 0.0539s/iter; left time: 3276.0250s\n",
      "2398it [02:06, 19.77it/s]\titers: 2400, epoch: 9 | loss: 0.3727119\n",
      "\tspeed: 0.0513s/iter; left time: 3112.4885s\n",
      "2499it [02:11, 16.77it/s]\titers: 2500, epoch: 9 | loss: 0.1450930\n",
      "\tspeed: 0.0513s/iter; left time: 3108.7258s\n",
      "2599it [02:16, 19.77it/s]\titers: 2600, epoch: 9 | loss: 0.2032005\n",
      "\tspeed: 0.0531s/iter; left time: 3211.8301s\n",
      "2698it [02:22, 15.66it/s]\titers: 2700, epoch: 9 | loss: 0.2506309\n",
      "\tspeed: 0.0543s/iter; left time: 3283.7589s\n",
      "2799it [02:27, 19.70it/s]\titers: 2800, epoch: 9 | loss: 0.1646569\n",
      "\tspeed: 0.0538s/iter; left time: 3245.0086s\n",
      "2898it [02:32, 19.77it/s]\titers: 2900, epoch: 9 | loss: 0.2910433\n",
      "\tspeed: 0.0506s/iter; left time: 3045.0283s\n",
      "2999it [02:37, 19.74it/s]\titers: 3000, epoch: 9 | loss: 0.2506888\n",
      "\tspeed: 0.0506s/iter; left time: 3040.3094s\n",
      "3099it [02:43, 19.80it/s]\titers: 3100, epoch: 9 | loss: 0.1528109\n",
      "\tspeed: 0.0554s/iter; left time: 3324.7867s\n",
      "3198it [02:48, 19.80it/s]\titers: 3200, epoch: 9 | loss: 0.3179746\n",
      "\tspeed: 0.0505s/iter; left time: 3026.9582s\n",
      "3299it [02:53, 18.35it/s]\titers: 3300, epoch: 9 | loss: 0.1613307\n",
      "\tspeed: 0.0510s/iter; left time: 3049.6728s\n",
      "3397it [02:58, 18.46it/s]\titers: 3400, epoch: 9 | loss: 0.3898421\n",
      "\tspeed: 0.0532s/iter; left time: 3175.6548s\n",
      "3498it [03:03, 19.77it/s]\titers: 3500, epoch: 9 | loss: 0.3073234\n",
      "\tspeed: 0.0506s/iter; left time: 3019.2033s\n",
      "3598it [03:09, 19.42it/s]\titers: 3600, epoch: 9 | loss: 0.3868546\n",
      "\tspeed: 0.0535s/iter; left time: 3182.1745s\n",
      "3698it [03:14, 19.76it/s]\titers: 3700, epoch: 9 | loss: 0.1887482\n",
      "\tspeed: 0.0505s/iter; left time: 3000.3661s\n",
      "3713it [03:15, 19.01it/s]\n",
      "Epoch: 9 cost time: 195.27078461647034\n",
      "810it [00:20, 38.97it/s]\n",
      "807it [00:19, 40.45it/s]\n",
      "Epoch: 9 | Train Loss: 0.2484585 Vali Loss: 0.3082378 Test Loss: 0.3780822 MAE Loss: 0.3876054\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 36.434636902809146 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=25\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.0001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'constant' \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 23:31:10,132] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 23:31:11,263] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 23:31:11,263] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 23:31:13,047] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 23:31:13,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 23:31:13,549] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 23:31:13,549] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 23:31:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 23:31:13,550] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 23:31:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 23:31:13,550] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 23:31:13,550] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 23:31:13,550] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 23:31:13,550] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 23:31:14,035] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 23:31:14,035] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 23:31:14,035] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 313.29 GB, percent = 41.5%\n",
      "[2024-05-07 23:31:14,150] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 23:31:14,150] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 23:31:14,151] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 313.29 GB, percent = 41.5%\n",
      "[2024-05-07 23:31:14,151] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 23:31:14,260] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 23:31:14,261] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 23:31:14,261] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 313.28 GB, percent = 41.5%\n",
      "[2024-05-07 23:31:14,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 23:31:14,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 23:31:14,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 23:31:14,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[4.000000000000002e-06], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f79cde0c590>\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 23:31:14,262] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 23:31:14,263] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.0001\n",
      "lr 4.000000000000002e-06\n",
      "98it [00:06, 18.56it/s]\titers: 100, epoch: 1 | loss: 0.8648155\n",
      "\tspeed: 0.0766s/iter; left time: 7098.5821s\n",
      "199it [00:11, 18.33it/s]\titers: 200, epoch: 1 | loss: 0.9663060\n",
      "\tspeed: 0.0542s/iter; left time: 5022.2866s\n",
      "297it [00:17, 19.56it/s]\titers: 300, epoch: 1 | loss: 0.7603557\n",
      "\tspeed: 0.0586s/iter; left time: 5418.8314s\n",
      "399it [00:22, 21.34it/s]\titers: 400, epoch: 1 | loss: 0.5165516\n",
      "\tspeed: 0.0467s/iter; left time: 4314.4245s\n",
      "498it [00:26, 21.43it/s]\titers: 500, epoch: 1 | loss: 0.5156228\n",
      "\tspeed: 0.0468s/iter; left time: 4320.9687s\n",
      "599it [00:32, 21.26it/s]\titers: 600, epoch: 1 | loss: 0.6026934\n",
      "\tspeed: 0.0508s/iter; left time: 4684.6267s\n",
      "698it [00:36, 21.40it/s]\titers: 700, epoch: 1 | loss: 0.7397388\n",
      "\tspeed: 0.0486s/iter; left time: 4481.8596s\n",
      "797it [00:41, 21.29it/s]\titers: 800, epoch: 1 | loss: 0.4624110\n",
      "\tspeed: 0.0468s/iter; left time: 4308.7117s\n",
      "898it [00:47, 19.19it/s]\titers: 900, epoch: 1 | loss: 0.3826446\n",
      "\tspeed: 0.0551s/iter; left time: 5064.5663s\n",
      "998it [00:52, 12.81it/s]\titers: 1000, epoch: 1 | loss: 0.4212686\n",
      "\tspeed: 0.0573s/iter; left time: 5263.6297s\n",
      "1098it [00:58, 14.84it/s]\titers: 1100, epoch: 1 | loss: 0.3545426\n",
      "\tspeed: 0.0575s/iter; left time: 5269.9044s\n",
      "1198it [01:03, 18.49it/s]\titers: 1200, epoch: 1 | loss: 0.3017982\n",
      "\tspeed: 0.0537s/iter; left time: 4921.1956s\n",
      "1298it [01:09, 18.84it/s]\titers: 1300, epoch: 1 | loss: 0.3068161\n",
      "\tspeed: 0.0532s/iter; left time: 4872.5729s\n",
      "1398it [01:15, 18.19it/s]\titers: 1400, epoch: 1 | loss: 0.4678942\n",
      "\tspeed: 0.0620s/iter; left time: 5668.8020s\n",
      "1498it [01:21, 18.86it/s]\titers: 1500, epoch: 1 | loss: 0.3242438\n",
      "\tspeed: 0.0553s/iter; left time: 5053.2620s\n",
      "1598it [01:26, 18.76it/s]\titers: 1600, epoch: 1 | loss: 0.3837070\n",
      "\tspeed: 0.0533s/iter; left time: 4860.6081s\n",
      "1698it [01:32, 19.00it/s]\titers: 1700, epoch: 1 | loss: 0.5708473\n",
      "\tspeed: 0.0598s/iter; left time: 5451.3486s\n",
      "1798it [01:37, 18.76it/s]\titers: 1800, epoch: 1 | loss: 0.3220300\n",
      "\tspeed: 0.0536s/iter; left time: 4876.9199s\n",
      "1898it [01:43, 15.69it/s]\titers: 1900, epoch: 1 | loss: 0.3062184\n",
      "\tspeed: 0.0567s/iter; left time: 5158.9128s\n",
      "1998it [01:49, 18.07it/s]\titers: 2000, epoch: 1 | loss: 0.4461419\n",
      "\tspeed: 0.0578s/iter; left time: 5248.8346s\n",
      "2098it [01:54, 18.78it/s]\titers: 2100, epoch: 1 | loss: 0.2285896\n",
      "\tspeed: 0.0530s/iter; left time: 4805.3093s\n",
      "2198it [02:00, 18.64it/s]\titers: 2200, epoch: 1 | loss: 0.1984109\n",
      "\tspeed: 0.0571s/iter; left time: 5171.3977s\n",
      "2298it [02:05, 18.09it/s]\titers: 2300, epoch: 1 | loss: 0.3349892\n",
      "\tspeed: 0.0546s/iter; left time: 4940.6945s\n",
      "2398it [02:11, 13.83it/s]\titers: 2400, epoch: 1 | loss: 0.6159282\n",
      "\tspeed: 0.0611s/iter; left time: 5525.4293s\n",
      "2498it [02:17, 18.77it/s]\titers: 2500, epoch: 1 | loss: 0.2770891\n",
      "\tspeed: 0.0531s/iter; left time: 4798.1355s\n",
      "2598it [02:22, 18.67it/s]\titers: 2600, epoch: 1 | loss: 0.2381167\n",
      "\tspeed: 0.0534s/iter; left time: 4815.2645s\n",
      "2698it [02:28, 18.70it/s]\titers: 2700, epoch: 1 | loss: 0.3315830\n",
      "\tspeed: 0.0589s/iter; left time: 5311.3112s\n",
      "2798it [02:33, 18.83it/s]\titers: 2800, epoch: 1 | loss: 0.1501264\n",
      "\tspeed: 0.0533s/iter; left time: 4801.3963s\n",
      "2898it [02:39, 13.41it/s]\titers: 2900, epoch: 1 | loss: 0.4579513\n",
      "\tspeed: 0.0570s/iter; left time: 5126.7646s\n",
      "2998it [02:45, 18.87it/s]\titers: 3000, epoch: 1 | loss: 0.1595016\n",
      "\tspeed: 0.0583s/iter; left time: 5235.7316s\n",
      "3098it [02:50, 18.40it/s]\titers: 3100, epoch: 1 | loss: 0.2903794\n",
      "\tspeed: 0.0541s/iter; left time: 4856.1523s\n",
      "3199it [02:56, 18.46it/s]\titers: 3200, epoch: 1 | loss: 0.4768536\n",
      "\tspeed: 0.0577s/iter; left time: 5172.0867s\n",
      "3298it [03:01, 20.14it/s]\titers: 3300, epoch: 1 | loss: 0.2780221\n",
      "\tspeed: 0.0520s/iter; left time: 4654.2933s\n",
      "3398it [03:08, 17.23it/s]\titers: 3400, epoch: 1 | loss: 0.3100349\n",
      "\tspeed: 0.0657s/iter; left time: 5873.6556s\n",
      "3498it [03:13, 18.91it/s]\titers: 3500, epoch: 1 | loss: 0.4008717\n",
      "\tspeed: 0.0558s/iter; left time: 4982.6310s\n",
      "3598it [03:19, 18.57it/s]\titers: 3600, epoch: 1 | loss: 0.4503819\n",
      "\tspeed: 0.0538s/iter; left time: 4803.4527s\n",
      "3698it [03:25, 16.48it/s]\titers: 3700, epoch: 1 | loss: 0.1777111\n",
      "\tspeed: 0.0634s/iter; left time: 5652.6119s\n",
      "3713it [03:26, 18.00it/s]\n",
      "Epoch: 1 cost time: 206.32007908821106\n",
      "810it [00:23, 33.78it/s]\n",
      "807it [00:23, 34.22it/s]\n",
      "Epoch: 1 | Train Loss: 0.4176987 Vali Loss: 0.3349823 Test Loss: 0.4150635 MAE Loss: 0.4283017\n",
      "lr = 0.0000040000\n",
      "Updating learning rate to 4.000000000000002e-06\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 4.000000000000002e-06\n",
      "99it [00:06, 18.83it/s]\titers: 100, epoch: 2 | loss: 0.2355459\n",
      "\tspeed: 0.5597s/iter; left time: 49819.8359s\n",
      "197it [00:11, 19.21it/s]\titers: 200, epoch: 2 | loss: 0.1870894\n",
      "\tspeed: 0.0551s/iter; left time: 4902.0913s\n",
      "298it [00:17, 17.63it/s]\titers: 300, epoch: 2 | loss: 0.2723903\n",
      "\tspeed: 0.0578s/iter; left time: 5134.6220s\n",
      "399it [00:23, 21.51it/s]\titers: 400, epoch: 2 | loss: 0.3853628\n",
      "\tspeed: 0.0559s/iter; left time: 4954.7749s\n",
      "498it [00:27, 22.40it/s]\titers: 500, epoch: 2 | loss: 0.2005530\n",
      "\tspeed: 0.0444s/iter; left time: 3937.3541s\n",
      "599it [00:32, 19.77it/s]\titers: 600, epoch: 2 | loss: 0.4764448\n",
      "\tspeed: 0.0528s/iter; left time: 4675.5239s\n",
      "699it [00:37, 19.75it/s]\titers: 700, epoch: 2 | loss: 0.2023444\n",
      "\tspeed: 0.0505s/iter; left time: 4467.7755s\n",
      "798it [00:43, 15.65it/s]\titers: 800, epoch: 2 | loss: 0.2764157\n",
      "\tspeed: 0.0529s/iter; left time: 4673.2275s\n",
      "898it [00:47, 22.84it/s]\titers: 900, epoch: 2 | loss: 0.5781910\n",
      "\tspeed: 0.0439s/iter; left time: 3872.5525s\n",
      "997it [00:51, 22.85it/s]\titers: 1000, epoch: 2 | loss: 0.2175918\n",
      "\tspeed: 0.0439s/iter; left time: 3865.9688s\n",
      "1099it [00:56, 20.06it/s]\titers: 1100, epoch: 2 | loss: 0.2497300\n",
      "\tspeed: 0.0455s/iter; left time: 4004.5226s\n",
      "1198it [01:02, 19.72it/s]\titers: 1200, epoch: 2 | loss: 0.3395084\n",
      "\tspeed: 0.0561s/iter; left time: 4932.8551s\n",
      "1299it [01:07, 19.77it/s]\titers: 1300, epoch: 2 | loss: 0.2367790\n",
      "\tspeed: 0.0506s/iter; left time: 4439.7114s\n",
      "1399it [01:12, 19.72it/s]\titers: 1400, epoch: 2 | loss: 0.3538096\n",
      "\tspeed: 0.0538s/iter; left time: 4719.1203s\n",
      "1499it [01:17, 19.87it/s]\titers: 1500, epoch: 2 | loss: 0.1722714\n",
      "\tspeed: 0.0507s/iter; left time: 4446.1350s\n",
      "1599it [01:22, 19.82it/s]\titers: 1600, epoch: 2 | loss: 0.4551695\n",
      "\tspeed: 0.0504s/iter; left time: 4412.9094s\n",
      "1699it [01:28, 19.82it/s]\titers: 1700, epoch: 2 | loss: 0.3220409\n",
      "\tspeed: 0.0534s/iter; left time: 4664.4956s\n",
      "1799it [01:33, 17.70it/s]\titers: 1800, epoch: 2 | loss: 0.4080679\n",
      "\tspeed: 0.0512s/iter; left time: 4468.6642s\n",
      "1899it [01:38, 12.95it/s]\titers: 1900, epoch: 2 | loss: 0.2795567\n",
      "\tspeed: 0.0544s/iter; left time: 4741.8894s\n",
      "1999it [01:43, 19.85it/s]\titers: 2000, epoch: 2 | loss: 0.3659088\n",
      "\tspeed: 0.0506s/iter; left time: 4404.1332s\n",
      "2099it [01:48, 19.80it/s]\titers: 2100, epoch: 2 | loss: 0.4141260\n",
      "\tspeed: 0.0508s/iter; left time: 4424.4379s\n",
      "2198it [01:54, 19.60it/s]\titers: 2200, epoch: 2 | loss: 0.2513401\n",
      "\tspeed: 0.0544s/iter; left time: 4727.8057s\n",
      "2298it [01:59, 19.71it/s]\titers: 2300, epoch: 2 | loss: 0.4138298\n",
      "\tspeed: 0.0508s/iter; left time: 4414.3291s\n",
      "2399it [02:04, 19.85it/s]\titers: 2400, epoch: 2 | loss: 0.2852002\n",
      "\tspeed: 0.0505s/iter; left time: 4379.2562s\n",
      "2499it [02:09, 18.34it/s]\titers: 2500, epoch: 2 | loss: 0.1990795\n",
      "\tspeed: 0.0519s/iter; left time: 4495.0855s\n",
      "2599it [02:14, 19.77it/s]\titers: 2600, epoch: 2 | loss: 0.2137397\n",
      "\tspeed: 0.0528s/iter; left time: 4569.2060s\n",
      "2699it [02:19, 19.81it/s]\titers: 2700, epoch: 2 | loss: 0.3196936\n",
      "\tspeed: 0.0506s/iter; left time: 4373.5608s\n",
      "2798it [02:25, 15.35it/s]\titers: 2800, epoch: 2 | loss: 0.3480120\n",
      "\tspeed: 0.0525s/iter; left time: 4531.3232s\n",
      "2898it [02:30, 19.79it/s]\titers: 2900, epoch: 2 | loss: 0.2799575\n",
      "\tspeed: 0.0530s/iter; left time: 4572.0190s\n",
      "2999it [02:35, 19.69it/s]\titers: 3000, epoch: 2 | loss: 0.2532555\n",
      "\tspeed: 0.0511s/iter; left time: 4399.1189s\n",
      "3098it [02:40, 19.69it/s]\titers: 3100, epoch: 2 | loss: 0.2247453\n",
      "\tspeed: 0.0532s/iter; left time: 4573.0335s\n",
      "3198it [02:46, 15.03it/s]\titers: 3200, epoch: 2 | loss: 0.2324004\n",
      "\tspeed: 0.0548s/iter; left time: 4707.4003s\n",
      "3299it [02:51, 19.77it/s]\titers: 3300, epoch: 2 | loss: 0.2375280\n",
      "\tspeed: 0.0506s/iter; left time: 4341.1764s\n",
      "3398it [02:56, 19.77it/s]\titers: 3400, epoch: 2 | loss: 0.3068245\n",
      "\tspeed: 0.0538s/iter; left time: 4610.0904s\n",
      "3499it [03:01, 19.82it/s]\titers: 3500, epoch: 2 | loss: 0.1999102\n",
      "\tspeed: 0.0505s/iter; left time: 4326.6909s\n",
      "3599it [03:07, 19.13it/s]\titers: 3600, epoch: 2 | loss: 0.2294866\n",
      "\tspeed: 0.0531s/iter; left time: 4541.8553s\n",
      "3699it [03:12, 19.82it/s]\titers: 3700, epoch: 2 | loss: 0.3171920\n",
      "\tspeed: 0.0534s/iter; left time: 4563.1716s\n",
      "3713it [03:13, 19.21it/s]\n",
      "Epoch: 2 cost time: 193.26980352401733\n",
      "810it [00:20, 39.29it/s]\n",
      "807it [00:21, 38.03it/s]\n",
      "Epoch: 2 | Train Loss: 0.2824859 Vali Loss: 0.3085616 Test Loss: 0.3755053 MAE Loss: 0.3941016\n",
      "Updating learning rate to 2.000000000000001e-06\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 2.000000000000001e-06\n",
      "98it [00:05, 19.78it/s]\titers: 100, epoch: 3 | loss: 0.2722718\n",
      "\tspeed: 0.4907s/iter; left time: 41854.6223s\n",
      "198it [00:10, 19.78it/s]\titers: 200, epoch: 3 | loss: 0.1678986\n",
      "\tspeed: 0.0505s/iter; left time: 4305.3311s\n",
      "299it [00:15, 19.81it/s]\titers: 300, epoch: 3 | loss: 0.4295530\n",
      "\tspeed: 0.0537s/iter; left time: 4573.5725s\n",
      "399it [00:20, 19.71it/s]\titers: 400, epoch: 3 | loss: 0.2823402\n",
      "\tspeed: 0.0517s/iter; left time: 4391.6609s\n",
      "498it [00:26, 18.12it/s]\titers: 500, epoch: 3 | loss: 0.2111049\n",
      "\tspeed: 0.0513s/iter; left time: 4358.3250s\n",
      "599it [00:31, 19.81it/s]\titers: 600, epoch: 3 | loss: 0.2441039\n",
      "\tspeed: 0.0533s/iter; left time: 4523.0245s\n",
      "698it [00:36, 18.59it/s]\titers: 700, epoch: 3 | loss: 0.2079458\n",
      "\tspeed: 0.0508s/iter; left time: 4306.1917s\n",
      "799it [00:41, 22.24it/s]\titers: 800, epoch: 3 | loss: 0.1967591\n",
      "\tspeed: 0.0524s/iter; left time: 4431.9458s\n",
      "899it [00:46, 19.82it/s]\titers: 900, epoch: 3 | loss: 0.1584016\n",
      "\tspeed: 0.0461s/iter; left time: 3895.7438s\n",
      "998it [00:51, 19.75it/s]\titers: 1000, epoch: 3 | loss: 0.2128878\n",
      "\tspeed: 0.0505s/iter; left time: 4263.3359s\n",
      "1099it [00:57, 19.78it/s]\titers: 1100, epoch: 3 | loss: 0.1846509\n",
      "\tspeed: 0.0561s/iter; left time: 4731.7342s\n",
      "1199it [01:02, 19.72it/s]\titers: 1200, epoch: 3 | loss: 0.1575334\n",
      "\tspeed: 0.0506s/iter; left time: 4256.7989s\n",
      "1298it [01:07, 19.73it/s]\titers: 1300, epoch: 3 | loss: 0.2276578\n",
      "\tspeed: 0.0506s/iter; left time: 4252.1489s\n",
      "1398it [01:12, 19.30it/s]\titers: 1400, epoch: 3 | loss: 0.2626719\n",
      "\tspeed: 0.0538s/iter; left time: 4523.3906s\n",
      "1499it [01:17, 19.82it/s]\titers: 1500, epoch: 3 | loss: 0.3449342\n",
      "\tspeed: 0.0536s/iter; left time: 4499.7148s\n",
      "1598it [01:22, 19.81it/s]\titers: 1600, epoch: 3 | loss: 0.3376254\n",
      "\tspeed: 0.0506s/iter; left time: 4237.2904s\n",
      "1698it [01:28, 19.71it/s]\titers: 1700, epoch: 3 | loss: 0.1722507\n",
      "\tspeed: 0.0540s/iter; left time: 4518.1737s\n",
      "1798it [01:33, 17.02it/s]\titers: 1800, epoch: 3 | loss: 0.2226452\n",
      "\tspeed: 0.0515s/iter; left time: 4307.2920s\n",
      "1898it [01:38, 19.28it/s]\titers: 1900, epoch: 3 | loss: 0.3377616\n",
      "\tspeed: 0.0508s/iter; left time: 4242.3110s\n",
      "1998it [01:43, 19.76it/s]\titers: 2000, epoch: 3 | loss: 0.4244378\n",
      "\tspeed: 0.0538s/iter; left time: 4484.5557s\n",
      "2099it [01:49, 19.77it/s]\titers: 2100, epoch: 3 | loss: 0.1842027\n",
      "\tspeed: 0.0505s/iter; left time: 4202.5315s\n",
      "2198it [01:54, 19.78it/s]\titers: 2200, epoch: 3 | loss: 0.2607881\n",
      "\tspeed: 0.0549s/iter; left time: 4566.0748s\n",
      "2298it [01:59, 19.76it/s]\titers: 2300, epoch: 3 | loss: 0.1570270\n",
      "\tspeed: 0.0537s/iter; left time: 4463.5602s\n",
      "2399it [02:04, 19.60it/s]\titers: 2400, epoch: 3 | loss: 0.4839672\n",
      "\tspeed: 0.0506s/iter; left time: 4196.9353s\n",
      "2499it [02:10, 14.09it/s]\titers: 2500, epoch: 3 | loss: 0.1581894\n",
      "\tspeed: 0.0551s/iter; left time: 4566.1550s\n",
      "2598it [02:15, 19.79it/s]\titers: 2600, epoch: 3 | loss: 0.3937258\n",
      "\tspeed: 0.0518s/iter; left time: 4286.7199s\n",
      "2699it [02:20, 19.72it/s]\titers: 2700, epoch: 3 | loss: 0.2505561\n",
      "\tspeed: 0.0504s/iter; left time: 4166.6185s\n",
      "2797it [02:25, 19.80it/s]\titers: 2800, epoch: 3 | loss: 0.1583175\n",
      "\tspeed: 0.0530s/iter; left time: 4376.0967s\n",
      "2899it [02:31, 15.36it/s]\titers: 2900, epoch: 3 | loss: 0.2278078\n",
      "\tspeed: 0.0527s/iter; left time: 4345.3889s\n",
      "2998it [02:36, 19.25it/s]\titers: 3000, epoch: 3 | loss: 0.2289520\n",
      "\tspeed: 0.0508s/iter; left time: 4188.5601s\n",
      "3098it [02:41, 19.62it/s]\titers: 3100, epoch: 3 | loss: 0.2793564\n",
      "\tspeed: 0.0537s/iter; left time: 4418.1356s\n",
      "3198it [02:46, 19.77it/s]\titers: 3200, epoch: 3 | loss: 0.3167221\n",
      "\tspeed: 0.0506s/iter; left time: 4161.6543s\n",
      "3298it [02:52, 19.63it/s]\titers: 3300, epoch: 3 | loss: 0.2860494\n",
      "\tspeed: 0.0546s/iter; left time: 4485.3644s\n",
      "3398it [02:57, 19.78it/s]\titers: 3400, epoch: 3 | loss: 0.2169731\n",
      "\tspeed: 0.0535s/iter; left time: 4390.3325s\n",
      "3499it [03:02, 19.43it/s]\titers: 3500, epoch: 3 | loss: 0.2587620\n",
      "\tspeed: 0.0506s/iter; left time: 4144.5465s\n",
      "3599it [03:07, 15.90it/s]\titers: 3600, epoch: 3 | loss: 0.3963194\n",
      "\tspeed: 0.0531s/iter; left time: 4345.7769s\n",
      "3698it [03:13, 19.84it/s]\titers: 3700, epoch: 3 | loss: 0.1817088\n",
      "\tspeed: 0.0531s/iter; left time: 4338.9106s\n",
      "3713it [03:13, 19.14it/s]\n",
      "Epoch: 3 cost time: 193.99415636062622\n",
      "810it [00:20, 38.80it/s]\n",
      "807it [00:20, 40.28it/s]\n",
      "Epoch: 3 | Train Loss: 0.2680686 Vali Loss: 0.2987585 Test Loss: 0.3640514 MAE Loss: 0.3807335\n",
      "Updating learning rate to 1.0000000000000006e-06\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 1.0000000000000006e-06\n",
      "99it [00:05, 19.47it/s]\titers: 100, epoch: 4 | loss: 0.2507894\n",
      "\tspeed: 0.4883s/iter; left time: 39842.4978s\n",
      "198it [00:10, 21.81it/s]\titers: 200, epoch: 4 | loss: 0.1783389\n",
      "\tspeed: 0.0498s/iter; left time: 4055.2031s\n",
      "297it [00:15, 21.61it/s]\titers: 300, epoch: 4 | loss: 0.1862787\n",
      "\tspeed: 0.0479s/iter; left time: 3896.0822s\n",
      "399it [00:20, 20.93it/s]\titers: 400, epoch: 4 | loss: 0.4044181\n",
      "\tspeed: 0.0463s/iter; left time: 3766.9811s\n",
      "499it [00:25, 19.80it/s]\titers: 500, epoch: 4 | loss: 0.4848672\n",
      "\tspeed: 0.0537s/iter; left time: 4359.6452s\n",
      "599it [00:30, 22.07it/s]\titers: 600, epoch: 4 | loss: 0.2195364\n",
      "\tspeed: 0.0476s/iter; left time: 3860.7900s\n",
      "698it [00:35, 19.76it/s]\titers: 700, epoch: 4 | loss: 0.3296422\n",
      "\tspeed: 0.0492s/iter; left time: 3982.8064s\n",
      "799it [00:39, 20.76it/s]\titers: 800, epoch: 4 | loss: 0.3097562\n",
      "\tspeed: 0.0482s/iter; left time: 3902.5500s\n",
      "899it [00:45, 19.78it/s]\titers: 900, epoch: 4 | loss: 0.2403398\n",
      "\tspeed: 0.0514s/iter; left time: 4148.6611s\n",
      "999it [00:50, 19.83it/s]\titers: 1000, epoch: 4 | loss: 0.3029386\n",
      "\tspeed: 0.0505s/iter; left time: 4072.7209s\n",
      "1099it [00:55, 19.75it/s]\titers: 1100, epoch: 4 | loss: 0.2077512\n",
      "\tspeed: 0.0505s/iter; left time: 4073.1684s\n",
      "1198it [01:00, 17.17it/s]\titers: 1200, epoch: 4 | loss: 0.3569716\n",
      "\tspeed: 0.0532s/iter; left time: 4284.4160s\n",
      "1299it [01:05, 19.74it/s]\titers: 1300, epoch: 4 | loss: 0.1822015\n",
      "\tspeed: 0.0504s/iter; left time: 4053.4624s\n",
      "1399it [01:10, 19.74it/s]\titers: 1400, epoch: 4 | loss: 0.4214979\n",
      "\tspeed: 0.0509s/iter; left time: 4088.0033s\n",
      "1498it [01:15, 19.79it/s]\titers: 1500, epoch: 4 | loss: 0.2453888\n",
      "\tspeed: 0.0509s/iter; left time: 4084.3320s\n",
      "1598it [01:20, 19.80it/s]\titers: 1600, epoch: 4 | loss: 0.1884746\n",
      "\tspeed: 0.0518s/iter; left time: 4152.2699s\n",
      "1699it [01:26, 19.69it/s]\titers: 1700, epoch: 4 | loss: 0.3405068\n",
      "\tspeed: 0.0505s/iter; left time: 4035.4497s\n",
      "1798it [01:31, 19.76it/s]\titers: 1800, epoch: 4 | loss: 0.1583807\n",
      "\tspeed: 0.0512s/iter; left time: 4088.9130s\n",
      "1897it [01:35, 22.86it/s]\titers: 1900, epoch: 4 | loss: 0.4298326\n",
      "\tspeed: 0.0436s/iter; left time: 3476.1127s\n",
      "1997it [01:40, 22.93it/s]\titers: 2000, epoch: 4 | loss: 0.1404785\n",
      "\tspeed: 0.0467s/iter; left time: 3718.0614s\n",
      "2099it [01:44, 23.13it/s]\titers: 2100, epoch: 4 | loss: 0.3449261\n",
      "\tspeed: 0.0429s/iter; left time: 3417.2456s\n",
      "2199it [01:49, 19.76it/s]\titers: 2200, epoch: 4 | loss: 0.3013996\n",
      "\tspeed: 0.0464s/iter; left time: 3688.7016s\n",
      "2298it [01:54, 19.79it/s]\titers: 2300, epoch: 4 | loss: 0.2469711\n",
      "\tspeed: 0.0505s/iter; left time: 4011.3259s\n",
      "2399it [01:59, 19.84it/s]\titers: 2400, epoch: 4 | loss: 0.2312789\n",
      "\tspeed: 0.0554s/iter; left time: 4389.1349s\n",
      "2499it [02:04, 19.85it/s]\titers: 2500, epoch: 4 | loss: 0.2882719\n",
      "\tspeed: 0.0506s/iter; left time: 4003.9258s\n",
      "2599it [02:09, 19.79it/s]\titers: 2600, epoch: 4 | loss: 0.2430922\n",
      "\tspeed: 0.0505s/iter; left time: 3996.9555s\n",
      "2698it [02:15, 19.73it/s]\titers: 2700, epoch: 4 | loss: 0.3569061\n",
      "\tspeed: 0.0528s/iter; left time: 4168.3547s\n",
      "2798it [02:20, 19.82it/s]\titers: 2800, epoch: 4 | loss: 0.2841214\n",
      "\tspeed: 0.0505s/iter; left time: 3986.1204s\n",
      "2898it [02:25, 19.79it/s]\titers: 2900, epoch: 4 | loss: 0.2080155\n",
      "\tspeed: 0.0505s/iter; left time: 3978.5171s\n",
      "2999it [02:30, 15.15it/s]\titers: 3000, epoch: 4 | loss: 0.2030192\n",
      "\tspeed: 0.0539s/iter; left time: 4242.7769s\n",
      "3099it [02:35, 19.76it/s]\titers: 3100, epoch: 4 | loss: 0.3112698\n",
      "\tspeed: 0.0539s/iter; left time: 4234.0956s\n",
      "3199it [02:40, 19.82it/s]\titers: 3200, epoch: 4 | loss: 0.2029513\n",
      "\tspeed: 0.0500s/iter; left time: 3924.4728s\n",
      "3299it [02:45, 19.67it/s]\titers: 3300, epoch: 4 | loss: 0.2659861\n",
      "\tspeed: 0.0506s/iter; left time: 3967.4035s\n",
      "3398it [02:51, 19.90it/s]\titers: 3400, epoch: 4 | loss: 0.3788758\n",
      "\tspeed: 0.0514s/iter; left time: 4025.0249s\n",
      "3499it [02:56, 19.71it/s]\titers: 3500, epoch: 4 | loss: 0.1297239\n",
      "\tspeed: 0.0508s/iter; left time: 3975.1068s\n",
      "3598it [03:01, 19.02it/s]\titers: 3600, epoch: 4 | loss: 0.2766859\n",
      "\tspeed: 0.0512s/iter; left time: 3997.5451s\n",
      "3698it [03:06, 17.56it/s]\titers: 3700, epoch: 4 | loss: 0.1081158\n",
      "\tspeed: 0.0549s/iter; left time: 4280.2511s\n",
      "3713it [03:07, 19.79it/s]\n",
      "Epoch: 4 cost time: 187.65424132347107\n",
      "810it [00:20, 40.29it/s]\n",
      "807it [00:20, 40.02it/s]\n",
      "Epoch: 4 | Train Loss: 0.2632696 Vali Loss: 0.2970087 Test Loss: 0.3617684 MAE Loss: 0.3854312\n",
      "Updating learning rate to 5.000000000000003e-07\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 5.000000000000003e-07\n",
      "99it [00:05, 17.95it/s]\titers: 100, epoch: 5 | loss: 0.4764091\n",
      "\tspeed: 0.4817s/iter; left time: 37508.6846s\n",
      "199it [00:11, 18.02it/s]\titers: 200, epoch: 5 | loss: 0.1777701\n",
      "\tspeed: 0.0558s/iter; left time: 4339.9781s\n",
      "299it [00:17, 17.96it/s]\titers: 300, epoch: 5 | loss: 0.1579572\n",
      "\tspeed: 0.0565s/iter; left time: 4385.5899s\n",
      "398it [00:22, 19.69it/s]\titers: 400, epoch: 5 | loss: 0.2620887\n",
      "\tspeed: 0.0533s/iter; left time: 4137.3992s\n",
      "499it [00:27, 21.98it/s]\titers: 500, epoch: 5 | loss: 0.1970958\n",
      "\tspeed: 0.0469s/iter; left time: 3630.1378s\n",
      "599it [00:32, 17.63it/s]\titers: 600, epoch: 5 | loss: 0.5398354\n",
      "\tspeed: 0.0550s/iter; left time: 4253.5421s\n",
      "697it [00:37, 21.42it/s]\titers: 700, epoch: 5 | loss: 0.3900315\n",
      "\tspeed: 0.0528s/iter; left time: 4078.8748s\n",
      "799it [00:42, 20.41it/s]\titers: 800, epoch: 5 | loss: 0.1699623\n",
      "\tspeed: 0.0491s/iter; left time: 3786.8366s\n",
      "899it [00:47, 20.19it/s]\titers: 900, epoch: 5 | loss: 0.2420781\n",
      "\tspeed: 0.0479s/iter; left time: 3691.4771s\n",
      "999it [00:52, 18.07it/s]\titers: 1000, epoch: 5 | loss: 0.4318485\n",
      "\tspeed: 0.0536s/iter; left time: 4122.7068s\n",
      "1099it [00:58, 21.05it/s]\titers: 1100, epoch: 5 | loss: 0.4541746\n",
      "\tspeed: 0.0516s/iter; left time: 3964.8292s\n",
      "1199it [01:02, 19.81it/s]\titers: 1200, epoch: 5 | loss: 0.3823799\n",
      "\tspeed: 0.0482s/iter; left time: 3697.8755s\n",
      "1298it [01:07, 20.81it/s]\titers: 1300, epoch: 5 | loss: 0.2353701\n",
      "\tspeed: 0.0489s/iter; left time: 3747.1213s\n",
      "1399it [01:13, 18.97it/s]\titers: 1400, epoch: 5 | loss: 0.2638191\n",
      "\tspeed: 0.0552s/iter; left time: 4228.9014s\n",
      "1499it [01:18, 18.19it/s]\titers: 1500, epoch: 5 | loss: 0.2359437\n",
      "\tspeed: 0.0553s/iter; left time: 4230.5798s\n",
      "1598it [01:24, 18.19it/s]\titers: 1600, epoch: 5 | loss: 0.2089884\n",
      "\tspeed: 0.0550s/iter; left time: 4203.4772s\n",
      "1698it [01:30, 19.81it/s]\titers: 1700, epoch: 5 | loss: 0.2061583\n",
      "\tspeed: 0.0573s/iter; left time: 4373.3616s\n",
      "1799it [01:35, 19.25it/s]\titers: 1800, epoch: 5 | loss: 0.1992607\n",
      "\tspeed: 0.0543s/iter; left time: 4139.3373s\n",
      "1899it [01:40, 20.06it/s]\titers: 1900, epoch: 5 | loss: 0.1696610\n",
      "\tspeed: 0.0496s/iter; left time: 3772.2185s\n",
      "1998it [01:45, 19.78it/s]\titers: 2000, epoch: 5 | loss: 0.5184348\n",
      "\tspeed: 0.0542s/iter; left time: 4117.1255s\n",
      "2098it [01:51, 17.91it/s]\titers: 2100, epoch: 5 | loss: 0.3432605\n",
      "\tspeed: 0.0513s/iter; left time: 3889.2113s\n",
      "2198it [01:56, 17.98it/s]\titers: 2200, epoch: 5 | loss: 0.2928708\n",
      "\tspeed: 0.0546s/iter; left time: 4134.9102s\n",
      "2299it [02:02, 17.45it/s]\titers: 2300, epoch: 5 | loss: 0.2954674\n",
      "\tspeed: 0.0555s/iter; left time: 4196.3599s\n",
      "2399it [02:07, 18.09it/s]\titers: 2400, epoch: 5 | loss: 0.4758029\n",
      "\tspeed: 0.0558s/iter; left time: 4220.6171s\n",
      "2499it [02:12, 17.63it/s]\titers: 2500, epoch: 5 | loss: 0.2112109\n",
      "\tspeed: 0.0515s/iter; left time: 3890.3854s\n",
      "2599it [02:18, 17.39it/s]\titers: 2600, epoch: 5 | loss: 0.2779678\n",
      "\tspeed: 0.0539s/iter; left time: 4059.6247s\n",
      "2698it [02:23, 18.01it/s]\titers: 2700, epoch: 5 | loss: 0.2428833\n",
      "\tspeed: 0.0576s/iter; left time: 4334.6507s\n",
      "2799it [02:29, 17.91it/s]\titers: 2800, epoch: 5 | loss: 0.1622097\n",
      "\tspeed: 0.0552s/iter; left time: 4151.5086s\n",
      "2898it [02:34, 19.63it/s]\titers: 2900, epoch: 5 | loss: 0.2796517\n",
      "\tspeed: 0.0532s/iter; left time: 3991.7409s\n",
      "2998it [02:40, 17.18it/s]\titers: 3000, epoch: 5 | loss: 0.1396985\n",
      "\tspeed: 0.0596s/iter; left time: 4470.4979s\n",
      "3097it [02:45, 19.73it/s]\titers: 3100, epoch: 5 | loss: 0.1957508\n",
      "\tspeed: 0.0532s/iter; left time: 3983.9082s\n",
      "3199it [02:51, 19.57it/s]\titers: 3200, epoch: 5 | loss: 0.2264999\n",
      "\tspeed: 0.0507s/iter; left time: 3791.1434s\n",
      "3298it [02:56, 19.76it/s]\titers: 3300, epoch: 5 | loss: 0.3092258\n",
      "\tspeed: 0.0515s/iter; left time: 3842.7414s\n",
      "3399it [03:01, 19.67it/s]\titers: 3400, epoch: 5 | loss: 0.2931702\n",
      "\tspeed: 0.0559s/iter; left time: 4168.3805s\n",
      "3498it [03:06, 19.77it/s]\titers: 3500, epoch: 5 | loss: 0.2309305\n",
      "\tspeed: 0.0508s/iter; left time: 3779.5971s\n",
      "3598it [03:11, 19.78it/s]\titers: 3600, epoch: 5 | loss: 0.3617947\n",
      "\tspeed: 0.0506s/iter; left time: 3761.0983s\n",
      "3698it [03:17, 15.02it/s]\titers: 3700, epoch: 5 | loss: 0.1971013\n",
      "\tspeed: 0.0529s/iter; left time: 3930.6492s\n",
      "3713it [03:18, 18.74it/s]\n",
      "Epoch: 5 cost time: 198.08990097045898\n",
      "810it [00:20, 39.90it/s]\n",
      "807it [00:20, 39.93it/s]\n",
      "Epoch: 5 | Train Loss: 0.2615719 Vali Loss: 0.2940261 Test Loss: 0.3581339 MAE Loss: 0.3751089\n",
      "Updating learning rate to 2.5000000000000015e-07\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 2.5000000000000015e-07\n",
      "98it [00:05, 19.74it/s]\titers: 100, epoch: 6 | loss: 0.2924639\n",
      "\tspeed: 0.4770s/iter; left time: 35371.8587s\n",
      "197it [00:10, 19.71it/s]\titers: 200, epoch: 6 | loss: 0.3288267\n",
      "\tspeed: 0.0505s/iter; left time: 3742.7646s\n",
      "297it [00:14, 23.39it/s]\titers: 300, epoch: 6 | loss: 0.1740759\n",
      "\tspeed: 0.0463s/iter; left time: 3423.7509s\n",
      "399it [00:19, 22.97it/s]\titers: 400, epoch: 6 | loss: 0.2559707\n",
      "\tspeed: 0.0432s/iter; left time: 3189.1731s\n",
      "498it [00:23, 23.18it/s]\titers: 500, epoch: 6 | loss: 0.2159299\n",
      "\tspeed: 0.0434s/iter; left time: 3204.0610s\n",
      "597it [00:27, 22.91it/s]\titers: 600, epoch: 6 | loss: 0.2496518\n",
      "\tspeed: 0.0436s/iter; left time: 3213.6811s\n",
      "699it [00:32, 23.43it/s]\titers: 700, epoch: 6 | loss: 0.1421504\n",
      "\tspeed: 0.0451s/iter; left time: 3313.9665s\n",
      "798it [00:36, 23.19it/s]\titers: 800, epoch: 6 | loss: 0.2444589\n",
      "\tspeed: 0.0430s/iter; left time: 3157.1722s\n",
      "897it [00:41, 20.67it/s]\titers: 900, epoch: 6 | loss: 0.2113967\n",
      "\tspeed: 0.0443s/iter; left time: 3249.6286s\n",
      "998it [00:46, 19.71it/s]\titers: 1000, epoch: 6 | loss: 0.2832673\n",
      "\tspeed: 0.0505s/iter; left time: 3702.3691s\n",
      "1099it [00:51, 19.64it/s]\titers: 1100, epoch: 6 | loss: 0.2038699\n",
      "\tspeed: 0.0502s/iter; left time: 3669.3996s\n",
      "1199it [00:56, 19.78it/s]\titers: 1200, epoch: 6 | loss: 0.2685325\n",
      "\tspeed: 0.0507s/iter; left time: 3704.9547s\n",
      "1299it [01:01, 19.79it/s]\titers: 1300, epoch: 6 | loss: 0.2262891\n",
      "\tspeed: 0.0506s/iter; left time: 3691.7493s\n",
      "1399it [01:06, 18.87it/s]\titers: 1400, epoch: 6 | loss: 0.3038735\n",
      "\tspeed: 0.0510s/iter; left time: 3716.0021s\n",
      "1498it [01:11, 19.83it/s]\titers: 1500, epoch: 6 | loss: 0.2284592\n",
      "\tspeed: 0.0510s/iter; left time: 3709.2575s\n",
      "1598it [01:16, 19.72it/s]\titers: 1600, epoch: 6 | loss: 0.3664175\n",
      "\tspeed: 0.0506s/iter; left time: 3675.5482s\n",
      "1699it [01:21, 19.74it/s]\titers: 1700, epoch: 6 | loss: 0.2605773\n",
      "\tspeed: 0.0507s/iter; left time: 3678.7992s\n",
      "1799it [01:26, 19.77it/s]\titers: 1800, epoch: 6 | loss: 0.3252819\n",
      "\tspeed: 0.0518s/iter; left time: 3752.8735s\n",
      "1898it [01:31, 19.93it/s]\titers: 1900, epoch: 6 | loss: 0.2510643\n",
      "\tspeed: 0.0504s/iter; left time: 3645.1292s\n",
      "1998it [01:36, 19.75it/s]\titers: 2000, epoch: 6 | loss: 0.3350762\n",
      "\tspeed: 0.0505s/iter; left time: 3646.8707s\n",
      "2099it [01:42, 19.77it/s]\titers: 2100, epoch: 6 | loss: 0.2013160\n",
      "\tspeed: 0.0506s/iter; left time: 3649.1695s\n",
      "2198it [01:47, 20.07it/s]\titers: 2200, epoch: 6 | loss: 0.1842322\n",
      "\tspeed: 0.0508s/iter; left time: 3662.3885s\n",
      "2299it [01:52, 19.74it/s]\titers: 2300, epoch: 6 | loss: 0.1796706\n",
      "\tspeed: 0.0505s/iter; left time: 3630.8573s\n",
      "2399it [01:57, 19.84it/s]\titers: 2400, epoch: 6 | loss: 0.2138801\n",
      "\tspeed: 0.0505s/iter; left time: 3631.9153s\n",
      "2498it [02:02, 19.66it/s]\titers: 2500, epoch: 6 | loss: 0.3059168\n",
      "\tspeed: 0.0521s/iter; left time: 3741.4692s\n",
      "2599it [02:07, 19.75it/s]\titers: 2600, epoch: 6 | loss: 0.3566888\n",
      "\tspeed: 0.0504s/iter; left time: 3614.7532s\n",
      "2698it [02:12, 19.94it/s]\titers: 2700, epoch: 6 | loss: 0.2136664\n",
      "\tspeed: 0.0494s/iter; left time: 3538.4846s\n",
      "2799it [02:17, 19.81it/s]\titers: 2800, epoch: 6 | loss: 0.1746127\n",
      "\tspeed: 0.0506s/iter; left time: 3615.1582s\n",
      "2898it [02:22, 19.87it/s]\titers: 2900, epoch: 6 | loss: 0.1840023\n",
      "\tspeed: 0.0546s/iter; left time: 3893.3771s\n",
      "2999it [02:28, 19.85it/s]\titers: 3000, epoch: 6 | loss: 0.2740930\n",
      "\tspeed: 0.0504s/iter; left time: 3592.7274s\n",
      "3098it [02:33, 19.80it/s]\titers: 3100, epoch: 6 | loss: 0.2484753\n",
      "\tspeed: 0.0505s/iter; left time: 3590.4665s\n",
      "3199it [02:38, 15.66it/s]\titers: 3200, epoch: 6 | loss: 0.3078261\n",
      "\tspeed: 0.0539s/iter; left time: 3827.1663s\n",
      "3299it [02:43, 19.80it/s]\titers: 3300, epoch: 6 | loss: 0.2242627\n",
      "\tspeed: 0.0505s/iter; left time: 3581.7569s\n",
      "3399it [02:48, 19.76it/s]\titers: 3400, epoch: 6 | loss: 0.3180671\n",
      "\tspeed: 0.0506s/iter; left time: 3583.2537s\n",
      "3499it [02:53, 19.89it/s]\titers: 3500, epoch: 6 | loss: 0.1906879\n",
      "\tspeed: 0.0505s/iter; left time: 3575.3914s\n",
      "3597it [02:58, 23.26it/s]\titers: 3600, epoch: 6 | loss: 0.2923839\n",
      "\tspeed: 0.0471s/iter; left time: 3326.3598s\n",
      "3698it [03:02, 19.90it/s]\titers: 3700, epoch: 6 | loss: 0.1533875\n",
      "\tspeed: 0.0450s/iter; left time: 3177.5065s\n",
      "3713it [03:03, 20.22it/s]\n",
      "Epoch: 6 cost time: 183.61506366729736\n",
      "810it [00:20, 40.08it/s]\n",
      "807it [00:20, 40.10it/s]\n",
      "Epoch: 6 | Train Loss: 0.2602838 Vali Loss: 0.2938139 Test Loss: 0.3582064 MAE Loss: 0.3764168\n",
      "Updating learning rate to 1.2500000000000007e-07\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 1.2500000000000007e-07\n",
      "99it [00:04, 22.69it/s]\titers: 100, epoch: 7 | loss: 0.2666512\n",
      "\tspeed: 0.4694s/iter; left time: 33069.0294s\n",
      "198it [00:09, 19.14it/s]\titers: 200, epoch: 7 | loss: 0.1968661\n",
      "\tspeed: 0.0503s/iter; left time: 3538.7010s\n",
      "299it [00:14, 19.80it/s]\titers: 300, epoch: 7 | loss: 0.1422561\n",
      "\tspeed: 0.0505s/iter; left time: 3548.0150s\n",
      "399it [00:19, 19.37it/s]\titers: 400, epoch: 7 | loss: 0.2974734\n",
      "\tspeed: 0.0517s/iter; left time: 3629.6368s\n",
      "498it [00:24, 19.74it/s]\titers: 500, epoch: 7 | loss: 0.2570440\n",
      "\tspeed: 0.0510s/iter; left time: 3571.2144s\n",
      "598it [00:30, 19.81it/s]\titers: 600, epoch: 7 | loss: 0.2058016\n",
      "\tspeed: 0.0554s/iter; left time: 3877.1863s\n",
      "699it [00:35, 19.95it/s]\titers: 700, epoch: 7 | loss: 0.3065006\n",
      "\tspeed: 0.0505s/iter; left time: 3523.8380s\n",
      "798it [00:40, 19.82it/s]\titers: 800, epoch: 7 | loss: 0.2393438\n",
      "\tspeed: 0.0505s/iter; left time: 3525.1570s\n",
      "898it [00:45, 15.24it/s]\titers: 900, epoch: 7 | loss: 0.1728936\n",
      "\tspeed: 0.0530s/iter; left time: 3691.1666s\n",
      "998it [00:51, 19.22it/s]\titers: 1000, epoch: 7 | loss: 0.4045295\n",
      "\tspeed: 0.0509s/iter; left time: 3542.6288s\n",
      "1098it [00:56, 19.15it/s]\titers: 1100, epoch: 7 | loss: 0.1606897\n",
      "\tspeed: 0.0502s/iter; left time: 3482.9024s\n",
      "1198it [01:01, 19.74it/s]\titers: 1200, epoch: 7 | loss: 0.2033209\n",
      "\tspeed: 0.0505s/iter; left time: 3502.2420s\n",
      "1298it [01:06, 16.94it/s]\titers: 1300, epoch: 7 | loss: 0.2632527\n",
      "\tspeed: 0.0509s/iter; left time: 3522.1923s\n",
      "1399it [01:11, 19.41it/s]\titers: 1400, epoch: 7 | loss: 0.2855108\n",
      "\tspeed: 0.0504s/iter; left time: 3484.3435s\n",
      "1499it [01:16, 19.68it/s]\titers: 1500, epoch: 7 | loss: 0.2799190\n",
      "\tspeed: 0.0514s/iter; left time: 3546.1847s\n",
      "1598it [01:21, 18.21it/s]\titers: 1600, epoch: 7 | loss: 0.1651811\n",
      "\tspeed: 0.0517s/iter; left time: 3563.6046s\n",
      "1699it [01:26, 19.53it/s]\titers: 1700, epoch: 7 | loss: 0.2743715\n",
      "\tspeed: 0.0532s/iter; left time: 3665.4438s\n",
      "1798it [01:31, 19.28it/s]\titers: 1800, epoch: 7 | loss: 0.2733626\n",
      "\tspeed: 0.0500s/iter; left time: 3435.8257s\n",
      "1899it [01:37, 18.63it/s]\titers: 1900, epoch: 7 | loss: 0.2699868\n",
      "\tspeed: 0.0517s/iter; left time: 3547.9147s\n",
      "1998it [01:42, 18.57it/s]\titers: 2000, epoch: 7 | loss: 0.2671144\n",
      "\tspeed: 0.0520s/iter; left time: 3567.3567s\n",
      "2098it [01:47, 19.76it/s]\titers: 2100, epoch: 7 | loss: 0.2033662\n",
      "\tspeed: 0.0524s/iter; left time: 3588.5957s\n",
      "2199it [01:52, 19.80it/s]\titers: 2200, epoch: 7 | loss: 0.1990301\n",
      "\tspeed: 0.0508s/iter; left time: 3471.9938s\n",
      "2298it [01:57, 19.55it/s]\titers: 2300, epoch: 7 | loss: 0.1941026\n",
      "\tspeed: 0.0518s/iter; left time: 3532.5332s\n",
      "2398it [02:02, 19.67it/s]\titers: 2400, epoch: 7 | loss: 0.3078028\n",
      "\tspeed: 0.0512s/iter; left time: 3486.7938s\n",
      "2499it [02:08, 19.72it/s]\titers: 2500, epoch: 7 | loss: 0.3217289\n",
      "\tspeed: 0.0526s/iter; left time: 3579.1458s\n",
      "2598it [02:13, 18.18it/s]\titers: 2600, epoch: 7 | loss: 0.1922292\n",
      "\tspeed: 0.0519s/iter; left time: 3525.7308s\n",
      "2698it [02:18, 19.44it/s]\titers: 2700, epoch: 7 | loss: 0.2740965\n",
      "\tspeed: 0.0514s/iter; left time: 3487.5241s\n",
      "2799it [02:23, 19.66it/s]\titers: 2800, epoch: 7 | loss: 0.2255042\n",
      "\tspeed: 0.0521s/iter; left time: 3530.0803s\n",
      "2899it [02:29, 19.70it/s]\titers: 2900, epoch: 7 | loss: 0.3295185\n",
      "\tspeed: 0.0540s/iter; left time: 3655.5004s\n",
      "2998it [02:34, 19.80it/s]\titers: 3000, epoch: 7 | loss: 0.2317319\n",
      "\tspeed: 0.0506s/iter; left time: 3418.7084s\n",
      "3098it [02:39, 19.67it/s]\titers: 3100, epoch: 7 | loss: 0.2718654\n",
      "\tspeed: 0.0515s/iter; left time: 3470.9742s\n",
      "3198it [02:44, 19.45it/s]\titers: 3200, epoch: 7 | loss: 0.1681557\n",
      "\tspeed: 0.0521s/iter; left time: 3509.2753s\n",
      "3298it [02:49, 19.62it/s]\titers: 3300, epoch: 7 | loss: 0.2545454\n",
      "\tspeed: 0.0500s/iter; left time: 3361.5349s\n",
      "3399it [02:54, 19.71it/s]\titers: 3400, epoch: 7 | loss: 0.2841327\n",
      "\tspeed: 0.0517s/iter; left time: 3470.8460s\n",
      "3499it [02:59, 18.73it/s]\titers: 3500, epoch: 7 | loss: 0.2417724\n",
      "\tspeed: 0.0514s/iter; left time: 3444.1597s\n",
      "3598it [03:05, 19.52it/s]\titers: 3600, epoch: 7 | loss: 0.2310693\n",
      "\tspeed: 0.0525s/iter; left time: 3516.6042s\n",
      "3699it [03:10, 19.55it/s]\titers: 3700, epoch: 7 | loss: 0.5034436\n",
      "\tspeed: 0.0510s/iter; left time: 3410.4382s\n",
      "3713it [03:10, 19.44it/s]\n",
      "Epoch: 7 cost time: 190.96903681755066\n",
      "810it [00:20, 39.67it/s]\n",
      "807it [00:20, 38.96it/s]\n",
      "Epoch: 7 | Train Loss: 0.2598909 Vali Loss: 0.2931266 Test Loss: 0.3567285 MAE Loss: 0.3760418\n",
      "Updating learning rate to 6.250000000000004e-08\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 6.250000000000004e-08\n",
      "99it [00:05, 19.79it/s]\titers: 100, epoch: 8 | loss: 0.3359127\n",
      "\tspeed: 0.4872s/iter; left time: 32512.3286s\n",
      "199it [00:10, 18.93it/s]\titers: 200, epoch: 8 | loss: 0.2898010\n",
      "\tspeed: 0.0519s/iter; left time: 3456.8886s\n",
      "297it [00:15, 19.74it/s]\titers: 300, epoch: 8 | loss: 0.2425419\n",
      "\tspeed: 0.0513s/iter; left time: 3416.0467s\n",
      "398it [00:21, 18.32it/s]\titers: 400, epoch: 8 | loss: 0.2997702\n",
      "\tspeed: 0.0541s/iter; left time: 3596.3058s\n",
      "498it [00:26, 19.54it/s]\titers: 500, epoch: 8 | loss: 0.4541180\n",
      "\tspeed: 0.0524s/iter; left time: 3478.3610s\n",
      "598it [00:31, 19.37it/s]\titers: 600, epoch: 8 | loss: 0.1259780\n",
      "\tspeed: 0.0521s/iter; left time: 3447.8469s\n",
      "697it [00:36, 16.94it/s]\titers: 700, epoch: 8 | loss: 0.2176243\n",
      "\tspeed: 0.0541s/iter; left time: 3579.1664s\n",
      "799it [00:42, 19.38it/s]\titers: 800, epoch: 8 | loss: 0.2739862\n",
      "\tspeed: 0.0512s/iter; left time: 3381.4605s\n",
      "899it [00:47, 19.17it/s]\titers: 900, epoch: 8 | loss: 0.2846550\n",
      "\tspeed: 0.0514s/iter; left time: 3391.2813s\n",
      "997it [00:52, 17.99it/s]\titers: 1000, epoch: 8 | loss: 0.2450302\n",
      "\tspeed: 0.0520s/iter; left time: 3424.1695s\n",
      "1098it [00:57, 19.34it/s]\titers: 1100, epoch: 8 | loss: 0.1794203\n",
      "\tspeed: 0.0547s/iter; left time: 3598.8572s\n",
      "1199it [01:03, 19.33it/s]\titers: 1200, epoch: 8 | loss: 0.2307662\n",
      "\tspeed: 0.0513s/iter; left time: 3369.4983s\n",
      "1299it [01:08, 18.88it/s]\titers: 1300, epoch: 8 | loss: 0.1367794\n",
      "\tspeed: 0.0522s/iter; left time: 3421.2603s\n",
      "1398it [01:13, 18.93it/s]\titers: 1400, epoch: 8 | loss: 0.2296386\n",
      "\tspeed: 0.0527s/iter; left time: 3448.9487s\n",
      "1499it [01:18, 19.63it/s]\titers: 1500, epoch: 8 | loss: 0.1951153\n",
      "\tspeed: 0.0540s/iter; left time: 3528.8839s\n",
      "1598it [01:24, 19.63it/s]\titers: 1600, epoch: 8 | loss: 0.3335105\n",
      "\tspeed: 0.0514s/iter; left time: 3352.2764s\n",
      "1699it [01:29, 19.65it/s]\titers: 1700, epoch: 8 | loss: 0.1659914\n",
      "\tspeed: 0.0511s/iter; left time: 3331.0165s\n",
      "1799it [01:34, 20.77it/s]\titers: 1800, epoch: 8 | loss: 0.2293361\n",
      "\tspeed: 0.0515s/iter; left time: 3351.0088s\n",
      "1899it [01:39, 19.56it/s]\titers: 1900, epoch: 8 | loss: 0.2059704\n",
      "\tspeed: 0.0540s/iter; left time: 3508.8064s\n",
      "1999it [01:45, 18.42it/s]\titers: 2000, epoch: 8 | loss: 0.1666517\n",
      "\tspeed: 0.0527s/iter; left time: 3415.8484s\n",
      "2098it [01:50, 19.66it/s]\titers: 2100, epoch: 8 | loss: 0.4471115\n",
      "\tspeed: 0.0514s/iter; left time: 3326.3064s\n",
      "2198it [01:55, 17.12it/s]\titers: 2200, epoch: 8 | loss: 0.2890432\n",
      "\tspeed: 0.0525s/iter; left time: 3396.5437s\n",
      "2299it [02:00, 19.09it/s]\titers: 2300, epoch: 8 | loss: 0.2506794\n",
      "\tspeed: 0.0531s/iter; left time: 3424.6405s\n",
      "2398it [02:05, 19.81it/s]\titers: 2400, epoch: 8 | loss: 0.3974907\n",
      "\tspeed: 0.0504s/iter; left time: 3248.3674s\n",
      "2498it [02:10, 18.95it/s]\titers: 2500, epoch: 8 | loss: 0.4030070\n",
      "\tspeed: 0.0514s/iter; left time: 3307.2439s\n",
      "2598it [02:16, 18.49it/s]\titers: 2600, epoch: 8 | loss: 0.3205005\n",
      "\tspeed: 0.0546s/iter; left time: 3504.6275s\n",
      "2698it [02:21, 18.67it/s]\titers: 2700, epoch: 8 | loss: 0.2014420\n",
      "\tspeed: 0.0533s/iter; left time: 3421.5792s\n",
      "2798it [02:26, 19.12it/s]\titers: 2800, epoch: 8 | loss: 0.5156963\n",
      "\tspeed: 0.0528s/iter; left time: 3383.1613s\n",
      "2899it [02:32, 19.57it/s]\titers: 2900, epoch: 8 | loss: 0.3185987\n",
      "\tspeed: 0.0520s/iter; left time: 3326.5311s\n",
      "2999it [02:37, 19.25it/s]\titers: 3000, epoch: 8 | loss: 0.2006791\n",
      "\tspeed: 0.0547s/iter; left time: 3489.6433s\n",
      "3099it [02:42, 19.62it/s]\titers: 3100, epoch: 8 | loss: 0.2652395\n",
      "\tspeed: 0.0510s/iter; left time: 3249.4734s\n",
      "3199it [02:48, 20.00it/s]\titers: 3200, epoch: 8 | loss: 0.2616567\n",
      "\tspeed: 0.0534s/iter; left time: 3399.5346s\n",
      "3299it [02:53, 19.16it/s]\titers: 3300, epoch: 8 | loss: 0.3022174\n",
      "\tspeed: 0.0532s/iter; left time: 3382.3169s\n",
      "3399it [02:58, 19.57it/s]\titers: 3400, epoch: 8 | loss: 0.2124904\n",
      "\tspeed: 0.0527s/iter; left time: 3340.3872s\n",
      "3499it [03:03, 18.52it/s]\titers: 3500, epoch: 8 | loss: 0.4043207\n",
      "\tspeed: 0.0513s/iter; left time: 3249.2615s\n",
      "3598it [03:08, 19.70it/s]\titers: 3600, epoch: 8 | loss: 0.3652759\n",
      "\tspeed: 0.0512s/iter; left time: 3238.4730s\n",
      "3698it [03:14, 18.44it/s]\titers: 3700, epoch: 8 | loss: 0.2707058\n",
      "\tspeed: 0.0528s/iter; left time: 3333.9038s\n",
      "3713it [03:15, 19.03it/s]\n",
      "Epoch: 8 cost time: 195.07577919960022\n",
      "810it [00:21, 37.65it/s]\n",
      "807it [00:21, 37.78it/s]\n",
      "Epoch: 8 | Train Loss: 0.2604993 Vali Loss: 0.2943356 Test Loss: 0.3588334 MAE Loss: 0.3791357\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125000000000002e-08\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 3.125000000000002e-08\n",
      "98it [00:05, 19.61it/s]\titers: 100, epoch: 9 | loss: 0.1790596\n",
      "\tspeed: 0.4924s/iter; left time: 31032.0602s\n",
      "198it [00:10, 17.66it/s]\titers: 200, epoch: 9 | loss: 0.2384738\n",
      "\tspeed: 0.0555s/iter; left time: 3495.2852s\n",
      "299it [00:16, 19.76it/s]\titers: 300, epoch: 9 | loss: 0.2938529\n",
      "\tspeed: 0.0536s/iter; left time: 3364.4945s\n",
      "399it [00:21, 19.84it/s]\titers: 400, epoch: 9 | loss: 0.2081152\n",
      "\tspeed: 0.0509s/iter; left time: 3193.8962s\n",
      "498it [00:26, 19.83it/s]\titers: 500, epoch: 9 | loss: 0.1959091\n",
      "\tspeed: 0.0506s/iter; left time: 3167.2599s\n",
      "599it [00:31, 17.48it/s]\titers: 600, epoch: 9 | loss: 0.1740111\n",
      "\tspeed: 0.0524s/iter; left time: 3273.8220s\n",
      "698it [00:36, 18.79it/s]\titers: 700, epoch: 9 | loss: 0.3880602\n",
      "\tspeed: 0.0521s/iter; left time: 3252.9994s\n",
      "798it [00:42, 19.98it/s]\titers: 800, epoch: 9 | loss: 0.1961279\n",
      "\tspeed: 0.0529s/iter; left time: 3294.1042s\n",
      "899it [00:47, 19.10it/s]\titers: 900, epoch: 9 | loss: 0.5073641\n",
      "\tspeed: 0.0535s/iter; left time: 3326.6759s\n",
      "999it [00:52, 19.03it/s]\titers: 1000, epoch: 9 | loss: 0.1670739\n",
      "\tspeed: 0.0520s/iter; left time: 3230.2559s\n",
      "1099it [00:58, 16.67it/s]\titers: 1100, epoch: 9 | loss: 0.3195287\n",
      "\tspeed: 0.0533s/iter; left time: 3308.5083s\n",
      "1198it [01:03, 17.22it/s]\titers: 1200, epoch: 9 | loss: 0.2854145\n",
      "\tspeed: 0.0532s/iter; left time: 3292.7969s\n",
      "1299it [01:08, 18.66it/s]\titers: 1300, epoch: 9 | loss: 0.2141262\n",
      "\tspeed: 0.0517s/iter; left time: 3194.3086s\n",
      "1399it [01:13, 17.90it/s]\titers: 1400, epoch: 9 | loss: 0.2479038\n",
      "\tspeed: 0.0527s/iter; left time: 3252.8593s\n",
      "1498it [01:19, 18.88it/s]\titers: 1500, epoch: 9 | loss: 0.3990278\n",
      "\tspeed: 0.0524s/iter; left time: 3230.2473s\n",
      "1599it [01:24, 19.23it/s]\titers: 1600, epoch: 9 | loss: 0.2025762\n",
      "\tspeed: 0.0518s/iter; left time: 3186.5216s\n",
      "1698it [01:29, 18.87it/s]\titers: 1700, epoch: 9 | loss: 0.1710771\n",
      "\tspeed: 0.0522s/iter; left time: 3204.9793s\n",
      "1798it [01:34, 18.95it/s]\titers: 1800, epoch: 9 | loss: 0.2629305\n",
      "\tspeed: 0.0512s/iter; left time: 3137.0705s\n",
      "1899it [01:39, 18.15it/s]\titers: 1900, epoch: 9 | loss: 0.2330240\n",
      "\tspeed: 0.0529s/iter; left time: 3241.3291s\n",
      "1997it [01:45, 19.54it/s]\titers: 2000, epoch: 9 | loss: 0.3747727\n",
      "\tspeed: 0.0519s/iter; left time: 3173.9370s\n",
      "2098it [01:50, 18.00it/s]\titers: 2100, epoch: 9 | loss: 0.2604649\n",
      "\tspeed: 0.0516s/iter; left time: 3145.7535s\n",
      "2198it [01:55, 19.07it/s]\titers: 2200, epoch: 9 | loss: 0.3093474\n",
      "\tspeed: 0.0525s/iter; left time: 3196.6587s\n",
      "2298it [02:00, 17.67it/s]\titers: 2300, epoch: 9 | loss: 0.2126524\n",
      "\tspeed: 0.0537s/iter; left time: 3265.2256s\n",
      "2398it [02:05, 19.47it/s]\titers: 2400, epoch: 9 | loss: 0.3865285\n",
      "\tspeed: 0.0510s/iter; left time: 3094.1214s\n",
      "2498it [02:11, 19.22it/s]\titers: 2500, epoch: 9 | loss: 0.1479678\n",
      "\tspeed: 0.0522s/iter; left time: 3166.8242s\n",
      "2598it [02:16, 19.76it/s]\titers: 2600, epoch: 9 | loss: 0.2074650\n",
      "\tspeed: 0.0516s/iter; left time: 3124.0658s\n",
      "2699it [02:21, 19.00it/s]\titers: 2700, epoch: 9 | loss: 0.3187999\n",
      "\tspeed: 0.0514s/iter; left time: 3107.9985s\n",
      "2799it [02:26, 19.64it/s]\titers: 2800, epoch: 9 | loss: 0.2104483\n",
      "\tspeed: 0.0506s/iter; left time: 3052.3035s\n",
      "2899it [02:31, 18.89it/s]\titers: 2900, epoch: 9 | loss: 0.3199832\n",
      "\tspeed: 0.0513s/iter; left time: 3090.6092s\n",
      "2998it [02:36, 19.09it/s]\titers: 3000, epoch: 9 | loss: 0.2843294\n",
      "\tspeed: 0.0531s/iter; left time: 3193.2511s\n",
      "3099it [02:42, 18.91it/s]\titers: 3100, epoch: 9 | loss: 0.1549636\n",
      "\tspeed: 0.0517s/iter; left time: 3104.5404s\n",
      "3199it [02:47, 19.01it/s]\titers: 3200, epoch: 9 | loss: 0.3207557\n",
      "\tspeed: 0.0521s/iter; left time: 3120.0250s\n",
      "3299it [02:52, 18.86it/s]\titers: 3300, epoch: 9 | loss: 0.1548045\n",
      "\tspeed: 0.0534s/iter; left time: 3196.9060s\n",
      "3399it [02:58, 17.87it/s]\titers: 3400, epoch: 9 | loss: 0.4030761\n",
      "\tspeed: 0.0531s/iter; left time: 3168.2538s\n",
      "3499it [03:03, 20.28it/s]\titers: 3500, epoch: 9 | loss: 0.2445704\n",
      "\tspeed: 0.0541s/iter; left time: 3226.1311s\n",
      "3599it [03:08, 18.75it/s]\titers: 3600, epoch: 9 | loss: 0.4219190\n",
      "\tspeed: 0.0525s/iter; left time: 3123.6413s\n",
      "3698it [03:13, 19.12it/s]\titers: 3700, epoch: 9 | loss: 0.2549910\n",
      "\tspeed: 0.0524s/iter; left time: 3114.8904s\n",
      "3713it [03:14, 19.06it/s]\n",
      "Epoch: 9 cost time: 194.77181935310364\n",
      "810it [00:21, 37.65it/s]\n",
      "807it [00:21, 36.81it/s]\n",
      "Epoch: 9 | Train Loss: 0.2603529 Vali Loss: 0.2936725 Test Loss: 0.3577862 MAE Loss: 0.3773888\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.562500000000001e-08\n",
      "learning_rate 4.000000000000002e-06\n",
      "lr 1.562500000000001e-08\n",
      "98it [00:05, 17.87it/s]\titers: 100, epoch: 10 | loss: 0.3013602\n",
      "\tspeed: 0.4997s/iter; left time: 29635.4997s\n",
      "199it [00:10, 18.14it/s]\titers: 200, epoch: 10 | loss: 0.3627931\n",
      "\tspeed: 0.0528s/iter; left time: 3124.8320s\n",
      "299it [00:16, 20.52it/s]\titers: 300, epoch: 10 | loss: 0.2881521\n",
      "\tspeed: 0.0518s/iter; left time: 3061.1060s\n",
      "398it [00:21, 19.16it/s]\titers: 400, epoch: 10 | loss: 0.2496841\n",
      "\tspeed: 0.0532s/iter; left time: 3137.3790s\n",
      "497it [00:26, 20.91it/s]\titers: 500, epoch: 10 | loss: 0.4016547\n",
      "\tspeed: 0.0524s/iter; left time: 3086.1221s\n",
      "599it [00:30, 23.21it/s]\titers: 600, epoch: 10 | loss: 0.4106877\n",
      "\tspeed: 0.0436s/iter; left time: 2566.2050s\n",
      "697it [00:35, 20.21it/s]\titers: 700, epoch: 10 | loss: 0.3005719\n",
      "\tspeed: 0.0457s/iter; left time: 2685.1673s\n",
      "798it [00:40, 19.14it/s]\titers: 800, epoch: 10 | loss: 0.2281473\n",
      "\tspeed: 0.0510s/iter; left time: 2987.0468s\n",
      "899it [00:46, 17.01it/s]\titers: 900, epoch: 10 | loss: 0.2825311\n",
      "\tspeed: 0.0547s/iter; left time: 3200.6658s\n",
      "999it [00:51, 19.27it/s]\titers: 1000, epoch: 10 | loss: 0.1074284\n",
      "\tspeed: 0.0520s/iter; left time: 3038.0490s\n",
      "1097it [00:56, 19.60it/s]\titers: 1100, epoch: 10 | loss: 0.1505243\n",
      "\tspeed: 0.0522s/iter; left time: 3045.1741s\n",
      "1198it [01:01, 19.38it/s]\titers: 1200, epoch: 10 | loss: 0.2891285\n",
      "\tspeed: 0.0517s/iter; left time: 3007.5609s\n",
      "1297it [01:07, 18.18it/s]\titers: 1300, epoch: 10 | loss: 0.1795415\n",
      "\tspeed: 0.0539s/iter; left time: 3130.1026s\n",
      "1397it [01:12, 18.83it/s]\titers: 1400, epoch: 10 | loss: 0.2512758\n",
      "\tspeed: 0.0517s/iter; left time: 2996.5317s\n",
      "1499it [01:17, 18.78it/s]\titers: 1500, epoch: 10 | loss: 0.2999441\n",
      "\tspeed: 0.0528s/iter; left time: 3060.4356s\n",
      "1599it [01:22, 19.05it/s]\titers: 1600, epoch: 10 | loss: 0.3497382\n",
      "\tspeed: 0.0531s/iter; left time: 3068.6608s\n",
      "1698it [01:28, 19.56it/s]\titers: 1700, epoch: 10 | loss: 0.2442191\n",
      "\tspeed: 0.0532s/iter; left time: 3072.6642s\n",
      "1798it [01:33, 19.20it/s]\titers: 1800, epoch: 10 | loss: 0.2437807\n",
      "\tspeed: 0.0521s/iter; left time: 3000.4833s\n",
      "1899it [01:38, 18.61it/s]\titers: 1900, epoch: 10 | loss: 0.2203846\n",
      "\tspeed: 0.0523s/iter; left time: 3006.2813s\n",
      "1998it [01:43, 19.36it/s]\titers: 2000, epoch: 10 | loss: 0.2646002\n",
      "\tspeed: 0.0537s/iter; left time: 3081.6006s\n",
      "2097it [01:49, 22.65it/s]\titers: 2100, epoch: 10 | loss: 0.2283419\n",
      "\tspeed: 0.0514s/iter; left time: 2948.3749s\n",
      "2199it [01:54, 19.58it/s]\titers: 2200, epoch: 10 | loss: 0.1518914\n",
      "\tspeed: 0.0500s/iter; left time: 2858.1394s\n",
      "2299it [01:59, 19.19it/s]\titers: 2300, epoch: 10 | loss: 0.2515754\n",
      "\tspeed: 0.0524s/iter; left time: 2992.1482s\n",
      "2399it [02:04, 18.99it/s]\titers: 2400, epoch: 10 | loss: 0.2357031\n",
      "\tspeed: 0.0523s/iter; left time: 2982.8186s\n",
      "2499it [02:09, 18.93it/s]\titers: 2500, epoch: 10 | loss: 0.2150553\n",
      "\tspeed: 0.0532s/iter; left time: 3025.6226s\n",
      "2598it [02:15, 18.55it/s]\titers: 2600, epoch: 10 | loss: 0.3879880\n",
      "\tspeed: 0.0525s/iter; left time: 2984.2197s\n",
      "2698it [02:20, 19.51it/s]\titers: 2700, epoch: 10 | loss: 0.2239453\n",
      "\tspeed: 0.0517s/iter; left time: 2932.8695s\n",
      "2798it [02:25, 16.96it/s]\titers: 2800, epoch: 10 | loss: 0.2341577\n",
      "\tspeed: 0.0535s/iter; left time: 3031.2536s\n",
      "2899it [02:31, 19.85it/s]\titers: 2900, epoch: 10 | loss: 0.2022432\n",
      "\tspeed: 0.0533s/iter; left time: 3009.4123s\n",
      "2999it [02:36, 19.78it/s]\titers: 3000, epoch: 10 | loss: 0.2591501\n",
      "\tspeed: 0.0513s/iter; left time: 2896.5856s\n",
      "3099it [02:41, 19.54it/s]\titers: 3100, epoch: 10 | loss: 0.3875715\n",
      "\tspeed: 0.0522s/iter; left time: 2937.0692s\n",
      "3198it [02:46, 18.19it/s]\titers: 3200, epoch: 10 | loss: 0.2911085\n",
      "\tspeed: 0.0519s/iter; left time: 2916.0969s\n",
      "3299it [02:51, 20.26it/s]\titers: 3300, epoch: 10 | loss: 0.1515903\n",
      "\tspeed: 0.0517s/iter; left time: 2902.8081s\n",
      "3398it [02:56, 19.34it/s]\titers: 3400, epoch: 10 | loss: 0.2150358\n",
      "\tspeed: 0.0525s/iter; left time: 2941.4278s\n",
      "3498it [03:02, 19.71it/s]\titers: 3500, epoch: 10 | loss: 0.2574613\n",
      "\tspeed: 0.0508s/iter; left time: 2837.5188s\n",
      "3599it [03:07, 19.79it/s]\titers: 3600, epoch: 10 | loss: 0.1961029\n",
      "\tspeed: 0.0506s/iter; left time: 2825.4509s\n",
      "3699it [03:12, 19.28it/s]\titers: 3700, epoch: 10 | loss: 0.2232280\n",
      "\tspeed: 0.0516s/iter; left time: 2873.1386s\n",
      "3713it [03:13, 19.23it/s]\n",
      "Epoch: 10 cost time: 193.1019856929779\n",
      "810it [00:21, 37.24it/s]\n",
      "807it [00:22, 36.60it/s]\n",
      "Epoch: 10 | Train Loss: 0.2601232 Vali Loss: 0.2935839 Test Loss: 0.3576819 MAE Loss: 0.3769768\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 39.767927916844684 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=25\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.0001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 23:55:27,318] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 23:55:28,152] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 23:55:28,152] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 23:55:28,152] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 23:55:29,066] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-06 23:55:29,066] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 23:55:29,845] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 23:55:29,846] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 23:55:29,846] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 23:55:29,847] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 23:55:29,848] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 23:55:29,848] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 23:55:29,848] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 23:55:29,848] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 23:55:29,848] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 23:55:29,848] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 23:55:30,133] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 23:55:30,133] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 23:55:30,134] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.46 GB, percent = 16.0%\n",
      "[2024-05-06 23:55:30,256] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 23:55:30,256] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 23:55:30,256] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.46 GB, percent = 16.0%\n",
      "[2024-05-06 23:55:30,256] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 23:55:30,364] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 23:55:30,364] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 23:55:30,365] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.47 GB, percent = 16.0%\n",
      "[2024-05-06 23:55:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 23:55:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 23:55:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 23:55:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa1fca2d310>\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 23:55:30,366] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 23:55:30,367] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "99it [00:06, 16.51it/s]\titers: 100, epoch: 1 | loss: 0.7838810\n",
      "\tspeed: 0.1046s/iter; left time: 9696.1261s\n",
      "199it [00:12, 16.52it/s]\titers: 200, epoch: 1 | loss: 0.5610510\n",
      "\tspeed: 0.0601s/iter; left time: 5566.1468s\n",
      "299it [00:18, 18.54it/s]\titers: 300, epoch: 1 | loss: 0.5590044\n",
      "\tspeed: 0.0597s/iter; left time: 5526.1485s\n",
      "399it [00:23, 19.82it/s]\titers: 400, epoch: 1 | loss: 0.3248384\n",
      "\tspeed: 0.0512s/iter; left time: 4728.2658s\n",
      "499it [00:29, 18.30it/s]\titers: 500, epoch: 1 | loss: 0.2929696\n",
      "\tspeed: 0.0575s/iter; left time: 5306.0062s\n",
      "599it [00:35, 16.47it/s]\titers: 600, epoch: 1 | loss: 0.3455908\n",
      "\tspeed: 0.0605s/iter; left time: 5582.7034s\n",
      "699it [00:41, 18.38it/s]\titers: 700, epoch: 1 | loss: 0.4141468\n",
      "\tspeed: 0.0549s/iter; left time: 5057.4301s\n",
      "799it [00:46, 18.05it/s]\titers: 800, epoch: 1 | loss: 0.3625296\n",
      "\tspeed: 0.0546s/iter; left time: 5028.0999s\n",
      "899it [00:52, 18.04it/s]\titers: 900, epoch: 1 | loss: 0.2639542\n",
      "\tspeed: 0.0567s/iter; left time: 5214.7234s\n",
      "997it [00:57, 21.20it/s]\titers: 1000, epoch: 1 | loss: 0.2760091\n",
      "\tspeed: 0.0501s/iter; left time: 4604.4890s\n",
      "1099it [01:02, 20.95it/s]\titers: 1100, epoch: 1 | loss: 0.2516553\n",
      "\tspeed: 0.0472s/iter; left time: 4327.5371s\n",
      "1199it [01:06, 19.90it/s]\titers: 1200, epoch: 1 | loss: 0.2215645\n",
      "\tspeed: 0.0486s/iter; left time: 4456.1603s\n",
      "1299it [01:11, 15.16it/s]\titers: 1300, epoch: 1 | loss: 0.2447615\n",
      "\tspeed: 0.0499s/iter; left time: 4568.9355s\n",
      "1399it [01:17, 18.56it/s]\titers: 1400, epoch: 1 | loss: 0.3327679\n",
      "\tspeed: 0.0541s/iter; left time: 4942.3752s\n",
      "1497it [01:22, 20.29it/s]\titers: 1500, epoch: 1 | loss: 0.2921066\n",
      "\tspeed: 0.0519s/iter; left time: 4740.4039s\n",
      "1599it [01:27, 20.93it/s]\titers: 1600, epoch: 1 | loss: 0.3088431\n",
      "\tspeed: 0.0503s/iter; left time: 4584.6262s\n",
      "1698it [01:32, 19.31it/s]\titers: 1700, epoch: 1 | loss: 0.3954904\n",
      "\tspeed: 0.0491s/iter; left time: 4473.1061s\n",
      "1799it [01:37, 18.11it/s]\titers: 1800, epoch: 1 | loss: 0.3114397\n",
      "\tspeed: 0.0549s/iter; left time: 4995.6079s\n",
      "1899it [01:43, 18.60it/s]\titers: 1900, epoch: 1 | loss: 0.2767161\n",
      "\tspeed: 0.0546s/iter; left time: 4963.8488s\n",
      "1999it [01:48, 18.13it/s]\titers: 2000, epoch: 1 | loss: 0.3208857\n",
      "\tspeed: 0.0540s/iter; left time: 4907.3220s\n",
      "2097it [01:54, 20.87it/s]\titers: 2100, epoch: 1 | loss: 0.1797302\n",
      "\tspeed: 0.0532s/iter; left time: 4823.4244s\n",
      "2198it [01:59, 18.13it/s]\titers: 2200, epoch: 1 | loss: 0.1682482\n",
      "\tspeed: 0.0545s/iter; left time: 4940.3815s\n",
      "2298it [02:05, 17.46it/s]\titers: 2300, epoch: 1 | loss: 0.2750728\n",
      "\tspeed: 0.0568s/iter; left time: 5142.2330s\n",
      "2398it [02:10, 16.86it/s]\titers: 2400, epoch: 1 | loss: 0.5704689\n",
      "\tspeed: 0.0556s/iter; left time: 5026.4871s\n",
      "2498it [02:16, 18.42it/s]\titers: 2500, epoch: 1 | loss: 0.2584201\n",
      "\tspeed: 0.0575s/iter; left time: 5197.4956s\n",
      "2598it [02:21, 18.40it/s]\titers: 2600, epoch: 1 | loss: 0.1999256\n",
      "\tspeed: 0.0540s/iter; left time: 4871.8909s\n",
      "2698it [02:27, 18.41it/s]\titers: 2700, epoch: 1 | loss: 0.3062195\n",
      "\tspeed: 0.0544s/iter; left time: 4906.0748s\n",
      "2798it [02:32, 18.48it/s]\titers: 2800, epoch: 1 | loss: 0.1383041\n",
      "\tspeed: 0.0561s/iter; left time: 5049.0683s\n",
      "2899it [02:38, 18.41it/s]\titers: 2900, epoch: 1 | loss: 0.4341204\n",
      "\tspeed: 0.0539s/iter; left time: 4850.2659s\n",
      "2999it [02:43, 18.40it/s]\titers: 3000, epoch: 1 | loss: 0.1516554\n",
      "\tspeed: 0.0544s/iter; left time: 4887.7522s\n",
      "3099it [02:49, 18.40it/s]\titers: 3100, epoch: 1 | loss: 0.2670549\n",
      "\tspeed: 0.0545s/iter; left time: 4891.5782s\n",
      "3199it [02:55, 18.60it/s]\titers: 3200, epoch: 1 | loss: 0.4697004\n",
      "\tspeed: 0.0590s/iter; left time: 5284.1799s\n",
      "3298it [03:00, 18.63it/s]\titers: 3300, epoch: 1 | loss: 0.2683537\n",
      "\tspeed: 0.0541s/iter; left time: 4841.7283s\n",
      "3398it [03:05, 18.25it/s]\titers: 3400, epoch: 1 | loss: 0.2894230\n",
      "\tspeed: 0.0541s/iter; left time: 4841.1083s\n",
      "3498it [03:11, 18.64it/s]\titers: 3500, epoch: 1 | loss: 0.3440822\n",
      "\tspeed: 0.0591s/iter; left time: 5275.3566s\n",
      "3598it [03:17, 18.52it/s]\titers: 3600, epoch: 1 | loss: 0.4466991\n",
      "\tspeed: 0.0535s/iter; left time: 4774.4163s\n",
      "3698it [03:22, 18.57it/s]\titers: 3700, epoch: 1 | loss: 0.1623485\n",
      "\tspeed: 0.0538s/iter; left time: 4794.9819s\n",
      "3713it [03:23, 18.25it/s]\n",
      "Epoch: 1 cost time: 203.46346235275269\n",
      "810it [00:23, 34.06it/s]\n",
      "807it [00:23, 34.03it/s]\n",
      "Epoch: 1 | Train Loss: 0.3365891 Vali Loss: 0.3202976 Test Loss: 0.3962304 MAE Loss: 0.4175301\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "98it [00:05, 19.82it/s]\titers: 100, epoch: 2 | loss: 0.2400643\n",
      "\tspeed: 0.5648s/iter; left time: 50275.2559s\n",
      "199it [00:10, 17.59it/s]\titers: 200, epoch: 2 | loss: 0.1836322\n",
      "\tspeed: 0.0514s/iter; left time: 4569.8126s\n",
      "299it [00:16, 19.82it/s]\titers: 300, epoch: 2 | loss: 0.2335510\n",
      "\tspeed: 0.0546s/iter; left time: 4853.1084s\n",
      "398it [00:21, 20.10it/s]\titers: 400, epoch: 2 | loss: 0.3274648\n",
      "\tspeed: 0.0509s/iter; left time: 4517.6270s\n",
      "499it [00:26, 19.67it/s]\titers: 500, epoch: 2 | loss: 0.1731802\n",
      "\tspeed: 0.0514s/iter; left time: 4554.3722s\n",
      "598it [00:31, 20.23it/s]\titers: 600, epoch: 2 | loss: 0.4199438\n",
      "\tspeed: 0.0501s/iter; left time: 4434.2322s\n",
      "698it [00:36, 19.75it/s]\titers: 700, epoch: 2 | loss: 0.1850913\n",
      "\tspeed: 0.0509s/iter; left time: 4500.0502s\n",
      "799it [00:41, 19.69it/s]\titers: 800, epoch: 2 | loss: 0.2533366\n",
      "\tspeed: 0.0536s/iter; left time: 4733.0234s\n",
      "899it [00:46, 22.69it/s]\titers: 900, epoch: 2 | loss: 0.5355504\n",
      "\tspeed: 0.0459s/iter; left time: 4045.0000s\n",
      "998it [00:50, 17.84it/s]\titers: 1000, epoch: 2 | loss: 0.2156441\n",
      "\tspeed: 0.0457s/iter; left time: 4023.3339s\n",
      "1098it [00:56, 19.00it/s]\titers: 1100, epoch: 2 | loss: 0.2419261\n",
      "\tspeed: 0.0537s/iter; left time: 4730.2058s\n",
      "1199it [01:01, 19.71it/s]\titers: 1200, epoch: 2 | loss: 0.2841569\n",
      "\tspeed: 0.0503s/iter; left time: 4420.9551s\n",
      "1298it [01:06, 19.70it/s]\titers: 1300, epoch: 2 | loss: 0.2153498\n",
      "\tspeed: 0.0506s/iter; left time: 4440.4869s\n",
      "1397it [01:11, 19.60it/s]\titers: 1400, epoch: 2 | loss: 0.2957562\n",
      "\tspeed: 0.0536s/iter; left time: 4704.1924s\n",
      "1499it [01:16, 22.78it/s]\titers: 1500, epoch: 2 | loss: 0.1613199\n",
      "\tspeed: 0.0440s/iter; left time: 3854.1499s\n",
      "1598it [01:21, 19.80it/s]\titers: 1600, epoch: 2 | loss: 0.4085783\n",
      "\tspeed: 0.0508s/iter; left time: 4444.7536s\n",
      "1697it [01:26, 21.26it/s]\titers: 1700, epoch: 2 | loss: 0.3056666\n",
      "\tspeed: 0.0497s/iter; left time: 4347.8209s\n",
      "1799it [01:31, 19.83it/s]\titers: 1800, epoch: 2 | loss: 0.3768072\n",
      "\tspeed: 0.0514s/iter; left time: 4484.6300s\n",
      "1899it [01:36, 19.84it/s]\titers: 1900, epoch: 2 | loss: 0.2604823\n",
      "\tspeed: 0.0509s/iter; left time: 4442.3808s\n",
      "1998it [01:41, 21.34it/s]\titers: 2000, epoch: 2 | loss: 0.3480584\n",
      "\tspeed: 0.0487s/iter; left time: 4240.7348s\n",
      "2099it [01:46, 17.37it/s]\titers: 2100, epoch: 2 | loss: 0.3941673\n",
      "\tspeed: 0.0513s/iter; left time: 4466.1438s\n",
      "2198it [01:51, 19.79it/s]\titers: 2200, epoch: 2 | loss: 0.2405066\n",
      "\tspeed: 0.0528s/iter; left time: 4589.5368s\n",
      "2298it [01:56, 19.78it/s]\titers: 2300, epoch: 2 | loss: 0.3830832\n",
      "\tspeed: 0.0505s/iter; left time: 4385.4770s\n",
      "2399it [02:01, 19.82it/s]\titers: 2400, epoch: 2 | loss: 0.2949306\n",
      "\tspeed: 0.0488s/iter; left time: 4229.9710s\n",
      "2498it [02:06, 18.32it/s]\titers: 2500, epoch: 2 | loss: 0.1771324\n",
      "\tspeed: 0.0515s/iter; left time: 4461.8375s\n",
      "2599it [02:11, 19.80it/s]\titers: 2600, epoch: 2 | loss: 0.2106501\n",
      "\tspeed: 0.0504s/iter; left time: 4364.2967s\n",
      "2699it [02:16, 19.72it/s]\titers: 2700, epoch: 2 | loss: 0.3128993\n",
      "\tspeed: 0.0505s/iter; left time: 4367.6943s\n",
      "2799it [02:21, 19.76it/s]\titers: 2800, epoch: 2 | loss: 0.3527225\n",
      "\tspeed: 0.0506s/iter; left time: 4363.5511s\n",
      "2898it [02:26, 19.79it/s]\titers: 2900, epoch: 2 | loss: 0.2901534\n",
      "\tspeed: 0.0512s/iter; left time: 4411.9351s\n",
      "2999it [02:32, 19.79it/s]\titers: 3000, epoch: 2 | loss: 0.2421283\n",
      "\tspeed: 0.0505s/iter; left time: 4352.5227s\n",
      "3098it [02:37, 19.81it/s]\titers: 3100, epoch: 2 | loss: 0.2185457\n",
      "\tspeed: 0.0506s/iter; left time: 4352.4257s\n",
      "3198it [02:42, 19.82it/s]\titers: 3200, epoch: 2 | loss: 0.2269746\n",
      "\tspeed: 0.0506s/iter; left time: 4344.1503s\n",
      "3299it [02:47, 19.87it/s]\titers: 3300, epoch: 2 | loss: 0.2256199\n",
      "\tspeed: 0.0549s/iter; left time: 4707.1486s\n",
      "3399it [02:52, 19.58it/s]\titers: 3400, epoch: 2 | loss: 0.2751393\n",
      "\tspeed: 0.0507s/iter; left time: 4349.4245s\n",
      "3499it [02:57, 18.43it/s]\titers: 3500, epoch: 2 | loss: 0.1947318\n",
      "\tspeed: 0.0511s/iter; left time: 4375.2098s\n",
      "3599it [03:03, 15.55it/s]\titers: 3600, epoch: 2 | loss: 0.2142713\n",
      "\tspeed: 0.0521s/iter; left time: 4457.9883s\n",
      "3699it [03:08, 18.14it/s]\titers: 3700, epoch: 2 | loss: 0.3344521\n",
      "\tspeed: 0.0535s/iter; left time: 4565.8132s\n",
      "3713it [03:09, 19.63it/s]\n",
      "Epoch: 2 cost time: 189.177250623703\n",
      "810it [00:21, 38.06it/s]\n",
      "807it [00:21, 38.33it/s]\n",
      "Epoch: 2 | Train Loss: 0.2643867 Vali Loss: 0.2930738 Test Loss: 0.3511531 MAE Loss: 0.3636484\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "99it [00:05, 19.80it/s]\titers: 100, epoch: 3 | loss: 0.2640540\n",
      "\tspeed: 0.4996s/iter; left time: 42612.1492s\n",
      "198it [00:10, 19.76it/s]\titers: 200, epoch: 3 | loss: 0.1625548\n",
      "\tspeed: 0.0537s/iter; left time: 4574.7940s\n",
      "299it [00:15, 19.73it/s]\titers: 300, epoch: 3 | loss: 0.4068857\n",
      "\tspeed: 0.0506s/iter; left time: 4304.5965s\n",
      "399it [00:20, 19.78it/s]\titers: 400, epoch: 3 | loss: 0.2723034\n",
      "\tspeed: 0.0505s/iter; left time: 4295.5001s\n",
      "498it [00:25, 14.83it/s]\titers: 500, epoch: 3 | loss: 0.1974532\n",
      "\tspeed: 0.0529s/iter; left time: 4493.0344s\n",
      "599it [00:31, 19.74it/s]\titers: 600, epoch: 3 | loss: 0.2228541\n",
      "\tspeed: 0.0538s/iter; left time: 4558.2558s\n",
      "698it [00:36, 19.81it/s]\titers: 700, epoch: 3 | loss: 0.1880372\n",
      "\tspeed: 0.0488s/iter; left time: 4130.0376s\n",
      "799it [00:41, 19.79it/s]\titers: 800, epoch: 3 | loss: 0.2002946\n",
      "\tspeed: 0.0506s/iter; left time: 4281.5159s\n",
      "898it [00:46, 18.89it/s]\titers: 900, epoch: 3 | loss: 0.1700963\n",
      "\tspeed: 0.0514s/iter; left time: 4341.1088s\n",
      "998it [00:51, 19.81it/s]\titers: 1000, epoch: 3 | loss: 0.1985812\n",
      "\tspeed: 0.0504s/iter; left time: 4251.9852s\n",
      "1099it [00:56, 19.77it/s]\titers: 1100, epoch: 3 | loss: 0.1747793\n",
      "\tspeed: 0.0505s/iter; left time: 4260.1736s\n",
      "1199it [01:01, 19.74it/s]\titers: 1200, epoch: 3 | loss: 0.1374225\n",
      "\tspeed: 0.0506s/iter; left time: 4263.6486s\n",
      "1299it [01:07, 19.83it/s]\titers: 1300, epoch: 3 | loss: 0.2104016\n",
      "\tspeed: 0.0548s/iter; left time: 4607.2714s\n",
      "1399it [01:12, 19.79it/s]\titers: 1400, epoch: 3 | loss: 0.2475239\n",
      "\tspeed: 0.0506s/iter; left time: 4248.8529s\n",
      "1499it [01:17, 19.77it/s]\titers: 1500, epoch: 3 | loss: 0.3567590\n",
      "\tspeed: 0.0505s/iter; left time: 4240.9820s\n",
      "1598it [01:22, 16.16it/s]\titers: 1600, epoch: 3 | loss: 0.2869079\n",
      "\tspeed: 0.0523s/iter; left time: 4379.1925s\n",
      "1698it [01:27, 19.06it/s]\titers: 1700, epoch: 3 | loss: 0.1641781\n",
      "\tspeed: 0.0506s/iter; left time: 4233.0075s\n",
      "1798it [01:32, 19.77it/s]\titers: 1800, epoch: 3 | loss: 0.2055587\n",
      "\tspeed: 0.0505s/iter; left time: 4224.7646s\n",
      "1898it [01:37, 19.78it/s]\titers: 1900, epoch: 3 | loss: 0.3146476\n",
      "\tspeed: 0.0506s/iter; left time: 4222.2531s\n",
      "1998it [01:43, 19.22it/s]\titers: 2000, epoch: 3 | loss: 0.4032407\n",
      "\tspeed: 0.0540s/iter; left time: 4505.4334s\n",
      "2099it [01:48, 19.80it/s]\titers: 2100, epoch: 3 | loss: 0.1844922\n",
      "\tspeed: 0.0510s/iter; left time: 4251.1797s\n",
      "2198it [01:53, 19.77it/s]\titers: 2200, epoch: 3 | loss: 0.2386276\n",
      "\tspeed: 0.0505s/iter; left time: 4202.4269s\n",
      "2299it [01:58, 19.83it/s]\titers: 2300, epoch: 3 | loss: 0.1571960\n",
      "\tspeed: 0.0505s/iter; left time: 4200.5707s\n",
      "2398it [02:04, 17.78it/s]\titers: 2400, epoch: 3 | loss: 0.4310690\n",
      "\tspeed: 0.0600s/iter; left time: 4976.3715s\n",
      "2499it [02:09, 18.92it/s]\titers: 2500, epoch: 3 | loss: 0.1503718\n",
      "\tspeed: 0.0560s/iter; left time: 4645.4287s\n",
      "2599it [02:14, 19.85it/s]\titers: 2600, epoch: 3 | loss: 0.3812739\n",
      "\tspeed: 0.0505s/iter; left time: 4185.2074s\n",
      "2699it [02:20, 17.43it/s]\titers: 2700, epoch: 3 | loss: 0.2274507\n",
      "\tspeed: 0.0575s/iter; left time: 4757.7541s\n",
      "2798it [02:26, 19.82it/s]\titers: 2800, epoch: 3 | loss: 0.1416587\n",
      "\tspeed: 0.0547s/iter; left time: 4521.5707s\n",
      "2898it [02:31, 19.83it/s]\titers: 2900, epoch: 3 | loss: 0.2139106\n",
      "\tspeed: 0.0505s/iter; left time: 4167.4077s\n",
      "2998it [02:36, 17.37it/s]\titers: 3000, epoch: 3 | loss: 0.2241662\n",
      "\tspeed: 0.0552s/iter; left time: 4547.7904s\n",
      "3098it [02:42, 17.55it/s]\titers: 3100, epoch: 3 | loss: 0.2268326\n",
      "\tspeed: 0.0571s/iter; left time: 4696.4959s\n",
      "3198it [02:48, 19.17it/s]\titers: 3200, epoch: 3 | loss: 0.2780645\n",
      "\tspeed: 0.0565s/iter; left time: 4641.6248s\n",
      "3298it [02:54, 16.75it/s]\titers: 3300, epoch: 3 | loss: 0.2918887\n",
      "\tspeed: 0.0604s/iter; left time: 4959.7453s\n",
      "3398it [02:59, 20.50it/s]\titers: 3400, epoch: 3 | loss: 0.2040429\n",
      "\tspeed: 0.0550s/iter; left time: 4509.5892s\n",
      "3499it [03:05, 17.33it/s]\titers: 3500, epoch: 3 | loss: 0.2533299\n",
      "\tspeed: 0.0544s/iter; left time: 4455.3091s\n",
      "3597it [03:10, 19.79it/s]\titers: 3600, epoch: 3 | loss: 0.3611647\n",
      "\tspeed: 0.0552s/iter; left time: 4511.9228s\n",
      "3699it [03:16, 19.62it/s]\titers: 3700, epoch: 3 | loss: 0.1617071\n",
      "\tspeed: 0.0568s/iter; left time: 4642.6942s\n",
      "3713it [03:17, 18.84it/s]\n",
      "Epoch: 3 cost time: 197.05066537857056\n",
      "810it [00:20, 39.13it/s]\n",
      "807it [00:21, 37.64it/s]\n",
      "Epoch: 3 | Train Loss: 0.2524274 Vali Loss: 0.2876566 Test Loss: 0.3513364 MAE Loss: 0.3742820\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "98it [00:05, 19.78it/s]\titers: 100, epoch: 4 | loss: 0.2343732\n",
      "\tspeed: 0.4988s/iter; left time: 40697.8163s\n",
      "198it [00:10, 17.90it/s]\titers: 200, epoch: 4 | loss: 0.1683504\n",
      "\tspeed: 0.0531s/iter; left time: 4330.0668s\n",
      "299it [00:15, 21.10it/s]\titers: 300, epoch: 4 | loss: 0.1744778\n",
      "\tspeed: 0.0499s/iter; left time: 4058.5692s\n",
      "398it [00:20, 18.61it/s]\titers: 400, epoch: 4 | loss: 0.3656359\n",
      "\tspeed: 0.0504s/iter; left time: 4094.0713s\n",
      "499it [00:25, 19.66it/s]\titers: 500, epoch: 4 | loss: 0.4704293\n",
      "\tspeed: 0.0528s/iter; left time: 4285.8654s\n",
      "597it [00:31, 14.27it/s]\titers: 600, epoch: 4 | loss: 0.1826869\n",
      "\tspeed: 0.0556s/iter; left time: 4510.0381s\n",
      "698it [00:36, 19.82it/s]\titers: 700, epoch: 4 | loss: 0.2927392\n",
      "\tspeed: 0.0515s/iter; left time: 4173.6309s\n",
      "799it [00:41, 19.80it/s]\titers: 800, epoch: 4 | loss: 0.2924649\n",
      "\tspeed: 0.0502s/iter; left time: 4060.8467s\n",
      "899it [00:46, 19.84it/s]\titers: 900, epoch: 4 | loss: 0.2248765\n",
      "\tspeed: 0.0504s/iter; left time: 4069.2009s\n",
      "998it [00:51, 19.72it/s]\titers: 1000, epoch: 4 | loss: 0.2879621\n",
      "\tspeed: 0.0518s/iter; left time: 4178.9680s\n",
      "1099it [00:56, 17.75it/s]\titers: 1100, epoch: 4 | loss: 0.1893965\n",
      "\tspeed: 0.0504s/iter; left time: 4063.2448s\n",
      "1198it [01:02, 17.14it/s]\titers: 1200, epoch: 4 | loss: 0.3458648\n",
      "\tspeed: 0.0560s/iter; left time: 4505.6235s\n",
      "1299it [01:07, 19.83it/s]\titers: 1300, epoch: 4 | loss: 0.1869053\n",
      "\tspeed: 0.0531s/iter; left time: 4265.7833s\n",
      "1398it [01:13, 18.99it/s]\titers: 1400, epoch: 4 | loss: 0.3784270\n",
      "\tspeed: 0.0560s/iter; left time: 4495.6912s\n",
      "1499it [01:18, 19.21it/s]\titers: 1500, epoch: 4 | loss: 0.2639445\n",
      "\tspeed: 0.0505s/iter; left time: 4053.0879s\n",
      "1599it [01:23, 18.62it/s]\titers: 1600, epoch: 4 | loss: 0.1894439\n",
      "\tspeed: 0.0530s/iter; left time: 4246.8979s\n",
      "1698it [01:29, 16.68it/s]\titers: 1700, epoch: 4 | loss: 0.3304960\n",
      "\tspeed: 0.0564s/iter; left time: 4514.7280s\n",
      "1798it [01:34, 17.79it/s]\titers: 1800, epoch: 4 | loss: 0.1485968\n",
      "\tspeed: 0.0525s/iter; left time: 4198.0010s\n",
      "1898it [01:39, 19.74it/s]\titers: 1900, epoch: 4 | loss: 0.3761029\n",
      "\tspeed: 0.0520s/iter; left time: 4146.4901s\n",
      "1999it [01:45, 18.69it/s]\titers: 2000, epoch: 4 | loss: 0.1300369\n",
      "\tspeed: 0.0532s/iter; left time: 4241.5435s\n",
      "2099it [01:50, 17.74it/s]\titers: 2100, epoch: 4 | loss: 0.3036593\n",
      "\tspeed: 0.0574s/iter; left time: 4571.9755s\n",
      "2198it [01:56, 19.76it/s]\titers: 2200, epoch: 4 | loss: 0.2651446\n",
      "\tspeed: 0.0548s/iter; left time: 4359.6663s\n",
      "2298it [02:01, 19.79it/s]\titers: 2300, epoch: 4 | loss: 0.2478092\n",
      "\tspeed: 0.0504s/iter; left time: 4003.2244s\n",
      "2398it [02:06, 19.22it/s]\titers: 2400, epoch: 4 | loss: 0.2454403\n",
      "\tspeed: 0.0521s/iter; left time: 4134.1996s\n",
      "2499it [02:12, 19.71it/s]\titers: 2500, epoch: 4 | loss: 0.2705346\n",
      "\tspeed: 0.0565s/iter; left time: 4473.3085s\n",
      "2598it [02:17, 17.83it/s]\titers: 2600, epoch: 4 | loss: 0.2353205\n",
      "\tspeed: 0.0529s/iter; left time: 4184.0385s\n",
      "2698it [02:22, 19.79it/s]\titers: 2700, epoch: 4 | loss: 0.3278998\n",
      "\tspeed: 0.0519s/iter; left time: 4099.3521s\n",
      "2797it [02:28, 15.05it/s]\titers: 2800, epoch: 4 | loss: 0.2441300\n",
      "\tspeed: 0.0588s/iter; left time: 4634.6679s\n",
      "2899it [02:33, 19.72it/s]\titers: 2900, epoch: 4 | loss: 0.1846991\n",
      "\tspeed: 0.0504s/iter; left time: 3973.7416s\n",
      "2998it [02:38, 19.71it/s]\titers: 3000, epoch: 4 | loss: 0.1916421\n",
      "\tspeed: 0.0512s/iter; left time: 4031.9172s\n",
      "3099it [02:43, 19.73it/s]\titers: 3100, epoch: 4 | loss: 0.2739919\n",
      "\tspeed: 0.0504s/iter; left time: 3957.0285s\n",
      "3198it [02:49, 20.58it/s]\titers: 3200, epoch: 4 | loss: 0.1700998\n",
      "\tspeed: 0.0529s/iter; left time: 4148.0902s\n",
      "3299it [02:54, 19.82it/s]\titers: 3300, epoch: 4 | loss: 0.2551312\n",
      "\tspeed: 0.0504s/iter; left time: 3952.4389s\n",
      "3398it [02:59, 19.80it/s]\titers: 3400, epoch: 4 | loss: 0.3640906\n",
      "\tspeed: 0.0505s/iter; left time: 3956.2953s\n",
      "3497it [03:04, 15.11it/s]\titers: 3500, epoch: 4 | loss: 0.1100007\n",
      "\tspeed: 0.0555s/iter; left time: 4340.9894s\n",
      "3598it [03:10, 19.41it/s]\titers: 3600, epoch: 4 | loss: 0.2495114\n",
      "\tspeed: 0.0522s/iter; left time: 4078.2677s\n",
      "3698it [03:15, 19.83it/s]\titers: 3700, epoch: 4 | loss: 0.0926265\n",
      "\tspeed: 0.0504s/iter; left time: 3927.0895s\n",
      "3713it [03:15, 18.95it/s]\n",
      "Epoch: 4 cost time: 195.91063022613525\n",
      "810it [00:21, 37.77it/s]\n",
      "807it [00:20, 38.96it/s]\n",
      "Epoch: 4 | Train Loss: 0.2447699 Vali Loss: 0.2807395 Test Loss: 0.3513915 MAE Loss: 0.3683100\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "97it [00:05, 20.00it/s]\titers: 100, epoch: 5 | loss: 0.4474192\n",
      "\tspeed: 0.5049s/iter; left time: 39322.0648s\n",
      "198it [00:10, 18.60it/s]\titers: 200, epoch: 5 | loss: 0.1607875\n",
      "\tspeed: 0.0528s/iter; left time: 4104.1382s\n",
      "298it [00:15, 18.67it/s]\titers: 300, epoch: 5 | loss: 0.1354191\n",
      "\tspeed: 0.0520s/iter; left time: 4041.9401s\n",
      "399it [00:21, 19.44it/s]\titers: 400, epoch: 5 | loss: 0.2324377\n",
      "\tspeed: 0.0556s/iter; left time: 4315.1967s\n",
      "499it [00:26, 19.22it/s]\titers: 500, epoch: 5 | loss: 0.1728408\n",
      "\tspeed: 0.0510s/iter; left time: 3947.7069s\n",
      "598it [00:31, 19.72it/s]\titers: 600, epoch: 5 | loss: 0.4775435\n",
      "\tspeed: 0.0508s/iter; left time: 3928.1276s\n",
      "698it [00:36, 19.82it/s]\titers: 700, epoch: 5 | loss: 0.3475066\n",
      "\tspeed: 0.0506s/iter; left time: 3907.3174s\n",
      "798it [00:42, 19.77it/s]\titers: 800, epoch: 5 | loss: 0.1707494\n",
      "\tspeed: 0.0551s/iter; left time: 4251.9523s\n",
      "898it [00:47, 19.54it/s]\titers: 900, epoch: 5 | loss: 0.2552074\n",
      "\tspeed: 0.0520s/iter; left time: 4006.2741s\n",
      "999it [00:52, 19.99it/s]\titers: 1000, epoch: 5 | loss: 0.3953588\n",
      "\tspeed: 0.0503s/iter; left time: 3870.3541s\n",
      "1099it [00:57, 17.92it/s]\titers: 1100, epoch: 5 | loss: 0.3742965\n",
      "\tspeed: 0.0511s/iter; left time: 3928.1798s\n",
      "1198it [01:02, 19.83it/s]\titers: 1200, epoch: 5 | loss: 0.3763417\n",
      "\tspeed: 0.0548s/iter; left time: 4207.0992s\n",
      "1299it [01:08, 19.74it/s]\titers: 1300, epoch: 5 | loss: 0.2420751\n",
      "\tspeed: 0.0506s/iter; left time: 3878.7583s\n",
      "1398it [01:13, 19.67it/s]\titers: 1400, epoch: 5 | loss: 0.2466243\n",
      "\tspeed: 0.0520s/iter; left time: 3979.5628s\n",
      "1499it [01:18, 18.48it/s]\titers: 1500, epoch: 5 | loss: 0.2046338\n",
      "\tspeed: 0.0514s/iter; left time: 3930.3232s\n",
      "1599it [01:23, 19.52it/s]\titers: 1600, epoch: 5 | loss: 0.1840027\n",
      "\tspeed: 0.0524s/iter; left time: 4000.0542s\n",
      "1697it [01:28, 19.80it/s]\titers: 1700, epoch: 5 | loss: 0.1885989\n",
      "\tspeed: 0.0485s/iter; left time: 3701.3617s\n",
      "1799it [01:33, 19.57it/s]\titers: 1800, epoch: 5 | loss: 0.1893921\n",
      "\tspeed: 0.0508s/iter; left time: 3869.7238s\n",
      "1898it [01:38, 13.55it/s]\titers: 1900, epoch: 5 | loss: 0.1593075\n",
      "\tspeed: 0.0536s/iter; left time: 4081.0028s\n",
      "1999it [01:44, 18.86it/s]\titers: 2000, epoch: 5 | loss: 0.5037849\n",
      "\tspeed: 0.0525s/iter; left time: 3985.7790s\n",
      "2098it [01:49, 18.81it/s]\titers: 2100, epoch: 5 | loss: 0.3312052\n",
      "\tspeed: 0.0518s/iter; left time: 3931.7570s\n",
      "2198it [01:54, 19.88it/s]\titers: 2200, epoch: 5 | loss: 0.2897596\n",
      "\tspeed: 0.0481s/iter; left time: 3644.2156s\n",
      "2298it [01:59, 13.91it/s]\titers: 2300, epoch: 5 | loss: 0.2815456\n",
      "\tspeed: 0.0538s/iter; left time: 4072.4003s\n",
      "2398it [02:04, 19.75it/s]\titers: 2400, epoch: 5 | loss: 0.4324606\n",
      "\tspeed: 0.0536s/iter; left time: 4047.0618s\n",
      "2498it [02:09, 19.76it/s]\titers: 2500, epoch: 5 | loss: 0.1878461\n",
      "\tspeed: 0.0503s/iter; left time: 3799.5432s\n",
      "2599it [02:14, 19.84it/s]\titers: 2600, epoch: 5 | loss: 0.2573230\n",
      "\tspeed: 0.0502s/iter; left time: 3786.3599s\n",
      "2699it [02:20, 18.94it/s]\titers: 2700, epoch: 5 | loss: 0.2050470\n",
      "\tspeed: 0.0517s/iter; left time: 3892.0187s\n",
      "2798it [02:25, 18.75it/s]\titers: 2800, epoch: 5 | loss: 0.1521245\n",
      "\tspeed: 0.0521s/iter; left time: 3917.6139s\n",
      "2898it [02:30, 18.72it/s]\titers: 2900, epoch: 5 | loss: 0.2426054\n",
      "\tspeed: 0.0532s/iter; left time: 3994.4626s\n",
      "2999it [02:35, 18.57it/s]\titers: 3000, epoch: 5 | loss: 0.1188551\n",
      "\tspeed: 0.0529s/iter; left time: 3967.5340s\n",
      "3097it [02:41, 19.68it/s]\titers: 3100, epoch: 5 | loss: 0.1524252\n",
      "\tspeed: 0.0549s/iter; left time: 4109.7402s\n",
      "3199it [02:46, 18.86it/s]\titers: 3200, epoch: 5 | loss: 0.1983854\n",
      "\tspeed: 0.0523s/iter; left time: 3911.6023s\n",
      "3299it [02:51, 18.55it/s]\titers: 3300, epoch: 5 | loss: 0.2945087\n",
      "\tspeed: 0.0516s/iter; left time: 3852.0123s\n",
      "3399it [02:56, 19.40it/s]\titers: 3400, epoch: 5 | loss: 0.2493188\n",
      "\tspeed: 0.0516s/iter; left time: 3846.8206s\n",
      "3498it [03:02, 18.14it/s]\titers: 3500, epoch: 5 | loss: 0.2132017\n",
      "\tspeed: 0.0522s/iter; left time: 3884.2780s\n",
      "3597it [03:06, 22.42it/s]\titers: 3600, epoch: 5 | loss: 0.3816530\n",
      "\tspeed: 0.0482s/iter; left time: 3586.9828s\n",
      "3699it [03:11, 22.43it/s]\titers: 3700, epoch: 5 | loss: 0.1615642\n",
      "\tspeed: 0.0444s/iter; left time: 3298.3343s\n",
      "3713it [03:12, 19.33it/s]\n",
      "Epoch: 5 cost time: 192.1333203315735\n",
      "810it [00:20, 38.75it/s]\n",
      "807it [00:20, 38.55it/s]\n",
      "Epoch: 5 | Train Loss: 0.2390104 Vali Loss: 0.2868012 Test Loss: 0.3518413 MAE Loss: 0.3633056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "97it [00:05, 18.56it/s]\titers: 100, epoch: 6 | loss: 0.2616808\n",
      "\tspeed: 0.4840s/iter; left time: 35896.1578s\n",
      "197it [00:10, 21.05it/s]\titers: 200, epoch: 6 | loss: 0.2785396\n",
      "\tspeed: 0.0498s/iter; left time: 3690.1953s\n",
      "299it [00:15, 19.14it/s]\titers: 300, epoch: 6 | loss: 0.1685918\n",
      "\tspeed: 0.0497s/iter; left time: 3672.1678s\n",
      "398it [00:21, 20.65it/s]\titers: 400, epoch: 6 | loss: 0.2504590\n",
      "\tspeed: 0.0530s/iter; left time: 3916.3064s\n",
      "497it [00:25, 20.36it/s]\titers: 500, epoch: 6 | loss: 0.1764779\n",
      "\tspeed: 0.0479s/iter; left time: 3532.6567s\n",
      "598it [00:30, 20.30it/s]\titers: 600, epoch: 6 | loss: 0.2151264\n",
      "\tspeed: 0.0515s/iter; left time: 3796.8090s\n",
      "699it [00:36, 14.25it/s]\titers: 700, epoch: 6 | loss: 0.1266306\n",
      "\tspeed: 0.0557s/iter; left time: 4099.7723s\n",
      "798it [00:41, 19.78it/s]\titers: 800, epoch: 6 | loss: 0.2466619\n",
      "\tspeed: 0.0498s/iter; left time: 3658.3969s\n",
      "897it [00:46, 19.73it/s]\titers: 900, epoch: 6 | loss: 0.2002235\n",
      "\tspeed: 0.0502s/iter; left time: 3679.4107s\n",
      "999it [00:51, 19.16it/s]\titers: 1000, epoch: 6 | loss: 0.2737607\n",
      "\tspeed: 0.0515s/iter; left time: 3772.1673s\n",
      "1099it [00:57, 19.77it/s]\titers: 1100, epoch: 6 | loss: 0.1820861\n",
      "\tspeed: 0.0547s/iter; left time: 4001.2753s\n",
      "1198it [01:02, 19.53it/s]\titers: 1200, epoch: 6 | loss: 0.2251021\n",
      "\tspeed: 0.0519s/iter; left time: 3793.8144s\n",
      "1298it [01:07, 18.58it/s]\titers: 1300, epoch: 6 | loss: 0.1722595\n",
      "\tspeed: 0.0513s/iter; left time: 3746.3216s\n",
      "1398it [01:12, 18.12it/s]\titers: 1400, epoch: 6 | loss: 0.2915171\n",
      "\tspeed: 0.0524s/iter; left time: 3817.3273s\n",
      "1499it [01:18, 19.77it/s]\titers: 1500, epoch: 6 | loss: 0.2504003\n",
      "\tspeed: 0.0548s/iter; left time: 3986.1711s\n",
      "1599it [01:23, 19.77it/s]\titers: 1600, epoch: 6 | loss: 0.3529468\n",
      "\tspeed: 0.0519s/iter; left time: 3772.0172s\n",
      "1699it [01:28, 19.55it/s]\titers: 1700, epoch: 6 | loss: 0.2670310\n",
      "\tspeed: 0.0508s/iter; left time: 3688.9975s\n",
      "1799it [01:34, 16.11it/s]\titers: 1800, epoch: 6 | loss: 0.2667663\n",
      "\tspeed: 0.0557s/iter; left time: 4035.8912s\n",
      "1898it [01:39, 19.25it/s]\titers: 1900, epoch: 6 | loss: 0.2061695\n",
      "\tspeed: 0.0510s/iter; left time: 3687.0010s\n",
      "1998it [01:44, 19.74it/s]\titers: 2000, epoch: 6 | loss: 0.3060033\n",
      "\tspeed: 0.0512s/iter; left time: 3700.2469s\n",
      "2098it [01:49, 19.47it/s]\titers: 2100, epoch: 6 | loss: 0.1816715\n",
      "\tspeed: 0.0518s/iter; left time: 3738.8357s\n",
      "2199it [01:54, 19.46it/s]\titers: 2200, epoch: 6 | loss: 0.1712995\n",
      "\tspeed: 0.0539s/iter; left time: 3884.8577s\n",
      "2298it [02:00, 19.29it/s]\titers: 2300, epoch: 6 | loss: 0.1588748\n",
      "\tspeed: 0.0536s/iter; left time: 3860.3472s\n",
      "2399it [02:05, 20.24it/s]\titers: 2400, epoch: 6 | loss: 0.1840176\n",
      "\tspeed: 0.0505s/iter; left time: 3626.5885s\n",
      "2498it [02:10, 19.73it/s]\titers: 2500, epoch: 6 | loss: 0.2567315\n",
      "\tspeed: 0.0510s/iter; left time: 3659.2638s\n",
      "2599it [02:16, 19.75it/s]\titers: 2600, epoch: 6 | loss: 0.2534186\n",
      "\tspeed: 0.0568s/iter; left time: 4071.2162s\n",
      "2698it [02:20, 21.06it/s]\titers: 2700, epoch: 6 | loss: 0.1853072\n",
      "\tspeed: 0.0489s/iter; left time: 3498.8730s\n",
      "2799it [02:26, 20.33it/s]\titers: 2800, epoch: 6 | loss: 0.1633412\n",
      "\tspeed: 0.0509s/iter; left time: 3640.5349s\n",
      "2898it [02:31, 19.72it/s]\titers: 2900, epoch: 6 | loss: 0.1641052\n",
      "\tspeed: 0.0521s/iter; left time: 3718.9295s\n",
      "2998it [02:36, 20.33it/s]\titers: 3000, epoch: 6 | loss: 0.2528276\n",
      "\tspeed: 0.0554s/iter; left time: 3951.0353s\n",
      "3098it [02:41, 20.03it/s]\titers: 3100, epoch: 6 | loss: 0.2280479\n",
      "\tspeed: 0.0486s/iter; left time: 3455.0264s\n",
      "3198it [02:46, 21.72it/s]\titers: 3200, epoch: 6 | loss: 0.2804870\n",
      "\tspeed: 0.0481s/iter; left time: 3417.0116s\n",
      "3298it [02:51, 20.34it/s]\titers: 3300, epoch: 6 | loss: 0.2298840\n",
      "\tspeed: 0.0547s/iter; left time: 3878.9053s\n",
      "3398it [02:56, 19.46it/s]\titers: 3400, epoch: 6 | loss: 0.3002828\n",
      "\tspeed: 0.0510s/iter; left time: 3611.9278s\n",
      "3497it [03:01, 20.63it/s]\titers: 3500, epoch: 6 | loss: 0.1777224\n",
      "\tspeed: 0.0496s/iter; left time: 3507.8313s\n",
      "3598it [03:07, 19.36it/s]\titers: 3600, epoch: 6 | loss: 0.2128613\n",
      "\tspeed: 0.0559s/iter; left time: 3953.0522s\n",
      "3699it [03:12, 19.37it/s]\titers: 3700, epoch: 6 | loss: 0.1376199\n",
      "\tspeed: 0.0507s/iter; left time: 3575.6777s\n",
      "3713it [03:13, 19.20it/s]\n",
      "Epoch: 6 cost time: 193.43434071540833\n",
      "810it [00:20, 40.19it/s]\n",
      "807it [00:20, 38.73it/s]\n",
      "Epoch: 6 | Train Loss: 0.2330910 Vali Loss: 0.2787986 Test Loss: 0.3522850 MAE Loss: 0.3690674\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "98it [00:05, 15.96it/s]\titers: 100, epoch: 7 | loss: 0.2315882\n",
      "\tspeed: 0.4927s/iter; left time: 34707.5585s\n",
      "198it [00:11, 19.63it/s]\titers: 200, epoch: 7 | loss: 0.1715670\n",
      "\tspeed: 0.0546s/iter; left time: 3840.1010s\n",
      "299it [00:16, 19.62it/s]\titers: 300, epoch: 7 | loss: 0.1247460\n",
      "\tspeed: 0.0519s/iter; left time: 3649.2144s\n",
      "399it [00:21, 19.44it/s]\titers: 400, epoch: 7 | loss: 0.2386006\n",
      "\tspeed: 0.0518s/iter; left time: 3630.9765s\n",
      "499it [00:26, 19.80it/s]\titers: 500, epoch: 7 | loss: 0.3038545\n",
      "\tspeed: 0.0539s/iter; left time: 3776.8514s\n",
      "598it [00:32, 18.63it/s]\titers: 600, epoch: 7 | loss: 0.1975371\n",
      "\tspeed: 0.0516s/iter; left time: 3612.0714s\n",
      "698it [00:37, 18.61it/s]\titers: 700, epoch: 7 | loss: 0.3119506\n",
      "\tspeed: 0.0532s/iter; left time: 3713.1723s\n",
      "799it [00:42, 19.78it/s]\titers: 800, epoch: 7 | loss: 0.2418718\n",
      "\tspeed: 0.0521s/iter; left time: 3634.4266s\n",
      "898it [00:48, 19.68it/s]\titers: 900, epoch: 7 | loss: 0.1589082\n",
      "\tspeed: 0.0553s/iter; left time: 3848.1338s\n",
      "999it [00:53, 19.43it/s]\titers: 1000, epoch: 7 | loss: 0.3041913\n",
      "\tspeed: 0.0535s/iter; left time: 3720.4080s\n",
      "1098it [00:58, 20.68it/s]\titers: 1100, epoch: 7 | loss: 0.1546989\n",
      "\tspeed: 0.0514s/iter; left time: 3570.3634s\n",
      "1199it [01:03, 17.08it/s]\titers: 1200, epoch: 7 | loss: 0.1913302\n",
      "\tspeed: 0.0532s/iter; left time: 3686.0739s\n",
      "1298it [01:09, 17.89it/s]\titers: 1300, epoch: 7 | loss: 0.2680190\n",
      "\tspeed: 0.0537s/iter; left time: 3721.4363s\n",
      "1398it [01:14, 19.14it/s]\titers: 1400, epoch: 7 | loss: 0.2831595\n",
      "\tspeed: 0.0520s/iter; left time: 3594.1717s\n",
      "1498it [01:19, 20.10it/s]\titers: 1500, epoch: 7 | loss: 0.2470515\n",
      "\tspeed: 0.0513s/iter; left time: 3541.2615s\n",
      "1599it [01:25, 19.06it/s]\titers: 1600, epoch: 7 | loss: 0.1344777\n",
      "\tspeed: 0.0567s/iter; left time: 3906.8045s\n",
      "1699it [01:30, 16.12it/s]\titers: 1700, epoch: 7 | loss: 0.2298640\n",
      "\tspeed: 0.0554s/iter; left time: 3816.5383s\n",
      "1799it [01:36, 18.51it/s]\titers: 1800, epoch: 7 | loss: 0.2482111\n",
      "\tspeed: 0.0575s/iter; left time: 3950.7620s\n",
      "1899it [01:42, 13.38it/s]\titers: 1900, epoch: 7 | loss: 0.2664019\n",
      "\tspeed: 0.0624s/iter; left time: 4286.7338s\n",
      "1999it [01:48, 16.79it/s]\titers: 2000, epoch: 7 | loss: 0.2322707\n",
      "\tspeed: 0.0568s/iter; left time: 3891.2603s\n",
      "2099it [01:53, 19.54it/s]\titers: 2100, epoch: 7 | loss: 0.1829427\n",
      "\tspeed: 0.0522s/iter; left time: 3572.7950s\n",
      "2199it [01:58, 19.48it/s]\titers: 2200, epoch: 7 | loss: 0.1760145\n",
      "\tspeed: 0.0518s/iter; left time: 3541.9975s\n",
      "2298it [02:04, 19.78it/s]\titers: 2300, epoch: 7 | loss: 0.1782535\n",
      "\tspeed: 0.0552s/iter; left time: 3765.5749s\n",
      "2398it [02:09, 18.84it/s]\titers: 2400, epoch: 7 | loss: 0.2643352\n",
      "\tspeed: 0.0517s/iter; left time: 3524.6270s\n",
      "2499it [02:14, 19.54it/s]\titers: 2500, epoch: 7 | loss: 0.2356830\n",
      "\tspeed: 0.0511s/iter; left time: 3476.3338s\n",
      "2598it [02:19, 19.09it/s]\titers: 2600, epoch: 7 | loss: 0.1871707\n",
      "\tspeed: 0.0525s/iter; left time: 3570.0974s\n",
      "2699it [02:25, 19.77it/s]\titers: 2700, epoch: 7 | loss: 0.2660877\n",
      "\tspeed: 0.0561s/iter; left time: 3805.2447s\n",
      "2799it [02:30, 21.00it/s]\titers: 2800, epoch: 7 | loss: 0.2133620\n",
      "\tspeed: 0.0497s/iter; left time: 3367.0273s\n",
      "2899it [02:35, 19.74it/s]\titers: 2900, epoch: 7 | loss: 0.2486593\n",
      "\tspeed: 0.0485s/iter; left time: 3281.5089s\n",
      "2998it [02:40, 19.53it/s]\titers: 3000, epoch: 7 | loss: 0.2368820\n",
      "\tspeed: 0.0512s/iter; left time: 3457.3821s\n",
      "3099it [02:45, 19.78it/s]\titers: 3100, epoch: 7 | loss: 0.2186572\n",
      "\tspeed: 0.0530s/iter; left time: 3574.7800s\n",
      "3198it [02:51, 19.20it/s]\titers: 3200, epoch: 7 | loss: 0.1837230\n",
      "\tspeed: 0.0522s/iter; left time: 3515.1690s\n",
      "3299it [02:56, 19.27it/s]\titers: 3300, epoch: 7 | loss: 0.2511695\n",
      "\tspeed: 0.0511s/iter; left time: 3433.2860s\n",
      "3398it [03:01, 18.19it/s]\titers: 3400, epoch: 7 | loss: 0.2510894\n",
      "\tspeed: 0.0511s/iter; left time: 3431.8900s\n",
      "3499it [03:06, 19.07it/s]\titers: 3500, epoch: 7 | loss: 0.1868791\n",
      "\tspeed: 0.0529s/iter; left time: 3548.0269s\n",
      "3599it [03:11, 19.43it/s]\titers: 3600, epoch: 7 | loss: 0.2346786\n",
      "\tspeed: 0.0512s/iter; left time: 3426.2374s\n",
      "3698it [03:16, 19.22it/s]\titers: 3700, epoch: 7 | loss: 0.3988494\n",
      "\tspeed: 0.0517s/iter; left time: 3458.4481s\n",
      "3713it [03:17, 18.78it/s]\n",
      "Epoch: 7 cost time: 197.6619908809662\n",
      "810it [00:20, 38.60it/s]\n",
      "807it [00:21, 37.82it/s]\n",
      "Epoch: 7 | Train Loss: 0.2294159 Vali Loss: 0.2773737 Test Loss: 0.3451754 MAE Loss: 0.3622079\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "99it [00:05, 18.97it/s]\titers: 100, epoch: 8 | loss: 0.2844345\n",
      "\tspeed: 0.5073s/iter; left time: 33853.8942s\n",
      "199it [00:10, 19.76it/s]\titers: 200, epoch: 8 | loss: 0.3134541\n",
      "\tspeed: 0.0522s/iter; left time: 3480.2014s\n",
      "299it [00:15, 19.48it/s]\titers: 300, epoch: 8 | loss: 0.2155727\n",
      "\tspeed: 0.0501s/iter; left time: 3334.5296s\n",
      "398it [00:21, 19.76it/s]\titers: 400, epoch: 8 | loss: 0.2745682\n",
      "\tspeed: 0.0553s/iter; left time: 3676.5265s\n",
      "498it [00:26, 18.89it/s]\titers: 500, epoch: 8 | loss: 0.3588421\n",
      "\tspeed: 0.0523s/iter; left time: 3472.2910s\n",
      "599it [00:31, 19.03it/s]\titers: 600, epoch: 8 | loss: 0.1041675\n",
      "\tspeed: 0.0514s/iter; left time: 3404.3572s\n",
      "698it [00:36, 19.39it/s]\titers: 700, epoch: 8 | loss: 0.1617145\n",
      "\tspeed: 0.0510s/iter; left time: 3370.2996s\n",
      "798it [00:42, 19.78it/s]\titers: 800, epoch: 8 | loss: 0.2441765\n",
      "\tspeed: 0.0546s/iter; left time: 3607.2340s\n",
      "898it [00:47, 19.66it/s]\titers: 900, epoch: 8 | loss: 0.2319251\n",
      "\tspeed: 0.0519s/iter; left time: 3419.6868s\n",
      "998it [00:52, 19.74it/s]\titers: 1000, epoch: 8 | loss: 0.1907366\n",
      "\tspeed: 0.0515s/iter; left time: 3389.8232s\n",
      "1098it [00:58, 17.50it/s]\titers: 1100, epoch: 8 | loss: 0.1659034\n",
      "\tspeed: 0.0567s/iter; left time: 3729.8208s\n",
      "1199it [01:03, 19.31it/s]\titers: 1200, epoch: 8 | loss: 0.1802160\n",
      "\tspeed: 0.0508s/iter; left time: 3337.0199s\n",
      "1297it [01:08, 20.40it/s]\titers: 1300, epoch: 8 | loss: 0.1343563\n",
      "\tspeed: 0.0495s/iter; left time: 3240.8530s\n",
      "1399it [01:13, 19.93it/s]\titers: 1400, epoch: 8 | loss: 0.1900661\n",
      "\tspeed: 0.0495s/iter; left time: 3238.2320s\n",
      "1499it [01:18, 17.85it/s]\titers: 1500, epoch: 8 | loss: 0.1516323\n",
      "\tspeed: 0.0553s/iter; left time: 3612.1694s\n",
      "1599it [01:23, 19.45it/s]\titers: 1600, epoch: 8 | loss: 0.3041510\n",
      "\tspeed: 0.0522s/iter; left time: 3402.6687s\n",
      "1699it [01:29, 19.21it/s]\titers: 1700, epoch: 8 | loss: 0.1460025\n",
      "\tspeed: 0.0525s/iter; left time: 3417.7633s\n",
      "1797it [01:34, 20.03it/s]\titers: 1800, epoch: 8 | loss: 0.2099312\n",
      "\tspeed: 0.0520s/iter; left time: 3382.5489s\n",
      "1897it [01:39, 22.32it/s]\titers: 1900, epoch: 8 | loss: 0.1858263\n",
      "\tspeed: 0.0524s/iter; left time: 3401.1197s\n",
      "1999it [01:44, 19.45it/s]\titers: 2000, epoch: 8 | loss: 0.1230642\n",
      "\tspeed: 0.0488s/iter; left time: 3163.0971s\n",
      "2098it [01:49, 19.75it/s]\titers: 2100, epoch: 8 | loss: 0.4333514\n",
      "\tspeed: 0.0508s/iter; left time: 3290.7663s\n",
      "2199it [01:54, 21.03it/s]\titers: 2200, epoch: 8 | loss: 0.2543928\n",
      "\tspeed: 0.0477s/iter; left time: 3082.9075s\n",
      "2297it [01:59, 19.72it/s]\titers: 2300, epoch: 8 | loss: 0.2501284\n",
      "\tspeed: 0.0563s/iter; left time: 3633.3718s\n",
      "2397it [02:04, 20.28it/s]\titers: 2400, epoch: 8 | loss: 0.3098821\n",
      "\tspeed: 0.0497s/iter; left time: 3201.8302s\n",
      "2499it [02:10, 20.09it/s]\titers: 2500, epoch: 8 | loss: 0.3046996\n",
      "\tspeed: 0.0510s/iter; left time: 3279.0523s\n",
      "2598it [02:15, 13.60it/s]\titers: 2600, epoch: 8 | loss: 0.3016855\n",
      "\tspeed: 0.0560s/iter; left time: 3595.5274s\n",
      "2698it [02:20, 17.28it/s]\titers: 2700, epoch: 8 | loss: 0.1826419\n",
      "\tspeed: 0.0523s/iter; left time: 3355.0303s\n",
      "2798it [02:26, 19.02it/s]\titers: 2800, epoch: 8 | loss: 0.4551526\n",
      "\tspeed: 0.0519s/iter; left time: 3323.6500s\n",
      "2899it [02:31, 18.63it/s]\titers: 2900, epoch: 8 | loss: 0.2517246\n",
      "\tspeed: 0.0521s/iter; left time: 3333.8636s\n",
      "2999it [02:36, 19.82it/s]\titers: 3000, epoch: 8 | loss: 0.1783622\n",
      "\tspeed: 0.0566s/iter; left time: 3609.8811s\n",
      "3099it [02:42, 19.73it/s]\titers: 3100, epoch: 8 | loss: 0.2239017\n",
      "\tspeed: 0.0512s/iter; left time: 3260.0463s\n",
      "3199it [02:47, 18.86it/s]\titers: 3200, epoch: 8 | loss: 0.2148659\n",
      "\tspeed: 0.0509s/iter; left time: 3238.3968s\n",
      "3299it [02:52, 19.08it/s]\titers: 3300, epoch: 8 | loss: 0.3344967\n",
      "\tspeed: 0.0517s/iter; left time: 3284.6756s\n",
      "3398it [02:57, 19.26it/s]\titers: 3400, epoch: 8 | loss: 0.1922351\n",
      "\tspeed: 0.0566s/iter; left time: 3589.0107s\n",
      "3498it [03:03, 19.67it/s]\titers: 3500, epoch: 8 | loss: 0.3765999\n",
      "\tspeed: 0.0523s/iter; left time: 3310.9626s\n",
      "3599it [03:08, 18.46it/s]\titers: 3600, epoch: 8 | loss: 0.2850727\n",
      "\tspeed: 0.0516s/iter; left time: 3264.3710s\n",
      "3699it [03:14, 13.95it/s]\titers: 3700, epoch: 8 | loss: 0.2773946\n",
      "\tspeed: 0.0570s/iter; left time: 3598.5048s\n",
      "3713it [03:14, 19.05it/s]\n",
      "Epoch: 8 cost time: 194.89283061027527\n",
      "810it [00:21, 37.98it/s]\n",
      "807it [00:20, 38.80it/s]\n",
      "Epoch: 8 | Train Loss: 0.2263394 Vali Loss: 0.2713491 Test Loss: 0.3369494 MAE Loss: 0.3479794\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "99it [00:06, 16.83it/s]\titers: 100, epoch: 9 | loss: 0.1539490\n",
      "\tspeed: 0.5046s/iter; left time: 31800.9777s\n",
      "198it [00:11, 19.97it/s]\titers: 200, epoch: 9 | loss: 0.2080016\n",
      "\tspeed: 0.0523s/iter; left time: 3289.7630s\n",
      "298it [00:16, 19.50it/s]\titers: 300, epoch: 9 | loss: 0.3223712\n",
      "\tspeed: 0.0542s/iter; left time: 3407.2757s\n",
      "399it [00:21, 19.39it/s]\titers: 400, epoch: 9 | loss: 0.1631040\n",
      "\tspeed: 0.0518s/iter; left time: 3248.4927s\n",
      "499it [00:27, 19.56it/s]\titers: 500, epoch: 9 | loss: 0.1786541\n",
      "\tspeed: 0.0524s/iter; left time: 3278.8550s\n",
      "598it [00:32, 19.84it/s]\titers: 600, epoch: 9 | loss: 0.1393923\n",
      "\tspeed: 0.0524s/iter; left time: 3275.2630s\n",
      "699it [00:38, 19.78it/s]\titers: 700, epoch: 9 | loss: 0.3271160\n",
      "\tspeed: 0.0561s/iter; left time: 3499.3072s\n",
      "798it [00:43, 19.40it/s]\titers: 800, epoch: 9 | loss: 0.2088670\n",
      "\tspeed: 0.0525s/iter; left time: 3272.2751s\n",
      "897it [00:48, 19.81it/s]\titers: 900, epoch: 9 | loss: 0.4009965\n",
      "\tspeed: 0.0531s/iter; left time: 3306.3846s\n",
      "999it [00:53, 15.22it/s]\titers: 1000, epoch: 9 | loss: 0.1363897\n",
      "\tspeed: 0.0540s/iter; left time: 3354.1936s\n",
      "1098it [00:58, 19.60it/s]\titers: 1100, epoch: 9 | loss: 0.2783168\n",
      "\tspeed: 0.0492s/iter; left time: 3049.3719s\n",
      "1199it [01:03, 19.24it/s]\titers: 1200, epoch: 9 | loss: 0.2497282\n",
      "\tspeed: 0.0494s/iter; left time: 3061.1822s\n",
      "1298it [01:08, 18.65it/s]\titers: 1300, epoch: 9 | loss: 0.1728990\n",
      "\tspeed: 0.0517s/iter; left time: 3198.3652s\n",
      "1397it [01:14, 22.23it/s]\titers: 1400, epoch: 9 | loss: 0.1829947\n",
      "\tspeed: 0.0536s/iter; left time: 3308.4690s\n",
      "1498it [01:19, 19.69it/s]\titers: 1500, epoch: 9 | loss: 0.3080802\n",
      "\tspeed: 0.0516s/iter; left time: 3180.1231s\n",
      "1598it [01:24, 19.11it/s]\titers: 1600, epoch: 9 | loss: 0.2051201\n",
      "\tspeed: 0.0544s/iter; left time: 3344.7782s\n",
      "1699it [01:30, 17.55it/s]\titers: 1700, epoch: 9 | loss: 0.1415945\n",
      "\tspeed: 0.0524s/iter; left time: 3218.3671s\n",
      "1798it [01:35, 18.42it/s]\titers: 1800, epoch: 9 | loss: 0.2303640\n",
      "\tspeed: 0.0527s/iter; left time: 3230.2721s\n",
      "1898it [01:40, 17.93it/s]\titers: 1900, epoch: 9 | loss: 0.1803210\n",
      "\tspeed: 0.0520s/iter; left time: 3184.3092s\n",
      "1999it [01:45, 18.22it/s]\titers: 2000, epoch: 9 | loss: 0.3253363\n",
      "\tspeed: 0.0523s/iter; left time: 3197.5292s\n",
      "2099it [01:51, 14.78it/s]\titers: 2100, epoch: 9 | loss: 0.2271540\n",
      "\tspeed: 0.0566s/iter; left time: 3454.4975s\n",
      "2199it [01:57, 17.20it/s]\titers: 2200, epoch: 9 | loss: 0.2478563\n",
      "\tspeed: 0.0561s/iter; left time: 3415.7445s\n",
      "2299it [02:02, 18.18it/s]\titers: 2300, epoch: 9 | loss: 0.1459801\n",
      "\tspeed: 0.0547s/iter; left time: 3327.6731s\n",
      "2399it [02:07, 19.33it/s]\titers: 2400, epoch: 9 | loss: 0.3402143\n",
      "\tspeed: 0.0507s/iter; left time: 3076.4200s\n",
      "2499it [02:13, 17.71it/s]\titers: 2500, epoch: 9 | loss: 0.1480887\n",
      "\tspeed: 0.0587s/iter; left time: 3560.3835s\n",
      "2599it [02:19, 19.38it/s]\titers: 2600, epoch: 9 | loss: 0.1720490\n",
      "\tspeed: 0.0543s/iter; left time: 3288.3742s\n",
      "2698it [02:24, 17.49it/s]\titers: 2700, epoch: 9 | loss: 0.2580763\n",
      "\tspeed: 0.0555s/iter; left time: 3354.6498s\n",
      "2799it [02:29, 18.03it/s]\titers: 2800, epoch: 9 | loss: 0.1690568\n",
      "\tspeed: 0.0537s/iter; left time: 3236.5084s\n",
      "2899it [02:35, 20.07it/s]\titers: 2900, epoch: 9 | loss: 0.2525652\n",
      "\tspeed: 0.0598s/iter; left time: 3600.9198s\n",
      "2999it [02:41, 17.32it/s]\titers: 3000, epoch: 9 | loss: 0.2286088\n",
      "\tspeed: 0.0585s/iter; left time: 3519.6509s\n",
      "3099it [02:47, 17.39it/s]\titers: 3100, epoch: 9 | loss: 0.1457327\n",
      "\tspeed: 0.0548s/iter; left time: 3286.8451s\n",
      "3199it [02:52, 19.79it/s]\titers: 3200, epoch: 9 | loss: 0.3103308\n",
      "\tspeed: 0.0567s/iter; left time: 3396.8208s\n",
      "3298it [02:58, 18.64it/s]\titers: 3300, epoch: 9 | loss: 0.1334814\n",
      "\tspeed: 0.0538s/iter; left time: 3216.8315s\n",
      "3398it [03:03, 19.22it/s]\titers: 3400, epoch: 9 | loss: 0.2989637\n",
      "\tspeed: 0.0527s/iter; left time: 3146.0532s\n",
      "3498it [03:09, 16.00it/s]\titers: 3500, epoch: 9 | loss: 0.2390614\n",
      "\tspeed: 0.0553s/iter; left time: 3296.2425s\n",
      "3599it [03:14, 16.95it/s]\titers: 3600, epoch: 9 | loss: 0.3305885\n",
      "\tspeed: 0.0528s/iter; left time: 3144.9612s\n",
      "3699it [03:19, 19.46it/s]\titers: 3700, epoch: 9 | loss: 0.2014689\n",
      "\tspeed: 0.0517s/iter; left time: 3070.6921s\n",
      "3713it [03:20, 18.53it/s]\n",
      "Epoch: 9 cost time: 200.35897135734558\n",
      "810it [00:21, 37.63it/s]\n",
      "807it [00:21, 38.06it/s]\n",
      "Epoch: 9 | Train Loss: 0.2233159 Vali Loss: 0.2806862 Test Loss: 0.3419643 MAE Loss: 0.3560280\n",
      "EarlyStopping counter: 1 out of 3\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "98it [00:05, 19.73it/s]\titers: 100, epoch: 10 | loss: 0.2427141\n",
      "\tspeed: 0.4918s/iter; left time: 29168.7857s\n",
      "199it [00:10, 19.76it/s]\titers: 200, epoch: 10 | loss: 0.3162464\n",
      "\tspeed: 0.0506s/iter; left time: 2994.0153s\n",
      "299it [00:15, 21.55it/s]\titers: 300, epoch: 10 | loss: 0.2518137\n",
      "\tspeed: 0.0483s/iter; left time: 2855.3253s\n",
      "398it [00:20, 19.77it/s]\titers: 400, epoch: 10 | loss: 0.2039752\n",
      "\tspeed: 0.0498s/iter; left time: 2939.8799s\n",
      "499it [00:25, 19.78it/s]\titers: 500, epoch: 10 | loss: 0.3065372\n",
      "\tspeed: 0.0545s/iter; left time: 3211.5516s\n",
      "598it [00:30, 19.81it/s]\titers: 600, epoch: 10 | loss: 0.3711802\n",
      "\tspeed: 0.0505s/iter; left time: 2972.0283s\n",
      "699it [00:36, 19.78it/s]\titers: 700, epoch: 10 | loss: 0.2595115\n",
      "\tspeed: 0.0506s/iter; left time: 2969.3537s\n",
      "798it [00:41, 19.51it/s]\titers: 800, epoch: 10 | loss: 0.1817314\n",
      "\tspeed: 0.0557s/iter; left time: 3266.3434s\n",
      "898it [00:46, 19.79it/s]\titers: 900, epoch: 10 | loss: 0.2399784\n",
      "\tspeed: 0.0505s/iter; left time: 2957.6071s\n",
      "998it [00:51, 19.80it/s]\titers: 1000, epoch: 10 | loss: 0.0877128\n",
      "\tspeed: 0.0505s/iter; left time: 2951.6071s\n",
      "1099it [00:56, 19.63it/s]\titers: 1100, epoch: 10 | loss: 0.1322480\n",
      "\tspeed: 0.0506s/iter; left time: 2949.1578s\n",
      "1198it [01:02, 19.80it/s]\titers: 1200, epoch: 10 | loss: 0.2840722\n",
      "\tspeed: 0.0557s/iter; left time: 3243.2285s\n",
      "1298it [01:07, 19.81it/s]\titers: 1300, epoch: 10 | loss: 0.1706120\n",
      "\tspeed: 0.0511s/iter; left time: 2969.2776s\n",
      "1399it [01:12, 19.74it/s]\titers: 1400, epoch: 10 | loss: 0.2571991\n",
      "\tspeed: 0.0503s/iter; left time: 2915.0506s\n",
      "1498it [01:17, 17.32it/s]\titers: 1500, epoch: 10 | loss: 0.2421079\n",
      "\tspeed: 0.0553s/iter; left time: 3203.4047s\n",
      "1599it [01:22, 19.88it/s]\titers: 1600, epoch: 10 | loss: 0.3175933\n",
      "\tspeed: 0.0501s/iter; left time: 2893.8229s\n",
      "1697it [01:27, 19.72it/s]\titers: 1700, epoch: 10 | loss: 0.2232439\n",
      "\tspeed: 0.0506s/iter; left time: 2918.7890s\n",
      "1798it [01:33, 19.77it/s]\titers: 1800, epoch: 10 | loss: 0.2117463\n",
      "\tspeed: 0.0513s/iter; left time: 2955.7906s\n",
      "1898it [01:38, 18.57it/s]\titers: 1900, epoch: 10 | loss: 0.1886370\n",
      "\tspeed: 0.0575s/iter; left time: 3305.0855s\n",
      "1999it [01:44, 19.45it/s]\titers: 2000, epoch: 10 | loss: 0.2202047\n",
      "\tspeed: 0.0525s/iter; left time: 3015.4339s\n",
      "2098it [01:49, 19.72it/s]\titers: 2100, epoch: 10 | loss: 0.1833770\n",
      "\tspeed: 0.0527s/iter; left time: 3018.8275s\n",
      "2198it [01:54, 18.64it/s]\titers: 2200, epoch: 10 | loss: 0.1077093\n",
      "\tspeed: 0.0518s/iter; left time: 2966.0078s\n",
      "2298it [02:00, 19.75it/s]\titers: 2300, epoch: 10 | loss: 0.2216998\n",
      "\tspeed: 0.0555s/iter; left time: 3167.6088s\n",
      "2399it [02:05, 19.80it/s]\titers: 2400, epoch: 10 | loss: 0.1977016\n",
      "\tspeed: 0.0505s/iter; left time: 2880.0304s\n",
      "2498it [02:10, 19.81it/s]\titers: 2500, epoch: 10 | loss: 0.1767807\n",
      "\tspeed: 0.0505s/iter; left time: 2876.5386s\n",
      "2599it [02:15, 18.65it/s]\titers: 2600, epoch: 10 | loss: 0.3071855\n",
      "\tspeed: 0.0541s/iter; left time: 3075.1555s\n",
      "2699it [02:20, 19.79it/s]\titers: 2700, epoch: 10 | loss: 0.1692386\n",
      "\tspeed: 0.0505s/iter; left time: 2866.6207s\n",
      "2799it [02:25, 19.76it/s]\titers: 2800, epoch: 10 | loss: 0.1679888\n",
      "\tspeed: 0.0505s/iter; left time: 2861.4404s\n",
      "2899it [02:30, 19.79it/s]\titers: 2900, epoch: 10 | loss: 0.2077754\n",
      "\tspeed: 0.0505s/iter; left time: 2854.8786s\n",
      "2999it [02:36, 19.46it/s]\titers: 3000, epoch: 10 | loss: 0.2938270\n",
      "\tspeed: 0.0549s/iter; left time: 3094.2496s\n",
      "3099it [02:41, 19.42it/s]\titers: 3100, epoch: 10 | loss: 0.2888597\n",
      "\tspeed: 0.0516s/iter; left time: 2903.9352s\n",
      "3199it [02:46, 19.02it/s]\titers: 3200, epoch: 10 | loss: 0.2689926\n",
      "\tspeed: 0.0522s/iter; left time: 2931.6121s\n",
      "3299it [02:52, 19.74it/s]\titers: 3300, epoch: 10 | loss: 0.1250704\n",
      "\tspeed: 0.0554s/iter; left time: 3111.0848s\n",
      "3399it [02:57, 17.37it/s]\titers: 3400, epoch: 10 | loss: 0.1749547\n",
      "\tspeed: 0.0534s/iter; left time: 2992.9279s\n",
      "3499it [03:02, 18.48it/s]\titers: 3500, epoch: 10 | loss: 0.1986256\n",
      "\tspeed: 0.0503s/iter; left time: 2809.4694s\n",
      "3598it [03:07, 19.61it/s]\titers: 3600, epoch: 10 | loss: 0.1884195\n",
      "\tspeed: 0.0512s/iter; left time: 2858.6773s\n",
      "3699it [03:13, 18.98it/s]\titers: 3700, epoch: 10 | loss: 0.1794343\n",
      "\tspeed: 0.0572s/iter; left time: 3185.0340s\n",
      "3713it [03:14, 19.11it/s]\n",
      "Epoch: 10 cost time: 194.25576663017273\n",
      "810it [00:20, 38.64it/s]\n",
      "807it [00:20, 39.75it/s]\n",
      "Epoch: 10 | Train Loss: 0.2204941 Vali Loss: 0.2785022 Test Loss: 0.3440349 MAE Loss: 0.3634143\n",
      "EarlyStopping counter: 2 out of 3\n",
      "lr = 0.0000100000\n",
      "learning_rate 1e-05\n",
      "lr 1e-05\n",
      "99it [00:05, 19.71it/s]\titers: 100, epoch: 11 | loss: 0.2226047\n",
      "\tspeed: 0.4741s/iter; left time: 26356.1291s\n",
      "198it [00:10, 16.22it/s]\titers: 200, epoch: 11 | loss: 0.2497960\n",
      "\tspeed: 0.0523s/iter; left time: 2900.7635s\n",
      "299it [00:14, 22.28it/s]\titers: 300, epoch: 11 | loss: 0.4099246\n",
      "\tspeed: 0.0469s/iter; left time: 2597.2618s\n",
      "399it [00:20, 18.61it/s]\titers: 400, epoch: 11 | loss: 0.3217982\n",
      "\tspeed: 0.0507s/iter; left time: 2804.6730s\n",
      "499it [00:25, 18.71it/s]\titers: 500, epoch: 11 | loss: 0.2258809\n",
      "\tspeed: 0.0542s/iter; left time: 2989.4750s\n",
      "599it [00:31, 18.93it/s]\titers: 600, epoch: 11 | loss: 0.2192411\n",
      "\tspeed: 0.0564s/iter; left time: 3104.8128s\n",
      "698it [00:36, 19.36it/s]\titers: 700, epoch: 11 | loss: 0.1370032\n",
      "\tspeed: 0.0521s/iter; left time: 2867.3661s\n",
      "798it [00:41, 19.81it/s]\titers: 800, epoch: 11 | loss: 0.3152646\n",
      "\tspeed: 0.0506s/iter; left time: 2775.4877s\n",
      "899it [00:46, 16.60it/s]\titers: 900, epoch: 11 | loss: 0.1793289\n",
      "\tspeed: 0.0557s/iter; left time: 3053.9266s\n",
      "999it [00:52, 19.78it/s]\titers: 1000, epoch: 11 | loss: 0.2195462\n",
      "\tspeed: 0.0515s/iter; left time: 2816.8225s\n",
      "1099it [00:57, 20.37it/s]\titers: 1100, epoch: 11 | loss: 0.1570368\n",
      "\tspeed: 0.0505s/iter; left time: 2759.7646s\n",
      "1198it [01:02, 18.53it/s]\titers: 1200, epoch: 11 | loss: 0.1659487\n",
      "\tspeed: 0.0510s/iter; left time: 2777.6359s\n",
      "1298it [01:07, 19.77it/s]\titers: 1300, epoch: 11 | loss: 0.2849747\n",
      "\tspeed: 0.0548s/iter; left time: 2978.8381s\n",
      "1398it [01:13, 21.48it/s]\titers: 1400, epoch: 11 | loss: 0.3298291\n",
      "\tspeed: 0.0534s/iter; left time: 2900.9752s\n",
      "1499it [01:17, 19.77it/s]\titers: 1500, epoch: 11 | loss: 0.1243528\n",
      "\tspeed: 0.0491s/iter; left time: 2660.4956s\n",
      "1599it [01:23, 19.68it/s]\titers: 1600, epoch: 11 | loss: 0.1901001\n",
      "\tspeed: 0.0510s/iter; left time: 2760.3427s\n",
      "1699it [01:28, 19.46it/s]\titers: 1700, epoch: 11 | loss: 0.2423322\n",
      "\tspeed: 0.0549s/iter; left time: 2966.2020s\n",
      "1798it [01:33, 19.75it/s]\titers: 1800, epoch: 11 | loss: 0.3426455\n",
      "\tspeed: 0.0506s/iter; left time: 2726.5192s\n",
      "1899it [01:38, 19.83it/s]\titers: 1900, epoch: 11 | loss: 0.1324632\n",
      "\tspeed: 0.0505s/iter; left time: 2718.4681s\n",
      "1999it [01:43, 19.82it/s]\titers: 2000, epoch: 11 | loss: 0.2271660\n",
      "\tspeed: 0.0512s/iter; left time: 2747.0922s\n",
      "2098it [01:48, 19.56it/s]\titers: 2100, epoch: 11 | loss: 0.1787997\n",
      "\tspeed: 0.0516s/iter; left time: 2766.5602s\n",
      "2198it [01:54, 19.76it/s]\titers: 2200, epoch: 11 | loss: 0.1798140\n",
      "\tspeed: 0.0511s/iter; left time: 2731.6038s\n",
      "2298it [01:59, 15.25it/s]\titers: 2300, epoch: 11 | loss: 0.2961617\n",
      "\tspeed: 0.0540s/iter; left time: 2880.9337s\n",
      "2398it [02:04, 19.78it/s]\titers: 2400, epoch: 11 | loss: 0.1426474\n",
      "\tspeed: 0.0526s/iter; left time: 2803.0721s\n",
      "2498it [02:09, 19.75it/s]\titers: 2500, epoch: 11 | loss: 0.3767688\n",
      "\tspeed: 0.0505s/iter; left time: 2689.0468s\n",
      "2598it [02:14, 19.52it/s]\titers: 2600, epoch: 11 | loss: 0.2841069\n",
      "\tspeed: 0.0519s/iter; left time: 2755.0073s\n",
      "2698it [02:20, 19.80it/s]\titers: 2700, epoch: 11 | loss: 0.2150493\n",
      "\tspeed: 0.0546s/iter; left time: 2894.3229s\n",
      "2798it [02:25, 19.77it/s]\titers: 2800, epoch: 11 | loss: 0.2564313\n",
      "\tspeed: 0.0505s/iter; left time: 2669.7122s\n",
      "2899it [02:30, 19.71it/s]\titers: 2900, epoch: 11 | loss: 0.4497221\n",
      "\tspeed: 0.0509s/iter; left time: 2687.6722s\n",
      "2999it [02:36, 14.49it/s]\titers: 3000, epoch: 11 | loss: 0.2540026\n",
      "\tspeed: 0.0554s/iter; left time: 2917.6652s\n",
      "3098it [02:41, 19.77it/s]\titers: 3100, epoch: 11 | loss: 0.1044876\n",
      "\tspeed: 0.0505s/iter; left time: 2656.1701s\n",
      "3199it [02:46, 19.74it/s]\titers: 3200, epoch: 11 | loss: 0.2096896\n",
      "\tspeed: 0.0506s/iter; left time: 2654.2073s\n",
      "3299it [02:51, 19.66it/s]\titers: 3300, epoch: 11 | loss: 0.3045055\n",
      "\tspeed: 0.0509s/iter; left time: 2667.3479s\n",
      "3398it [02:56, 19.80it/s]\titers: 3400, epoch: 11 | loss: 0.1100050\n",
      "\tspeed: 0.0537s/iter; left time: 2807.2729s\n",
      "3498it [03:01, 19.79it/s]\titers: 3500, epoch: 11 | loss: 0.2421690\n",
      "\tspeed: 0.0510s/iter; left time: 2661.4559s\n",
      "3599it [03:06, 20.77it/s]\titers: 3600, epoch: 11 | loss: 0.1640910\n",
      "\tspeed: 0.0514s/iter; left time: 2679.4886s\n",
      "3698it [03:11, 19.46it/s]\titers: 3700, epoch: 11 | loss: 0.1108136\n",
      "\tspeed: 0.0503s/iter; left time: 2613.6688s\n",
      "3713it [03:12, 19.27it/s]\n",
      "Epoch: 11 cost time: 192.6948812007904\n",
      "810it [00:21, 38.25it/s]\n",
      "807it [00:21, 37.02it/s]\n",
      "Epoch: 11 | Train Loss: 0.2177464 Vali Loss: 0.2844976 Test Loss: 0.3428949 MAE Loss: 0.3511776\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "Total time: 44.20890150864919 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=25\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.00001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'constant' \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vali_loss = [0.3202976, 0.2930738, 0.2876566, 0.2807395, 0.2868012, 0.2787986, 0.2773737, 0.2713491, 0.2806862, 0.2785022, 0.2844976]\n",
    "tr_loss = [0.3365891, 0.2643867, 0.2524274, 0.2447699, 0.2390104, 0.2330910, 0.2294159, 0.2263394, 0.2233159, 0.2204941, 0.2177464]\n",
    "legend_labels = plot_train_val_loss(tr_loss, vali_loss, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 01:48:40,406] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 01:48:41,623] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 01:48:41,624] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 01:48:43,265] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 01:48:43,760] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 01:48:43,761] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 01:48:43,761] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 01:48:43,762] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 01:48:43,762] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 01:48:43,762] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 01:48:43,763] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 01:48:43,763] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 01:48:43,763] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 01:48:43,763] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 01:48:44,271] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 01:48:44,271] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 01:48:44,272] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.38 GB, percent = 16.2%\n",
      "[2024-05-07 01:48:44,414] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 01:48:44,414] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 01:48:44,414] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.44 GB, percent = 16.2%\n",
      "[2024-05-07 01:48:44,414] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 01:48:44,541] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 01:48:44,542] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 01:48:44,542] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.44 GB, percent = 16.2%\n",
      "[2024-05-07 01:48:44,542] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 01:48:44,542] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 01:48:44,543] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 01:48:44,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7b61168990>\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 01:48:44,543] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   train_batch_size ............. 256\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  256\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 01:48:44,544] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 01:48:44,545] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 01:48:44,545] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 01:48:44,545] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 01:48:44,545] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 01:48:44,545] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 256, \n",
      "    \"train_micro_batch_size_per_gpu\": 256, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:36,  2.74it/s]\titers: 100, epoch: 1 | loss: 0.4383089\n",
      "\tspeed: 0.3834s/iter; left time: 2630.1881s\n",
      "199it [01:12,  2.68it/s]\titers: 200, epoch: 1 | loss: 0.3168621\n",
      "\tspeed: 0.3601s/iter; left time: 2434.9600s\n",
      "299it [01:48,  2.75it/s]\titers: 300, epoch: 1 | loss: 0.3138762\n",
      "\tspeed: 0.3565s/iter; left time: 2374.7763s\n",
      "348it [02:06,  2.76it/s]\n",
      "Epoch: 1 cost time: 126.0025520324707\n",
      "75it [00:19,  3.84it/s]\n",
      "75it [00:19,  3.78it/s]\n",
      "Epoch: 1 | Train Loss: 0.4278012 Vali Loss: 0.3185768 Test Loss: 0.3749815 MAE Loss: 0.4002741\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:32,  3.05it/s]\titers: 100, epoch: 2 | loss: 0.2989920\n",
      "\tspeed: 0.9194s/iter; left time: 5988.3764s\n",
      "199it [01:05,  3.17it/s]\titers: 200, epoch: 2 | loss: 0.2854707\n",
      "\tspeed: 0.3274s/iter; left time: 2099.5649s\n",
      "299it [01:37,  3.17it/s]\titers: 300, epoch: 2 | loss: 0.2790671\n",
      "\tspeed: 0.3280s/iter; left time: 2070.3756s\n",
      "348it [01:53,  3.06it/s]\n",
      "Epoch: 2 cost time: 113.7213282585144\n",
      "75it [00:16,  4.44it/s]\n",
      "75it [00:15,  4.71it/s]\n",
      "Epoch: 2 | Train Loss: 0.2747759 Vali Loss: 0.2981417 Test Loss: 0.3477145 MAE Loss: 0.3740955\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:32,  3.12it/s]\titers: 100, epoch: 3 | loss: 0.2652175\n",
      "\tspeed: 0.8378s/iter; left time: 5165.2331s\n",
      "199it [01:05,  3.17it/s]\titers: 200, epoch: 3 | loss: 0.2418660\n",
      "\tspeed: 0.3264s/iter; left time: 1979.7761s\n",
      "299it [01:38,  3.01it/s]\titers: 300, epoch: 3 | loss: 0.2839068\n",
      "\tspeed: 0.3293s/iter; left time: 1964.2028s\n",
      "348it [01:54,  3.05it/s]\n",
      "Epoch: 3 cost time: 114.25396466255188\n",
      "75it [00:15,  4.73it/s]\n",
      "75it [00:15,  4.74it/s]\n",
      "Epoch: 3 | Train Loss: 0.2615289 Vali Loss: 0.2942223 Test Loss: 0.3447941 MAE Loss: 0.3660946\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:31,  3.19it/s]\titers: 100, epoch: 4 | loss: 0.2818418\n",
      "\tspeed: 0.8141s/iter; left time: 4735.4884s\n",
      "199it [01:04,  3.18it/s]\titers: 200, epoch: 4 | loss: 0.2701691\n",
      "\tspeed: 0.3301s/iter; left time: 1887.4617s\n",
      "299it [01:37,  3.04it/s]\titers: 300, epoch: 4 | loss: 0.2343760\n",
      "\tspeed: 0.3269s/iter; left time: 1836.3654s\n",
      "348it [01:53,  3.07it/s]\n",
      "Epoch: 4 cost time: 113.44374513626099\n",
      "75it [00:16,  4.62it/s]\n",
      "75it [00:16,  4.62it/s]\n",
      "Epoch: 4 | Train Loss: 0.2570295 Vali Loss: 0.2900112 Test Loss: 0.3394612 MAE Loss: 0.3664377\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:32,  3.14it/s]\titers: 100, epoch: 5 | loss: 0.2651567\n",
      "\tspeed: 0.8420s/iter; left time: 4605.1434s\n",
      "199it [01:05,  3.18it/s]\titers: 200, epoch: 5 | loss: 0.2810154\n",
      "\tspeed: 0.3234s/iter; left time: 1736.1691s\n",
      "299it [01:37,  3.15it/s]\titers: 300, epoch: 5 | loss: 0.2424490\n",
      "\tspeed: 0.3196s/iter; left time: 1683.7348s\n",
      "348it [01:53,  3.07it/s]\n",
      "Epoch: 5 cost time: 113.50898599624634\n",
      "75it [00:16,  4.64it/s]\n",
      "75it [00:15,  4.76it/s]\n",
      "Epoch: 5 | Train Loss: 0.2545159 Vali Loss: 0.2893073 Test Loss: 0.3390148 MAE Loss: 0.3615554\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:32,  3.16it/s]\titers: 100, epoch: 6 | loss: 0.2276232\n",
      "\tspeed: 0.8315s/iter; left time: 4258.0465s\n",
      "199it [01:03,  3.15it/s]\titers: 200, epoch: 6 | loss: 0.2644709\n",
      "\tspeed: 0.3180s/iter; left time: 1596.6362s\n",
      "299it [01:35,  3.10it/s]\titers: 300, epoch: 6 | loss: 0.2383226\n",
      "\tspeed: 0.3188s/iter; left time: 1568.7560s\n",
      "348it [01:51,  3.12it/s]\n",
      "Epoch: 6 cost time: 111.38864064216614\n",
      "75it [00:16,  4.56it/s]\n",
      "75it [00:16,  4.59it/s]\n",
      "Epoch: 6 | Train Loss: 0.2531469 Vali Loss: 0.2883784 Test Loss: 0.3412866 MAE Loss: 0.3681198\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:32,  3.05it/s]\titers: 100, epoch: 7 | loss: 0.2473038\n",
      "\tspeed: 0.8272s/iter; left time: 3948.0738s\n",
      "199it [01:04,  3.12it/s]\titers: 200, epoch: 7 | loss: 0.2704551\n",
      "\tspeed: 0.3210s/iter; left time: 1500.0924s\n",
      "299it [01:36,  3.15it/s]\titers: 300, epoch: 7 | loss: 0.2744439\n",
      "\tspeed: 0.3185s/iter; left time: 1456.7172s\n",
      "348it [01:51,  3.11it/s]\n",
      "Epoch: 7 cost time: 111.83486557006836\n",
      "75it [00:16,  4.66it/s]\n",
      "75it [00:15,  4.74it/s]\n",
      "Epoch: 7 | Train Loss: 0.2520134 Vali Loss: 0.2858504 Test Loss: 0.3362303 MAE Loss: 0.3623939\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:32,  3.16it/s]\titers: 100, epoch: 8 | loss: 0.2255530\n",
      "\tspeed: 0.8156s/iter; left time: 3609.1262s\n",
      "199it [01:04,  3.19it/s]\titers: 200, epoch: 8 | loss: 0.2311270\n",
      "\tspeed: 0.3197s/iter; left time: 1382.6469s\n",
      "299it [01:36,  3.12it/s]\titers: 300, epoch: 8 | loss: 0.2523777\n",
      "\tspeed: 0.3177s/iter; left time: 1342.2432s\n",
      "348it [01:51,  3.12it/s]\n",
      "Epoch: 8 cost time: 111.66413950920105\n",
      "75it [00:15,  4.69it/s]\n",
      "75it [00:15,  4.79it/s]\n",
      "Epoch: 8 | Train Loss: 0.2520672 Vali Loss: 0.2881475 Test Loss: 0.3388793 MAE Loss: 0.3668156\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [00:32,  3.16it/s]\titers: 100, epoch: 9 | loss: 0.2695733\n",
      "\tspeed: 0.8004s/iter; left time: 3263.3755s\n",
      "199it [01:04,  3.16it/s]\titers: 200, epoch: 9 | loss: 0.2845022\n",
      "\tspeed: 0.3211s/iter; left time: 1276.9329s\n",
      "299it [01:36,  3.18it/s]\titers: 300, epoch: 9 | loss: 0.2427607\n",
      "\tspeed: 0.3170s/iter; left time: 1228.9856s\n",
      "348it [01:52,  3.09it/s]\n",
      "Epoch: 9 cost time: 112.5933928489685\n",
      "75it [00:15,  4.71it/s]\n",
      "75it [00:16,  4.64it/s]\n",
      "Epoch: 9 | Train Loss: 0.2520111 Vali Loss: 0.2873899 Test Loss: 0.3373981 MAE Loss: 0.3643361\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [00:32,  3.18it/s]\titers: 100, epoch: 10 | loss: 0.1958383\n",
      "\tspeed: 0.8088s/iter; left time: 3016.0673s\n",
      "199it [01:04,  3.11it/s]\titers: 200, epoch: 10 | loss: 0.2133498\n",
      "\tspeed: 0.3188s/iter; left time: 1157.0833s\n",
      "299it [01:36,  3.19it/s]\titers: 300, epoch: 10 | loss: 0.2800419\n",
      "\tspeed: 0.3195s/iter; left time: 1127.5841s\n",
      "348it [01:52,  3.09it/s]\n",
      "Epoch: 10 cost time: 112.52375149726868\n",
      "75it [00:16,  4.63it/s]\n",
      "75it [00:15,  4.74it/s]\n",
      "Epoch: 10 | Train Loss: 0.2514976 Vali Loss: 0.2875280 Test Loss: 0.3375961 MAE Loss: 0.3642690\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 25.097158082326253 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=256\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 02:13:46,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 02:13:47,322] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 02:13:47,322] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 02:13:49,526] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 02:13:50,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 02:13:50,314] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 02:13:50,314] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 02:13:50,315] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 02:13:50,315] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 02:13:50,315] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 02:13:50,315] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 02:13:50,315] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 02:13:50,315] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 02:13:50,315] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 02:13:50,550] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 02:13:50,551] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:13:50,551] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.84 GB, percent = 20.3%\n",
      "[2024-05-07 02:13:50,672] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 02:13:50,673] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:13:50,673] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.84 GB, percent = 20.3%\n",
      "[2024-05-07 02:13:50,673] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 02:13:50,812] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 02:13:50,813] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:13:50,813] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.84 GB, percent = 20.3%\n",
      "[2024-05-07 02:13:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 02:13:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 02:13:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 02:13:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 02:13:50,814] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 02:13:50,814] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 02:13:50,814] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 02:13:50,814] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 02:13:50,814] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5e28044150>\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 02:13:50,815] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   train_batch_size ............. 128\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 02:13:50,816] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 128, \n",
      "    \"train_micro_batch_size_per_gpu\": 128, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:22,  4.31it/s]\titers: 100, epoch: 1 | loss: 0.5089871\n",
      "\tspeed: 0.2378s/iter; left time: 3286.9883s\n",
      "127it [00:28,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199it [00:44,  5.23it/s]\titers: 200, epoch: 1 | loss: 0.2775090\n",
      "\tspeed: 0.2216s/iter; left time: 3040.2054s\n",
      "299it [01:06,  4.70it/s]\titers: 300, epoch: 1 | loss: 0.3590579\n",
      "\tspeed: 0.2193s/iter; left time: 2986.4835s\n",
      "399it [01:28,  4.28it/s]\titers: 400, epoch: 1 | loss: 0.2895975\n",
      "\tspeed: 0.2192s/iter; left time: 2963.7327s\n",
      "499it [01:50,  4.94it/s]\titers: 500, epoch: 1 | loss: 0.2993958\n",
      "\tspeed: 0.2200s/iter; left time: 2951.9997s\n",
      "599it [02:13,  5.00it/s]\titers: 600, epoch: 1 | loss: 0.2859322\n",
      "\tspeed: 0.2265s/iter; left time: 3017.5638s\n",
      "696it [02:34,  4.52it/s]\n",
      "Epoch: 1 cost time: 154.00415992736816\n",
      "151it [00:19,  7.63it/s]\n",
      "151it [00:19,  7.80it/s]\n",
      "Epoch: 1 | Train Loss: 0.3591971 Vali Loss: 0.3131735 Test Loss: 0.3844208 MAE Loss: 0.4030330\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:19,  4.71it/s]\titers: 100, epoch: 2 | loss: 0.2870230\n",
      "\tspeed: 0.8177s/iter; left time: 10732.1881s\n",
      "199it [00:38,  5.76it/s]\titers: 200, epoch: 2 | loss: 0.3863401\n",
      "\tspeed: 0.1924s/iter; left time: 2505.9206s\n",
      "299it [00:58,  5.15it/s]\titers: 300, epoch: 2 | loss: 0.2559213\n",
      "\tspeed: 0.2005s/iter; left time: 2590.9100s\n",
      "399it [01:19,  4.82it/s]\titers: 400, epoch: 2 | loss: 0.3209968\n",
      "\tspeed: 0.2052s/iter; left time: 2631.6802s\n",
      "499it [01:40,  5.15it/s]\titers: 500, epoch: 2 | loss: 0.2062332\n",
      "\tspeed: 0.2126s/iter; left time: 2704.8184s\n",
      "599it [02:01,  4.67it/s]\titers: 600, epoch: 2 | loss: 0.2129133\n",
      "\tspeed: 0.2118s/iter; left time: 2673.9780s\n",
      "696it [02:21,  4.91it/s]\n",
      "Epoch: 2 cost time: 141.82609033584595\n",
      "151it [00:16,  9.23it/s]\n",
      "151it [00:16,  9.18it/s]\n",
      "Epoch: 2 | Train Loss: 0.2626779 Vali Loss: 0.2992348 Test Loss: 0.3542148 MAE Loss: 0.3739178\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:20,  5.44it/s]\titers: 100, epoch: 3 | loss: 0.2841502\n",
      "\tspeed: 0.7556s/iter; left time: 9391.6126s\n",
      "199it [00:41,  4.91it/s]\titers: 200, epoch: 3 | loss: 0.3034377\n",
      "\tspeed: 0.2037s/iter; left time: 2511.5747s\n",
      "299it [01:01,  5.35it/s]\titers: 300, epoch: 3 | loss: 0.2580580\n",
      "\tspeed: 0.2043s/iter; left time: 2497.9609s\n",
      "399it [01:22,  4.27it/s]\titers: 400, epoch: 3 | loss: 0.2632921\n",
      "\tspeed: 0.2048s/iter; left time: 2484.4681s\n",
      "499it [01:42,  5.00it/s]\titers: 500, epoch: 3 | loss: 0.2794692\n",
      "\tspeed: 0.2038s/iter; left time: 2451.5816s\n",
      "599it [02:02,  5.29it/s]\titers: 600, epoch: 3 | loss: 0.2568230\n",
      "\tspeed: 0.2050s/iter; left time: 2445.3581s\n",
      "696it [02:23,  4.86it/s]\n",
      "Epoch: 3 cost time: 143.22470903396606\n",
      "151it [00:16,  8.91it/s]\n",
      "151it [00:16,  9.17it/s]\n",
      "Epoch: 3 | Train Loss: 0.2507019 Vali Loss: 0.2897986 Test Loss: 0.3482069 MAE Loss: 0.3638271\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:20,  5.45it/s]\titers: 100, epoch: 4 | loss: 0.2440619\n",
      "\tspeed: 0.7632s/iter; left time: 8954.1875s\n",
      "199it [00:41,  5.15it/s]\titers: 200, epoch: 4 | loss: 0.2543245\n",
      "\tspeed: 0.2091s/iter; left time: 2432.2252s\n",
      "299it [01:02,  4.49it/s]\titers: 300, epoch: 4 | loss: 0.2354078\n",
      "\tspeed: 0.2064s/iter; left time: 2380.8743s\n",
      "399it [01:23,  4.35it/s]\titers: 400, epoch: 4 | loss: 0.3248844\n",
      "\tspeed: 0.2096s/iter; left time: 2396.4786s\n",
      "499it [01:44,  5.17it/s]\titers: 500, epoch: 4 | loss: 0.3028212\n",
      "\tspeed: 0.2076s/iter; left time: 2353.0418s\n",
      "599it [02:04,  4.49it/s]\titers: 600, epoch: 4 | loss: 0.2362802\n",
      "\tspeed: 0.2049s/iter; left time: 2301.8843s\n",
      "696it [02:24,  4.80it/s]\n",
      "Epoch: 4 cost time: 144.91801738739014\n",
      "151it [00:17,  8.85it/s]\n",
      "151it [00:16,  9.20it/s]\n",
      "Epoch: 4 | Train Loss: 0.2445876 Vali Loss: 0.2895375 Test Loss: 0.3475404 MAE Loss: 0.3779169\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:20,  4.94it/s]\titers: 100, epoch: 5 | loss: 0.2174860\n",
      "\tspeed: 0.7615s/iter; left time: 8404.4329s\n",
      "199it [00:41,  5.41it/s]\titers: 200, epoch: 5 | loss: 0.2938947\n",
      "\tspeed: 0.2046s/iter; left time: 2237.2691s\n",
      "299it [01:01,  4.87it/s]\titers: 300, epoch: 5 | loss: 0.2703697\n",
      "\tspeed: 0.2062s/iter; left time: 2235.0037s\n",
      "399it [01:22,  3.50it/s]\titers: 400, epoch: 5 | loss: 0.2847760\n",
      "\tspeed: 0.2091s/iter; left time: 2244.8914s\n",
      "499it [01:43,  5.29it/s]\titers: 500, epoch: 5 | loss: 0.2154768\n",
      "\tspeed: 0.2090s/iter; left time: 2223.1532s\n",
      "599it [02:04,  4.85it/s]\titers: 600, epoch: 5 | loss: 0.1930077\n",
      "\tspeed: 0.2081s/iter; left time: 2192.5374s\n",
      "696it [02:24,  4.82it/s]\n",
      "Epoch: 5 cost time: 144.25706124305725\n",
      "151it [00:16,  9.26it/s]\n",
      "151it [00:16,  8.97it/s]\n",
      "Epoch: 5 | Train Loss: 0.2423693 Vali Loss: 0.2835751 Test Loss: 0.3452735 MAE Loss: 0.3625991\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:20,  5.34it/s]\titers: 100, epoch: 6 | loss: 0.2555818\n",
      "\tspeed: 0.7545s/iter; left time: 7802.4814s\n",
      "199it [00:41,  4.05it/s]\titers: 200, epoch: 6 | loss: 0.2079971\n",
      "\tspeed: 0.2030s/iter; left time: 2078.5103s\n",
      "299it [01:02,  5.27it/s]\titers: 300, epoch: 6 | loss: 0.3408970\n",
      "\tspeed: 0.2086s/iter; left time: 2115.4308s\n",
      "399it [01:23,  4.84it/s]\titers: 400, epoch: 6 | loss: 0.2746707\n",
      "\tspeed: 0.2120s/iter; left time: 2128.3374s\n",
      "499it [01:44,  3.90it/s]\titers: 500, epoch: 6 | loss: 0.1933526\n",
      "\tspeed: 0.2115s/iter; left time: 2102.6803s\n",
      "599it [02:05,  4.92it/s]\titers: 600, epoch: 6 | loss: 0.2592312\n",
      "\tspeed: 0.2075s/iter; left time: 2042.1647s\n",
      "696it [02:25,  4.79it/s]\n",
      "Epoch: 6 cost time: 145.30145168304443\n",
      "151it [00:16,  9.19it/s]\n",
      "151it [00:16,  9.24it/s]\n",
      "Epoch: 6 | Train Loss: 0.2408242 Vali Loss: 0.2819801 Test Loss: 0.3457615 MAE Loss: 0.3642869\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:21,  5.08it/s]\titers: 100, epoch: 7 | loss: 0.3065282\n",
      "\tspeed: 0.7548s/iter; left time: 7280.0494s\n",
      "199it [00:41,  5.41it/s]\titers: 200, epoch: 7 | loss: 0.2147583\n",
      "\tspeed: 0.2064s/iter; left time: 1970.1588s\n",
      "299it [01:02,  4.82it/s]\titers: 300, epoch: 7 | loss: 0.2329259\n",
      "\tspeed: 0.2038s/iter; left time: 1924.4559s\n",
      "399it [01:22,  5.37it/s]\titers: 400, epoch: 7 | loss: 0.3092867\n",
      "\tspeed: 0.2074s/iter; left time: 1937.8268s\n",
      "499it [01:43,  5.20it/s]\titers: 500, epoch: 7 | loss: 0.2574410\n",
      "\tspeed: 0.2087s/iter; left time: 1929.2520s\n",
      "599it [02:04,  4.40it/s]\titers: 600, epoch: 7 | loss: 0.2927569\n",
      "\tspeed: 0.2082s/iter; left time: 1904.3041s\n",
      "696it [02:24,  4.80it/s]\n",
      "Epoch: 7 cost time: 144.85158729553223\n",
      "151it [00:16,  9.15it/s]\n",
      "151it [00:16,  9.22it/s]\n",
      "Epoch: 7 | Train Loss: 0.2396706 Vali Loss: 0.2817801 Test Loss: 0.3429151 MAE Loss: 0.3647488\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:21,  4.60it/s]\titers: 100, epoch: 8 | loss: 0.2271046\n",
      "\tspeed: 0.7605s/iter; left time: 6805.3300s\n",
      "199it [00:41,  5.02it/s]\titers: 200, epoch: 8 | loss: 0.1984335\n",
      "\tspeed: 0.2033s/iter; left time: 1799.0075s\n",
      "299it [01:02,  4.75it/s]\titers: 300, epoch: 8 | loss: 0.2522891\n",
      "\tspeed: 0.2107s/iter; left time: 1843.2423s\n",
      "399it [01:23,  4.49it/s]\titers: 400, epoch: 8 | loss: 0.2015206\n",
      "\tspeed: 0.2103s/iter; left time: 1819.0793s\n",
      "499it [01:44,  4.23it/s]\titers: 500, epoch: 8 | loss: 0.2734291\n",
      "\tspeed: 0.2123s/iter; left time: 1815.2700s\n",
      "599it [02:06,  5.02it/s]\titers: 600, epoch: 8 | loss: 0.2155892\n",
      "\tspeed: 0.2175s/iter; left time: 1837.6483s\n",
      "696it [02:27,  4.72it/s]\n",
      "Epoch: 8 cost time: 147.46773290634155\n",
      "151it [00:16,  9.18it/s]\n",
      "151it [00:16,  9.20it/s]\n",
      "Epoch: 8 | Train Loss: 0.2385794 Vali Loss: 0.2841937 Test Loss: 0.3460383 MAE Loss: 0.3670893\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [00:20,  4.19it/s]\titers: 100, epoch: 9 | loss: 0.2252072\n",
      "\tspeed: 0.7460s/iter; left time: 6156.6382s\n",
      "199it [00:41,  4.87it/s]\titers: 200, epoch: 9 | loss: 0.2629856\n",
      "\tspeed: 0.2120s/iter; left time: 1728.6730s\n",
      "299it [01:02,  5.06it/s]\titers: 300, epoch: 9 | loss: 0.2568341\n",
      "\tspeed: 0.2092s/iter; left time: 1684.8924s\n",
      "399it [01:23,  4.63it/s]\titers: 400, epoch: 9 | loss: 0.2852782\n",
      "\tspeed: 0.2089s/iter; left time: 1661.5259s\n",
      "499it [01:44,  4.59it/s]\titers: 500, epoch: 9 | loss: 0.1961140\n",
      "\tspeed: 0.2110s/iter; left time: 1656.9965s\n",
      "599it [02:05,  5.42it/s]\titers: 600, epoch: 9 | loss: 0.2798184\n",
      "\tspeed: 0.2064s/iter; left time: 1600.1996s\n",
      "696it [02:26,  4.76it/s]\n",
      "Epoch: 9 cost time: 146.26341891288757\n",
      "151it [00:16,  9.26it/s]\n",
      "151it [00:16,  9.12it/s]\n",
      "Epoch: 9 | Train Loss: 0.2384348 Vali Loss: 0.2829929 Test Loss: 0.3445210 MAE Loss: 0.3645996\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [00:20,  5.26it/s]\titers: 100, epoch: 10 | loss: 0.2438715\n",
      "\tspeed: 0.7459s/iter; left time: 5636.9263s\n",
      "199it [00:41,  4.62it/s]\titers: 200, epoch: 10 | loss: 0.1981618\n",
      "\tspeed: 0.2079s/iter; left time: 1550.4476s\n",
      "299it [01:02,  5.29it/s]\titers: 300, epoch: 10 | loss: 0.2348903\n",
      "\tspeed: 0.2073s/iter; left time: 1525.2577s\n",
      "399it [01:23,  4.59it/s]\titers: 400, epoch: 10 | loss: 0.1898185\n",
      "\tspeed: 0.2103s/iter; left time: 1526.2963s\n",
      "499it [01:44,  4.70it/s]\titers: 500, epoch: 10 | loss: 0.1664813\n",
      "\tspeed: 0.2105s/iter; left time: 1506.3856s\n",
      "599it [02:06,  4.99it/s]\titers: 600, epoch: 10 | loss: 0.2626489\n",
      "\tspeed: 0.2178s/iter; left time: 1537.0655s\n",
      "696it [02:27,  4.73it/s]\n",
      "Epoch: 10 cost time: 147.16022634506226\n",
      "151it [00:16,  9.27it/s]\n",
      "151it [00:16,  9.25it/s]\n",
      "Epoch: 10 | Train Loss: 0.2386682 Vali Loss: 0.2829155 Test Loss: 0.3436000 MAE Loss: 0.3635829\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 30.43413914044698 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=128\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 20:03:37,973] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 20:03:39,003] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 20:03:39,003] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 20:03:40,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 20:03:41,407] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 20:03:41,408] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 20:03:41,408] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 20:03:41,409] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 20:03:41,409] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 20:03:41,409] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 20:03:41,409] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 20:03:41,409] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 20:03:41,409] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 20:03:41,409] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 20:03:41,658] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 20:03:41,658] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 20:03:41,658] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 306.42 GB, percent = 40.6%\n",
      "[2024-05-07 20:03:41,785] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 20:03:41,786] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 20:03:41,786] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 306.74 GB, percent = 40.7%\n",
      "[2024-05-07 20:03:41,786] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 20:03:41,910] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 20:03:41,910] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 20:03:41,910] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 307.01 GB, percent = 40.7%\n",
      "[2024-05-07 20:03:41,911] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 20:03:41,911] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 20:03:41,911] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 20:03:41,911] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 20:03:41,911] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd293f84bd0>\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   train_batch_size ............. 128\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128\n",
      "[2024-05-07 20:03:41,912] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 20:03:41,913] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 128, \n",
      "    \"train_micro_batch_size_per_gpu\": 128, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:22,  4.61it/s]\titers: 100, epoch: 1 | loss: 0.5089871\n",
      "\tspeed: 0.2363s/iter; left time: 3265.3317s\n",
      "199it [00:44,  4.74it/s]\titers: 200, epoch: 1 | loss: 0.2775090\n",
      "\tspeed: 0.2156s/iter; left time: 2958.7147s\n",
      "299it [01:06,  4.92it/s]\titers: 300, epoch: 1 | loss: 0.3590579\n",
      "\tspeed: 0.2201s/iter; left time: 2998.1513s\n",
      "399it [01:27,  4.76it/s]\titers: 400, epoch: 1 | loss: 0.2895975\n",
      "\tspeed: 0.2151s/iter; left time: 2907.8774s\n",
      "499it [01:49,  3.73it/s]\titers: 500, epoch: 1 | loss: 0.2993958\n",
      "\tspeed: 0.2164s/iter; left time: 2903.6767s\n",
      "599it [02:11,  5.11it/s]\titers: 600, epoch: 1 | loss: 0.2859322\n",
      "\tspeed: 0.2260s/iter; left time: 3009.9080s\n",
      "696it [02:33,  4.55it/s]\n",
      "Epoch: 1 cost time: 153.03078365325928\n",
      "151it [00:19,  7.62it/s]\n",
      "151it [00:19,  7.78it/s]\n",
      "Epoch: 1 | Train Loss: 0.3591971 Vali Loss: 0.3131735 Test Loss: 0.3844208 MAE Loss: 0.4030330\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:19,  5.33it/s]\titers: 100, epoch: 2 | loss: 0.2870230\n",
      "\tspeed: 0.8177s/iter; left time: 10732.3224s\n",
      "199it [00:39,  5.71it/s]\titers: 200, epoch: 2 | loss: 0.3863401\n",
      "\tspeed: 0.1931s/iter; left time: 2515.2089s\n",
      "299it [00:59,  4.67it/s]\titers: 300, epoch: 2 | loss: 0.2559213\n",
      "\tspeed: 0.2023s/iter; left time: 2615.0883s\n",
      "399it [01:21,  5.13it/s]\titers: 400, epoch: 2 | loss: 0.3209968\n",
      "\tspeed: 0.2174s/iter; left time: 2788.4218s\n",
      "499it [01:42,  4.10it/s]\titers: 500, epoch: 2 | loss: 0.2062332\n",
      "\tspeed: 0.2128s/iter; left time: 2707.8766s\n",
      "599it [02:04,  5.37it/s]\titers: 600, epoch: 2 | loss: 0.2129133\n",
      "\tspeed: 0.2181s/iter; left time: 2753.8530s\n",
      "696it [02:25,  4.80it/s]\n",
      "Epoch: 2 cost time: 145.0032877922058\n",
      "151it [00:16,  9.12it/s]\n",
      "151it [00:16,  9.17it/s]\n",
      "Epoch: 2 | Train Loss: 0.2626779 Vali Loss: 0.2992348 Test Loss: 0.3542148 MAE Loss: 0.3739178\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:21,  4.26it/s]\titers: 100, epoch: 3 | loss: 0.2841502\n",
      "\tspeed: 0.7608s/iter; left time: 9456.3486s\n",
      "199it [00:42,  5.08it/s]\titers: 200, epoch: 3 | loss: 0.3034377\n",
      "\tspeed: 0.2117s/iter; left time: 2609.5349s\n",
      "299it [01:03,  5.36it/s]\titers: 300, epoch: 3 | loss: 0.2580580\n",
      "\tspeed: 0.2102s/iter; left time: 2570.0171s\n",
      "399it [01:24,  5.20it/s]\titers: 400, epoch: 3 | loss: 0.2632921\n",
      "\tspeed: 0.2128s/iter; left time: 2581.3445s\n",
      "499it [01:46,  4.68it/s]\titers: 500, epoch: 3 | loss: 0.2794692\n",
      "\tspeed: 0.2150s/iter; left time: 2586.7165s\n",
      "599it [02:07,  5.27it/s]\titers: 600, epoch: 3 | loss: 0.2568230\n",
      "\tspeed: 0.2108s/iter; left time: 2514.1534s\n",
      "696it [02:28,  4.69it/s]\n",
      "Epoch: 3 cost time: 148.50521063804626\n",
      "151it [00:16,  9.19it/s]\n",
      "151it [00:16,  9.07it/s]\n",
      "Epoch: 3 | Train Loss: 0.2507019 Vali Loss: 0.2897986 Test Loss: 0.3482069 MAE Loss: 0.3638271\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:21,  4.73it/s]\titers: 100, epoch: 4 | loss: 0.2440619\n",
      "\tspeed: 0.7790s/iter; left time: 9139.5357s\n",
      "199it [00:42,  5.38it/s]\titers: 200, epoch: 4 | loss: 0.2543245\n",
      "\tspeed: 0.2141s/iter; left time: 2490.8942s\n",
      "299it [01:03,  4.90it/s]\titers: 300, epoch: 4 | loss: 0.2354078\n",
      "\tspeed: 0.2115s/iter; left time: 2439.4379s\n",
      "399it [01:24,  5.34it/s]\titers: 400, epoch: 4 | loss: 0.3248844\n",
      "\tspeed: 0.2071s/iter; left time: 2368.0300s\n",
      "499it [01:45,  4.40it/s]\titers: 500, epoch: 4 | loss: 0.3028212\n",
      "\tspeed: 0.2114s/iter; left time: 2395.7607s\n",
      "599it [02:07,  3.88it/s]\titers: 600, epoch: 4 | loss: 0.2362802\n",
      "\tspeed: 0.2196s/iter; left time: 2466.7725s\n",
      "696it [02:28,  4.68it/s]\n",
      "Epoch: 4 cost time: 148.8654203414917\n",
      "151it [00:16,  9.18it/s]\n",
      "151it [00:16,  9.25it/s]\n",
      "Epoch: 4 | Train Loss: 0.2445876 Vali Loss: 0.2895375 Test Loss: 0.3475404 MAE Loss: 0.3779169\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:21,  3.97it/s]\titers: 100, epoch: 5 | loss: 0.2174860\n",
      "\tspeed: 0.7708s/iter; left time: 8507.3093s\n",
      "199it [00:42,  5.01it/s]\titers: 200, epoch: 5 | loss: 0.2938947\n",
      "\tspeed: 0.2102s/iter; left time: 2298.9466s\n",
      "299it [01:04,  3.86it/s]\titers: 300, epoch: 5 | loss: 0.2703697\n",
      "\tspeed: 0.2186s/iter; left time: 2369.3897s\n",
      "399it [01:26,  4.64it/s]\titers: 400, epoch: 5 | loss: 0.2847760\n",
      "\tspeed: 0.2178s/iter; left time: 2338.1037s\n",
      "499it [01:47,  5.31it/s]\titers: 500, epoch: 5 | loss: 0.2154768\n",
      "\tspeed: 0.2101s/iter; left time: 2235.0491s\n",
      "599it [02:08,  4.44it/s]\titers: 600, epoch: 5 | loss: 0.1930077\n",
      "\tspeed: 0.2115s/iter; left time: 2228.7650s\n",
      "696it [02:29,  4.67it/s]\n",
      "Epoch: 5 cost time: 149.10001587867737\n",
      "151it [00:16,  9.03it/s]\n",
      "151it [00:16,  9.28it/s]\n",
      "Epoch: 5 | Train Loss: 0.2423693 Vali Loss: 0.2835751 Test Loss: 0.3452735 MAE Loss: 0.3625991\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:21,  4.35it/s]\titers: 100, epoch: 6 | loss: 0.2555818\n",
      "\tspeed: 0.7611s/iter; left time: 7870.1761s\n",
      "199it [00:43,  3.88it/s]\titers: 200, epoch: 6 | loss: 0.2079971\n",
      "\tspeed: 0.2203s/iter; left time: 2256.4397s\n",
      "299it [01:04,  5.23it/s]\titers: 300, epoch: 6 | loss: 0.3408970\n",
      "\tspeed: 0.2123s/iter; left time: 2152.7774s\n",
      "399it [01:26,  4.97it/s]\titers: 400, epoch: 6 | loss: 0.2746707\n",
      "\tspeed: 0.2189s/iter; left time: 2197.7512s\n",
      "499it [01:48,  4.01it/s]\titers: 500, epoch: 6 | loss: 0.1933526\n",
      "\tspeed: 0.2152s/iter; left time: 2138.9265s\n",
      "599it [02:09,  4.46it/s]\titers: 600, epoch: 6 | loss: 0.2592312\n",
      "\tspeed: 0.2141s/iter; left time: 2107.1429s\n",
      "696it [02:30,  4.62it/s]\n",
      "Epoch: 6 cost time: 150.774405002594\n",
      "151it [00:16,  9.25it/s]\n",
      "151it [00:16,  9.30it/s]\n",
      "Epoch: 6 | Train Loss: 0.2408242 Vali Loss: 0.2819801 Test Loss: 0.3457615 MAE Loss: 0.3642869\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:21,  4.37it/s]\titers: 100, epoch: 7 | loss: 0.3065282\n",
      "\tspeed: 0.7674s/iter; left time: 7401.9347s\n",
      "199it [00:43,  4.99it/s]\titers: 200, epoch: 7 | loss: 0.2147583\n",
      "\tspeed: 0.2174s/iter; left time: 2075.1564s\n",
      "299it [01:06,  4.92it/s]\titers: 300, epoch: 7 | loss: 0.2329259\n",
      "\tspeed: 0.2260s/iter; left time: 2134.1247s\n",
      "399it [01:27,  4.01it/s]\titers: 400, epoch: 7 | loss: 0.3092867\n",
      "\tspeed: 0.2110s/iter; left time: 1972.1557s\n",
      "499it [01:50,  4.45it/s]\titers: 500, epoch: 7 | loss: 0.2574410\n",
      "\tspeed: 0.2270s/iter; left time: 2098.6490s\n",
      "599it [02:11,  5.66it/s]\titers: 600, epoch: 7 | loss: 0.2927569\n",
      "\tspeed: 0.2135s/iter; left time: 1952.6247s\n",
      "696it [02:28,  4.67it/s]\n",
      "Epoch: 7 cost time: 148.8965437412262\n",
      "151it [00:16,  9.21it/s]\n",
      "151it [00:16,  9.19it/s]\n",
      "Epoch: 7 | Train Loss: 0.2396706 Vali Loss: 0.2817801 Test Loss: 0.3429151 MAE Loss: 0.3647488\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:17,  5.66it/s]\titers: 100, epoch: 8 | loss: 0.2271046\n",
      "\tspeed: 0.6929s/iter; left time: 6200.9184s\n",
      "199it [00:36,  4.56it/s]\titers: 200, epoch: 8 | loss: 0.1984335\n",
      "\tspeed: 0.1895s/iter; left time: 1676.8565s\n",
      "299it [00:59,  3.28it/s]\titers: 300, epoch: 8 | loss: 0.2522891\n",
      "\tspeed: 0.2257s/iter; left time: 1975.0561s\n",
      "399it [01:21,  5.37it/s]\titers: 400, epoch: 8 | loss: 0.2015206\n",
      "\tspeed: 0.2212s/iter; left time: 1913.5171s\n",
      "499it [01:43,  3.74it/s]\titers: 500, epoch: 8 | loss: 0.2734291\n",
      "\tspeed: 0.2247s/iter; left time: 1921.1734s\n",
      "599it [02:06,  5.28it/s]\titers: 600, epoch: 8 | loss: 0.2155892\n",
      "\tspeed: 0.2297s/iter; left time: 1940.5095s\n",
      "696it [02:28,  4.68it/s]\n",
      "Epoch: 8 cost time: 148.8003008365631\n",
      "151it [00:16,  9.00it/s]\n",
      "151it [00:16,  8.90it/s]\n",
      "Epoch: 8 | Train Loss: 0.2385794 Vali Loss: 0.2841937 Test Loss: 0.3460383 MAE Loss: 0.3670893\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [00:22,  5.22it/s]\titers: 100, epoch: 9 | loss: 0.2252072\n",
      "\tspeed: 0.7876s/iter; left time: 6499.9167s\n",
      "199it [00:45,  4.62it/s]\titers: 200, epoch: 9 | loss: 0.2629856\n",
      "\tspeed: 0.2286s/iter; left time: 1863.7391s\n",
      "299it [01:08,  3.87it/s]\titers: 300, epoch: 9 | loss: 0.2568341\n",
      "\tspeed: 0.2310s/iter; left time: 1860.4139s\n",
      "399it [01:31,  4.43it/s]\titers: 400, epoch: 9 | loss: 0.2852782\n",
      "\tspeed: 0.2226s/iter; left time: 1770.3188s\n",
      "499it [01:52,  4.06it/s]\titers: 500, epoch: 9 | loss: 0.1961140\n",
      "\tspeed: 0.2176s/iter; left time: 1708.8260s\n",
      "599it [02:14,  5.31it/s]\titers: 600, epoch: 9 | loss: 0.2798184\n",
      "\tspeed: 0.2154s/iter; left time: 1669.6776s\n",
      "696it [02:36,  4.46it/s]\n",
      "Epoch: 9 cost time: 156.0769488811493\n",
      "151it [00:16,  8.89it/s]\n",
      "151it [00:17,  8.47it/s]\n",
      "Epoch: 9 | Train Loss: 0.2384348 Vali Loss: 0.2829929 Test Loss: 0.3445210 MAE Loss: 0.3645996\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [00:23,  3.28it/s]\titers: 100, epoch: 10 | loss: 0.2438715\n",
      "\tspeed: 0.7976s/iter; left time: 6027.1611s\n",
      "199it [00:45,  4.83it/s]\titers: 200, epoch: 10 | loss: 0.1981618\n",
      "\tspeed: 0.2221s/iter; left time: 1656.0405s\n",
      "299it [01:07,  4.09it/s]\titers: 300, epoch: 10 | loss: 0.2348903\n",
      "\tspeed: 0.2192s/iter; left time: 1612.3524s\n",
      "399it [01:29,  4.74it/s]\titers: 400, epoch: 10 | loss: 0.1898185\n",
      "\tspeed: 0.2251s/iter; left time: 1633.7351s\n",
      "499it [01:51,  4.74it/s]\titers: 500, epoch: 10 | loss: 0.1664813\n",
      "\tspeed: 0.2174s/iter; left time: 1556.2284s\n",
      "599it [02:14,  4.66it/s]\titers: 600, epoch: 10 | loss: 0.2626489\n",
      "\tspeed: 0.2304s/iter; left time: 1626.2116s\n",
      "696it [02:36,  4.44it/s]\n",
      "Epoch: 10 cost time: 156.5961582660675\n",
      "151it [00:17,  8.88it/s]\n",
      "151it [00:17,  8.83it/s]\n",
      "Epoch: 10 | Train Loss: 0.2386682 Vali Loss: 0.2829155 Test Loss: 0.3436000 MAE Loss: 0.3635829\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 31.271412134170532 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=128\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 02:50:38,738] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 02:50:39,666] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 02:50:39,666] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 02:50:41,997] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 02:50:42,588] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 02:50:42,589] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 02:50:42,589] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 02:50:42,590] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 02:50:42,590] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 02:50:42,590] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 02:50:42,590] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 02:50:42,590] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 02:50:42,590] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 02:50:42,590] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 02:50:43,163] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 02:50:43,164] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:50:43,164] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.93 GB, percent = 20.3%\n",
      "[2024-05-07 02:50:43,280] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 02:50:43,280] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:50:43,281] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.93 GB, percent = 20.3%\n",
      "[2024-05-07 02:50:43,281] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 02:50:43,417] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 02:50:43,418] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-07 02:50:43,418] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.92 GB, percent = 20.3%\n",
      "[2024-05-07 02:50:43,419] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 02:50:43,419] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 02:50:43,419] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 02:50:43,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 02:50:43,419] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f91fcc0ce50>\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 02:50:43,420] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   train_batch_size ............. 16\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  16\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 02:50:43,421] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 16, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:05, 22.10it/s]\titers: 100, epoch: 1 | loss: 0.4640228\n",
      "\tspeed: 0.0728s/iter; left time: 8098.2035s\n",
      "198it [00:10, 21.25it/s]\titers: 200, epoch: 1 | loss: 0.3895122\n",
      "\tspeed: 0.0459s/iter; left time: 5097.9657s\n",
      "297it [00:15, 20.77it/s]\titers: 300, epoch: 1 | loss: 0.2119239\n",
      "\tspeed: 0.0480s/iter; left time: 5328.9927s\n",
      "398it [00:20, 21.58it/s]\titers: 400, epoch: 1 | loss: 0.1853268\n",
      "\tspeed: 0.0523s/iter; left time: 5806.5403s\n",
      "497it [00:25, 20.82it/s]\titers: 500, epoch: 1 | loss: 0.6048411\n",
      "\tspeed: 0.0471s/iter; left time: 5227.8905s\n",
      "599it [00:29, 20.89it/s]\titers: 600, epoch: 1 | loss: 0.1580903\n",
      "\tspeed: 0.0475s/iter; left time: 5257.0116s\n",
      "698it [00:34, 20.77it/s]\titers: 700, epoch: 1 | loss: 0.3699072\n",
      "\tspeed: 0.0479s/iter; left time: 5302.9541s\n",
      "799it [00:39, 20.64it/s]\titers: 800, epoch: 1 | loss: 0.2591982\n",
      "\tspeed: 0.0484s/iter; left time: 5348.2418s\n",
      "898it [00:43, 21.55it/s]\titers: 900, epoch: 1 | loss: 0.2759808\n",
      "\tspeed: 0.0434s/iter; left time: 4793.8701s\n",
      "997it [00:48, 20.86it/s]\titers: 1000, epoch: 1 | loss: 0.3709054\n",
      "\tspeed: 0.0474s/iter; left time: 5226.9379s\n",
      "1099it [00:53, 22.86it/s]\titers: 1100, epoch: 1 | loss: 0.2579150\n",
      "\tspeed: 0.0470s/iter; left time: 5186.9656s\n",
      "1199it [00:58, 21.64it/s]\titers: 1200, epoch: 1 | loss: 0.4067648\n",
      "\tspeed: 0.0499s/iter; left time: 5501.6408s\n",
      "1298it [01:02, 21.72it/s]\titers: 1300, epoch: 1 | loss: 0.2608645\n",
      "\tspeed: 0.0435s/iter; left time: 4789.2394s\n",
      "1398it [01:07, 20.89it/s]\titers: 1400, epoch: 1 | loss: 0.2932175\n",
      "\tspeed: 0.0487s/iter; left time: 5361.0270s\n",
      "1497it [01:12, 21.04it/s]\titers: 1500, epoch: 1 | loss: 0.2310580\n",
      "\tspeed: 0.0474s/iter; left time: 5204.1159s\n",
      "1597it [01:17, 21.52it/s]\titers: 1600, epoch: 1 | loss: 0.3739561\n",
      "\tspeed: 0.0511s/iter; left time: 5608.4244s\n",
      "1699it [01:22, 20.02it/s]\titers: 1700, epoch: 1 | loss: 0.1748407\n",
      "\tspeed: 0.0464s/iter; left time: 5093.6278s\n",
      "1797it [01:26, 21.30it/s]\titers: 1800, epoch: 1 | loss: 0.1693369\n",
      "\tspeed: 0.0473s/iter; left time: 5182.5969s\n",
      "1899it [01:31, 21.38it/s]\titers: 1900, epoch: 1 | loss: 0.4926152\n",
      "\tspeed: 0.0469s/iter; left time: 5129.4437s\n",
      "1998it [01:36, 21.65it/s]\titers: 2000, epoch: 1 | loss: 0.3330681\n",
      "\tspeed: 0.0501s/iter; left time: 5482.0553s\n",
      "2097it [01:41, 21.30it/s]\titers: 2100, epoch: 1 | loss: 0.2021187\n",
      "\tspeed: 0.0468s/iter; left time: 5118.3406s\n",
      "2199it [01:45, 21.17it/s]\titers: 2200, epoch: 1 | loss: 0.3498833\n",
      "\tspeed: 0.0471s/iter; left time: 5137.9567s\n",
      "2299it [01:50, 21.03it/s]\titers: 2300, epoch: 1 | loss: 0.2974980\n",
      "\tspeed: 0.0502s/iter; left time: 5477.8531s\n",
      "2398it [01:55, 21.74it/s]\titers: 2400, epoch: 1 | loss: 0.3143662\n",
      "\tspeed: 0.0514s/iter; left time: 5602.2513s\n",
      "2498it [02:00, 20.98it/s]\titers: 2500, epoch: 1 | loss: 0.5284200\n",
      "\tspeed: 0.0480s/iter; left time: 5228.5952s\n",
      "2597it [02:05, 21.36it/s]\titers: 2600, epoch: 1 | loss: 0.2638915\n",
      "\tspeed: 0.0468s/iter; left time: 5089.4243s\n",
      "2699it [02:10, 21.48it/s]\titers: 2700, epoch: 1 | loss: 0.2055815\n",
      "\tspeed: 0.0467s/iter; left time: 5079.4320s\n",
      "2797it [02:15, 21.66it/s]\titers: 2800, epoch: 1 | loss: 0.2358500\n",
      "\tspeed: 0.0514s/iter; left time: 5580.5152s\n",
      "2899it [02:19, 21.54it/s]\titers: 2900, epoch: 1 | loss: 0.1415800\n",
      "\tspeed: 0.0466s/iter; left time: 5058.5072s\n",
      "2998it [02:24, 21.46it/s]\titers: 3000, epoch: 1 | loss: 0.3261589\n",
      "\tspeed: 0.0464s/iter; left time: 5028.3121s\n",
      "3097it [02:28, 21.55it/s]\titers: 3100, epoch: 1 | loss: 0.1467273\n",
      "\tspeed: 0.0448s/iter; left time: 4853.8609s\n",
      "3197it [02:33, 20.88it/s]\titers: 3200, epoch: 1 | loss: 0.2421476\n",
      "\tspeed: 0.0486s/iter; left time: 5256.3332s\n",
      "3299it [02:38, 21.62it/s]\titers: 3300, epoch: 1 | loss: 0.1484015\n",
      "\tspeed: 0.0466s/iter; left time: 5035.0523s\n",
      "3398it [02:43, 21.46it/s]\titers: 3400, epoch: 1 | loss: 0.1746576\n",
      "\tspeed: 0.0465s/iter; left time: 5020.0369s\n",
      "3499it [02:48, 17.91it/s]\titers: 3500, epoch: 1 | loss: 0.5137304\n",
      "\tspeed: 0.0488s/iter; left time: 5269.5673s\n",
      "3598it [02:52, 21.79it/s]\titers: 3600, epoch: 1 | loss: 0.4960748\n",
      "\tspeed: 0.0469s/iter; left time: 5054.3287s\n",
      "3697it [02:57, 21.29it/s]\titers: 3700, epoch: 1 | loss: 0.2748311\n",
      "\tspeed: 0.0465s/iter; left time: 5003.6340s\n",
      "3799it [03:01, 22.83it/s]\titers: 3800, epoch: 1 | loss: 0.3574205\n",
      "\tspeed: 0.0453s/iter; left time: 4877.0133s\n",
      "3898it [03:06, 16.52it/s]\titers: 3900, epoch: 1 | loss: 0.1325430\n",
      "\tspeed: 0.0486s/iter; left time: 5225.2790s\n",
      "3999it [03:12, 21.62it/s]\titers: 4000, epoch: 1 | loss: 0.1276695\n",
      "\tspeed: 0.0533s/iter; left time: 5719.6020s\n",
      "4099it [03:17, 19.72it/s]\titers: 4100, epoch: 1 | loss: 0.2816359\n",
      "\tspeed: 0.0508s/iter; left time: 5448.8685s\n",
      "4197it [03:21, 21.43it/s]\titers: 4200, epoch: 1 | loss: 0.1050589\n",
      "\tspeed: 0.0470s/iter; left time: 5042.6873s\n",
      "4299it [03:26, 20.00it/s]\titers: 4300, epoch: 1 | loss: 0.3350677\n",
      "\tspeed: 0.0452s/iter; left time: 4836.1740s\n",
      "4399it [03:31, 21.82it/s]\titers: 4400, epoch: 1 | loss: 0.1728681\n",
      "\tspeed: 0.0493s/iter; left time: 5276.7640s\n",
      "4498it [03:35, 21.66it/s]\titers: 4500, epoch: 1 | loss: 0.1671835\n",
      "\tspeed: 0.0463s/iter; left time: 4950.3648s\n",
      "4597it [03:40, 23.66it/s]\titers: 4600, epoch: 1 | loss: 0.1628848\n",
      "\tspeed: 0.0450s/iter; left time: 4804.2618s\n",
      "4699it [03:45, 19.21it/s]\titers: 4700, epoch: 1 | loss: 0.2538822\n",
      "\tspeed: 0.0476s/iter; left time: 5081.8158s\n",
      "4798it [03:50, 22.87it/s]\titers: 4800, epoch: 1 | loss: 0.3638191\n",
      "\tspeed: 0.0496s/iter; left time: 5283.6654s\n",
      "4897it [03:54, 21.05it/s]\titers: 4900, epoch: 1 | loss: 0.2842970\n",
      "\tspeed: 0.0461s/iter; left time: 4908.2282s\n",
      "4999it [03:59, 20.65it/s]\titers: 5000, epoch: 1 | loss: 0.4253926\n",
      "\tspeed: 0.0469s/iter; left time: 4993.3557s\n",
      "5098it [04:04, 20.73it/s]\titers: 5100, epoch: 1 | loss: 0.1859242\n",
      "\tspeed: 0.0477s/iter; left time: 5066.8055s\n",
      "5198it [04:09, 25.49it/s]\titers: 5200, epoch: 1 | loss: 0.1259896\n",
      "\tspeed: 0.0490s/iter; left time: 5201.2808s\n",
      "5297it [04:13, 21.80it/s]\titers: 5300, epoch: 1 | loss: 0.3395597\n",
      "\tspeed: 0.0437s/iter; left time: 4631.3123s\n",
      "5399it [04:18, 21.83it/s]\titers: 5400, epoch: 1 | loss: 0.5036479\n",
      "\tspeed: 0.0467s/iter; left time: 4951.4894s\n",
      "5498it [04:22, 22.34it/s]\titers: 5500, epoch: 1 | loss: 0.3224979\n",
      "\tspeed: 0.0459s/iter; left time: 4854.9726s\n",
      "5569it [04:26, 20.93it/s]\n",
      "Epoch: 1 cost time: 266.0716588497162\n",
      "1215it [00:25, 47.27it/s]\n",
      "1210it [00:25, 46.70it/s]\n",
      "Epoch: 1 | Train Loss: 0.2883092 Vali Loss: 0.3196120 Test Loss: 0.3952762 MAE Loss: 0.4039942\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:04, 23.10it/s]\titers: 100, epoch: 2 | loss: 0.2929907\n",
      "\tspeed: 0.6189s/iter; left time: 65420.5945s\n",
      "199it [00:09, 22.92it/s]\titers: 200, epoch: 2 | loss: 0.2731037\n",
      "\tspeed: 0.0434s/iter; left time: 4586.5088s\n",
      "298it [00:13, 21.78it/s]\titers: 300, epoch: 2 | loss: 0.1551319\n",
      "\tspeed: 0.0445s/iter; left time: 4694.0665s\n",
      "397it [00:18, 22.79it/s]\titers: 400, epoch: 2 | loss: 0.2019835\n",
      "\tspeed: 0.0442s/iter; left time: 4657.1547s\n",
      "497it [00:22, 21.00it/s]\titers: 500, epoch: 2 | loss: 0.1305725\n",
      "\tspeed: 0.0458s/iter; left time: 4818.3186s\n",
      "599it [00:27, 21.95it/s]\titers: 600, epoch: 2 | loss: 0.4677656\n",
      "\tspeed: 0.0444s/iter; left time: 4667.2170s\n",
      "698it [00:31, 23.23it/s]\titers: 700, epoch: 2 | loss: 0.1308829\n",
      "\tspeed: 0.0439s/iter; left time: 4618.0407s\n",
      "797it [00:36, 20.94it/s]\titers: 800, epoch: 2 | loss: 0.3055653\n",
      "\tspeed: 0.0456s/iter; left time: 4789.9084s\n",
      "899it [00:40, 20.80it/s]\titers: 900, epoch: 2 | loss: 0.4042915\n",
      "\tspeed: 0.0460s/iter; left time: 4829.1501s\n",
      "998it [00:45, 22.93it/s]\titers: 1000, epoch: 2 | loss: 0.2650278\n",
      "\tspeed: 0.0471s/iter; left time: 4931.8106s\n",
      "1097it [00:49, 23.55it/s]\titers: 1100, epoch: 2 | loss: 0.4418144\n",
      "\tspeed: 0.0413s/iter; left time: 4326.5280s\n",
      "1199it [00:53, 22.57it/s]\titers: 1200, epoch: 2 | loss: 0.2410091\n",
      "\tspeed: 0.0444s/iter; left time: 4640.9414s\n",
      "1298it [00:58, 22.13it/s]\titers: 1300, epoch: 2 | loss: 0.3886764\n",
      "\tspeed: 0.0449s/iter; left time: 4693.3563s\n",
      "1397it [01:02, 24.22it/s]\titers: 1400, epoch: 2 | loss: 0.1648963\n",
      "\tspeed: 0.0443s/iter; left time: 4623.2481s\n",
      "1499it [01:07, 22.92it/s]\titers: 1500, epoch: 2 | loss: 0.2138817\n",
      "\tspeed: 0.0437s/iter; left time: 4563.6488s\n",
      "1598it [01:11, 22.66it/s]\titers: 1600, epoch: 2 | loss: 0.4434977\n",
      "\tspeed: 0.0441s/iter; left time: 4598.6471s\n",
      "1698it [01:16, 22.34it/s]\titers: 1700, epoch: 2 | loss: 0.1838997\n",
      "\tspeed: 0.0435s/iter; left time: 4530.1108s\n",
      "1798it [01:20, 18.36it/s]\titers: 1800, epoch: 2 | loss: 0.3365076\n",
      "\tspeed: 0.0455s/iter; left time: 4729.6515s\n",
      "1898it [01:25, 22.97it/s]\titers: 1900, epoch: 2 | loss: 0.2909105\n",
      "\tspeed: 0.0447s/iter; left time: 4647.6776s\n",
      "1999it [01:29, 21.96it/s]\titers: 2000, epoch: 2 | loss: 0.2555481\n",
      "\tspeed: 0.0438s/iter; left time: 4548.0592s\n",
      "2098it [01:33, 22.54it/s]\titers: 2100, epoch: 2 | loss: 0.1857077\n",
      "\tspeed: 0.0448s/iter; left time: 4646.1760s\n",
      "2197it [01:38, 22.28it/s]\titers: 2200, epoch: 2 | loss: 0.3774820\n",
      "\tspeed: 0.0449s/iter; left time: 4649.3071s\n",
      "2298it [01:42, 24.89it/s]\titers: 2300, epoch: 2 | loss: 0.1615517\n",
      "\tspeed: 0.0459s/iter; left time: 4752.4890s\n",
      "2397it [01:47, 22.38it/s]\titers: 2400, epoch: 2 | loss: 0.3376251\n",
      "\tspeed: 0.0430s/iter; left time: 4446.5530s\n",
      "2497it [01:52, 20.97it/s]\titers: 2500, epoch: 2 | loss: 0.2213862\n",
      "\tspeed: 0.0483s/iter; left time: 4986.9297s\n",
      "2599it [01:56, 22.12it/s]\titers: 2600, epoch: 2 | loss: 0.3588010\n",
      "\tspeed: 0.0459s/iter; left time: 4733.0242s\n",
      "2697it [02:01, 22.39it/s]\titers: 2700, epoch: 2 | loss: 0.4581910\n",
      "\tspeed: 0.0453s/iter; left time: 4674.8581s\n",
      "2798it [02:05, 23.81it/s]\titers: 2800, epoch: 2 | loss: 0.1076813\n",
      "\tspeed: 0.0437s/iter; left time: 4506.0566s\n",
      "2898it [02:09, 25.49it/s]\titers: 2900, epoch: 2 | loss: 0.2276736\n",
      "\tspeed: 0.0434s/iter; left time: 4463.2212s\n",
      "2997it [02:14, 22.70it/s]\titers: 3000, epoch: 2 | loss: 0.4535929\n",
      "\tspeed: 0.0415s/iter; left time: 4267.6453s\n",
      "3099it [02:18, 19.44it/s]\titers: 3100, epoch: 2 | loss: 0.2621855\n",
      "\tspeed: 0.0457s/iter; left time: 4694.1602s\n",
      "3199it [02:23, 22.26it/s]\titers: 3200, epoch: 2 | loss: 0.4062025\n",
      "\tspeed: 0.0455s/iter; left time: 4670.0758s\n",
      "3298it [02:27, 23.01it/s]\titers: 3300, epoch: 2 | loss: 0.2240495\n",
      "\tspeed: 0.0432s/iter; left time: 4430.8175s\n",
      "3398it [02:31, 22.65it/s]\titers: 3400, epoch: 2 | loss: 0.2781274\n",
      "\tspeed: 0.0434s/iter; left time: 4445.0377s\n",
      "3497it [02:36, 22.38it/s]\titers: 3500, epoch: 2 | loss: 0.1517460\n",
      "\tspeed: 0.0447s/iter; left time: 4576.5663s\n",
      "3599it [02:41, 22.34it/s]\titers: 3600, epoch: 2 | loss: 0.2795445\n",
      "\tspeed: 0.0466s/iter; left time: 4760.5958s\n",
      "3698it [02:45, 22.71it/s]\titers: 3700, epoch: 2 | loss: 0.2607090\n",
      "\tspeed: 0.0442s/iter; left time: 4518.2023s\n",
      "3797it [02:49, 22.38it/s]\titers: 3800, epoch: 2 | loss: 0.5770710\n",
      "\tspeed: 0.0437s/iter; left time: 4453.6439s\n",
      "3899it [02:54, 23.38it/s]\titers: 3900, epoch: 2 | loss: 0.2153377\n",
      "\tspeed: 0.0449s/iter; left time: 4572.1471s\n",
      "3998it [02:58, 23.42it/s]\titers: 4000, epoch: 2 | loss: 0.1472694\n",
      "\tspeed: 0.0441s/iter; left time: 4486.3546s\n",
      "4097it [03:02, 24.68it/s]\titers: 4100, epoch: 2 | loss: 0.2462316\n",
      "\tspeed: 0.0436s/iter; left time: 4437.4134s\n",
      "4199it [03:07, 23.57it/s]\titers: 4200, epoch: 2 | loss: 0.2588490\n",
      "\tspeed: 0.0428s/iter; left time: 4347.4058s\n",
      "4298it [03:11, 22.89it/s]\titers: 4300, epoch: 2 | loss: 0.3262249\n",
      "\tspeed: 0.0449s/iter; left time: 4558.1381s\n",
      "4398it [03:16, 22.99it/s]\titers: 4400, epoch: 2 | loss: 0.2916642\n",
      "\tspeed: 0.0421s/iter; left time: 4269.2240s\n",
      "4497it [03:20, 22.92it/s]\titers: 4500, epoch: 2 | loss: 0.2070520\n",
      "\tspeed: 0.0453s/iter; left time: 4586.7638s\n",
      "4599it [03:25, 21.78it/s]\titers: 4600, epoch: 2 | loss: 0.3181069\n",
      "\tspeed: 0.0445s/iter; left time: 4501.7734s\n",
      "4698it [03:29, 22.11it/s]\titers: 4700, epoch: 2 | loss: 0.1869451\n",
      "\tspeed: 0.0445s/iter; left time: 4504.3062s\n",
      "4797it [03:33, 24.09it/s]\titers: 4800, epoch: 2 | loss: 0.1669098\n",
      "\tspeed: 0.0434s/iter; left time: 4383.4865s\n",
      "4898it [03:38, 23.12it/s]\titers: 4900, epoch: 2 | loss: 0.2244294\n",
      "\tspeed: 0.0468s/iter; left time: 4718.2920s\n",
      "4997it [03:42, 23.66it/s]\titers: 5000, epoch: 2 | loss: 0.1979356\n",
      "\tspeed: 0.0434s/iter; left time: 4378.2891s\n",
      "5099it [03:47, 22.90it/s]\titers: 5100, epoch: 2 | loss: 0.2357883\n",
      "\tspeed: 0.0440s/iter; left time: 4426.4012s\n",
      "5198it [03:51, 23.24it/s]\titers: 5200, epoch: 2 | loss: 0.1534695\n",
      "\tspeed: 0.0433s/iter; left time: 4360.1596s\n",
      "5299it [03:56, 22.66it/s]\titers: 5300, epoch: 2 | loss: 0.1747609\n",
      "\tspeed: 0.0482s/iter; left time: 4847.3410s\n",
      "5398it [04:00, 21.95it/s]\titers: 5400, epoch: 2 | loss: 0.2202682\n",
      "\tspeed: 0.0438s/iter; left time: 4400.1955s\n",
      "5497it [04:05, 22.97it/s]\titers: 5500, epoch: 2 | loss: 0.1544333\n",
      "\tspeed: 0.0446s/iter; left time: 4473.3644s\n",
      "5569it [04:08, 22.42it/s]\n",
      "Epoch: 2 cost time: 248.38623929023743\n",
      "1215it [00:22, 53.29it/s]\n",
      "1210it [00:23, 52.33it/s]\n",
      "Epoch: 2 | Train Loss: 0.2515607 Vali Loss: 0.2963539 Test Loss: 0.3589380 MAE Loss: 0.3671424\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "97it [00:04, 20.96it/s]\titers: 100, epoch: 3 | loss: 0.1589714\n",
      "\tspeed: 0.5696s/iter; left time: 57042.4929s\n",
      "199it [00:09, 22.81it/s]\titers: 200, epoch: 3 | loss: 0.3907443\n",
      "\tspeed: 0.0439s/iter; left time: 4389.5672s\n",
      "299it [00:13, 17.91it/s]\titers: 300, epoch: 3 | loss: 0.1490990\n",
      "\tspeed: 0.0464s/iter; left time: 4638.2848s\n",
      "398it [00:18, 22.75it/s]\titers: 400, epoch: 3 | loss: 0.2241326\n",
      "\tspeed: 0.0437s/iter; left time: 4367.9099s\n",
      "497it [00:22, 22.95it/s]\titers: 500, epoch: 3 | loss: 0.1301522\n",
      "\tspeed: 0.0432s/iter; left time: 4308.2357s\n",
      "597it [00:26, 22.98it/s]\titers: 600, epoch: 3 | loss: 0.4145180\n",
      "\tspeed: 0.0430s/iter; left time: 4283.8443s\n",
      "699it [00:31, 22.02it/s]\titers: 700, epoch: 3 | loss: 0.5878633\n",
      "\tspeed: 0.0439s/iter; left time: 4373.4702s\n",
      "798it [00:35, 22.31it/s]\titers: 800, epoch: 3 | loss: 0.5536679\n",
      "\tspeed: 0.0460s/iter; left time: 4577.2337s\n",
      "897it [00:40, 22.90it/s]\titers: 900, epoch: 3 | loss: 0.2602861\n",
      "\tspeed: 0.0437s/iter; left time: 4341.2236s\n",
      "999it [00:44, 23.16it/s]\titers: 1000, epoch: 3 | loss: 0.2301973\n",
      "\tspeed: 0.0455s/iter; left time: 4518.1710s\n",
      "1097it [00:48, 26.51it/s]\titers: 1100, epoch: 3 | loss: 0.2163446\n",
      "\tspeed: 0.0429s/iter; left time: 4249.4683s\n",
      "1198it [00:53, 22.96it/s]\titers: 1200, epoch: 3 | loss: 0.2052290\n",
      "\tspeed: 0.0446s/iter; left time: 4421.0965s\n",
      "1297it [00:57, 23.05it/s]\titers: 1300, epoch: 3 | loss: 0.2586745\n",
      "\tspeed: 0.0436s/iter; left time: 4315.0892s\n",
      "1399it [01:02, 24.48it/s]\titers: 1400, epoch: 3 | loss: 0.2532375\n",
      "\tspeed: 0.0434s/iter; left time: 4288.0538s\n",
      "1498it [01:06, 22.48it/s]\titers: 1500, epoch: 3 | loss: 0.1332084\n",
      "\tspeed: 0.0439s/iter; left time: 4332.3289s\n",
      "1597it [01:10, 21.66it/s]\titers: 1600, epoch: 3 | loss: 0.3732828\n",
      "\tspeed: 0.0449s/iter; left time: 4427.4743s\n",
      "1699it [01:15, 23.23it/s]\titers: 1700, epoch: 3 | loss: 0.3018057\n",
      "\tspeed: 0.0435s/iter; left time: 4284.6617s\n",
      "1798it [01:19, 23.03it/s]\titers: 1800, epoch: 3 | loss: 0.1469958\n",
      "\tspeed: 0.0435s/iter; left time: 4278.0748s\n",
      "1897it [01:24, 23.25it/s]\titers: 1900, epoch: 3 | loss: 0.3944418\n",
      "\tspeed: 0.0439s/iter; left time: 4312.9136s\n",
      "1998it [01:28, 18.55it/s]\titers: 2000, epoch: 3 | loss: 0.2977020\n",
      "\tspeed: 0.0462s/iter; left time: 4535.7377s\n",
      "2098it [01:33, 23.68it/s]\titers: 2100, epoch: 3 | loss: 0.2496956\n",
      "\tspeed: 0.0434s/iter; left time: 4263.2707s\n",
      "2197it [01:37, 22.50it/s]\titers: 2200, epoch: 3 | loss: 0.3040985\n",
      "\tspeed: 0.0436s/iter; left time: 4273.6506s\n",
      "2297it [01:41, 22.90it/s]\titers: 2300, epoch: 3 | loss: 0.2890674\n",
      "\tspeed: 0.0458s/iter; left time: 4485.4442s\n",
      "2397it [01:46, 21.47it/s]\titers: 2400, epoch: 3 | loss: 0.2212038\n",
      "\tspeed: 0.0477s/iter; left time: 4666.3730s\n",
      "2499it [01:51, 21.12it/s]\titers: 2500, epoch: 3 | loss: 0.2126463\n",
      "\tspeed: 0.0470s/iter; left time: 4589.0792s\n",
      "2598it [01:55, 22.20it/s]\titers: 2600, epoch: 3 | loss: 0.2855602\n",
      "\tspeed: 0.0456s/iter; left time: 4456.4334s\n",
      "2699it [02:00, 22.02it/s]\titers: 2700, epoch: 3 | loss: 0.1803435\n",
      "\tspeed: 0.0480s/iter; left time: 4678.5758s\n",
      "2798it [02:05, 22.28it/s]\titers: 2800, epoch: 3 | loss: 0.2652529\n",
      "\tspeed: 0.0451s/iter; left time: 4390.2171s\n",
      "2899it [02:10, 22.87it/s]\titers: 2900, epoch: 3 | loss: 0.2021844\n",
      "\tspeed: 0.0474s/iter; left time: 4615.3479s\n",
      "2998it [02:14, 22.59it/s]\titers: 3000, epoch: 3 | loss: 0.4252892\n",
      "\tspeed: 0.0429s/iter; left time: 4173.0784s\n",
      "3097it [02:18, 22.95it/s]\titers: 3100, epoch: 3 | loss: 0.1637453\n",
      "\tspeed: 0.0430s/iter; left time: 4177.3678s\n",
      "3199it [02:23, 22.58it/s]\titers: 3200, epoch: 3 | loss: 0.3820504\n",
      "\tspeed: 0.0438s/iter; left time: 4247.1594s\n",
      "3297it [02:27, 23.21it/s]\titers: 3300, epoch: 3 | loss: 0.1985346\n",
      "\tspeed: 0.0469s/iter; left time: 4548.6228s\n",
      "3399it [02:32, 23.39it/s]\titers: 3400, epoch: 3 | loss: 0.1845516\n",
      "\tspeed: 0.0442s/iter; left time: 4280.5064s\n",
      "3498it [02:36, 22.83it/s]\titers: 3500, epoch: 3 | loss: 0.4447735\n",
      "\tspeed: 0.0441s/iter; left time: 4263.7586s\n",
      "3597it [02:40, 23.98it/s]\titers: 3600, epoch: 3 | loss: 0.5830618\n",
      "\tspeed: 0.0439s/iter; left time: 4238.5462s\n",
      "3697it [02:45, 25.48it/s]\titers: 3700, epoch: 3 | loss: 0.2817661\n",
      "\tspeed: 0.0451s/iter; left time: 4357.9993s\n",
      "3799it [02:49, 23.21it/s]\titers: 3800, epoch: 3 | loss: 0.4496366\n",
      "\tspeed: 0.0427s/iter; left time: 4121.8381s\n",
      "3898it [02:54, 25.25it/s]\titers: 3900, epoch: 3 | loss: 0.4081948\n",
      "\tspeed: 0.0432s/iter; left time: 4161.5986s\n",
      "3997it [02:58, 23.30it/s]\titers: 4000, epoch: 3 | loss: 0.1815780\n",
      "\tspeed: 0.0428s/iter; left time: 4123.2315s\n",
      "4099it [03:02, 22.88it/s]\titers: 4100, epoch: 3 | loss: 0.2015270\n",
      "\tspeed: 0.0437s/iter; left time: 4203.7758s\n",
      "4198it [03:07, 23.15it/s]\titers: 4200, epoch: 3 | loss: 0.1572601\n",
      "\tspeed: 0.0434s/iter; left time: 4165.2497s\n",
      "4297it [03:11, 22.52it/s]\titers: 4300, epoch: 3 | loss: 0.2993488\n",
      "\tspeed: 0.0439s/iter; left time: 4210.8957s\n",
      "4399it [03:15, 21.49it/s]\titers: 4400, epoch: 3 | loss: 0.2803695\n",
      "\tspeed: 0.0450s/iter; left time: 4315.2678s\n",
      "4498it [03:20, 21.78it/s]\titers: 4500, epoch: 3 | loss: 0.1155906\n",
      "\tspeed: 0.0450s/iter; left time: 4308.4387s\n",
      "4597it [03:24, 20.24it/s]\titers: 4600, epoch: 3 | loss: 0.2339757\n",
      "\tspeed: 0.0456s/iter; left time: 4366.0380s\n",
      "4699it [03:29, 22.60it/s]\titers: 4700, epoch: 3 | loss: 0.1953004\n",
      "\tspeed: 0.0439s/iter; left time: 4191.7767s\n",
      "4798it [03:33, 23.29it/s]\titers: 4800, epoch: 3 | loss: 0.3707686\n",
      "\tspeed: 0.0427s/iter; left time: 4075.7804s\n",
      "4897it [03:37, 22.55it/s]\titers: 4900, epoch: 3 | loss: 0.0955852\n",
      "\tspeed: 0.0441s/iter; left time: 4202.2689s\n",
      "4999it [03:42, 23.16it/s]\titers: 5000, epoch: 3 | loss: 0.1558964\n",
      "\tspeed: 0.0450s/iter; left time: 4286.5774s\n",
      "5098it [03:46, 23.41it/s]\titers: 5100, epoch: 3 | loss: 0.1638742\n",
      "\tspeed: 0.0443s/iter; left time: 4215.8272s\n",
      "5198it [03:51, 28.62it/s]\titers: 5200, epoch: 3 | loss: 0.3144034\n",
      "\tspeed: 0.0425s/iter; left time: 4035.9194s\n",
      "5298it [03:55, 23.77it/s]\titers: 5300, epoch: 3 | loss: 0.3830726\n",
      "\tspeed: 0.0431s/iter; left time: 4092.9107s\n",
      "5397it [03:59, 20.00it/s]\titers: 5400, epoch: 3 | loss: 0.4186058\n",
      "\tspeed: 0.0446s/iter; left time: 4230.4352s\n",
      "5499it [04:04, 22.35it/s]\titers: 5500, epoch: 3 | loss: 0.3028476\n",
      "\tspeed: 0.0445s/iter; left time: 4217.9443s\n",
      "5569it [04:07, 22.49it/s]\n",
      "Epoch: 3 cost time: 247.60035729408264\n",
      "1215it [00:22, 53.23it/s]\n",
      "1210it [00:23, 52.27it/s]\n",
      "Epoch: 3 | Train Loss: 0.2362607 Vali Loss: 0.2800609 Test Loss: 0.3453749 MAE Loss: 0.3587281\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "97it [00:04, 22.78it/s]\titers: 100, epoch: 4 | loss: 0.1435079\n",
      "\tspeed: 0.5607s/iter; left time: 53031.0927s\n",
      "199it [00:09, 23.98it/s]\titers: 200, epoch: 4 | loss: 0.1821009\n",
      "\tspeed: 0.0414s/iter; left time: 3911.7674s\n",
      "298it [00:13, 22.86it/s]\titers: 300, epoch: 4 | loss: 0.0956856\n",
      "\tspeed: 0.0442s/iter; left time: 4167.7486s\n",
      "397it [00:17, 22.55it/s]\titers: 400, epoch: 4 | loss: 0.3949292\n",
      "\tspeed: 0.0442s/iter; left time: 4166.9992s\n",
      "497it [00:22, 22.15it/s]\titers: 500, epoch: 4 | loss: 0.2589200\n",
      "\tspeed: 0.0437s/iter; left time: 4114.3129s\n",
      "599it [00:26, 21.45it/s]\titers: 600, epoch: 4 | loss: 0.3460396\n",
      "\tspeed: 0.0444s/iter; left time: 4178.3404s\n",
      "698it [00:31, 20.55it/s]\titers: 700, epoch: 4 | loss: 0.3924566\n",
      "\tspeed: 0.0457s/iter; left time: 4296.1579s\n",
      "797it [00:35, 25.45it/s]\titers: 800, epoch: 4 | loss: 0.2428441\n",
      "\tspeed: 0.0417s/iter; left time: 3912.7746s\n",
      "898it [00:39, 23.01it/s]\titers: 900, epoch: 4 | loss: 0.1523906\n",
      "\tspeed: 0.0389s/iter; left time: 3651.9240s\n",
      "999it [00:44, 23.21it/s]\titers: 1000, epoch: 4 | loss: 0.2377011\n",
      "\tspeed: 0.0471s/iter; left time: 4413.9005s\n",
      "1098it [00:48, 22.98it/s]\titers: 1100, epoch: 4 | loss: 0.2690270\n",
      "\tspeed: 0.0435s/iter; left time: 4071.4711s\n",
      "1197it [00:52, 22.80it/s]\titers: 1200, epoch: 4 | loss: 0.3016870\n",
      "\tspeed: 0.0431s/iter; left time: 4024.6804s\n",
      "1299it [00:57, 20.67it/s]\titers: 1300, epoch: 4 | loss: 0.1404258\n",
      "\tspeed: 0.0444s/iter; left time: 4141.6705s\n",
      "1399it [01:02, 22.99it/s]\titers: 1400, epoch: 4 | loss: 0.2328763\n",
      "\tspeed: 0.0480s/iter; left time: 4478.3270s\n",
      "1498it [01:06, 22.69it/s]\titers: 1500, epoch: 4 | loss: 0.2280584\n",
      "\tspeed: 0.0442s/iter; left time: 4115.2715s\n",
      "1597it [01:10, 22.87it/s]\titers: 1600, epoch: 4 | loss: 0.2060982\n",
      "\tspeed: 0.0450s/iter; left time: 4192.7455s\n",
      "1699it [01:15, 22.76it/s]\titers: 1700, epoch: 4 | loss: 0.2654159\n",
      "\tspeed: 0.0442s/iter; left time: 4111.6223s\n",
      "1799it [01:20, 21.31it/s]\titers: 1800, epoch: 4 | loss: 0.3307393\n",
      "\tspeed: 0.0483s/iter; left time: 4482.9612s\n",
      "1898it [01:24, 22.94it/s]\titers: 1900, epoch: 4 | loss: 0.1774644\n",
      "\tspeed: 0.0437s/iter; left time: 4049.7479s\n",
      "1997it [01:28, 22.83it/s]\titers: 2000, epoch: 4 | loss: 0.2857103\n",
      "\tspeed: 0.0439s/iter; left time: 4066.8213s\n",
      "2096it [01:33, 23.00it/s]\titers: 2100, epoch: 4 | loss: 0.3544426\n",
      "\tspeed: 0.0437s/iter; left time: 4049.1193s\n",
      "2198it [01:37, 22.09it/s]\titers: 2200, epoch: 4 | loss: 0.1305403\n",
      "\tspeed: 0.0441s/iter; left time: 4082.3556s\n",
      "2297it [01:41, 23.03it/s]\titers: 2300, epoch: 4 | loss: 0.2613513\n",
      "\tspeed: 0.0431s/iter; left time: 3983.2129s\n",
      "2399it [01:46, 23.06it/s]\titers: 2400, epoch: 4 | loss: 0.2397124\n",
      "\tspeed: 0.0437s/iter; left time: 4033.0757s\n",
      "2498it [01:50, 25.27it/s]\titers: 2500, epoch: 4 | loss: 0.1704367\n",
      "\tspeed: 0.0416s/iter; left time: 3830.2630s\n",
      "2597it [01:54, 22.86it/s]\titers: 2600, epoch: 4 | loss: 0.1534580\n",
      "\tspeed: 0.0415s/iter; left time: 3817.0734s\n",
      "2698it [01:59, 23.12it/s]\titers: 2700, epoch: 4 | loss: 0.1157241\n",
      "\tspeed: 0.0461s/iter; left time: 4235.9047s\n",
      "2797it [02:03, 20.48it/s]\titers: 2800, epoch: 4 | loss: 0.2934614\n",
      "\tspeed: 0.0466s/iter; left time: 4280.1636s\n",
      "2899it [02:08, 20.75it/s]\titers: 2900, epoch: 4 | loss: 0.2267350\n",
      "\tspeed: 0.0476s/iter; left time: 4364.6824s\n",
      "2998it [02:13, 22.68it/s]\titers: 3000, epoch: 4 | loss: 0.1143957\n",
      "\tspeed: 0.0454s/iter; left time: 4160.3496s\n",
      "3097it [02:17, 22.68it/s]\titers: 3100, epoch: 4 | loss: 0.1678500\n",
      "\tspeed: 0.0463s/iter; left time: 4243.4774s\n",
      "3199it [02:22, 22.56it/s]\titers: 3200, epoch: 4 | loss: 0.2379598\n",
      "\tspeed: 0.0444s/iter; left time: 4057.7641s\n",
      "3298it [02:26, 20.61it/s]\titers: 3300, epoch: 4 | loss: 0.1460187\n",
      "\tspeed: 0.0450s/iter; left time: 4116.3524s\n",
      "3397it [02:31, 22.26it/s]\titers: 3400, epoch: 4 | loss: 0.1227094\n",
      "\tspeed: 0.0472s/iter; left time: 4309.6492s\n",
      "3499it [02:36, 16.26it/s]\titers: 3500, epoch: 4 | loss: 0.1135184\n",
      "\tspeed: 0.0495s/iter; left time: 4515.3653s\n",
      "3598it [02:40, 22.56it/s]\titers: 3600, epoch: 4 | loss: 0.1767642\n",
      "\tspeed: 0.0442s/iter; left time: 4025.2008s\n",
      "3697it [02:45, 23.03it/s]\titers: 3700, epoch: 4 | loss: 0.2689063\n",
      "\tspeed: 0.0431s/iter; left time: 3917.9510s\n",
      "3799it [02:49, 23.15it/s]\titers: 3800, epoch: 4 | loss: 0.1686668\n",
      "\tspeed: 0.0440s/iter; left time: 3995.8354s\n",
      "3898it [02:54, 22.34it/s]\titers: 3900, epoch: 4 | loss: 0.2182539\n",
      "\tspeed: 0.0451s/iter; left time: 4094.0918s\n",
      "3998it [02:58, 20.10it/s]\titers: 4000, epoch: 4 | loss: 0.2110508\n",
      "\tspeed: 0.0466s/iter; left time: 4222.5252s\n",
      "4099it [03:03, 19.97it/s]\titers: 4100, epoch: 4 | loss: 0.1463311\n",
      "\tspeed: 0.0479s/iter; left time: 4339.7801s\n",
      "4197it [03:08, 24.25it/s]\titers: 4200, epoch: 4 | loss: 0.2487208\n",
      "\tspeed: 0.0458s/iter; left time: 4141.1927s\n",
      "4299it [03:12, 22.00it/s]\titers: 4300, epoch: 4 | loss: 0.1318168\n",
      "\tspeed: 0.0452s/iter; left time: 4085.9214s\n",
      "4397it [03:17, 22.09it/s]\titers: 4400, epoch: 4 | loss: 0.1550433\n",
      "\tspeed: 0.0480s/iter; left time: 4330.7971s\n",
      "4499it [03:22, 22.17it/s]\titers: 4500, epoch: 4 | loss: 0.1822099\n",
      "\tspeed: 0.0454s/iter; left time: 4095.8541s\n",
      "4598it [03:26, 22.67it/s]\titers: 4600, epoch: 4 | loss: 0.0921284\n",
      "\tspeed: 0.0447s/iter; left time: 4022.3091s\n",
      "4697it [03:30, 22.45it/s]\titers: 4700, epoch: 4 | loss: 0.2784167\n",
      "\tspeed: 0.0437s/iter; left time: 3932.9060s\n",
      "4799it [03:35, 21.94it/s]\titers: 4800, epoch: 4 | loss: 0.1387221\n",
      "\tspeed: 0.0464s/iter; left time: 4173.1988s\n",
      "4898it [03:39, 22.83it/s]\titers: 4900, epoch: 4 | loss: 0.1338070\n",
      "\tspeed: 0.0440s/iter; left time: 3946.7860s\n",
      "4998it [03:44, 23.96it/s]\titers: 5000, epoch: 4 | loss: 0.1776586\n",
      "\tspeed: 0.0424s/iter; left time: 3806.5436s\n",
      "5098it [03:48, 22.93it/s]\titers: 5100, epoch: 4 | loss: 0.4774237\n",
      "\tspeed: 0.0428s/iter; left time: 3837.4913s\n",
      "5197it [03:52, 20.80it/s]\titers: 5200, epoch: 4 | loss: 0.2077049\n",
      "\tspeed: 0.0447s/iter; left time: 3998.9931s\n",
      "5299it [03:57, 22.67it/s]\titers: 5300, epoch: 4 | loss: 0.3271281\n",
      "\tspeed: 0.0430s/iter; left time: 3840.3163s\n",
      "5399it [04:01, 23.17it/s]\titers: 5400, epoch: 4 | loss: 0.2926713\n",
      "\tspeed: 0.0455s/iter; left time: 4060.5222s\n",
      "5498it [04:06, 22.08it/s]\titers: 5500, epoch: 4 | loss: 0.1966766\n",
      "\tspeed: 0.0452s/iter; left time: 4033.6732s\n",
      "5569it [04:09, 22.33it/s]\n",
      "Epoch: 4 cost time: 249.43177318572998\n",
      "1215it [00:23, 52.68it/s]\n",
      "1210it [00:22, 53.59it/s]\n",
      "Epoch: 4 | Train Loss: 0.2266556 Vali Loss: 0.2750657 Test Loss: 0.3401952 MAE Loss: 0.3541265\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:04, 22.00it/s]\titers: 100, epoch: 5 | loss: 0.1001077\n",
      "\tspeed: 0.5538s/iter; left time: 49288.9701s\n",
      "198it [00:09, 22.65it/s]\titers: 200, epoch: 5 | loss: 0.0934598\n",
      "\tspeed: 0.0439s/iter; left time: 3900.5797s\n",
      "299it [00:13, 19.83it/s]\titers: 300, epoch: 5 | loss: 0.1784621\n",
      "\tspeed: 0.0460s/iter; left time: 4088.8425s\n",
      "398it [00:18, 22.89it/s]\titers: 400, epoch: 5 | loss: 0.0876804\n",
      "\tspeed: 0.0442s/iter; left time: 3916.7288s\n",
      "497it [00:22, 23.12it/s]\titers: 500, epoch: 5 | loss: 0.4314702\n",
      "\tspeed: 0.0444s/iter; left time: 3938.4913s\n",
      "599it [00:26, 23.25it/s]\titers: 600, epoch: 5 | loss: 0.2537716\n",
      "\tspeed: 0.0444s/iter; left time: 3930.6083s\n",
      "698it [00:31, 21.82it/s]\titers: 700, epoch: 5 | loss: 0.2568684\n",
      "\tspeed: 0.0448s/iter; left time: 3960.1433s\n",
      "799it [00:35, 26.36it/s]\titers: 800, epoch: 5 | loss: 0.3552506\n",
      "\tspeed: 0.0419s/iter; left time: 3699.5837s\n",
      "899it [00:39, 24.89it/s]\titers: 900, epoch: 5 | loss: 0.4283354\n",
      "\tspeed: 0.0348s/iter; left time: 3065.3100s\n",
      "998it [00:43, 23.78it/s]\titers: 1000, epoch: 5 | loss: 0.2036508\n",
      "\tspeed: 0.0430s/iter; left time: 3787.7039s\n",
      "1097it [00:47, 22.83it/s]\titers: 1100, epoch: 5 | loss: 0.1292213\n",
      "\tspeed: 0.0442s/iter; left time: 3888.4251s\n",
      "1199it [00:52, 20.20it/s]\titers: 1200, epoch: 5 | loss: 0.2045536\n",
      "\tspeed: 0.0447s/iter; left time: 3925.1189s\n",
      "1298it [00:56, 21.51it/s]\titers: 1300, epoch: 5 | loss: 0.2818192\n",
      "\tspeed: 0.0453s/iter; left time: 3981.2953s\n",
      "1397it [01:01, 22.60it/s]\titers: 1400, epoch: 5 | loss: 0.0802321\n",
      "\tspeed: 0.0456s/iter; left time: 4001.7972s\n",
      "1499it [01:05, 22.73it/s]\titers: 1500, epoch: 5 | loss: 0.3334651\n",
      "\tspeed: 0.0442s/iter; left time: 3871.1546s\n",
      "1598it [01:10, 22.60it/s]\titers: 1600, epoch: 5 | loss: 0.1346885\n",
      "\tspeed: 0.0449s/iter; left time: 3928.3570s\n",
      "1699it [01:14, 24.25it/s]\titers: 1700, epoch: 5 | loss: 0.2080003\n",
      "\tspeed: 0.0423s/iter; left time: 3693.4561s\n",
      "1798it [01:19, 21.08it/s]\titers: 1800, epoch: 5 | loss: 0.3508993\n",
      "\tspeed: 0.0463s/iter; left time: 4046.4319s\n",
      "1897it [01:23, 21.15it/s]\titers: 1900, epoch: 5 | loss: 0.2184114\n",
      "\tspeed: 0.0465s/iter; left time: 4054.5078s\n",
      "1999it [01:28, 21.55it/s]\titers: 2000, epoch: 5 | loss: 0.1183965\n",
      "\tspeed: 0.0450s/iter; left time: 3918.8536s\n",
      "2098it [01:33, 19.51it/s]\titers: 2100, epoch: 5 | loss: 0.2543345\n",
      "\tspeed: 0.0480s/iter; left time: 4177.8144s\n",
      "2197it [01:37, 22.10it/s]\titers: 2200, epoch: 5 | loss: 0.4359419\n",
      "\tspeed: 0.0444s/iter; left time: 3860.5235s\n",
      "2299it [01:42, 23.36it/s]\titers: 2300, epoch: 5 | loss: 0.1474369\n",
      "\tspeed: 0.0446s/iter; left time: 3873.6858s\n",
      "2398it [01:46, 24.12it/s]\titers: 2400, epoch: 5 | loss: 0.2060412\n",
      "\tspeed: 0.0412s/iter; left time: 3575.8069s\n",
      "2497it [01:50, 23.24it/s]\titers: 2500, epoch: 5 | loss: 0.1575324\n",
      "\tspeed: 0.0438s/iter; left time: 3797.4461s\n",
      "2599it [01:55, 21.56it/s]\titers: 2600, epoch: 5 | loss: 0.2088712\n",
      "\tspeed: 0.0455s/iter; left time: 3936.5399s\n",
      "2698it [01:59, 21.65it/s]\titers: 2700, epoch: 5 | loss: 0.1508362\n",
      "\tspeed: 0.0438s/iter; left time: 3787.9466s\n",
      "2797it [02:03, 22.85it/s]\titers: 2800, epoch: 5 | loss: 0.2452481\n",
      "\tspeed: 0.0454s/iter; left time: 3918.5106s\n",
      "2899it [02:08, 26.35it/s]\titers: 2900, epoch: 5 | loss: 0.2412814\n",
      "\tspeed: 0.0440s/iter; left time: 3788.7856s\n",
      "2998it [02:12, 22.16it/s]\titers: 3000, epoch: 5 | loss: 0.3373100\n",
      "\tspeed: 0.0448s/iter; left time: 3859.8238s\n",
      "3099it [02:17, 23.05it/s]\titers: 3100, epoch: 5 | loss: 0.1683078\n",
      "\tspeed: 0.0479s/iter; left time: 4121.4210s\n",
      "3198it [02:22, 21.14it/s]\titers: 3200, epoch: 5 | loss: 0.3415336\n",
      "\tspeed: 0.0445s/iter; left time: 3824.3852s\n",
      "3297it [02:26, 23.05it/s]\titers: 3300, epoch: 5 | loss: 0.2520479\n",
      "\tspeed: 0.0450s/iter; left time: 3864.2983s\n",
      "3399it [02:31, 22.39it/s]\titers: 3400, epoch: 5 | loss: 0.1065566\n",
      "\tspeed: 0.0449s/iter; left time: 3844.6548s\n",
      "3498it [02:35, 21.46it/s]\titers: 3500, epoch: 5 | loss: 0.4766877\n",
      "\tspeed: 0.0453s/iter; left time: 3877.5885s\n",
      "3599it [02:40, 23.15it/s]\titers: 3600, epoch: 5 | loss: 0.3603278\n",
      "\tspeed: 0.0482s/iter; left time: 4123.3433s\n",
      "3699it [02:44, 23.27it/s]\titers: 3700, epoch: 5 | loss: 0.3176454\n",
      "\tspeed: 0.0426s/iter; left time: 3636.0001s\n",
      "3798it [02:49, 21.93it/s]\titers: 3800, epoch: 5 | loss: 0.2514902\n",
      "\tspeed: 0.0448s/iter; left time: 3818.3501s\n",
      "3897it [02:53, 22.21it/s]\titers: 3900, epoch: 5 | loss: 0.2817028\n",
      "\tspeed: 0.0444s/iter; left time: 3781.5917s\n",
      "3998it [02:58, 22.86it/s]\titers: 4000, epoch: 5 | loss: 0.1905456\n",
      "\tspeed: 0.0505s/iter; left time: 4294.3910s\n",
      "4099it [03:02, 22.81it/s]\titers: 4100, epoch: 5 | loss: 0.2800602\n",
      "\tspeed: 0.0427s/iter; left time: 3625.6115s\n",
      "4198it [03:07, 21.91it/s]\titers: 4200, epoch: 5 | loss: 0.1424052\n",
      "\tspeed: 0.0438s/iter; left time: 3717.8067s\n",
      "4297it [03:11, 22.82it/s]\titers: 4300, epoch: 5 | loss: 0.2686920\n",
      "\tspeed: 0.0440s/iter; left time: 3728.4388s\n",
      "4398it [03:16, 22.16it/s]\titers: 4400, epoch: 5 | loss: 0.3230411\n",
      "\tspeed: 0.0486s/iter; left time: 4117.4109s\n",
      "4499it [03:20, 22.97it/s]\titers: 4500, epoch: 5 | loss: 0.1117826\n",
      "\tspeed: 0.0435s/iter; left time: 3679.1116s\n",
      "4598it [03:25, 22.44it/s]\titers: 4600, epoch: 5 | loss: 0.1735208\n",
      "\tspeed: 0.0439s/iter; left time: 3708.7183s\n",
      "4699it [03:30, 21.83it/s]\titers: 4700, epoch: 5 | loss: 0.1531664\n",
      "\tspeed: 0.0473s/iter; left time: 3996.1058s\n",
      "4799it [03:34, 20.66it/s]\titers: 4800, epoch: 5 | loss: 0.2198039\n",
      "\tspeed: 0.0485s/iter; left time: 4092.0512s\n",
      "4898it [03:39, 22.66it/s]\titers: 4900, epoch: 5 | loss: 0.2447141\n",
      "\tspeed: 0.0450s/iter; left time: 3786.1062s\n",
      "4997it [03:43, 22.01it/s]\titers: 5000, epoch: 5 | loss: 0.3541823\n",
      "\tspeed: 0.0461s/iter; left time: 3874.9430s\n",
      "5099it [03:48, 22.78it/s]\titers: 5100, epoch: 5 | loss: 0.1422275\n",
      "\tspeed: 0.0448s/iter; left time: 3766.8735s\n",
      "5198it [03:53, 22.27it/s]\titers: 5200, epoch: 5 | loss: 0.2910119\n",
      "\tspeed: 0.0464s/iter; left time: 3894.4552s\n",
      "5297it [03:57, 23.29it/s]\titers: 5300, epoch: 5 | loss: 0.2148215\n",
      "\tspeed: 0.0432s/iter; left time: 3623.1457s\n",
      "5398it [04:01, 24.00it/s]\titers: 5400, epoch: 5 | loss: 0.4485242\n",
      "\tspeed: 0.0413s/iter; left time: 3457.5878s\n",
      "5497it [04:05, 23.10it/s]\titers: 5500, epoch: 5 | loss: 0.2019572\n",
      "\tspeed: 0.0436s/iter; left time: 3644.7340s\n",
      "5569it [04:09, 22.36it/s]\n",
      "Epoch: 5 cost time: 249.11209082603455\n",
      "1215it [00:23, 52.36it/s]\n",
      "1210it [00:22, 53.63it/s]\n",
      "Epoch: 5 | Train Loss: 0.2219607 Vali Loss: 0.2740866 Test Loss: 0.3377681 MAE Loss: 0.3502523\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "97it [00:04, 22.99it/s]\titers: 100, epoch: 6 | loss: 0.3815301\n",
      "\tspeed: 0.5607s/iter; left time: 46781.4303s\n",
      "199it [00:09, 18.88it/s]\titers: 200, epoch: 6 | loss: 0.1804386\n",
      "\tspeed: 0.0448s/iter; left time: 3737.2400s\n",
      "298it [00:13, 22.78it/s]\titers: 300, epoch: 6 | loss: 0.2887501\n",
      "\tspeed: 0.0460s/iter; left time: 3827.9929s\n",
      "397it [00:18, 22.11it/s]\titers: 400, epoch: 6 | loss: 0.1206325\n",
      "\tspeed: 0.0449s/iter; left time: 3730.5514s\n",
      "499it [00:22, 20.68it/s]\titers: 500, epoch: 6 | loss: 0.2301950\n",
      "\tspeed: 0.0451s/iter; left time: 3743.4823s\n",
      "598it [00:27, 23.36it/s]\titers: 600, epoch: 6 | loss: 0.1543923\n",
      "\tspeed: 0.0430s/iter; left time: 3564.0557s\n",
      "699it [00:31, 23.64it/s]\titers: 700, epoch: 6 | loss: 0.1641994\n",
      "\tspeed: 0.0456s/iter; left time: 3779.1502s\n",
      "798it [00:36, 22.69it/s]\titers: 800, epoch: 6 | loss: 0.1167125\n",
      "\tspeed: 0.0438s/iter; left time: 3627.5428s\n",
      "897it [00:40, 21.92it/s]\titers: 900, epoch: 6 | loss: 0.2703745\n",
      "\tspeed: 0.0439s/iter; left time: 3629.6066s\n",
      "999it [00:45, 21.58it/s]\titers: 1000, epoch: 6 | loss: 0.1242225\n",
      "\tspeed: 0.0453s/iter; left time: 3735.9556s\n",
      "1099it [00:49, 23.11it/s]\titers: 1100, epoch: 6 | loss: 0.2561055\n",
      "\tspeed: 0.0476s/iter; left time: 3927.4304s\n",
      "1198it [00:54, 22.88it/s]\titers: 1200, epoch: 6 | loss: 0.2465091\n",
      "\tspeed: 0.0436s/iter; left time: 3589.5609s\n",
      "1297it [00:58, 23.01it/s]\titers: 1300, epoch: 6 | loss: 0.3823775\n",
      "\tspeed: 0.0439s/iter; left time: 3608.9394s\n",
      "1397it [01:02, 22.51it/s]\titers: 1400, epoch: 6 | loss: 0.1718348\n",
      "\tspeed: 0.0428s/iter; left time: 3513.8933s\n",
      "1499it [01:07, 22.75it/s]\titers: 1500, epoch: 6 | loss: 0.3280811\n",
      "\tspeed: 0.0422s/iter; left time: 3460.9327s\n",
      "1598it [01:11, 21.97it/s]\titers: 1600, epoch: 6 | loss: 0.1332120\n",
      "\tspeed: 0.0438s/iter; left time: 3584.8934s\n",
      "1697it [01:15, 23.28it/s]\titers: 1700, epoch: 6 | loss: 0.2457435\n",
      "\tspeed: 0.0435s/iter; left time: 3559.6794s\n",
      "1799it [01:20, 21.97it/s]\titers: 1800, epoch: 6 | loss: 0.1821045\n",
      "\tspeed: 0.0439s/iter; left time: 3591.8823s\n",
      "1899it [01:24, 22.27it/s]\titers: 1900, epoch: 6 | loss: 0.0839293\n",
      "\tspeed: 0.0464s/iter; left time: 3790.4982s\n",
      "1998it [01:29, 22.68it/s]\titers: 2000, epoch: 6 | loss: 0.2861444\n",
      "\tspeed: 0.0435s/iter; left time: 3546.3855s\n",
      "2097it [01:33, 20.41it/s]\titers: 2100, epoch: 6 | loss: 0.3183901\n",
      "\tspeed: 0.0456s/iter; left time: 3712.3123s\n",
      "2199it [01:38, 21.59it/s]\titers: 2200, epoch: 6 | loss: 0.1599838\n",
      "\tspeed: 0.0443s/iter; left time: 3606.5856s\n",
      "2298it [01:42, 22.71it/s]\titers: 2300, epoch: 6 | loss: 0.3159854\n",
      "\tspeed: 0.0444s/iter; left time: 3606.3220s\n",
      "2398it [01:47, 22.75it/s]\titers: 2400, epoch: 6 | loss: 0.1469861\n",
      "\tspeed: 0.0463s/iter; left time: 3759.3341s\n",
      "2497it [01:51, 22.52it/s]\titers: 2500, epoch: 6 | loss: 0.1695774\n",
      "\tspeed: 0.0449s/iter; left time: 3639.0481s\n",
      "2599it [01:56, 23.12it/s]\titers: 2600, epoch: 6 | loss: 0.2129727\n",
      "\tspeed: 0.0435s/iter; left time: 3524.4817s\n",
      "2698it [02:00, 23.16it/s]\titers: 2700, epoch: 6 | loss: 0.3060529\n",
      "\tspeed: 0.0434s/iter; left time: 3505.8031s\n",
      "2799it [02:04, 23.49it/s]\titers: 2800, epoch: 6 | loss: 0.1716938\n",
      "\tspeed: 0.0430s/iter; left time: 3474.7859s\n",
      "2898it [02:09, 23.12it/s]\titers: 2900, epoch: 6 | loss: 0.1882775\n",
      "\tspeed: 0.0438s/iter; left time: 3529.0973s\n",
      "2997it [02:13, 25.50it/s]\titers: 3000, epoch: 6 | loss: 0.2350046\n",
      "\tspeed: 0.0415s/iter; left time: 3341.4758s\n",
      "3099it [02:17, 23.59it/s]\titers: 3100, epoch: 6 | loss: 0.2081704\n",
      "\tspeed: 0.0419s/iter; left time: 3373.4149s\n",
      "3197it [02:22, 21.48it/s]\titers: 3200, epoch: 6 | loss: 0.3154490\n",
      "\tspeed: 0.0470s/iter; left time: 3774.6599s\n",
      "3299it [02:26, 22.14it/s]\titers: 3300, epoch: 6 | loss: 0.1352761\n",
      "\tspeed: 0.0449s/iter; left time: 3604.6768s\n",
      "3398it [02:30, 23.85it/s]\titers: 3400, epoch: 6 | loss: 0.1064849\n",
      "\tspeed: 0.0418s/iter; left time: 3352.8855s\n",
      "3497it [02:35, 22.86it/s]\titers: 3500, epoch: 6 | loss: 0.3077194\n",
      "\tspeed: 0.0447s/iter; left time: 3581.3060s\n",
      "3599it [02:39, 21.07it/s]\titers: 3600, epoch: 6 | loss: 0.1395978\n",
      "\tspeed: 0.0455s/iter; left time: 3637.3344s\n",
      "3698it [02:43, 26.55it/s]\titers: 3700, epoch: 6 | loss: 0.1492867\n",
      "\tspeed: 0.0403s/iter; left time: 3213.6669s\n",
      "3797it [02:47, 23.75it/s]\titers: 3800, epoch: 6 | loss: 0.1533311\n",
      "\tspeed: 0.0408s/iter; left time: 3251.7001s\n",
      "3899it [02:52, 21.17it/s]\titers: 3900, epoch: 6 | loss: 0.3036847\n",
      "\tspeed: 0.0459s/iter; left time: 3658.5694s\n",
      "3998it [02:56, 22.29it/s]\titers: 4000, epoch: 6 | loss: 0.1374898\n",
      "\tspeed: 0.0421s/iter; left time: 3351.9787s\n",
      "4099it [03:01, 22.16it/s]\titers: 4100, epoch: 6 | loss: 0.2637557\n",
      "\tspeed: 0.0480s/iter; left time: 3816.0516s\n",
      "4198it [03:05, 23.16it/s]\titers: 4200, epoch: 6 | loss: 0.1130424\n",
      "\tspeed: 0.0446s/iter; left time: 3536.5422s\n",
      "4297it [03:10, 22.88it/s]\titers: 4300, epoch: 6 | loss: 0.3741280\n",
      "\tspeed: 0.0438s/iter; left time: 3472.9722s\n",
      "4399it [03:14, 22.19it/s]\titers: 4400, epoch: 6 | loss: 0.2087213\n",
      "\tspeed: 0.0445s/iter; left time: 3522.8254s\n",
      "4497it [03:19, 22.96it/s]\titers: 4500, epoch: 6 | loss: 0.1483999\n",
      "\tspeed: 0.0458s/iter; left time: 3616.4725s\n",
      "4599it [03:23, 24.61it/s]\titers: 4600, epoch: 6 | loss: 0.1329774\n",
      "\tspeed: 0.0425s/iter; left time: 3356.4585s\n",
      "4698it [03:27, 25.07it/s]\titers: 4700, epoch: 6 | loss: 0.2250728\n",
      "\tspeed: 0.0434s/iter; left time: 3418.7413s\n",
      "4797it [03:32, 21.29it/s]\titers: 4800, epoch: 6 | loss: 0.3161777\n",
      "\tspeed: 0.0445s/iter; left time: 3506.7873s\n",
      "4899it [03:37, 22.79it/s]\titers: 4900, epoch: 6 | loss: 0.3476612\n",
      "\tspeed: 0.0469s/iter; left time: 3689.9023s\n",
      "4998it [03:41, 23.31it/s]\titers: 5000, epoch: 6 | loss: 0.1664551\n",
      "\tspeed: 0.0438s/iter; left time: 3438.4235s\n",
      "5097it [03:45, 21.85it/s]\titers: 5100, epoch: 6 | loss: 0.3953101\n",
      "\tspeed: 0.0445s/iter; left time: 3492.7621s\n",
      "5199it [03:50, 22.39it/s]\titers: 5200, epoch: 6 | loss: 0.2724382\n",
      "\tspeed: 0.0438s/iter; left time: 3433.3656s\n",
      "5298it [03:54, 21.32it/s]\titers: 5300, epoch: 6 | loss: 0.2760254\n",
      "\tspeed: 0.0464s/iter; left time: 3626.3210s\n",
      "5397it [03:59, 23.26it/s]\titers: 5400, epoch: 6 | loss: 0.1506906\n",
      "\tspeed: 0.0432s/iter; left time: 3377.1220s\n",
      "5499it [04:03, 23.15it/s]\titers: 5500, epoch: 6 | loss: 0.1576057\n",
      "\tspeed: 0.0442s/iter; left time: 3452.7817s\n",
      "5569it [04:06, 22.56it/s]\n",
      "Epoch: 6 cost time: 246.8848295211792\n",
      "1215it [00:23, 52.42it/s]\n",
      "1210it [00:23, 50.73it/s]\n",
      "Epoch: 6 | Train Loss: 0.2181386 Vali Loss: 0.2731422 Test Loss: 0.3382419 MAE Loss: 0.3486905\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:04, 22.72it/s]\titers: 100, epoch: 7 | loss: 0.1902671\n",
      "\tspeed: 0.5704s/iter; left time: 44411.4825s\n",
      "198it [00:09, 22.88it/s]\titers: 200, epoch: 7 | loss: 0.1109150\n",
      "\tspeed: 0.0436s/iter; left time: 3393.7076s\n",
      "297it [00:13, 22.36it/s]\titers: 300, epoch: 7 | loss: 0.2120049\n",
      "\tspeed: 0.0443s/iter; left time: 3440.0812s\n",
      "398it [00:18, 21.84it/s]\titers: 400, epoch: 7 | loss: 0.1696895\n",
      "\tspeed: 0.0466s/iter; left time: 3612.9148s\n",
      "497it [00:22, 22.81it/s]\titers: 500, epoch: 7 | loss: 0.0854222\n",
      "\tspeed: 0.0426s/iter; left time: 3298.0341s\n",
      "599it [00:26, 25.56it/s]\titers: 600, epoch: 7 | loss: 0.3541794\n",
      "\tspeed: 0.0451s/iter; left time: 3485.9875s\n",
      "698it [00:31, 27.51it/s]\titers: 700, epoch: 7 | loss: 0.1178324\n",
      "\tspeed: 0.0424s/iter; left time: 3278.4289s\n",
      "797it [00:35, 21.98it/s]\titers: 800, epoch: 7 | loss: 0.4498747\n",
      "\tspeed: 0.0456s/iter; left time: 3520.4662s\n",
      "899it [00:40, 22.39it/s]\titers: 900, epoch: 7 | loss: 0.1539575\n",
      "\tspeed: 0.0443s/iter; left time: 3413.6966s\n",
      "998it [00:44, 23.82it/s]\titers: 1000, epoch: 7 | loss: 0.2766108\n",
      "\tspeed: 0.0431s/iter; left time: 3316.9727s\n",
      "1097it [00:48, 22.88it/s]\titers: 1100, epoch: 7 | loss: 0.1332790\n",
      "\tspeed: 0.0435s/iter; left time: 3342.3680s\n",
      "1197it [00:53, 20.48it/s]\titers: 1200, epoch: 7 | loss: 0.1777721\n",
      "\tspeed: 0.0459s/iter; left time: 3521.8597s\n",
      "1299it [00:57, 22.95it/s]\titers: 1300, epoch: 7 | loss: 0.1302734\n",
      "\tspeed: 0.0435s/iter; left time: 3337.3251s\n",
      "1398it [01:02, 22.69it/s]\titers: 1400, epoch: 7 | loss: 0.2542859\n",
      "\tspeed: 0.0435s/iter; left time: 3328.9205s\n",
      "1497it [01:06, 22.23it/s]\titers: 1500, epoch: 7 | loss: 0.2087514\n",
      "\tspeed: 0.0440s/iter; left time: 3366.9050s\n",
      "1599it [01:10, 21.13it/s]\titers: 1600, epoch: 7 | loss: 0.1493897\n",
      "\tspeed: 0.0442s/iter; left time: 3374.8051s\n",
      "1699it [01:15, 25.61it/s]\titers: 1700, epoch: 7 | loss: 0.1770298\n",
      "\tspeed: 0.0463s/iter; left time: 3528.3059s\n",
      "1798it [01:19, 20.74it/s]\titers: 1800, epoch: 7 | loss: 0.1553992\n",
      "\tspeed: 0.0445s/iter; left time: 3388.8453s\n",
      "1897it [01:24, 22.49it/s]\titers: 1900, epoch: 7 | loss: 0.1226098\n",
      "\tspeed: 0.0451s/iter; left time: 3431.5512s\n",
      "1999it [01:28, 22.62it/s]\titers: 2000, epoch: 7 | loss: 0.1975595\n",
      "\tspeed: 0.0434s/iter; left time: 3297.4350s\n",
      "2098it [01:33, 21.63it/s]\titers: 2100, epoch: 7 | loss: 0.2328193\n",
      "\tspeed: 0.0459s/iter; left time: 3480.3227s\n",
      "2197it [01:37, 22.80it/s]\titers: 2200, epoch: 7 | loss: 0.1161320\n",
      "\tspeed: 0.0423s/iter; left time: 3203.4612s\n",
      "2299it [01:42, 24.91it/s]\titers: 2300, epoch: 7 | loss: 0.1789447\n",
      "\tspeed: 0.0434s/iter; left time: 3283.3501s\n",
      "2398it [01:46, 28.36it/s]\titers: 2400, epoch: 7 | loss: 0.1616197\n",
      "\tspeed: 0.0422s/iter; left time: 3188.0057s\n",
      "2498it [01:49, 29.34it/s]\titers: 2500, epoch: 7 | loss: 0.2207845\n",
      "\tspeed: 0.0341s/iter; left time: 2574.0232s\n",
      "2597it [01:53, 28.38it/s]\titers: 2600, epoch: 7 | loss: 0.1425173\n",
      "\tspeed: 0.0360s/iter; left time: 2711.8953s\n",
      "2697it [01:56, 29.04it/s]\titers: 2700, epoch: 7 | loss: 0.0809170\n",
      "\tspeed: 0.0343s/iter; left time: 2579.6603s\n",
      "2799it [02:00, 21.93it/s]\titers: 2800, epoch: 7 | loss: 0.1578877\n",
      "\tspeed: 0.0410s/iter; left time: 3079.7580s\n",
      "2898it [02:05, 22.19it/s]\titers: 2900, epoch: 7 | loss: 0.4684889\n",
      "\tspeed: 0.0446s/iter; left time: 3351.2973s\n",
      "2997it [02:09, 21.59it/s]\titers: 3000, epoch: 7 | loss: 0.2079102\n",
      "\tspeed: 0.0469s/iter; left time: 3516.9731s\n",
      "3099it [02:14, 22.19it/s]\titers: 3100, epoch: 7 | loss: 0.1311921\n",
      "\tspeed: 0.0481s/iter; left time: 3602.0000s\n",
      "3198it [02:19, 23.26it/s]\titers: 3200, epoch: 7 | loss: 0.1124409\n",
      "\tspeed: 0.0434s/iter; left time: 3243.1469s\n",
      "3297it [02:23, 22.21it/s]\titers: 3300, epoch: 7 | loss: 0.1801856\n",
      "\tspeed: 0.0450s/iter; left time: 3356.3305s\n",
      "3399it [02:28, 22.03it/s]\titers: 3400, epoch: 7 | loss: 0.3140938\n",
      "\tspeed: 0.0446s/iter; left time: 3327.6067s\n",
      "3497it [02:32, 22.82it/s]\titers: 3500, epoch: 7 | loss: 0.1666026\n",
      "\tspeed: 0.0479s/iter; left time: 3566.0171s\n",
      "3599it [02:37, 21.62it/s]\titers: 3600, epoch: 7 | loss: 0.3044763\n",
      "\tspeed: 0.0448s/iter; left time: 3333.2700s\n",
      "3698it [02:41, 24.11it/s]\titers: 3700, epoch: 7 | loss: 0.1391239\n",
      "\tspeed: 0.0441s/iter; left time: 3274.8353s\n",
      "3799it [02:46, 20.86it/s]\titers: 3800, epoch: 7 | loss: 0.2278983\n",
      "\tspeed: 0.0505s/iter; left time: 3746.1107s\n",
      "3898it [02:51, 23.31it/s]\titers: 3900, epoch: 7 | loss: 0.1507782\n",
      "\tspeed: 0.0469s/iter; left time: 3472.4486s\n",
      "3997it [02:55, 23.13it/s]\titers: 4000, epoch: 7 | loss: 0.4460998\n",
      "\tspeed: 0.0431s/iter; left time: 3186.7309s\n",
      "4099it [02:59, 23.51it/s]\titers: 4100, epoch: 7 | loss: 0.0728384\n",
      "\tspeed: 0.0418s/iter; left time: 3090.9447s\n",
      "4198it [03:04, 22.80it/s]\titers: 4200, epoch: 7 | loss: 0.1142927\n",
      "\tspeed: 0.0415s/iter; left time: 3059.6439s\n",
      "4297it [03:08, 21.42it/s]\titers: 4300, epoch: 7 | loss: 0.1411736\n",
      "\tspeed: 0.0484s/iter; left time: 3565.4114s\n",
      "4399it [03:13, 22.93it/s]\titers: 4400, epoch: 7 | loss: 0.3112051\n",
      "\tspeed: 0.0433s/iter; left time: 3185.1425s\n",
      "4498it [03:17, 24.21it/s]\titers: 4500, epoch: 7 | loss: 0.2203231\n",
      "\tspeed: 0.0434s/iter; left time: 3189.4824s\n",
      "4597it [03:21, 26.60it/s]\titers: 4600, epoch: 7 | loss: 0.1519230\n",
      "\tspeed: 0.0425s/iter; left time: 3118.1722s\n",
      "4699it [03:26, 16.96it/s]\titers: 4700, epoch: 7 | loss: 0.1690700\n",
      "\tspeed: 0.0487s/iter; left time: 3564.8359s\n",
      "4798it [03:30, 23.32it/s]\titers: 4800, epoch: 7 | loss: 0.1511119\n",
      "\tspeed: 0.0428s/iter; left time: 3130.8931s\n",
      "4897it [03:35, 22.86it/s]\titers: 4900, epoch: 7 | loss: 0.2057839\n",
      "\tspeed: 0.0436s/iter; left time: 3183.8662s\n",
      "4999it [03:39, 22.34it/s]\titers: 5000, epoch: 7 | loss: 0.1174179\n",
      "\tspeed: 0.0420s/iter; left time: 3065.2568s\n",
      "5098it [03:43, 22.34it/s]\titers: 5100, epoch: 7 | loss: 0.1491790\n",
      "\tspeed: 0.0443s/iter; left time: 3228.9063s\n",
      "5198it [03:48, 23.42it/s]\titers: 5200, epoch: 7 | loss: 0.2925315\n",
      "\tspeed: 0.0462s/iter; left time: 3363.2021s\n",
      "5297it [03:52, 22.86it/s]\titers: 5300, epoch: 7 | loss: 0.1875010\n",
      "\tspeed: 0.0432s/iter; left time: 3140.7629s\n",
      "5399it [03:57, 22.86it/s]\titers: 5400, epoch: 7 | loss: 0.2260272\n",
      "\tspeed: 0.0439s/iter; left time: 3183.7059s\n",
      "5498it [04:01, 22.64it/s]\titers: 5500, epoch: 7 | loss: 0.1926086\n",
      "\tspeed: 0.0442s/iter; left time: 3200.2539s\n",
      "5569it [04:05, 22.70it/s]\n",
      "Epoch: 7 cost time: 245.30779147148132\n",
      "1215it [00:22, 53.94it/s]\n",
      "1210it [00:22, 54.36it/s]\n",
      "Epoch: 7 | Train Loss: 0.2170138 Vali Loss: 0.2723201 Test Loss: 0.3347535 MAE Loss: 0.3453789\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:04, 21.77it/s]\titers: 100, epoch: 8 | loss: 0.1548254\n",
      "\tspeed: 0.5486s/iter; left time: 39665.9094s\n",
      "198it [00:09, 22.48it/s]\titers: 200, epoch: 8 | loss: 0.1315216\n",
      "\tspeed: 0.0452s/iter; left time: 3263.2432s\n",
      "298it [00:13, 23.19it/s]\titers: 300, epoch: 8 | loss: 0.1835038\n",
      "\tspeed: 0.0470s/iter; left time: 3388.3315s\n",
      "397it [00:18, 23.21it/s]\titers: 400, epoch: 8 | loss: 0.0798364\n",
      "\tspeed: 0.0430s/iter; left time: 3099.2534s\n",
      "499it [00:22, 22.86it/s]\titers: 500, epoch: 8 | loss: 0.2324598\n",
      "\tspeed: 0.0438s/iter; left time: 3148.7036s\n",
      "598it [00:26, 27.55it/s]\titers: 600, epoch: 8 | loss: 0.1062531\n",
      "\tspeed: 0.0388s/iter; left time: 2785.5132s\n",
      "697it [00:31, 23.32it/s]\titers: 700, epoch: 8 | loss: 0.1533282\n",
      "\tspeed: 0.0470s/iter; left time: 3368.9729s\n",
      "799it [00:35, 23.28it/s]\titers: 800, epoch: 8 | loss: 0.1384606\n",
      "\tspeed: 0.0431s/iter; left time: 3086.3603s\n",
      "898it [00:39, 23.05it/s]\titers: 900, epoch: 8 | loss: 0.1295297\n",
      "\tspeed: 0.0432s/iter; left time: 3092.0836s\n",
      "997it [00:44, 23.12it/s]\titers: 1000, epoch: 8 | loss: 0.2020756\n",
      "\tspeed: 0.0435s/iter; left time: 3104.9877s\n",
      "1099it [00:49, 23.24it/s]\titers: 1100, epoch: 8 | loss: 0.1667664\n",
      "\tspeed: 0.0480s/iter; left time: 3421.2798s\n",
      "1198it [00:53, 23.20it/s]\titers: 1200, epoch: 8 | loss: 0.3294936\n",
      "\tspeed: 0.0430s/iter; left time: 3059.8845s\n",
      "1297it [00:57, 23.22it/s]\titers: 1300, epoch: 8 | loss: 0.2298934\n",
      "\tspeed: 0.0431s/iter; left time: 3062.2122s\n",
      "1399it [01:02, 18.94it/s]\titers: 1400, epoch: 8 | loss: 0.2319268\n",
      "\tspeed: 0.0446s/iter; left time: 3164.6221s\n",
      "1497it [01:06, 23.15it/s]\titers: 1500, epoch: 8 | loss: 0.1634253\n",
      "\tspeed: 0.0463s/iter; left time: 3282.4030s\n",
      "1599it [01:11, 22.89it/s]\titers: 1600, epoch: 8 | loss: 0.1649427\n",
      "\tspeed: 0.0429s/iter; left time: 3039.6910s\n",
      "1698it [01:15, 23.16it/s]\titers: 1700, epoch: 8 | loss: 0.1469267\n",
      "\tspeed: 0.0436s/iter; left time: 3082.6070s\n",
      "1797it [01:19, 22.90it/s]\titers: 1800, epoch: 8 | loss: 0.2234570\n",
      "\tspeed: 0.0437s/iter; left time: 3084.1125s\n",
      "1898it [01:24, 27.96it/s]\titers: 1900, epoch: 8 | loss: 0.1763351\n",
      "\tspeed: 0.0457s/iter; left time: 3220.1924s\n",
      "1997it [01:28, 23.28it/s]\titers: 2000, epoch: 8 | loss: 0.2040183\n",
      "\tspeed: 0.0420s/iter; left time: 2954.7838s\n",
      "2099it [01:32, 23.27it/s]\titers: 2100, epoch: 8 | loss: 0.1921739\n",
      "\tspeed: 0.0430s/iter; left time: 3021.1151s\n",
      "2198it [01:37, 22.99it/s]\titers: 2200, epoch: 8 | loss: 0.2170924\n",
      "\tspeed: 0.0433s/iter; left time: 3038.7553s\n",
      "2297it [01:41, 23.19it/s]\titers: 2300, epoch: 8 | loss: 0.1180489\n",
      "\tspeed: 0.0478s/iter; left time: 3347.2693s\n",
      "2399it [01:46, 23.24it/s]\titers: 2400, epoch: 8 | loss: 0.2999781\n",
      "\tspeed: 0.0433s/iter; left time: 3028.5280s\n",
      "2498it [01:50, 22.68it/s]\titers: 2500, epoch: 8 | loss: 0.1905760\n",
      "\tspeed: 0.0435s/iter; left time: 3040.9239s\n",
      "2597it [01:54, 22.97it/s]\titers: 2600, epoch: 8 | loss: 0.2862871\n",
      "\tspeed: 0.0432s/iter; left time: 3016.5300s\n",
      "2698it [01:58, 30.38it/s]\titers: 2700, epoch: 8 | loss: 0.1342036\n",
      "\tspeed: 0.0373s/iter; left time: 2596.7136s\n",
      "2798it [02:01, 30.51it/s]\titers: 2800, epoch: 8 | loss: 0.1171229\n",
      "\tspeed: 0.0327s/iter; left time: 2278.1715s\n",
      "2896it [02:05, 29.78it/s]\titers: 2900, epoch: 8 | loss: 0.1720067\n",
      "\tspeed: 0.0335s/iter; left time: 2331.6415s\n",
      "2997it [02:08, 29.64it/s]\titers: 3000, epoch: 8 | loss: 0.1135999\n",
      "\tspeed: 0.0341s/iter; left time: 2367.6881s\n",
      "3097it [02:12, 22.61it/s]\titers: 3100, epoch: 8 | loss: 0.1048643\n",
      "\tspeed: 0.0398s/iter; left time: 2761.0259s\n",
      "3199it [02:17, 23.22it/s]\titers: 3200, epoch: 8 | loss: 0.1791612\n",
      "\tspeed: 0.0447s/iter; left time: 3095.6572s\n",
      "3298it [02:21, 22.07it/s]\titers: 3300, epoch: 8 | loss: 0.2215142\n",
      "\tspeed: 0.0441s/iter; left time: 3048.9714s\n",
      "3397it [02:25, 23.26it/s]\titers: 3400, epoch: 8 | loss: 0.2259173\n",
      "\tspeed: 0.0433s/iter; left time: 2985.0303s\n",
      "3499it [02:30, 23.03it/s]\titers: 3500, epoch: 8 | loss: 0.1752705\n",
      "\tspeed: 0.0434s/iter; left time: 2987.9419s\n",
      "3598it [02:34, 22.96it/s]\titers: 3600, epoch: 8 | loss: 0.2478075\n",
      "\tspeed: 0.0448s/iter; left time: 3080.1035s\n",
      "3697it [02:38, 23.02it/s]\titers: 3700, epoch: 8 | loss: 0.1919439\n",
      "\tspeed: 0.0434s/iter; left time: 2979.9774s\n",
      "3799it [02:43, 23.16it/s]\titers: 3800, epoch: 8 | loss: 0.1537008\n",
      "\tspeed: 0.0435s/iter; left time: 2985.4602s\n",
      "3898it [02:47, 22.91it/s]\titers: 3900, epoch: 8 | loss: 0.3781292\n",
      "\tspeed: 0.0437s/iter; left time: 2994.3729s\n",
      "3998it [02:52, 18.46it/s]\titers: 4000, epoch: 8 | loss: 0.2790553\n",
      "\tspeed: 0.0465s/iter; left time: 3180.6674s\n",
      "4099it [02:55, 30.59it/s]\titers: 4100, epoch: 8 | loss: 0.2424593\n",
      "\tspeed: 0.0330s/iter; left time: 2254.1870s\n",
      "4199it [02:59, 23.20it/s]\titers: 4200, epoch: 8 | loss: 0.5083591\n",
      "\tspeed: 0.0379s/iter; left time: 2586.9786s\n",
      "4298it [03:03, 22.99it/s]\titers: 4300, epoch: 8 | loss: 0.1987321\n",
      "\tspeed: 0.0432s/iter; left time: 2944.7640s\n",
      "4397it [03:08, 22.87it/s]\titers: 4400, epoch: 8 | loss: 0.1665694\n",
      "\tspeed: 0.0436s/iter; left time: 2961.4434s\n",
      "4498it [03:12, 23.33it/s]\titers: 4500, epoch: 8 | loss: 0.1366101\n",
      "\tspeed: 0.0474s/iter; left time: 3215.8486s\n",
      "4597it [03:17, 22.88it/s]\titers: 4600, epoch: 8 | loss: 0.7367159\n",
      "\tspeed: 0.0432s/iter; left time: 2932.0720s\n",
      "4699it [03:21, 23.08it/s]\titers: 4700, epoch: 8 | loss: 0.1278419\n",
      "\tspeed: 0.0434s/iter; left time: 2935.6135s\n",
      "4798it [03:25, 22.73it/s]\titers: 4800, epoch: 8 | loss: 0.1452395\n",
      "\tspeed: 0.0439s/iter; left time: 2965.5322s\n",
      "4897it [03:30, 23.10it/s]\titers: 4900, epoch: 8 | loss: 0.1068725\n",
      "\tspeed: 0.0473s/iter; left time: 3193.0714s\n",
      "4999it [03:35, 23.02it/s]\titers: 5000, epoch: 8 | loss: 0.2519360\n",
      "\tspeed: 0.0431s/iter; left time: 2906.9683s\n",
      "5098it [03:39, 22.88it/s]\titers: 5100, epoch: 8 | loss: 0.1384707\n",
      "\tspeed: 0.0445s/iter; left time: 2993.7268s\n",
      "5197it [03:43, 22.77it/s]\titers: 5200, epoch: 8 | loss: 0.1846444\n",
      "\tspeed: 0.0427s/iter; left time: 2872.1349s\n",
      "5298it [03:48, 21.01it/s]\titers: 5300, epoch: 8 | loss: 0.2094012\n",
      "\tspeed: 0.0482s/iter; left time: 3232.3917s\n",
      "5397it [03:52, 23.42it/s]\titers: 5400, epoch: 8 | loss: 0.2991923\n",
      "\tspeed: 0.0429s/iter; left time: 2872.8583s\n",
      "5499it [03:57, 23.07it/s]\titers: 5500, epoch: 8 | loss: 0.1822630\n",
      "\tspeed: 0.0429s/iter; left time: 2870.0318s\n",
      "5569it [04:00, 23.18it/s]\n",
      "Epoch: 8 cost time: 240.2094452381134\n",
      "1215it [00:22, 55.07it/s]\n",
      "1210it [00:23, 51.17it/s]\n",
      "Epoch: 8 | Train Loss: 0.2168201 Vali Loss: 0.2723431 Test Loss: 0.3381192 MAE Loss: 0.3486131\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "97it [00:04, 23.24it/s]\titers: 100, epoch: 9 | loss: 0.1116658\n",
      "\tspeed: 0.5340s/iter; left time: 35631.9991s\n",
      "199it [00:08, 22.90it/s]\titers: 200, epoch: 9 | loss: 0.1125868\n",
      "\tspeed: 0.0436s/iter; left time: 2903.0248s\n",
      "298it [00:13, 22.46it/s]\titers: 300, epoch: 9 | loss: 0.2821782\n",
      "\tspeed: 0.0437s/iter; left time: 2907.3294s\n",
      "397it [00:17, 20.90it/s]\titers: 400, epoch: 9 | loss: 0.1524059\n",
      "\tspeed: 0.0476s/iter; left time: 3164.5827s\n",
      "499it [00:22, 23.40it/s]\titers: 500, epoch: 9 | loss: 0.2922044\n",
      "\tspeed: 0.0430s/iter; left time: 2849.6139s\n",
      "598it [00:26, 22.82it/s]\titers: 600, epoch: 9 | loss: 0.1389984\n",
      "\tspeed: 0.0433s/iter; left time: 2867.4889s\n",
      "697it [00:31, 22.55it/s]\titers: 700, epoch: 9 | loss: 0.1402777\n",
      "\tspeed: 0.0446s/iter; left time: 2948.4707s\n",
      "798it [00:35, 17.25it/s]\titers: 800, epoch: 9 | loss: 0.1626137\n",
      "\tspeed: 0.0471s/iter; left time: 3108.2139s\n",
      "898it [00:40, 23.15it/s]\titers: 900, epoch: 9 | loss: 0.1514084\n",
      "\tspeed: 0.0459s/iter; left time: 3023.8067s\n",
      "997it [00:44, 22.60it/s]\titers: 1000, epoch: 9 | loss: 0.2397038\n",
      "\tspeed: 0.0439s/iter; left time: 2888.4014s\n",
      "1099it [00:49, 22.45it/s]\titers: 1100, epoch: 9 | loss: 0.2657808\n",
      "\tspeed: 0.0436s/iter; left time: 2868.3716s\n",
      "1198it [00:53, 22.26it/s]\titers: 1200, epoch: 9 | loss: 0.1345396\n",
      "\tspeed: 0.0447s/iter; left time: 2933.2848s\n",
      "1299it [00:58, 22.13it/s]\titers: 1300, epoch: 9 | loss: 0.2192908\n",
      "\tspeed: 0.0455s/iter; left time: 2980.2726s\n",
      "1398it [01:02, 22.30it/s]\titers: 1400, epoch: 9 | loss: 0.1174312\n",
      "\tspeed: 0.0448s/iter; left time: 2930.5976s\n",
      "1497it [01:07, 20.88it/s]\titers: 1500, epoch: 9 | loss: 0.1614828\n",
      "\tspeed: 0.0453s/iter; left time: 2962.1033s\n",
      "1599it [01:11, 22.55it/s]\titers: 1600, epoch: 9 | loss: 0.2581987\n",
      "\tspeed: 0.0450s/iter; left time: 2934.6378s\n",
      "1698it [01:16, 23.16it/s]\titers: 1700, epoch: 9 | loss: 0.1880197\n",
      "\tspeed: 0.0449s/iter; left time: 2921.7907s\n",
      "1797it [01:20, 23.33it/s]\titers: 1800, epoch: 9 | loss: 0.3705100\n",
      "\tspeed: 0.0430s/iter; left time: 2793.1562s\n",
      "1899it [01:24, 22.76it/s]\titers: 1900, epoch: 9 | loss: 0.1543432\n",
      "\tspeed: 0.0435s/iter; left time: 2826.8254s\n",
      "1998it [01:29, 22.98it/s]\titers: 2000, epoch: 9 | loss: 0.3967336\n",
      "\tspeed: 0.0434s/iter; left time: 2812.8807s\n",
      "2099it [01:33, 23.70it/s]\titers: 2100, epoch: 9 | loss: 0.1917100\n",
      "\tspeed: 0.0451s/iter; left time: 2920.3924s\n",
      "2197it [01:37, 22.42it/s]\titers: 2200, epoch: 9 | loss: 0.2471255\n",
      "\tspeed: 0.0402s/iter; left time: 2596.0400s\n",
      "2298it [01:40, 30.23it/s]\titers: 2300, epoch: 9 | loss: 0.2812023\n",
      "\tspeed: 0.0331s/iter; left time: 2137.1314s\n",
      "2398it [01:44, 30.33it/s]\titers: 2400, epoch: 9 | loss: 0.2617283\n",
      "\tspeed: 0.0331s/iter; left time: 2131.6648s\n",
      "2498it [01:47, 30.04it/s]\titers: 2500, epoch: 9 | loss: 0.1998960\n",
      "\tspeed: 0.0331s/iter; left time: 2132.1070s\n",
      "2599it [01:51, 25.15it/s]\titers: 2600, epoch: 9 | loss: 0.1010066\n",
      "\tspeed: 0.0363s/iter; left time: 2328.6729s\n",
      "2699it [01:54, 29.80it/s]\titers: 2700, epoch: 9 | loss: 0.2437957\n",
      "\tspeed: 0.0332s/iter; left time: 2127.2630s\n",
      "2798it [01:58, 23.15it/s]\titers: 2800, epoch: 9 | loss: 0.3533569\n",
      "\tspeed: 0.0430s/iter; left time: 2755.6231s\n",
      "2897it [02:03, 22.91it/s]\titers: 2900, epoch: 9 | loss: 0.2151160\n",
      "\tspeed: 0.0432s/iter; left time: 2763.8192s\n",
      "2999it [02:07, 22.58it/s]\titers: 3000, epoch: 9 | loss: 0.2776822\n",
      "\tspeed: 0.0435s/iter; left time: 2779.6279s\n",
      "3098it [02:12, 22.98it/s]\titers: 3100, epoch: 9 | loss: 0.0953405\n",
      "\tspeed: 0.0469s/iter; left time: 2987.0424s\n",
      "3197it [02:16, 22.72it/s]\titers: 3200, epoch: 9 | loss: 0.2624729\n",
      "\tspeed: 0.0436s/iter; left time: 2776.2960s\n",
      "3299it [02:20, 23.00it/s]\titers: 3300, epoch: 9 | loss: 0.2748373\n",
      "\tspeed: 0.0434s/iter; left time: 2760.2899s\n",
      "3398it [02:25, 23.00it/s]\titers: 3400, epoch: 9 | loss: 0.2227735\n",
      "\tspeed: 0.0434s/iter; left time: 2754.5829s\n",
      "3497it [02:29, 23.19it/s]\titers: 3500, epoch: 9 | loss: 0.1723470\n",
      "\tspeed: 0.0467s/iter; left time: 2959.2678s\n",
      "3599it [02:34, 21.48it/s]\titers: 3600, epoch: 9 | loss: 0.3846277\n",
      "\tspeed: 0.0437s/iter; left time: 2765.8476s\n",
      "3698it [02:38, 22.46it/s]\titers: 3700, epoch: 9 | loss: 0.1894829\n",
      "\tspeed: 0.0434s/iter; left time: 2740.8898s\n",
      "3796it [02:42, 29.25it/s]\titers: 3800, epoch: 9 | loss: 0.2294280\n",
      "\tspeed: 0.0406s/iter; left time: 2557.8442s\n",
      "3899it [02:46, 25.68it/s]\titers: 3900, epoch: 9 | loss: 0.1726390\n",
      "\tspeed: 0.0354s/iter; left time: 2230.3579s\n",
      "3998it [02:50, 23.24it/s]\titers: 4000, epoch: 9 | loss: 0.2148015\n",
      "\tspeed: 0.0429s/iter; left time: 2693.9212s\n",
      "4096it [02:54, 28.26it/s]\titers: 4100, epoch: 9 | loss: 0.1881074\n",
      "\tspeed: 0.0414s/iter; left time: 2598.7679s\n",
      "4199it [02:58, 23.23it/s]\titers: 4200, epoch: 9 | loss: 0.2021489\n",
      "\tspeed: 0.0392s/iter; left time: 2457.7749s\n",
      "4298it [03:03, 19.84it/s]\titers: 4300, epoch: 9 | loss: 0.2973333\n",
      "\tspeed: 0.0446s/iter; left time: 2789.6383s\n",
      "4398it [03:07, 23.16it/s]\titers: 4400, epoch: 9 | loss: 0.2624298\n",
      "\tspeed: 0.0451s/iter; left time: 2817.2364s\n",
      "4497it [03:11, 21.46it/s]\titers: 4500, epoch: 9 | loss: 0.2555313\n",
      "\tspeed: 0.0443s/iter; left time: 2763.4166s\n",
      "4599it [03:16, 22.59it/s]\titers: 4600, epoch: 9 | loss: 0.2586336\n",
      "\tspeed: 0.0447s/iter; left time: 2781.0148s\n",
      "4699it [03:19, 29.73it/s]\titers: 4700, epoch: 9 | loss: 0.3145275\n",
      "\tspeed: 0.0336s/iter; left time: 2090.0955s\n",
      "4797it [03:23, 26.11it/s]\titers: 4800, epoch: 9 | loss: 0.3213842\n",
      "\tspeed: 0.0359s/iter; left time: 2226.5830s\n",
      "4897it [03:27, 22.30it/s]\titers: 4900, epoch: 9 | loss: 0.1859561\n",
      "\tspeed: 0.0390s/iter; left time: 2417.0712s\n",
      "4996it [03:30, 30.21it/s]\titers: 5000, epoch: 9 | loss: 0.4456352\n",
      "\tspeed: 0.0343s/iter; left time: 2118.2252s\n",
      "5096it [03:34, 30.12it/s]\titers: 5100, epoch: 9 | loss: 0.2015412\n",
      "\tspeed: 0.0332s/iter; left time: 2048.5561s\n",
      "5199it [03:37, 30.12it/s]\titers: 5200, epoch: 9 | loss: 0.4112512\n",
      "\tspeed: 0.0333s/iter; left time: 2051.3924s\n",
      "5297it [03:40, 26.20it/s]\titers: 5300, epoch: 9 | loss: 0.2727522\n",
      "\tspeed: 0.0346s/iter; left time: 2127.2672s\n",
      "5399it [03:44, 29.79it/s]\titers: 5400, epoch: 9 | loss: 0.4096894\n",
      "\tspeed: 0.0338s/iter; left time: 2073.6438s\n",
      "5497it [03:48, 29.31it/s]\titers: 5500, epoch: 9 | loss: 0.1740401\n",
      "\tspeed: 0.0388s/iter; left time: 2377.4863s\n",
      "5569it [03:50, 24.16it/s]\n",
      "Epoch: 9 cost time: 230.52427077293396\n",
      "1215it [00:21, 56.66it/s]\n",
      "1210it [00:21, 55.23it/s]\n",
      "Epoch: 9 | Train Loss: 0.2164044 Vali Loss: 0.2720522 Test Loss: 0.3365882 MAE Loss: 0.3470547\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "97it [00:04, 22.25it/s]\titers: 100, epoch: 10 | loss: 0.1166115\n",
      "\tspeed: 0.5251s/iter; left time: 32112.4031s\n",
      "199it [00:09, 22.44it/s]\titers: 200, epoch: 10 | loss: 0.2164431\n",
      "\tspeed: 0.0445s/iter; left time: 2716.2980s\n",
      "298it [00:13, 22.53it/s]\titers: 300, epoch: 10 | loss: 0.2781680\n",
      "\tspeed: 0.0445s/iter; left time: 2714.2416s\n",
      "397it [00:17, 23.36it/s]\titers: 400, epoch: 10 | loss: 0.1738352\n",
      "\tspeed: 0.0436s/iter; left time: 2651.6555s\n",
      "499it [00:22, 23.33it/s]\titers: 500, epoch: 10 | loss: 0.2664959\n",
      "\tspeed: 0.0431s/iter; left time: 2617.4234s\n",
      "598it [00:26, 22.37it/s]\titers: 600, epoch: 10 | loss: 0.2561653\n",
      "\tspeed: 0.0442s/iter; left time: 2680.0242s\n",
      "697it [00:31, 22.24it/s]\titers: 700, epoch: 10 | loss: 0.1515809\n",
      "\tspeed: 0.0450s/iter; left time: 2722.5872s\n",
      "799it [00:35, 22.99it/s]\titers: 800, epoch: 10 | loss: 0.1422565\n",
      "\tspeed: 0.0442s/iter; left time: 2671.3246s\n",
      "898it [00:39, 23.41it/s]\titers: 900, epoch: 10 | loss: 0.3045399\n",
      "\tspeed: 0.0432s/iter; left time: 2609.7179s\n",
      "997it [00:44, 23.36it/s]\titers: 1000, epoch: 10 | loss: 0.2005964\n",
      "\tspeed: 0.0429s/iter; left time: 2583.2367s\n",
      "1099it [00:48, 23.11it/s]\titers: 1100, epoch: 10 | loss: 0.3476654\n",
      "\tspeed: 0.0429s/iter; left time: 2578.5280s\n",
      "1198it [00:52, 23.34it/s]\titers: 1200, epoch: 10 | loss: 0.1921686\n",
      "\tspeed: 0.0429s/iter; left time: 2578.2972s\n",
      "1297it [00:57, 23.35it/s]\titers: 1300, epoch: 10 | loss: 0.1425631\n",
      "\tspeed: 0.0429s/iter; left time: 2572.7939s\n",
      "1399it [01:01, 22.43it/s]\titers: 1400, epoch: 10 | loss: 0.1416197\n",
      "\tspeed: 0.0442s/iter; left time: 2646.8926s\n",
      "1498it [01:05, 22.54it/s]\titers: 1500, epoch: 10 | loss: 0.0793414\n",
      "\tspeed: 0.0445s/iter; left time: 2660.5642s\n",
      "1597it [01:10, 22.50it/s]\titers: 1600, epoch: 10 | loss: 0.1917571\n",
      "\tspeed: 0.0445s/iter; left time: 2657.1176s\n",
      "1699it [01:14, 22.41it/s]\titers: 1700, epoch: 10 | loss: 0.1152145\n",
      "\tspeed: 0.0446s/iter; left time: 2654.7524s\n",
      "1798it [01:19, 22.33it/s]\titers: 1800, epoch: 10 | loss: 0.1821397\n",
      "\tspeed: 0.0447s/iter; left time: 2660.2877s\n",
      "1897it [01:23, 23.33it/s]\titers: 1900, epoch: 10 | loss: 0.1099721\n",
      "\tspeed: 0.0443s/iter; left time: 2628.2328s\n",
      "1999it [01:28, 22.51it/s]\titers: 2000, epoch: 10 | loss: 0.2226355\n",
      "\tspeed: 0.0445s/iter; left time: 2634.2814s\n",
      "2098it [01:32, 22.40it/s]\titers: 2100, epoch: 10 | loss: 0.2269297\n",
      "\tspeed: 0.0446s/iter; left time: 2635.6165s\n",
      "2197it [01:37, 21.87it/s]\titers: 2200, epoch: 10 | loss: 0.2373885\n",
      "\tspeed: 0.0448s/iter; left time: 2644.4855s\n",
      "2299it [01:41, 22.58it/s]\titers: 2300, epoch: 10 | loss: 0.1667070\n",
      "\tspeed: 0.0444s/iter; left time: 2618.3412s\n",
      "2398it [01:46, 22.52it/s]\titers: 2400, epoch: 10 | loss: 0.2264643\n",
      "\tspeed: 0.0446s/iter; left time: 2622.5357s\n",
      "2497it [01:50, 22.16it/s]\titers: 2500, epoch: 10 | loss: 0.2633585\n",
      "\tspeed: 0.0447s/iter; left time: 2626.8023s\n",
      "2599it [01:54, 22.35it/s]\titers: 2600, epoch: 10 | loss: 0.1302186\n",
      "\tspeed: 0.0446s/iter; left time: 2615.4816s\n",
      "2698it [01:59, 22.48it/s]\titers: 2700, epoch: 10 | loss: 0.2219853\n",
      "\tspeed: 0.0446s/iter; left time: 2611.8025s\n",
      "2797it [02:03, 22.51it/s]\titers: 2800, epoch: 10 | loss: 0.1260884\n",
      "\tspeed: 0.0445s/iter; left time: 2602.9653s\n",
      "2899it [02:08, 23.16it/s]\titers: 2900, epoch: 10 | loss: 0.1223920\n",
      "\tspeed: 0.0440s/iter; left time: 2566.4180s\n",
      "2998it [02:12, 23.26it/s]\titers: 3000, epoch: 10 | loss: 0.3603388\n",
      "\tspeed: 0.0432s/iter; left time: 2514.4252s\n",
      "3097it [02:16, 23.30it/s]\titers: 3100, epoch: 10 | loss: 0.1953427\n",
      "\tspeed: 0.0431s/iter; left time: 2504.9238s\n",
      "3199it [02:21, 23.40it/s]\titers: 3200, epoch: 10 | loss: 0.1526048\n",
      "\tspeed: 0.0428s/iter; left time: 2487.2789s\n",
      "3298it [02:25, 22.47it/s]\titers: 3300, epoch: 10 | loss: 0.1359098\n",
      "\tspeed: 0.0446s/iter; left time: 2583.5699s\n",
      "3397it [02:30, 22.61it/s]\titers: 3400, epoch: 10 | loss: 0.2809900\n",
      "\tspeed: 0.0444s/iter; left time: 2568.4989s\n",
      "3499it [02:34, 23.30it/s]\titers: 3500, epoch: 10 | loss: 0.3894456\n",
      "\tspeed: 0.0436s/iter; left time: 2515.6354s\n",
      "3598it [02:38, 22.35it/s]\titers: 3600, epoch: 10 | loss: 0.2511583\n",
      "\tspeed: 0.0445s/iter; left time: 2565.1211s\n",
      "3697it [02:43, 22.33it/s]\titers: 3700, epoch: 10 | loss: 0.3068283\n",
      "\tspeed: 0.0445s/iter; left time: 2562.3341s\n",
      "3799it [02:47, 22.68it/s]\titers: 3800, epoch: 10 | loss: 0.1698139\n",
      "\tspeed: 0.0444s/iter; left time: 2551.5762s\n",
      "3898it [02:52, 22.33it/s]\titers: 3900, epoch: 10 | loss: 0.2389025\n",
      "\tspeed: 0.0446s/iter; left time: 2555.9366s\n",
      "3997it [02:56, 22.51it/s]\titers: 4000, epoch: 10 | loss: 0.1525568\n",
      "\tspeed: 0.0444s/iter; left time: 2543.4881s\n",
      "4099it [03:01, 22.39it/s]\titers: 4100, epoch: 10 | loss: 0.5095955\n",
      "\tspeed: 0.0444s/iter; left time: 2536.2166s\n",
      "4198it [03:05, 22.56it/s]\titers: 4200, epoch: 10 | loss: 0.2541534\n",
      "\tspeed: 0.0443s/iter; left time: 2530.1762s\n",
      "4297it [03:09, 22.53it/s]\titers: 4300, epoch: 10 | loss: 0.1073301\n",
      "\tspeed: 0.0444s/iter; left time: 2528.6624s\n",
      "4399it [03:14, 22.53it/s]\titers: 4400, epoch: 10 | loss: 0.1586269\n",
      "\tspeed: 0.0443s/iter; left time: 2521.3648s\n",
      "4498it [03:18, 22.38it/s]\titers: 4500, epoch: 10 | loss: 0.2709049\n",
      "\tspeed: 0.0445s/iter; left time: 2524.6185s\n",
      "4597it [03:23, 22.61it/s]\titers: 4600, epoch: 10 | loss: 0.2143913\n",
      "\tspeed: 0.0445s/iter; left time: 2518.8546s\n",
      "4699it [03:27, 22.57it/s]\titers: 4700, epoch: 10 | loss: 0.0991250\n",
      "\tspeed: 0.0444s/iter; left time: 2509.7150s\n",
      "4798it [03:32, 22.52it/s]\titers: 4800, epoch: 10 | loss: 0.0843474\n",
      "\tspeed: 0.0444s/iter; left time: 2506.1426s\n",
      "4897it [03:36, 22.66it/s]\titers: 4900, epoch: 10 | loss: 0.1788571\n",
      "\tspeed: 0.0443s/iter; left time: 2499.4707s\n",
      "4999it [03:41, 22.75it/s]\titers: 5000, epoch: 10 | loss: 0.2542384\n",
      "\tspeed: 0.0443s/iter; left time: 2494.8431s\n",
      "5098it [03:45, 23.27it/s]\titers: 5100, epoch: 10 | loss: 0.1663207\n",
      "\tspeed: 0.0430s/iter; left time: 2412.2819s\n",
      "5197it [03:49, 23.22it/s]\titers: 5200, epoch: 10 | loss: 0.3767314\n",
      "\tspeed: 0.0429s/iter; left time: 2405.8075s\n",
      "5299it [03:53, 23.29it/s]\titers: 5300, epoch: 10 | loss: 0.2159511\n",
      "\tspeed: 0.0429s/iter; left time: 2401.6140s\n",
      "5398it [03:58, 23.32it/s]\titers: 5400, epoch: 10 | loss: 0.2219592\n",
      "\tspeed: 0.0428s/iter; left time: 2393.3049s\n",
      "5497it [04:02, 23.48it/s]\titers: 5500, epoch: 10 | loss: 0.1704788\n",
      "\tspeed: 0.0429s/iter; left time: 2393.3732s\n",
      "5569it [04:05, 22.68it/s]\n",
      "Epoch: 10 cost time: 245.59976148605347\n",
      "1215it [00:22, 53.50it/s]\n",
      "1210it [00:22, 52.86it/s]\n",
      "Epoch: 10 | Train Loss: 0.2162420 Vali Loss: 0.2718146 Test Loss: 0.3361417 MAE Loss: 0.3456436\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 7.812499999999999e-08\n",
      "99it [00:04, 23.30it/s]\titers: 100, epoch: 11 | loss: 0.1776258\n",
      "\tspeed: 0.5532s/iter; left time: 30751.2207s\n",
      "198it [00:08, 23.09it/s]\titers: 200, epoch: 11 | loss: 0.2842452\n",
      "\tspeed: 0.0430s/iter; left time: 2388.7651s\n",
      "297it [00:13, 23.21it/s]\titers: 300, epoch: 11 | loss: 0.2970787\n",
      "\tspeed: 0.0430s/iter; left time: 2379.7288s\n",
      "399it [00:17, 23.31it/s]\titers: 400, epoch: 11 | loss: 0.2336779\n",
      "\tspeed: 0.0430s/iter; left time: 2374.8772s\n",
      "498it [00:21, 23.39it/s]\titers: 500, epoch: 11 | loss: 0.1820496\n",
      "\tspeed: 0.0430s/iter; left time: 2372.4035s\n",
      "597it [00:25, 22.89it/s]\titers: 600, epoch: 11 | loss: 0.4388315\n",
      "\tspeed: 0.0431s/iter; left time: 2372.7365s\n",
      "699it [00:30, 23.38it/s]\titers: 700, epoch: 11 | loss: 0.0724258\n",
      "\tspeed: 0.0429s/iter; left time: 2358.8877s\n",
      "798it [00:34, 23.35it/s]\titers: 800, epoch: 11 | loss: 0.3714865\n",
      "\tspeed: 0.0428s/iter; left time: 2349.7604s\n",
      "897it [00:38, 23.32it/s]\titers: 900, epoch: 11 | loss: 0.2005490\n",
      "\tspeed: 0.0429s/iter; left time: 2349.2806s\n",
      "999it [00:43, 23.36it/s]\titers: 1000, epoch: 11 | loss: 0.3399100\n",
      "\tspeed: 0.0430s/iter; left time: 2350.5745s\n",
      "1098it [00:47, 23.34it/s]\titers: 1100, epoch: 11 | loss: 0.2819273\n",
      "\tspeed: 0.0429s/iter; left time: 2339.9930s\n",
      "1197it [00:51, 22.51it/s]\titers: 1200, epoch: 11 | loss: 0.2163856\n",
      "\tspeed: 0.0433s/iter; left time: 2361.6054s\n",
      "1299it [00:56, 23.41it/s]\titers: 1300, epoch: 11 | loss: 0.0977791\n",
      "\tspeed: 0.0435s/iter; left time: 2363.8581s\n",
      "1398it [01:00, 23.10it/s]\titers: 1400, epoch: 11 | loss: 0.1840870\n",
      "\tspeed: 0.0438s/iter; left time: 2377.3937s\n",
      "1497it [01:04, 22.09it/s]\titers: 1500, epoch: 11 | loss: 0.2565878\n",
      "\tspeed: 0.0444s/iter; left time: 2405.5538s\n",
      "1599it [01:09, 22.20it/s]\titers: 1600, epoch: 11 | loss: 0.1463204\n",
      "\tspeed: 0.0451s/iter; left time: 2438.2583s\n",
      "1698it [01:13, 22.29it/s]\titers: 1700, epoch: 11 | loss: 0.2104851\n",
      "\tspeed: 0.0448s/iter; left time: 2417.2100s\n",
      "1797it [01:18, 22.90it/s]\titers: 1800, epoch: 11 | loss: 0.2140828\n",
      "\tspeed: 0.0439s/iter; left time: 2365.1173s\n",
      "1899it [01:22, 23.33it/s]\titers: 1900, epoch: 11 | loss: 0.3459928\n",
      "\tspeed: 0.0433s/iter; left time: 2327.8488s\n",
      "1998it [01:26, 23.13it/s]\titers: 2000, epoch: 11 | loss: 0.1424098\n",
      "\tspeed: 0.0430s/iter; left time: 2309.9649s\n",
      "2097it [01:31, 23.34it/s]\titers: 2100, epoch: 11 | loss: 0.3696553\n",
      "\tspeed: 0.0421s/iter; left time: 2258.0425s\n",
      "2199it [01:35, 23.29it/s]\titers: 2200, epoch: 11 | loss: 0.1600388\n",
      "\tspeed: 0.0430s/iter; left time: 2301.2520s\n",
      "2298it [01:39, 23.21it/s]\titers: 2300, epoch: 11 | loss: 0.6009594\n",
      "\tspeed: 0.0430s/iter; left time: 2293.7461s\n",
      "2397it [01:44, 22.38it/s]\titers: 2400, epoch: 11 | loss: 0.1874643\n",
      "\tspeed: 0.0434s/iter; left time: 2311.5993s\n",
      "2499it [01:48, 22.37it/s]\titers: 2500, epoch: 11 | loss: 0.1302022\n",
      "\tspeed: 0.0447s/iter; left time: 2376.2574s\n",
      "2598it [01:53, 22.51it/s]\titers: 2600, epoch: 11 | loss: 0.2020666\n",
      "\tspeed: 0.0446s/iter; left time: 2369.8782s\n",
      "2697it [01:57, 22.46it/s]\titers: 2700, epoch: 11 | loss: 0.2940470\n",
      "\tspeed: 0.0446s/iter; left time: 2361.4944s\n",
      "2799it [02:01, 22.35it/s]\titers: 2800, epoch: 11 | loss: 0.1306584\n",
      "\tspeed: 0.0445s/iter; left time: 2354.4341s\n",
      "2898it [02:06, 22.36it/s]\titers: 2900, epoch: 11 | loss: 0.1438151\n",
      "\tspeed: 0.0446s/iter; left time: 2352.0579s\n",
      "2997it [02:10, 23.28it/s]\titers: 3000, epoch: 11 | loss: 0.1613295\n",
      "\tspeed: 0.0443s/iter; left time: 2335.8794s\n",
      "3099it [02:15, 23.32it/s]\titers: 3100, epoch: 11 | loss: 0.3402521\n",
      "\tspeed: 0.0430s/iter; left time: 2262.6441s\n",
      "3198it [02:19, 23.27it/s]\titers: 3200, epoch: 11 | loss: 0.3806716\n",
      "\tspeed: 0.0430s/iter; left time: 2257.5817s\n",
      "3297it [02:23, 22.40it/s]\titers: 3300, epoch: 11 | loss: 0.1893248\n",
      "\tspeed: 0.0444s/iter; left time: 2323.8508s\n",
      "3399it [02:28, 22.58it/s]\titers: 3400, epoch: 11 | loss: 0.1659772\n",
      "\tspeed: 0.0446s/iter; left time: 2331.4328s\n",
      "3498it [02:32, 22.36it/s]\titers: 3500, epoch: 11 | loss: 0.1798519\n",
      "\tspeed: 0.0446s/iter; left time: 2328.9718s\n",
      "3597it [02:37, 22.39it/s]\titers: 3600, epoch: 11 | loss: 0.1356301\n",
      "\tspeed: 0.0446s/iter; left time: 2321.2532s\n",
      "3699it [02:41, 23.25it/s]\titers: 3700, epoch: 11 | loss: 0.2005601\n",
      "\tspeed: 0.0435s/iter; left time: 2261.4348s\n",
      "3798it [02:45, 23.44it/s]\titers: 3800, epoch: 11 | loss: 0.2520767\n",
      "\tspeed: 0.0429s/iter; left time: 2223.9085s\n",
      "3897it [02:50, 23.41it/s]\titers: 3900, epoch: 11 | loss: 0.1629921\n",
      "\tspeed: 0.0428s/iter; left time: 2216.1419s\n",
      "3999it [02:54, 23.30it/s]\titers: 4000, epoch: 11 | loss: 0.1370835\n",
      "\tspeed: 0.0429s/iter; left time: 2217.8185s\n",
      "4098it [02:58, 23.19it/s]\titers: 4100, epoch: 11 | loss: 0.3932292\n",
      "\tspeed: 0.0430s/iter; left time: 2216.6758s\n",
      "4197it [03:02, 23.08it/s]\titers: 4200, epoch: 11 | loss: 0.1951586\n",
      "\tspeed: 0.0431s/iter; left time: 2219.1577s\n",
      "4299it [03:07, 23.25it/s]\titers: 4300, epoch: 11 | loss: 0.1263675\n",
      "\tspeed: 0.0431s/iter; left time: 2212.6496s\n",
      "4398it [03:11, 23.27it/s]\titers: 4400, epoch: 11 | loss: 0.2528196\n",
      "\tspeed: 0.0430s/iter; left time: 2204.2341s\n",
      "4497it [03:15, 23.30it/s]\titers: 4500, epoch: 11 | loss: 0.2941355\n",
      "\tspeed: 0.0430s/iter; left time: 2199.1276s\n",
      "4599it [03:20, 23.10it/s]\titers: 4600, epoch: 11 | loss: 0.2418145\n",
      "\tspeed: 0.0431s/iter; left time: 2199.6904s\n",
      "4698it [03:24, 23.35it/s]\titers: 4700, epoch: 11 | loss: 0.2560378\n",
      "\tspeed: 0.0430s/iter; left time: 2191.4980s\n",
      "4797it [03:28, 23.33it/s]\titers: 4800, epoch: 11 | loss: 0.1752687\n",
      "\tspeed: 0.0431s/iter; left time: 2194.6715s\n",
      "4899it [03:33, 23.23it/s]\titers: 4900, epoch: 11 | loss: 0.1684085\n",
      "\tspeed: 0.0430s/iter; left time: 2182.4412s\n",
      "4998it [03:37, 22.52it/s]\titers: 5000, epoch: 11 | loss: 0.1689172\n",
      "\tspeed: 0.0437s/iter; left time: 2212.7066s\n",
      "5097it [03:41, 22.35it/s]\titers: 5100, epoch: 11 | loss: 0.1249677\n",
      "\tspeed: 0.0446s/iter; left time: 2258.5926s\n",
      "5199it [03:46, 22.30it/s]\titers: 5200, epoch: 11 | loss: 0.2822768\n",
      "\tspeed: 0.0447s/iter; left time: 2256.4793s\n",
      "5298it [03:50, 22.38it/s]\titers: 5300, epoch: 11 | loss: 0.2672289\n",
      "\tspeed: 0.0446s/iter; left time: 2248.8393s\n",
      "5397it [03:55, 22.48it/s]\titers: 5400, epoch: 11 | loss: 0.1733765\n",
      "\tspeed: 0.0445s/iter; left time: 2239.9270s\n",
      "5499it [03:59, 22.41it/s]\titers: 5500, epoch: 11 | loss: 0.1786906\n",
      "\tspeed: 0.0445s/iter; left time: 2231.9807s\n",
      "5569it [04:03, 22.92it/s]\n",
      "Epoch: 11 cost time: 243.0265953540802\n",
      "1215it [00:22, 54.04it/s]\n",
      "1210it [00:22, 54.76it/s]\n",
      "Epoch: 11 | Train Loss: 0.2166432 Vali Loss: 0.2719435 Test Loss: 0.3364601 MAE Loss: 0.3464940\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9062499999999997e-08\n",
      "98it [00:04, 22.40it/s]\titers: 100, epoch: 12 | loss: 0.1489671\n",
      "\tspeed: 0.5260s/iter; left time: 26311.3687s\n",
      "197it [00:09, 22.42it/s]\titers: 200, epoch: 12 | loss: 0.3669643\n",
      "\tspeed: 0.0446s/iter; left time: 2225.7051s\n",
      "299it [00:13, 22.55it/s]\titers: 300, epoch: 12 | loss: 0.0964715\n",
      "\tspeed: 0.0446s/iter; left time: 2222.3642s\n",
      "398it [00:18, 22.41it/s]\titers: 400, epoch: 12 | loss: 0.2583011\n",
      "\tspeed: 0.0446s/iter; left time: 2218.2235s\n",
      "497it [00:22, 23.08it/s]\titers: 500, epoch: 12 | loss: 0.1551928\n",
      "\tspeed: 0.0440s/iter; left time: 2182.5116s\n",
      "599it [00:26, 22.95it/s]\titers: 600, epoch: 12 | loss: 0.1487257\n",
      "\tspeed: 0.0432s/iter; left time: 2140.5945s\n",
      "698it [00:31, 23.17it/s]\titers: 700, epoch: 12 | loss: 0.1178678\n",
      "\tspeed: 0.0433s/iter; left time: 2138.8763s\n",
      "797it [00:35, 23.34it/s]\titers: 800, epoch: 12 | loss: 0.3151687\n",
      "\tspeed: 0.0431s/iter; left time: 2124.3558s\n",
      "899it [00:39, 23.11it/s]\titers: 900, epoch: 12 | loss: 0.1164375\n",
      "\tspeed: 0.0432s/iter; left time: 2124.9286s\n",
      "998it [00:44, 23.15it/s]\titers: 1000, epoch: 12 | loss: 0.1520642\n",
      "\tspeed: 0.0434s/iter; left time: 2129.5738s\n",
      "1097it [00:48, 23.08it/s]\titers: 1100, epoch: 12 | loss: 0.2325860\n",
      "\tspeed: 0.0431s/iter; left time: 2112.6467s\n",
      "1199it [00:52, 23.20it/s]\titers: 1200, epoch: 12 | loss: 0.1315940\n",
      "\tspeed: 0.0429s/iter; left time: 2100.5969s\n",
      "1298it [00:56, 23.27it/s]\titers: 1300, epoch: 12 | loss: 0.3915799\n",
      "\tspeed: 0.0430s/iter; left time: 2100.5080s\n",
      "1397it [01:01, 22.09it/s]\titers: 1400, epoch: 12 | loss: 0.2059708\n",
      "\tspeed: 0.0446s/iter; left time: 2170.6432s\n",
      "1499it [01:05, 22.45it/s]\titers: 1500, epoch: 12 | loss: 0.1662808\n",
      "\tspeed: 0.0449s/iter; left time: 2182.3737s\n",
      "1598it [01:10, 22.48it/s]\titers: 1600, epoch: 12 | loss: 0.2273160\n",
      "\tspeed: 0.0447s/iter; left time: 2166.7153s\n",
      "1697it [01:14, 22.44it/s]\titers: 1700, epoch: 12 | loss: 0.1538002\n",
      "\tspeed: 0.0446s/iter; left time: 2160.6671s\n",
      "1799it [01:19, 22.38it/s]\titers: 1800, epoch: 12 | loss: 0.2014102\n",
      "\tspeed: 0.0447s/iter; left time: 2161.1765s\n",
      "1898it [01:23, 22.40it/s]\titers: 1900, epoch: 12 | loss: 0.1618975\n",
      "\tspeed: 0.0444s/iter; left time: 2139.7911s\n",
      "1997it [01:28, 22.42it/s]\titers: 2000, epoch: 12 | loss: 0.1130233\n",
      "\tspeed: 0.0447s/iter; left time: 2150.4169s\n",
      "2099it [01:32, 22.97it/s]\titers: 2100, epoch: 12 | loss: 0.2785451\n",
      "\tspeed: 0.0449s/iter; left time: 2156.0430s\n",
      "2198it [01:37, 23.33it/s]\titers: 2200, epoch: 12 | loss: 0.1685129\n",
      "\tspeed: 0.0431s/iter; left time: 2065.9191s\n",
      "2297it [01:41, 22.30it/s]\titers: 2300, epoch: 12 | loss: 0.1865517\n",
      "\tspeed: 0.0441s/iter; left time: 2110.0283s\n",
      "2399it [01:45, 22.37it/s]\titers: 2400, epoch: 12 | loss: 0.1662346\n",
      "\tspeed: 0.0446s/iter; left time: 2130.0045s\n",
      "2498it [01:50, 22.36it/s]\titers: 2500, epoch: 12 | loss: 0.2710271\n",
      "\tspeed: 0.0449s/iter; left time: 2137.9419s\n",
      "2597it [01:54, 22.02it/s]\titers: 2600, epoch: 12 | loss: 0.1039333\n",
      "\tspeed: 0.0449s/iter; left time: 2132.7158s\n",
      "2699it [01:59, 22.15it/s]\titers: 2700, epoch: 12 | loss: 0.3176569\n",
      "\tspeed: 0.0452s/iter; left time: 2142.8336s\n",
      "2798it [02:03, 23.26it/s]\titers: 2800, epoch: 12 | loss: 0.1591241\n",
      "\tspeed: 0.0439s/iter; left time: 2075.2792s\n",
      "2897it [02:08, 22.77it/s]\titers: 2900, epoch: 12 | loss: 0.1197414\n",
      "\tspeed: 0.0443s/iter; left time: 2089.6386s\n",
      "2999it [02:12, 23.22it/s]\titers: 3000, epoch: 12 | loss: 0.1708530\n",
      "\tspeed: 0.0429s/iter; left time: 2021.3049s\n",
      "3098it [02:16, 23.28it/s]\titers: 3100, epoch: 12 | loss: 0.2866040\n",
      "\tspeed: 0.0431s/iter; left time: 2027.1811s\n",
      "3197it [02:21, 22.92it/s]\titers: 3200, epoch: 12 | loss: 0.2935490\n",
      "\tspeed: 0.0432s/iter; left time: 2025.3843s\n",
      "3299it [02:25, 23.26it/s]\titers: 3300, epoch: 12 | loss: 0.3218733\n",
      "\tspeed: 0.0430s/iter; left time: 2012.1195s\n",
      "3398it [02:29, 23.32it/s]\titers: 3400, epoch: 12 | loss: 0.3417062\n",
      "\tspeed: 0.0429s/iter; left time: 2003.7440s\n",
      "3497it [02:33, 23.17it/s]\titers: 3500, epoch: 12 | loss: 0.3361369\n",
      "\tspeed: 0.0430s/iter; left time: 2004.6800s\n",
      "3599it [02:38, 23.26it/s]\titers: 3600, epoch: 12 | loss: 0.2060035\n",
      "\tspeed: 0.0436s/iter; left time: 2030.0021s\n",
      "3698it [02:42, 22.38it/s]\titers: 3700, epoch: 12 | loss: 0.1162586\n",
      "\tspeed: 0.0436s/iter; left time: 2022.2301s\n",
      "3797it [02:47, 23.19it/s]\titers: 3800, epoch: 12 | loss: 0.2389810\n",
      "\tspeed: 0.0442s/iter; left time: 2045.7127s\n",
      "3899it [02:51, 22.53it/s]\titers: 3900, epoch: 12 | loss: 0.1455294\n",
      "\tspeed: 0.0446s/iter; left time: 2061.8787s\n",
      "3998it [02:56, 22.37it/s]\titers: 4000, epoch: 12 | loss: 0.2049389\n",
      "\tspeed: 0.0445s/iter; left time: 2054.4007s\n",
      "4097it [03:00, 22.53it/s]\titers: 4100, epoch: 12 | loss: 0.2090959\n",
      "\tspeed: 0.0445s/iter; left time: 2046.0440s\n",
      "4199it [03:05, 21.91it/s]\titers: 4200, epoch: 12 | loss: 0.0915532\n",
      "\tspeed: 0.0444s/iter; left time: 2039.7558s\n",
      "4298it [03:09, 23.32it/s]\titers: 4300, epoch: 12 | loss: 0.0870273\n",
      "\tspeed: 0.0429s/iter; left time: 1963.7925s\n",
      "4397it [03:13, 22.69it/s]\titers: 4400, epoch: 12 | loss: 0.2435672\n",
      "\tspeed: 0.0431s/iter; left time: 1968.5422s\n",
      "4499it [03:17, 23.33it/s]\titers: 4500, epoch: 12 | loss: 0.1116485\n",
      "\tspeed: 0.0431s/iter; left time: 1968.0584s\n",
      "4598it [03:22, 23.24it/s]\titers: 4600, epoch: 12 | loss: 0.2574611\n",
      "\tspeed: 0.0430s/iter; left time: 1955.9565s\n",
      "4697it [03:26, 23.27it/s]\titers: 4700, epoch: 12 | loss: 0.3557546\n",
      "\tspeed: 0.0428s/iter; left time: 1944.5613s\n",
      "4799it [03:30, 23.29it/s]\titers: 4800, epoch: 12 | loss: 0.1652659\n",
      "\tspeed: 0.0431s/iter; left time: 1951.9115s\n",
      "4898it [03:35, 23.23it/s]\titers: 4900, epoch: 12 | loss: 0.1352832\n",
      "\tspeed: 0.0429s/iter; left time: 1940.9842s\n",
      "4997it [03:39, 23.29it/s]\titers: 5000, epoch: 12 | loss: 0.2151084\n",
      "\tspeed: 0.0430s/iter; left time: 1942.1563s\n",
      "5099it [03:43, 23.42it/s]\titers: 5100, epoch: 12 | loss: 0.3117214\n",
      "\tspeed: 0.0429s/iter; left time: 1931.9321s\n",
      "5198it [03:47, 23.31it/s]\titers: 5200, epoch: 12 | loss: 0.2819805\n",
      "\tspeed: 0.0429s/iter; left time: 1928.6955s\n",
      "5297it [03:52, 23.32it/s]\titers: 5300, epoch: 12 | loss: 0.1849984\n",
      "\tspeed: 0.0429s/iter; left time: 1920.9681s\n",
      "5399it [03:56, 23.36it/s]\titers: 5400, epoch: 12 | loss: 0.1153025\n",
      "\tspeed: 0.0429s/iter; left time: 1916.8452s\n",
      "5498it [04:00, 23.25it/s]\titers: 5500, epoch: 12 | loss: 0.2681099\n",
      "\tspeed: 0.0429s/iter; left time: 1914.5858s\n",
      "5569it [04:03, 22.83it/s]\n",
      "Epoch: 12 cost time: 243.91034364700317\n",
      "1215it [00:22, 54.25it/s]\n",
      "1210it [00:21, 56.19it/s]\n",
      "Epoch: 12 | Train Loss: 0.2160548 Vali Loss: 0.2719658 Test Loss: 0.3365452 MAE Loss: 0.3466185\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9531249999999998e-08\n",
      "97it [00:04, 23.26it/s]\titers: 100, epoch: 13 | loss: 0.1355273\n",
      "\tspeed: 0.5165s/iter; left time: 22960.0871s\n",
      "199it [00:08, 23.33it/s]\titers: 200, epoch: 13 | loss: 0.2663215\n",
      "\tspeed: 0.0429s/iter; left time: 1901.1967s\n",
      "298it [00:13, 23.24it/s]\titers: 300, epoch: 13 | loss: 0.0901046\n",
      "\tspeed: 0.0429s/iter; left time: 1898.7406s\n",
      "397it [00:17, 23.28it/s]\titers: 400, epoch: 13 | loss: 0.4501817\n",
      "\tspeed: 0.0429s/iter; left time: 1892.6579s\n",
      "499it [00:21, 23.08it/s]\titers: 500, epoch: 13 | loss: 0.1909175\n",
      "\tspeed: 0.0431s/iter; left time: 1900.1150s\n",
      "598it [00:26, 22.14it/s]\titers: 600, epoch: 13 | loss: 0.2036900\n",
      "\tspeed: 0.0445s/iter; left time: 1954.3443s\n",
      "697it [00:30, 22.12it/s]\titers: 700, epoch: 13 | loss: 0.2185232\n",
      "\tspeed: 0.0451s/iter; left time: 1979.0242s\n",
      "799it [00:35, 23.20it/s]\titers: 800, epoch: 13 | loss: 0.1980292\n",
      "\tspeed: 0.0438s/iter; left time: 1915.5297s\n",
      "898it [00:39, 23.32it/s]\titers: 900, epoch: 13 | loss: 0.2226872\n",
      "\tspeed: 0.0430s/iter; left time: 1878.0476s\n",
      "997it [00:43, 23.27it/s]\titers: 1000, epoch: 13 | loss: 0.1934659\n",
      "\tspeed: 0.0429s/iter; left time: 1869.3259s\n",
      "1099it [00:47, 23.40it/s]\titers: 1100, epoch: 13 | loss: 0.3135662\n",
      "\tspeed: 0.0428s/iter; left time: 1860.5094s\n",
      "1198it [00:52, 23.31it/s]\titers: 1200, epoch: 13 | loss: 0.2562559\n",
      "\tspeed: 0.0430s/iter; left time: 1866.2356s\n",
      "1297it [00:56, 22.32it/s]\titers: 1300, epoch: 13 | loss: 0.1652735\n",
      "\tspeed: 0.0440s/iter; left time: 1901.6868s\n",
      "1399it [01:01, 22.30it/s]\titers: 1400, epoch: 13 | loss: 0.0892268\n",
      "\tspeed: 0.0449s/iter; left time: 1939.4954s\n",
      "1498it [01:05, 22.47it/s]\titers: 1500, epoch: 13 | loss: 0.2073091\n",
      "\tspeed: 0.0448s/iter; left time: 1926.8834s\n",
      "1597it [01:09, 22.57it/s]\titers: 1600, epoch: 13 | loss: 0.1756770\n",
      "\tspeed: 0.0446s/iter; left time: 1916.8034s\n",
      "1699it [01:14, 22.41it/s]\titers: 1700, epoch: 13 | loss: 0.1276106\n",
      "\tspeed: 0.0447s/iter; left time: 1913.9959s\n",
      "1798it [01:18, 22.38it/s]\titers: 1800, epoch: 13 | loss: 0.1294912\n",
      "\tspeed: 0.0446s/iter; left time: 1908.4313s\n",
      "1897it [01:23, 22.31it/s]\titers: 1900, epoch: 13 | loss: 0.5152246\n",
      "\tspeed: 0.0447s/iter; left time: 1904.7842s\n",
      "1999it [01:27, 22.40it/s]\titers: 2000, epoch: 13 | loss: 0.1879629\n",
      "\tspeed: 0.0446s/iter; left time: 1896.2996s\n",
      "2098it [01:32, 22.51it/s]\titers: 2100, epoch: 13 | loss: 0.2079790\n",
      "\tspeed: 0.0448s/iter; left time: 1900.0515s\n",
      "2197it [01:36, 22.26it/s]\titers: 2200, epoch: 13 | loss: 0.1912174\n",
      "\tspeed: 0.0452s/iter; left time: 1916.3482s\n",
      "2299it [01:41, 22.48it/s]\titers: 2300, epoch: 13 | loss: 0.1825664\n",
      "\tspeed: 0.0447s/iter; left time: 1887.1501s\n",
      "2398it [01:45, 22.38it/s]\titers: 2400, epoch: 13 | loss: 0.1622130\n",
      "\tspeed: 0.0451s/iter; left time: 1899.7449s\n",
      "2497it [01:50, 22.11it/s]\titers: 2500, epoch: 13 | loss: 0.1065469\n",
      "\tspeed: 0.0447s/iter; left time: 1881.0527s\n",
      "2599it [01:54, 23.12it/s]\titers: 2600, epoch: 13 | loss: 0.1665487\n",
      "\tspeed: 0.0427s/iter; left time: 1791.9876s\n",
      "2698it [01:59, 22.28it/s]\titers: 2700, epoch: 13 | loss: 0.1119574\n",
      "\tspeed: 0.0447s/iter; left time: 1871.2669s\n",
      "2797it [02:03, 22.41it/s]\titers: 2800, epoch: 13 | loss: 0.1110070\n",
      "\tspeed: 0.0438s/iter; left time: 1828.3177s\n",
      "2899it [02:07, 23.28it/s]\titers: 2900, epoch: 13 | loss: 0.3802202\n",
      "\tspeed: 0.0440s/iter; left time: 1831.6314s\n",
      "2998it [02:12, 23.44it/s]\titers: 3000, epoch: 13 | loss: 0.1332236\n",
      "\tspeed: 0.0429s/iter; left time: 1784.5473s\n",
      "3097it [02:16, 23.37it/s]\titers: 3100, epoch: 13 | loss: 0.1220593\n",
      "\tspeed: 0.0429s/iter; left time: 1777.8466s\n",
      "3199it [02:20, 23.37it/s]\titers: 3200, epoch: 13 | loss: 0.1295133\n",
      "\tspeed: 0.0428s/iter; left time: 1770.2654s\n",
      "3298it [02:25, 23.39it/s]\titers: 3300, epoch: 13 | loss: 0.2595626\n",
      "\tspeed: 0.0430s/iter; left time: 1773.0359s\n",
      "3397it [02:29, 22.80it/s]\titers: 3400, epoch: 13 | loss: 0.1945525\n",
      "\tspeed: 0.0430s/iter; left time: 1769.8868s\n",
      "3499it [02:33, 23.39it/s]\titers: 3500, epoch: 13 | loss: 0.1397350\n",
      "\tspeed: 0.0436s/iter; left time: 1789.4550s\n",
      "3598it [02:38, 22.23it/s]\titers: 3600, epoch: 13 | loss: 0.1302713\n",
      "\tspeed: 0.0449s/iter; left time: 1837.2849s\n",
      "3697it [02:42, 22.40it/s]\titers: 3700, epoch: 13 | loss: 0.2296652\n",
      "\tspeed: 0.0451s/iter; left time: 1843.3626s\n",
      "3799it [02:47, 22.35it/s]\titers: 3800, epoch: 13 | loss: 0.2341122\n",
      "\tspeed: 0.0451s/iter; left time: 1836.9562s\n",
      "3898it [02:51, 22.32it/s]\titers: 3900, epoch: 13 | loss: 0.2093909\n",
      "\tspeed: 0.0448s/iter; left time: 1821.6720s\n",
      "3997it [02:56, 22.55it/s]\titers: 4000, epoch: 13 | loss: 0.1575873\n",
      "\tspeed: 0.0444s/iter; left time: 1800.0181s\n",
      "4099it [03:00, 22.44it/s]\titers: 4100, epoch: 13 | loss: 0.1481451\n",
      "\tspeed: 0.0445s/iter; left time: 1801.7935s\n",
      "4198it [03:05, 22.28it/s]\titers: 4200, epoch: 13 | loss: 0.1441889\n",
      "\tspeed: 0.0447s/iter; left time: 1804.8734s\n",
      "4297it [03:09, 22.50it/s]\titers: 4300, epoch: 13 | loss: 0.1961092\n",
      "\tspeed: 0.0446s/iter; left time: 1796.5799s\n",
      "4399it [03:14, 22.21it/s]\titers: 4400, epoch: 13 | loss: 0.1030517\n",
      "\tspeed: 0.0450s/iter; left time: 1805.3542s\n",
      "4498it [03:18, 23.06it/s]\titers: 4500, epoch: 13 | loss: 0.1150243\n",
      "\tspeed: 0.0444s/iter; left time: 1778.1745s\n",
      "4597it [03:22, 21.92it/s]\titers: 4600, epoch: 13 | loss: 0.1697171\n",
      "\tspeed: 0.0448s/iter; left time: 1788.2848s\n",
      "4699it [03:27, 23.32it/s]\titers: 4700, epoch: 13 | loss: 0.1923511\n",
      "\tspeed: 0.0430s/iter; left time: 1715.3785s\n",
      "4798it [03:31, 23.33it/s]\titers: 4800, epoch: 13 | loss: 0.2619301\n",
      "\tspeed: 0.0429s/iter; left time: 1703.7546s\n",
      "4897it [03:35, 22.31it/s]\titers: 4900, epoch: 13 | loss: 0.5079402\n",
      "\tspeed: 0.0442s/iter; left time: 1752.4988s\n",
      "4999it [03:40, 22.50it/s]\titers: 5000, epoch: 13 | loss: 0.0968406\n",
      "\tspeed: 0.0445s/iter; left time: 1758.4851s\n",
      "5098it [03:44, 21.84it/s]\titers: 5100, epoch: 13 | loss: 0.1816287\n",
      "\tspeed: 0.0451s/iter; left time: 1778.7657s\n",
      "5197it [03:49, 21.76it/s]\titers: 5200, epoch: 13 | loss: 0.1655571\n",
      "\tspeed: 0.0437s/iter; left time: 1717.8885s\n",
      "5299it [03:53, 22.51it/s]\titers: 5300, epoch: 13 | loss: 0.1695750\n",
      "\tspeed: 0.0448s/iter; left time: 1756.6226s\n",
      "5398it [03:58, 22.40it/s]\titers: 5400, epoch: 13 | loss: 0.1960293\n",
      "\tspeed: 0.0445s/iter; left time: 1740.5458s\n",
      "5497it [04:02, 22.50it/s]\titers: 5500, epoch: 13 | loss: 0.1181158\n",
      "\tspeed: 0.0446s/iter; left time: 1740.0967s\n",
      "5569it [04:05, 22.65it/s]\n",
      "Epoch: 13 cost time: 245.8271448612213\n",
      "1215it [00:21, 57.23it/s]\n",
      "1210it [00:22, 54.12it/s]\n",
      "Epoch: 13 | Train Loss: 0.2161817 Vali Loss: 0.2719755 Test Loss: 0.3364900 MAE Loss: 0.3465284\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 63.93595753908157 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size= 16\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 03:54:35,500] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 03:54:36,665] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 03:54:36,665] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 88899\n",
      "val 19227\n",
      "test 19155\n",
      "d_llm 768\n",
      "[2024-05-07 03:54:38,266] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 03:54:38,743] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 03:54:38,744] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 03:54:38,744] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 03:54:38,745] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 03:54:38,745] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 03:54:38,745] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 03:54:38,746] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 03:54:38,746] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 03:54:38,746] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 03:54:38,746] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 03:54:39,255] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 03:54:39,256] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB \n",
      "[2024-05-07 03:54:39,256] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.1 GB, percent = 21.1%\n",
      "[2024-05-07 03:54:39,360] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 03:54:39,360] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-07 03:54:39,361] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.1 GB, percent = 21.1%\n",
      "[2024-05-07 03:54:39,361] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 03:54:39,460] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 03:54:39,461] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.78 GB         Max_CA 1 GB \n",
      "[2024-05-07 03:54:39,461] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.1 GB, percent = 21.1%\n",
      "[2024-05-07 03:54:39,461] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 03:54:39,461] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 03:54:39,461] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 03:54:39,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f14e81a0210>\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 03:54:39,462] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 03:54:39,463] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:06, 19.04it/s]\titers: 100, epoch: 1 | loss: 0.4223907\n",
      "\tspeed: 0.0746s/iter; left time: 5520.8019s\n",
      "199it [00:11, 19.32it/s]\titers: 200, epoch: 1 | loss: 0.5959699\n",
      "\tspeed: 0.0524s/iter; left time: 3870.5395s\n",
      "299it [00:16, 19.19it/s]\titers: 300, epoch: 1 | loss: 0.3203190\n",
      "\tspeed: 0.0524s/iter; left time: 3864.0543s\n",
      "399it [00:21, 18.97it/s]\titers: 400, epoch: 1 | loss: 0.3139966\n",
      "\tspeed: 0.0524s/iter; left time: 3861.9377s\n",
      "499it [00:27, 18.87it/s]\titers: 500, epoch: 1 | loss: 0.3245276\n",
      "\tspeed: 0.0523s/iter; left time: 3850.2004s\n",
      "599it [00:32, 18.48it/s]\titers: 600, epoch: 1 | loss: 0.6641069\n",
      "\tspeed: 0.0539s/iter; left time: 3959.5580s\n",
      "699it [00:37, 18.49it/s]\titers: 700, epoch: 1 | loss: 0.4222422\n",
      "\tspeed: 0.0540s/iter; left time: 3960.7378s\n",
      "799it [00:43, 18.56it/s]\titers: 800, epoch: 1 | loss: 0.4216006\n",
      "\tspeed: 0.0537s/iter; left time: 3935.8623s\n",
      "899it [00:48, 18.63it/s]\titers: 900, epoch: 1 | loss: 0.6105897\n",
      "\tspeed: 0.0537s/iter; left time: 3932.8349s\n",
      "999it [00:54, 18.54it/s]\titers: 1000, epoch: 1 | loss: 0.3794679\n",
      "\tspeed: 0.0544s/iter; left time: 3978.6589s\n",
      "1099it [00:59, 18.35it/s]\titers: 1100, epoch: 1 | loss: 0.5451850\n",
      "\tspeed: 0.0540s/iter; left time: 3942.2437s\n",
      "1199it [01:04, 18.83it/s]\titers: 1200, epoch: 1 | loss: 0.3004782\n",
      "\tspeed: 0.0538s/iter; left time: 3921.7857s\n",
      "1299it [01:10, 18.83it/s]\titers: 1300, epoch: 1 | loss: 0.2404264\n",
      "\tspeed: 0.0539s/iter; left time: 3919.6329s\n",
      "1399it [01:15, 19.06it/s]\titers: 1400, epoch: 1 | loss: 0.3180234\n",
      "\tspeed: 0.0524s/iter; left time: 3809.3893s\n",
      "1499it [01:20, 18.56it/s]\titers: 1500, epoch: 1 | loss: 0.2236478\n",
      "\tspeed: 0.0531s/iter; left time: 3852.5964s\n",
      "1599it [01:26, 18.62it/s]\titers: 1600, epoch: 1 | loss: 0.3743631\n",
      "\tspeed: 0.0537s/iter; left time: 3891.1224s\n",
      "1699it [01:31, 18.77it/s]\titers: 1700, epoch: 1 | loss: 0.3626256\n",
      "\tspeed: 0.0537s/iter; left time: 3885.8173s\n",
      "1799it [01:37, 18.07it/s]\titers: 1800, epoch: 1 | loss: 0.2971509\n",
      "\tspeed: 0.0541s/iter; left time: 3907.3617s\n",
      "1899it [01:42, 18.35it/s]\titers: 1900, epoch: 1 | loss: 0.4888404\n",
      "\tspeed: 0.0541s/iter; left time: 3906.8879s\n",
      "1999it [01:47, 18.69it/s]\titers: 2000, epoch: 1 | loss: 0.2516645\n",
      "\tspeed: 0.0540s/iter; left time: 3891.1058s\n",
      "2099it [01:53, 18.49it/s]\titers: 2100, epoch: 1 | loss: 0.4087180\n",
      "\tspeed: 0.0539s/iter; left time: 3876.7277s\n",
      "2199it [01:58, 18.78it/s]\titers: 2200, epoch: 1 | loss: 0.9474214\n",
      "\tspeed: 0.0536s/iter; left time: 3854.0971s\n",
      "2299it [02:03, 18.70it/s]\titers: 2300, epoch: 1 | loss: 0.4366411\n",
      "\tspeed: 0.0535s/iter; left time: 3842.8647s\n",
      "2399it [02:09, 18.40it/s]\titers: 2400, epoch: 1 | loss: 0.3305367\n",
      "\tspeed: 0.0539s/iter; left time: 3860.5198s\n",
      "2499it [02:14, 18.81it/s]\titers: 2500, epoch: 1 | loss: 0.3928124\n",
      "\tspeed: 0.0538s/iter; left time: 3852.9126s\n",
      "2599it [02:20, 18.63it/s]\titers: 2600, epoch: 1 | loss: 0.3465686\n",
      "\tspeed: 0.0542s/iter; left time: 3873.4335s\n",
      "2699it [02:25, 18.48it/s]\titers: 2700, epoch: 1 | loss: 0.3859066\n",
      "\tspeed: 0.0537s/iter; left time: 3832.5987s\n",
      "2799it [02:30, 18.31it/s]\titers: 2800, epoch: 1 | loss: 0.7347122\n",
      "\tspeed: 0.0547s/iter; left time: 3897.9217s\n",
      "2899it [02:36, 19.14it/s]\titers: 2900, epoch: 1 | loss: 0.1591640\n",
      "\tspeed: 0.0521s/iter; left time: 3710.7684s\n",
      "2998it [02:41, 19.16it/s]\titers: 3000, epoch: 1 | loss: 0.3627007\n",
      "\tspeed: 0.0520s/iter; left time: 3698.6656s\n",
      "3098it [02:46, 19.37it/s]\titers: 3100, epoch: 1 | loss: 0.3244961\n",
      "\tspeed: 0.0520s/iter; left time: 3688.3693s\n",
      "3198it [02:51, 18.48it/s]\titers: 3200, epoch: 1 | loss: 0.2034762\n",
      "\tspeed: 0.0534s/iter; left time: 3787.3506s\n",
      "3298it [02:57, 18.93it/s]\titers: 3300, epoch: 1 | loss: 0.3865297\n",
      "\tspeed: 0.0534s/iter; left time: 3780.3036s\n",
      "3398it [03:02, 19.05it/s]\titers: 3400, epoch: 1 | loss: 0.5641545\n",
      "\tspeed: 0.0522s/iter; left time: 3689.6222s\n",
      "3498it [03:07, 19.18it/s]\titers: 3500, epoch: 1 | loss: 0.2177169\n",
      "\tspeed: 0.0521s/iter; left time: 3674.3274s\n",
      "3598it [03:12, 19.35it/s]\titers: 3600, epoch: 1 | loss: 0.3266651\n",
      "\tspeed: 0.0526s/iter; left time: 3708.8649s\n",
      "3698it [03:18, 18.60it/s]\titers: 3700, epoch: 1 | loss: 0.3373245\n",
      "\tspeed: 0.0527s/iter; left time: 3712.0426s\n",
      "3704it [03:18, 18.66it/s]\n",
      "Epoch: 1 cost time: 198.5333652496338\n",
      "801it [00:22, 36.10it/s]\n",
      "798it [00:22, 36.02it/s]\n",
      "Epoch: 1 | Train Loss: 0.4054521 Vali Loss: 0.4668616 Test Loss: 0.5954937 MAE Loss: 0.4858742\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "98it [00:05, 19.85it/s]\titers: 100, epoch: 2 | loss: 0.2681057\n",
      "\tspeed: 0.5367s/iter; left time: 37715.3197s\n",
      "198it [00:10, 19.76it/s]\titers: 200, epoch: 2 | loss: 0.4343516\n",
      "\tspeed: 0.0503s/iter; left time: 3532.9631s\n",
      "299it [00:15, 19.58it/s]\titers: 300, epoch: 2 | loss: 0.2256020\n",
      "\tspeed: 0.0502s/iter; left time: 3520.5485s\n",
      "397it [00:20, 20.06it/s]\titers: 400, epoch: 2 | loss: 0.3756625\n",
      "\tspeed: 0.0504s/iter; left time: 3525.6772s\n",
      "497it [00:25, 20.00it/s]\titers: 500, epoch: 2 | loss: 0.5589446\n",
      "\tspeed: 0.0503s/iter; left time: 3515.1834s\n",
      "598it [00:30, 19.84it/s]\titers: 600, epoch: 2 | loss: 0.5391380\n",
      "\tspeed: 0.0503s/iter; left time: 3510.5588s\n",
      "699it [00:35, 19.79it/s]\titers: 700, epoch: 2 | loss: 0.3084567\n",
      "\tspeed: 0.0501s/iter; left time: 3493.0383s\n",
      "798it [00:40, 19.82it/s]\titers: 800, epoch: 2 | loss: 0.4387231\n",
      "\tspeed: 0.0502s/iter; left time: 3490.9493s\n",
      "898it [00:45, 19.83it/s]\titers: 900, epoch: 2 | loss: 0.2520717\n",
      "\tspeed: 0.0504s/iter; left time: 3501.9361s\n",
      "997it [00:49, 23.43it/s]\titers: 1000, epoch: 2 | loss: 0.2863692\n",
      "\tspeed: 0.0452s/iter; left time: 3133.1988s\n",
      "1099it [00:54, 23.42it/s]\titers: 1100, epoch: 2 | loss: 0.3114134\n",
      "\tspeed: 0.0428s/iter; left time: 2967.1729s\n",
      "1198it [00:58, 23.43it/s]\titers: 1200, epoch: 2 | loss: 0.2413797\n",
      "\tspeed: 0.0427s/iter; left time: 2951.7623s\n",
      "1297it [01:02, 23.46it/s]\titers: 1300, epoch: 2 | loss: 0.3149279\n",
      "\tspeed: 0.0427s/iter; left time: 2948.1060s\n",
      "1399it [01:07, 23.45it/s]\titers: 1400, epoch: 2 | loss: 0.2959424\n",
      "\tspeed: 0.0427s/iter; left time: 2944.5134s\n",
      "1498it [01:11, 23.25it/s]\titers: 1500, epoch: 2 | loss: 0.2875414\n",
      "\tspeed: 0.0428s/iter; left time: 2945.7719s\n",
      "1597it [01:15, 23.29it/s]\titers: 1600, epoch: 2 | loss: 0.4039539\n",
      "\tspeed: 0.0428s/iter; left time: 2941.9594s\n",
      "1698it [01:20, 20.23it/s]\titers: 1700, epoch: 2 | loss: 0.3472232\n",
      "\tspeed: 0.0496s/iter; left time: 3406.3378s\n",
      "1797it [01:24, 23.51it/s]\titers: 1800, epoch: 2 | loss: 0.2405710\n",
      "\tspeed: 0.0438s/iter; left time: 3006.9816s\n",
      "1899it [01:29, 23.34it/s]\titers: 1900, epoch: 2 | loss: 0.4635366\n",
      "\tspeed: 0.0428s/iter; left time: 2930.2816s\n",
      "1998it [01:33, 23.39it/s]\titers: 2000, epoch: 2 | loss: 0.2646867\n",
      "\tspeed: 0.0428s/iter; left time: 2929.0117s\n",
      "2097it [01:37, 23.37it/s]\titers: 2100, epoch: 2 | loss: 0.5670242\n",
      "\tspeed: 0.0428s/iter; left time: 2922.9365s\n",
      "2199it [01:42, 23.34it/s]\titers: 2200, epoch: 2 | loss: 0.4276363\n",
      "\tspeed: 0.0428s/iter; left time: 2919.0360s\n",
      "2298it [01:46, 23.54it/s]\titers: 2300, epoch: 2 | loss: 0.4009806\n",
      "\tspeed: 0.0427s/iter; left time: 2906.3545s\n",
      "2397it [01:50, 23.29it/s]\titers: 2400, epoch: 2 | loss: 0.3583636\n",
      "\tspeed: 0.0428s/iter; left time: 2909.6070s\n",
      "2499it [01:54, 23.38it/s]\titers: 2500, epoch: 2 | loss: 0.4431607\n",
      "\tspeed: 0.0426s/iter; left time: 2894.7842s\n",
      "2598it [01:59, 23.39it/s]\titers: 2600, epoch: 2 | loss: 0.2441379\n",
      "\tspeed: 0.0427s/iter; left time: 2895.5594s\n",
      "2697it [02:03, 23.30it/s]\titers: 2700, epoch: 2 | loss: 0.2098461\n",
      "\tspeed: 0.0428s/iter; left time: 2899.4380s\n",
      "2799it [02:07, 23.35it/s]\titers: 2800, epoch: 2 | loss: 0.3505946\n",
      "\tspeed: 0.0427s/iter; left time: 2886.9267s\n",
      "2898it [02:12, 23.44it/s]\titers: 2900, epoch: 2 | loss: 0.3808426\n",
      "\tspeed: 0.0427s/iter; left time: 2880.5092s\n",
      "2997it [02:16, 23.13it/s]\titers: 3000, epoch: 2 | loss: 0.4235360\n",
      "\tspeed: 0.0432s/iter; left time: 2909.9187s\n",
      "3099it [02:20, 23.40it/s]\titers: 3100, epoch: 2 | loss: 0.3814765\n",
      "\tspeed: 0.0427s/iter; left time: 2870.0622s\n",
      "3198it [02:24, 23.53it/s]\titers: 3200, epoch: 2 | loss: 0.3062441\n",
      "\tspeed: 0.0427s/iter; left time: 2870.5019s\n",
      "3297it [02:29, 23.51it/s]\titers: 3300, epoch: 2 | loss: 0.3805599\n",
      "\tspeed: 0.0428s/iter; left time: 2869.8394s\n",
      "3399it [02:33, 23.39it/s]\titers: 3400, epoch: 2 | loss: 0.3785999\n",
      "\tspeed: 0.0428s/iter; left time: 2864.6273s\n",
      "3498it [02:37, 23.43it/s]\titers: 3500, epoch: 2 | loss: 0.2268941\n",
      "\tspeed: 0.0426s/iter; left time: 2851.1276s\n",
      "3597it [02:41, 23.48it/s]\titers: 3600, epoch: 2 | loss: 0.2483408\n",
      "\tspeed: 0.0427s/iter; left time: 2854.2400s\n",
      "3699it [02:46, 23.54it/s]\titers: 3700, epoch: 2 | loss: 0.2530798\n",
      "\tspeed: 0.0428s/iter; left time: 2853.0693s\n",
      "3704it [02:46, 22.24it/s]\n",
      "Epoch: 2 cost time: 166.5547866821289\n",
      "801it [00:19, 41.54it/s]\n",
      "798it [00:19, 41.43it/s]\n",
      "Epoch: 2 | Train Loss: 0.3584804 Vali Loss: 0.4601169 Test Loss: 0.6070074 MAE Loss: 0.4756980\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "98it [00:05, 19.68it/s]\titers: 100, epoch: 3 | loss: 0.2221248\n",
      "\tspeed: 0.4669s/iter; left time: 31080.5216s\n",
      "199it [00:10, 19.93it/s]\titers: 200, epoch: 3 | loss: 0.2708915\n",
      "\tspeed: 0.0502s/iter; left time: 3338.6071s\n",
      "298it [00:15, 19.90it/s]\titers: 300, epoch: 3 | loss: 0.3087833\n",
      "\tspeed: 0.0500s/iter; left time: 3319.7191s\n",
      "397it [00:20, 19.86it/s]\titers: 400, epoch: 3 | loss: 0.4231710\n",
      "\tspeed: 0.0500s/iter; left time: 3311.8168s\n",
      "498it [00:25, 19.92it/s]\titers: 500, epoch: 3 | loss: 0.2248602\n",
      "\tspeed: 0.0501s/iter; left time: 3314.5704s\n",
      "598it [00:30, 19.79it/s]\titers: 600, epoch: 3 | loss: 0.3257944\n",
      "\tspeed: 0.0503s/iter; left time: 3324.3720s\n",
      "699it [00:35, 19.77it/s]\titers: 700, epoch: 3 | loss: 0.4300116\n",
      "\tspeed: 0.0502s/iter; left time: 3313.3857s\n",
      "799it [00:40, 19.78it/s]\titers: 800, epoch: 3 | loss: 0.2880510\n",
      "\tspeed: 0.0506s/iter; left time: 3336.2617s\n",
      "898it [00:45, 19.77it/s]\titers: 900, epoch: 3 | loss: 0.3791609\n",
      "\tspeed: 0.0508s/iter; left time: 3344.0410s\n",
      "997it [00:50, 20.08it/s]\titers: 1000, epoch: 3 | loss: 0.3540645\n",
      "\tspeed: 0.0505s/iter; left time: 3315.6543s\n",
      "1098it [00:55, 19.81it/s]\titers: 1100, epoch: 3 | loss: 0.4958504\n",
      "\tspeed: 0.0503s/iter; left time: 3299.4714s\n",
      "1198it [01:00, 19.78it/s]\titers: 1200, epoch: 3 | loss: 0.3193567\n",
      "\tspeed: 0.0503s/iter; left time: 3295.4464s\n",
      "1299it [01:05, 19.83it/s]\titers: 1300, epoch: 3 | loss: 0.3404786\n",
      "\tspeed: 0.0504s/iter; left time: 3291.9683s\n",
      "1398it [01:10, 19.85it/s]\titers: 1400, epoch: 3 | loss: 0.5753043\n",
      "\tspeed: 0.0503s/iter; left time: 3283.5556s\n",
      "1498it [01:15, 19.91it/s]\titers: 1500, epoch: 3 | loss: 0.5255642\n",
      "\tspeed: 0.0500s/iter; left time: 3260.0764s\n",
      "1599it [01:20, 19.94it/s]\titers: 1600, epoch: 3 | loss: 0.5402439\n",
      "\tspeed: 0.0501s/iter; left time: 3262.5146s\n",
      "1698it [01:25, 19.95it/s]\titers: 1700, epoch: 3 | loss: 0.3224945\n",
      "\tspeed: 0.0501s/iter; left time: 3256.9586s\n",
      "1798it [01:30, 20.00it/s]\titers: 1800, epoch: 3 | loss: 0.1992101\n",
      "\tspeed: 0.0505s/iter; left time: 3273.8161s\n",
      "1898it [01:35, 19.78it/s]\titers: 1900, epoch: 3 | loss: 0.3166184\n",
      "\tspeed: 0.0504s/iter; left time: 3263.3038s\n",
      "1998it [01:40, 19.82it/s]\titers: 2000, epoch: 3 | loss: 0.2978621\n",
      "\tspeed: 0.0503s/iter; left time: 3252.1849s\n",
      "2097it [01:45, 20.10it/s]\titers: 2100, epoch: 3 | loss: 0.3691386\n",
      "\tspeed: 0.0503s/iter; left time: 3248.3729s\n",
      "2198it [01:50, 19.89it/s]\titers: 2200, epoch: 3 | loss: 0.2718411\n",
      "\tspeed: 0.0504s/iter; left time: 3247.0950s\n",
      "2297it [01:55, 20.04it/s]\titers: 2300, epoch: 3 | loss: 0.3401999\n",
      "\tspeed: 0.0503s/iter; left time: 3239.0539s\n",
      "2398it [02:00, 19.82it/s]\titers: 2400, epoch: 3 | loss: 0.4892381\n",
      "\tspeed: 0.0504s/iter; left time: 3237.7224s\n",
      "2498it [02:05, 19.94it/s]\titers: 2500, epoch: 3 | loss: 0.3578659\n",
      "\tspeed: 0.0502s/iter; left time: 3223.2591s\n",
      "2599it [02:11, 19.80it/s]\titers: 2600, epoch: 3 | loss: 0.3652331\n",
      "\tspeed: 0.0502s/iter; left time: 3216.9640s\n",
      "2698it [02:15, 19.87it/s]\titers: 2700, epoch: 3 | loss: 0.2065698\n",
      "\tspeed: 0.0503s/iter; left time: 3218.5546s\n",
      "2799it [02:21, 19.78it/s]\titers: 2800, epoch: 3 | loss: 0.2362365\n",
      "\tspeed: 0.0503s/iter; left time: 3211.7285s\n",
      "2899it [02:26, 19.81it/s]\titers: 2900, epoch: 3 | loss: 0.4617788\n",
      "\tspeed: 0.0505s/iter; left time: 3218.3224s\n",
      "2998it [02:31, 19.81it/s]\titers: 3000, epoch: 3 | loss: 0.3151016\n",
      "\tspeed: 0.0504s/iter; left time: 3206.5702s\n",
      "3099it [02:36, 19.84it/s]\titers: 3100, epoch: 3 | loss: 0.5195781\n",
      "\tspeed: 0.0503s/iter; left time: 3200.4750s\n",
      "3199it [02:41, 19.91it/s]\titers: 3200, epoch: 3 | loss: 0.2099432\n",
      "\tspeed: 0.0503s/iter; left time: 3195.6073s\n",
      "3298it [02:46, 19.79it/s]\titers: 3300, epoch: 3 | loss: 0.3337395\n",
      "\tspeed: 0.0505s/iter; left time: 3200.2599s\n",
      "3398it [02:51, 20.04it/s]\titers: 3400, epoch: 3 | loss: 0.2839755\n",
      "\tspeed: 0.0503s/iter; left time: 3184.6585s\n",
      "3498it [02:56, 19.98it/s]\titers: 3500, epoch: 3 | loss: 0.1948923\n",
      "\tspeed: 0.0500s/iter; left time: 3158.1143s\n",
      "3597it [03:01, 20.09it/s]\titers: 3600, epoch: 3 | loss: 0.5332850\n",
      "\tspeed: 0.0499s/iter; left time: 3144.9515s\n",
      "3698it [03:06, 19.93it/s]\titers: 3700, epoch: 3 | loss: 0.2087279\n",
      "\tspeed: 0.0502s/iter; left time: 3159.2614s\n",
      "3704it [03:06, 19.85it/s]\n",
      "Epoch: 3 cost time: 186.6031153202057\n",
      "801it [00:19, 41.72it/s]\n",
      "798it [00:19, 41.36it/s]\n",
      "Epoch: 3 | Train Loss: 0.3351687 Vali Loss: 0.4607436 Test Loss: 0.5973320 MAE Loss: 0.4717305\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "98it [00:05, 19.82it/s]\titers: 100, epoch: 4 | loss: 0.3880310\n",
      "\tspeed: 0.4442s/iter; left time: 27928.0693s\n",
      "198it [00:10, 19.71it/s]\titers: 200, epoch: 4 | loss: 0.3108150\n",
      "\tspeed: 0.0503s/iter; left time: 3160.3568s\n",
      "299it [00:15, 19.78it/s]\titers: 300, epoch: 4 | loss: 0.2787597\n",
      "\tspeed: 0.0505s/iter; left time: 3166.0638s\n",
      "397it [00:20, 19.78it/s]\titers: 400, epoch: 4 | loss: 0.3843335\n",
      "\tspeed: 0.0505s/iter; left time: 3159.0371s\n",
      "498it [00:25, 19.77it/s]\titers: 500, epoch: 4 | loss: 0.4073288\n",
      "\tspeed: 0.0504s/iter; left time: 3149.2856s\n",
      "598it [00:30, 19.81it/s]\titers: 600, epoch: 4 | loss: 0.3482420\n",
      "\tspeed: 0.0505s/iter; left time: 3151.3253s\n",
      "698it [00:35, 19.82it/s]\titers: 700, epoch: 4 | loss: 0.1922983\n",
      "\tspeed: 0.0503s/iter; left time: 3130.7974s\n",
      "798it [00:40, 19.82it/s]\titers: 800, epoch: 4 | loss: 0.2529073\n",
      "\tspeed: 0.0505s/iter; left time: 3142.0827s\n",
      "899it [00:45, 19.79it/s]\titers: 900, epoch: 4 | loss: 0.2426165\n",
      "\tspeed: 0.0505s/iter; left time: 3134.7631s\n",
      "999it [00:50, 19.97it/s]\titers: 1000, epoch: 4 | loss: 0.3319871\n",
      "\tspeed: 0.0502s/iter; left time: 3113.0480s\n",
      "1098it [00:55, 19.79it/s]\titers: 1100, epoch: 4 | loss: 0.2638730\n",
      "\tspeed: 0.0505s/iter; left time: 3121.6820s\n",
      "1199it [01:00, 19.77it/s]\titers: 1200, epoch: 4 | loss: 0.2304963\n",
      "\tspeed: 0.0506s/iter; left time: 3123.7054s\n",
      "1298it [01:05, 19.81it/s]\titers: 1300, epoch: 4 | loss: 0.2255826\n",
      "\tspeed: 0.0507s/iter; left time: 3123.6168s\n",
      "1398it [01:10, 19.80it/s]\titers: 1400, epoch: 4 | loss: 0.2508558\n",
      "\tspeed: 0.0505s/iter; left time: 3112.2411s\n",
      "1498it [01:15, 19.78it/s]\titers: 1500, epoch: 4 | loss: 0.2034351\n",
      "\tspeed: 0.0505s/iter; left time: 3105.7429s\n",
      "1598it [01:20, 19.79it/s]\titers: 1600, epoch: 4 | loss: 0.4089696\n",
      "\tspeed: 0.0505s/iter; left time: 3102.0489s\n",
      "1698it [01:25, 19.75it/s]\titers: 1700, epoch: 4 | loss: 0.3527075\n",
      "\tspeed: 0.0506s/iter; left time: 3100.6589s\n",
      "1798it [01:31, 20.15it/s]\titers: 1800, epoch: 4 | loss: 0.2091527\n",
      "\tspeed: 0.0503s/iter; left time: 3074.2237s\n",
      "1899it [01:36, 19.79it/s]\titers: 1900, epoch: 4 | loss: 0.4152802\n",
      "\tspeed: 0.0507s/iter; left time: 3094.4441s\n",
      "1998it [01:41, 19.80it/s]\titers: 2000, epoch: 4 | loss: 0.3145154\n",
      "\tspeed: 0.0505s/iter; left time: 3081.1806s\n",
      "2099it [01:46, 19.79it/s]\titers: 2100, epoch: 4 | loss: 0.2314731\n",
      "\tspeed: 0.0505s/iter; left time: 3076.0707s\n",
      "2198it [01:51, 19.80it/s]\titers: 2200, epoch: 4 | loss: 0.3815633\n",
      "\tspeed: 0.0505s/iter; left time: 3070.8064s\n",
      "2299it [01:56, 19.79it/s]\titers: 2300, epoch: 4 | loss: 0.2775665\n",
      "\tspeed: 0.0505s/iter; left time: 3066.4004s\n",
      "2399it [02:01, 19.81it/s]\titers: 2400, epoch: 4 | loss: 0.3916576\n",
      "\tspeed: 0.0505s/iter; left time: 3060.2999s\n",
      "2499it [02:06, 19.80it/s]\titers: 2500, epoch: 4 | loss: 0.2535008\n",
      "\tspeed: 0.0505s/iter; left time: 3052.5787s\n",
      "2597it [02:11, 19.87it/s]\titers: 2600, epoch: 4 | loss: 0.3491861\n",
      "\tspeed: 0.0501s/iter; left time: 3021.5088s\n",
      "2697it [02:16, 20.11it/s]\titers: 2700, epoch: 4 | loss: 0.2625010\n",
      "\tspeed: 0.0501s/iter; left time: 3020.8621s\n",
      "2798it [02:21, 19.96it/s]\titers: 2800, epoch: 4 | loss: 0.2058029\n",
      "\tspeed: 0.0503s/iter; left time: 3026.9081s\n",
      "2897it [02:26, 20.10it/s]\titers: 2900, epoch: 4 | loss: 0.4313609\n",
      "\tspeed: 0.0500s/iter; left time: 3004.9626s\n",
      "2998it [02:31, 19.78it/s]\titers: 3000, epoch: 4 | loss: 0.5291396\n",
      "\tspeed: 0.0502s/iter; left time: 3012.7484s\n",
      "3097it [02:36, 20.04it/s]\titers: 3100, epoch: 4 | loss: 0.2566871\n",
      "\tspeed: 0.0501s/iter; left time: 3001.1786s\n",
      "3199it [02:41, 19.86it/s]\titers: 3200, epoch: 4 | loss: 0.3481719\n",
      "\tspeed: 0.0503s/iter; left time: 3005.5595s\n",
      "3298it [02:46, 19.84it/s]\titers: 3300, epoch: 4 | loss: 0.3199565\n",
      "\tspeed: 0.0503s/iter; left time: 3000.9213s\n",
      "3398it [02:51, 19.93it/s]\titers: 3400, epoch: 4 | loss: 0.2152870\n",
      "\tspeed: 0.0501s/iter; left time: 2985.2972s\n",
      "3498it [02:56, 19.83it/s]\titers: 3500, epoch: 4 | loss: 0.4139068\n",
      "\tspeed: 0.0502s/iter; left time: 2984.6054s\n",
      "3598it [03:01, 19.86it/s]\titers: 3600, epoch: 4 | loss: 0.3341966\n",
      "\tspeed: 0.0502s/iter; left time: 2981.7715s\n",
      "3698it [03:06, 19.86it/s]\titers: 3700, epoch: 4 | loss: 0.3596921\n",
      "\tspeed: 0.0503s/iter; left time: 2983.5835s\n",
      "3704it [03:06, 19.81it/s]\n",
      "Epoch: 4 cost time: 186.99164080619812\n",
      "801it [00:19, 40.21it/s]\n",
      "798it [00:19, 40.99it/s]\n",
      "Epoch: 4 | Train Loss: 0.3201757 Vali Loss: 0.4635207 Test Loss: 0.6046352 MAE Loss: 0.4830727\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "97it [00:04, 23.35it/s]\titers: 100, epoch: 5 | loss: 0.2359943\n",
      "\tspeed: 0.4450s/iter; left time: 26328.4976s\n",
      "199it [00:08, 23.46it/s]\titers: 200, epoch: 5 | loss: 0.3167121\n",
      "\tspeed: 0.0428s/iter; left time: 2527.0535s\n",
      "298it [00:13, 23.33it/s]\titers: 300, epoch: 5 | loss: 0.2393951\n",
      "\tspeed: 0.0428s/iter; left time: 2526.2723s\n",
      "397it [00:17, 22.30it/s]\titers: 400, epoch: 5 | loss: 0.4431411\n",
      "\tspeed: 0.0449s/iter; left time: 2643.4085s\n",
      "499it [00:21, 23.30it/s]\titers: 500, epoch: 5 | loss: 0.2193561\n",
      "\tspeed: 0.0429s/iter; left time: 2521.0494s\n",
      "598it [00:26, 23.36it/s]\titers: 600, epoch: 5 | loss: 0.2968115\n",
      "\tspeed: 0.0429s/iter; left time: 2517.8933s\n",
      "697it [00:30, 23.26it/s]\titers: 700, epoch: 5 | loss: 0.5240078\n",
      "\tspeed: 0.0430s/iter; left time: 2519.0181s\n",
      "799it [00:34, 23.08it/s]\titers: 800, epoch: 5 | loss: 0.2400572\n",
      "\tspeed: 0.0430s/iter; left time: 2511.2459s\n",
      "898it [00:39, 23.28it/s]\titers: 900, epoch: 5 | loss: 0.2995527\n",
      "\tspeed: 0.0429s/iter; left time: 2505.2545s\n",
      "997it [00:43, 23.37it/s]\titers: 1000, epoch: 5 | loss: 0.4046963\n",
      "\tspeed: 0.0429s/iter; left time: 2499.2968s\n",
      "1099it [00:47, 23.25it/s]\titers: 1100, epoch: 5 | loss: 0.4085477\n",
      "\tspeed: 0.0429s/iter; left time: 2495.4689s\n",
      "1198it [00:51, 23.31it/s]\titers: 1200, epoch: 5 | loss: 0.5284631\n",
      "\tspeed: 0.0428s/iter; left time: 2488.0566s\n",
      "1297it [00:56, 23.35it/s]\titers: 1300, epoch: 5 | loss: 0.2835044\n",
      "\tspeed: 0.0428s/iter; left time: 2480.5170s\n",
      "1399it [01:00, 23.33it/s]\titers: 1400, epoch: 5 | loss: 0.4967519\n",
      "\tspeed: 0.0429s/iter; left time: 2484.2812s\n",
      "1498it [01:04, 23.36it/s]\titers: 1500, epoch: 5 | loss: 0.2430444\n",
      "\tspeed: 0.0428s/iter; left time: 2470.8156s\n",
      "1597it [01:08, 23.47it/s]\titers: 1600, epoch: 5 | loss: 0.2636428\n",
      "\tspeed: 0.0428s/iter; left time: 2466.6682s\n",
      "1699it [01:13, 23.35it/s]\titers: 1700, epoch: 5 | loss: 0.4190512\n",
      "\tspeed: 0.0428s/iter; left time: 2466.1364s\n",
      "1798it [01:17, 23.36it/s]\titers: 1800, epoch: 5 | loss: 0.2351682\n",
      "\tspeed: 0.0429s/iter; left time: 2467.1819s\n",
      "1897it [01:21, 23.45it/s]\titers: 1900, epoch: 5 | loss: 0.3332414\n",
      "\tspeed: 0.0428s/iter; left time: 2456.1888s\n",
      "1999it [01:26, 23.32it/s]\titers: 2000, epoch: 5 | loss: 0.2260720\n",
      "\tspeed: 0.0429s/iter; left time: 2457.9494s\n",
      "2098it [01:30, 23.27it/s]\titers: 2100, epoch: 5 | loss: 0.4405123\n",
      "\tspeed: 0.0429s/iter; left time: 2451.6733s\n",
      "2197it [01:34, 23.45it/s]\titers: 2200, epoch: 5 | loss: 0.3217337\n",
      "\tspeed: 0.0429s/iter; left time: 2449.1123s\n",
      "2299it [01:39, 23.27it/s]\titers: 2300, epoch: 5 | loss: 0.1710387\n",
      "\tspeed: 0.0428s/iter; left time: 2439.0445s\n",
      "2398it [01:43, 23.28it/s]\titers: 2400, epoch: 5 | loss: 0.3098585\n",
      "\tspeed: 0.0429s/iter; left time: 2438.9965s\n",
      "2497it [01:47, 20.45it/s]\titers: 2500, epoch: 5 | loss: 0.2922665\n",
      "\tspeed: 0.0441s/iter; left time: 2503.8878s\n",
      "2597it [01:52, 20.03it/s]\titers: 2600, epoch: 5 | loss: 0.3190425\n",
      "\tspeed: 0.0500s/iter; left time: 2835.4585s\n",
      "2699it [01:57, 20.03it/s]\titers: 2700, epoch: 5 | loss: 0.3740696\n",
      "\tspeed: 0.0500s/iter; left time: 2829.8322s\n",
      "2797it [02:02, 20.02it/s]\titers: 2800, epoch: 5 | loss: 0.1854866\n",
      "\tspeed: 0.0501s/iter; left time: 2828.3280s\n",
      "2899it [02:07, 20.10it/s]\titers: 2900, epoch: 5 | loss: 0.4202749\n",
      "\tspeed: 0.0499s/iter; left time: 2814.2135s\n",
      "2998it [02:12, 19.96it/s]\titers: 3000, epoch: 5 | loss: 0.2912006\n",
      "\tspeed: 0.0501s/iter; left time: 2816.2101s\n",
      "3099it [02:17, 19.83it/s]\titers: 3100, epoch: 5 | loss: 0.3069955\n",
      "\tspeed: 0.0501s/iter; left time: 2814.4159s\n",
      "3197it [02:22, 20.06it/s]\titers: 3200, epoch: 5 | loss: 0.5091502\n",
      "\tspeed: 0.0501s/iter; left time: 2808.2570s\n",
      "3299it [02:27, 19.91it/s]\titers: 3300, epoch: 5 | loss: 0.2460854\n",
      "\tspeed: 0.0499s/iter; left time: 2794.5385s\n",
      "3399it [02:32, 19.99it/s]\titers: 3400, epoch: 5 | loss: 0.3382645\n",
      "\tspeed: 0.0500s/iter; left time: 2790.6312s\n",
      "3499it [02:37, 20.20it/s]\titers: 3500, epoch: 5 | loss: 0.2759967\n",
      "\tspeed: 0.0500s/iter; left time: 2786.5607s\n",
      "3599it [02:42, 19.92it/s]\titers: 3600, epoch: 5 | loss: 0.1895376\n",
      "\tspeed: 0.0505s/iter; left time: 2810.5655s\n",
      "3699it [02:47, 20.00it/s]\titers: 3700, epoch: 5 | loss: 0.2388311\n",
      "\tspeed: 0.0504s/iter; left time: 2798.9554s\n",
      "3704it [02:48, 22.02it/s]\n",
      "Epoch: 5 cost time: 168.17836260795593\n",
      "801it [00:19, 41.60it/s]\n",
      "798it [00:20, 39.40it/s]\n",
      "Epoch: 5 | Train Loss: 0.3108096 Vali Loss: 0.4655517 Test Loss: 0.6063247 MAE Loss: 0.4846382\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 18.93258905808131 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 04:13:31,024] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 04:13:32,051] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 04:13:32,052] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 04:13:34,157] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 04:13:34,760] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 04:13:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 04:13:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 04:13:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 04:13:34,762] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 04:13:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 04:13:34,762] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 04:13:34,762] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 04:13:34,762] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 04:13:34,762] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 04:13:35,015] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 04:13:35,015] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-07 04:13:35,016] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 167.21 GB, percent = 22.2%\n",
      "[2024-05-07 04:13:35,153] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 04:13:35,154] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 04:13:35,154] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 167.33 GB, percent = 22.2%\n",
      "[2024-05-07 04:13:35,155] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 04:13:35,279] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 04:13:35,280] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 04:13:35,280] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 167.52 GB, percent = 22.2%\n",
      "[2024-05-07 04:13:35,280] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 04:13:35,280] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 04:13:35,280] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 04:13:35,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7feca488ead0>\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 04:13:35,281] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   train_batch_size ............. 256\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  256\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 04:13:35,282] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 256, \n",
      "    \"train_micro_batch_size_per_gpu\": 256, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:53,  1.81it/s]\titers: 100, epoch: 1 | loss: 0.7924910\n",
      "\tspeed: 0.5533s/iter; left time: 3796.2111s\n",
      "199it [01:47,  1.93it/s]\titers: 200, epoch: 1 | loss: 0.8146667\n",
      "\tspeed: 0.5340s/iter; left time: 3610.6086s\n",
      "299it [02:39,  1.89it/s]\titers: 300, epoch: 1 | loss: 0.4022322\n",
      "\tspeed: 0.5270s/iter; left time: 3510.1473s\n",
      "348it [03:05,  1.87it/s]\n",
      "Epoch: 1 cost time: 185.6590132713318\n",
      "75it [00:24,  3.11it/s]\n",
      "75it [00:24,  3.02it/s]\n",
      "Epoch: 1 | Train Loss: 0.7335863 Vali Loss: 0.4286170 Test Loss: 0.5148269 MAE Loss: 0.4875044\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:49,  1.90it/s]\titers: 100, epoch: 2 | loss: 0.2892886\n",
      "\tspeed: 1.2618s/iter; left time: 8218.1652s\n",
      "199it [01:39,  1.98it/s]\titers: 200, epoch: 2 | loss: 0.2372673\n",
      "\tspeed: 0.4947s/iter; left time: 3172.2212s\n",
      "299it [02:27,  2.00it/s]\titers: 300, epoch: 2 | loss: 0.2764629\n",
      "\tspeed: 0.4879s/iter; left time: 3079.8727s\n",
      "348it [02:52,  2.02it/s]\n",
      "Epoch: 2 cost time: 172.40239191055298\n",
      "75it [00:21,  3.42it/s]\n",
      "75it [00:21,  3.46it/s]\n",
      "Epoch: 2 | Train Loss: 0.2950241 Vali Loss: 0.3102634 Test Loss: 0.3623776 MAE Loss: 0.3871454\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:49,  2.08it/s]\titers: 100, epoch: 3 | loss: 0.2823599\n",
      "\tspeed: 1.1945s/iter; left time: 7364.2863s\n",
      "199it [01:37,  2.10it/s]\titers: 200, epoch: 3 | loss: 0.2535993\n",
      "\tspeed: 0.4862s/iter; left time: 2949.0150s\n",
      "299it [02:26,  2.09it/s]\titers: 300, epoch: 3 | loss: 0.2804884\n",
      "\tspeed: 0.4881s/iter; left time: 2911.6129s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 3 cost time: 170.90554809570312\n",
      "75it [00:21,  3.51it/s]\n",
      "75it [00:21,  3.46it/s]\n",
      "Epoch: 3 | Train Loss: 0.2674387 Vali Loss: 0.3076874 Test Loss: 0.3612001 MAE Loss: 0.3886420\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:48,  2.07it/s]\titers: 100, epoch: 4 | loss: 0.2620426\n",
      "\tspeed: 1.1827s/iter; left time: 6879.4971s\n",
      "199it [01:37,  2.08it/s]\titers: 200, epoch: 4 | loss: 0.2317601\n",
      "\tspeed: 0.4878s/iter; left time: 2788.9959s\n",
      "299it [02:26,  2.02it/s]\titers: 300, epoch: 4 | loss: 0.2485865\n",
      "\tspeed: 0.4929s/iter; left time: 2768.4722s\n",
      "348it [02:51,  2.03it/s]\n",
      "Epoch: 4 cost time: 171.27495503425598\n",
      "75it [00:21,  3.42it/s]\n",
      "75it [00:21,  3.47it/s]\n",
      "Epoch: 4 | Train Loss: 0.2618203 Vali Loss: 0.2993182 Test Loss: 0.3491780 MAE Loss: 0.3742798\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:49,  2.00it/s]\titers: 100, epoch: 5 | loss: 0.2884774\n",
      "\tspeed: 1.1919s/iter; left time: 6518.3799s\n",
      "199it [01:38,  2.07it/s]\titers: 200, epoch: 5 | loss: 0.2609696\n",
      "\tspeed: 0.4938s/iter; left time: 2651.1212s\n",
      "299it [02:26,  2.07it/s]\titers: 300, epoch: 5 | loss: 0.2586366\n",
      "\tspeed: 0.4808s/iter; left time: 2533.5552s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 5 cost time: 170.8090627193451\n",
      "75it [00:21,  3.50it/s]\n",
      "75it [00:21,  3.55it/s]\n",
      "Epoch: 5 | Train Loss: 0.2594115 Vali Loss: 0.2987600 Test Loss: 0.3470569 MAE Loss: 0.3723963\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:49,  2.01it/s]\titers: 100, epoch: 6 | loss: 0.2288424\n",
      "\tspeed: 1.1758s/iter; left time: 6021.3236s\n",
      "199it [01:38,  2.11it/s]\titers: 200, epoch: 6 | loss: 0.2506319\n",
      "\tspeed: 0.4915s/iter; left time: 2467.6617s\n",
      "299it [02:26,  2.00it/s]\titers: 300, epoch: 6 | loss: 0.2732101\n",
      "\tspeed: 0.4865s/iter; left time: 2394.2664s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 6 cost time: 170.84989285469055\n",
      "75it [00:21,  3.43it/s]\n",
      "75it [00:21,  3.54it/s]\n",
      "Epoch: 6 | Train Loss: 0.2574476 Vali Loss: 0.2975944 Test Loss: 0.3470358 MAE Loss: 0.3726654\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:49,  2.11it/s]\titers: 100, epoch: 7 | loss: 0.2826740\n",
      "\tspeed: 1.1773s/iter; left time: 5619.1275s\n",
      "199it [01:38,  2.03it/s]\titers: 200, epoch: 7 | loss: 0.2579176\n",
      "\tspeed: 0.4947s/iter; left time: 2311.7460s\n",
      "299it [02:27,  2.05it/s]\titers: 300, epoch: 7 | loss: 0.2547844\n",
      "\tspeed: 0.4891s/iter; left time: 2236.5507s\n",
      "348it [02:51,  2.03it/s]\n",
      "Epoch: 7 cost time: 171.4683392047882\n",
      "75it [00:21,  3.42it/s]\n",
      "75it [00:21,  3.52it/s]\n",
      "Epoch: 7 | Train Loss: 0.2575966 Vali Loss: 0.2980080 Test Loss: 0.3464064 MAE Loss: 0.3700639\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:48,  2.03it/s]\titers: 100, epoch: 8 | loss: 0.2269270\n",
      "\tspeed: 1.1595s/iter; left time: 5130.6049s\n",
      "199it [01:37,  2.06it/s]\titers: 200, epoch: 8 | loss: 0.2126721\n",
      "\tspeed: 0.4866s/iter; left time: 2104.5583s\n",
      "299it [02:26,  1.92it/s]\titers: 300, epoch: 8 | loss: 0.2390753\n",
      "\tspeed: 0.4893s/iter; left time: 2067.4057s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 8 cost time: 170.43771648406982\n",
      "75it [00:21,  3.43it/s]\n",
      "75it [00:21,  3.51it/s]\n",
      "Epoch: 8 | Train Loss: 0.2568925 Vali Loss: 0.2971834 Test Loss: 0.3454415 MAE Loss: 0.3709200\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [00:49,  1.97it/s]\titers: 100, epoch: 9 | loss: 0.2594174\n",
      "\tspeed: 1.1813s/iter; left time: 4815.9618s\n",
      "199it [01:38,  2.11it/s]\titers: 200, epoch: 9 | loss: 0.2434006\n",
      "\tspeed: 0.4937s/iter; left time: 1963.2935s\n",
      "299it [02:28,  1.98it/s]\titers: 300, epoch: 9 | loss: 0.2900310\n",
      "\tspeed: 0.4941s/iter; left time: 1915.6502s\n",
      "348it [02:52,  2.02it/s]\n",
      "Epoch: 9 cost time: 172.36468076705933\n",
      "75it [00:22,  3.38it/s]\n",
      "75it [00:21,  3.49it/s]\n",
      "Epoch: 9 | Train Loss: 0.2563906 Vali Loss: 0.2961416 Test Loss: 0.3452539 MAE Loss: 0.3702572\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [00:49,  2.08it/s]\titers: 100, epoch: 10 | loss: 0.2604442\n",
      "\tspeed: 1.1875s/iter; left time: 4428.0647s\n",
      "199it [01:38,  2.06it/s]\titers: 200, epoch: 10 | loss: 0.2561238\n",
      "\tspeed: 0.4908s/iter; left time: 1781.0296s\n",
      "299it [02:27,  2.07it/s]\titers: 300, epoch: 10 | loss: 0.2330354\n",
      "\tspeed: 0.4954s/iter; left time: 1748.2806s\n",
      "348it [02:51,  2.03it/s]\n",
      "Epoch: 10 cost time: 171.67270731925964\n",
      "75it [00:21,  3.47it/s]\n",
      "75it [00:21,  3.51it/s]\n",
      "Epoch: 10 | Train Loss: 0.2572500 Vali Loss: 0.2973907 Test Loss: 0.3455891 MAE Loss: 0.3704735\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 7.812499999999999e-08\n",
      "99it [00:49,  2.08it/s]\titers: 100, epoch: 11 | loss: 0.2504212\n",
      "\tspeed: 1.1642s/iter; left time: 3936.0059s\n",
      "199it [01:37,  2.09it/s]\titers: 200, epoch: 11 | loss: 0.3085657\n",
      "\tspeed: 0.4823s/iter; left time: 1582.5337s\n",
      "299it [02:26,  2.05it/s]\titers: 300, epoch: 11 | loss: 0.2211960\n",
      "\tspeed: 0.4882s/iter; left time: 1552.9166s\n",
      "348it [02:50,  2.05it/s]\n",
      "Epoch: 11 cost time: 170.13866305351257\n",
      "75it [00:21,  3.48it/s]\n",
      "75it [00:21,  3.51it/s]\n",
      "Epoch: 11 | Train Loss: 0.2569707 Vali Loss: 0.2960816 Test Loss: 0.3457005 MAE Loss: 0.3706421\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9062499999999997e-08\n",
      "99it [00:48,  2.01it/s]\titers: 100, epoch: 12 | loss: 0.2714269\n",
      "\tspeed: 1.1639s/iter; left time: 3530.1240s\n",
      "199it [01:36,  2.09it/s]\titers: 200, epoch: 12 | loss: 0.2932100\n",
      "\tspeed: 0.4842s/iter; left time: 1420.2491s\n",
      "299it [02:25,  2.12it/s]\titers: 300, epoch: 12 | loss: 0.2513402\n",
      "\tspeed: 0.4876s/iter; left time: 1381.3725s\n",
      "348it [02:49,  2.05it/s]\n",
      "Epoch: 12 cost time: 169.766592502594\n",
      "75it [00:22,  3.38it/s]\n",
      "75it [00:21,  3.48it/s]\n",
      "Epoch: 12 | Train Loss: 0.2562508 Vali Loss: 0.2976863 Test Loss: 0.3455568 MAE Loss: 0.3705397\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9531249999999998e-08\n",
      "99it [00:48,  2.11it/s]\titers: 100, epoch: 13 | loss: 0.3033277\n",
      "\tspeed: 1.1699s/iter; left time: 3141.1299s\n",
      "199it [01:37,  2.06it/s]\titers: 200, epoch: 13 | loss: 0.2334814\n",
      "\tspeed: 0.4867s/iter; left time: 1258.1864s\n",
      "299it [02:26,  2.01it/s]\titers: 300, epoch: 13 | loss: 0.2872292\n",
      "\tspeed: 0.4883s/iter; left time: 1213.3848s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 13 cost time: 170.94944214820862\n",
      "75it [00:21,  3.49it/s]\n",
      "75it [00:21,  3.52it/s]\n",
      "Epoch: 13 | Train Loss: 0.2563445 Vali Loss: 0.2969681 Test Loss: 0.3455251 MAE Loss: 0.3704900\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.765624999999999e-09\n",
      "99it [00:49,  1.97it/s]\titers: 100, epoch: 14 | loss: 0.2154903\n",
      "\tspeed: 1.1656s/iter; left time: 2724.0218s\n",
      "199it [01:38,  2.04it/s]\titers: 200, epoch: 14 | loss: 0.2443887\n",
      "\tspeed: 0.4887s/iter; left time: 1093.1530s\n",
      "299it [02:27,  1.94it/s]\titers: 300, epoch: 14 | loss: 0.2181189\n",
      "\tspeed: 0.4940s/iter; left time: 1055.6725s\n",
      "348it [02:51,  2.03it/s]\n",
      "Epoch: 14 cost time: 171.415922164917\n",
      "75it [00:21,  3.43it/s]\n",
      "75it [00:22,  3.39it/s]\n",
      "Epoch: 14 | Train Loss: 0.2560277 Vali Loss: 0.2966712 Test Loss: 0.3455086 MAE Loss: 0.3704474\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 50.942139240105945 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=12 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=256\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 05:04:28,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 05:04:30,308] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 05:04:30,308] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-07 05:04:33,757] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 05:04:34,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 05:04:34,766] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 05:04:34,766] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 05:04:34,767] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 05:04:34,767] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 05:04:34,767] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 05:04:34,767] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 05:04:34,767] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 05:04:34,767] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 05:04:34,767] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 05:04:35,025] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 05:04:35,025] [INFO] [utils.py:801:see_memory_usage] MA 0.7 GB         Max_MA 0.8 GB         CA 0.83 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:04:35,026] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 172.46 GB, percent = 22.9%\n",
      "[2024-05-07 05:04:35,149] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 05:04:35,149] [INFO] [utils.py:801:see_memory_usage] MA 0.7 GB         Max_MA 0.9 GB         CA 1.03 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:04:35,149] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 172.46 GB, percent = 22.9%\n",
      "[2024-05-07 05:04:35,149] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 05:04:35,258] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 05:04:35,258] [INFO] [utils.py:801:see_memory_usage] MA 0.7 GB         Max_MA 0.7 GB         CA 1.03 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:04:35,258] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 172.48 GB, percent = 22.9%\n",
      "[2024-05-07 05:04:35,259] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 05:04:35,259] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 05:04:35,259] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 05:04:35,259] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 05:04:35,259] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8fccc6ed10>\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 05:04:35,260] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   train_batch_size ............. 256\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  256\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 05:04:35,261] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 256, \n",
      "    \"train_micro_batch_size_per_gpu\": 256, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [01:08,  1.40it/s]\titers: 100, epoch: 1 | loss: 0.3439665\n",
      "\tspeed: 0.7004s/iter; left time: 4805.2736s\n",
      "199it [02:16,  1.49it/s]\titers: 200, epoch: 1 | loss: 0.3402621\n",
      "\tspeed: 0.6854s/iter; left time: 4634.1482s\n",
      "299it [03:23,  1.46it/s]\titers: 300, epoch: 1 | loss: 0.2647491\n",
      "\tspeed: 0.6733s/iter; left time: 4484.7595s\n",
      "348it [03:57,  1.47it/s]\n",
      "Epoch: 1 cost time: 237.3211510181427\n",
      "75it [00:30,  2.48it/s]\n",
      "75it [00:29,  2.52it/s]\n",
      "Epoch: 1 | Train Loss: 0.3659654 Vali Loss: 0.3242963 Test Loss: 0.3814572 MAE Loss: 0.4000934\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [01:02,  1.60it/s]\titers: 100, epoch: 2 | loss: 0.3152560\n",
      "\tspeed: 1.5822s/iter; left time: 10305.1414s\n",
      "199it [02:06,  1.60it/s]\titers: 200, epoch: 2 | loss: 0.2853609\n",
      "\tspeed: 0.6325s/iter; left time: 4056.0787s\n",
      "299it [03:09,  1.60it/s]\titers: 300, epoch: 2 | loss: 0.2702471\n",
      "\tspeed: 0.6305s/iter; left time: 3980.1631s\n",
      "348it [03:40,  1.58it/s]\n",
      "Epoch: 2 cost time: 220.32050728797913\n",
      "75it [00:27,  2.73it/s]\n",
      "75it [00:27,  2.75it/s]\n",
      "Epoch: 2 | Train Loss: 0.2699270 Vali Loss: 0.3145793 Test Loss: 0.3695414 MAE Loss: 0.3861847\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [01:04,  1.48it/s]\titers: 100, epoch: 3 | loss: 0.2767274\n",
      "\tspeed: 1.5268s/iter; left time: 9413.0129s\n",
      "199it [02:09,  1.59it/s]\titers: 200, epoch: 3 | loss: 0.2755283\n",
      "\tspeed: 0.6452s/iter; left time: 3913.3278s\n",
      "299it [03:14,  1.52it/s]\titers: 300, epoch: 3 | loss: 0.2490387\n",
      "\tspeed: 0.6502s/iter; left time: 3878.2790s\n",
      "348it [03:45,  1.54it/s]\n",
      "Epoch: 3 cost time: 225.3813202381134\n",
      "75it [00:27,  2.72it/s]\n",
      "75it [00:27,  2.75it/s]\n",
      "Epoch: 3 | Train Loss: 0.2557406 Vali Loss: 0.3004788 Test Loss: 0.3529094 MAE Loss: 0.3814841\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [01:04,  1.55it/s]\titers: 100, epoch: 4 | loss: 0.2151692\n",
      "\tspeed: 1.5243s/iter; left time: 8867.0306s\n",
      "199it [02:09,  1.56it/s]\titers: 200, epoch: 4 | loss: 0.2653588\n",
      "\tspeed: 0.6504s/iter; left time: 3718.1655s\n",
      "299it [03:14,  1.57it/s]\titers: 300, epoch: 4 | loss: 0.2378830\n",
      "\tspeed: 0.6519s/iter; left time: 3661.7237s\n",
      "348it [03:46,  1.54it/s]\n",
      "Epoch: 4 cost time: 226.3733251094818\n",
      "75it [00:27,  2.71it/s]\n",
      "75it [00:27,  2.73it/s]\n",
      "Epoch: 4 | Train Loss: 0.2498293 Vali Loss: 0.2942786 Test Loss: 0.3429480 MAE Loss: 0.3675991\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [01:04,  1.53it/s]\titers: 100, epoch: 5 | loss: 0.2682878\n",
      "\tspeed: 1.5359s/iter; left time: 8399.8544s\n",
      "199it [02:09,  1.58it/s]\titers: 200, epoch: 5 | loss: 0.2312374\n",
      "\tspeed: 0.6425s/iter; left time: 3449.4337s\n",
      "299it [03:13,  1.56it/s]\titers: 300, epoch: 5 | loss: 0.2547927\n",
      "\tspeed: 0.6457s/iter; left time: 3402.0145s\n",
      "348it [03:45,  1.54it/s]\n",
      "Epoch: 5 cost time: 225.56756234169006\n",
      "75it [00:28,  2.66it/s]\n",
      "75it [00:26,  2.79it/s]\n",
      "Epoch: 5 | Train Loss: 0.2477527 Vali Loss: 0.2920437 Test Loss: 0.3412064 MAE Loss: 0.3674579\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [01:05,  1.40it/s]\titers: 100, epoch: 6 | loss: 0.1936845\n",
      "\tspeed: 1.5389s/iter; left time: 7880.9106s\n",
      "199it [02:09,  1.59it/s]\titers: 200, epoch: 6 | loss: 0.2681586\n",
      "\tspeed: 0.6431s/iter; left time: 3228.8121s\n",
      "299it [03:12,  1.59it/s]\titers: 300, epoch: 6 | loss: 0.2617953\n",
      "\tspeed: 0.6343s/iter; left time: 3121.2480s\n",
      "348it [03:43,  1.56it/s]\n",
      "Epoch: 6 cost time: 223.7302532196045\n",
      "75it [00:27,  2.75it/s]\n",
      "75it [00:27,  2.72it/s]\n",
      "Epoch: 6 | Train Loss: 0.2459100 Vali Loss: 0.2922932 Test Loss: 0.3402219 MAE Loss: 0.3675644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [01:04,  1.59it/s]\titers: 100, epoch: 7 | loss: 0.2316971\n",
      "\tspeed: 1.5015s/iter; left time: 7166.8849s\n",
      "199it [02:08,  1.55it/s]\titers: 200, epoch: 7 | loss: 0.2614762\n",
      "\tspeed: 0.6465s/iter; left time: 3021.2298s\n",
      "299it [03:13,  1.53it/s]\titers: 300, epoch: 7 | loss: 0.2647679\n",
      "\tspeed: 0.6500s/iter; left time: 2972.6223s\n",
      "348it [03:45,  1.54it/s]\n",
      "Epoch: 7 cost time: 225.81025910377502\n",
      "75it [00:27,  2.74it/s]\n",
      "75it [00:27,  2.75it/s]\n",
      "Epoch: 7 | Train Loss: 0.2453593 Vali Loss: 0.2924128 Test Loss: 0.3403738 MAE Loss: 0.3673278\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [01:04,  1.60it/s]\titers: 100, epoch: 8 | loss: 0.2525187\n",
      "\tspeed: 1.5123s/iter; left time: 6691.8236s\n",
      "199it [02:09,  1.52it/s]\titers: 200, epoch: 8 | loss: 0.2650570\n",
      "\tspeed: 0.6469s/iter; left time: 2797.9302s\n",
      "299it [03:13,  1.52it/s]\titers: 300, epoch: 8 | loss: 0.2480436\n",
      "\tspeed: 0.6475s/iter; left time: 2735.8207s\n",
      "348it [03:45,  1.55it/s]\n",
      "Epoch: 8 cost time: 225.00377917289734\n",
      "75it [00:28,  2.64it/s]\n",
      "75it [00:27,  2.69it/s]\n",
      "Epoch: 8 | Train Loss: 0.2449469 Vali Loss: 0.2919028 Test Loss: 0.3402341 MAE Loss: 0.3665702\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [01:03,  1.65it/s]\titers: 100, epoch: 9 | loss: 0.2788871\n",
      "\tspeed: 1.5307s/iter; left time: 6240.6796s\n",
      "199it [02:08,  1.47it/s]\titers: 200, epoch: 9 | loss: 0.2133065\n",
      "\tspeed: 0.6491s/iter; left time: 2581.5431s\n",
      "299it [03:13,  1.58it/s]\titers: 300, epoch: 9 | loss: 0.2307284\n",
      "\tspeed: 0.6505s/iter; left time: 2521.9401s\n",
      "348it [03:45,  1.54it/s]\n",
      "Epoch: 9 cost time: 225.44134283065796\n",
      "75it [00:27,  2.69it/s]\n",
      "75it [00:27,  2.73it/s]\n",
      "Epoch: 9 | Train Loss: 0.2447373 Vali Loss: 0.2925079 Test Loss: 0.3401390 MAE Loss: 0.3665641\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [01:04,  1.57it/s]\titers: 100, epoch: 10 | loss: 0.2127697\n",
      "\tspeed: 1.5173s/iter; left time: 5658.1858s\n",
      "199it [02:08,  1.52it/s]\titers: 200, epoch: 10 | loss: 0.2426991\n",
      "\tspeed: 0.6418s/iter; left time: 2329.1719s\n",
      "299it [03:13,  1.60it/s]\titers: 300, epoch: 10 | loss: 0.2595877\n",
      "\tspeed: 0.6448s/iter; left time: 2275.6261s\n",
      "348it [03:45,  1.55it/s]\n",
      "Epoch: 10 cost time: 225.17468881607056\n",
      "75it [00:27,  2.75it/s]\n",
      "75it [00:27,  2.73it/s]\n",
      "Epoch: 10 | Train Loss: 0.2452664 Vali Loss: 0.2925189 Test Loss: 0.3395184 MAE Loss: 0.3659287\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 7.812499999999999e-08\n",
      "99it [01:04,  1.59it/s]\titers: 100, epoch: 11 | loss: 0.2013029\n",
      "\tspeed: 1.5123s/iter; left time: 5112.9330s\n",
      "199it [02:08,  1.45it/s]\titers: 200, epoch: 11 | loss: 0.2419287\n",
      "\tspeed: 0.6454s/iter; left time: 2117.4864s\n",
      "299it [03:13,  1.57it/s]\titers: 300, epoch: 11 | loss: 0.2499891\n",
      "\tspeed: 0.6394s/iter; left time: 2033.9841s\n",
      "348it [03:43,  1.56it/s]\n",
      "Epoch: 11 cost time: 223.74667382240295\n",
      "75it [00:27,  2.72it/s]\n",
      "75it [00:27,  2.75it/s]\n",
      "Epoch: 11 | Train Loss: 0.2446344 Vali Loss: 0.2925778 Test Loss: 0.3397157 MAE Loss: 0.3661593\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 52.18964409828186 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=12 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=256\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 05:56:39,031] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 05:56:40,083] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 05:56:40,083] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-07 05:56:45,271] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 05:56:46,189] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 05:56:46,190] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 05:56:46,191] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 05:56:46,193] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 05:56:46,193] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 05:56:46,193] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 05:56:46,194] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 05:56:46,194] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 05:56:46,194] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 05:56:46,194] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 05:56:46,540] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 05:56:46,541] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:56:46,541] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 202.07 GB, percent = 26.8%\n",
      "[2024-05-07 05:56:46,844] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 05:56:46,845] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:56:46,845] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 206.76 GB, percent = 27.4%\n",
      "[2024-05-07 05:56:46,845] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 05:56:47,007] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 05:56:47,007] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-07 05:56:47,007] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 209.11 GB, percent = 27.7%\n",
      "[2024-05-07 05:56:47,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 05:56:47,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 05:56:47,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 05:56:47,008] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 05:56:47,009] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 05:56:47,009] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 05:56:47,009] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 05:56:47,009] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 05:56:47,009] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efd6c795e50>\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 05:56:47,010] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 05:56:47,011] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:14,  7.75it/s]\titers: 100, epoch: 1 | loss: 0.9641595\n",
      "\tspeed: 0.1632s/iter; left time: 12104.2617s\n",
      "199it [00:27,  7.38it/s]\titers: 200, epoch: 1 | loss: 0.5187201\n",
      "\tspeed: 0.1332s/iter; left time: 9867.4846s\n",
      "299it [00:41,  7.66it/s]\titers: 300, epoch: 1 | loss: 0.4029001\n",
      "\tspeed: 0.1345s/iter; left time: 9947.6865s\n",
      "399it [00:54,  7.34it/s]\titers: 400, epoch: 1 | loss: 0.2808163\n",
      "\tspeed: 0.1342s/iter; left time: 9908.8522s\n",
      "499it [01:08,  7.50it/s]\titers: 500, epoch: 1 | loss: 0.1841253\n",
      "\tspeed: 0.1344s/iter; left time: 9910.6320s\n",
      "599it [01:21,  7.36it/s]\titers: 600, epoch: 1 | loss: 0.2845896\n",
      "\tspeed: 0.1341s/iter; left time: 9879.0750s\n",
      "699it [01:34,  7.41it/s]\titers: 700, epoch: 1 | loss: 0.3291208\n",
      "\tspeed: 0.1344s/iter; left time: 9888.5538s\n",
      "799it [01:48,  7.52it/s]\titers: 800, epoch: 1 | loss: 0.2157963\n",
      "\tspeed: 0.1328s/iter; left time: 9753.8800s\n",
      "899it [02:01,  7.34it/s]\titers: 900, epoch: 1 | loss: 0.3774287\n",
      "\tspeed: 0.1345s/iter; left time: 9865.6934s\n",
      "999it [02:15,  7.59it/s]\titers: 1000, epoch: 1 | loss: 0.2994530\n",
      "\tspeed: 0.1340s/iter; left time: 9814.6056s\n",
      "1099it [02:28,  7.27it/s]\titers: 1100, epoch: 1 | loss: 0.2394145\n",
      "\tspeed: 0.1344s/iter; left time: 9835.3305s\n",
      "1199it [02:41,  7.48it/s]\titers: 1200, epoch: 1 | loss: 0.2472853\n",
      "\tspeed: 0.1339s/iter; left time: 9786.0983s\n",
      "1299it [02:55,  7.56it/s]\titers: 1300, epoch: 1 | loss: 0.2571820\n",
      "\tspeed: 0.1339s/iter; left time: 9770.3256s\n",
      "1399it [03:08,  7.51it/s]\titers: 1400, epoch: 1 | loss: 0.2126374\n",
      "\tspeed: 0.1333s/iter; left time: 9714.8112s\n",
      "1499it [03:22,  7.48it/s]\titers: 1500, epoch: 1 | loss: 0.2242659\n",
      "\tspeed: 0.1335s/iter; left time: 9714.9054s\n",
      "1599it [03:35,  7.50it/s]\titers: 1600, epoch: 1 | loss: 0.3551038\n",
      "\tspeed: 0.1354s/iter; left time: 9838.5303s\n",
      "1699it [03:48,  7.37it/s]\titers: 1700, epoch: 1 | loss: 0.2962065\n",
      "\tspeed: 0.1338s/iter; left time: 9710.9116s\n",
      "1799it [04:02,  7.54it/s]\titers: 1800, epoch: 1 | loss: 0.3189642\n",
      "\tspeed: 0.1348s/iter; left time: 9766.2560s\n",
      "1899it [04:15,  7.61it/s]\titers: 1900, epoch: 1 | loss: 0.2609983\n",
      "\tspeed: 0.1354s/iter; left time: 9796.8349s\n",
      "1999it [04:29,  7.61it/s]\titers: 2000, epoch: 1 | loss: 0.3362970\n",
      "\tspeed: 0.1336s/iter; left time: 9657.2650s\n",
      "2099it [04:42,  7.38it/s]\titers: 2100, epoch: 1 | loss: 0.1997824\n",
      "\tspeed: 0.1351s/iter; left time: 9748.9576s\n",
      "2199it [04:56,  7.62it/s]\titers: 2200, epoch: 1 | loss: 0.2255914\n",
      "\tspeed: 0.1356s/iter; left time: 9770.1878s\n",
      "2299it [05:09,  7.55it/s]\titers: 2300, epoch: 1 | loss: 0.3413877\n",
      "\tspeed: 0.1335s/iter; left time: 9607.3445s\n",
      "2399it [05:23,  7.48it/s]\titers: 2400, epoch: 1 | loss: 0.2875497\n",
      "\tspeed: 0.1361s/iter; left time: 9777.7662s\n",
      "2499it [05:36,  7.17it/s]\titers: 2500, epoch: 1 | loss: 0.3320526\n",
      "\tspeed: 0.1351s/iter; left time: 9692.2106s\n",
      "2599it [05:50,  7.40it/s]\titers: 2600, epoch: 1 | loss: 0.1992021\n",
      "\tspeed: 0.1357s/iter; left time: 9725.0681s\n",
      "2699it [06:04,  7.57it/s]\titers: 2700, epoch: 1 | loss: 0.2342773\n",
      "\tspeed: 0.1377s/iter; left time: 9853.2799s\n",
      "2799it [06:17,  7.49it/s]\titers: 2800, epoch: 1 | loss: 0.1815586\n",
      "\tspeed: 0.1348s/iter; left time: 9632.9922s\n",
      "2899it [06:31,  7.14it/s]\titers: 2900, epoch: 1 | loss: 0.2151070\n",
      "\tspeed: 0.1367s/iter; left time: 9758.1641s\n",
      "2999it [06:44,  7.47it/s]\titers: 3000, epoch: 1 | loss: 0.2274868\n",
      "\tspeed: 0.1345s/iter; left time: 9587.0754s\n",
      "3099it [06:58,  7.48it/s]\titers: 3100, epoch: 1 | loss: 0.1735005\n",
      "\tspeed: 0.1355s/iter; left time: 9644.3383s\n",
      "3199it [07:11,  7.33it/s]\titers: 3200, epoch: 1 | loss: 0.1491423\n",
      "\tspeed: 0.1361s/iter; left time: 9673.2772s\n",
      "3299it [07:25,  7.35it/s]\titers: 3300, epoch: 1 | loss: 0.2412028\n",
      "\tspeed: 0.1349s/iter; left time: 9570.6403s\n",
      "3399it [07:38,  7.06it/s]\titers: 3400, epoch: 1 | loss: 0.3968665\n",
      "\tspeed: 0.1352s/iter; left time: 9577.6981s\n",
      "3499it [07:52,  7.63it/s]\titers: 3500, epoch: 1 | loss: 0.2387104\n",
      "\tspeed: 0.1363s/iter; left time: 9643.5561s\n",
      "3599it [08:05,  7.54it/s]\titers: 3600, epoch: 1 | loss: 0.2146533\n",
      "\tspeed: 0.1330s/iter; left time: 9398.0472s\n",
      "3699it [08:19,  7.27it/s]\titers: 3700, epoch: 1 | loss: 0.1906886\n",
      "\tspeed: 0.1350s/iter; left time: 9525.1736s\n",
      "3713it [08:21,  7.41it/s]\n",
      "Epoch: 1 cost time: 501.33936858177185\n",
      "810it [00:52, 15.44it/s]\n",
      "807it [00:53, 15.22it/s]\n",
      "Epoch: 1 | Train Loss: 0.2935759 Vali Loss: 0.3151243 Test Loss: 0.3966921 MAE Loss: 0.4009331\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:13,  7.69it/s]\titers: 100, epoch: 2 | loss: 0.2668546\n",
      "\tspeed: 1.2457s/iter; left time: 87760.2631s\n",
      "199it [00:26,  7.67it/s]\titers: 200, epoch: 2 | loss: 0.3243296\n",
      "\tspeed: 0.1316s/iter; left time: 9256.6121s\n",
      "299it [00:39,  7.34it/s]\titers: 300, epoch: 2 | loss: 0.2878442\n",
      "\tspeed: 0.1314s/iter; left time: 9228.7568s\n",
      "399it [00:52,  7.74it/s]\titers: 400, epoch: 2 | loss: 0.3907331\n",
      "\tspeed: 0.1303s/iter; left time: 9143.5468s\n",
      "499it [01:05,  7.88it/s]\titers: 500, epoch: 2 | loss: 0.2069688\n",
      "\tspeed: 0.1302s/iter; left time: 9119.9218s\n",
      "599it [01:18,  7.59it/s]\titers: 600, epoch: 2 | loss: 0.2945153\n",
      "\tspeed: 0.1319s/iter; left time: 9225.8964s\n",
      "699it [01:31,  7.62it/s]\titers: 700, epoch: 2 | loss: 0.2082459\n",
      "\tspeed: 0.1305s/iter; left time: 9117.0528s\n",
      "799it [01:44,  7.96it/s]\titers: 800, epoch: 2 | loss: 0.3093166\n",
      "\tspeed: 0.1316s/iter; left time: 9181.7393s\n",
      "899it [01:58,  7.72it/s]\titers: 900, epoch: 2 | loss: 0.1970092\n",
      "\tspeed: 0.1314s/iter; left time: 9149.2445s\n",
      "999it [02:10,  7.76it/s]\titers: 1000, epoch: 2 | loss: 0.3330566\n",
      "\tspeed: 0.1292s/iter; left time: 8984.0047s\n",
      "1099it [02:24,  7.76it/s]\titers: 1100, epoch: 2 | loss: 0.1897289\n",
      "\tspeed: 0.1319s/iter; left time: 9161.6293s\n",
      "1199it [02:37,  7.58it/s]\titers: 1200, epoch: 2 | loss: 0.4427165\n",
      "\tspeed: 0.1307s/iter; left time: 9062.4473s\n",
      "1299it [02:50,  7.84it/s]\titers: 1300, epoch: 2 | loss: 0.2237228\n",
      "\tspeed: 0.1297s/iter; left time: 8979.9061s\n",
      "1399it [03:03,  7.38it/s]\titers: 1400, epoch: 2 | loss: 0.1716717\n",
      "\tspeed: 0.1312s/iter; left time: 9073.8577s\n",
      "1499it [03:16,  7.83it/s]\titers: 1500, epoch: 2 | loss: 0.5217724\n",
      "\tspeed: 0.1292s/iter; left time: 8921.3507s\n",
      "1599it [03:29,  7.64it/s]\titers: 1600, epoch: 2 | loss: 0.2182254\n",
      "\tspeed: 0.1296s/iter; left time: 8932.5803s\n",
      "1699it [03:42,  7.74it/s]\titers: 1700, epoch: 2 | loss: 0.2576517\n",
      "\tspeed: 0.1290s/iter; left time: 8878.1206s\n",
      "1799it [03:55,  7.48it/s]\titers: 1800, epoch: 2 | loss: 0.1207245\n",
      "\tspeed: 0.1302s/iter; left time: 8952.9947s\n",
      "1899it [04:08,  7.60it/s]\titers: 1900, epoch: 2 | loss: 0.2838496\n",
      "\tspeed: 0.1309s/iter; left time: 8989.3057s\n",
      "1999it [04:21,  7.29it/s]\titers: 2000, epoch: 2 | loss: 0.2352560\n",
      "\tspeed: 0.1291s/iter; left time: 8851.2320s\n",
      "2099it [04:33,  7.86it/s]\titers: 2100, epoch: 2 | loss: 0.2004760\n",
      "\tspeed: 0.1286s/iter; left time: 8800.6295s\n",
      "2199it [04:46,  7.91it/s]\titers: 2200, epoch: 2 | loss: 0.3143178\n",
      "\tspeed: 0.1281s/iter; left time: 8756.3078s\n",
      "2299it [04:59,  7.98it/s]\titers: 2300, epoch: 2 | loss: 0.2416739\n",
      "\tspeed: 0.1293s/iter; left time: 8821.6624s\n",
      "2399it [05:12,  7.74it/s]\titers: 2400, epoch: 2 | loss: 0.4222754\n",
      "\tspeed: 0.1280s/iter; left time: 8724.2782s\n",
      "2499it [05:25,  7.66it/s]\titers: 2500, epoch: 2 | loss: 0.1435327\n",
      "\tspeed: 0.1294s/iter; left time: 8804.1315s\n",
      "2599it [05:38,  7.65it/s]\titers: 2600, epoch: 2 | loss: 0.2831287\n",
      "\tspeed: 0.1299s/iter; left time: 8828.9280s\n",
      "2699it [05:51,  7.76it/s]\titers: 2700, epoch: 2 | loss: 0.2098521\n",
      "\tspeed: 0.1291s/iter; left time: 8760.3018s\n",
      "2799it [06:04,  7.80it/s]\titers: 2800, epoch: 2 | loss: 0.2984158\n",
      "\tspeed: 0.1285s/iter; left time: 8704.9662s\n",
      "2899it [06:17,  7.91it/s]\titers: 2900, epoch: 2 | loss: 0.2197979\n",
      "\tspeed: 0.1296s/iter; left time: 8764.9072s\n",
      "2999it [06:30,  7.82it/s]\titers: 3000, epoch: 2 | loss: 0.1694328\n",
      "\tspeed: 0.1299s/iter; left time: 8776.5083s\n",
      "3099it [06:43,  7.76it/s]\titers: 3100, epoch: 2 | loss: 0.2197636\n",
      "\tspeed: 0.1301s/iter; left time: 8775.5389s\n",
      "3199it [06:56,  6.76it/s]\titers: 3200, epoch: 2 | loss: 0.2478591\n",
      "\tspeed: 0.1305s/iter; left time: 8792.0170s\n",
      "3299it [07:09,  7.79it/s]\titers: 3300, epoch: 2 | loss: 0.1612138\n",
      "\tspeed: 0.1292s/iter; left time: 8685.8848s\n",
      "3399it [07:22,  7.83it/s]\titers: 3400, epoch: 2 | loss: 0.1399053\n",
      "\tspeed: 0.1289s/iter; left time: 8652.7743s\n",
      "3499it [07:35,  7.09it/s]\titers: 3500, epoch: 2 | loss: 0.1988449\n",
      "\tspeed: 0.1301s/iter; left time: 8722.2576s\n",
      "3599it [07:47,  7.74it/s]\titers: 3600, epoch: 2 | loss: 0.1694340\n",
      "\tspeed: 0.1287s/iter; left time: 8614.7713s\n",
      "3699it [08:00,  7.78it/s]\titers: 3700, epoch: 2 | loss: 0.1109314\n",
      "\tspeed: 0.1290s/iter; left time: 8620.2123s\n",
      "3713it [08:02,  7.69it/s]\n",
      "Epoch: 2 cost time: 482.6202630996704\n",
      "810it [00:48, 16.63it/s]\n",
      "807it [00:48, 16.63it/s]\n",
      "Epoch: 2 | Train Loss: 0.2395417 Vali Loss: 0.2934191 Test Loss: 0.3401946 MAE Loss: 0.3558949\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:13,  7.87it/s]\titers: 100, epoch: 3 | loss: 0.2172087\n",
      "\tspeed: 1.1583s/iter; left time: 77300.9557s\n",
      "199it [00:26,  7.98it/s]\titers: 200, epoch: 3 | loss: 0.1346914\n",
      "\tspeed: 0.1292s/iter; left time: 8607.2023s\n",
      "299it [00:38,  7.85it/s]\titers: 300, epoch: 3 | loss: 0.2193775\n",
      "\tspeed: 0.1274s/iter; left time: 8479.1426s\n",
      "399it [00:51,  7.95it/s]\titers: 400, epoch: 3 | loss: 0.4463703\n",
      "\tspeed: 0.1289s/iter; left time: 8562.2122s\n",
      "499it [01:04,  7.91it/s]\titers: 500, epoch: 3 | loss: 0.1829557\n",
      "\tspeed: 0.1298s/iter; left time: 8612.9704s\n",
      "599it [01:17,  7.85it/s]\titers: 600, epoch: 3 | loss: 0.2435770\n",
      "\tspeed: 0.1294s/iter; left time: 8568.6135s\n",
      "699it [01:30,  7.85it/s]\titers: 700, epoch: 3 | loss: 0.2425336\n",
      "\tspeed: 0.1300s/iter; left time: 8596.4155s\n",
      "799it [01:43,  7.91it/s]\titers: 800, epoch: 3 | loss: 0.4156528\n",
      "\tspeed: 0.1297s/iter; left time: 8561.6894s\n",
      "899it [01:56,  7.60it/s]\titers: 900, epoch: 3 | loss: 0.4306667\n",
      "\tspeed: 0.1294s/iter; left time: 8532.0547s\n",
      "999it [02:09,  7.89it/s]\titers: 1000, epoch: 3 | loss: 0.2407355\n",
      "\tspeed: 0.1274s/iter; left time: 8388.9259s\n",
      "1099it [02:22,  7.84it/s]\titers: 1100, epoch: 3 | loss: 0.2281860\n",
      "\tspeed: 0.1291s/iter; left time: 8484.0079s\n",
      "1199it [02:34,  7.85it/s]\titers: 1200, epoch: 3 | loss: 0.1639353\n",
      "\tspeed: 0.1281s/iter; left time: 8408.4342s\n",
      "1299it [02:47,  7.76it/s]\titers: 1300, epoch: 3 | loss: 0.2385784\n",
      "\tspeed: 0.1303s/iter; left time: 8540.2250s\n",
      "1399it [03:01,  7.80it/s]\titers: 1400, epoch: 3 | loss: 0.3162254\n",
      "\tspeed: 0.1307s/iter; left time: 8549.3000s\n",
      "1499it [03:13,  7.96it/s]\titers: 1500, epoch: 3 | loss: 0.1490571\n",
      "\tspeed: 0.1283s/iter; left time: 8380.0062s\n",
      "1599it [03:26,  7.76it/s]\titers: 1600, epoch: 3 | loss: 0.3864870\n",
      "\tspeed: 0.1290s/iter; left time: 8415.6784s\n",
      "1699it [03:39,  7.91it/s]\titers: 1700, epoch: 3 | loss: 0.3177374\n",
      "\tspeed: 0.1288s/iter; left time: 8388.8410s\n",
      "1799it [03:52,  7.59it/s]\titers: 1800, epoch: 3 | loss: 0.1520831\n",
      "\tspeed: 0.1295s/iter; left time: 8421.0023s\n",
      "1899it [04:05,  7.86it/s]\titers: 1900, epoch: 3 | loss: 0.2257083\n",
      "\tspeed: 0.1310s/iter; left time: 8507.3739s\n",
      "1999it [04:18,  7.80it/s]\titers: 2000, epoch: 3 | loss: 0.2256435\n",
      "\tspeed: 0.1295s/iter; left time: 8396.5862s\n",
      "2099it [04:31,  7.61it/s]\titers: 2100, epoch: 3 | loss: 0.2019173\n",
      "\tspeed: 0.1291s/iter; left time: 8356.5010s\n",
      "2199it [04:44,  7.85it/s]\titers: 2200, epoch: 3 | loss: 0.1541355\n",
      "\tspeed: 0.1297s/iter; left time: 8385.4880s\n",
      "2299it [04:57,  7.76it/s]\titers: 2300, epoch: 3 | loss: 0.1263089\n",
      "\tspeed: 0.1295s/iter; left time: 8356.8220s\n",
      "2399it [05:10,  7.84it/s]\titers: 2400, epoch: 3 | loss: 0.2702385\n",
      "\tspeed: 0.1284s/iter; left time: 8272.3114s\n",
      "2499it [05:23,  7.66it/s]\titers: 2500, epoch: 3 | loss: 0.2562164\n",
      "\tspeed: 0.1302s/iter; left time: 8376.4809s\n",
      "2599it [05:36,  7.33it/s]\titers: 2600, epoch: 3 | loss: 0.2490318\n",
      "\tspeed: 0.1301s/iter; left time: 8357.9881s\n",
      "2699it [05:49,  7.85it/s]\titers: 2700, epoch: 3 | loss: 0.1571666\n",
      "\tspeed: 0.1301s/iter; left time: 8345.3311s\n",
      "2799it [06:02,  7.74it/s]\titers: 2800, epoch: 3 | loss: 0.1761787\n",
      "\tspeed: 0.1302s/iter; left time: 8338.7341s\n",
      "2899it [06:15,  7.64it/s]\titers: 2900, epoch: 3 | loss: 0.1350867\n",
      "\tspeed: 0.1290s/iter; left time: 8247.7474s\n",
      "2999it [06:28,  7.49it/s]\titers: 3000, epoch: 3 | loss: 0.2478373\n",
      "\tspeed: 0.1283s/iter; left time: 8191.8988s\n",
      "3099it [06:41,  7.70it/s]\titers: 3100, epoch: 3 | loss: 0.2496981\n",
      "\tspeed: 0.1300s/iter; left time: 8286.1154s\n",
      "3199it [06:54,  7.63it/s]\titers: 3200, epoch: 3 | loss: 0.1517304\n",
      "\tspeed: 0.1311s/iter; left time: 8344.5590s\n",
      "3299it [07:07,  7.87it/s]\titers: 3300, epoch: 3 | loss: 0.1905589\n",
      "\tspeed: 0.1286s/iter; left time: 8171.4350s\n",
      "3399it [07:20,  7.71it/s]\titers: 3400, epoch: 3 | loss: 0.2230773\n",
      "\tspeed: 0.1306s/iter; left time: 8283.3393s\n",
      "3499it [07:33,  7.77it/s]\titers: 3500, epoch: 3 | loss: 0.2365967\n",
      "\tspeed: 0.1302s/iter; left time: 8244.0711s\n",
      "3599it [07:45,  7.64it/s]\titers: 3600, epoch: 3 | loss: 0.1072769\n",
      "\tspeed: 0.1280s/iter; left time: 8092.3576s\n",
      "3699it [07:58,  7.67it/s]\titers: 3700, epoch: 3 | loss: 0.2879986\n",
      "\tspeed: 0.1293s/iter; left time: 8166.4374s\n",
      "3713it [08:00,  7.72it/s]\n",
      "Epoch: 3 cost time: 480.7530138492584\n",
      "810it [00:49, 16.46it/s]\n",
      "807it [00:49, 16.41it/s]\n",
      "Epoch: 3 | Train Loss: 0.2212686 Vali Loss: 0.2801371 Test Loss: 0.3329907 MAE Loss: 0.3440673\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:12,  8.09it/s]\titers: 100, epoch: 4 | loss: 0.2128312\n",
      "\tspeed: 1.1668s/iter; left time: 73533.3663s\n",
      "199it [00:26,  7.46it/s]\titers: 200, epoch: 4 | loss: 0.2195538\n",
      "\tspeed: 0.1302s/iter; left time: 8189.5968s\n",
      "299it [00:39,  7.78it/s]\titers: 300, epoch: 4 | loss: 0.3302707\n",
      "\tspeed: 0.1301s/iter; left time: 8174.8477s\n",
      "399it [00:51,  7.61it/s]\titers: 400, epoch: 4 | loss: 0.4481091\n",
      "\tspeed: 0.1293s/iter; left time: 8110.3094s\n",
      "499it [01:04,  7.78it/s]\titers: 500, epoch: 4 | loss: 0.0987328\n",
      "\tspeed: 0.1293s/iter; left time: 8094.7420s\n",
      "599it [01:17,  7.68it/s]\titers: 600, epoch: 4 | loss: 0.2090068\n",
      "\tspeed: 0.1306s/iter; left time: 8162.9084s\n",
      "699it [01:30,  7.90it/s]\titers: 700, epoch: 4 | loss: 0.3150179\n",
      "\tspeed: 0.1301s/iter; left time: 8124.1131s\n",
      "799it [01:43,  7.61it/s]\titers: 800, epoch: 4 | loss: 0.1733373\n",
      "\tspeed: 0.1284s/iter; left time: 8004.9067s\n",
      "899it [01:56,  7.80it/s]\titers: 900, epoch: 4 | loss: 0.2353803\n",
      "\tspeed: 0.1308s/iter; left time: 8135.6995s\n",
      "999it [02:09,  7.08it/s]\titers: 1000, epoch: 4 | loss: 0.2693732\n",
      "\tspeed: 0.1296s/iter; left time: 8049.7458s\n",
      "1099it [02:22,  7.72it/s]\titers: 1100, epoch: 4 | loss: 0.2488151\n",
      "\tspeed: 0.1298s/iter; left time: 8048.7112s\n",
      "1199it [02:35,  7.68it/s]\titers: 1200, epoch: 4 | loss: 0.3202523\n",
      "\tspeed: 0.1305s/iter; left time: 8083.3458s\n",
      "1299it [02:48,  7.66it/s]\titers: 1300, epoch: 4 | loss: 0.2792143\n",
      "\tspeed: 0.1290s/iter; left time: 7973.5800s\n",
      "1399it [03:01,  7.90it/s]\titers: 1400, epoch: 4 | loss: 0.3689791\n",
      "\tspeed: 0.1276s/iter; left time: 7878.3504s\n",
      "1499it [03:14,  7.75it/s]\titers: 1500, epoch: 4 | loss: 0.1964427\n",
      "\tspeed: 0.1306s/iter; left time: 8046.7106s\n",
      "1599it [03:27,  7.66it/s]\titers: 1600, epoch: 4 | loss: 0.1753232\n",
      "\tspeed: 0.1305s/iter; left time: 8031.1628s\n",
      "1699it [03:40,  7.79it/s]\titers: 1700, epoch: 4 | loss: 0.1751649\n",
      "\tspeed: 0.1296s/iter; left time: 7961.0773s\n",
      "1799it [03:53,  7.75it/s]\titers: 1800, epoch: 4 | loss: 0.1906732\n",
      "\tspeed: 0.1296s/iter; left time: 7947.3094s\n",
      "1899it [04:06,  7.47it/s]\titers: 1900, epoch: 4 | loss: 0.1933302\n",
      "\tspeed: 0.1299s/iter; left time: 7954.5031s\n",
      "1999it [04:19,  7.85it/s]\titers: 2000, epoch: 4 | loss: 0.1602807\n",
      "\tspeed: 0.1303s/iter; left time: 7961.6955s\n",
      "2099it [04:32,  7.85it/s]\titers: 2100, epoch: 4 | loss: 0.2727919\n",
      "\tspeed: 0.1302s/iter; left time: 7947.9370s\n",
      "2199it [04:45,  7.59it/s]\titers: 2200, epoch: 4 | loss: 0.1243803\n",
      "\tspeed: 0.1324s/iter; left time: 8069.0350s\n",
      "2299it [04:58,  7.76it/s]\titers: 2300, epoch: 4 | loss: 0.2286512\n",
      "\tspeed: 0.1306s/iter; left time: 7941.2797s\n",
      "2399it [05:11,  7.96it/s]\titers: 2400, epoch: 4 | loss: 0.1426104\n",
      "\tspeed: 0.1286s/iter; left time: 7807.5649s\n",
      "2499it [05:24,  7.70it/s]\titers: 2500, epoch: 4 | loss: 0.1815710\n",
      "\tspeed: 0.1302s/iter; left time: 7891.7564s\n",
      "2599it [05:37,  7.57it/s]\titers: 2600, epoch: 4 | loss: 0.2303303\n",
      "\tspeed: 0.1296s/iter; left time: 7842.1469s\n",
      "2699it [05:50,  7.33it/s]\titers: 2700, epoch: 4 | loss: 0.1436880\n",
      "\tspeed: 0.1301s/iter; left time: 7861.4657s\n",
      "2799it [06:03,  7.71it/s]\titers: 2800, epoch: 4 | loss: 0.3447067\n",
      "\tspeed: 0.1293s/iter; left time: 7797.0012s\n",
      "2899it [06:16,  7.90it/s]\titers: 2900, epoch: 4 | loss: 0.1544191\n",
      "\tspeed: 0.1286s/iter; left time: 7744.5155s\n",
      "2999it [06:29,  7.38it/s]\titers: 3000, epoch: 4 | loss: 0.2189909\n",
      "\tspeed: 0.1306s/iter; left time: 7849.3109s\n",
      "3099it [06:42,  7.90it/s]\titers: 3100, epoch: 4 | loss: 0.1446553\n",
      "\tspeed: 0.1296s/iter; left time: 7778.0146s\n",
      "3199it [06:55,  7.87it/s]\titers: 3200, epoch: 4 | loss: 0.2125824\n",
      "\tspeed: 0.1281s/iter; left time: 7673.4097s\n",
      "3299it [07:08,  7.69it/s]\titers: 3300, epoch: 4 | loss: 0.1498930\n",
      "\tspeed: 0.1280s/iter; left time: 7655.6829s\n",
      "3399it [07:21,  7.63it/s]\titers: 3400, epoch: 4 | loss: 0.1350155\n",
      "\tspeed: 0.1300s/iter; left time: 7765.0751s\n",
      "3499it [07:34,  7.81it/s]\titers: 3500, epoch: 4 | loss: 0.2077062\n",
      "\tspeed: 0.1298s/iter; left time: 7740.9816s\n",
      "3599it [07:47,  7.73it/s]\titers: 3600, epoch: 4 | loss: 0.1565008\n",
      "\tspeed: 0.1295s/iter; left time: 7708.7758s\n",
      "3699it [08:00,  7.82it/s]\titers: 3700, epoch: 4 | loss: 0.1517958\n",
      "\tspeed: 0.1311s/iter; left time: 7788.3626s\n",
      "3713it [08:02,  7.70it/s]\n",
      "Epoch: 4 cost time: 482.0531530380249\n",
      "810it [00:48, 16.65it/s]\n",
      "807it [00:48, 16.49it/s]\n",
      "Epoch: 4 | Train Loss: 0.2116419 Vali Loss: 0.2813208 Test Loss: 0.3359991 MAE Loss: 0.3474960\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:13,  7.54it/s]\titers: 100, epoch: 5 | loss: 0.1215705\n",
      "\tspeed: 1.1264s/iter; left time: 66808.0713s\n",
      "199it [00:26,  7.83it/s]\titers: 200, epoch: 5 | loss: 0.1519264\n",
      "\tspeed: 0.1310s/iter; left time: 7757.2976s\n",
      "299it [00:39,  7.42it/s]\titers: 300, epoch: 5 | loss: 0.1742376\n",
      "\tspeed: 0.1295s/iter; left time: 7654.4247s\n",
      "399it [00:52,  7.66it/s]\titers: 400, epoch: 5 | loss: 0.2460077\n",
      "\tspeed: 0.1287s/iter; left time: 7596.2775s\n",
      "499it [01:05,  7.67it/s]\titers: 500, epoch: 5 | loss: 0.0752749\n",
      "\tspeed: 0.1297s/iter; left time: 7639.4090s\n",
      "599it [01:17,  7.77it/s]\titers: 600, epoch: 5 | loss: 0.1421984\n",
      "\tspeed: 0.1291s/iter; left time: 7593.6574s\n",
      "699it [01:30,  7.87it/s]\titers: 700, epoch: 5 | loss: 0.2719428\n",
      "\tspeed: 0.1288s/iter; left time: 7564.2063s\n",
      "799it [01:43,  7.53it/s]\titers: 800, epoch: 5 | loss: 0.2143029\n",
      "\tspeed: 0.1303s/iter; left time: 7639.0179s\n",
      "899it [01:56,  7.82it/s]\titers: 900, epoch: 5 | loss: 0.2020324\n",
      "\tspeed: 0.1309s/iter; left time: 7660.6069s\n",
      "999it [02:09,  7.76it/s]\titers: 1000, epoch: 5 | loss: 0.2187834\n",
      "\tspeed: 0.1288s/iter; left time: 7524.3423s\n",
      "1099it [02:22,  7.95it/s]\titers: 1100, epoch: 5 | loss: 0.2859931\n",
      "\tspeed: 0.1311s/iter; left time: 7646.4071s\n",
      "1199it [02:35,  7.86it/s]\titers: 1200, epoch: 5 | loss: 0.1921416\n",
      "\tspeed: 0.1295s/iter; left time: 7537.3679s\n",
      "1299it [02:48,  7.68it/s]\titers: 1300, epoch: 5 | loss: 0.1542293\n",
      "\tspeed: 0.1279s/iter; left time: 7431.0823s\n",
      "1399it [03:01,  7.76it/s]\titers: 1400, epoch: 5 | loss: 0.1083390\n",
      "\tspeed: 0.1291s/iter; left time: 7488.1829s\n",
      "1499it [03:14,  7.89it/s]\titers: 1500, epoch: 5 | loss: 0.1162234\n",
      "\tspeed: 0.1296s/iter; left time: 7504.0130s\n",
      "1599it [03:27,  7.78it/s]\titers: 1600, epoch: 5 | loss: 0.2247154\n",
      "\tspeed: 0.1291s/iter; left time: 7465.5940s\n",
      "1699it [03:40,  7.74it/s]\titers: 1700, epoch: 5 | loss: 0.2029028\n",
      "\tspeed: 0.1307s/iter; left time: 7543.0326s\n",
      "1799it [03:53,  7.86it/s]\titers: 1800, epoch: 5 | loss: 0.2313351\n",
      "\tspeed: 0.1319s/iter; left time: 7600.2303s\n",
      "1899it [04:06,  7.60it/s]\titers: 1900, epoch: 5 | loss: 0.2222791\n",
      "\tspeed: 0.1302s/iter; left time: 7487.3311s\n",
      "1999it [04:19,  7.50it/s]\titers: 2000, epoch: 5 | loss: 0.1447722\n",
      "\tspeed: 0.1303s/iter; left time: 7480.1031s\n",
      "2099it [04:32,  7.76it/s]\titers: 2100, epoch: 5 | loss: 0.2559798\n",
      "\tspeed: 0.1294s/iter; left time: 7413.3344s\n",
      "2199it [04:45,  7.87it/s]\titers: 2200, epoch: 5 | loss: 0.1325725\n",
      "\tspeed: 0.1282s/iter; left time: 7334.7348s\n",
      "2299it [04:58,  7.68it/s]\titers: 2300, epoch: 5 | loss: 0.2350173\n",
      "\tspeed: 0.1308s/iter; left time: 7468.7265s\n",
      "2399it [05:11,  7.63it/s]\titers: 2400, epoch: 5 | loss: 0.1642561\n",
      "\tspeed: 0.1291s/iter; left time: 7357.1695s\n",
      "2499it [05:24,  7.81it/s]\titers: 2500, epoch: 5 | loss: 0.1604826\n",
      "\tspeed: 0.1291s/iter; left time: 7346.9613s\n",
      "2599it [05:37,  7.27it/s]\titers: 2600, epoch: 5 | loss: 0.2684038\n",
      "\tspeed: 0.1300s/iter; left time: 7383.4459s\n",
      "2699it [05:50,  7.80it/s]\titers: 2700, epoch: 5 | loss: 0.1760338\n",
      "\tspeed: 0.1296s/iter; left time: 7349.3280s\n",
      "2799it [06:03,  7.58it/s]\titers: 2800, epoch: 5 | loss: 0.1796928\n",
      "\tspeed: 0.1296s/iter; left time: 7336.9359s\n",
      "2899it [06:16,  7.83it/s]\titers: 2900, epoch: 5 | loss: 0.2157445\n",
      "\tspeed: 0.1283s/iter; left time: 7248.9894s\n",
      "2999it [06:29,  7.74it/s]\titers: 3000, epoch: 5 | loss: 0.1468672\n",
      "\tspeed: 0.1293s/iter; left time: 7294.2783s\n",
      "3099it [06:41,  7.38it/s]\titers: 3100, epoch: 5 | loss: 0.2015075\n",
      "\tspeed: 0.1286s/iter; left time: 7240.0154s\n",
      "3199it [06:54,  7.66it/s]\titers: 3200, epoch: 5 | loss: 0.1676449\n",
      "\tspeed: 0.1286s/iter; left time: 7228.6235s\n",
      "3299it [07:07,  7.94it/s]\titers: 3300, epoch: 5 | loss: 0.1916084\n",
      "\tspeed: 0.1291s/iter; left time: 7242.1087s\n",
      "3399it [07:20,  7.60it/s]\titers: 3400, epoch: 5 | loss: 0.2393851\n",
      "\tspeed: 0.1277s/iter; left time: 7152.8014s\n",
      "3499it [07:33,  7.81it/s]\titers: 3500, epoch: 5 | loss: 0.3022619\n",
      "\tspeed: 0.1270s/iter; left time: 7103.0511s\n",
      "3599it [07:46,  7.49it/s]\titers: 3600, epoch: 5 | loss: 0.2383408\n",
      "\tspeed: 0.1297s/iter; left time: 7238.2799s\n",
      "3699it [07:59,  7.79it/s]\titers: 3700, epoch: 5 | loss: 0.1483875\n",
      "\tspeed: 0.1302s/iter; left time: 7252.0090s\n",
      "3713it [08:01,  7.72it/s]\n",
      "Epoch: 5 cost time: 481.0824730396271\n",
      "810it [00:49, 16.45it/s]\n",
      "807it [00:48, 16.53it/s]\n",
      "Epoch: 5 | Train Loss: 0.2056262 Vali Loss: 0.2857605 Test Loss: 0.3462862 MAE Loss: 0.3538258\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:13,  7.90it/s]\titers: 100, epoch: 6 | loss: 0.2537978\n",
      "\tspeed: 1.1310s/iter; left time: 62880.8368s\n",
      "199it [00:26,  7.62it/s]\titers: 200, epoch: 6 | loss: 0.1386817\n",
      "\tspeed: 0.1320s/iter; left time: 7323.0929s\n",
      "299it [00:39,  7.40it/s]\titers: 300, epoch: 6 | loss: 0.2591326\n",
      "\tspeed: 0.1297s/iter; left time: 7185.9866s\n",
      "399it [00:52,  7.73it/s]\titers: 400, epoch: 6 | loss: 0.1535020\n",
      "\tspeed: 0.1287s/iter; left time: 7116.7508s\n",
      "499it [01:05,  8.01it/s]\titers: 500, epoch: 6 | loss: 0.2082774\n",
      "\tspeed: 0.1294s/iter; left time: 7140.6738s\n",
      "599it [01:17,  7.90it/s]\titers: 600, epoch: 6 | loss: 0.2359465\n",
      "\tspeed: 0.1278s/iter; left time: 7042.5415s\n",
      "699it [01:30,  7.94it/s]\titers: 700, epoch: 6 | loss: 0.3018428\n",
      "\tspeed: 0.1287s/iter; left time: 7075.6214s\n",
      "799it [01:43,  7.59it/s]\titers: 800, epoch: 6 | loss: 0.2652551\n",
      "\tspeed: 0.1290s/iter; left time: 7080.9192s\n",
      "899it [01:56,  7.95it/s]\titers: 900, epoch: 6 | loss: 0.2376828\n",
      "\tspeed: 0.1297s/iter; left time: 7104.3505s\n",
      "999it [02:09,  7.22it/s]\titers: 1000, epoch: 6 | loss: 0.1226375\n",
      "\tspeed: 0.1276s/iter; left time: 6979.4044s\n",
      "1099it [02:22,  7.66it/s]\titers: 1100, epoch: 6 | loss: 0.1675810\n",
      "\tspeed: 0.1306s/iter; left time: 7128.6737s\n",
      "1199it [02:35,  7.78it/s]\titers: 1200, epoch: 6 | loss: 0.2391902\n",
      "\tspeed: 0.1280s/iter; left time: 6975.4700s\n",
      "1299it [02:48,  7.71it/s]\titers: 1300, epoch: 6 | loss: 0.1843557\n",
      "\tspeed: 0.1289s/iter; left time: 7011.8871s\n",
      "1399it [03:00,  7.91it/s]\titers: 1400, epoch: 6 | loss: 0.1571867\n",
      "\tspeed: 0.1284s/iter; left time: 6971.6291s\n",
      "1499it [03:13,  7.82it/s]\titers: 1500, epoch: 6 | loss: 0.1495090\n",
      "\tspeed: 0.1293s/iter; left time: 7007.8482s\n",
      "1599it [03:26,  7.91it/s]\titers: 1600, epoch: 6 | loss: 0.0854176\n",
      "\tspeed: 0.1276s/iter; left time: 6903.1901s\n",
      "1699it [03:39,  7.76it/s]\titers: 1700, epoch: 6 | loss: 0.2547580\n",
      "\tspeed: 0.1293s/iter; left time: 6982.0451s\n",
      "1799it [03:52,  7.36it/s]\titers: 1800, epoch: 6 | loss: 0.1928886\n",
      "\tspeed: 0.1311s/iter; left time: 7067.7501s\n",
      "1899it [04:05,  7.91it/s]\titers: 1900, epoch: 6 | loss: 0.2520036\n",
      "\tspeed: 0.1297s/iter; left time: 6978.6015s\n",
      "1999it [04:18,  7.74it/s]\titers: 2000, epoch: 6 | loss: 0.1259657\n",
      "\tspeed: 0.1321s/iter; left time: 7091.9933s\n",
      "2099it [04:32,  7.94it/s]\titers: 2100, epoch: 6 | loss: 0.2468439\n",
      "\tspeed: 0.1327s/iter; left time: 7114.2890s\n",
      "2199it [04:45,  7.76it/s]\titers: 2200, epoch: 6 | loss: 0.1148948\n",
      "\tspeed: 0.1296s/iter; left time: 6935.5440s\n",
      "2299it [04:58,  7.76it/s]\titers: 2300, epoch: 6 | loss: 0.1980886\n",
      "\tspeed: 0.1296s/iter; left time: 6918.7712s\n",
      "2399it [05:11,  7.79it/s]\titers: 2400, epoch: 6 | loss: 0.1522728\n",
      "\tspeed: 0.1303s/iter; left time: 6942.8206s\n",
      "2499it [05:23,  7.57it/s]\titers: 2500, epoch: 6 | loss: 0.3693871\n",
      "\tspeed: 0.1294s/iter; left time: 6881.5834s\n",
      "2599it [05:36,  7.88it/s]\titers: 2600, epoch: 6 | loss: 0.1994973\n",
      "\tspeed: 0.1290s/iter; left time: 6850.5436s\n",
      "2699it [05:49,  7.54it/s]\titers: 2700, epoch: 6 | loss: 0.2647148\n",
      "\tspeed: 0.1301s/iter; left time: 6893.3708s\n",
      "2799it [06:02,  7.50it/s]\titers: 2800, epoch: 6 | loss: 0.2415183\n",
      "\tspeed: 0.1301s/iter; left time: 6880.5853s\n",
      "2899it [06:15,  7.75it/s]\titers: 2900, epoch: 6 | loss: 0.2359923\n",
      "\tspeed: 0.1307s/iter; left time: 6899.1244s\n",
      "2999it [06:28,  7.78it/s]\titers: 3000, epoch: 6 | loss: 0.1775244\n",
      "\tspeed: 0.1302s/iter; left time: 6860.4605s\n",
      "3099it [06:41,  7.86it/s]\titers: 3100, epoch: 6 | loss: 0.1864435\n",
      "\tspeed: 0.1296s/iter; left time: 6815.4564s\n",
      "3199it [06:54,  7.65it/s]\titers: 3200, epoch: 6 | loss: 0.1932236\n",
      "\tspeed: 0.1296s/iter; left time: 6802.6954s\n",
      "3299it [07:08,  7.90it/s]\titers: 3300, epoch: 6 | loss: 0.1104027\n",
      "\tspeed: 0.1315s/iter; left time: 6890.3689s\n",
      "3399it [07:21,  7.50it/s]\titers: 3400, epoch: 6 | loss: 0.2285420\n",
      "\tspeed: 0.1307s/iter; left time: 6837.5715s\n",
      "3499it [07:34,  7.67it/s]\titers: 3500, epoch: 6 | loss: 0.1582985\n",
      "\tspeed: 0.1314s/iter; left time: 6857.5049s\n",
      "3599it [07:47,  7.13it/s]\titers: 3600, epoch: 6 | loss: 0.2720512\n",
      "\tspeed: 0.1313s/iter; left time: 6840.3076s\n",
      "3699it [08:00,  7.84it/s]\titers: 3700, epoch: 6 | loss: 0.3566822\n",
      "\tspeed: 0.1300s/iter; left time: 6761.6529s\n",
      "3713it [08:02,  7.70it/s]\n",
      "Epoch: 6 cost time: 482.2840657234192\n",
      "810it [00:50, 16.17it/s]\n",
      "807it [00:48, 16.54it/s]\n",
      "Epoch: 6 | Train Loss: 0.2030284 Vali Loss: 0.2816860 Test Loss: 0.3389031 MAE Loss: 0.3452845\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "success delete checkpoints\n",
      "Total time: 59.024877615769704 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=24 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 21:13:47,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 21:13:47,950] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 21:13:47,951] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 21:13:50,105] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 21:13:50,667] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 21:13:50,668] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 21:13:50,668] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 21:13:50,669] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 21:13:50,669] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 21:13:50,669] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 21:13:50,670] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 21:13:50,670] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 21:13:50,670] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 21:13:50,670] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 21:13:51,156] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 21:13:51,156] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:13:51,157] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.48 GB, percent = 16.0%\n",
      "[2024-05-07 21:13:51,261] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 21:13:51,261] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:13:51,261] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.48 GB, percent = 16.0%\n",
      "[2024-05-07 21:13:51,261] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 21:13:51,361] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 21:13:51,361] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:13:51,361] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.53 GB, percent = 16.0%\n",
      "[2024-05-07 21:13:51,362] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 21:13:51,362] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 21:13:51,362] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 21:13:51,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 21:13:51,362] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 21:13:51,362] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 21:13:51,362] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 21:13:51,362] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 21:13:51,362] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7feb808edd90>\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 21:13:51,363] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   train_batch_size ............. 256\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  256\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 21:13:51,364] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 256, \n",
      "    \"train_micro_batch_size_per_gpu\": 256, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:53,  1.89it/s]\titers: 100, epoch: 1 | loss: 0.7883415\n",
      "\tspeed: 0.5461s/iter; left time: 3746.5207s\n",
      "199it [01:44,  1.93it/s]\titers: 200, epoch: 1 | loss: 0.7040399\n",
      "\tspeed: 0.5193s/iter; left time: 3510.8367s\n",
      "299it [02:37,  1.96it/s]\titers: 300, epoch: 1 | loss: 0.2462529\n",
      "\tspeed: 0.5221s/iter; left time: 3477.5102s\n",
      "348it [03:02,  1.91it/s]\n",
      "Epoch: 1 cost time: 182.52406334877014\n",
      "75it [00:24,  3.06it/s]\n",
      "75it [00:24,  3.12it/s]\n",
      "Epoch: 1 | Train Loss: 0.6489126 Vali Loss: 0.3186343 Test Loss: 0.3737744 MAE Loss: 0.3986427\n",
      "99it [00:48,  2.03it/s]\titers: 100, epoch: 2 | loss: 0.2622710\n",
      "\tspeed: 1.2446s/iter; left time: 8105.7729s\n",
      "199it [01:37,  2.07it/s]\titers: 200, epoch: 2 | loss: 0.2274466\n",
      "\tspeed: 0.4858s/iter; left time: 3115.3411s\n",
      "299it [02:26,  2.08it/s]\titers: 300, epoch: 2 | loss: 0.2788286\n",
      "\tspeed: 0.4873s/iter; left time: 3076.3501s\n",
      "348it [02:50,  2.04it/s]\n",
      "Epoch: 2 cost time: 170.18898272514343\n",
      "75it [00:21,  3.50it/s]\n",
      "75it [00:21,  3.43it/s]\n",
      "Epoch: 2 | Train Loss: 0.2694943 Vali Loss: 0.3127262 Test Loss: 0.3682635 MAE Loss: 0.3909483\n",
      "99it [00:48,  2.07it/s]\titers: 100, epoch: 3 | loss: 0.2945827\n",
      "\tspeed: 1.1784s/iter; left time: 7264.8179s\n",
      "199it [01:37,  2.06it/s]\titers: 200, epoch: 3 | loss: 0.2477433\n",
      "\tspeed: 0.4882s/iter; left time: 2960.8262s\n",
      "299it [02:26,  2.08it/s]\titers: 300, epoch: 3 | loss: 0.2773684\n",
      "\tspeed: 0.4879s/iter; left time: 2910.5801s\n",
      "348it [02:50,  2.05it/s]\n",
      "Epoch: 3 cost time: 170.09763026237488\n",
      "75it [00:22,  3.40it/s]\n",
      "75it [00:21,  3.49it/s]\n",
      "Epoch: 3 | Train Loss: 0.2665176 Vali Loss: 0.3220427 Test Loss: 0.3720944 MAE Loss: 0.3937257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "99it [00:48,  2.10it/s]\titers: 100, epoch: 4 | loss: 0.2660215\n",
      "\tspeed: 1.1657s/iter; left time: 6780.7754s\n",
      "199it [01:38,  2.07it/s]\titers: 200, epoch: 4 | loss: 0.2361992\n",
      "\tspeed: 0.4942s/iter; left time: 2825.1073s\n",
      "299it [02:27,  2.04it/s]\titers: 300, epoch: 4 | loss: 0.2522499\n",
      "\tspeed: 0.4907s/iter; left time: 2756.0219s\n",
      "348it [02:51,  2.03it/s]\n",
      "Epoch: 4 cost time: 171.59524369239807\n",
      "75it [00:21,  3.49it/s]\n",
      "75it [00:21,  3.55it/s]\n",
      "Epoch: 4 | Train Loss: 0.2613215 Vali Loss: 0.3110140 Test Loss: 0.3713182 MAE Loss: 0.3862818\n",
      "99it [00:48,  2.00it/s]\titers: 100, epoch: 5 | loss: 0.2827490\n",
      "\tspeed: 1.1722s/iter; left time: 6410.7568s\n",
      "159it [01:18,  2.06it/s]^C\n",
      "[2024-05-07 21:29:47,705] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2024-05-07 21:29:47,705] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 68972 closing signal SIGINT\n",
      "159it [01:18,  2.02it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main_onecycle_batch.py\", line 222, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 2002, in backward\n",
      "    self.allreduce_gradients()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1918, in allreduce_gradients\n",
      "    self.optimizer.overlapping_partition_gradients_reduce_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 859, in overlapping_partition_gradients_reduce_epilogue\n",
      "    self.independent_gradient_partition_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 760, in independent_gradient_partition_epilogue\n",
      "    get_accelerator().synchronize()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/accelerator/cuda_accelerator.py\", line 77, in synchronize\n",
      "    return torch.cuda.synchronize(device_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 801, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 16.16052524248759 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=12 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=256\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main_onecycle_batch.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 21:30:29,368] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 21:30:30,395] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 21:30:30,395] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 21:30:32,319] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 21:30:32,859] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 21:30:32,860] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 21:30:32,860] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 21:30:32,861] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 21:30:32,861] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 21:30:32,861] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 21:30:32,862] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 21:30:32,862] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 21:30:32,862] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 21:30:32,862] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 21:30:33,104] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 21:30:33,105] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:30:33,105] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.37 GB, percent = 16.1%\n",
      "[2024-05-07 21:30:33,325] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 21:30:33,326] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:30:33,326] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.39 GB, percent = 16.1%\n",
      "[2024-05-07 21:30:33,326] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 21:30:33,433] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 21:30:33,434] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:30:33,434] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.41 GB, percent = 16.1%\n",
      "[2024-05-07 21:30:33,434] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 21:30:33,434] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 21:30:33,434] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 21:30:33,434] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faeef3a3350>\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 21:30:33,435] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 21:30:33,436] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.1\n",
      "lr 0.0040000000000000036\n",
      "98it [00:08, 14.30it/s]\titers: 100, epoch: 1 | loss: 1.3018347\n",
      "\tspeed: 0.0930s/iter; left time: 6895.5333s\n",
      "198it [00:15, 15.25it/s]\titers: 200, epoch: 1 | loss: 0.2773972\n",
      "\tspeed: 0.0703s/iter; left time: 5208.9335s\n",
      "298it [00:21, 15.38it/s]\titers: 300, epoch: 1 | loss: 0.5414254\n",
      "\tspeed: 0.0651s/iter; left time: 4814.5887s\n",
      "398it [00:28, 15.23it/s]\titers: 400, epoch: 1 | loss: 0.3951997\n",
      "\tspeed: 0.0657s/iter; left time: 4852.4056s\n",
      "498it [00:35, 14.12it/s]\titers: 500, epoch: 1 | loss: 0.3838741\n",
      "\tspeed: 0.0703s/iter; left time: 5187.9004s\n",
      "598it [00:42, 14.09it/s]\titers: 600, epoch: 1 | loss: 0.4530095\n",
      "\tspeed: 0.0711s/iter; left time: 5235.2902s\n",
      "698it [00:49, 15.28it/s]\titers: 700, epoch: 1 | loss: 0.4901458\n",
      "\tspeed: 0.0698s/iter; left time: 5135.6989s\n",
      "798it [00:55, 15.29it/s]\titers: 800, epoch: 1 | loss: 0.2672842\n",
      "\tspeed: 0.0655s/iter; left time: 4814.3995s\n",
      "898it [01:02, 15.19it/s]\titers: 900, epoch: 1 | loss: 0.2285301\n",
      "\tspeed: 0.0658s/iter; left time: 4829.6369s\n",
      "998it [01:09, 15.23it/s]\titers: 1000, epoch: 1 | loss: 0.5595503\n",
      "\tspeed: 0.0672s/iter; left time: 4925.9166s\n",
      "1098it [01:15, 15.26it/s]\titers: 1100, epoch: 1 | loss: 0.3235709\n",
      "\tspeed: 0.0660s/iter; left time: 4827.6856s\n",
      "1198it [01:23, 13.88it/s]\titers: 1200, epoch: 1 | loss: 0.5283078\n",
      "\tspeed: 0.0727s/iter; left time: 5310.5958s\n",
      "1298it [01:30, 14.14it/s]\titers: 1300, epoch: 1 | loss: 0.2374892\n",
      "\tspeed: 0.0708s/iter; left time: 5164.2723s\n",
      "1398it [01:37, 14.17it/s]\titers: 1400, epoch: 1 | loss: 0.3900464\n",
      "\tspeed: 0.0708s/iter; left time: 5156.7466s\n",
      "1498it [01:44, 14.18it/s]\titers: 1500, epoch: 1 | loss: 0.2501970\n",
      "\tspeed: 0.0727s/iter; left time: 5289.8498s\n",
      "1598it [01:51, 14.12it/s]\titers: 1600, epoch: 1 | loss: 0.2322036\n",
      "\tspeed: 0.0708s/iter; left time: 5143.2923s\n",
      "1698it [01:58, 15.54it/s]\titers: 1700, epoch: 1 | loss: 0.4848007\n",
      "\tspeed: 0.0699s/iter; left time: 5074.7511s\n",
      "1798it [02:05, 13.72it/s]\titers: 1800, epoch: 1 | loss: 0.5632914\n",
      "\tspeed: 0.0716s/iter; left time: 5184.9795s\n",
      "1898it [02:12, 13.68it/s]\titers: 1900, epoch: 1 | loss: 0.2422455\n",
      "\tspeed: 0.0723s/iter; left time: 5235.2653s\n",
      "1998it [02:20, 14.16it/s]\titers: 2000, epoch: 1 | loss: 0.2809480\n",
      "\tspeed: 0.0735s/iter; left time: 5313.1711s\n",
      "2098it [02:27, 14.15it/s]\titers: 2100, epoch: 1 | loss: 0.7111614\n",
      "\tspeed: 0.0710s/iter; left time: 5126.6564s\n",
      "2198it [02:34, 14.04it/s]\titers: 2200, epoch: 1 | loss: 0.2816000\n",
      "\tspeed: 0.0760s/iter; left time: 5479.6876s\n",
      "2298it [02:42, 14.11it/s]\titers: 2300, epoch: 1 | loss: 0.2601966\n",
      "\tspeed: 0.0712s/iter; left time: 5120.9973s\n",
      "2398it [02:49, 14.63it/s]\titers: 2400, epoch: 1 | loss: 0.3540437\n",
      "\tspeed: 0.0694s/iter; left time: 4986.4452s\n",
      "2498it [02:56, 14.20it/s]\titers: 2500, epoch: 1 | loss: 0.2655982\n",
      "\tspeed: 0.0734s/iter; left time: 5265.7191s\n",
      "2598it [03:03, 14.13it/s]\titers: 2600, epoch: 1 | loss: 0.3539497\n",
      "\tspeed: 0.0710s/iter; left time: 5085.5533s\n",
      "2698it [03:10, 15.47it/s]\titers: 2700, epoch: 1 | loss: 0.3898718\n",
      "\tspeed: 0.0715s/iter; left time: 5116.6501s\n",
      "2798it [03:17, 15.24it/s]\titers: 2800, epoch: 1 | loss: 0.2510217\n",
      "\tspeed: 0.0655s/iter; left time: 4677.1491s\n",
      "2898it [03:23, 14.97it/s]\titers: 2900, epoch: 1 | loss: 0.4762558\n",
      "\tspeed: 0.0664s/iter; left time: 4735.6238s\n",
      "2998it [03:30, 14.13it/s]\titers: 3000, epoch: 1 | loss: 0.3308515\n",
      "\tspeed: 0.0719s/iter; left time: 5125.9460s\n",
      "3098it [03:38, 14.13it/s]\titers: 3100, epoch: 1 | loss: 0.4297276\n",
      "\tspeed: 0.0707s/iter; left time: 5032.9503s\n",
      "3198it [03:45, 14.15it/s]\titers: 3200, epoch: 1 | loss: 0.3559036\n",
      "\tspeed: 0.0752s/iter; left time: 5345.6990s\n",
      "3298it [03:52, 14.09it/s]\titers: 3300, epoch: 1 | loss: 0.5769126\n",
      "\tspeed: 0.0708s/iter; left time: 5021.7769s\n",
      "3398it [04:00, 13.63it/s]\titers: 3400, epoch: 1 | loss: 0.6221976\n",
      "\tspeed: 0.0754s/iter; left time: 5339.6618s\n",
      "3498it [04:07, 14.14it/s]\titers: 3500, epoch: 1 | loss: 0.3641264\n",
      "\tspeed: 0.0708s/iter; left time: 5007.4580s\n",
      "3598it [04:14, 14.10it/s]\titers: 3600, epoch: 1 | loss: 0.4351018\n",
      "\tspeed: 0.0713s/iter; left time: 5036.7616s\n",
      "3698it [04:21, 14.15it/s]\titers: 3700, epoch: 1 | loss: 0.4874085\n",
      "\tspeed: 0.0753s/iter; left time: 5315.8616s\n",
      "3713it [04:23, 14.12it/s]\n",
      "Epoch: 1 cost time: 263.0463237762451\n",
      "810it [00:29, 27.45it/s]\n",
      "807it [00:29, 27.68it/s]\n",
      "Epoch: 1 | Train Loss: 0.6286423 Vali Loss: 0.5355053 Test Loss: 0.6813103 MAE Loss: 0.5999266\n",
      "lr = 0.0040000000\n",
      "Updating learning rate to 0.0040000000000000036\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0040000000000000036\n",
      "99it [00:07, 14.18it/s]\titers: 100, epoch: 2 | loss: 0.6214426\n",
      "\tspeed: 0.6871s/iter; left time: 48407.2361s\n",
      "199it [00:14, 14.10it/s]\titers: 200, epoch: 2 | loss: 0.2989522\n",
      "\tspeed: 0.0704s/iter; left time: 4950.5700s\n",
      "299it [00:21, 14.21it/s]\titers: 300, epoch: 2 | loss: 0.4888882\n",
      "\tspeed: 0.0718s/iter; left time: 5040.5758s\n",
      "399it [00:28, 14.21it/s]\titers: 400, epoch: 2 | loss: 0.2795322\n",
      "\tspeed: 0.0705s/iter; left time: 4945.2435s\n",
      "499it [00:36, 13.92it/s]\titers: 500, epoch: 2 | loss: 0.4207671\n",
      "\tspeed: 0.0731s/iter; left time: 5119.3977s\n",
      "599it [00:43, 14.44it/s]\titers: 600, epoch: 2 | loss: 0.5384430\n",
      "\tspeed: 0.0707s/iter; left time: 4942.7416s\n",
      "699it [00:50, 14.31it/s]\titers: 700, epoch: 2 | loss: 0.6434021\n",
      "\tspeed: 0.0706s/iter; left time: 4933.4448s\n",
      "799it [00:57, 14.13it/s]\titers: 800, epoch: 2 | loss: 0.5268459\n",
      "\tspeed: 0.0718s/iter; left time: 5008.3613s\n",
      "899it [01:04, 14.18it/s]\titers: 900, epoch: 2 | loss: 0.4619353\n",
      "\tspeed: 0.0707s/iter; left time: 4921.3752s\n",
      "999it [01:11, 14.19it/s]\titers: 1000, epoch: 2 | loss: 0.4086932\n",
      "\tspeed: 0.0720s/iter; left time: 5006.1337s\n",
      "1099it [01:18, 14.14it/s]\titers: 1100, epoch: 2 | loss: 0.2481058\n",
      "\tspeed: 0.0705s/iter; left time: 4899.2745s\n",
      "1199it [01:26, 14.08it/s]\titers: 1200, epoch: 2 | loss: 0.3965248\n",
      "\tspeed: 0.0744s/iter; left time: 5160.6387s\n",
      "1299it [01:33, 14.09it/s]\titers: 1300, epoch: 2 | loss: 0.4694316\n",
      "\tspeed: 0.0706s/iter; left time: 4888.6028s\n",
      "1399it [01:40, 12.63it/s]\titers: 1400, epoch: 2 | loss: 0.4078845\n",
      "\tspeed: 0.0725s/iter; left time: 5015.0331s\n",
      "1499it [01:47, 14.18it/s]\titers: 1500, epoch: 2 | loss: 0.2782418\n",
      "\tspeed: 0.0679s/iter; left time: 4685.2144s\n",
      "1599it [01:54, 14.93it/s]\titers: 1600, epoch: 2 | loss: 0.4097579\n",
      "\tspeed: 0.0703s/iter; left time: 4845.9877s\n",
      "1699it [02:01, 14.14it/s]\titers: 1700, epoch: 2 | loss: 0.4311902\n",
      "\tspeed: 0.0730s/iter; left time: 5028.8246s\n",
      "1799it [02:08, 14.17it/s]\titers: 1800, epoch: 2 | loss: 0.3299456\n",
      "\tspeed: 0.0704s/iter; left time: 4837.4607s\n",
      "1899it [02:15, 13.93it/s]\titers: 1900, epoch: 2 | loss: 0.4830045\n",
      "\tspeed: 0.0743s/iter; left time: 5101.8871s\n",
      "1999it [02:23, 14.11it/s]\titers: 2000, epoch: 2 | loss: 0.3055364\n",
      "\tspeed: 0.0705s/iter; left time: 4835.1359s\n",
      "2099it [02:30, 14.26it/s]\titers: 2100, epoch: 2 | loss: 0.6179667\n",
      "\tspeed: 0.0708s/iter; left time: 4843.2256s\n",
      "2199it [02:37, 14.09it/s]\titers: 2200, epoch: 2 | loss: 0.4922070\n",
      "\tspeed: 0.0753s/iter; left time: 5147.9134s\n",
      "2299it [02:44, 14.41it/s]\titers: 2300, epoch: 2 | loss: 0.4491961\n",
      "\tspeed: 0.0707s/iter; left time: 4825.2709s\n",
      "2399it [02:52, 14.09it/s]\titers: 2400, epoch: 2 | loss: 0.2701320\n",
      "\tspeed: 0.0748s/iter; left time: 5099.8850s\n",
      "2499it [02:59, 14.08it/s]\titers: 2500, epoch: 2 | loss: 0.7289787\n",
      "\tspeed: 0.0705s/iter; left time: 4798.8668s\n",
      "2599it [03:06, 11.27it/s]\titers: 2600, epoch: 2 | loss: 0.5003756\n",
      "\tspeed: 0.0724s/iter; left time: 4921.6238s\n",
      "2699it [03:13, 14.08it/s]\titers: 2700, epoch: 2 | loss: 0.6010097\n",
      "\tspeed: 0.0729s/iter; left time: 4945.3647s\n",
      "2799it [03:20, 14.20it/s]\titers: 2800, epoch: 2 | loss: 0.3696593\n",
      "\tspeed: 0.0707s/iter; left time: 4790.7209s\n",
      "2899it [03:27, 16.27it/s]\titers: 2900, epoch: 2 | loss: 0.5907549\n",
      "\tspeed: 0.0676s/iter; left time: 4571.6776s\n",
      "2999it [03:33, 16.21it/s]\titers: 3000, epoch: 2 | loss: 0.4649055\n",
      "\tspeed: 0.0617s/iter; left time: 4164.6212s\n",
      "3099it [03:39, 16.14it/s]\titers: 3100, epoch: 2 | loss: 0.4051694\n",
      "\tspeed: 0.0617s/iter; left time: 4161.3681s\n",
      "3199it [03:46, 16.16it/s]\titers: 3200, epoch: 2 | loss: 0.4013422\n",
      "\tspeed: 0.0633s/iter; left time: 4260.3823s\n",
      "3299it [03:52, 16.19it/s]\titers: 3300, epoch: 2 | loss: 0.5216808\n",
      "\tspeed: 0.0619s/iter; left time: 4162.4398s\n",
      "3399it [03:59, 14.07it/s]\titers: 3400, epoch: 2 | loss: 0.3848541\n",
      "\tspeed: 0.0746s/iter; left time: 5009.8964s\n",
      "3499it [04:06, 14.09it/s]\titers: 3500, epoch: 2 | loss: 0.3608422\n",
      "\tspeed: 0.0705s/iter; left time: 4725.8307s\n",
      "3599it [04:14, 14.10it/s]\titers: 3600, epoch: 2 | loss: 0.7046528\n",
      "\tspeed: 0.0707s/iter; left time: 4734.4603s\n",
      "3699it [04:21, 14.16it/s]\titers: 3700, epoch: 2 | loss: 0.4068891\n",
      "\tspeed: 0.0753s/iter; left time: 5034.7506s\n",
      "3713it [04:22, 14.14it/s]\n",
      "Epoch: 2 cost time: 262.64594411849976\n",
      "810it [00:26, 30.27it/s]\n",
      "807it [00:26, 30.38it/s]\n",
      "Epoch: 2 | Train Loss: 0.4587001 Vali Loss: 0.5627227 Test Loss: 0.6904276 MAE Loss: 0.5884605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0020000000000000018\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0020000000000000018\n",
      "99it [00:07, 14.35it/s]\titers: 100, epoch: 3 | loss: 0.2903684\n",
      "\tspeed: 0.6175s/iter; left time: 41211.7335s\n",
      "199it [00:14, 15.69it/s]\titers: 200, epoch: 3 | loss: 0.3505423\n",
      "\tspeed: 0.0677s/iter; left time: 4510.1197s\n",
      "217it [00:15, 16.07it/s]^C\n",
      "[2024-05-07 21:41:28,041] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2024-05-07 21:41:28,042] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 19110 closing signal SIGINT\n",
      "218it [00:15, 14.26it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 259, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Total time: 11.173830191294352 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.1\n",
    "llama_layers=12 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad, lr 0.01, GPT2 - 12 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-07 21:41:50,720] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 21:41:51,932] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 21:41:51,932] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-07 21:41:53,725] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 21:41:54,255] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 21:41:54,256] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 21:41:54,256] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 21:41:54,257] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 21:41:54,257] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 21:41:54,257] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 21:41:54,257] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 21:41:54,257] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 21:41:54,257] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 21:41:54,257] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 21:41:54,704] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 21:41:54,704] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:41:54,705] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.26 GB, percent = 16.7%\n",
      "[2024-05-07 21:41:54,823] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 21:41:54,827] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:41:54,827] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.4 GB, percent = 16.8%\n",
      "[2024-05-07 21:41:54,827] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 21:41:54,965] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 21:41:54,966] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-07 21:41:54,966] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.53 GB, percent = 16.8%\n",
      "[2024-05-07 21:41:54,966] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 21:41:54,966] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 21:41:54,966] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 21:41:54,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003999999999999993], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fee51f21150>\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 21:41:54,967] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 21:41:54,968] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.01\n",
      "lr 0.0003999999999999993\n",
      "99it [00:08, 14.02it/s]\titers: 100, epoch: 1 | loss: 0.5836514\n",
      "\tspeed: 0.1006s/iter; left time: 7460.5930s\n",
      "199it [00:15, 13.85it/s]\titers: 200, epoch: 1 | loss: 0.1995095\n",
      "\tspeed: 0.0714s/iter; left time: 5291.5705s\n",
      "299it [00:23, 14.12it/s]\titers: 300, epoch: 1 | loss: 0.3300208\n",
      "\tspeed: 0.0709s/iter; left time: 5241.0281s\n",
      "399it [00:30, 14.10it/s]\titers: 400, epoch: 1 | loss: 0.3175232\n",
      "\tspeed: 0.0712s/iter; left time: 5257.9168s\n",
      "499it [00:37, 13.83it/s]\titers: 500, epoch: 1 | loss: 0.3049659\n",
      "\tspeed: 0.0713s/iter; left time: 5260.5933s\n",
      "599it [00:44, 15.33it/s]\titers: 600, epoch: 1 | loss: 0.3909899\n",
      "\tspeed: 0.0688s/iter; left time: 5064.7947s\n",
      "699it [00:50, 14.78it/s]\titers: 700, epoch: 1 | loss: 0.4301423\n",
      "\tspeed: 0.0663s/iter; left time: 4874.4556s\n",
      "799it [00:57, 15.24it/s]\titers: 800, epoch: 1 | loss: 0.2574376\n",
      "\tspeed: 0.0701s/iter; left time: 5147.6562s\n",
      "899it [01:04, 14.11it/s]\titers: 900, epoch: 1 | loss: 0.1871500\n",
      "\tspeed: 0.0694s/iter; left time: 5088.8495s\n",
      "999it [01:11, 14.08it/s]\titers: 1000, epoch: 1 | loss: 0.5983112\n",
      "\tspeed: 0.0709s/iter; left time: 5195.1229s\n",
      "1099it [01:19, 14.62it/s]\titers: 1100, epoch: 1 | loss: 0.3021997\n",
      "\tspeed: 0.0738s/iter; left time: 5400.2533s\n",
      "1199it [01:26, 14.28it/s]\titers: 1200, epoch: 1 | loss: 0.4689808\n",
      "\tspeed: 0.0700s/iter; left time: 5116.1868s\n",
      "1299it [01:33, 13.89it/s]\titers: 1300, epoch: 1 | loss: 0.2274295\n",
      "\tspeed: 0.0758s/iter; left time: 5530.1840s\n",
      "1399it [01:40, 14.16it/s]\titers: 1400, epoch: 1 | loss: 0.3468739\n",
      "\tspeed: 0.0708s/iter; left time: 5155.0224s\n",
      "1499it [01:47, 14.65it/s]\titers: 1500, epoch: 1 | loss: 0.1709339\n",
      "\tspeed: 0.0704s/iter; left time: 5121.4772s\n",
      "1599it [01:55, 14.15it/s]\titers: 1600, epoch: 1 | loss: 0.1894719\n",
      "\tspeed: 0.0727s/iter; left time: 5280.8167s\n",
      "1699it [02:02, 14.65it/s]\titers: 1700, epoch: 1 | loss: 0.3699158\n",
      "\tspeed: 0.0708s/iter; left time: 5135.7945s\n",
      "1799it [02:09, 14.13it/s]\titers: 1800, epoch: 1 | loss: 0.5675749\n",
      "\tspeed: 0.0723s/iter; left time: 5238.4967s\n",
      "1899it [02:16, 14.44it/s]\titers: 1900, epoch: 1 | loss: 0.2678504\n",
      "\tspeed: 0.0707s/iter; left time: 5112.4058s\n",
      "1999it [02:23, 13.87it/s]\titers: 2000, epoch: 1 | loss: 0.2136116\n",
      "\tspeed: 0.0708s/iter; left time: 5115.0557s\n",
      "2099it [02:30, 14.14it/s]\titers: 2100, epoch: 1 | loss: 0.7287684\n",
      "\tspeed: 0.0726s/iter; left time: 5237.5981s\n",
      "2199it [02:37, 14.17it/s]\titers: 2200, epoch: 1 | loss: 0.2062197\n",
      "\tspeed: 0.0708s/iter; left time: 5103.2736s\n",
      "2299it [02:45, 14.12it/s]\titers: 2300, epoch: 1 | loss: 0.1987709\n",
      "\tspeed: 0.0732s/iter; left time: 5268.5711s\n",
      "2399it [02:52, 14.22it/s]\titers: 2400, epoch: 1 | loss: 0.2918237\n",
      "\tspeed: 0.0705s/iter; left time: 5066.8474s\n",
      "2499it [02:59, 13.50it/s]\titers: 2500, epoch: 1 | loss: 0.2548137\n",
      "\tspeed: 0.0730s/iter; left time: 5238.0997s\n",
      "2599it [03:06, 14.16it/s]\titers: 2600, epoch: 1 | loss: 0.2414641\n",
      "\tspeed: 0.0708s/iter; left time: 5072.1574s\n",
      "2699it [03:13, 14.06it/s]\titers: 2700, epoch: 1 | loss: 0.3367170\n",
      "\tspeed: 0.0709s/iter; left time: 5073.0216s\n",
      "2799it [03:21, 14.17it/s]\titers: 2800, epoch: 1 | loss: 0.2078272\n",
      "\tspeed: 0.0734s/iter; left time: 5245.7614s\n",
      "2899it [03:28, 14.17it/s]\titers: 2900, epoch: 1 | loss: 0.2959862\n",
      "\tspeed: 0.0708s/iter; left time: 5051.5397s\n",
      "2999it [03:35, 14.15it/s]\titers: 3000, epoch: 1 | loss: 0.2478465\n",
      "\tspeed: 0.0733s/iter; left time: 5225.8440s\n",
      "3099it [03:42, 14.09it/s]\titers: 3100, epoch: 1 | loss: 0.4699209\n",
      "\tspeed: 0.0707s/iter; left time: 5033.9791s\n",
      "3199it [03:49, 14.10it/s]\titers: 3200, epoch: 1 | loss: 0.3440496\n",
      "\tspeed: 0.0728s/iter; left time: 5173.8170s\n",
      "3299it [03:56, 14.95it/s]\titers: 3300, epoch: 1 | loss: 0.4867219\n",
      "\tspeed: 0.0702s/iter; left time: 4984.7005s\n",
      "3399it [04:03, 13.00it/s]\titers: 3400, epoch: 1 | loss: 0.3700071\n",
      "\tspeed: 0.0708s/iter; left time: 5014.3213s\n",
      "3499it [04:11, 13.89it/s]\titers: 3500, epoch: 1 | loss: 0.2317251\n",
      "\tspeed: 0.0744s/iter; left time: 5263.6494s\n",
      "3599it [04:18, 13.90it/s]\titers: 3600, epoch: 1 | loss: 0.3402976\n",
      "\tspeed: 0.0712s/iter; left time: 5027.6161s\n",
      "3699it [04:26, 14.12it/s]\titers: 3700, epoch: 1 | loss: 0.4496215\n",
      "\tspeed: 0.0760s/iter; left time: 5365.4412s\n",
      "3713it [04:27, 13.90it/s]\n",
      "Epoch: 1 cost time: 267.1778824329376\n",
      "810it [00:29, 27.53it/s]\n",
      "807it [00:29, 27.15it/s]\n",
      "Epoch: 1 | Train Loss: 0.3208009 Vali Loss: 0.3561391 Test Loss: 0.4409448 MAE Loss: 0.4430181\n",
      "lr = 0.0004000000\n",
      "Updating learning rate to 0.0003999999999999993\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 0.0003999999999999993\n",
      "99it [00:07, 14.20it/s]\titers: 100, epoch: 2 | loss: 0.3807177\n",
      "\tspeed: 0.6926s/iter; left time: 48789.5863s\n",
      "199it [00:14, 14.25it/s]\titers: 200, epoch: 2 | loss: 0.2954260\n",
      "\tspeed: 0.0707s/iter; left time: 4971.7088s\n",
      "299it [00:21, 12.51it/s]\titers: 300, epoch: 2 | loss: 0.4302769\n",
      "\tspeed: 0.0719s/iter; left time: 5047.6047s\n",
      "399it [00:28, 13.64it/s]\titers: 400, epoch: 2 | loss: 0.1375852\n",
      "\tspeed: 0.0723s/iter; left time: 5074.9070s\n",
      "499it [00:36, 14.40it/s]\titers: 500, epoch: 2 | loss: 0.2626297\n",
      "\tspeed: 0.0710s/iter; left time: 4974.0205s\n",
      "599it [00:42, 16.35it/s]\titers: 600, epoch: 2 | loss: 0.4243643\n",
      "\tspeed: 0.0670s/iter; left time: 4686.0316s\n",
      "699it [00:48, 16.24it/s]\titers: 700, epoch: 2 | loss: 0.5233704\n",
      "\tspeed: 0.0618s/iter; left time: 4318.4113s\n",
      "799it [00:55, 14.16it/s]\titers: 800, epoch: 2 | loss: 0.3958096\n",
      "\tspeed: 0.0634s/iter; left time: 4423.3307s\n",
      "899it [01:02, 14.17it/s]\titers: 900, epoch: 2 | loss: 0.2556992\n",
      "\tspeed: 0.0718s/iter; left time: 5004.2013s\n",
      "999it [01:09, 14.23it/s]\titers: 1000, epoch: 2 | loss: 0.2820742\n",
      "\tspeed: 0.0707s/iter; left time: 4917.2245s\n",
      "1099it [01:16, 14.19it/s]\titers: 1100, epoch: 2 | loss: 0.1572514\n",
      "\tspeed: 0.0736s/iter; left time: 5111.5082s\n",
      "1199it [01:24, 14.13it/s]\titers: 1200, epoch: 2 | loss: 0.2641591\n",
      "\tspeed: 0.0707s/iter; left time: 4904.7102s\n",
      "1299it [01:31, 14.20it/s]\titers: 1300, epoch: 2 | loss: 0.2594783\n",
      "\tspeed: 0.0737s/iter; left time: 5102.9843s\n",
      "1399it [01:37, 16.16it/s]\titers: 1400, epoch: 2 | loss: 0.3434907\n",
      "\tspeed: 0.0632s/iter; left time: 4369.4684s\n",
      "1499it [01:44, 13.00it/s]\titers: 1500, epoch: 2 | loss: 0.1935534\n",
      "\tspeed: 0.0714s/iter; left time: 4927.8210s\n",
      "1599it [01:51, 14.10it/s]\titers: 1600, epoch: 2 | loss: 0.2813818\n",
      "\tspeed: 0.0712s/iter; left time: 4908.1691s\n",
      "1699it [01:59, 14.16it/s]\titers: 1700, epoch: 2 | loss: 0.3038721\n",
      "\tspeed: 0.0708s/iter; left time: 4872.7634s\n",
      "1799it [02:06, 14.17it/s]\titers: 1800, epoch: 2 | loss: 0.2573387\n",
      "\tspeed: 0.0743s/iter; left time: 5107.0156s\n",
      "1899it [02:13, 13.84it/s]\titers: 1900, epoch: 2 | loss: 0.3629737\n",
      "\tspeed: 0.0707s/iter; left time: 4853.5541s\n",
      "1999it [02:20, 13.98it/s]\titers: 2000, epoch: 2 | loss: 0.2843108\n",
      "\tspeed: 0.0710s/iter; left time: 4863.7705s\n",
      "2099it [02:27, 14.17it/s]\titers: 2100, epoch: 2 | loss: 0.5417817\n",
      "\tspeed: 0.0718s/iter; left time: 4913.9365s\n",
      "2199it [02:34, 14.08it/s]\titers: 2200, epoch: 2 | loss: 0.3306193\n",
      "\tspeed: 0.0707s/iter; left time: 4835.1925s\n",
      "2299it [02:42, 14.24it/s]\titers: 2300, epoch: 2 | loss: 0.3984080\n",
      "\tspeed: 0.0728s/iter; left time: 4969.4635s\n",
      "2399it [02:49, 14.13it/s]\titers: 2400, epoch: 2 | loss: 0.1687707\n",
      "\tspeed: 0.0707s/iter; left time: 4817.7815s\n",
      "2499it [02:56, 14.11it/s]\titers: 2500, epoch: 2 | loss: 0.3206879\n",
      "\tspeed: 0.0716s/iter; left time: 4875.2248s\n",
      "2599it [03:03, 14.06it/s]\titers: 2600, epoch: 2 | loss: 0.3922915\n",
      "\tspeed: 0.0706s/iter; left time: 4797.9465s\n",
      "2699it [03:10, 13.94it/s]\titers: 2700, epoch: 2 | loss: 0.5193573\n",
      "\tspeed: 0.0708s/iter; left time: 4801.2011s\n",
      "2799it [03:17, 14.19it/s]\titers: 2800, epoch: 2 | loss: 0.3060983\n",
      "\tspeed: 0.0720s/iter; left time: 4875.0917s\n",
      "2899it [03:24, 14.11it/s]\titers: 2900, epoch: 2 | loss: 0.4765341\n",
      "\tspeed: 0.0708s/iter; left time: 4791.3136s\n",
      "2999it [03:32, 14.15it/s]\titers: 3000, epoch: 2 | loss: 0.3631784\n",
      "\tspeed: 0.0732s/iter; left time: 4945.7887s\n",
      "3099it [03:39, 14.12it/s]\titers: 3100, epoch: 2 | loss: 0.2606176\n",
      "\tspeed: 0.0707s/iter; left time: 4768.3783s\n",
      "3199it [03:46, 14.05it/s]\titers: 3200, epoch: 2 | loss: 0.2050763\n",
      "\tspeed: 0.0733s/iter; left time: 4936.4367s\n",
      "3299it [03:53, 14.34it/s]\titers: 3300, epoch: 2 | loss: 0.3002484\n",
      "\tspeed: 0.0706s/iter; left time: 4749.8835s\n",
      "3399it [04:00, 11.96it/s]\titers: 3400, epoch: 2 | loss: 0.2471168\n",
      "\tspeed: 0.0716s/iter; left time: 4808.8816s\n",
      "3499it [04:07, 14.13it/s]\titers: 3500, epoch: 2 | loss: 0.2697740\n",
      "\tspeed: 0.0711s/iter; left time: 4766.8523s\n",
      "3599it [04:14, 14.03it/s]\titers: 3600, epoch: 2 | loss: 0.4471852\n",
      "\tspeed: 0.0709s/iter; left time: 4748.4644s\n",
      "3699it [04:22, 14.27it/s]\titers: 3700, epoch: 2 | loss: 0.2424006\n",
      "\tspeed: 0.0729s/iter; left time: 4873.8253s\n",
      "3713it [04:23, 14.10it/s]\n",
      "Epoch: 2 cost time: 263.28896021842957\n",
      "810it [00:26, 30.81it/s]\n",
      "807it [00:27, 29.64it/s]\n",
      "Epoch: 2 | Train Loss: 0.3082944 Vali Loss: 0.3677447 Test Loss: 0.4620375 MAE Loss: 0.4458528\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00019999999999999966\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 0.00019999999999999966\n",
      "99it [00:07, 14.11it/s]\titers: 100, epoch: 3 | loss: 0.2060168\n",
      "\tspeed: 0.6204s/iter; left time: 41403.5706s\n",
      "199it [00:14, 14.20it/s]\titers: 200, epoch: 3 | loss: 0.2320447\n",
      "\tspeed: 0.0753s/iter; left time: 5019.5578s\n",
      "299it [00:21, 14.25it/s]\titers: 300, epoch: 3 | loss: 0.2089755\n",
      "\tspeed: 0.0706s/iter; left time: 4699.6635s\n",
      "399it [00:29, 14.15it/s]\titers: 400, epoch: 3 | loss: 0.1816453\n",
      "\tspeed: 0.0729s/iter; left time: 4840.2360s\n",
      "499it [00:36, 14.14it/s]\titers: 500, epoch: 3 | loss: 0.2663675\n",
      "\tspeed: 0.0704s/iter; left time: 4667.3466s\n",
      "599it [00:43, 13.62it/s]\titers: 600, epoch: 3 | loss: 0.4034433\n",
      "\tspeed: 0.0724s/iter; left time: 4795.9356s\n",
      "699it [00:50, 14.11it/s]\titers: 700, epoch: 3 | loss: 0.2279717\n",
      "\tspeed: 0.0705s/iter; left time: 4660.3209s\n",
      "799it [00:57, 14.21it/s]\titers: 800, epoch: 3 | loss: 0.3731582\n",
      "\tspeed: 0.0708s/iter; left time: 4672.2000s\n",
      "899it [01:05, 14.11it/s]\titers: 900, epoch: 3 | loss: 0.2372894\n",
      "\tspeed: 0.0752s/iter; left time: 4958.7544s\n",
      "999it [01:12, 14.31it/s]\titers: 1000, epoch: 3 | loss: 0.3016148\n",
      "\tspeed: 0.0706s/iter; left time: 4644.6866s\n",
      "1099it [01:19, 14.13it/s]\titers: 1100, epoch: 3 | loss: 0.2362360\n",
      "\tspeed: 0.0721s/iter; left time: 4740.9321s\n",
      "1199it [01:26, 14.08it/s]\titers: 1200, epoch: 3 | loss: 0.2171668\n",
      "\tspeed: 0.0708s/iter; left time: 4644.8296s\n",
      "1299it [01:33, 14.18it/s]\titers: 1300, epoch: 3 | loss: 0.2963160\n",
      "\tspeed: 0.0723s/iter; left time: 4737.9261s\n",
      "1399it [01:40, 14.08it/s]\titers: 1400, epoch: 3 | loss: 0.2736282\n",
      "\tspeed: 0.0702s/iter; left time: 4592.5278s\n",
      "1499it [01:47, 14.21it/s]\titers: 1500, epoch: 3 | loss: 0.3048444\n",
      "\tspeed: 0.0708s/iter; left time: 4625.9360s\n",
      "1599it [01:55, 13.99it/s]\titers: 1600, epoch: 3 | loss: 0.5499757\n",
      "\tspeed: 0.0731s/iter; left time: 4768.7209s\n",
      "1699it [02:02, 14.27it/s]\titers: 1700, epoch: 3 | loss: 0.2527401\n",
      "\tspeed: 0.0704s/iter; left time: 4583.8971s\n",
      "1799it [02:09, 14.18it/s]\titers: 1800, epoch: 3 | loss: 0.3268303\n",
      "\tspeed: 0.0729s/iter; left time: 4741.2237s\n",
      "1899it [02:16, 14.07it/s]\titers: 1900, epoch: 3 | loss: 0.2667126\n",
      "\tspeed: 0.0707s/iter; left time: 4591.4276s\n",
      "1999it [02:23, 12.62it/s]\titers: 2000, epoch: 3 | loss: 0.2014492\n",
      "\tspeed: 0.0726s/iter; left time: 4708.0752s\n",
      "2099it [02:30, 14.09it/s]\titers: 2100, epoch: 3 | loss: 0.3860649\n",
      "\tspeed: 0.0707s/iter; left time: 4577.4445s\n",
      "2199it [02:37, 14.07it/s]\titers: 2200, epoch: 3 | loss: 0.4203002\n",
      "\tspeed: 0.0707s/iter; left time: 4572.6057s\n",
      "2299it [02:45, 14.18it/s]\titers: 2300, epoch: 3 | loss: 0.1914153\n",
      "\tspeed: 0.0717s/iter; left time: 4629.1336s\n",
      "2399it [02:52, 14.08it/s]\titers: 2400, epoch: 3 | loss: 0.3540859\n",
      "\tspeed: 0.0708s/iter; left time: 4560.8316s\n",
      "2499it [02:59, 12.62it/s]\titers: 2500, epoch: 3 | loss: 0.2334221\n",
      "\tspeed: 0.0721s/iter; left time: 4640.3506s\n",
      "2599it [03:06, 14.00it/s]\titers: 2600, epoch: 3 | loss: 0.1960667\n",
      "\tspeed: 0.0704s/iter; left time: 4519.6869s\n",
      "2699it [03:13, 14.11it/s]\titers: 2700, epoch: 3 | loss: 0.3883330\n",
      "\tspeed: 0.0707s/iter; left time: 4535.2234s\n",
      "2799it [03:20, 16.24it/s]\titers: 2800, epoch: 3 | loss: 0.2692099\n",
      "\tspeed: 0.0675s/iter; left time: 4321.9233s\n",
      "2899it [03:27, 14.05it/s]\titers: 2900, epoch: 3 | loss: 0.2833339\n",
      "\tspeed: 0.0693s/iter; left time: 4430.4352s\n",
      "2999it [03:34, 14.33it/s]\titers: 3000, epoch: 3 | loss: 0.3195656\n",
      "\tspeed: 0.0709s/iter; left time: 4522.8935s\n",
      "3099it [03:41, 14.89it/s]\titers: 3100, epoch: 3 | loss: 0.3543431\n",
      "\tspeed: 0.0717s/iter; left time: 4566.9628s\n",
      "3199it [03:47, 15.92it/s]\titers: 3200, epoch: 3 | loss: 0.2888516\n",
      "\tspeed: 0.0636s/iter; left time: 4046.8500s\n",
      "3299it [03:54, 15.58it/s]\titers: 3300, epoch: 3 | loss: 0.4189922\n",
      "\tspeed: 0.0633s/iter; left time: 4018.6768s\n",
      "3399it [04:01, 14.54it/s]\titers: 3400, epoch: 3 | loss: 0.5077572\n",
      "\tspeed: 0.0711s/iter; left time: 4510.0371s\n",
      "3499it [04:08, 14.07it/s]\titers: 3500, epoch: 3 | loss: 0.2929228\n",
      "\tspeed: 0.0713s/iter; left time: 4518.5184s\n",
      "3599it [04:15, 13.71it/s]\titers: 3600, epoch: 3 | loss: 0.2886040\n",
      "\tspeed: 0.0693s/iter; left time: 4383.0621s\n",
      "3699it [04:22, 15.05it/s]\titers: 3700, epoch: 3 | loss: 0.3936318\n",
      "\tspeed: 0.0726s/iter; left time: 4582.3792s\n",
      "3713it [04:23, 14.08it/s]\n",
      "Epoch: 3 cost time: 263.6675479412079\n",
      "810it [00:26, 30.13it/s]\n",
      "807it [00:26, 30.65it/s]\n",
      "Epoch: 3 | Train Loss: 0.2823230 Vali Loss: 0.3410125 Test Loss: 0.4278955 MAE Loss: 0.4287347\n",
      "Updating learning rate to 9.999999999999983e-05\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 9.999999999999983e-05\n",
      "99it [00:07, 14.18it/s]\titers: 100, epoch: 4 | loss: 0.2850732\n",
      "\tspeed: 0.6341s/iter; left time: 39960.1552s\n",
      "199it [00:14, 14.12it/s]\titers: 200, epoch: 4 | loss: 0.3363286\n",
      "\tspeed: 0.0709s/iter; left time: 4460.4953s\n",
      "299it [00:21, 14.17it/s]\titers: 300, epoch: 4 | loss: 0.3450076\n",
      "\tspeed: 0.0707s/iter; left time: 4442.4987s\n",
      "399it [00:28, 14.14it/s]\titers: 400, epoch: 4 | loss: 0.2469949\n",
      "\tspeed: 0.0706s/iter; left time: 4425.5780s\n",
      "499it [00:35, 14.08it/s]\titers: 500, epoch: 4 | loss: 0.2506803\n",
      "\tspeed: 0.0706s/iter; left time: 4418.2316s\n",
      "599it [00:42, 14.13it/s]\titers: 600, epoch: 4 | loss: 0.2981749\n",
      "\tspeed: 0.0710s/iter; left time: 4436.2677s\n",
      "699it [00:49, 14.23it/s]\titers: 700, epoch: 4 | loss: 0.1728855\n",
      "\tspeed: 0.0705s/iter; left time: 4401.4961s\n",
      "799it [00:56, 14.16it/s]\titers: 800, epoch: 4 | loss: 0.4024906\n",
      "\tspeed: 0.0706s/iter; left time: 4401.6006s\n",
      "899it [01:03, 14.13it/s]\titers: 900, epoch: 4 | loss: 0.1857461\n",
      "\tspeed: 0.0707s/iter; left time: 4400.5050s\n",
      "999it [01:10, 14.17it/s]\titers: 1000, epoch: 4 | loss: 0.2279058\n",
      "\tspeed: 0.0707s/iter; left time: 4394.6354s\n",
      "1099it [01:18, 14.25it/s]\titers: 1100, epoch: 4 | loss: 0.2613455\n",
      "\tspeed: 0.0702s/iter; left time: 4356.3843s\n",
      "1199it [01:25, 14.11it/s]\titers: 1200, epoch: 4 | loss: 0.3150434\n",
      "\tspeed: 0.0706s/iter; left time: 4373.1434s\n",
      "1299it [01:32, 14.13it/s]\titers: 1300, epoch: 4 | loss: 0.3235995\n",
      "\tspeed: 0.0708s/iter; left time: 4379.6445s\n",
      "1399it [01:39, 14.12it/s]\titers: 1400, epoch: 4 | loss: 0.2922999\n",
      "\tspeed: 0.0708s/iter; left time: 4369.8087s\n",
      "1499it [01:46, 14.20it/s]\titers: 1500, epoch: 4 | loss: 0.2654918\n",
      "\tspeed: 0.0706s/iter; left time: 4348.9057s\n",
      "1599it [01:53, 14.12it/s]\titers: 1600, epoch: 4 | loss: 0.1525872\n",
      "\tspeed: 0.0704s/iter; left time: 4329.1836s\n",
      "1699it [02:00, 14.13it/s]\titers: 1700, epoch: 4 | loss: 0.3410408\n",
      "\tspeed: 0.0707s/iter; left time: 4340.8880s\n",
      "1799it [02:07, 14.24it/s]\titers: 1800, epoch: 4 | loss: 0.3263940\n",
      "\tspeed: 0.0706s/iter; left time: 4326.3201s\n",
      "1899it [02:14, 14.66it/s]\titers: 1900, epoch: 4 | loss: 0.2103821\n",
      "\tspeed: 0.0702s/iter; left time: 4300.7869s\n",
      "1999it [02:21, 14.22it/s]\titers: 2000, epoch: 4 | loss: 0.1575353\n",
      "\tspeed: 0.0707s/iter; left time: 4323.4056s\n",
      "2099it [02:28, 14.31it/s]\titers: 2100, epoch: 4 | loss: 0.2228255\n",
      "\tspeed: 0.0706s/iter; left time: 4308.2342s\n",
      "2199it [02:35, 14.13it/s]\titers: 2200, epoch: 4 | loss: 0.7159751\n",
      "\tspeed: 0.0706s/iter; left time: 4303.5052s\n",
      "2299it [02:42, 14.13it/s]\titers: 2300, epoch: 4 | loss: 0.3386425\n",
      "\tspeed: 0.0707s/iter; left time: 4297.1779s\n",
      "2399it [02:49, 14.35it/s]\titers: 2400, epoch: 4 | loss: 0.2929739\n",
      "\tspeed: 0.0706s/iter; left time: 4285.0040s\n",
      "2499it [02:56, 14.14it/s]\titers: 2500, epoch: 4 | loss: 0.1755292\n",
      "\tspeed: 0.0706s/iter; left time: 4279.3313s\n",
      "2599it [03:03, 14.34it/s]\titers: 2600, epoch: 4 | loss: 0.3945553\n",
      "\tspeed: 0.0706s/iter; left time: 4270.1338s\n",
      "2699it [03:10, 14.21it/s]\titers: 2700, epoch: 4 | loss: 0.4380026\n",
      "\tspeed: 0.0702s/iter; left time: 4244.1284s\n",
      "2799it [03:17, 15.36it/s]\titers: 2800, epoch: 4 | loss: 0.2202066\n",
      "\tspeed: 0.0699s/iter; left time: 4214.6167s\n",
      "2899it [03:24, 14.14it/s]\titers: 2900, epoch: 4 | loss: 0.2243514\n",
      "\tspeed: 0.0705s/iter; left time: 4244.8505s\n",
      "2999it [03:31, 14.17it/s]\titers: 3000, epoch: 4 | loss: 0.3540102\n",
      "\tspeed: 0.0703s/iter; left time: 4226.8802s\n",
      "3099it [03:39, 14.47it/s]\titers: 3100, epoch: 4 | loss: 0.2107886\n",
      "\tspeed: 0.0702s/iter; left time: 4211.7014s\n",
      "3199it [03:46, 14.10it/s]\titers: 3200, epoch: 4 | loss: 0.2969052\n",
      "\tspeed: 0.0707s/iter; left time: 4239.2911s\n",
      "3299it [03:53, 14.20it/s]\titers: 3300, epoch: 4 | loss: 0.1453811\n",
      "\tspeed: 0.0705s/iter; left time: 4220.0632s\n",
      "3399it [04:00, 14.11it/s]\titers: 3400, epoch: 4 | loss: 0.2620192\n",
      "\tspeed: 0.0707s/iter; left time: 4225.0247s\n",
      "3499it [04:07, 14.17it/s]\titers: 3500, epoch: 4 | loss: 0.2125727\n",
      "\tspeed: 0.0705s/iter; left time: 4204.6605s\n",
      "3599it [04:14, 14.18it/s]\titers: 3600, epoch: 4 | loss: 0.2650917\n",
      "\tspeed: 0.0706s/iter; left time: 4202.1459s\n",
      "3699it [04:21, 14.19it/s]\titers: 3700, epoch: 4 | loss: 0.2754830\n",
      "\tspeed: 0.0704s/iter; left time: 4182.1003s\n",
      "3713it [04:22, 14.15it/s]\n",
      "Epoch: 4 cost time: 262.4283559322357\n",
      "810it [00:26, 31.02it/s]\n",
      "807it [00:25, 31.16it/s]\n",
      "Epoch: 4 | Train Loss: 0.2737913 Vali Loss: 0.3290863 Test Loss: 0.4110485 MAE Loss: 0.4164289\n",
      "Updating learning rate to 4.9999999999999914e-05\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 4.9999999999999914e-05\n",
      "99it [00:07, 14.16it/s]\titers: 100, epoch: 5 | loss: 0.2547922\n",
      "\tspeed: 0.6195s/iter; left time: 36743.1560s\n",
      "199it [00:14, 14.11it/s]\titers: 200, epoch: 5 | loss: 0.2239320\n",
      "\tspeed: 0.0706s/iter; left time: 4177.3748s\n",
      "299it [00:21, 14.34it/s]\titers: 300, epoch: 5 | loss: 0.2795399\n",
      "\tspeed: 0.0706s/iter; left time: 4170.7957s\n",
      "399it [00:28, 14.12it/s]\titers: 400, epoch: 5 | loss: 0.2529288\n",
      "\tspeed: 0.0706s/iter; left time: 4168.6502s\n",
      "499it [00:35, 14.13it/s]\titers: 500, epoch: 5 | loss: 0.3104394\n",
      "\tspeed: 0.0707s/iter; left time: 4164.5299s\n",
      "599it [00:42, 14.17it/s]\titers: 600, epoch: 5 | loss: 0.2676745\n",
      "\tspeed: 0.0707s/iter; left time: 4159.3832s\n",
      "699it [00:49, 14.12it/s]\titers: 700, epoch: 5 | loss: 0.2176494\n",
      "\tspeed: 0.0705s/iter; left time: 4141.3804s\n",
      "799it [00:56, 14.15it/s]\titers: 800, epoch: 5 | loss: 0.3251584\n",
      "\tspeed: 0.0706s/iter; left time: 4136.9820s\n",
      "899it [01:03, 14.13it/s]\titers: 900, epoch: 5 | loss: 0.1725598\n",
      "\tspeed: 0.0706s/iter; left time: 4128.9180s\n",
      "999it [01:10, 14.16it/s]\titers: 1000, epoch: 5 | loss: 0.2251233\n",
      "\tspeed: 0.0706s/iter; left time: 4122.7082s\n",
      "1099it [01:18, 14.06it/s]\titers: 1100, epoch: 5 | loss: 0.3784579\n",
      "\tspeed: 0.0706s/iter; left time: 4117.0327s\n",
      "1199it [01:25, 14.20it/s]\titers: 1200, epoch: 5 | loss: 0.2353330\n",
      "\tspeed: 0.0705s/iter; left time: 4104.9143s\n",
      "1299it [01:32, 14.19it/s]\titers: 1300, epoch: 5 | loss: 0.2355106\n",
      "\tspeed: 0.0706s/iter; left time: 4103.3769s\n",
      "1399it [01:39, 14.12it/s]\titers: 1400, epoch: 5 | loss: 0.3234698\n",
      "\tspeed: 0.0707s/iter; left time: 4098.8093s\n",
      "1499it [01:46, 14.41it/s]\titers: 1500, epoch: 5 | loss: 0.5084689\n",
      "\tspeed: 0.0705s/iter; left time: 4083.9933s\n",
      "1599it [01:53, 14.19it/s]\titers: 1600, epoch: 5 | loss: 0.3202273\n",
      "\tspeed: 0.0704s/iter; left time: 4072.3297s\n",
      "1699it [02:00, 14.12it/s]\titers: 1700, epoch: 5 | loss: 0.2381863\n",
      "\tspeed: 0.0706s/iter; left time: 4074.5600s\n",
      "1799it [02:07, 14.13it/s]\titers: 1800, epoch: 5 | loss: 0.2227603\n",
      "\tspeed: 0.0704s/iter; left time: 4052.9849s\n",
      "1899it [02:14, 14.49it/s]\titers: 1900, epoch: 5 | loss: 0.2214449\n",
      "\tspeed: 0.0705s/iter; left time: 4054.8729s\n",
      "1999it [02:21, 14.11it/s]\titers: 2000, epoch: 5 | loss: 0.2486089\n",
      "\tspeed: 0.0706s/iter; left time: 4053.1434s\n",
      "2099it [02:28, 14.30it/s]\titers: 2100, epoch: 5 | loss: 0.2273594\n",
      "\tspeed: 0.0704s/iter; left time: 4034.0722s\n",
      "2199it [02:35, 14.07it/s]\titers: 2200, epoch: 5 | loss: 0.2207451\n",
      "\tspeed: 0.0707s/iter; left time: 4043.5526s\n",
      "2299it [02:42, 14.18it/s]\titers: 2300, epoch: 5 | loss: 0.2202586\n",
      "\tspeed: 0.0707s/iter; left time: 4037.4335s\n",
      "2399it [02:49, 14.12it/s]\titers: 2400, epoch: 5 | loss: 0.3636014\n",
      "\tspeed: 0.0707s/iter; left time: 4028.0423s\n",
      "2499it [02:56, 14.13it/s]\titers: 2500, epoch: 5 | loss: 0.5312688\n",
      "\tspeed: 0.0710s/iter; left time: 4038.5614s\n",
      "2599it [03:03, 14.18it/s]\titers: 2600, epoch: 5 | loss: 0.2011853\n",
      "\tspeed: 0.0706s/iter; left time: 4012.7775s\n",
      "2699it [03:10, 14.31it/s]\titers: 2700, epoch: 5 | loss: 0.3248979\n",
      "\tspeed: 0.0707s/iter; left time: 4007.1634s\n",
      "2799it [03:18, 14.13it/s]\titers: 2800, epoch: 5 | loss: 0.2308205\n",
      "\tspeed: 0.0706s/iter; left time: 3996.6715s\n",
      "2899it [03:25, 14.16it/s]\titers: 2900, epoch: 5 | loss: 0.1552545\n",
      "\tspeed: 0.0708s/iter; left time: 3998.1730s\n",
      "2999it [03:32, 14.15it/s]\titers: 3000, epoch: 5 | loss: 0.4603769\n",
      "\tspeed: 0.0708s/iter; left time: 3991.0888s\n",
      "3099it [03:39, 14.21it/s]\titers: 3100, epoch: 5 | loss: 0.1326291\n",
      "\tspeed: 0.0707s/iter; left time: 3981.9366s\n",
      "3199it [03:46, 14.12it/s]\titers: 3200, epoch: 5 | loss: 0.5425274\n",
      "\tspeed: 0.0706s/iter; left time: 3968.0501s\n",
      "3299it [03:53, 14.14it/s]\titers: 3300, epoch: 5 | loss: 0.1765730\n",
      "\tspeed: 0.0710s/iter; left time: 3986.2765s\n",
      "3399it [04:00, 14.21it/s]\titers: 3400, epoch: 5 | loss: 0.3265516\n",
      "\tspeed: 0.0704s/iter; left time: 3945.4030s\n",
      "3499it [04:07, 14.14it/s]\titers: 3500, epoch: 5 | loss: 0.4152337\n",
      "\tspeed: 0.0707s/iter; left time: 3952.3754s\n",
      "3599it [04:14, 14.39it/s]\titers: 3600, epoch: 5 | loss: 0.2647927\n",
      "\tspeed: 0.0706s/iter; left time: 3941.5641s\n",
      "3699it [04:21, 14.28it/s]\titers: 3700, epoch: 5 | loss: 0.3092241\n",
      "\tspeed: 0.0705s/iter; left time: 3926.0171s\n",
      "3713it [04:22, 14.14it/s]\n",
      "Epoch: 5 cost time: 262.67727756500244\n",
      "810it [00:26, 31.15it/s]\n",
      "807it [00:25, 31.12it/s]\n",
      "Epoch: 5 | Train Loss: 0.2653406 Vali Loss: 0.3274055 Test Loss: 0.4087338 MAE Loss: 0.4076380\n",
      "Updating learning rate to 2.4999999999999957e-05\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 2.4999999999999957e-05\n",
      "99it [00:07, 14.14it/s]\titers: 100, epoch: 6 | loss: 0.1900274\n",
      "\tspeed: 0.6223s/iter; left time: 34599.4166s\n",
      "199it [00:14, 14.12it/s]\titers: 200, epoch: 6 | loss: 0.2017278\n",
      "\tspeed: 0.0706s/iter; left time: 3920.7910s\n",
      "299it [00:21, 14.15it/s]\titers: 300, epoch: 6 | loss: 0.2855739\n",
      "\tspeed: 0.0703s/iter; left time: 3895.3909s\n",
      "399it [00:28, 14.10it/s]\titers: 400, epoch: 6 | loss: 0.2750932\n",
      "\tspeed: 0.0708s/iter; left time: 3914.9556s\n",
      "499it [00:35, 14.14it/s]\titers: 500, epoch: 6 | loss: 0.2057180\n",
      "\tspeed: 0.0705s/iter; left time: 3889.2422s\n",
      "599it [00:42, 14.09it/s]\titers: 600, epoch: 6 | loss: 0.3565043\n",
      "\tspeed: 0.0705s/iter; left time: 3881.5268s\n",
      "699it [00:49, 14.14it/s]\titers: 700, epoch: 6 | loss: 0.2315780\n",
      "\tspeed: 0.0704s/iter; left time: 3869.2171s\n",
      "799it [00:56, 14.41it/s]\titers: 800, epoch: 6 | loss: 0.3441859\n",
      "\tspeed: 0.0705s/iter; left time: 3872.8814s\n",
      "899it [01:03, 14.12it/s]\titers: 900, epoch: 6 | loss: 0.2225824\n",
      "\tspeed: 0.0706s/iter; left time: 3871.2106s\n",
      "999it [01:10, 14.09it/s]\titers: 1000, epoch: 6 | loss: 0.4156579\n",
      "\tspeed: 0.0705s/iter; left time: 3856.8735s\n",
      "1099it [01:17, 14.29it/s]\titers: 1100, epoch: 6 | loss: 0.2040297\n",
      "\tspeed: 0.0704s/iter; left time: 3841.0851s\n",
      "1199it [01:24, 14.14it/s]\titers: 1200, epoch: 6 | loss: 0.2548464\n",
      "\tspeed: 0.0707s/iter; left time: 3853.7394s\n",
      "1299it [01:32, 14.09it/s]\titers: 1300, epoch: 6 | loss: 0.4313008\n",
      "\tspeed: 0.0706s/iter; left time: 3841.6875s\n",
      "1399it [01:39, 14.15it/s]\titers: 1400, epoch: 6 | loss: 0.1959398\n",
      "\tspeed: 0.0707s/iter; left time: 3836.3042s\n",
      "1499it [01:46, 14.23it/s]\titers: 1500, epoch: 6 | loss: 0.2298430\n",
      "\tspeed: 0.0707s/iter; left time: 3833.8485s\n",
      "1599it [01:53, 14.28it/s]\titers: 1600, epoch: 6 | loss: 0.1216452\n",
      "\tspeed: 0.0704s/iter; left time: 3808.9849s\n",
      "1699it [02:00, 14.10it/s]\titers: 1700, epoch: 6 | loss: 0.2642347\n",
      "\tspeed: 0.0706s/iter; left time: 3810.4202s\n",
      "1799it [02:07, 14.13it/s]\titers: 1800, epoch: 6 | loss: 0.2215318\n",
      "\tspeed: 0.0706s/iter; left time: 3806.5421s\n",
      "1899it [02:14, 14.20it/s]\titers: 1900, epoch: 6 | loss: 0.1594957\n",
      "\tspeed: 0.0704s/iter; left time: 3788.4857s\n",
      "1999it [02:21, 14.15it/s]\titers: 2000, epoch: 6 | loss: 0.2110322\n",
      "\tspeed: 0.0705s/iter; left time: 3786.9993s\n",
      "2099it [02:28, 14.10it/s]\titers: 2100, epoch: 6 | loss: 0.1495766\n",
      "\tspeed: 0.0707s/iter; left time: 3786.8278s\n",
      "2199it [02:35, 14.16it/s]\titers: 2200, epoch: 6 | loss: 0.3010820\n",
      "\tspeed: 0.0706s/iter; left time: 3776.0630s\n",
      "2299it [02:42, 14.16it/s]\titers: 2300, epoch: 6 | loss: 0.2182588\n",
      "\tspeed: 0.0706s/iter; left time: 3771.5852s\n",
      "2399it [02:49, 14.39it/s]\titers: 2400, epoch: 6 | loss: 0.1980515\n",
      "\tspeed: 0.0706s/iter; left time: 3762.7481s\n",
      "2499it [02:56, 14.14it/s]\titers: 2500, epoch: 6 | loss: 0.4472761\n",
      "\tspeed: 0.0705s/iter; left time: 3751.7656s\n",
      "2599it [03:03, 14.40it/s]\titers: 2600, epoch: 6 | loss: 0.3845581\n",
      "\tspeed: 0.0702s/iter; left time: 3726.7665s\n",
      "2699it [03:10, 14.14it/s]\titers: 2700, epoch: 6 | loss: 0.2889526\n",
      "\tspeed: 0.0706s/iter; left time: 3743.8201s\n",
      "2799it [03:17, 14.14it/s]\titers: 2800, epoch: 6 | loss: 0.1386573\n",
      "\tspeed: 0.0705s/iter; left time: 3728.6451s\n",
      "2899it [03:24, 14.25it/s]\titers: 2900, epoch: 6 | loss: 0.2944917\n",
      "\tspeed: 0.0706s/iter; left time: 3728.2442s\n",
      "2999it [03:31, 14.61it/s]\titers: 3000, epoch: 6 | loss: 0.2648446\n",
      "\tspeed: 0.0701s/iter; left time: 3694.9031s\n",
      "3099it [03:38, 14.15it/s]\titers: 3100, epoch: 6 | loss: 0.1956895\n",
      "\tspeed: 0.0705s/iter; left time: 3708.2422s\n",
      "3199it [03:46, 14.51it/s]\titers: 3200, epoch: 6 | loss: 0.1697849\n",
      "\tspeed: 0.0704s/iter; left time: 3698.2052s\n",
      "3299it [03:53, 14.14it/s]\titers: 3300, epoch: 6 | loss: 0.3220503\n",
      "\tspeed: 0.0706s/iter; left time: 3699.3030s\n",
      "3399it [04:00, 14.43it/s]\titers: 3400, epoch: 6 | loss: 0.3041096\n",
      "\tspeed: 0.0705s/iter; left time: 3688.8108s\n",
      "3499it [04:07, 14.17it/s]\titers: 3500, epoch: 6 | loss: 0.1947867\n",
      "\tspeed: 0.0708s/iter; left time: 3694.3146s\n",
      "3599it [04:14, 14.16it/s]\titers: 3600, epoch: 6 | loss: 0.2075166\n",
      "\tspeed: 0.0706s/iter; left time: 3679.2195s\n",
      "3699it [04:21, 14.17it/s]\titers: 3700, epoch: 6 | loss: 0.2104171\n",
      "\tspeed: 0.0706s/iter; left time: 3672.8201s\n",
      "3713it [04:22, 14.15it/s]\n",
      "Epoch: 6 cost time: 262.3809130191803\n",
      "810it [00:25, 31.41it/s]\n",
      "807it [00:25, 31.25it/s]\n",
      "Epoch: 6 | Train Loss: 0.2631719 Vali Loss: 0.3245579 Test Loss: 0.4043427 MAE Loss: 0.4074341\n",
      "Updating learning rate to 1.2499999999999979e-05\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 1.2499999999999979e-05\n",
      "99it [00:07, 14.11it/s]\titers: 100, epoch: 7 | loss: 0.2067951\n",
      "\tspeed: 0.6188s/iter; left time: 32107.0966s\n",
      "199it [00:14, 14.16it/s]\titers: 200, epoch: 7 | loss: 0.3243938\n",
      "\tspeed: 0.0705s/iter; left time: 3648.4192s\n",
      "299it [00:21, 14.12it/s]\titers: 300, epoch: 7 | loss: 0.2243662\n",
      "\tspeed: 0.0707s/iter; left time: 3652.0313s\n",
      "399it [00:28, 14.08it/s]\titers: 400, epoch: 7 | loss: 0.2895494\n",
      "\tspeed: 0.0706s/iter; left time: 3644.0399s\n",
      "499it [00:35, 14.18it/s]\titers: 500, epoch: 7 | loss: 0.3088275\n",
      "\tspeed: 0.0707s/iter; left time: 3641.8365s\n",
      "599it [00:42, 14.26it/s]\titers: 600, epoch: 7 | loss: 0.1571313\n",
      "\tspeed: 0.0705s/iter; left time: 3623.5680s\n",
      "699it [00:49, 14.17it/s]\titers: 700, epoch: 7 | loss: 0.1987019\n",
      "\tspeed: 0.0705s/iter; left time: 3617.9207s\n",
      "799it [00:56, 14.19it/s]\titers: 800, epoch: 7 | loss: 0.1343365\n",
      "\tspeed: 0.0706s/iter; left time: 3611.2331s\n",
      "899it [01:03, 14.77it/s]\titers: 900, epoch: 7 | loss: 0.3138053\n",
      "\tspeed: 0.0695s/iter; left time: 3552.1018s\n",
      "999it [01:10, 14.47it/s]\titers: 1000, epoch: 7 | loss: 0.2484949\n",
      "\tspeed: 0.0697s/iter; left time: 3551.3093s\n",
      "1099it [01:17, 14.14it/s]\titers: 1100, epoch: 7 | loss: 0.2292576\n",
      "\tspeed: 0.0704s/iter; left time: 3580.4901s\n",
      "1199it [01:24, 14.15it/s]\titers: 1200, epoch: 7 | loss: 0.2077962\n",
      "\tspeed: 0.0704s/iter; left time: 3574.0823s\n",
      "1299it [01:31, 14.23it/s]\titers: 1300, epoch: 7 | loss: 0.4331632\n",
      "\tspeed: 0.0705s/iter; left time: 3573.4694s\n",
      "1399it [01:38, 14.52it/s]\titers: 1400, epoch: 7 | loss: 0.4093733\n",
      "\tspeed: 0.0704s/iter; left time: 3560.3692s\n",
      "1499it [01:45, 14.72it/s]\titers: 1500, epoch: 7 | loss: 0.3107385\n",
      "\tspeed: 0.0703s/iter; left time: 3547.2855s\n",
      "1599it [01:52, 14.12it/s]\titers: 1600, epoch: 7 | loss: 0.3653145\n",
      "\tspeed: 0.0708s/iter; left time: 3566.4481s\n",
      "1699it [01:59, 14.18it/s]\titers: 1700, epoch: 7 | loss: 0.2331020\n",
      "\tspeed: 0.0701s/iter; left time: 3524.0387s\n",
      "1799it [02:07, 14.39it/s]\titers: 1800, epoch: 7 | loss: 0.1522053\n",
      "\tspeed: 0.0706s/iter; left time: 3541.1997s\n",
      "1899it [02:14, 14.14it/s]\titers: 1900, epoch: 7 | loss: 0.2380904\n",
      "\tspeed: 0.0702s/iter; left time: 3517.6545s\n",
      "1999it [02:21, 14.21it/s]\titers: 2000, epoch: 7 | loss: 0.2228810\n",
      "\tspeed: 0.0706s/iter; left time: 3529.9809s\n",
      "2099it [02:28, 14.17it/s]\titers: 2100, epoch: 7 | loss: 0.2023186\n",
      "\tspeed: 0.0703s/iter; left time: 3507.3054s\n",
      "2199it [02:35, 14.30it/s]\titers: 2200, epoch: 7 | loss: 0.2354292\n",
      "\tspeed: 0.0708s/iter; left time: 3526.6688s\n",
      "2299it [02:42, 14.13it/s]\titers: 2300, epoch: 7 | loss: 0.3015803\n",
      "\tspeed: 0.0706s/iter; left time: 3505.5421s\n",
      "2399it [02:49, 14.23it/s]\titers: 2400, epoch: 7 | loss: 0.2196183\n",
      "\tspeed: 0.0703s/iter; left time: 3484.5878s\n",
      "2499it [02:56, 14.12it/s]\titers: 2500, epoch: 7 | loss: 0.2242392\n",
      "\tspeed: 0.0705s/iter; left time: 3489.1811s\n",
      "2599it [03:03, 14.14it/s]\titers: 2600, epoch: 7 | loss: 0.2573054\n",
      "\tspeed: 0.0706s/iter; left time: 3484.0431s\n",
      "2699it [03:10, 14.16it/s]\titers: 2700, epoch: 7 | loss: 0.1387736\n",
      "\tspeed: 0.0707s/iter; left time: 3484.7591s\n",
      "2799it [03:17, 14.11it/s]\titers: 2800, epoch: 7 | loss: 0.2754147\n",
      "\tspeed: 0.0705s/iter; left time: 3467.7217s\n",
      "2899it [03:24, 14.17it/s]\titers: 2900, epoch: 7 | loss: 0.2166269\n",
      "\tspeed: 0.0703s/iter; left time: 3450.6443s\n",
      "2999it [03:31, 14.13it/s]\titers: 3000, epoch: 7 | loss: 0.4716643\n",
      "\tspeed: 0.0707s/iter; left time: 3462.3157s\n",
      "3099it [03:38, 14.13it/s]\titers: 3100, epoch: 7 | loss: 0.1667530\n",
      "\tspeed: 0.0706s/iter; left time: 3450.8267s\n",
      "3199it [03:45, 14.32it/s]\titers: 3200, epoch: 7 | loss: 0.3068798\n",
      "\tspeed: 0.0704s/iter; left time: 3435.8862s\n",
      "3299it [03:52, 14.15it/s]\titers: 3300, epoch: 7 | loss: 0.3381716\n",
      "\tspeed: 0.0704s/iter; left time: 3426.4011s\n",
      "3399it [03:59, 14.26it/s]\titers: 3400, epoch: 7 | loss: 0.2492865\n",
      "\tspeed: 0.0704s/iter; left time: 3417.9030s\n",
      "3499it [04:06, 14.12it/s]\titers: 3500, epoch: 7 | loss: 0.3858875\n",
      "\tspeed: 0.0708s/iter; left time: 3430.1807s\n",
      "3599it [04:13, 14.18it/s]\titers: 3600, epoch: 7 | loss: 0.2329971\n",
      "\tspeed: 0.0705s/iter; left time: 3413.2147s\n",
      "3699it [04:21, 14.03it/s]\titers: 3700, epoch: 7 | loss: 0.2574738\n",
      "\tspeed: 0.0708s/iter; left time: 3416.2469s\n",
      "3713it [04:22, 14.17it/s]\n",
      "Epoch: 7 cost time: 262.08859753608704\n",
      "810it [00:26, 31.08it/s]\n",
      "807it [00:25, 31.30it/s]\n",
      "Epoch: 7 | Train Loss: 0.2605017 Vali Loss: 0.3240366 Test Loss: 0.4041178 MAE Loss: 0.4094134\n",
      "Updating learning rate to 6.249999999999989e-06\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 6.249999999999989e-06\n",
      "99it [00:07, 14.33it/s]\titers: 100, epoch: 8 | loss: 0.4766352\n",
      "\tspeed: 0.6180s/iter; left time: 29770.0682s\n",
      "199it [00:14, 14.10it/s]\titers: 200, epoch: 8 | loss: 0.2519725\n",
      "\tspeed: 0.0705s/iter; left time: 3390.1305s\n",
      "299it [00:21, 14.07it/s]\titers: 300, epoch: 8 | loss: 0.1626760\n",
      "\tspeed: 0.0706s/iter; left time: 3388.4444s\n",
      "399it [00:28, 14.09it/s]\titers: 400, epoch: 8 | loss: 0.3577460\n",
      "\tspeed: 0.0707s/iter; left time: 3386.4079s\n",
      "499it [00:35, 14.15it/s]\titers: 500, epoch: 8 | loss: 0.1934984\n",
      "\tspeed: 0.0708s/iter; left time: 3380.6945s\n",
      "599it [00:42, 14.13it/s]\titers: 600, epoch: 8 | loss: 0.2415648\n",
      "\tspeed: 0.0706s/iter; left time: 3367.1553s\n",
      "699it [00:49, 14.34it/s]\titers: 700, epoch: 8 | loss: 0.1300421\n",
      "\tspeed: 0.0704s/iter; left time: 3349.6100s\n",
      "799it [00:56, 14.17it/s]\titers: 800, epoch: 8 | loss: 0.2470798\n",
      "\tspeed: 0.0709s/iter; left time: 3364.8801s\n",
      "899it [01:03, 14.13it/s]\titers: 900, epoch: 8 | loss: 0.3576845\n",
      "\tspeed: 0.0706s/iter; left time: 3343.6613s\n",
      "999it [01:10, 14.21it/s]\titers: 1000, epoch: 8 | loss: 0.3293496\n",
      "\tspeed: 0.0706s/iter; left time: 3339.1832s\n",
      "1099it [01:17, 14.23it/s]\titers: 1100, epoch: 8 | loss: 0.2772523\n",
      "\tspeed: 0.0705s/iter; left time: 3323.6253s\n",
      "1199it [01:25, 14.07it/s]\titers: 1200, epoch: 8 | loss: 0.4905272\n",
      "\tspeed: 0.0708s/iter; left time: 3332.4984s\n",
      "1299it [01:32, 14.19it/s]\titers: 1300, epoch: 8 | loss: 0.7016559\n",
      "\tspeed: 0.0706s/iter; left time: 3317.6551s\n",
      "1399it [01:39, 14.49it/s]\titers: 1400, epoch: 8 | loss: 0.1862490\n",
      "\tspeed: 0.0704s/iter; left time: 3298.2829s\n",
      "1499it [01:46, 14.27it/s]\titers: 1500, epoch: 8 | loss: 0.3012656\n",
      "\tspeed: 0.0705s/iter; left time: 3296.7304s\n",
      "1599it [01:53, 14.22it/s]\titers: 1600, epoch: 8 | loss: 0.2349371\n",
      "\tspeed: 0.0706s/iter; left time: 3295.3110s\n",
      "1699it [02:00, 14.24it/s]\titers: 1700, epoch: 8 | loss: 0.1799236\n",
      "\tspeed: 0.0703s/iter; left time: 3275.9675s\n",
      "1799it [02:07, 14.17it/s]\titers: 1800, epoch: 8 | loss: 0.2045377\n",
      "\tspeed: 0.0707s/iter; left time: 3285.7361s\n",
      "1899it [02:14, 14.13it/s]\titers: 1900, epoch: 8 | loss: 0.2540616\n",
      "\tspeed: 0.0704s/iter; left time: 3265.9059s\n",
      "1999it [02:21, 14.16it/s]\titers: 2000, epoch: 8 | loss: 0.1738922\n",
      "\tspeed: 0.0705s/iter; left time: 3261.7031s\n",
      "2099it [02:28, 14.09it/s]\titers: 2100, epoch: 8 | loss: 0.5857936\n",
      "\tspeed: 0.0704s/iter; left time: 3249.7373s\n",
      "2199it [02:35, 14.36it/s]\titers: 2200, epoch: 8 | loss: 0.1736989\n",
      "\tspeed: 0.0702s/iter; left time: 3232.0828s\n",
      "2299it [02:42, 14.15it/s]\titers: 2300, epoch: 8 | loss: 0.1892766\n",
      "\tspeed: 0.0705s/iter; left time: 3242.1667s\n",
      "2399it [02:49, 14.14it/s]\titers: 2400, epoch: 8 | loss: 0.3536912\n",
      "\tspeed: 0.0704s/iter; left time: 3228.3531s\n",
      "2499it [02:56, 13.91it/s]\titers: 2500, epoch: 8 | loss: 0.1776892\n",
      "\tspeed: 0.0704s/iter; left time: 3223.7659s\n",
      "2599it [03:03, 14.25it/s]\titers: 2600, epoch: 8 | loss: 0.2241938\n",
      "\tspeed: 0.0706s/iter; left time: 3223.5179s\n",
      "2699it [03:10, 14.17it/s]\titers: 2700, epoch: 8 | loss: 0.2439608\n",
      "\tspeed: 0.0705s/iter; left time: 3211.1319s\n",
      "2799it [03:17, 14.23it/s]\titers: 2800, epoch: 8 | loss: 0.2335986\n",
      "\tspeed: 0.0704s/iter; left time: 3198.8755s\n",
      "2899it [03:24, 14.19it/s]\titers: 2900, epoch: 8 | loss: 0.2457659\n",
      "\tspeed: 0.0701s/iter; left time: 3180.3854s\n",
      "2999it [03:31, 14.20it/s]\titers: 3000, epoch: 8 | loss: 0.5120807\n",
      "\tspeed: 0.0703s/iter; left time: 3181.2337s\n",
      "3099it [03:38, 14.24it/s]\titers: 3100, epoch: 8 | loss: 0.3607441\n",
      "\tspeed: 0.0707s/iter; left time: 3192.2817s\n",
      "3199it [03:45, 14.14it/s]\titers: 3200, epoch: 8 | loss: 0.2646918\n",
      "\tspeed: 0.0705s/iter; left time: 3175.6558s\n",
      "3299it [03:53, 14.11it/s]\titers: 3300, epoch: 8 | loss: 0.2872843\n",
      "\tspeed: 0.0705s/iter; left time: 3169.1467s\n",
      "3399it [04:00, 14.14it/s]\titers: 3400, epoch: 8 | loss: 0.1757559\n",
      "\tspeed: 0.0708s/iter; left time: 3174.6257s\n",
      "3499it [04:07, 14.07it/s]\titers: 3500, epoch: 8 | loss: 0.2626288\n",
      "\tspeed: 0.0706s/iter; left time: 3161.8332s\n",
      "3599it [04:14, 14.20it/s]\titers: 3600, epoch: 8 | loss: 0.1669066\n",
      "\tspeed: 0.0705s/iter; left time: 3151.3184s\n",
      "3699it [04:21, 14.18it/s]\titers: 3700, epoch: 8 | loss: 0.3808859\n",
      "\tspeed: 0.0704s/iter; left time: 3138.1220s\n",
      "3713it [04:22, 14.16it/s]\n",
      "Epoch: 8 cost time: 262.30409383773804\n",
      "810it [00:25, 31.46it/s]\n",
      "807it [00:26, 31.02it/s]\n",
      "Epoch: 8 | Train Loss: 0.2585965 Vali Loss: 0.3220685 Test Loss: 0.4018546 MAE Loss: 0.4056657\n",
      "Updating learning rate to 3.1249999999999946e-06\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 3.1249999999999946e-06\n",
      "99it [00:07, 14.18it/s]\titers: 100, epoch: 9 | loss: 0.1803083\n",
      "\tspeed: 0.6176s/iter; left time: 27458.7723s\n",
      "199it [00:14, 14.22it/s]\titers: 200, epoch: 9 | loss: 0.3970101\n",
      "\tspeed: 0.0705s/iter; left time: 3125.8316s\n",
      "299it [00:21, 14.14it/s]\titers: 300, epoch: 9 | loss: 0.2722712\n",
      "\tspeed: 0.0706s/iter; left time: 3126.3885s\n",
      "399it [00:28, 14.14it/s]\titers: 400, epoch: 9 | loss: 0.1972882\n",
      "\tspeed: 0.0708s/iter; left time: 3124.2745s\n",
      "499it [00:35, 14.15it/s]\titers: 500, epoch: 9 | loss: 0.2547354\n",
      "\tspeed: 0.0707s/iter; left time: 3112.9446s\n",
      "599it [00:42, 14.17it/s]\titers: 600, epoch: 9 | loss: 0.1562134\n",
      "\tspeed: 0.0707s/iter; left time: 3109.1469s\n",
      "699it [00:49, 14.14it/s]\titers: 700, epoch: 9 | loss: 0.1415634\n",
      "\tspeed: 0.0707s/iter; left time: 3100.8665s\n",
      "799it [00:56, 14.29it/s]\titers: 800, epoch: 9 | loss: 0.2279366\n",
      "\tspeed: 0.0704s/iter; left time: 3082.2445s\n",
      "899it [01:03, 14.30it/s]\titers: 900, epoch: 9 | loss: 0.1797852\n",
      "\tspeed: 0.0705s/iter; left time: 3078.3737s\n",
      "999it [01:10, 14.17it/s]\titers: 1000, epoch: 9 | loss: 0.3454222\n",
      "\tspeed: 0.0706s/iter; left time: 3076.0616s\n",
      "1099it [01:17, 14.18it/s]\titers: 1100, epoch: 9 | loss: 0.2683747\n",
      "\tspeed: 0.0707s/iter; left time: 3072.6931s\n",
      "1199it [01:25, 14.14it/s]\titers: 1200, epoch: 9 | loss: 0.1765474\n",
      "\tspeed: 0.0704s/iter; left time: 3054.0254s\n",
      "1299it [01:32, 14.19it/s]\titers: 1300, epoch: 9 | loss: 0.2695628\n",
      "\tspeed: 0.0703s/iter; left time: 3042.9783s\n",
      "1399it [01:39, 14.39it/s]\titers: 1400, epoch: 9 | loss: 0.4457194\n",
      "\tspeed: 0.0705s/iter; left time: 3040.8061s\n",
      "1499it [01:46, 14.14it/s]\titers: 1500, epoch: 9 | loss: 0.2478726\n",
      "\tspeed: 0.0705s/iter; left time: 3035.1104s\n",
      "1599it [01:53, 14.15it/s]\titers: 1600, epoch: 9 | loss: 0.2403383\n",
      "\tspeed: 0.0706s/iter; left time: 3031.1331s\n",
      "1699it [02:00, 14.20it/s]\titers: 1700, epoch: 9 | loss: 0.2338661\n",
      "\tspeed: 0.0707s/iter; left time: 3029.6348s\n",
      "1799it [02:07, 14.16it/s]\titers: 1800, epoch: 9 | loss: 0.2622049\n",
      "\tspeed: 0.0706s/iter; left time: 3016.8859s\n",
      "1899it [02:14, 14.03it/s]\titers: 1900, epoch: 9 | loss: 0.5011097\n",
      "\tspeed: 0.0709s/iter; left time: 3024.9455s\n",
      "1999it [02:21, 13.86it/s]\titers: 2000, epoch: 9 | loss: 0.3101994\n",
      "\tspeed: 0.0712s/iter; left time: 3029.9984s\n",
      "2099it [02:28, 14.12it/s]\titers: 2100, epoch: 9 | loss: 0.1940371\n",
      "\tspeed: 0.0713s/iter; left time: 3026.1889s\n",
      "2199it [02:35, 14.13it/s]\titers: 2200, epoch: 9 | loss: 0.3532252\n",
      "\tspeed: 0.0708s/iter; left time: 2998.5875s\n",
      "2299it [02:42, 14.07it/s]\titers: 2300, epoch: 9 | loss: 0.3145600\n",
      "\tspeed: 0.0706s/iter; left time: 2984.4349s\n",
      "2399it [02:49, 14.25it/s]\titers: 2400, epoch: 9 | loss: 0.2950912\n",
      "\tspeed: 0.0703s/iter; left time: 2965.2643s\n",
      "2499it [02:56, 14.13it/s]\titers: 2500, epoch: 9 | loss: 0.2543536\n",
      "\tspeed: 0.0707s/iter; left time: 2973.0150s\n",
      "2599it [03:03, 15.26it/s]\titers: 2600, epoch: 9 | loss: 0.2649936\n",
      "\tspeed: 0.0702s/iter; left time: 2945.3028s\n",
      "2699it [03:10, 14.13it/s]\titers: 2700, epoch: 9 | loss: 0.2999886\n",
      "\tspeed: 0.0677s/iter; left time: 2834.8209s\n",
      "2799it [03:17, 14.14it/s]\titers: 2800, epoch: 9 | loss: 0.1292567\n",
      "\tspeed: 0.0708s/iter; left time: 2955.0050s\n",
      "2899it [03:24, 14.12it/s]\titers: 2900, epoch: 9 | loss: 0.2695836\n",
      "\tspeed: 0.0711s/iter; left time: 2961.2468s\n",
      "2999it [03:31, 14.06it/s]\titers: 3000, epoch: 9 | loss: 0.3089233\n",
      "\tspeed: 0.0707s/iter; left time: 2937.7625s\n",
      "3099it [03:39, 14.15it/s]\titers: 3100, epoch: 9 | loss: 0.3686288\n",
      "\tspeed: 0.0707s/iter; left time: 2930.2030s\n",
      "3199it [03:46, 14.15it/s]\titers: 3200, epoch: 9 | loss: 0.2197729\n",
      "\tspeed: 0.0706s/iter; left time: 2917.9595s\n",
      "3299it [03:53, 14.16it/s]\titers: 3300, epoch: 9 | loss: 0.1898033\n",
      "\tspeed: 0.0707s/iter; left time: 2914.9735s\n",
      "3399it [04:00, 14.13it/s]\titers: 3400, epoch: 9 | loss: 0.1709957\n",
      "\tspeed: 0.0706s/iter; left time: 2906.6523s\n",
      "3499it [04:07, 14.15it/s]\titers: 3500, epoch: 9 | loss: 0.3548788\n",
      "\tspeed: 0.0706s/iter; left time: 2900.5104s\n",
      "3599it [04:14, 14.12it/s]\titers: 3600, epoch: 9 | loss: 0.1643440\n",
      "\tspeed: 0.0708s/iter; left time: 2899.4165s\n",
      "3699it [04:21, 14.15it/s]\titers: 3700, epoch: 9 | loss: 0.1351032\n",
      "\tspeed: 0.0709s/iter; left time: 2895.7493s\n",
      "3713it [04:22, 14.15it/s]\n",
      "Epoch: 9 cost time: 262.45336270332336\n",
      "810it [00:25, 31.18it/s]\n",
      "807it [00:26, 30.96it/s]\n",
      "Epoch: 9 | Train Loss: 0.2581895 Vali Loss: 0.3218702 Test Loss: 0.4001854 MAE Loss: 0.4064985\n",
      "Updating learning rate to 1.5624999999999973e-06\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 1.5624999999999973e-06\n",
      "98it [00:09,  9.77it/s]\titers: 100, epoch: 10 | loss: 0.5749952\n",
      "\tspeed: 0.6419s/iter; left time: 26152.3229s\n",
      "199it [00:17, 14.37it/s]\titers: 200, epoch: 10 | loss: 0.2301414\n",
      "\tspeed: 0.0801s/iter; left time: 3254.5452s\n",
      "299it [00:24, 14.13it/s]\titers: 300, epoch: 10 | loss: 0.3535250\n",
      "\tspeed: 0.0708s/iter; left time: 2870.3968s\n",
      "399it [00:31, 14.05it/s]\titers: 400, epoch: 10 | loss: 0.1994564\n",
      "\tspeed: 0.0713s/iter; left time: 2885.3983s\n",
      "499it [00:38, 14.21it/s]\titers: 500, epoch: 10 | loss: 0.2324077\n",
      "\tspeed: 0.0706s/iter; left time: 2846.5841s\n",
      "599it [00:45, 14.06it/s]\titers: 600, epoch: 10 | loss: 0.2245833\n",
      "\tspeed: 0.0720s/iter; left time: 2896.9835s\n",
      "699it [00:53, 13.95it/s]\titers: 700, epoch: 10 | loss: 0.4728862\n",
      "\tspeed: 0.0722s/iter; left time: 2897.6231s\n",
      "799it [01:00, 14.09it/s]\titers: 800, epoch: 10 | loss: 0.2237841\n",
      "\tspeed: 0.0709s/iter; left time: 2838.2463s\n",
      "899it [01:07, 14.29it/s]\titers: 900, epoch: 10 | loss: 0.2545428\n",
      "\tspeed: 0.0701s/iter; left time: 2799.1092s\n",
      "999it [01:14, 14.13it/s]\titers: 1000, epoch: 10 | loss: 0.3706342\n",
      "\tspeed: 0.0716s/iter; left time: 2853.9401s\n",
      "1099it [01:21, 13.88it/s]\titers: 1100, epoch: 10 | loss: 0.2483986\n",
      "\tspeed: 0.0711s/iter; left time: 2825.5641s\n",
      "1199it [01:28, 13.40it/s]\titers: 1200, epoch: 10 | loss: 0.3615908\n",
      "\tspeed: 0.0702s/iter; left time: 2784.6716s\n",
      "1299it [01:35, 13.94it/s]\titers: 1300, epoch: 10 | loss: 0.3640245\n",
      "\tspeed: 0.0728s/iter; left time: 2877.3462s\n",
      "1399it [01:42, 15.51it/s]\titers: 1400, epoch: 10 | loss: 0.3386068\n",
      "\tspeed: 0.0671s/iter; left time: 2648.2643s\n",
      "1499it [01:49, 15.71it/s]\titers: 1500, epoch: 10 | loss: 0.3020665\n",
      "\tspeed: 0.0655s/iter; left time: 2578.0860s\n",
      "1599it [01:55, 15.30it/s]\titers: 1600, epoch: 10 | loss: 0.3830546\n",
      "\tspeed: 0.0644s/iter; left time: 2526.7194s\n",
      "1699it [02:02, 14.72it/s]\titers: 1700, epoch: 10 | loss: 0.2865904\n",
      "\tspeed: 0.0683s/iter; left time: 2674.5568s\n",
      "1799it [02:09, 15.50it/s]\titers: 1800, epoch: 10 | loss: 0.2419049\n",
      "\tspeed: 0.0676s/iter; left time: 2639.8019s\n",
      "1899it [02:16, 14.18it/s]\titers: 1900, epoch: 10 | loss: 0.1329444\n",
      "\tspeed: 0.0702s/iter; left time: 2733.0107s\n",
      "1999it [02:23, 14.11it/s]\titers: 2000, epoch: 10 | loss: 0.3626999\n",
      "\tspeed: 0.0712s/iter; left time: 2764.3772s\n",
      "2099it [02:30, 14.13it/s]\titers: 2100, epoch: 10 | loss: 0.3524399\n",
      "\tspeed: 0.0709s/iter; left time: 2748.1388s\n",
      "2199it [02:37, 14.11it/s]\titers: 2200, epoch: 10 | loss: 0.3363607\n",
      "\tspeed: 0.0708s/iter; left time: 2736.3671s\n",
      "2299it [02:44, 14.23it/s]\titers: 2300, epoch: 10 | loss: 0.1852504\n",
      "\tspeed: 0.0707s/iter; left time: 2724.4108s\n",
      "2399it [02:51, 14.11it/s]\titers: 2400, epoch: 10 | loss: 0.2169005\n",
      "\tspeed: 0.0708s/iter; left time: 2723.6109s\n",
      "2499it [02:58, 14.26it/s]\titers: 2500, epoch: 10 | loss: 0.3323396\n",
      "\tspeed: 0.0706s/iter; left time: 2706.1639s\n",
      "2599it [03:05, 14.15it/s]\titers: 2600, epoch: 10 | loss: 0.1931204\n",
      "\tspeed: 0.0708s/iter; left time: 2709.3054s\n",
      "2699it [03:12, 14.21it/s]\titers: 2700, epoch: 10 | loss: 0.1635457\n",
      "\tspeed: 0.0707s/iter; left time: 2698.1559s\n",
      "2799it [03:19, 14.06it/s]\titers: 2800, epoch: 10 | loss: 0.1824584\n",
      "\tspeed: 0.0707s/iter; left time: 2688.7630s\n",
      "2899it [03:26, 14.16it/s]\titers: 2900, epoch: 10 | loss: 0.4017439\n",
      "\tspeed: 0.0708s/iter; left time: 2686.2053s\n",
      "2999it [03:34, 14.22it/s]\titers: 3000, epoch: 10 | loss: 0.2886693\n",
      "\tspeed: 0.0708s/iter; left time: 2678.1240s\n",
      "3099it [03:41, 14.18it/s]\titers: 3100, epoch: 10 | loss: 0.1636171\n",
      "\tspeed: 0.0709s/iter; left time: 2677.0301s\n",
      "3199it [03:48, 14.15it/s]\titers: 3200, epoch: 10 | loss: 0.1358148\n",
      "\tspeed: 0.0708s/iter; left time: 2664.5920s\n",
      "3299it [03:55, 14.20it/s]\titers: 3300, epoch: 10 | loss: 0.2598672\n",
      "\tspeed: 0.0707s/iter; left time: 2653.2484s\n",
      "3399it [04:02, 14.15it/s]\titers: 3400, epoch: 10 | loss: 0.3989696\n",
      "\tspeed: 0.0709s/iter; left time: 2654.0224s\n",
      "3499it [04:09, 14.12it/s]\titers: 3500, epoch: 10 | loss: 0.1806194\n",
      "\tspeed: 0.0708s/iter; left time: 2642.1619s\n",
      "3599it [04:16, 14.16it/s]\titers: 3600, epoch: 10 | loss: 0.3184419\n",
      "\tspeed: 0.0708s/iter; left time: 2636.8313s\n",
      "3699it [04:23, 14.17it/s]\titers: 3700, epoch: 10 | loss: 0.2915985\n",
      "\tspeed: 0.0706s/iter; left time: 2623.2736s\n",
      "3713it [04:24, 14.03it/s]\n",
      "Epoch: 10 cost time: 264.60488629341125\n",
      "810it [00:26, 30.64it/s]\n",
      "807it [00:26, 30.58it/s]\n",
      "Epoch: 10 | Train Loss: 0.2578906 Vali Loss: 0.3208272 Test Loss: 0.3996573 MAE Loss: 0.4046818\n",
      "Updating learning rate to 7.812499999999987e-07\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 7.812499999999987e-07\n",
      "99it [00:07, 14.12it/s]\titers: 100, epoch: 11 | loss: 0.1904727\n",
      "\tspeed: 0.6285s/iter; left time: 23274.7984s\n",
      "199it [00:14, 14.10it/s]\titers: 200, epoch: 11 | loss: 0.3127575\n",
      "\tspeed: 0.0707s/iter; left time: 2611.2120s\n",
      "299it [00:21, 14.23it/s]\titers: 300, epoch: 11 | loss: 0.2059831\n",
      "\tspeed: 0.0707s/iter; left time: 2603.8548s\n",
      "399it [00:28, 14.12it/s]\titers: 400, epoch: 11 | loss: 0.4278945\n",
      "\tspeed: 0.0707s/iter; left time: 2595.2020s\n",
      "499it [00:35, 14.12it/s]\titers: 500, epoch: 11 | loss: 0.2363466\n",
      "\tspeed: 0.0708s/iter; left time: 2592.6764s\n",
      "599it [00:42, 14.18it/s]\titers: 600, epoch: 11 | loss: 0.1821239\n",
      "\tspeed: 0.0705s/iter; left time: 2577.0828s\n",
      "699it [00:49, 14.14it/s]\titers: 700, epoch: 11 | loss: 0.2443228\n",
      "\tspeed: 0.0710s/iter; left time: 2586.1800s\n",
      "799it [00:56, 14.18it/s]\titers: 800, epoch: 11 | loss: 0.4458205\n",
      "\tspeed: 0.0709s/iter; left time: 2574.6886s\n",
      "899it [01:03, 14.19it/s]\titers: 900, epoch: 11 | loss: 0.2050153\n",
      "\tspeed: 0.0706s/iter; left time: 2559.0134s\n",
      "999it [01:11, 14.16it/s]\titers: 1000, epoch: 11 | loss: 0.2166513\n",
      "\tspeed: 0.0707s/iter; left time: 2556.0480s\n",
      "1099it [01:18, 14.08it/s]\titers: 1100, epoch: 11 | loss: 0.2122803\n",
      "\tspeed: 0.0711s/iter; left time: 2560.6602s\n",
      "1199it [01:25, 14.27it/s]\titers: 1200, epoch: 11 | loss: 0.2711682\n",
      "\tspeed: 0.0707s/iter; left time: 2540.6352s\n",
      "1299it [01:32, 14.15it/s]\titers: 1300, epoch: 11 | loss: 0.1947108\n",
      "\tspeed: 0.0707s/iter; left time: 2533.1100s\n",
      "1399it [01:39, 14.11it/s]\titers: 1400, epoch: 11 | loss: 0.2547933\n",
      "\tspeed: 0.0709s/iter; left time: 2531.7744s\n",
      "1499it [01:46, 14.18it/s]\titers: 1500, epoch: 11 | loss: 0.2095743\n",
      "\tspeed: 0.0704s/iter; left time: 2509.7494s\n",
      "1599it [01:53, 14.16it/s]\titers: 1600, epoch: 11 | loss: 0.1963345\n",
      "\tspeed: 0.0707s/iter; left time: 2512.3203s\n",
      "1699it [02:00, 14.06it/s]\titers: 1700, epoch: 11 | loss: 0.3193652\n",
      "\tspeed: 0.0709s/iter; left time: 2510.9993s\n",
      "1799it [02:07, 14.16it/s]\titers: 1800, epoch: 11 | loss: 0.3180754\n",
      "\tspeed: 0.0707s/iter; left time: 2497.7132s\n",
      "1899it [02:14, 14.17it/s]\titers: 1900, epoch: 11 | loss: 0.3282925\n",
      "\tspeed: 0.0705s/iter; left time: 2485.2709s\n",
      "1999it [02:21, 14.14it/s]\titers: 2000, epoch: 11 | loss: 0.1596671\n",
      "\tspeed: 0.0706s/iter; left time: 2481.5313s\n",
      "2099it [02:28, 14.21it/s]\titers: 2100, epoch: 11 | loss: 0.1662285\n",
      "\tspeed: 0.0708s/iter; left time: 2481.9412s\n",
      "2199it [02:35, 14.15it/s]\titers: 2200, epoch: 11 | loss: 0.1135852\n",
      "\tspeed: 0.0691s/iter; left time: 2414.2409s\n",
      "2299it [02:42, 14.17it/s]\titers: 2300, epoch: 11 | loss: 0.3867224\n",
      "\tspeed: 0.0706s/iter; left time: 2460.3836s\n",
      "2399it [02:49, 15.69it/s]\titers: 2400, epoch: 11 | loss: 0.2725988\n",
      "\tspeed: 0.0697s/iter; left time: 2419.6408s\n",
      "2499it [02:56, 14.17it/s]\titers: 2500, epoch: 11 | loss: 0.1613893\n",
      "\tspeed: 0.0671s/iter; left time: 2323.3104s\n",
      "2599it [03:03, 14.09it/s]\titers: 2600, epoch: 11 | loss: 0.2581804\n",
      "\tspeed: 0.0707s/iter; left time: 2440.5619s\n",
      "2699it [03:10, 15.36it/s]\titers: 2700, epoch: 11 | loss: 0.2363049\n",
      "\tspeed: 0.0681s/iter; left time: 2343.7780s\n",
      "2799it [03:17, 14.14it/s]\titers: 2800, epoch: 11 | loss: 0.1910572\n",
      "\tspeed: 0.0680s/iter; left time: 2334.4257s\n",
      "2899it [03:24, 13.47it/s]\titers: 2900, epoch: 11 | loss: 0.3124407\n",
      "\tspeed: 0.0708s/iter; left time: 2424.0516s\n",
      "2999it [03:31, 14.01it/s]\titers: 3000, epoch: 11 | loss: 0.2445571\n",
      "\tspeed: 0.0710s/iter; left time: 2422.7247s\n",
      "3099it [03:38, 15.97it/s]\titers: 3100, epoch: 11 | loss: 0.2396148\n",
      "\tspeed: 0.0681s/iter; left time: 2315.8514s\n",
      "3199it [03:44, 14.14it/s]\titers: 3200, epoch: 11 | loss: 0.1956449\n",
      "\tspeed: 0.0674s/iter; left time: 2286.0875s\n",
      "3299it [03:51, 14.14it/s]\titers: 3300, epoch: 11 | loss: 0.2243443\n",
      "\tspeed: 0.0708s/iter; left time: 2393.7837s\n",
      "3399it [03:59, 14.10it/s]\titers: 3400, epoch: 11 | loss: 0.1368080\n",
      "\tspeed: 0.0709s/iter; left time: 2390.4223s\n",
      "3499it [04:06, 14.17it/s]\titers: 3500, epoch: 11 | loss: 0.2701402\n",
      "\tspeed: 0.0709s/iter; left time: 2383.9218s\n",
      "3599it [04:13, 13.97it/s]\titers: 3600, epoch: 11 | loss: 0.3101719\n",
      "\tspeed: 0.0712s/iter; left time: 2386.6117s\n",
      "3699it [04:20, 14.15it/s]\titers: 3700, epoch: 11 | loss: 0.2739262\n",
      "\tspeed: 0.0711s/iter; left time: 2377.4046s\n",
      "3713it [04:21, 14.20it/s]\n",
      "Epoch: 11 cost time: 261.4554991722107\n",
      "810it [00:27, 29.39it/s]\n",
      "807it [00:28, 28.68it/s]\n",
      "Epoch: 11 | Train Loss: 0.2577309 Vali Loss: 0.3210090 Test Loss: 0.3996594 MAE Loss: 0.4043331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.9062499999999933e-07\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 3.9062499999999933e-07\n",
      "99it [00:07, 13.28it/s]\titers: 100, epoch: 12 | loss: 0.1269330\n",
      "\tspeed: 0.6474s/iter; left time: 21569.2343s\n",
      "199it [00:14, 14.27it/s]\titers: 200, epoch: 12 | loss: 0.3069650\n",
      "\tspeed: 0.0712s/iter; left time: 2363.8304s\n",
      "299it [00:22, 10.61it/s]\titers: 300, epoch: 12 | loss: 0.3081747\n",
      "\tspeed: 0.0752s/iter; left time: 2491.3012s\n",
      "399it [00:29, 14.12it/s]\titers: 400, epoch: 12 | loss: 0.2172643\n",
      "\tspeed: 0.0713s/iter; left time: 2355.0799s\n",
      "499it [00:36, 14.71it/s]\titers: 500, epoch: 12 | loss: 0.2463418\n",
      "\tspeed: 0.0700s/iter; left time: 2303.9130s\n",
      "599it [00:43, 13.14it/s]\titers: 600, epoch: 12 | loss: 0.1834984\n",
      "\tspeed: 0.0732s/iter; left time: 2403.5796s\n",
      "699it [00:51, 14.17it/s]\titers: 700, epoch: 12 | loss: 0.2054815\n",
      "\tspeed: 0.0707s/iter; left time: 2311.9425s\n",
      "799it [00:57, 14.03it/s]\titers: 800, epoch: 12 | loss: 0.4045949\n",
      "\tspeed: 0.0693s/iter; left time: 2260.3357s\n",
      "899it [01:05, 13.96it/s]\titers: 900, epoch: 12 | loss: 0.2300192\n",
      "\tspeed: 0.0731s/iter; left time: 2377.3903s\n",
      "999it [01:12, 13.91it/s]\titers: 1000, epoch: 12 | loss: 0.1596646\n",
      "\tspeed: 0.0715s/iter; left time: 2316.7625s\n",
      "1099it [01:19, 14.08it/s]\titers: 1100, epoch: 12 | loss: 0.4802470\n",
      "\tspeed: 0.0721s/iter; left time: 2331.6010s\n",
      "1199it [01:27, 14.07it/s]\titers: 1200, epoch: 12 | loss: 0.1896719\n",
      "\tspeed: 0.0745s/iter; left time: 2399.3375s\n",
      "1299it [01:34, 14.27it/s]\titers: 1300, epoch: 12 | loss: 0.2074844\n",
      "\tspeed: 0.0710s/iter; left time: 2280.4308s\n",
      "1399it [01:41, 14.07it/s]\titers: 1400, epoch: 12 | loss: 0.2856647\n",
      "\tspeed: 0.0709s/iter; left time: 2271.1017s\n",
      "1499it [01:48, 14.12it/s]\titers: 1500, epoch: 12 | loss: 0.2659214\n",
      "\tspeed: 0.0754s/iter; left time: 2407.5798s\n",
      "1599it [01:56, 14.19it/s]\titers: 1600, epoch: 12 | loss: 0.3211598\n",
      "\tspeed: 0.0726s/iter; left time: 2309.7645s\n",
      "1699it [02:03, 13.81it/s]\titers: 1700, epoch: 12 | loss: 0.2616035\n",
      "\tspeed: 0.0710s/iter; left time: 2252.6176s\n",
      "1799it [02:10, 13.81it/s]\titers: 1800, epoch: 12 | loss: 0.2285235\n",
      "\tspeed: 0.0752s/iter; left time: 2377.4471s\n",
      "1899it [02:17, 13.83it/s]\titers: 1900, epoch: 12 | loss: 0.1519215\n",
      "\tspeed: 0.0719s/iter; left time: 2267.2943s\n",
      "1999it [02:25, 14.05it/s]\titers: 2000, epoch: 12 | loss: 0.1641596\n",
      "\tspeed: 0.0715s/iter; left time: 2247.4161s\n",
      "2099it [02:32, 14.47it/s]\titers: 2100, epoch: 12 | loss: 0.1987431\n",
      "\tspeed: 0.0746s/iter; left time: 2336.2543s\n",
      "2199it [02:39, 13.50it/s]\titers: 2200, epoch: 12 | loss: 0.1622933\n",
      "\tspeed: 0.0714s/iter; left time: 2228.1970s\n",
      "2299it [02:46, 12.08it/s]\titers: 2300, epoch: 12 | loss: 0.3297952\n",
      "\tspeed: 0.0726s/iter; left time: 2259.6582s\n",
      "2399it [02:54, 14.32it/s]\titers: 2400, epoch: 12 | loss: 0.3120134\n",
      "\tspeed: 0.0713s/iter; left time: 2212.3829s\n",
      "2499it [03:01, 12.91it/s]\titers: 2500, epoch: 12 | loss: 0.3803558\n",
      "\tspeed: 0.0760s/iter; left time: 2349.5569s\n",
      "2599it [03:09, 14.00it/s]\titers: 2600, epoch: 12 | loss: 0.2338369\n",
      "\tspeed: 0.0760s/iter; left time: 2342.1752s\n",
      "2699it [03:16, 14.07it/s]\titers: 2700, epoch: 12 | loss: 0.2216882\n",
      "\tspeed: 0.0709s/iter; left time: 2178.8919s\n",
      "2799it [03:23, 13.74it/s]\titers: 2800, epoch: 12 | loss: 0.2514156\n",
      "\tspeed: 0.0748s/iter; left time: 2289.9819s\n",
      "2899it [03:30, 14.08it/s]\titers: 2900, epoch: 12 | loss: 0.1984776\n",
      "\tspeed: 0.0712s/iter; left time: 2172.8250s\n",
      "2999it [03:38, 13.93it/s]\titers: 3000, epoch: 12 | loss: 0.3187185\n",
      "\tspeed: 0.0746s/iter; left time: 2267.9990s\n",
      "3099it [03:45, 14.13it/s]\titers: 3100, epoch: 12 | loss: 0.3006230\n",
      "\tspeed: 0.0710s/iter; left time: 2151.2398s\n",
      "3199it [03:53, 13.61it/s]\titers: 3200, epoch: 12 | loss: 0.2003332\n",
      "\tspeed: 0.0777s/iter; left time: 2349.2794s\n",
      "3299it [04:00, 14.27it/s]\titers: 3300, epoch: 12 | loss: 0.2321879\n",
      "\tspeed: 0.0701s/iter; left time: 2110.9833s\n",
      "3399it [04:07, 13.17it/s]\titers: 3400, epoch: 12 | loss: 0.1802494\n",
      "\tspeed: 0.0718s/iter; left time: 2155.2118s\n",
      "3499it [04:14, 14.13it/s]\titers: 3500, epoch: 12 | loss: 0.1800704\n",
      "\tspeed: 0.0750s/iter; left time: 2244.1145s\n",
      "3599it [04:22, 14.35it/s]\titers: 3600, epoch: 12 | loss: 0.1965446\n",
      "\tspeed: 0.0731s/iter; left time: 2179.7179s\n",
      "3699it [04:29, 10.86it/s]\titers: 3700, epoch: 12 | loss: 0.2436828\n",
      "\tspeed: 0.0759s/iter; left time: 2254.4577s\n",
      "3713it [04:30, 13.71it/s]\n",
      "Epoch: 12 cost time: 270.9184944629669\n",
      "810it [00:28, 28.54it/s]\n",
      "807it [00:30, 26.41it/s]\n",
      "Epoch: 12 | Train Loss: 0.2573993 Vali Loss: 0.3210966 Test Loss: 0.3996950 MAE Loss: 0.4048226\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.9531249999999967e-07\n",
      "learning_rate 0.0003999999999999993\n",
      "lr 1.9531249999999967e-07\n",
      "99it [00:07, 14.05it/s]\titers: 100, epoch: 13 | loss: 0.2138142\n",
      "\tspeed: 0.6765s/iter; left time: 20027.0102s\n",
      "199it [00:15, 13.93it/s]\titers: 200, epoch: 13 | loss: 0.3438984\n",
      "\tspeed: 0.0752s/iter; left time: 2217.8220s\n",
      "299it [00:22, 14.15it/s]\titers: 300, epoch: 13 | loss: 0.4544505\n",
      "\tspeed: 0.0754s/iter; left time: 2216.5705s\n",
      "399it [00:30, 14.33it/s]\titers: 400, epoch: 13 | loss: 0.3986380\n",
      "\tspeed: 0.0745s/iter; left time: 2184.2737s\n",
      "499it [00:37, 14.60it/s]\titers: 500, epoch: 13 | loss: 0.1931839\n",
      "\tspeed: 0.0707s/iter; left time: 2065.6630s\n",
      "599it [00:44, 13.34it/s]\titers: 600, epoch: 13 | loss: 0.1710044\n",
      "\tspeed: 0.0761s/iter; left time: 2215.6937s\n",
      "699it [00:51, 13.62it/s]\titers: 700, epoch: 13 | loss: 0.1983127\n",
      "\tspeed: 0.0708s/iter; left time: 2054.5026s\n",
      "799it [00:59, 10.65it/s]\titers: 800, epoch: 13 | loss: 0.2082743\n",
      "\tspeed: 0.0784s/iter; left time: 2264.7351s\n",
      "899it [01:06, 14.34it/s]\titers: 900, epoch: 13 | loss: 0.2282243\n",
      "\tspeed: 0.0722s/iter; left time: 2080.9284s\n",
      "999it [01:14, 12.39it/s]\titers: 1000, epoch: 13 | loss: 0.1703668\n",
      "\tspeed: 0.0750s/iter; left time: 2152.4020s\n",
      "1099it [01:21, 14.17it/s]\titers: 1100, epoch: 13 | loss: 0.1670852\n",
      "\tspeed: 0.0751s/iter; left time: 2148.3879s\n",
      "1199it [01:29, 12.76it/s]\titers: 1200, epoch: 13 | loss: 0.3117691\n",
      "\tspeed: 0.0711s/iter; left time: 2027.9371s\n",
      "1245it [01:32, 13.67it/s]^C\n",
      "[2024-05-07 22:47:12,895] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2024-05-07 22:47:12,895] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 36869 closing signal SIGINT\n",
      "1246it [01:32, 13.44it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 259, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Total time: 65.5531731804212 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.01\n",
    "llama_layers=12 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.94s/it]\n",
      "d_llm 4096\n",
      "[2024-05-07 01:04:13,384] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-07 01:04:14,225] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-07 01:04:14,225] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-07 01:04:14,226] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-07 01:04:15,198] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-07 01:04:15,199] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-07 01:04:26,997] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-07 01:04:26,998] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-07 01:04:26,998] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-07 01:04:26,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-07 01:04:26,999] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-07 01:04:27,000] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-07 01:04:27,000] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-07 01:04:27,000] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-07 01:04:27,000] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-07 01:04:27,000] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-07 01:04:27,285] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-07 01:04:27,286] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.67 GB         CA 12.68 GB         Max_CA 13 GB \n",
      "[2024-05-07 01:04:27,287] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.08 GB, percent = 15.9%\n",
      "[2024-05-07 01:04:27,421] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-07 01:04:27,422] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.76 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-07 01:04:27,422] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.08 GB, percent = 15.9%\n",
      "[2024-05-07 01:04:27,422] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-07 01:04:27,550] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-07 01:04:27,550] [INFO] [utils.py:801:see_memory_usage] MA 12.59 GB         Max_MA 12.59 GB         CA 12.84 GB         Max_CA 13 GB \n",
      "[2024-05-07 01:04:27,550] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.08 GB, percent = 15.9%\n",
      "[2024-05-07 01:04:27,551] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-07 01:04:27,551] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-07 01:04:27,551] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-07 01:04:27,551] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-07 01:04:27,552] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3cf0a825d0>\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 8\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  3\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-07 01:04:27,553] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-07 01:04:27,554] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 8, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 3, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "1069it [02:56,  6.11it/s]^C\n",
      "1069it [02:56,  6.05it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main_copy_copy.py\", line 208, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Total time: 4.079379705588023 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=32\n",
    "\n",
    "# num_process=1\n",
    "batch_size=3\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch  --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main_copy_copy.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"LLAMA\" \\\n",
    "  --llm_dim 4096 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
